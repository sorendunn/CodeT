{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file provides functions to help investigate the jsonl's produced by inference for debugging and general investigation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Here are some relevant code fragments from other files of the repo:\n",
      "# --------------------------------------------------\n",
      "# the below code fragment can be found in:\n",
      "# fortuna/prob_model/likelihood/regression.py\n",
      "# --------------------------------------------------\n",
      "# from typing import Optional, Union\n",
      "# \n",
      "# import jax.numpy as jnp\n",
      "# import numpy as np\n",
      "# from jax import vmap\n",
      "# from jax._src.prng import PRNGKeyArray\n",
      "# \n",
      "# from fortuna.data.loader import InputsLoader\n",
      "# from fortuna.model.model_manager.regression import RegressionModelManager\n",
      "# from fortuna.output_calibrator.output_calib_manager.base import \\\n",
      "#     OutputCalibManager\n",
      "# from fortuna.prob_model.likelihood.base import Likelihood\n",
      "# from fortuna.prob_output_layer.regression import RegressionProbOutputLayer\n",
      "# from fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n",
      "# \n",
      "# \n",
      "# class RegressionLikelihood(Likelihood):\n",
      "#     def __init__(\n",
      "#         self,\n",
      "#         model_manager: RegressionModelManager,\n",
      "# --------------------------------------------------\n",
      "\"\"\"Based on the above, complete the following code from the main script file:\"\"\"\n",
      "from fortuna.prob_output_layer.base import ProbOutputLayer\n",
      "from fortuna.typing import (Array, Batch, CalibMutable, CalibParams, Mutable,\n",
      "                            Params)\n",
      "from fortuna.utils.random import WithRNG\n",
      "\n",
      "\n",
      "class Likelihood(WithRNG):\n",
      "    def __init__(\n",
      "        self,\n",
      "        model_manager: ModelManager,\n"
     ]
    }
   ],
   "source": [
    "## View Prompt Examples\n",
    "# Function to read a JSON Lines file and return the prompt of a desired line\n",
    "def get_prompt_at_line(jsonl_file_path, desired_line_no):\n",
    "    with open(jsonl_file_path, 'r') as file:\n",
    "        for line_no, line in enumerate(file, start=1):\n",
    "            if line_no == desired_line_no:\n",
    "                json_object = json.loads(line)\n",
    "                prompt = json_object.get('prompt', None)\n",
    "                return prompt\n",
    "    return None  # Return None if the desired line was not found\n",
    "\n",
    "# Specify the .jsonl file path and the desired line number\n",
    "jsonl_file_path = 'temp_subsets/rg-one-gram-ws-20-ss-2-one-line_0.1_instruct_infile_snippets_10.jsonl'\n",
    "# jsonl_file_path = 'subsets/rg-one-gram-ws-20-ss-2-one-line_0.1_instruct.jsonl'\n",
    "desired_line_no = 64  # For example, we want the prompt at line 10\n",
    "\n",
    "# Get the prompt at the desired line\n",
    "prompt_at_desired_line = get_prompt_at_line(jsonl_file_path, desired_line_no)\n",
    "\n",
    "if prompt_at_desired_line:\n",
    "    print(prompt_at_desired_line)\n",
    "else:\n",
    "    print(f\"No prompt found at line {desired_line_no}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output JSONL file paths\n",
    "base_jsonl_name = \"rg-one-gram-ws-20-ss-10_0.1_instruct_temp_0_100\"\n",
    "\n",
    "use_system_message = True\n",
    "\n",
    "if use_system_message:\n",
    "    ending = \".jsonl\"\n",
    "else:\n",
    "    ending = \"_no_system.jsonl\"\n",
    "\n",
    "# Original and preprocessed JSONL file paths\n",
    "original_responses_path = 'raw_generations/' + base_jsonl_name + '_raw_generations' + ending\n",
    "input_jsonl_file_path = 'subsets/' + base_jsonl_name + '.jsonl'\n",
    "output_jsonl_file_path = \"processed_generations/\" + base_jsonl_name + \"_generations\" + ending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess api completions\n",
    "def preprocess_api_completion(completion):\n",
    "    # Extract content within ``\n",
    "    if '```python' in completion:\n",
    "        start = completion.find('```python') + 9  # Start index of content inside ``\n",
    "        end = completion.rfind('```')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "    elif '```' in completion:\n",
    "        start = completion.find('```') + 3  # Start index of content inside ``\n",
    "        end = completion.rfind('```')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "    elif '`' in completion:\n",
    "        start = completion.find('`') + 1  # Start index of content inside ``\n",
    "        end = completion.rfind('`')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "\n",
    "    # Remove lines starting with '#'\n",
    "    lines = [line.split('#', 1)[0].rstrip() for line in completion.split('\\n')]\n",
    "    # Save only the first non-empty line\n",
    "    final_string = \"\"\n",
    "    for line in lines:\n",
    "        final_string += line\n",
    "    return \" \".join(final_string.split()).replace(\"( \", \"(\").replace(\" )\", \")\")  # Return empty string if no non-empty lines are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the completion string\n",
    "def preprocess_completion(completion):\n",
    "    # Extract content within ```...```\n",
    "    end = None  # End index of content inside ```\n",
    "    if '```python' in completion:\n",
    "        start = completion.find('```python') + 9  # Start index of content inside ```python\n",
    "        end = completion.find('```', start)  # Find ending backticks after the start\n",
    "    elif '```' in completion:\n",
    "        start = completion.find('```') + 3  # Start index of content inside ```\n",
    "        end = completion.find('```', start)  # Find ending backticks after the start\n",
    "    elif '```py' in completion:\n",
    "        start = completion.find('```') + 5  # Start index of content inside ```py\n",
    "        end = completion.find('```', start)  # Find ending backticks after the start\n",
    "\n",
    "    if end == -1:  # If the closing backticks are not found\n",
    "        end = len(completion)  # Set end to the length of the string\n",
    "\n",
    "    # Extract the content if valid start and end indices are found\n",
    "    if end is not None and start < end:\n",
    "        completion = completion[start:end]\n",
    "    else:\n",
    "        return completion  # Return the original string if no valid code block is found\n",
    "\n",
    "    # Remove lines starting with '#'\n",
    "    lines = [line.split('#', 1)[0].rstrip() for line in completion.split('\\n')]\n",
    "\n",
    "    # Save only the first non-empty line\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            return \" \".join(line.split())\n",
    "\n",
    "    return completion  # Return the original string if no non-empty lines are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the same processing on the ground truth and completion as the evaluation code\n",
    "def process_completion_and_ground_truth(target, predictions, passk):\n",
    "    target_lines = [line.strip() for line in target.splitlines() if line.strip()]\n",
    "    for prediction in predictions[:passk]:\n",
    "        prediction_lines = [line.strip() for line in prediction.splitlines() if line.strip()][:len(target_lines)]\n",
    "    return prediction_lines, target_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSONL Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a jsonl with just the ground truth and the completion to compare the two\n",
    "\n",
    "# jsonl_path = \"processed_generations/rg-one-gram-ws-20-ss-2-fixed_0.1_with_instructions_temp_0_generations_processed.jsonl\"\n",
    "# jsonl_path = \"processed_generations/rg-one-gram-ws-20-ss-2-one-line_0.1_instruct_generations_processed.jsonl\"\n",
    "\n",
    "for jsonl_path in [output_jsonl_file_path, output_jsonl_file_path.replace(\".jsonl\",\"_processed.jsonl\")]:\n",
    "    with open(jsonl_path, 'r') as original_file, open(jsonl_path.replace(\".jsonl\",\"_gt.jsonl\"), 'w') as output_file:\n",
    "        for line in original_file:\n",
    "            entry = json.loads(line.strip())\n",
    "            if \"choices\" in entry:\n",
    "                completion = entry[\"choices\"][0][\"text\"]\n",
    "            else:\n",
    "                completion = entry[\"completion\"]\n",
    "            ground_truth = entry[\"metadata\"][\"ground_truth\"]\n",
    "            \n",
    "            output_entry = {\n",
    "                \"completion\": completion,\n",
    "                \"ground_truth\": ground_truth\n",
    "            }\n",
    "            \n",
    "            output_file.write(json.dumps(output_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process in the same way that is done for eval to see if there are any easy fixes here\n",
    "# jsonl_path = \"processed_generations/rg-one-gram-ws-20-ss-2-one-line_0.1_instruct_generations.jsonl\"\n",
    "\n",
    "for jsonl_path in [output_jsonl_file_path, output_jsonl_file_path.replace(\".jsonl\",\"_processed.jsonl\")]:\n",
    "    with open(jsonl_path, 'r') as original_file, open(jsonl_path.replace(\".jsonl\",\"_eval_gt.jsonl\"), 'w') as output_file:\n",
    "        for line in original_file:\n",
    "            entry = json.loads(line.strip())\n",
    "            completion = [entry['choices'][0][\"text\"]]\n",
    "            ground_truth = entry[\"metadata\"][\"ground_truth\"]\n",
    "            completion_processed, ground_truth_processed = process_completion_and_ground_truth(ground_truth, completion, 1)\n",
    "            \n",
    "            output_entry = {\n",
    "                \"completion\": completion_processed,\n",
    "                \"ground_truth\": ground_truth_processed\n",
    "            }\n",
    "            \n",
    "            output_file.write(json.dumps(output_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSONL Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"completion\": [\"yield from self._targets_loader()\"], \"ground_truth\": [\"yield from self._targets_loader()\"]}\n",
      "{\"completion\": [\"prohibited.add(\\\"done\\\")\"], \"ground_truth\": [\"prohibited.add(\\\"done\\\")\"]}\n",
      "{\"completion\": [\"parser.add_argument(\"], \"ground_truth\": [\"parser.add_argument(\"]}\n",
      "{\"completion\": [\"}\"], \"ground_truth\": [\"}\"]}\n",
      "{\"completion\": [\"calib_data_loader=calib_data_loader,\"], \"ground_truth\": [\"calib_data_loader=calib_data_loader,\"]}\n",
      "{\"completion\": [\"scheduler_config = self.get_scheduler_config()\"], \"ground_truth\": [\"scheduler_config = self.get_scheduler_config()\"]}\n",
      "{\"completion\": [\"conv: ModuleDef = nn.Conv\"], \"ground_truth\": [\"conv: ModuleDef = nn.Conv\"]}\n",
      "{\"completion\": [\"{\"], \"ground_truth\": [\"{\"]}\n",
      "{\"completion\": [\"prob_output_layer: ProbOutputLayer,\"], \"ground_truth\": [\"prob_output_layer: ProbOutputLayer,\"]}\n",
      "{\"completion\": [\"model must have been calibrated beforehand.\"], \"ground_truth\": [\"model must have been calibrated beforehand.\"]}\n",
      "{\"completion\": [\"self, tensordict: Optional[TensorDictBase] = None, **kwargs\"], \"ground_truth\": [\"self, tensordict: Optional[TensorDictBase] = None, **kwargs\"]}\n",
      "{\"completion\": [\"(\"], \"ground_truth\": [\"(\"]}\n",
      "{\"completion\": [\"images = images.cpu().permute(0, 2, 3, 1).numpy()\"], \"ground_truth\": [\"images = images.cpu().permute(0, 2, 3, 1).numpy()\"]}\n",
      "{\"completion\": [\"env.set_seed(seed)\"], \"ground_truth\": [\"env.set_seed(seed)\"]}\n",
      "{\"completion\": [\"calib_config=calib_config,\"], \"ground_truth\": [\"calib_config=calib_config,\"]}\n",
      "{\"completion\": [\") -> Dict[str, jnp.ndarray]:\"], \"ground_truth\": [\") -> Dict[str, jnp.ndarray]:\"]}\n",
      "{\"completion\": [\"_init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\\\"], \"ground_truth\": [\"_init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\\\"]}\n",
      "{\"completion\": [\"addscore = 2 * addscore_precision * addscore_recall / (addscore_precision + addscore_recall)\"], \"ground_truth\": [\"addscore = 2 * addscore_precision * addscore_recall / (addscore_precision + addscore_recall)\"]}\n",
      "{\"completion\": [\"from_pixels = kwargs.pop(\\\"from_pixels\\\", False)\"], \"ground_truth\": [\"from_pixels = kwargs.pop(\\\"from_pixels\\\", False)\"]}\n",
      "{\"completion\": [\"self._fun = fun\"], \"ground_truth\": [\"self._fun = fun\"]}\n",
      "{\"completion\": [\"beta_end: float = 0.02,\"], \"ground_truth\": [\"beta_end: float = 0.02,\"]}\n",
      "{\"completion\": [\"},\"], \"ground_truth\": [\"},\"]}\n",
      "{\"completion\": [\"collect_demo_data(\"], \"ground_truth\": [\"collect_demo_data(\"]}\n",
      "{\"completion\": [\"return size + idx\"], \"ground_truth\": [\"return size + idx\"]}\n",
      "{\"completion\": [\"if rank == 0:\"], \"ground_truth\": [\"if rank == 0:\"]}\n",
      "{\"completion\": [\"dataset = TUDataset(self.root, name)\"], \"ground_truth\": [\"dataset = TUDataset(self.root, name)\"]}\n",
      "{\"completion\": [\"dropout_rate=self.dropout_rate,\"], \"ground_truth\": [\"dropout_rate=self.dropout_rate,\"]}\n",
      "{\"completion\": [\"spec = None\"], \"ground_truth\": [\"spec = None\"]}\n",
      "{\"completion\": [\"tsf_loc = (\"], \"ground_truth\": [\"tsf_loc = (\"]}\n",
      "{\"completion\": [\"baseline_benchmark_state_factory: benchmarks.BenchmarkStateFactory,\"], \"ground_truth\": [\"baseline_benchmark_state_factory: benchmarks.BenchmarkStateFactory,\"]}\n",
      "{\"completion\": [\"import os\"], \"ground_truth\": [\"import os\"]}\n",
      "{\"completion\": [\"calib_config=self.reg_calib_config_nodir_nodump,\"], \"ground_truth\": [\"calib_config=self.reg_calib_config_nodir_nodump,\"]}\n",
      "{\"completion\": [\"*args,\"], \"ground_truth\": [\"*args,\"]}\n",
      "{\"completion\": [\">>> references = [[\\\"does this sentence match\\\", \\\"does this sentence match!?!\\\"],\"], \"ground_truth\": [\">>> references = [[\\\"does this sentence match\\\", \\\"does this sentence match!?!\\\"],\"]}\n",
      "{\"completion\": [\"for x, t in zip(evaluation_modules, evaluation_module_types)\"], \"ground_truth\": [\"for x, t in zip(evaluation_modules, evaluation_module_types)\"]}\n",
      "{\"completion\": [\"n_data=10,\"], \"ground_truth\": [\"n_data=10,\"]}\n",
      "{\"completion\": [\"progress_bar.update(len(data))\"], \"ground_truth\": [\"progress_bar.update(len(data))\"]}\n",
      "{\"completion\": [\"kernel_size=_kernel,\"], \"ground_truth\": [\"kernel_size=_kernel,\"]}\n",
      "{\"completion\": [\"MultiDeviceCalibModelCalibrator)\"], \"ground_truth\": [\"MultiDeviceCalibModelCalibrator)\"]}\n",
      "{\"completion\": [\"global_obs_shape: int,\"], \"ground_truth\": [\"global_obs_shape: int,\"]}\n",
      "{\"completion\": [\"self._trial = self._trial_client.materialize()\"], \"ground_truth\": [\"self._trial = self._trial_client.materialize()\"]}\n",
      "{\"completion\": [\"self.assertFalse(improved)\"], \"ground_truth\": [\"self.assertFalse(improved)\"]}\n",
      "{\"completion\": [\"scores: Optional[Array] = None,\"], \"ground_truth\": [\"scores: Optional[Array] = None,\"]}\n",
      "{\"completion\": [\"time.sleep(0.1)\"], \"ground_truth\": [\"time.sleep(0.1)\"]}\n",
      "{\"completion\": [\"else:\"], \"ground_truth\": [\"else:\"]}\n",
      "{\"completion\": [\"return results\"], \"ground_truth\": [\"return results\"]}\n",
      "{\"completion\": [\"start_index = batch * batch_size\"], \"ground_truth\": [\"start_index = batch * batch_size\"]}\n",
      "{\"completion\": [\"image quality. This pipeline requires a value of at least `1`.\"], \"ground_truth\": [\"image quality. This pipeline requires a value of at least `1`.\"]}\n",
      "{\"completion\": [\"def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\"], \"ground_truth\": [\"def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\"]}\n",
      "{\"completion\": [\"tensordict = TensorDict({}, self.batch_size, device=self.device)\"], \"ground_truth\": [\"tensordict = TensorDict({}, self.batch_size, device=self.device)\"]}\n",
      "{\"completion\": [\"transformer=transformer,\"], \"ground_truth\": [\"transformer=transformer,\"]}\n",
      "{\"completion\": [\".select(*self.qvalue_network.in_keys)\"], \"ground_truth\": [\".select(*self.qvalue_network.in_keys)\"]}\n",
      "{\"completion\": [\"predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)\"], \"ground_truth\": [\"predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)\"]}\n",
      "{\"completion\": [\"config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\"], \"ground_truth\": [\"config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\"]}\n",
      "{\"completion\": [\"(1, 0, preds_0, refs_0, None, tmp_dir, 0),\"], \"ground_truth\": [\"(1, 0, preds_0, refs_0, None, tmp_dir, 0),\"]}\n",
      "{\"completion\": [\"env.set_seed(seed)\"], \"ground_truth\": [\"env.set_seed(seed)\"]}\n",
      "{\"completion\": [\"proto.value.string_value = parameter_value.value\"], \"ground_truth\": [\"proto.value.string_value = parameter_value.value\"]}\n",
      "{\"completion\": [\"for i, pad_idx in enumerate(num_non_padding):\"], \"ground_truth\": [\"for i, pad_idx in enumerate(num_non_padding):\"]}\n",
      "{\"completion\": [\"\\\"image\\\": init_image,\"], \"ground_truth\": [\"\\\"image\\\": init_image,\"]}\n",
      "{\"completion\": [\"_, idx = model(data)\"], \"ground_truth\": [\"_, idx = model(data)\"]}\n",
      "{\"completion\": [\"return out\"], \"ground_truth\": [\"return out\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the function to compare two JSONL files\n",
    "def compare_jsonl(file1, file2):\n",
    "    # Open the first JSONL file\n",
    "    with open(file1, 'r') as f1:\n",
    "        # Read lines into a list of dictionaries\n",
    "        lines1 = [json.loads(line.strip()) for line in f1]\n",
    "\n",
    "    # Open the second JSONL file\n",
    "    with open(file2, 'r') as f2:\n",
    "        # Read lines into a list of dictionaries\n",
    "        lines2 = [json.loads(line.strip()) for line in f2]\n",
    "\n",
    "    # Ensure both files have the same number of lines to compare\n",
    "    if len(lines1) != len(lines2):\n",
    "        print(\"Files have different number of lines and cannot be compared.\")\n",
    "        return\n",
    "\n",
    "    # Loop through both lists and check for matching 'completion' and 'ground_truth'\n",
    "    # in file1 but not in file2\n",
    "    for line1, line2 in zip(lines1, lines2):\n",
    "        if (line1['completion'] == line1['ground_truth']) and (line2['completion'] != line2['ground_truth']):\n",
    "            print(json.dumps(line1))  # Convert the dictionary back to JSON string format for printing\n",
    "\n",
    "# Example usage\n",
    "file1 = 'processed_generations/rg-one-gram-ws-20-ss-2-one-line_0.1_instruct_generations_processed_eval_gt.jsonl'\n",
    "file2 = 'processed_generations/rg-one-gram-ws-20-ss-2-one-line_0.1_instruct_generations_processed_gt.jsonl'\n",
    "\n",
    "compare_jsonl(file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"completion\": [\"yield from self._targets_loader()\"], \"ground_truth\": [\"yield from self._targets_loader()\"]}\n",
      "{\"completion\": [\"prohibited.add(\\\"done\\\")\"], \"ground_truth\": [\"prohibited.add(\\\"done\\\")\"]}\n",
      "{\"completion\": [\"parser.add_argument(\"], \"ground_truth\": [\"parser.add_argument(\"]}\n",
      "{\"completion\": [\"}\"], \"ground_truth\": [\"}\"]}\n",
      "{\"completion\": [\"calib_data_loader=calib_data_loader,\"], \"ground_truth\": [\"calib_data_loader=calib_data_loader,\"]}\n",
      "{\"completion\": [\"scheduler_config = self.get_scheduler_config()\"], \"ground_truth\": [\"scheduler_config = self.get_scheduler_config()\"]}\n",
      "{\"completion\": [\"conv: ModuleDef = nn.Conv\"], \"ground_truth\": [\"conv: ModuleDef = nn.Conv\"]}\n",
      "{\"completion\": [\"{\"], \"ground_truth\": [\"{\"]}\n",
      "{\"completion\": [\"prob_output_layer: ProbOutputLayer,\"], \"ground_truth\": [\"prob_output_layer: ProbOutputLayer,\"]}\n",
      "{\"completion\": [\"model must have been calibrated beforehand.\"], \"ground_truth\": [\"model must have been calibrated beforehand.\"]}\n",
      "{\"completion\": [\"self, tensordict: Optional[TensorDictBase] = None, **kwargs\"], \"ground_truth\": [\"self, tensordict: Optional[TensorDictBase] = None, **kwargs\"]}\n",
      "{\"completion\": [\"(\"], \"ground_truth\": [\"(\"]}\n",
      "{\"completion\": [\"images = images.cpu().permute(0, 2, 3, 1).numpy()\"], \"ground_truth\": [\"images = images.cpu().permute(0, 2, 3, 1).numpy()\"]}\n",
      "{\"completion\": [\"env.set_seed(seed)\"], \"ground_truth\": [\"env.set_seed(seed)\"]}\n",
      "{\"completion\": [\"calib_config=calib_config,\"], \"ground_truth\": [\"calib_config=calib_config,\"]}\n",
      "{\"completion\": [\") -> Dict[str, jnp.ndarray]:\"], \"ground_truth\": [\") -> Dict[str, jnp.ndarray]:\"]}\n",
      "{\"completion\": [\"_init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\\\"], \"ground_truth\": [\"_init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\\\"]}\n",
      "{\"completion\": [\"addscore = 2 * addscore_precision * addscore_recall / (addscore_precision + addscore_recall)\"], \"ground_truth\": [\"addscore = 2 * addscore_precision * addscore_recall / (addscore_precision + addscore_recall)\"]}\n",
      "{\"completion\": [\"from_pixels = kwargs.pop(\\\"from_pixels\\\", False)\"], \"ground_truth\": [\"from_pixels = kwargs.pop(\\\"from_pixels\\\", False)\"]}\n",
      "{\"completion\": [\"self._fun = fun\"], \"ground_truth\": [\"self._fun = fun\"]}\n",
      "{\"completion\": [\"from federatedscope.core.auxiliaries.runner_builder import get_runner\"], \"ground_truth\": [\"from federatedscope.core.auxiliaries.runner_builder import get_runner\"]}\n",
      "{\"completion\": [\"beta_end: float = 0.02,\"], \"ground_truth\": [\"beta_end: float = 0.02,\"]}\n",
      "{\"completion\": [\"},\"], \"ground_truth\": [\"},\"]}\n",
      "{\"completion\": [\"collect_demo_data(\"], \"ground_truth\": [\"collect_demo_data(\"]}\n",
      "{\"completion\": [\"return size + idx\"], \"ground_truth\": [\"return size + idx\"]}\n",
      "{\"completion\": [\"if rank == 0:\"], \"ground_truth\": [\"if rank == 0:\"]}\n",
      "{\"completion\": [\"dataset = TUDataset(self.root, name)\"], \"ground_truth\": [\"dataset = TUDataset(self.root, name)\"]}\n",
      "{\"completion\": [\"dropout_rate=self.dropout_rate,\"], \"ground_truth\": [\"dropout_rate=self.dropout_rate,\"]}\n",
      "{\"completion\": [\"spec = None\"], \"ground_truth\": [\"spec = None\"]}\n",
      "{\"completion\": [\"tsf_loc = (\"], \"ground_truth\": [\"tsf_loc = (\"]}\n",
      "{\"completion\": [\"baseline_benchmark_state_factory: benchmarks.BenchmarkStateFactory,\"], \"ground_truth\": [\"baseline_benchmark_state_factory: benchmarks.BenchmarkStateFactory,\"]}\n",
      "{\"completion\": [\"import os\"], \"ground_truth\": [\"import os\"]}\n",
      "{\"completion\": [\"calib_config=self.reg_calib_config_nodir_nodump,\"], \"ground_truth\": [\"calib_config=self.reg_calib_config_nodir_nodump,\"]}\n",
      "{\"completion\": [\"*args,\"], \"ground_truth\": [\"*args,\"]}\n",
      "{\"completion\": [\"for x, t in zip(evaluation_modules, evaluation_module_types)\"], \"ground_truth\": [\"for x, t in zip(evaluation_modules, evaluation_module_types)\"]}\n",
      "{\"completion\": [\"n_data=10,\"], \"ground_truth\": [\"n_data=10,\"]}\n",
      "{\"completion\": [\"kernel_size=_kernel,\"], \"ground_truth\": [\"kernel_size=_kernel,\"]}\n",
      "{\"completion\": [\"MultiDeviceCalibModelCalibrator)\"], \"ground_truth\": [\"MultiDeviceCalibModelCalibrator)\"]}\n",
      "{\"completion\": [\"global_obs_shape: int,\"], \"ground_truth\": [\"global_obs_shape: int,\"]}\n",
      "{\"completion\": [\"self._trial = self._trial_client.materialize()\"], \"ground_truth\": [\"self._trial = self._trial_client.materialize()\"]}\n",
      "{\"completion\": [\"self.assertFalse(improved)\"], \"ground_truth\": [\"self.assertFalse(improved)\"]}\n",
      "{\"completion\": [\"scores: Optional[Array] = None,\"], \"ground_truth\": [\"scores: Optional[Array] = None,\"]}\n",
      "{\"completion\": [\"time.sleep(0.1)\"], \"ground_truth\": [\"time.sleep(0.1)\"]}\n",
      "{\"completion\": [\"else:\"], \"ground_truth\": [\"else:\"]}\n",
      "{\"completion\": [\"return results\"], \"ground_truth\": [\"return results\"]}\n",
      "{\"completion\": [\"start_index = batch * batch_size\"], \"ground_truth\": [\"start_index = batch * batch_size\"]}\n",
      "{\"completion\": [\"image quality. This pipeline requires a value of at least `1`.\"], \"ground_truth\": [\"image quality. This pipeline requires a value of at least `1`.\"]}\n",
      "{\"completion\": [\"def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\"], \"ground_truth\": [\"def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\"]}\n",
      "{\"completion\": [\"tensordict = TensorDict({}, self.batch_size, device=self.device)\"], \"ground_truth\": [\"tensordict = TensorDict({}, self.batch_size, device=self.device)\"]}\n",
      "{\"completion\": [\"transformer=transformer,\"], \"ground_truth\": [\"transformer=transformer,\"]}\n",
      "{\"completion\": [\".select(*self.qvalue_network.in_keys)\"], \"ground_truth\": [\".select(*self.qvalue_network.in_keys)\"]}\n",
      "{\"completion\": [\"kwargs[\\\"num_inference_steps\\\"] = num_inference_steps\"], \"ground_truth\": [\"kwargs[\\\"num_inference_steps\\\"] = num_inference_steps\"]}\n",
      "{\"completion\": [\"predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)\"], \"ground_truth\": [\"predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)\"]}\n",
      "{\"completion\": [\"config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\"], \"ground_truth\": [\"config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\"]}\n",
      "{\"completion\": [\"(1, 0, preds_0, refs_0, None, tmp_dir, 0),\"], \"ground_truth\": [\"(1, 0, preds_0, refs_0, None, tmp_dir, 0),\"]}\n",
      "{\"completion\": [\"env.set_seed(seed)\"], \"ground_truth\": [\"env.set_seed(seed)\"]}\n",
      "{\"completion\": [\"proto.value.string_value = parameter_value.value\"], \"ground_truth\": [\"proto.value.string_value = parameter_value.value\"]}\n",
      "{\"completion\": [\"for i, pad_idx in enumerate(num_non_padding):\"], \"ground_truth\": [\"for i, pad_idx in enumerate(num_non_padding):\"]}\n",
      "{\"completion\": [\"\\\"image\\\": init_image,\"], \"ground_truth\": [\"\\\"image\\\": init_image,\"]}\n",
      "{\"completion\": [\"_, idx = model(data)\"], \"ground_truth\": [\"_, idx = model(data)\"]}\n",
      "{\"completion\": [\"return out\"], \"ground_truth\": [\"return out\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the function to find matching completion and ground_truth\n",
    "def print_matching_lines(jsonl_file):\n",
    "    # Open the JSONL file\n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        # Iterate over each line in the file\n",
    "        for line in f:\n",
    "            # Parse the JSON content\n",
    "            data = json.loads(line.strip())\n",
    "            # Check if the completion and ground_truth match\n",
    "            if data['completion'] == data['ground_truth']:\n",
    "                # Convert dictionary to JSON string and print\n",
    "                print(json.dumps(data))\n",
    "\n",
    "# Example usage\n",
    "jsonl_file = 'processed_generations/rg-one-gram-ws-20-ss-2-one-line_0.1_instruct_generations_eval_gt.jsonl'\n",
    "print_matching_lines(jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"completion\": [\"parser.add_argument(\"], \"ground_truth\": [\"parser.add_argument(\"]}\n",
      "{\"completion\": [\"yield from self._targets_loader()\"], \"ground_truth\": [\"yield from self._targets_loader()\"]}\n",
      "{\"completion\": [\"prob_output_layer: ProbOutputLayer,\"], \"ground_truth\": [\"prob_output_layer: ProbOutputLayer,\"]}\n",
      "{\"completion\": [\"{\"], \"ground_truth\": [\"{\"]}\n",
      "{\"completion\": [\"scheduler_config = self.get_scheduler_config()\"], \"ground_truth\": [\"scheduler_config = self.get_scheduler_config()\"]}\n",
      "{\"completion\": [\"if self.is_functional and params is None:\"], \"ground_truth\": [\"if self.is_functional and params is None:\"]}\n",
      "{\"completion\": [\"prohibited.add(\\\"done\\\")\"], \"ground_truth\": [\"prohibited.add(\\\"done\\\")\"]}\n",
      "{\"completion\": [\"calib_data_loader=calib_data_loader,\"], \"ground_truth\": [\"calib_data_loader=calib_data_loader,\"]}\n",
      "{\"completion\": [\"(\"], \"ground_truth\": [\"(\"]}\n",
      "{\"completion\": [\"self, tensordict: Optional[TensorDictBase] = None, **kwargs\"], \"ground_truth\": [\"self, tensordict: Optional[TensorDictBase] = None, **kwargs\"]}\n",
      "{\"completion\": [\"conv: ModuleDef = nn.Conv\"], \"ground_truth\": [\"conv: ModuleDef = nn.Conv\"]}\n",
      "{\"completion\": [\"_init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\\\"], \"ground_truth\": [\"_init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\\\"]}\n",
      "{\"completion\": [\"model must have been calibrated beforehand.\"], \"ground_truth\": [\"model must have been calibrated beforehand.\"]}\n",
      "{\"completion\": [\"int_max_value = int(max_value)\"], \"ground_truth\": [\"int_max_value = int(max_value)\"]}\n",
      "{\"completion\": [\"val_data_loader=self.reg_val_data_loader,\"], \"ground_truth\": [\"val_data_loader=self.reg_val_data_loader,\"]}\n",
      "{\"completion\": [\"images = images.cpu().permute(0, 2, 3, 1).numpy()\"], \"ground_truth\": [\"images = images.cpu().permute(0, 2, 3, 1).numpy()\"]}\n",
      "{\"completion\": [\"scheduler = scheduler_class(**scheduler_config)\"], \"ground_truth\": [\"scheduler = scheduler_class(**scheduler_config)\"]}\n",
      "{\"completion\": [\") -> Dict[str, jnp.ndarray]:\"], \"ground_truth\": [\") -> Dict[str, jnp.ndarray]:\"]}\n",
      "{\"completion\": [\"hpc_action = hpc_action.cuda()\"], \"ground_truth\": [\"hpc_action = hpc_action.cuda()\"]}\n",
      "{\"completion\": [\"self.evaluation_module_names = [module.name for module in self.evaluation_modules]\"], \"ground_truth\": [\"self.evaluation_module_names = [module.name for module in self.evaluation_modules]\"]}\n",
      "{\"completion\": [\"default=\\\"LazyMemmapStorage\\\",\"], \"ground_truth\": [\"default=\\\"LazyMemmapStorage\\\",\"]}\n",
      "{\"completion\": [\"self._fun = fun\"], \"ground_truth\": [\"self._fun = fun\"]}\n",
      "{\"completion\": [\"from ding.config import read_config, compile_config\"], \"ground_truth\": [\"from ding.config import read_config, compile_config\"]}\n",
      "{\"completion\": [\"from federatedscope.core.auxiliaries.runner_builder import get_runner\"], \"ground_truth\": [\"from federatedscope.core.auxiliaries.runner_builder import get_runner\"]}\n",
      "{\"completion\": [\"for line in lines:\"], \"ground_truth\": [\"for line in lines:\"]}\n",
      "{\"completion\": [\"{\\\"start\\\": 0, \\\"entity\\\": \\\"B-LOC\\\"},\"], \"ground_truth\": [\"{\\\"start\\\": 0, \\\"entity\\\": \\\"B-LOC\\\"},\"]}\n",
      "{\"completion\": [\"return results\"], \"ground_truth\": [\"return results\"]}\n",
      "{\"completion\": [\"return size + idx\"], \"ground_truth\": [\"return size + idx\"]}\n",
      "{\"completion\": [\"plt.title(\\\"value\\\")\"], \"ground_truth\": [\"plt.title(\\\"value\\\")\"]}\n",
      "{\"completion\": [\"tsf_loc = (\"], \"ground_truth\": [\"tsf_loc = (\"]}\n",
      "{\"completion\": [\"action_dim_gsde, state_dim_gsde = None, None\"], \"ground_truth\": [\"action_dim_gsde, state_dim_gsde = None, None\"]}\n",
      "{\"completion\": [\"dropout_rate=self.dropout_rate,\"], \"ground_truth\": [\"dropout_rate=self.dropout_rate,\"]}\n",
      "{\"completion\": [\"calib_config=self.class_calib_config_nodir_nodump,\"], \"ground_truth\": [\"calib_config=self.class_calib_config_nodir_nodump,\"]}\n",
      "{\"completion\": [\"kwargs[\\\"num_inference_steps\\\"] = num_inference_steps\"], \"ground_truth\": [\"kwargs[\\\"num_inference_steps\\\"] = num_inference_steps\"]}\n",
      "{\"completion\": [\"calib_config=self.reg_calib_config_nodir_nodump,\"], \"ground_truth\": [\"calib_config=self.reg_calib_config_nodir_nodump,\"]}\n",
      "{\"completion\": [\"_has_ts = False\"], \"ground_truth\": [\"_has_ts = False\"]}\n",
      "{\"completion\": [\"config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\"], \"ground_truth\": [\"config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\"]}\n",
      "{\"completion\": [\"del tdmodule[3]\"], \"ground_truth\": [\"del tdmodule[3]\"]}\n",
      "{\"completion\": [\"collect_demo_data(\"], \"ground_truth\": [\"collect_demo_data(\"]}\n",
      "{\"completion\": [\"predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)\"], \"ground_truth\": [\"predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)\"]}\n",
      "{\"completion\": [\"yield from self._inputs_loader()\"], \"ground_truth\": [\"yield from self._inputs_loader()\"]}\n",
      "{\"completion\": [\"*args,\"], \"ground_truth\": [\"*args,\"]}\n",
      "{\"completion\": [\"if isinstance(replay_path, str):\"], \"ground_truth\": [\"if isinstance(replay_path, str):\"]}\n",
      "{\"completion\": [\"while True:\"], \"ground_truth\": [\"while True:\"]}\n",
      "{\"completion\": [\"raise RuntimeError(\"], \"ground_truth\": [\"raise RuntimeError(\"]}\n",
      "{\"completion\": [\"MultiDeviceCalibModelCalibrator)\"], \"ground_truth\": [\"MultiDeviceCalibModelCalibrator)\"]}\n",
      "{\"completion\": [\"cfg.data.type = 'toy'\"], \"ground_truth\": [\"cfg.data.type = 'toy'\"]}\n",
      "{\"completion\": [\"global_obs_shape: int,\"], \"ground_truth\": [\"global_obs_shape: int,\"]}\n",
      "{\"completion\": [\"plt.title(\\\"value\\\")\"], \"ground_truth\": [\"plt.title(\\\"value\\\")\"]}\n",
      "{\"completion\": [\"self.assertFalse(improved)\"], \"ground_truth\": [\"self.assertFalse(improved)\"]}\n",
      "{\"completion\": [\"scores: Optional[Array] = None,\"], \"ground_truth\": [\"scores: Optional[Array] = None,\"]}\n",
      "{\"completion\": [\"py_study_config = vz.StudyConfig(\"], \"ground_truth\": [\"py_study_config = vz.StudyConfig(\"]}\n",
      "{\"completion\": [\"start_index = batch * batch_size\"], \"ground_truth\": [\"start_index = batch * batch_size\"]}\n",
      "{\"completion\": [\"spec = None\"], \"ground_truth\": [\"spec = None\"]}\n",
      "{\"completion\": [\"def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\"], \"ground_truth\": [\"def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\"]}\n",
      "{\"completion\": [\".select(*self.qvalue_network.in_keys)\"], \"ground_truth\": [\".select(*self.qvalue_network.in_keys)\"]}\n",
      "{\"completion\": [\"transformer=transformer,\"], \"ground_truth\": [\"transformer=transformer,\"]}\n",
      "{\"completion\": [\"def _set_seed_initial(self, seed: int) -> None:\"], \"ground_truth\": [\"def _set_seed_initial(self, seed: int) -> None:\"]}\n",
      "{\"completion\": [\"num_images_per_prompt (`int`, *optional*, defaults to 1):\"], \"ground_truth\": [\"num_images_per_prompt (`int`, *optional*, defaults to 1):\"]}\n",
      "{\"completion\": [\"import os\"], \"ground_truth\": [\"import os\"]}\n",
      "{\"completion\": [\"model_id=\\\"username/repo\\\",\"], \"ground_truth\": [\"model_id=\\\"username/repo\\\",\"]}\n",
      "{\"completion\": [\"for i, pad_idx in enumerate(num_non_padding):\"], \"ground_truth\": [\"for i, pad_idx in enumerate(num_non_padding):\"]}\n",
      "{\"completion\": [\"\\\"image\\\": init_image,\"], \"ground_truth\": [\"\\\"image\\\": init_image,\"]}\n",
      "{\"completion\": [\"_, idx = model(data)\"], \"ground_truth\": [\"_, idx = model(data)\"]}\n",
      "{\"completion\": [\"The user can define and use customized network model but must obey the same inferface definition indicated \\\\\"], \"ground_truth\": [\"The user can define and use customized network model but must obey the same inferface definition indicated \\\\\"]}\n",
      "{\"completion\": [\"SafeProbabilisticSequential(\"], \"ground_truth\": [\"SafeProbabilisticSequential(\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the function to find matching completion and ground_truth\n",
    "def print_matching_lines(jsonl_file):\n",
    "    # Open the JSONL file\n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        # Iterate over each line in the file\n",
    "        for line in f:\n",
    "            # Parse the JSON content\n",
    "            data = json.loads(line.strip())\n",
    "            # Check if the completion and ground_truth match\n",
    "            if data['completion'] == data['ground_truth']:\n",
    "                # Convert dictionary to JSON string and print\n",
    "                print(json.dumps(data))\n",
    "                \n",
    "jsonl_file = 'processed_generations/rg-one-gram-ws-20-ss-2-fixed_0.1_with_instructions_temp_0_generations_processed_eval_gt.jsonl'\n",
    "print_matching_lines(jsonl_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
