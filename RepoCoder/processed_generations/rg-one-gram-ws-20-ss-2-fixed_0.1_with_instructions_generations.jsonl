{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/_utils.py\n# --------------------------------------------------\n#             )\n#             print(\" -- \".join(strings))\n# \n#     @staticmethod\n#     def erase():\n#         for k in timeit._REG:\n#             timeit._REG[k] = [0.0, 0.0, 0]\n# \n# \n# def _check_for_faulty_process(processes):\n#     terminate = False\n#     for p in processes:\n#         if not p.is_alive():\n#             terminate = True\n#             for _p in processes:\n#                 if _p.is_alive():\n#                     _p.terminate()\n#         if terminate:\n#             break\n#     if terminate:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#             state_dict[f\"worker{idx}\"] = _state_dict\n# \n#         return state_dict\n# \n#     @_check_start\n#     def load_state_dict(self, state_dict: OrderedDict) -> None:\n#         if \"worker0\" not in state_dict:\n#             state_dict = OrderedDict(\n#                 **{f\"worker{idx}\": state_dict for idx in range(self.num_workers)}\n#             )\n#         for i, channel in enumerate(self.parent_channels):\n#             channel.send((\"load_state_dict\", state_dict[f\"worker{i}\"]))\n#         for channel in self.parent_channels:\n#             msg, _ = channel.recv()\n#             if msg != \"loaded\":\n#                 raise RuntimeError(f\"Expected 'loaded' but received {msg}\")\n# \n#     @_check_start\n#     def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         self._assert_tensordict_shape(tensordict)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/_utils_internal.py\n# --------------------------------------------------\n#     return devices\n# \n# \n# def generate_seeds(seed, repeat):\n#     seeds = [seed]\n#     for _ in range(repeat - 1):\n#         seed = seed_generator(seed)\n#         seeds.append(seed)\n#     return seeds\n# \n# \n# # Decorator to retry upon certain Exceptions.\n# def retry(ExceptionToCheck, tries=3, delay=3, skip_after_retries=False):\n#     def deco_retry(f):\n#         @wraps(f)\n#         def f_retry(*args, **kwargs):\n#             mtries, mdelay = tries, delay\n#             while mtries > 1:\n#                 try:\n#                     return f(*args, **kwargs)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n# \n#         elif cmd == \"state_dict\":\n#             state_dict = _recursively_strip_locks_from_state_dict(env.state_dict())\n#             msg = \"state_dict\"\n#             child_pipe.send((msg, state_dict))\n# \n#         else:\n#             err_msg = f\"{cmd} from env\"\n#             try:\n#                 attr = getattr(env, cmd)\n#                 if callable(attr):\n#                     args, kwargs = data\n#                     args_replace = []\n#                     for _arg in args:\n#                         if isinstance(_arg, str) and _arg == \"_self\":\n#                             continue\n#                         else:\n#                             args_replace.append(_arg)\n#                     result = attr(*args_replace, **kwargs)\n#                 else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# build_tools/setup_helpers/extension.py\n# --------------------------------------------------\n#                 [\"cmake\", str(_ROOT_DIR)] + cmake_args,\n#                 cwd=self.build_temp,\n#                 stderr=STDOUT,\n#             )\n#         except CalledProcessError as exc:\n#             print(exc.output)\n# \n#         try:\n#             check_output(\n#                 [\"cmake\", \"--build\", \".\"] + build_args,\n#                 cwd=self.build_temp,\n#                 stderr=STDOUT,\n#             )\n#         except CalledProcessError as exc:\n#             print(exc.output)\n# \n#     def get_ext_filename(self, fullname):\n#         ext_filename = super().get_ext_filename(fullname)\n#         ext_filename_parts = ext_filename.split(\".\")\n#         without_abi = ext_filename_parts[:-2] + ext_filename_parts[-1:]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# build_tools/setup_helpers/extension.py\n# --------------------------------------------------\n#     ]\n# \n# \n# # Based off of\n# # https://github.com/pybind/cmake_example/blob/580c5fd29d4651db99d8874714b07c0c49a53f8a/setup.py\n# class CMakeBuild(build_ext):\n#     def run(self):\n#         try:\n#             subprocess.check_output([\"cmake\", \"--version\"])\n#         except OSError:\n#             raise RuntimeError(\"CMake is not available.\") from None\n#         super().run()\n# \n#     def build_extension(self, ext):\n#         # Since two library files (libtorchrl and _torchrl) need to be\n#         # recognized by setuptools, we instantiate `Extension` twice. (see `get_ext_modules`)\n#         # This leads to the situation where this `build_extension` method is called twice.\n#         # However, the following `cmake` command will build all of them at the same time,\n#         # so, we do not need to perform `cmake` twice.\n#         # Therefore we call `cmake` only for `torchrl._torchrl`.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# build_tools/setup_helpers/extension.py\n# --------------------------------------------------\n#                 stderr=STDOUT,\n#             )\n#         except CalledProcessError as exc:\n#             print(exc.output)\n# \n#         try:\n#             check_output(\n#                 [\"cmake\", \"--build\", \".\"] + build_args,\n#                 cwd=self.build_temp,\n#                 stderr=STDOUT,\n#             )\n#         except CalledProcessError as exc:\n#             print(exc.output)\n# \n#     def get_ext_filename(self, fullname):\n#         ext_filename = super().get_ext_filename(fullname)\n#         ext_filename_parts = ext_filename.split(\".\")\n#         without_abi = ext_filename_parts[:-2] + ext_filename_parts[-1:]\n#         ext_filename = \".\".join(without_abi)\n#         return ext_filename\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport argparse\nimport distutils.command.clean\nimport glob\nimport os\nimport shutil\nimport subprocess\nimport sys\nfrom datetime import date\nfrom pathlib import Path\nfrom typing import List\n\nfrom setuptools import find_packages, setup\nfrom torch.utils.cpp_extension import BuildExtension, CppExtension\n\ncwd = os.path.dirname(os.path.abspath(__file__))\ntry:\n    sha = (\n        subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=cwd)\n        .decode(\"ascii\")\n        .strip()\n    )\nexcept Exception:\n    sha = \"Unknown\"\n\n\ndef get_version():\n    version_txt = os.path.join(cwd, \"version.txt\")\n    with open(version_txt, \"r\") as f:\n        version = f.readline().strip()\n    if os.getenv(\"BUILD_VERSION\"):\n        version = os.getenv(\"BUILD_VERSION\")\n    elif sha != \"Unknown\":\n        version += \"+\" + sha[:7]\n    return version\n\n\nROOT_DIR = Path(__file__).parent.resolve()\n\n\npackage_name = \"torchrl\"\n\n\ndef get_nightly_version():\n    today = date.today()\n    return f\"{today.year}.{today.month}.{today.day}\"\n\n\ndef parse_args(argv: List[str]) -> argparse.Namespace:\n    parser = argparse.ArgumentParser(description=\"torchrl setup\")\n    parser.add_argument(\n        \"--package_name\",\n        type=str,\n        default=\"torchrl\",\n        help=\"the name of this output wheel\",\n    )\n    return parser.parse_known_args(argv)\n\n\ndef write_version_file(version):\n    version_path = os.path.join(cwd, \"torchrl\", \"version.py\")\n    with open(version_path, \"w\") as f:\n        f.write(\"__version__ = '{}'\\n\".format(version))\n        f.write(\"git_version = {}\\n\".format(repr(sha)))\n\n\ndef _get_pytorch_version():\n    # if \"PYTORCH_VERSION\" in os.environ:\n    #     return f\"torch=={os.environ['PYTORCH_VERSION']}\"\n    return \"torch\"\n\n\ndef _get_packages():\n    exclude = [\n        \"build*\",\n        \"test*\",\n        \"torchrl.csrc*\",\n        \"third_party*\",\n        \"tools*\",\n    ]\n    return find_packages(exclude=exclude)\n\n\nROOT_DIR = Path(__file__).parent.resolve()\n\n\nclass clean(distutils.command.clean.clean):\n    def run(self):\n        # Run default behavior first\n        distutils.command.clean.clean.run(self)\n\n        # Remove torchrl extension\n        for path in (ROOT_DIR / \"torchrl\").glob(\"**/*.so\"):\n            print(f\"removing '{path}'\")\n            path.unlink()\n        # Remove build directory\n        build_dirs = [\n            ROOT_DIR / \"build\",\n        ]\n        for path in build_dirs:\n            if path.exists():\n                print(f\"removing '{path}' (and everything under it)\")\n                shutil.rmtree(str(path), ignore_errors=True)\n\n\n# def _run_cmd(cmd):\n#     try:\n#         return subprocess.check_output(cmd, cwd=ROOT_DIR).decode(\"ascii\").strip()\n#     except Exception:\n#         return None\n\n\ndef get_extensions():\n    extension = CppExtension\n\n    extra_link_args = []\n    extra_compile_args = {\n        \"cxx\": [\n            \"-O3\",\n            \"-std=c++14\",\n            \"-fdiagnostics-color=always\",", "choices": [{"text": "\"-Wno-reorder\","}], "metadata": {"task_id": "pytorch_rl/156", "ground_truth": "        ]", "fpath_tuple": ["pytorch_rl", "setup.py"], "context_start_lineno": 0, "line_no": 124, "query_window": {"context": "                print(f\"removing '{path}' (and everything under it)\")\n                shutil.rmtree(str(path), ignore_errors=True)\n\n\n# def _run_cmd(cmd):\n#     try:\n#         return subprocess.check_output(cmd, cwd=ROOT_DIR).decode(\"ascii\").strip()\n#     except Exception:\n#         return None\n\n\ndef get_extensions():\n    extension = CppExtension\n\n    extra_link_args = []\n    extra_compile_args = {\n        \"cxx\": [\n            \"-O3\",\n            \"-std=c++14\",\n            \"-fdiagnostics-color=always\",", "metadata": {"fpath_tuple": ["pytorch_rl", "setup.py"], "line_no": 124, "task_id": "pytorch_rl/156", "start_line_no": 104, "end_line_no": 124, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "                [\"cmake\", str(_ROOT_DIR)] + cmake_args,\n                cwd=self.build_temp,\n                stderr=STDOUT,\n            )\n        except CalledProcessError as exc:\n            print(exc.output)\n\n        try:\n            check_output(\n                [\"cmake\", \"--build\", \".\"] + build_args,\n                cwd=self.build_temp,\n                stderr=STDOUT,\n            )\n        except CalledProcessError as exc:\n            print(exc.output)\n\n    def get_ext_filename(self, fullname):\n        ext_filename = super().get_ext_filename(fullname)\n        ext_filename_parts = ext_filename.split(\".\")\n        without_abi = ext_filename_parts[:-2] + ext_filename_parts[-1:]", "metadata": [{"fpath_tuple": ["pytorch_rl", "build_tools", "setup_helpers", "extension.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.22}, {"context": "_USE_OPENMP = (\n    _get_build(\"USE_OPENMP\", True)\n    and \"ATen parallel backend: OpenMP\" in torch.__config__.parallel_info()\n)\n_TORCH_CUDA_ARCH_LIST = os.environ.get(\"TORCH_CUDA_ARCH_LIST\", None)\n\n\ndef get_ext_modules():\n    return [\n        Extension(name=\"torchrl._torchrl\", sources=[]),\n    ]\n\n\n# Based off of\n# https://github.com/pybind/cmake_example/blob/580c5fd29d4651db99d8874714b07c0c49a53f8a/setup.py\nclass CMakeBuild(build_ext):\n    def run(self):\n        try:\n            subprocess.check_output([\"cmake\", \"--version\"])\n        except OSError:", "metadata": [{"fpath_tuple": ["pytorch_rl", "build_tools", "setup_helpers", "extension.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21465968586387435}, {"context": "            if hasattr(self, \"parallel\") and self.parallel:\n                # CMake 3.12+ only.\n                build_args += [\"-j{}\".format(self.parallel)]\n\n        if not os.path.exists(self.build_temp):\n            os.makedirs(self.build_temp)\n\n        print(\" \".join([\"cmake\", str(_ROOT_DIR)] + cmake_args))\n        try:\n            check_output(\n                [\"cmake\", str(_ROOT_DIR)] + cmake_args,\n                cwd=self.build_temp,\n                stderr=STDOUT,\n            )\n        except CalledProcessError as exc:\n            print(exc.output)\n\n        try:\n            check_output(\n                [\"cmake\", \"--build\", \".\"] + build_args,", "metadata": [{"fpath_tuple": ["pytorch_rl", "build_tools", "setup_helpers", "extension.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20625}, {"context": "            child_pipe.send((\"closing\", None))\n            child_pipe.close()\n            if verbose:\n                print(f\"{pid} closed\")\n            break\n\n        elif cmd == \"load_state_dict\":\n            env.load_state_dict(data)\n            msg = \"loaded\"\n            child_pipe.send((msg, None))\n\n        elif cmd == \"state_dict\":\n            state_dict = _recursively_strip_locks_from_state_dict(env.state_dict())\n            msg = \"state_dict\"\n            child_pipe.send((msg, state_dict))\n\n        else:\n            err_msg = f\"{cmd} from env\"\n            try:\n                attr = getattr(env, cmd)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 1050, "start_line_no": 1040, "end_line_no": 1060, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2054794520547945}, {"context": "def get_relative_path(curr_file, *path_components):\n    return os.path.join(os.path.dirname(curr_file), *path_components)\n\n\ndef get_available_devices():\n    devices = [torch.device(\"cpu\")]\n    n_cuda = torch.cuda.device_count()\n    if n_cuda > 0:\n        for i in range(n_cuda):\n            devices += [torch.device(f\"cuda:{i}\")]\n    return devices\n\n\ndef generate_seeds(seed, repeat):\n    seeds = [seed]\n    for _ in range(repeat - 1):\n        seed = seed_generator(seed)\n        seeds.append(seed)\n    return seeds\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "_utils_internal.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2052980132450331}, {"context": "\n    @_check_start\n    def state_dict(self) -> OrderedDict:\n        state_dict = OrderedDict()\n        for channel in self.parent_channels:\n            channel.send((\"state_dict\", None))\n        for idx, channel in enumerate(self.parent_channels):\n            msg, _state_dict = channel.recv()\n            if msg != \"state_dict\":\n                raise RuntimeError(f\"Expected 'state_dict' but received {msg}\")\n            state_dict[f\"worker{idx}\"] = _state_dict\n\n        return state_dict\n\n    @_check_start\n    def load_state_dict(self, state_dict: OrderedDict) -> None:\n        if \"worker0\" not in state_dict:\n            state_dict = OrderedDict(\n                **{f\"worker{idx}\": state_dict for idx in range(self.num_workers)}\n            )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20512820512820512}, {"context": "    @staticmethod\n    def print(prefix=None):\n        keys = list(timeit._REG)\n        keys.sort()\n        for name in keys:\n            strings = []\n            if prefix:\n                strings.append(prefix)\n            strings.append(\n                f\"{name} took {timeit._REG[name][0] * 1000:4.4} msec (total = {timeit._REG[name][1]} sec)\"\n            )\n            print(\" -- \".join(strings))\n\n    @staticmethod\n    def erase():\n        for k in timeit._REG:\n            timeit._REG[k] = [0.0, 0.0, 0]\n\n\ndef _check_for_faulty_process(processes):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20512820512820512}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/textual_inversion/textual_inversion.py\n# --------------------------------------------------\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--allow_tf32\",\n#         action=\"store_true\",\n#         help=(\n#             \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n#             \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--report_to\",\n#         type=str,\n#         default=\"tensorboard\",\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/text_to_image/train_text_to_image_flax.py\n# --------------------------------------------------\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--mixed_precision\",\n#         type=str,\n#         default=\"no\",\n#         choices=[\"no\", \"fp16\", \"bf16\"],\n#         help=(\n#             \"Whether to use mixed precision. Choose\"\n#             \"between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.\"\n#             \"and an Nvidia Ampere GPU.\"\n#         ),\n#     )\n#     parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n# \n#     args = parser.parse_args()\n#     env_local_rank = int(os.environ.get(\"LOCAL_RANK\", -1))\n#     if env_local_rank != -1 and env_local_rank != args.local_rank:\n#         args.local_rank = env_local_rank\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/text_to_image/train_text_to_image_flax.py\n# --------------------------------------------------\n#             \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--report_to\",\n#         type=str,\n#         default=\"tensorboard\",\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--mixed_precision\",\n#         type=str,\n#         default=\"no\",\n#         choices=[\"no\", \"fp16\", \"bf16\"],\n#         help=(\n#             \"Whether to use mixed precision. Choose\"\n#             \"between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/dreambooth/train_dreambooth_lora.py\n# examples/dreambooth/train_dreambooth.py\n# examples/research_projects/multi_subject_dreambooth/train_multi_subject_dreambooth.py\n# --------------------------------------------------\n#         action=\"store_true\",\n#         help=(\n#             \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n#             \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--report_to\",\n#         type=str,\n#         default=\"tensorboard\",\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--mixed_precision\",\n#         type=str,\n#         default=None,\n#         choices=[\"no\", \"fp16\", \"bf16\"],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/dreambooth/train_dreambooth_lora.py\n# examples/dreambooth/train_dreambooth.py\n# examples/research_projects/multi_subject_dreambooth/train_multi_subject_dreambooth.py\n# --------------------------------------------------\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--mixed_precision\",\n#         type=str,\n#         default=None,\n#         choices=[\"no\", \"fp16\", \"bf16\"],\n#         help=(\n#             \"Whether to use mixed precision. Choose between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >=\"\n#             \" 1.10.and an Nvidia Ampere GPU.  Default to the value of accelerate config of the current system or the\"\n#             \" flag passed with the `accelerate.launch` command. Use this argument to override the accelerate config.\"\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--prior_generation_precision\",\n#         type=str,\n#         default=None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/textual_inversion/textual_inversion.py\n# --------------------------------------------------\n#     parser.add_argument(\n#         \"--report_to\",\n#         type=str,\n#         default=\"tensorboard\",\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--validation_prompt\",\n#         type=str,\n#         default=None,\n#         help=\"A prompt that is used during validation to verify that the model is learning.\",\n#     )\n#     parser.add_argument(\n#         \"--num_validation_images\",\n#         type=int,\n#         default=4,\n#         help=\"Number of images that should be generated during validation with `validation_prompt`.\",\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n,\n        default=None,\n        required=False,\n        help=\"A folder containing the training data of class images.\",\n    )\n    parser.add_argument(\n        \"--instance_prompt\",\n        type=str,\n        default=None,\n        required=True,\n        help=\"The prompt with identifier specifying the instance\",\n    )\n    parser.add_argument(\n        \"--class_prompt\",\n        type=str,\n        default=None,\n        help=\"The prompt to specify images in the same class as provided instance images.\",\n    )\n    parser.add_argument(\n        \"--with_prior_preservation\",\n        default=False,\n        action=\"store_true\",\n        help=\"Flag to add prior preservation loss.\",\n    )\n    parser.add_argument(\"--prior_loss_weight\", type=float, default=1.0, help=\"The weight of prior preservation loss.\")\n    parser.add_argument(\n        \"--num_class_images\",\n        type=int,\n        default=100,\n        help=(\n            \"Minimal class images for prior preservation loss. If there are not enough images already present in\"\n            \" class_data_dir, additional images will be sampled with class_prompt.\"\n        ),\n    )\n    parser.add_argument(\n        \"--output_dir\",\n        type=str,\n        default=\"text-inversion-model\",\n        help=\"The output directory where the model predictions and checkpoints will be written.\",\n    )\n    parser.add_argument(\"--seed\", type=int, default=None, help=\"A seed for reproducible training.\")\n    parser.add_argument(\n        \"--resolution\",\n        type=int,\n        default=512,\n        help=(\n            \"The resolution for input images, all the images in the train/validation dataset will be resized to this\"\n            \" resolution\"\n        ),\n    )\n    parser.add_argument(\n        \"--center_crop\",\n        default=False,\n        action=\"store_true\",\n        help=(\n            \"Whether to center crop the input images to the resolution. If not set, the images will be randomly\"\n            \" cropped. The images will be resized to the resolution first before cropping.\"\n        ),\n    )\n    parser.add_argument(\"--train_text_encoder\", action=\"store_true\", help=\"Whether to train the text encoder\")\n    parser.add_argument(\n        \"--train_batch_size\", type=int, default=4, help=\"Batch size (per device) for the training dataloader.\"\n    )\n    parser.add_argument(\n        \"--sample_batch_size\", type=int, default=4, help=\"Batch size (per device) for sampling images.\"\n    )\n    parser.add_argument(\"--num_train_epochs\", type=int, default=1)\n    parser.add_argument(\n        \"--max_train_steps\",\n        type=int,\n        default=None,\n        help=\"Total number of training steps to perform.  If provided, overrides num_train_epochs.\",\n    )\n    parser.add_argument(\n        \"--checkpointing_steps\",\n        type=int,\n        default=500,\n        help=(\n            \"Save a checkpoint of the training state every X updates. These checkpoints can be used both as final\"\n            \" checkpoints in case they are better than the last checkpoint, and are also suitable for resuming\"\n            \" training using `--resume_from_checkpoint`.\"\n        ),\n    )\n    parser.add_argument(\n        \"--resume_from_checkpoint\",\n        type=str,\n        default=None,\n        help=(\n            \"Whether training should be resumed from a previous checkpoint. Use a path saved by\"\n            ' `--checkpointing_steps`, or `\"latest\"` to automatically select the last available checkpoint.'\n        ),\n    )\n    parser.add_argument(\n        \"--gradient_accumulation_steps\",\n        type=int,\n        default=1,\n        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n    )\n    parser.add_argument(\n        \"--gradient_checkpointing\",\n        action=\"store_true\",\n        help=\"Whether or not to use gradient checkpointing to save memory at the expense of slower backward pass.\",\n    )\n    parser.add_argument(\n        \"--learning_rate\",\n        type=float,\n        default=5e-6,\n        help=\"Initial learning rate (after the potential warmup period) to use.\",\n    )\n    parser.add_argument(\n        \"--scale_lr\",\n        action=\"store_true\",\n        default=False,\n        help=\"Scale the learning rate by the number of GPUs, gradient accumulation steps, and batch size.\",\n    )\n    parser.add_argument(\n        \"--lr_scheduler\",\n        type=str,\n        default=\"constant\",\n        help=(\n            'The scheduler type to use. Choose between [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\",'\n            ' \"constant\", \"constant_with_warmup\"]'\n        ),\n    )\n    parser.add_argument(\n        \"--lr_warmup_steps\", type=int, default=500, help=\"Number of steps for the warmup in the lr scheduler.\"\n    )\n    parser.add_argument(\n        \"--lr_num_cycles\",\n        type=int,\n        default=1,\n        help=\"Number of hard resets of the lr in cosine_with_restarts scheduler.\",\n    )\n    parser.add_argument(\"--lr_power\", type=float, default=1.0, help=\"Power factor of the polynomial scheduler.\")\n    parser.add_argument(\n        \"--use_8bit_adam\", action=\"store_true\", help=\"Whether or not to use 8-bit Adam from bitsandbytes.\"\n    )\n    parser.add_argument(\"--adam_beta1\", type=float, default=0.9, help=\"The beta1 parameter for the Adam optimizer.\")\n    parser.add_argument(\"--adam_beta2\", type=float, default=0.999, help=\"The beta2 parameter for the Adam optimizer.\")\n    parser.add_argument(\"--adam_weight_decay\", type=float, default=1e-2, help=\"Weight decay to use.\")\n    parser.add_argument(\"--adam_epsilon\", type=float, default=1e-08, help=\"Epsilon value for the Adam optimizer\")\n    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n    parser.add_argument(\"--push_to_hub\", action=\"store_true\", help=\"Whether or not to push the model to the Hub.\")\n    parser.add_argument(\"--hub_token\", type=str, default=None, help=\"The token to use to push to the Model Hub.\")\n    parser.add_argument(\n        \"--hub_model_id\",\n        type=str,\n        default=None,\n        help=\"The name of the repository to keep in sync with the local `output_dir`.\",\n    )\n    parser.add_argument(\n        \"--logging_dir\",\n        type=str,\n        default=\"logs\",\n        help=(\n            \"[TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to\"\n            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )", "choices": [{"text": "parser.add_argument("}], "metadata": {"task_id": "huggingface_diffusers/75", "ground_truth": "    parser.add_argument(", "fpath_tuple": ["huggingface_diffusers", "examples", "research_projects", "multi_subject_dreambooth", "train_multi_subject_dreambooth.py"], "context_start_lineno": 89, "line_no": 265, "query_window": {"context": "            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )", "metadata": {"fpath_tuple": ["huggingface_diffusers", "examples", "research_projects", "multi_subject_dreambooth", "train_multi_subject_dreambooth.py"], "line_no": 265, "task_id": "huggingface_diffusers/75", "start_line_no": 245, "end_line_no": 265, "window_size": 20, "context_start_lineno": 89, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )\n    parser.add_argument(", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "textual_inversion", "textual_inversion.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.8677685950413223}, {"context": "        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )\n    parser.add_argument(\n        \"--mixed_precision\",\n        type=str,\n        default=None,\n        choices=[\"no\", \"fp16\", \"bf16\"],", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "dreambooth", "train_dreambooth_lora.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "dreambooth", "train_dreambooth.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "research_projects", "multi_subject_dreambooth", "train_multi_subject_dreambooth.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7819548872180451}, {"context": "        \"--logging_dir\",\n        type=str,\n        default=\"logs\",\n        help=(\n            \"[TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to\"\n            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "dreambooth", "train_dreambooth_lora.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "dreambooth", "train_dreambooth.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "research_projects", "multi_subject_dreambooth", "train_multi_subject_dreambooth.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.674074074074074}, {"context": "        type=str,\n        default=None,\n        help=\"The name of the repository to keep in sync with the local `output_dir`.\",\n    )\n    parser.add_argument(\n        \"--logging_dir\",\n        type=str,\n        default=\"logs\",\n        help=(\n            \"[TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to\"\n            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "text_to_image", "train_text_to_image_flax.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5448275862068965}, {"context": "            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )\n    parser.add_argument(\n        \"--mixed_precision\",\n        type=str,\n        default=\"no\",\n        choices=[\"no\", \"fp16\", \"bf16\"],\n        help=(\n            \"Whether to use mixed precision. Choose\"\n            \"between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.\"", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "text_to_image", "train_text_to_image_flax.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5369127516778524}, {"context": "    )\n    parser.add_argument(\n        \"--mixed_precision\",\n        type=str,\n        default=\"no\",\n        choices=[\"no\", \"fp16\", \"bf16\"],\n        help=(\n            \"Whether to use mixed precision. Choose\"\n            \"between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.\"\n            \"and an Nvidia Ampere GPU.\"\n        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "textual_inversion", "textual_inversion.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.506578947368421}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n# \n#     def empty_cache(self):\n#         self.__dict__[\"_parent\"] = None\n# \n# \n# class TransformedEnv(EnvBase):\n#     \"\"\"A transformed_in environment.\n# \n#     Args:\n#         env (EnvBase): original environment to be transformed_in.\n#         transform (Transform, optional): transform to apply to the tensordict resulting\n#             from :obj:`env.step(td)`. If none is provided, an empty Compose\n#             placeholder in an eval mode is used.\n#         cache_specs (bool, optional): if True, the specs will be cached once\n#             and for all after the first call (i.e. the specs will be\n#             transformed_in only once). If the transform changes during\n#             training, the original spec transform may not be valid anymore,\n#             in which case this value should be set  to `False`. Default is\n#             `True`.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#                 self._env.reward_spec(), device=self.device\n#             )\n#             if len(reward_spec.shape) == 0:\n#                 reward_spec.shape = torch.Size([1])\n#             self.__dict__[\"_reward_spec\"] = reward_spec\n#         return self._reward_spec\n# \n#     @reward_spec.setter\n#     def reward_spec(self, value: TensorSpec) -> None:\n#         if not hasattr(value, \"shape\"):\n#             raise TypeError(\n#                 f\"reward_spec of type {type(value)} do not have a shape \" f\"attribute.\"\n#             )\n#         if len(value.shape) == 0:\n#             raise RuntimeError(\n#                 \"the reward_spec shape cannot be empty (this error\"\n#                 \" usually comes from trying to set a reward_spec\"\n#                 \" with a null number of dimensions. Try using a multidimensional\"\n#                 \" spec instead, for instance with a singleton dimension at the tail).\"\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#         if self._observation_spec is None:\n#             self._set_properties()\n#         return self._observation_spec\n# \n#     @observation_spec.setter\n#     def observation_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec) and value is not None:\n#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n#         self.__dict__[\"_observation_spec\"] = value\n# \n#     @property\n#     def input_spec(self) -> TensorSpec:\n#         if self._input_spec is None:\n#             self._set_properties()\n#         return self._input_spec\n# \n#     @input_spec.setter\n#     def input_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec) and value is not None:\n#             raise TypeError(\"The type of an input_spec must be Composite.\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#         self.__dict__[\"_input_spec\"] = value\n# \n#     @property\n#     def observation_spec(self) -> TensorSpec:\n#         if self._observation_spec is None:\n#             self.__dict__[\"_observation_spec\"] = _dmcontrol_to_torchrl_spec_transform(\n#                 self._env.observation_spec(), device=self.device\n#             )\n#         return self._observation_spec\n# \n#     @observation_spec.setter\n#     def observation_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec):\n#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n#         self.__dict__[\"_observation_spec\"] = value\n# \n#     @property\n#     def reward_spec(self) -> TensorSpec:\n#         if self._reward_spec is None:\n#             reward_spec = _dmcontrol_to_torchrl_spec_transform(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#         self.__dict__[\"_input_spec\"] = value\n# \n#     @property\n#     def reward_spec(self) -> TensorSpec:\n#         if self._reward_spec is None:\n#             self._set_properties()\n#         return self._reward_spec\n# \n#     @reward_spec.setter\n#     def reward_spec(self, value: TensorSpec) -> None:\n#         if not hasattr(value, \"shape\") and value is not None:\n#             raise TypeError(\n#                 f\"reward_spec of type {type(value)} do not have a shape \" f\"attribute.\"\n#             )\n#         if value is not None and len(value.shape) == 0:\n#             raise RuntimeError(\n#                 \"the reward_spec shape cannot be empty (this error\"\n#                 \" usually comes from trying to set a reward_spec\"\n#                 \" with a null number of dimensions. Try using a multidimensional\"\n#                 \" spec instead, for instance with a singleton dimension at the tail).\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#     @property\n#     def input_spec(self) -> TensorSpec:\n#         if self._input_spec is None:\n#             self._set_properties()\n#         return self._input_spec\n# \n#     @input_spec.setter\n#     def input_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec) and value is not None:\n#             raise TypeError(\"The type of an input_spec must be Composite.\")\n#         self.__dict__[\"_input_spec\"] = value\n# \n#     @property\n#     def reward_spec(self) -> TensorSpec:\n#         if self._reward_spec is None:\n#             self._set_properties()\n#         return self._reward_spec\n# \n#     @reward_spec.setter\n#     def reward_spec(self, value: TensorSpec) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#     @observation_spec.setter\n#     def observation_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec):\n#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n#         self.__dict__[\"_observation_spec\"] = value\n# \n#     @property\n#     def reward_spec(self) -> TensorSpec:\n#         if self._reward_spec is None:\n#             reward_spec = _dmcontrol_to_torchrl_spec_transform(\n#                 self._env.reward_spec(), device=self.device\n#             )\n#             if len(reward_spec.shape) == 0:\n#                 reward_spec.shape = torch.Size([1])\n#             self.__dict__[\"_reward_spec\"] = reward_spec\n#         return self._reward_spec\n# \n#     @reward_spec.setter\n#     def reward_spec(self, value: TensorSpec) -> None:\n#         if not hasattr(value, \"shape\"):\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nose but with other features that we don't want to loose.\n                transform = [transform]\n            else:\n                for t in transform:\n                    t.reset_parent()\n            env_transform = env.transform\n            if type(env_transform) is not Compose:\n                env_transform.reset_parent()\n                env_transform = [env_transform]\n            else:\n                for t in env_transform:\n                    t.reset_parent()\n            transform = Compose(*env_transform, *transform).to(device)\n        else:\n            self._set_env(env, device)\n            if transform is None:\n                transform = Compose()\n            else:\n                transform = transform.to(device)\n        self.transform = transform\n\n        self._last_obs = None\n        self.cache_specs = cache_specs\n        self.__dict__[\"_reward_spec\"] = None\n        self.__dict__[\"_input_spec\"] = None\n        self.__dict__[\"_observation_spec\"] = None\n        self.batch_size = self.base_env.batch_size\n\n    def _set_env(self, env: EnvBase, device) -> None:\n        if device != env.device:\n            env = env.to(device)\n        self.base_env = env\n        # updates need not be inplace, as transforms may modify values out-place\n        self.base_env._inplace_update = False\n\n    @property\n    def transform(self) -> Transform:\n        return self._transform\n\n    @transform.setter\n    def transform(self, transform: Transform):\n        if not isinstance(transform, Transform):\n            raise ValueError(\n                f\"\"\"Expected a transform of type torchrl.envs.transforms.Transform,\nbut got an object of type {type(transform)}.\"\"\"\n            )\n        prev_transform = self.transform\n        if prev_transform is not None:\n            prev_transform.empty_cache()\n            prev_transform.__dict__[\"_container\"] = None\n        transform.set_container(self)\n        transform.eval()\n        self._transform = transform\n\n    @property\n    def device(self) -> bool:\n        return self.base_env.device\n\n    @device.setter\n    def device(self, value):\n        raise RuntimeError(\"device is a read-only property\")\n\n    @property\n    def batch_locked(self) -> bool:\n        return self.base_env.batch_locked\n\n    @batch_locked.setter\n    def batch_locked(self, value):\n        raise RuntimeError(\"batch_locked is a read-only property\")\n\n    @property\n    def run_type_checks(self) -> bool:\n        return self.base_env.run_type_checks\n\n    @run_type_checks.setter\n    def run_type_checks(self, value):\n        raise RuntimeError(\n            \"run_type_checks is a read-only property for TransformedEnvs\"\n        )\n\n    @property\n    def _inplace_update(self):\n        return self.base_env._inplace_update\n\n    @property\n    def observation_spec(self) -> TensorSpec:\n        \"\"\"Observation spec of the transformed environment.\"\"\"\n        if self._observation_spec is None or not self.cache_specs:\n            observation_spec = self.transform.transform_observation_spec(\n                self.base_env.observation_spec.clone()\n            )\n            if self.cache_specs:\n                self.__dict__[\"_observation_spec\"] = observation_spec\n        else:\n            observation_spec = self._observation_spec\n        return observation_spec\n\n    @property\n    def action_spec(self) -> TensorSpec:\n        \"\"\"Action spec of the transformed environment.\"\"\"\n        return self.input_spec[\"action\"]\n\n    @property\n    def input_spec(self) -> TensorSpec:\n        \"\"\"Action spec of the transformed environment.\"\"\"\n        if self._input_spec is None or not self.cache_specs:\n            input_spec = self.transform.transform_input_spec(\n                self.base_env.input_spec.clone()\n            )\n            if self.cache_specs:\n                self.__dict__[\"_input_spec\"] = input_spec\n        else:\n            input_spec = self._input_spec\n        return input_spec\n\n    @property\n    def reward_spec(self) -> TensorSpec:\n        \"\"\"Reward spec of the transformed environment.\"\"\"\n        if self._reward_spec is None or not self.cache_specs:\n            reward_spec = self.transform.transform_reward_spec(\n                self.base_env.reward_spec.clone()\n            )\n            if self.cache_specs:\n                self.__dict__[\"_reward_spec\"] = reward_spec\n        else:\n            reward_spec = self._reward_spec\n        return reward_spec\n\n    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n        tensordict = tensordict.clone(False)\n        tensordict_in = self.transform.inv(tensordict)\n        tensordict_out = self.base_env._step(tensordict_in)\n        tensordict_out = (\n            tensordict_out.update(  # update the output with the original tensordict\n                tensordict.exclude(\n                    *tensordict_out.keys()\n                )  # exclude the newly written keys\n            )\n        )\n        next_tensordict = self.transform._step(tensordict_out)\n        # tensordict_out.update(next_tensordict, inplace=False)\n\n        return next_tensordict\n\n    def set_seed(\n        self, seed: Optional[int] = None, static_seed: bool = False\n    ) -> Optional[int]:\n        \"\"\"Set the seeds of the environment.\"\"\"\n        return self.base_env.set_seed(seed, static_seed=static_seed)\n\n    def _set_seed(self, seed: Optional[int]):\n        \"\"\"This method is not used in transformed envs.\"\"\"\n        pass\n\n    def _reset(self, tensordict: Optional[TensorDictBase] = None, **kwargs):\n        if tensordict is not None:\n            tensordict = tensordict.clone(recurse=False)\n        out_tensordict = self.base_env.reset(tensordict=tensordict, **kwargs)\n        out_tensordict = self.transform.reset(out_tensordict)\n        out_tensordict = self.transform(out_tensordict)\n        return out_tensordict\n\n    def state_dict(self) -> OrderedDict:\n        state_dict = self.transform.state_dict()\n        return state_dict\n\n    def load_state_dict(self, state_dict: OrderedDict, **kwargs) -> None:\n        self.transform.load_state_dict(state_dict, **kwargs)\n\n    def eval(self) -> TransformedEnv:\n        if \"transform\" in self.__dir__():\n            # when calling __init__, eval() is called but transforms are not set\n            # yet.\n            self.transform.eval()\n        return self\n\n    def train(self, mode: bool = True) -> TransformedEnv:\n        self.transform.train(mode)\n        return self\n\n    @property\n    def is_closed(self) -> bool:\n        return self.base_env.is_closed\n\n    @is_closed.setter\n    def is_closed(self, value: bool):\n        self.base_env.is_closed = value\n\n    def close(self):\n        self.base_env.close()\n        self.is_closed = True\n\n    def empty_cache(self):\n        self.__dict__[\"_observation_spec\"] = None\n        self.__dict__[\"_input_spec\"] = None\n        self.__dict__[\"_reward_spec\"] = None\n\n    def append_transform(self, transform: Transform) -> None:\n        self._erase_metadata()\n        if not isinstance(transform, Transform):\n            raise ValueError(\n                \"TransformedEnv.append_transform expected a transform but received an object of \"", "choices": [{"text": "\"type {type(transform)}.\""}], "metadata": {"task_id": "pytorch_rl/98", "ground_truth": "                f\"type {type(transform)} instead.\"", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "context_start_lineno": 316, "line_no": 518, "query_window": {"context": "        return self.base_env.is_closed\n\n    @is_closed.setter\n    def is_closed(self, value: bool):\n        self.base_env.is_closed = value\n\n    def close(self):\n        self.base_env.close()\n        self.is_closed = True\n\n    def empty_cache(self):\n        self.__dict__[\"_observation_spec\"] = None\n        self.__dict__[\"_input_spec\"] = None\n        self.__dict__[\"_reward_spec\"] = None\n\n    def append_transform(self, transform: Transform) -> None:\n        self._erase_metadata()\n        if not isinstance(transform, Transform):\n            raise ValueError(\n                \"TransformedEnv.append_transform expected a transform but received an object of \"", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 518, "task_id": "pytorch_rl/98", "start_line_no": 498, "end_line_no": 518, "window_size": 20, "context_start_lineno": 316, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        self.__dict__[\"_input_spec\"] = value\n\n    @property\n    def observation_spec(self) -> TensorSpec:\n        if self._observation_spec is None:\n            self.__dict__[\"_observation_spec\"] = _dmcontrol_to_torchrl_spec_transform(\n                self._env.observation_spec(), device=self.device\n            )\n        return self._observation_spec\n\n    @observation_spec.setter\n    def observation_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec):\n            raise TypeError(\"The type of an observation_spec must be Composite.\")\n        self.__dict__[\"_observation_spec\"] = value\n\n    @property\n    def reward_spec(self) -> TensorSpec:\n        if self._reward_spec is None:\n            reward_spec = _dmcontrol_to_torchrl_spec_transform(", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45544554455445546}, {"context": "        if self._observation_spec is None:\n            self._set_properties()\n        return self._observation_spec\n\n    @observation_spec.setter\n    def observation_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec) and value is not None:\n            raise TypeError(\"The type of an observation_spec must be Composite.\")\n        self.__dict__[\"_observation_spec\"] = value\n\n    @property\n    def input_spec(self) -> TensorSpec:\n        if self._input_spec is None:\n            self._set_properties()\n        return self._input_spec\n\n    @input_spec.setter\n    def input_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec) and value is not None:\n            raise TypeError(\"The type of an input_spec must be Composite.\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45054945054945056}, {"context": "    @property\n    def input_spec(self) -> TensorSpec:\n        if self._input_spec is None:\n            self._set_properties()\n        return self._input_spec\n\n    @input_spec.setter\n    def input_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec) and value is not None:\n            raise TypeError(\"The type of an input_spec must be Composite.\")\n        self.__dict__[\"_input_spec\"] = value\n\n    @property\n    def reward_spec(self) -> TensorSpec:\n        if self._reward_spec is None:\n            self._set_properties()\n        return self._reward_spec\n\n    @reward_spec.setter\n    def reward_spec(self, value: TensorSpec) -> None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.43956043956043955}, {"context": "                action=_dmcontrol_to_torchrl_spec_transform(\n                    self._env.action_spec(), device=self.device\n                )\n            )\n        return self._input_spec\n\n    @input_spec.setter\n    def input_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec):\n            raise TypeError(\"The type of an input_spec must be Composite.\")\n        self.__dict__[\"_input_spec\"] = value\n\n    @property\n    def observation_spec(self) -> TensorSpec:\n        if self._observation_spec is None:\n            self.__dict__[\"_observation_spec\"] = _dmcontrol_to_torchrl_spec_transform(\n                self._env.observation_spec(), device=self.device\n            )\n        return self._observation_spec\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4230769230769231}, {"context": "        if self._device is None:\n            self._set_properties()\n        return self._device\n\n    @device.setter\n    def device(self, value: DEVICE_TYPING) -> None:\n        self.to(value)\n\n    @property\n    def observation_spec(self) -> TensorSpec:\n        if self._observation_spec is None:\n            self._set_properties()\n        return self._observation_spec\n\n    @observation_spec.setter\n    def observation_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec) and value is not None:\n            raise TypeError(\"The type of an observation_spec must be Composite.\")\n        self.__dict__[\"_observation_spec\"] = value\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.40816326530612246}, {"context": "    @observation_spec.setter\n    def observation_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec):\n            raise TypeError(\"The type of an observation_spec must be Composite.\")\n        self.__dict__[\"_observation_spec\"] = value\n\n    @property\n    def reward_spec(self) -> TensorSpec:\n        if self._reward_spec is None:\n            reward_spec = _dmcontrol_to_torchrl_spec_transform(\n                self._env.reward_spec(), device=self.device\n            )\n            if len(reward_spec.shape) == 0:\n                reward_spec.shape = torch.Size([1])\n            self.__dict__[\"_reward_spec\"] = reward_spec\n        return self._reward_spec\n\n    @reward_spec.setter\n    def reward_spec(self, value: TensorSpec) -> None:\n        if not hasattr(value, \"shape\"):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.40707964601769914}, {"context": "                            break\n                        transform = orig_trans.clone()\n                        transform.reset_parent()\n                        out.append_transform(transform)\n            elif isinstance(container, TransformedEnv):\n                out = TransformedEnv(container.base_env)\n            else:\n                raise ValueError(f\"container is of type {type(container)}\")\n            self.__dict__[\"_parent\"] = out\n        return self.__dict__[\"_parent\"]\n\n    def empty_cache(self):\n        self.__dict__[\"_parent\"] = None\n\n\nclass TransformedEnv(EnvBase):\n    \"\"\"A transformed_in environment.\n\n    Args:\n        env (EnvBase): original environment to be transformed_in.", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3669724770642202}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/league/player.py\n# --------------------------------------------------\n# from typing import Callable, Optional, List\n# from collections import namedtuple\n# import numpy as np\n# from easydict import EasyDict\n# \n# from ding.utils import import_module, PLAYER_REGISTRY\n# from .algorithm import pfsp\n# \n# \n# class Player:\n#     \"\"\"\n#     Overview:\n#         Base player class, player is the basic member of a league\n#     Interfaces:\n#         __init__\n#     Property:\n#         race, payoff, checkpoint_path, player_id, total_agent_step\n#     \"\"\"\n#     _name = \"BasePlayer\"  # override this variable for sub-class player\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/network/soft_argmax.py\n# --------------------------------------------------\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# \n# \n# class SoftArgmax(nn.Module):\n#     r\"\"\"\n#     Overview:\n#         An nn.Module that computes SoftArgmax\n#     Interface:\n#         __init__, forward\n# \n#     .. note:\n# \n#         For more softargmax info, you can refere to\n#         the wiki page <https://wikimili.com/en/Softmax_function> or\n#         the lecture <https://mc.ai/softmax-function-beyond-the-basics/>\n# \n#     \"\"\"\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/fake_linklink.py\n# --------------------------------------------------\n# from collections import namedtuple\n# \n# \n# class FakeClass:\n# \n#     def __init__(self, *args, **kwargs):\n#         pass\n# \n# \n# class FakeNN:\n#     SyncBatchNorm2d = FakeClass\n# \n# \n# class FakeLink:\n#     nn = FakeNN()\n#     syncbnVarMode_t = namedtuple(\"syncbnVarMode_t\", \"L2\")(L2=None)\n#     allreduceOp_t = namedtuple(\"allreduceOp_t\", ['Sum', 'Max'])\n# \n# \n# link = FakeLink()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/common/utils.py\n# --------------------------------------------------\n# import torch\n# from easydict import EasyDict\n# from ding.utils import import_module, MODEL_REGISTRY\n# \n# \n# def create_model(cfg: EasyDict) -> torch.nn.Module:\n#     r\"\"\"\n#     Overview:\n#         Creat model given config dictionary\n#     Arguments:\n#         - cfg: (:obj:`dict`):\n#             The trainning configuration, the key ``import_name`` is\n#             used to import module, and they key ``type`` is used to build model.\n#     Returns:\n#         - (:obj:`torch.nn.Module`) The corresponding model.\n#     \"\"\"\n#     import_module(cfg.pop('import_names', []))\n#     # must use pop\n#     return MODEL_REGISTRY.build(cfg.pop(\"type\"), **cfg)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/replay_buffer/base_buffer.py\n# --------------------------------------------------\n# from typing import Union, Dict, Any, List\n# from abc import ABC, abstractmethod\n# import copy\n# from easydict import EasyDict\n# \n# from ding.utils import import_module, BUFFER_REGISTRY\n# \n# \n# class IBuffer(ABC):\n#     r\"\"\"\n#     Overview:\n#         Buffer interface\n#     Interfaces:\n#         default_config, push, update, sample, clear, count, state_dict, load_state_dict\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls) -> EasyDict:\n#         r\"\"\"\n#         Overview:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/policy_factory.py\n# --------------------------------------------------\n# from typing import Dict, Any, Callable\n# from collections import namedtuple\n# import numpy as np\n# \n# from ding.torch_utils import to_device\n# \n# \n# class PolicyFactory:\n#     r\"\"\"\n#     Overview:\n#         Pure random policy. Only used for initial sample collecting if `cfg.policy.random_collect_size` > 0.\n#     \"\"\"\n# \n#     @staticmethod\n#     def get_random_policy(\n#             policy: 'BasePolicy',  # noqa\n#             action_space: 'EnvElementInfo' = None,  # noqa\n#             forward_fn: Callable = None,\n#     ) -> None:\n#         assert not (action_space is None and forward_fn is None)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/coordinator/base_parallel_commander.py\n# --------------------------------------------------\n#     Overview:\n#         Base parallel commander abstract class.\n#     Interface:\n#         get_collector_task\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls: type) -> EasyDict:\n#         cfg = EasyDict(copy.deepcopy(cls.config))\n#         cfg.cfg_type = cls.__name__ + 'Dict'\n#         return cfg\n# \n#     @abstractmethod\n#     def get_collector_task(self) -> dict:\n#         raise NotImplementedError\n# \n#     def judge_collector_finish(self, task_id: str, info: dict) -> bool:\n#         collector_done = info.get('collector_done', False)\n#         if collector_done:\n#             return True\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/reward_model/base_reward_model.py\n# --------------------------------------------------\n# from abc import ABC, abstractmethod\n# from easydict import EasyDict\n# import copy\n# from ding.utils import REWARD_MODEL_REGISTRY, import_module\n# \n# \n# class BaseRewardModel(ABC):\n#     \"\"\"\n#     Overview:\n#         the base class of reward model\n#     Interface:\n#         ``default_config``, ``estimate``, ``train``, ``clear_data``, ``collect_data``, ``load_expert_date``\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls: type) -> EasyDict:\n#         cfg = EasyDict(copy.deepcopy(cls.config))\n#         cfg.cfg_type = cls.__name__ + 'Dict'\n#         return cfg\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/coordinator/base_parallel_commander.py\n# --------------------------------------------------\n# from abc import ABC, abstractmethod\n# from collections import defaultdict\n# from easydict import EasyDict\n# import copy\n# \n# from ding.utils import import_module, COMMANDER_REGISTRY, LimitedSpaceContainer\n# \n# \n# class BaseCommander(ABC):\n#     r\"\"\"\n#     Overview:\n#         Base parallel commander abstract class.\n#     Interface:\n#         get_collector_task\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls: type) -> EasyDict:\n#         cfg = EasyDict(copy.deepcopy(cls.config))\n#         cfg.cfg_type = cls.__name__ + 'Dict'\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom collections import namedtuple\nfrom easydict import EasyDict\nimport copy\n\n\nclass BaseSerialCommander(object):\n    r\"\"\"\n    Overview:\n        Base serial commander class.\n    Interface:", "choices": [{"text": "__init__, get_collector_task, submit_task, is_finish, get_results"}], "metadata": {"task_id": "opendilab_ACE/164", "ground_truth": "        __init__, step", "fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "base_serial_commander.py"], "context_start_lineno": 0, "line_no": 10, "query_window": {"context": "from collections import namedtuple\nfrom easydict import EasyDict\nimport copy\n\n\nclass BaseSerialCommander(object):\n    r\"\"\"\n    Overview:\n        Base serial commander class.\n    Interface:", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "base_serial_commander.py"], "line_no": 10, "task_id": "opendilab_ACE/164", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "from abc import ABC, abstractmethod\nfrom collections import defaultdict\nfrom easydict import EasyDict\nimport copy\n\nfrom ding.utils import import_module, COMMANDER_REGISTRY, LimitedSpaceContainer\n\n\nclass BaseCommander(ABC):\n    r\"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "base_parallel_commander.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4}, {"context": "from abc import ABC, abstractmethod\nfrom easydict import EasyDict\nimport copy\nfrom ding.utils import REWARD_MODEL_REGISTRY, import_module\n\n\nclass BaseRewardModel(ABC):\n    \"\"\"\n    Overview:\n        the base class of reward model", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "reward_model", "base_reward_model.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.35}, {"context": "from abc import ABC, abstractmethod\nfrom collections import defaultdict\nfrom easydict import EasyDict\nimport copy\n\nfrom ding.utils import import_module, COMMANDER_REGISTRY, LimitedSpaceContainer\n\n\nclass BaseCommander(ABC):\n    r\"\"\"\n    Overview:\n        Base parallel commander abstract class.\n    Interface:\n        get_collector_task\n    \"\"\"\n\n    @classmethod\n    def default_config(cls: type) -> EasyDict:\n        cfg = EasyDict(copy.deepcopy(cls.config))\n        cfg.cfg_type = cls.__name__ + 'Dict'", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "base_parallel_commander.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3373493975903614}, {"context": "from typing import Dict, Any, Callable\nfrom collections import namedtuple\nimport numpy as np\n\nfrom ding.torch_utils import to_device\n\n\nclass PolicyFactory:\n    r\"\"\"\n    Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "policy_factory.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.32075471698113206}, {"context": "from typing import Union, Dict, Any, List\nfrom abc import ABC, abstractmethod\nimport copy\nfrom easydict import EasyDict\n\nfrom ding.utils import import_module, BUFFER_REGISTRY\n\n\nclass IBuffer(ABC):\n    r\"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "base_buffer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3157894736842105}, {"context": "import torch\nfrom easydict import EasyDict\nfrom ding.utils import import_module, MODEL_REGISTRY\n\n\ndef create_model(cfg: EasyDict) -> torch.nn.Module:\n    r\"\"\"\n    Overview:\n        Creat model given config dictionary\n    Arguments:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "common", "utils.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3}, {"context": "from collections import namedtuple\n\n\nclass FakeClass:\n\n    def __init__(self, *args, **kwargs):\n        pass\n\n\nclass FakeNN:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "fake_linklink.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2916666666666667}, {"context": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass SoftArgmax(nn.Module):\n    r\"\"\"\n    Overview:\n        An nn.Module that computes SoftArgmax\n    Interface:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "network", "soft_argmax.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2857142857142857}, {"context": "from typing import Callable, Optional, List\nfrom collections import namedtuple\nimport numpy as np\nfrom easydict import EasyDict\n\nfrom ding.utils import import_module, PLAYER_REGISTRY\nfrom .algorithm import pfsp\n\n\nclass Player:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "league", "player.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2833333333333333}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_joint.py\n# --------------------------------------------------\n#                 shape_inputs=self.shape_inputs,\n#                 output_dim=self.output_dim,\n#                 output_type=\"continuous\",\n#             )\n#         )\n# \n#         self.params = FrozenDict(\n#             dict(\n#                 model=self.joint.likelihood.model_manager.model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#                 lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#     def test_lik_log_batched_joint_prob(self):\n#         for batch in self.data_arr:\n#             log_joint_prob, aux = self.joint._batched_log_joint_prob(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_output_maker.py\n# --------------------------------------------------\n#         )\n# \n#     def test_regressor_model_manager_apply(self):\n#         regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n#         params = FrozenDict(\n#             dict(\n#                 model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n#                 lik_log_var=self.model.init(\n#                     self.rng, jnp.zeros((2,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#         inputs = make_array_random_inputs(\n#             n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n#         )\n#         assert regressor_model_manager.apply(params, inputs).shape == (\n#             self.n_inputs,\n#             2 * self.output_dim,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_joint.py\n# --------------------------------------------------\n#         )\n# \n#         self.params = FrozenDict(\n#             dict(\n#                 model=self.joint.likelihood.model_manager.model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#                 lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#     def test_lik_log_batched_joint_prob(self):\n#         for batch in self.data_arr:\n#             log_joint_prob, aux = self.joint._batched_log_joint_prob(\n#                 self.params, batch, n_data=batch[1].shape[0], return_aux=[\"outputs\"]\n#             )\n#             assert jnp.array([log_joint_prob]).shape == (1,)\n#             assert aux[\"outputs\"].shape == (self.n_inputs, 2 * self.output_dim)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_output_maker.py\n# --------------------------------------------------\n#             n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n#         )\n#         assert classifier_model_manager.apply(params, inputs).shape == (\n#             self.n_inputs,\n#             self.output_dim,\n#         )\n# \n#     def test_regressor_model_manager_apply(self):\n#         regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n#         params = FrozenDict(\n#             dict(\n#                 model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n#                 lik_log_var=self.model.init(\n#                     self.rng, jnp.zeros((2,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#         inputs = make_array_random_inputs(\n#             n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_joint.py\n# --------------------------------------------------\n#         )\n# \n#         self.params = FrozenDict(\n#             dict(\n#                 model=self.joint.likelihood.model_manager.model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#                 lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#     def test_lik_log_batched_joint_prob(self):\n#         for batch in self.data_arr:\n#             log_joint_prob, aux = self.joint._batched_log_joint_prob(\n#                 self.params, batch, n_data=batch[1].shape[0], return_aux=[\"outputs\"]\n#             )\n#             assert jnp.array([log_joint_prob]).shape == (1,)\n#             assert aux[\"outputs\"].shape == (self.n_inputs, 2 * self.output_dim)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_output_maker.py\n# --------------------------------------------------\n#         )\n# \n#     def test_regressor_model_manager_apply(self):\n#         regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n#         params = FrozenDict(\n#             dict(\n#                 model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n#                 lik_log_var=self.model.init(\n#                     self.rng, jnp.zeros((2,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#         inputs = make_array_random_inputs(\n#             n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n#         )\n#         assert regressor_model_manager.apply(params, inputs).shape == (\n#             self.n_inputs,\n#             2 * self.output_dim,\n#         )\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nsLoader\nfrom fortuna.model.mlp import MLP\nfrom fortuna.model.model_manager.classification import \\\n    ClassificationModelManager\nfrom fortuna.model.model_manager.regression import RegressionModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_model.likelihood.classification import \\\n    ClassificationLikelihood\nfrom fortuna.prob_model.likelihood.regression import RegressionLikelihood\nfrom fortuna.prob_output_layer.classification import \\\n    ClassificationProbOutputLayer\nfrom fortuna.prob_output_layer.regression import RegressionProbOutputLayer\nfrom fortuna.utils.random import RandomNumberGenerator\nfrom tests.make_data import (make_array_random_data,\n                             make_generator_fun_random_data)\n\n\nclass TestLikelihoods(unittest.TestCase):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.shape_inputs = (3,)\n        self.n_inputs = 10\n        self.output_dim = 2\n        self.n_batches = 2\n        self.batch_size = 3\n        self.rng = random.PRNGKey(0)\n        rng = RandomNumberGenerator(seed=0)\n        reg_prob_output_layer = RegressionProbOutputLayer()\n        reg_prob_output_layer.rng = rng\n        self.reg_lik = RegressionLikelihood(\n            model_manager=RegressionModelManager(\n                model=MLP(output_dim=self.output_dim),\n                likelihood_log_variance_model=MLP(output_dim=self.output_dim),\n            ),\n            output_calib_manager=OutputCalibManager(output_calibrator=None),\n            prob_output_layer=reg_prob_output_layer,\n        )\n        self.reg_lik.rng = rng\n        class_prob_output_layer = ClassificationProbOutputLayer()\n        class_prob_output_layer.rng = rng\n        self.class_lik = ClassificationLikelihood(\n            model_manager=ClassificationModelManager(\n                model=MLP(output_dim=self.output_dim)\n            ),\n            output_calib_manager=OutputCalibManager(output_calibrator=None),\n            prob_output_layer=class_prob_output_layer,\n        )\n        self.class_lik.rng = rng\n\n        self.reg_data_arr = DataLoader.from_array_data(\n            make_array_random_data(\n                n_data=self.n_inputs,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n        self.reg_inputs_arr = InputsLoader.from_data_loader(self.reg_data_arr)\n\n        self.reg_data_gen_fun = DataLoader.from_callable_iterable(\n            make_generator_fun_random_data(\n                n_batches=self.n_batches,\n                batch_size=self.batch_size,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n        self.reg_inputs_gen_fun = InputsLoader.from_data_loader(self.reg_data_gen_fun)\n\n        self.class_data_arr = DataLoader.from_array_data(\n            make_array_random_data(\n                n_data=self.n_inputs,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"discrete\",\n            )\n        )\n        self.class_inputs_arr = InputsLoader.from_data_loader(self.class_data_arr)\n\n        self.class_data_gen_fun = DataLoader.from_callable_iterable(\n            make_generator_fun_random_data(\n                n_batches=self.n_batches,\n                batch_size=self.batch_size,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"discrete\",\n            )\n        )\n        self.class_inputs_gen_fun = InputsLoader.from_data_loader(\n            self.class_data_gen_fun\n        )\n\n    def test_lik_batched_log_joint_prob(self):\n        params = FrozenDict(\n            dict(\n                model=self.reg_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.reg_lik.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        for batch_data in self.reg_data_arr:\n            batched_log_joint_prob1 = self.reg_lik._batched_log_joint_prob(\n                params, batch_data, n_data=batch_data[1].shape[0]\n            )\n            batched_log_joint_prob2 = self.reg_lik._batched_log_joint_prob(\n                params, batch_data, n_data=2 * batch_data[1].shape[0]\n            )\n            assert jnp.allclose(batched_log_joint_prob2, 2 * batched_log_joint_prob1)\n            assert jnp.array([batched_log_joint_prob1]).shape == (1,)\n\n            _, aux = self.reg_lik._batched_log_joint_prob(\n                params,\n                batch_data,\n                n_data=batch_data[1].shape[0],\n                return_aux=[\"outputs\"],\n            )\n            assert aux[\"outputs\"].shape == (self.n_inputs, 2 * self.output_dim)\n\n    def test_lik_log_joint_prob(self):\n        params = FrozenDict(\n            dict(\n                model=self.reg_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.reg_lik.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        log_probs = self.reg_lik.log_prob(params, self.reg_data_arr)\n        assert log_probs.shape == (self.n_inputs,)\n\n        log_probs = self.reg_lik.log_prob(params, self.reg_data_gen_fun)\n        assert log_probs.shape == (self.n_batches * self.batch_size,)\n\n    def test_sample(self):\n        params = FrozenDict(\n            dict(\n                model=self.reg_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.reg_lik.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        samples = self.reg_lik.sample(10, params, self.reg_inputs_arr)\n        assert samples.shape == (10, self.n_inputs, self.output_dim)\n\n        params = FrozenDict(\n            dict(\n                model=self.class_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)", "choices": [{"text": ")"}], "metadata": {"task_id": "awslabs_fortuna/29", "ground_truth": "                ),", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_likelihood.py"], "context_start_lineno": 6, "line_no": 167, "query_window": {"context": "\n    def test_sample(self):\n        params = FrozenDict(\n            dict(\n                model=self.reg_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.reg_lik.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        samples = self.reg_lik.sample(10, params, self.reg_inputs_arr)\n        assert samples.shape == (10, self.n_inputs, self.output_dim)\n\n        params = FrozenDict(\n            dict(\n                model=self.class_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_likelihood.py"], "line_no": 167, "task_id": "awslabs_fortuna/29", "start_line_no": 147, "end_line_no": 167, "window_size": 20, "context_start_lineno": 6, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n        )\n        assert classifier_model_manager.apply(params, inputs).shape == (\n            self.n_inputs,\n            self.output_dim,\n        )\n\n    def test_regressor_model_manager_apply(self):\n        regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n        params = FrozenDict(\n            dict(\n                model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n                lik_log_var=self.model.init(\n                    self.rng, jnp.zeros((2,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        inputs = make_array_random_inputs(\n            n_inputs=self.n_inputs, shape_inputs=self.shape_inputs", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_output_maker.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6463414634146342}, {"context": "                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n\n        self.params = FrozenDict(\n            dict(\n                model=self.joint.likelihood.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n    def test_lik_log_batched_joint_prob(self):\n        for batch in self.data_arr:\n            log_joint_prob, aux = self.joint._batched_log_joint_prob(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_joint.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6235294117647059}, {"context": "        self.model = MLP(output_dim=self.output_dim)\n        self.lik_log_var = MLP(output_dim=self.output_dim)\n\n    def test_classifier_model_manager_apply(self):\n        classifier_model_manager = ClassificationModelManager(self.model)\n        params = FrozenDict(\n            dict(model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)))\n        )\n\n        inputs = make_array_random_inputs(\n            n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n        )\n        assert classifier_model_manager.apply(params, inputs).shape == (\n            self.n_inputs,\n            self.output_dim,\n        )\n\n    def test_regressor_model_manager_apply(self):\n        regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n        params = FrozenDict(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_output_maker.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5764705882352941}, {"context": "                ),\n                lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n    def test_lik_log_batched_joint_prob(self):\n        for batch in self.data_arr:\n            log_joint_prob, aux = self.joint._batched_log_joint_prob(\n                self.params, batch, n_data=batch[1].shape[0], return_aux=[\"outputs\"]\n            )\n            assert jnp.array([log_joint_prob]).shape == (1,)\n            assert aux[\"outputs\"].shape == (self.n_inputs, 2 * self.output_dim)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_joint.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 64, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5531914893617021}, {"context": "            dict(\n                model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n                lik_log_var=self.model.init(\n                    self.rng, jnp.zeros((2,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        inputs = make_array_random_inputs(\n            n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n        )\n        assert regressor_model_manager.apply(params, inputs).shape == (\n            self.n_inputs,\n            2 * self.output_dim,\n        )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_output_maker.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 55, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5512820512820513}, {"context": "                    likelihood_log_variance_model=MLP(output_dim=self.output_dim),\n                ),\n                prob_output_layer=RegressionProbOutputLayer(),\n                output_calib_manager=OutputCalibManager(output_calibrator=None),\n            ),\n        )\n\n        self.data_arr = DataLoader.from_array_data(\n            make_array_random_data(\n                n_data=self.n_inputs,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n\n        self.params = FrozenDict(\n            dict(\n                model=self.joint.likelihood.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_joint.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.46534653465346537}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n# \n# \n# class DataLoader:\n#     def __init__(\n#         self,\n#         data_loader: Union[\n#             FromIterableToDataLoader,\n#             FromCallableIterableToDataLoader,\n#             FromArrayDataToDataLoader,\n#             FromTensorFlowDataLoaderToDataLoader,\n#             FromTorchDataLoaderToDataLoader,\n#             ChoppedDataLoader\n#         ],\n#     ):\n#         \"\"\"\n#         A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n#         are arrays, with different data points over the first dimension.\n# \n#         Parameters\n#         ----------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#     @classmethod\n#     def from_iterable(cls, iterable: Iterable[Batch],) -> DataLoader:\n#         \"\"\"\n#         Transform an iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n# \n#         Parameters\n#         ----------\n#         iterable: Iterable[Batch]\n#             An iterable of tuples of input and target arrays.\n# \n#         Returns\n#         -------\n#         DataLoader\n#             A data loader object.\n#         \"\"\"\n#         return cls(data_loader=FromIterableToDataLoader(iterable))\n# \n#     @classmethod\n#     def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         Transform a TensorFlow data loader into a :class:`~fortuna.data.loader.DataLoader` object.\n# \n#         Parameters\n#         ----------\n#         tf_data_loader\n#             A TensorFlow data loader where each batch is a tuple of input and target Tensors.\n# \n#         Returns\n#         -------\n#         DataLoader\n#             A data loader object.\n#         \"\"\"\n#         return cls(\n#             data_loader=FromTensorFlowDataLoaderToDataLoader(\n#                 tf_data_loader=tf_data_loader\n#             )\n#         )\n# \n#     @classmethod\n#     def from_torch_data_loader(cls, torch_data_loader) -> DataLoader:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/classification.py\n# --------------------------------------------------\n#     ) -> Status:\n#         \"\"\"\n#         Calibrate the probabilistic classifier.\n# \n#         Parameters\n#         ----------\n#         calib_data_loader : DataLoader\n#             A calibration data loader.\n#         val_data_loader : DataLoader\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/regression.py\n# --------------------------------------------------\n#         Parameters\n#         ----------\n#         calib_data_loader : DataLoader\n#             A calibration data loader.\n#         val_data_loader : DataLoader\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n#             self._check_output_dim(val_data_loader)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         Returns\n#         -------\n#         DataLoader\n#             A data loader object.\n#         \"\"\"\n#         return cls(data_loader=FromIterableToDataLoader(iterable))\n# \n#     @classmethod\n#     def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n#         \"\"\"\n#         Transform a TensorFlow data loader into a :class:`~fortuna.data.loader.DataLoader` object.\n# \n#         Parameters\n#         ----------\n#         tf_data_loader\n#             A TensorFlow data loader where each batch is a tuple of input and target Tensors.\n# \n#         Returns\n#         -------\n#         DataLoader\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#     def from_array_data(\n#         cls,\n#         data: Batch,\n#         batch_size: Optional[int] = None,\n#         shuffle: bool = False,\n#         prefetch: bool = False,\n#     ) -> DataLoader:\n#         \"\"\"\n#         Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n#         respectively.\n# \n#         Parameters\n#         ----------\n#         data: Batch\n#             Input and target arrays of data.\n#         batch_size: Optional[int]\n#             The batch size. If not given, the data will not be batched.\n#         shuffle: bool\n#             Whether the data loader should shuffle at every call.\n#         prefetch: bool\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#             FromTorchDataLoaderToDataLoader,\n#             ChoppedDataLoader\n#         ],\n#     ):\n#         \"\"\"\n#         A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n#         are arrays, with different data points over the first dimension.\n# \n#         Parameters\n#         ----------\n#         data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n#         FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n#             A data loader.\n#         \"\"\"\n#         self._data_loader = data_loader\n# \n#     def __iter__(self):\n#         yield from self._data_loader()\n# \n#     @classmethod\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n#         FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n#             A data loader.\n#         \"\"\"\n#         self._data_loader = data_loader\n# \n#     def __iter__(self):\n#         yield from self._data_loader()\n# \n#     @classmethod\n#     def from_array_data(\n#         cls,\n#         data: Batch,\n#         batch_size: Optional[int] = None,\n#         shuffle: bool = False,\n#         prefetch: bool = False,\n#     ) -> DataLoader:\n#         \"\"\"\n#         Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n#         respectively.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n where each batch is a tuple of input and target Tensors.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(\n            data_loader=FromTorchDataLoaderToDataLoader(\n                torch_data_loader=torch_data_loader\n            )\n        )\n\n    def to_array_data(self) -> Batch:\n        \"\"\"\n        Reduce a data loader to a tuple of input and target arrays.\n\n        Returns\n        -------\n        Batch\n            Tuple of input and target arrays.\n        \"\"\"\n        inputs, targets = [], []\n        for batch_inputs, batch_targets in self._data_loader():\n            inputs.append(batch_inputs)\n            targets.append(batch_targets)\n        return np.concatenate(inputs, 0), np.concatenate(targets, 0)\n\n    def to_array_inputs(self) -> Array:\n        \"\"\"\n        Reduce a data loader to an array of target data.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        inputs = []\n        for batch_inputs, batch_targets in self._data_loader():\n            inputs.append(batch_inputs)\n        return np.concatenate(inputs, 0)\n\n    def to_array_targets(self) -> Array:\n        \"\"\"\n        Reduce a data loader to an array of target data.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        targets = []\n        for batch_inputs, batch_targets in self._data_loader():\n            targets.append(batch_targets)\n        return np.concatenate(targets, 0)\n\n    def to_inputs_loader(self) -> InputsLoader:\n        \"\"\"\n        Reduce a data loader to an inputs loader.\n\n        Returns\n        -------\n        InputsLoader\n            The inputs loader derived from the data loader.\n        \"\"\"\n        return InputsLoader.from_data_loader(DataLoader(data_loader=self._data_loader))\n\n    def to_targets_loader(self) -> TargetsLoader:\n        \"\"\"\n        Reduce a data loader to a targets loader.\n\n        Returns\n        -------\n        TargetsLoader\n            The targets loader derived from the data loader.\n        \"\"\"\n        return TargetsLoader.from_data_loader(DataLoader(data_loader=self._data_loader))\n\n    @classmethod\n    def chop(cls, data_loader: DataLoader, divisor: int) -> DataLoader:\n        \"\"\"\n        Chop the last part of each batch of the data loader, to make sure the number od data points per batch divides\n        `divisor`.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader\n        divisor : int\n            Number of data points that each batched must divide.\n\n        Returns\n        -------\n        DataLoader\n            A data loader with chopped batches.\n        \"\"\"\n        return cls(data_loader=ChoppedDataLoader(data_loader=data_loader, divisor=divisor))\n\n\nclass InputsLoader:\n    def __init__(\n        self,\n        inputs_loader: Union[\n            FromArrayInputsToInputsLoader,\n            FromDataLoaderToInputsLoader,\n            FromCallableIterableToInputsLoader,\n            FromIterableToInputsLoader,\n            ChoppedInputsLoader\n        ],\n    ):\n        \"\"\"\n        An inputs loader class. Each batch is an array of inputs, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        inputs_loader : Union[FromArrayInputsToInputsLoader, FromDataLoaderToInputsLoader]\n            An inputs loader.\n        \"\"\"\n        self._inputs_loader = inputs_loader\n\n    def __iter__(self):\n        yield from self._inputs_loader()\n\n    @classmethod\n    def from_data_loader(cls, data_loader: DataLoader) -> InputsLoader:\n        \"\"\"\n        Reduce a data loader to an inputs loader.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader.\n        \"\"\"\n        return cls(inputs_loader=FromDataLoaderToInputsLoader(data_loader))\n\n    @classmethod\n    def from_array_inputs(\n        cls,\n        inputs: Array,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ) -> InputsLoader:\n        \"\"\"\n        Build a :class:`~fortuna.data.loader.InputsLoader` object from an array of input data.\n\n        Parameters\n        ----------\n        inputs: Array\n            Input array of data.\n        batch_size: Optional[int]\n            The batch size. If not given, the inputs will not be batched.\n        shuffle: bool\n            Whether the inputs loader should shuffle at every call.\n        prefetch: bool\n            Whether to prefetch the next batch.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader built out of the array of inputs.\n        \"\"\"\n        return cls(\n            inputs_loader=FromArrayInputsToInputsLoader(\n                inputs, batch_size=batch_size, shuffle=shuffle, prefetch=prefetch\n            )\n        )\n\n    def to_array_inputs(self) -> Array:\n        \"\"\"\n        Reduce an inputs loader to an array of inputs.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        inputs = []\n        for batch_inputs in self._inputs_loader():\n            inputs.append(batch_inputs)\n        return np.concatenate(inputs, 0)\n\n    @classmethod\n    def from_callable_iterable(\n        cls, fun: Callable[[], Iterable[Array]],\n    ) -> InputsLoader:\n        \"\"\"\n        Transform a callable iterable into a :class:`~fortuna.data.loader.InputsLoader` object.\n\n        Parameters\n        ----------\n        fun: Callable[[], Iterable[Array]]\n            A callable iterable of input arrays.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader object.\n        \"\"\"\n        return cls(inputs_loader=FromCallableIterableToInputsLoader(fun))\n\n    @classmethod\n    def from_iterable(cls, iterable: Iterable[Array],) -> InputsLoader:\n        \"\"\"\n        Transform an iterable into a :class:`~fortuna.data.loader.InputsLoader` object.\n\n        Parameters\n        ----------\n        iterable: Iterable[Array]\n            An iterable of input arrays.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader object.\n        \"\"\"\n        return cls(inputs_loader=FromIterableToInputsLoader(iterable))\n\n    @classmethod\n    def chop(cls, inputs_loader: InputsLoader, divisor: int) -> InputsLoader:\n        \"\"\"\n        Chop the last part of each batch of the inputs loader, to make sure the number od data points per batch divides\n        `divisor`.\n\n        Parameters\n        ----------\n        inputs_loader : InputsLoader\n            An inputs loader.\n        divisor : int\n            Number of data points that each batched must divide.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader with chopped batches.\n        \"\"\"\n        return cls(inputs_loader=ChoppedInputsLoader(inputs_loader=inputs_loader, divisor=divisor))\n\n\nclass TargetsLoader:\n    def __init__(\n        self,\n        targets_loader: Union[\n            FromArrayTargetsToTargetsLoader,\n            FromDataLoaderToTargetsLoader,\n            FromCallableIterableToTargetsLoader,\n            FromIterableToTargetsLoader,\n            ChoppedTargetsLoader\n        ],\n    ):\n        \"\"\"\n        A targets loader class. Each batch is an array of targets, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        targets_loader : Union[FromArrayTargetsToTargetsLoader, FromDataLoaderToTargetsLoader]\n            A targets loader.\n        \"\"\"\n        self._targets_loader = targets_loader\n\n    def __iter__(self):", "choices": [{"text": "yield from self._targets_loader()"}], "metadata": {"task_id": "awslabs_fortuna/148", "ground_truth": "        yield from self._targets_loader()", "fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "context_start_lineno": 136, "line_no": 402, "query_window": {"context": "        self,\n        targets_loader: Union[\n            FromArrayTargetsToTargetsLoader,\n            FromDataLoaderToTargetsLoader,\n            FromCallableIterableToTargetsLoader,\n            FromIterableToTargetsLoader,\n            ChoppedTargetsLoader\n        ],\n    ):\n        \"\"\"\n        A targets loader class. Each batch is an array of targets, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        targets_loader : Union[FromArrayTargetsToTargetsLoader, FromDataLoaderToTargetsLoader]\n            A targets loader.\n        \"\"\"\n        self._targets_loader = targets_loader\n\n    def __iter__(self):", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 402, "task_id": "awslabs_fortuna/148", "start_line_no": 382, "end_line_no": 402, "window_size": 20, "context_start_lineno": 136, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            FromTorchDataLoaderToDataLoader,\n            ChoppedDataLoader\n        ],\n    ):\n        \"\"\"\n        A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n        are arrays, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n        FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n            A data loader.\n        \"\"\"\n        self._data_loader = data_loader\n\n    def __iter__(self):\n        yield from self._data_loader()\n\n    @classmethod", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6705882352941176}, {"context": "\n\nclass DataLoader:\n    def __init__(\n        self,\n        data_loader: Union[\n            FromIterableToDataLoader,\n            FromCallableIterableToDataLoader,\n            FromArrayDataToDataLoader,\n            FromTensorFlowDataLoaderToDataLoader,\n            FromTorchDataLoaderToDataLoader,\n            ChoppedDataLoader\n        ],\n    ):\n        \"\"\"\n        A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n        are arrays, with different data points over the first dimension.\n\n        Parameters\n        ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6172839506172839}, {"context": "        data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n        FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n            A data loader.\n        \"\"\"\n        self._data_loader = data_loader\n\n    def __iter__(self):\n        yield from self._data_loader()\n\n    @classmethod\n    def from_array_data(\n        cls,\n        data: Batch,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ) -> DataLoader:\n        \"\"\"\n        Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n        respectively.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.37735849056603776}, {"context": "    @classmethod\n    def from_iterable(cls, iterable: Iterable[Batch],) -> DataLoader:\n        \"\"\"\n        Transform an iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        iterable: Iterable[Batch]\n            An iterable of tuples of input and target arrays.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromIterableToDataLoader(iterable))\n\n    @classmethod\n    def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n        \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3106796116504854}, {"context": "\n    def calibrate(\n        self,\n        calib_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_config: CalibConfig = CalibConfig(),\n    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "regression.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3076923076923077}, {"context": "            fit_config,\n            calib_config,\n            **fit_kwargs,\n        )\n\n    def calibrate(\n        self,\n        calib_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_config: CalibConfig = CalibConfig(),\n    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "classification.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3076923076923077}, {"context": "        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromIterableToDataLoader(iterable))\n\n    @classmethod\n    def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n        \"\"\"\n        Transform a TensorFlow data loader into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        tf_data_loader\n            A TensorFlow data loader where each batch is a tuple of input and target Tensors.\n\n        Returns\n        -------\n        DataLoader", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3069306930693069}, {"context": "        fun: Callable[[], Iterable[Batch]]\n            A callable iterable of tuples of input and target arrays.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromCallableIterableToDataLoader(fun))\n\n    @classmethod\n    def from_iterable(cls, iterable: Iterable[Batch],) -> DataLoader:\n        \"\"\"\n        Transform an iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        iterable: Iterable[Batch]\n            An iterable of tuples of input and target arrays.\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3018867924528302}, {"context": "from __future__ import annotations\n\nfrom typing import Callable, Iterable, Optional, Union\n\nimport jax\nimport numpy as np\nfrom flax import jax_utils\nfrom jax.tree_util import tree_map\n\nfrom fortuna.typing import Array, Batch\n\n\nclass DataLoader:\n    def __init__(\n        self,\n        data_loader: Union[\n            FromIterableToDataLoader,\n            FromCallableIterableToDataLoader,\n            FromArrayDataToDataLoader,\n            FromTensorFlowDataLoaderToDataLoader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.28125}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n# \n# \n# class RegressionPredictive(Predictive):\n#     def __init__(\n#         self,\n#         output_calib_manager: OutputCalibManager,\n#         prob_output_layer: RegressionProbOutputLayer,\n#     ):\n#         super().__init__(\n#             output_calib_manager=output_calib_manager,\n#             prob_output_layer=prob_output_layer,\n#         )\n# \n#     def quantile(\n#         self,\n#         q: Union[float, Array, List],\n#         outputs: Array,\n#         n_target_samples: Optional[int] = 30,\n#         rng: Optional[PRNGKeyArray] = None,\n#         calibrated: bool = True,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/predictive/base.py\n# --------------------------------------------------\n#     def __init__(self, posterior: Posterior):\n#         \"\"\"\n#         Predictive distribution abstract class.\n# \n#         Parameters\n#         ----------\n#         posterior : Posterior\n#              A posterior distribution object.\n#         \"\"\"\n#         self.likelihood = posterior.joint.likelihood\n#         self.posterior = posterior\n# \n#     def log_prob(\n#         self,\n#         data_loader: DataLoader,\n#         n_posterior_samples: int = 30,\n#         rng: Optional[PRNGKeyArray] = None,\n#         distribute: bool = True,\n#         **kwargs\n#     ) -> jnp.ndarray:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/predictive/base.py\n# --------------------------------------------------\n# from fortuna.data.loader import (DataLoader,\n#                                  DeviceDimensionAugmentedDataLoader,\n#                                  DeviceDimensionAugmentedInputsLoader,\n#                                  InputsLoader, TargetsLoader)\n# from fortuna.prob_model.posterior.base import Posterior\n# from fortuna.typing import Array, Batch, CalibMutable, CalibParams\n# from fortuna.utils.random import WithRNG\n# \n# \n# class Predictive(WithRNG):\n#     def __init__(self, posterior: Posterior):\n#         \"\"\"\n#         Predictive distribution abstract class.\n# \n#         Parameters\n#         ----------\n#         posterior : Posterior\n#              A posterior distribution object.\n#         \"\"\"\n#         self.likelihood = posterior.joint.likelihood\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/base.py\n# --------------------------------------------------\n# from fortuna.utils.random import WithRNG\n# \n# \n# class Predictive(WithRNG, abc.ABC):\n#     def __init__(\n#         self,\n#         output_calib_manager: OutputCalibManager,\n#         prob_output_layer: ProbOutputLayer,\n#     ):\n#         r\"\"\"\n#         Abstract predictive distribution. It characterizes the distribution of the target variable given the\n#         calibrated outputs. It can be see as :math:`p(y|\\omega)`, where :math:`y` is a target variable and\n#         :math:`\\omega` a calibrated output.\n#         \"\"\"\n#         self.output_calib_manager = output_calib_manager\n#         self.prob_output_layer = prob_output_layer\n#         self.state = None\n# \n#     def log_prob(\n#         self, outputs: Array, targets: Array, calibrated: bool = True, **kwargs\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/likelihood/classification.py\n# --------------------------------------------------\n#     OutputCalibManager\n# from fortuna.prob_model.likelihood.base import Likelihood\n# from fortuna.prob_output_layer.classification import \\\n#     ClassificationProbOutputLayer\n# from fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n# \n# \n# class ClassificationLikelihood(Likelihood):\n#     def __init__(\n#         self,\n#         model_manager: ClassificationModelManager,\n#         prob_output_layer: ClassificationProbOutputLayer,\n#         output_calib_manager: OutputCalibManager,\n#     ):\n#         \"\"\"\n#         A classification likelihood function class. In this class, the likelihood function is additionally assumed to\n#         be a probability density function, i.e. positive and integrating to 1. The likelihood is formed by three\n#         objects applied in sequence: the model manager, the output calibrator and the probabilistic output layer. The\n#         model manager maps parameters and inputs to outputs. The output calibration takes outputs and returns some\n#         calibrated version of them. The probabilistic output layer describes the probability distribution of the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/joint/base.py\n# --------------------------------------------------\n# from fortuna.prob_model.joint.state import JointState\n# from fortuna.prob_model.likelihood.base import Likelihood\n# from fortuna.prob_model.prior.base import Prior\n# from fortuna.typing import Batch, CalibMutable, CalibParams, Mutable, Params\n# from fortuna.utils.random import WithRNG\n# \n# \n# class Joint(WithRNG):\n#     def __init__(self, prior: Prior, likelihood: Likelihood):\n#         r\"\"\"\n#         Joint distribution class. This is the joint distribution of target variables and random model parameters given\n#         input variables and calibration parameters. It is given by\n# \n#         .. math::\n#             p(y, w|x, \\phi),\n# \n#         where:\n#          - :math:`x` is an observed input variable;\n#          - :math:`y` is an observed target variable;\n#          - :math:`w` denotes the random model parameters;\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/likelihood/regression.py\n# --------------------------------------------------\n#     OutputCalibManager\n# from fortuna.prob_model.likelihood.base import Likelihood\n# from fortuna.prob_output_layer.regression import RegressionProbOutputLayer\n# from fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n# \n# \n# class RegressionLikelihood(Likelihood):\n#     def __init__(\n#         self,\n#         model_manager: RegressionModelManager,\n#         prob_output_layer: RegressionProbOutputLayer,\n#         output_calib_manager: OutputCalibManager,\n#     ):\n#         \"\"\"\n#         A classification likelihood function class. In this class, the likelihood function is additionally assumed to\n#         be a probability density function, i.e. positive and integrating to 1. The likelihood is formed by three\n#         objects applied in sequence: the model manager, the output calibrator and the probabilistic output layer. The\n#         model manager maps parameters and inputs to outputs. The output calibration takes outputs and returns some\n#         calibrated version of them. The probabilistic output layer describes the probability distribution of the\n#         calibrated outputs.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport abc\nfrom typing import Any, Callable, List, Optional, Tuple, Union\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import jit, pmap\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import (DataLoader,\n                                 DeviceDimensionAugmentedDataLoader,\n                                 DeviceDimensionAugmentedInputsLoader,\n                                 InputsLoader)\nfrom fortuna.model.model_manager.base import ModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import (Array, Batch, CalibMutable, CalibParams, Mutable,\n                            Params)\nfrom fortuna.utils.random import WithRNG\n\n\nclass Likelihood(WithRNG):\n    def __init__(\n        self,\n        model_manager: ModelManager,", "choices": [{"text": "prob_output_layer: ProbOutputLayer,"}], "metadata": {"task_id": "awslabs_fortuna/104", "ground_truth": "        prob_output_layer: ProbOutputLayer,", "fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "base.py"], "context_start_lineno": 0, "line_no": 25, "query_window": {"context": "from jax import jit, pmap\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import (DataLoader,\n                                 DeviceDimensionAugmentedDataLoader,\n                                 DeviceDimensionAugmentedInputsLoader,\n                                 InputsLoader)\nfrom fortuna.model.model_manager.base import ModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import (Array, Batch, CalibMutable, CalibParams, Mutable,\n                            Params)\nfrom fortuna.utils.random import WithRNG\n\n\nclass Likelihood(WithRNG):\n    def __init__(\n        self,\n        model_manager: ModelManager,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "base.py"], "line_no": 25, "task_id": "awslabs_fortuna/104", "start_line_no": 5, "end_line_no": 25, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "from typing import Optional, Union\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom jax import vmap\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import InputsLoader\nfrom fortuna.model.model_manager.regression import RegressionModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_model.likelihood.base import Likelihood\nfrom fortuna.prob_output_layer.regression import RegressionProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n\n\nclass RegressionLikelihood(Likelihood):\n    def __init__(\n        self,\n        model_manager: RegressionModelManager,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "regression.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.616822429906542}, {"context": "from typing import List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import DataLoader\nfrom fortuna.model.model_manager.state import ModelManagerState\nfrom fortuna.output_calibrator.output_calib_manager.state import \\\n    OutputCalibManagerState\nfrom fortuna.prob_model.joint.state import JointState\nfrom fortuna.prob_model.likelihood.base import Likelihood\nfrom fortuna.prob_model.prior.base import Prior\nfrom fortuna.typing import Batch, CalibMutable, CalibParams, Mutable, Params\nfrom fortuna.utils.random import WithRNG\n\n\nclass Joint(WithRNG):\n    def __init__(self, prior: Prior, likelihood: Likelihood):\n        r\"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "joint", "base.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5546218487394958}, {"context": "from typing import Optional\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import vmap\n\nfrom fortuna.data.loader import InputsLoader\nfrom fortuna.model.model_manager.classification import \\\n    ClassificationModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_model.likelihood.base import Likelihood\nfrom fortuna.prob_output_layer.classification import \\\n    ClassificationProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n\n\nclass ClassificationLikelihood(Likelihood):\n    def __init__(\n        self,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "classification.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5436893203883495}, {"context": "import abc\nfrom typing import Any, List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG, abc.ABC):\n    def __init__(\n        self,\n        output_calib_manager: OutputCalibManager,\n        prob_output_layer: ProbOutputLayer,\n    ):\n        r\"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "base.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5315315315315315}, {"context": "import abc\nfrom typing import Callable, Dict, List, Optional, Tuple, Union\n\nimport jax\nimport jax.numpy as jnp\nimport jax.scipy as jsp\nfrom jax import jit, lax, pmap, random\nfrom jax._src.prng import PRNGKeyArray\nfrom jax.tree_util import tree_map\n\nfrom fortuna.data.loader import (DataLoader,\n                                 DeviceDimensionAugmentedDataLoader,\n                                 DeviceDimensionAugmentedInputsLoader,\n                                 InputsLoader, TargetsLoader)\nfrom fortuna.prob_model.posterior.base import Posterior\nfrom fortuna.typing import Array, Batch, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG):", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "base.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4918032786885246}, {"context": "from fortuna.data.loader import (DataLoader,\n                                 DeviceDimensionAugmentedDataLoader,\n                                 DeviceDimensionAugmentedInputsLoader,\n                                 InputsLoader, TargetsLoader)\nfrom fortuna.prob_model.posterior.base import Posterior\nfrom fortuna.typing import Array, Batch, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG):\n    def __init__(self, posterior: Posterior):\n        \"\"\"\n        Predictive distribution abstract class.\n\n        Parameters\n        ----------\n        posterior : Posterior\n             A posterior distribution object.\n        \"\"\"\n        self.likelihood = posterior.joint.likelihood", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "base.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.49122807017543857}, {"context": "from typing import List, Optional, Union\n\nimport jax.numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.calib_model.predictive.base import Predictive\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.regression import RegressionProbOutputLayer\nfrom fortuna.typing import Array\n\n\nclass RegressionPredictive(Predictive):\n    def __init__(\n        self,\n        output_calib_manager: OutputCalibManager,\n        prob_output_layer: RegressionProbOutputLayer,\n    ):\n        super().__init__(\n            output_calib_manager=output_calib_manager,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.43859649122807015}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/vae.py\n# --------------------------------------------------\n#         sample = self.conv_in(sample)\n# \n#         # down\n#         for down_block in self.down_blocks:\n#             sample = down_block(sample)\n# \n#         # middle\n#         sample = self.mid_block(sample)\n# \n#         # post-process\n#         sample = self.conv_norm_out(sample)\n#         sample = self.conv_act(sample)\n#         sample = self.conv_out(sample)\n# \n#         return sample\n# \n# \n# class Decoder(nn.Module):\n#     def __init__(\n#         self,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/vae_flax.py\n# --------------------------------------------------\n#                 padding=\"VALID\",\n#                 dtype=self.dtype,\n#             )\n# \n#     def __call__(self, hidden_states, deterministic=True):\n#         residual = hidden_states\n#         hidden_states = self.norm1(hidden_states)\n#         hidden_states = nn.swish(hidden_states)\n#         hidden_states = self.conv1(hidden_states)\n# \n#         hidden_states = self.norm2(hidden_states)\n#         hidden_states = nn.swish(hidden_states)\n#         hidden_states = self.dropout_layer(hidden_states, deterministic)\n#         hidden_states = self.conv2(hidden_states)\n# \n#         if self.conv_shortcut is not None:\n#             residual = self.conv_shortcut(residual)\n# \n#         return hidden_states + residual\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_1d_blocks.py\n# --------------------------------------------------\n#         self.group_norm_1 = nn.GroupNorm(1, mid_channels)\n#         self.gelu_1 = nn.GELU()\n#         self.conv_2 = nn.Conv1d(mid_channels, out_channels, 5, padding=2)\n# \n#         if not self.is_last:\n#             self.group_norm_2 = nn.GroupNorm(1, out_channels)\n#             self.gelu_2 = nn.GELU()\n# \n#     def forward(self, hidden_states):\n#         residual = self.conv_skip(hidden_states) if self.has_conv_skip else hidden_states\n# \n#         hidden_states = self.conv_1(hidden_states)\n#         hidden_states = self.group_norm_1(hidden_states)\n#         hidden_states = self.gelu_1(hidden_states)\n#         hidden_states = self.conv_2(hidden_states)\n# \n#         if not self.is_last:\n#             hidden_states = self.group_norm_2(hidden_states)\n#             hidden_states = self.gelu_2(hidden_states)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_1d_blocks.py\n# --------------------------------------------------\n#     def __init__(self, num_groups_out, out_channels, embed_dim, act_fn):\n#         super().__init__()\n#         self.final_conv1d_1 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n#         self.final_conv1d_gn = nn.GroupNorm(num_groups_out, embed_dim)\n#         if act_fn == \"silu\":\n#             self.final_conv1d_act = nn.SiLU()\n#         if act_fn == \"mish\":\n#             self.final_conv1d_act = nn.Mish()\n#         self.final_conv1d_2 = nn.Conv1d(embed_dim, out_channels, 1)\n# \n#     def forward(self, hidden_states, temb=None):\n#         hidden_states = self.final_conv1d_1(hidden_states)\n#         hidden_states = rearrange_dims(hidden_states)\n#         hidden_states = self.final_conv1d_gn(hidden_states)\n#         hidden_states = rearrange_dims(hidden_states)\n#         hidden_states = self.final_conv1d_act(hidden_states)\n#         hidden_states = self.final_conv1d_2(hidden_states)\n#         return hidden_states\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_1d_blocks.py\n# --------------------------------------------------\n#     def forward(self, hidden_states, temb=None):\n#         hidden_states = self.final_conv1d_1(hidden_states)\n#         hidden_states = rearrange_dims(hidden_states)\n#         hidden_states = self.final_conv1d_gn(hidden_states)\n#         hidden_states = rearrange_dims(hidden_states)\n#         hidden_states = self.final_conv1d_act(hidden_states)\n#         hidden_states = self.final_conv1d_2(hidden_states)\n#         return hidden_states\n# \n# \n# class OutValueFunctionBlock(nn.Module):\n#     def __init__(self, fc_dim, embed_dim):\n#         super().__init__()\n#         self.final_block = nn.ModuleList(\n#             [\n#                 nn.Linear(fc_dim + embed_dim, fc_dim // 2),\n#                 nn.Mish(),\n#                 nn.Linear(fc_dim // 2, 1),\n#             ]\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_1d_blocks.py\n# --------------------------------------------------\n# class ResConvBlock(nn.Module):\n#     def __init__(self, in_channels, mid_channels, out_channels, is_last=False):\n#         super().__init__()\n#         self.is_last = is_last\n#         self.has_conv_skip = in_channels != out_channels\n# \n#         if self.has_conv_skip:\n#             self.conv_skip = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n# \n#         self.conv_1 = nn.Conv1d(in_channels, mid_channels, 5, padding=2)\n#         self.group_norm_1 = nn.GroupNorm(1, mid_channels)\n#         self.gelu_1 = nn.GELU()\n#         self.conv_2 = nn.Conv1d(mid_channels, out_channels, 5, padding=2)\n# \n#         if not self.is_last:\n#             self.group_norm_2 = nn.GroupNorm(1, out_channels)\n#             self.gelu_2 = nn.GELU()\n# \n#     def forward(self, hidden_states):\n#         residual = self.conv_skip(hidden_states) if self.has_conv_skip else hidden_states\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom functools import partial\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Upsample1D(nn.Module):\n    \"\"\"\n    An upsampling layer with an optional convolution.\n\n    Parameters:\n            channels: channels in the inputs and outputs.\n            use_conv: a bool determining if a convolution is applied.\n            use_conv_transpose:\n            out_channels:\n    \"\"\"\n\n    def __init__(self, channels, use_conv=False, use_conv_transpose=False, out_channels=None, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.use_conv_transpose = use_conv_transpose\n        self.name = name\n\n        self.conv = None\n        if use_conv_transpose:\n            self.conv = nn.ConvTranspose1d(channels, self.out_channels, 4, 2, 1)\n        elif use_conv:\n            self.conv = nn.Conv1d(self.channels, self.out_channels, 3, padding=1)\n\n    def forward(self, x):\n        assert x.shape[1] == self.channels\n        if self.use_conv_transpose:\n            return self.conv(x)\n\n        x = F.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n\n        if self.use_conv:\n            x = self.conv(x)\n\n        return x\n\n\nclass Downsample1D(nn.Module):\n    \"\"\"\n    A downsampling layer with an optional convolution.\n\n    Parameters:\n        channels: channels in the inputs and outputs.\n        use_conv: a bool determining if a convolution is applied.\n        out_channels:\n        padding:\n    \"\"\"\n\n    def __init__(self, channels, use_conv=False, out_channels=None, padding=1, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.padding = padding\n        stride = 2\n        self.name = name\n\n        if use_conv:\n            self.conv = nn.Conv1d(self.channels, self.out_channels, 3, stride=stride, padding=padding)\n        else:\n            assert self.channels == self.out_channels\n            self.conv = nn.AvgPool1d(kernel_size=stride, stride=stride)\n\n    def forward(self, x):\n        assert x.shape[1] == self.channels\n        return self.conv(x)\n\n\nclass Upsample2D(nn.Module):\n    \"\"\"\n    An upsampling layer with an optional convolution.\n\n    Parameters:\n        channels: channels in the inputs and outputs.\n        use_conv: a bool determining if a convolution is applied.\n        use_conv_transpose:\n        out_channels:\n    \"\"\"\n\n    def __init__(self, channels, use_conv=False, use_conv_transpose=False, out_channels=None, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.use_conv_transpose = use_conv_transpose\n        self.name = name\n\n        conv = None\n        if use_conv_transpose:\n            conv = nn.ConvTranspose2d(channels, self.out_channels, 4, 2, 1)\n        elif use_conv:\n            conv = nn.Conv2d(self.channels, self.out_channels, 3, padding=1)\n\n        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n        if name == \"conv\":\n            self.conv = conv\n        else:\n            self.Conv2d_0 = conv\n\n    def forward(self, hidden_states, output_size=None):\n        assert hidden_states.shape[1] == self.channels\n\n        if self.use_conv_transpose:\n            return self.conv(hidden_states)\n\n        # Cast to float32 to as 'upsample_nearest2d_out_frame' op does not support bfloat16\n        # TODO(Suraj): Remove this cast once the issue is fixed in PyTorch\n        # https://github.com/pytorch/pytorch/issues/86679\n        dtype = hidden_states.dtype\n        if dtype == torch.bfloat16:\n            hidden_states = hidden_states.to(torch.float32)\n\n        # upsample_nearest_nhwc fails with large batch sizes. see https://github.com/huggingface/diffusers/issues/984\n        if hidden_states.shape[0] >= 64:\n            hidden_states = hidden_states.contiguous()\n\n        # if `output_size` is passed we force the interpolation output\n        # size and do not make use of `scale_factor=2`\n        if output_size is None:\n            hidden_states = F.interpolate(hidden_states, scale_factor=2.0, mode=\"nearest\")\n        else:\n            hidden_states = F.interpolate(hidden_states, size=output_size, mode=\"nearest\")\n\n        # If the input is bfloat16, we cast back to bfloat16\n        if dtype == torch.bfloat16:\n            hidden_states = hidden_states.to(dtype)\n\n        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n        if self.use_conv:\n            if self.name == \"conv\":\n                hidden_states = self.conv(hidden_states)\n            else:\n                hidden_states = self.Conv2d_0(hidden_states)\n\n        return hidden_states\n\n\nclass Downsample2D(nn.Module):\n    \"\"\"\n    A downsampling layer with an optional convolution.\n\n    Parameters:\n        channels: channels in the inputs and outputs.\n        use_conv: a bool determining if a convolution is applied.\n        out_channels:\n        padding:\n    \"\"\"\n\n    def __init__(self, channels, use_conv=False, out_channels=None, padding=1, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.padding = padding\n        stride = 2\n        self.name = name\n\n        if use_conv:\n            conv = nn.Conv2d(self.channels, self.out_channels, 3, stride=stride, padding=padding)\n        else:\n            assert self.channels == self.out_channels\n            conv = nn.AvgPool2d(kernel_size=stride, stride=stride)\n\n        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n        if name == \"conv\":\n            self.Conv2d_0 = conv", "choices": [{"text": "class Downsample2D(nn.Module):"}], "metadata": {"task_id": "huggingface_diffusers/132", "ground_truth": "            self.conv = conv", "fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "resnet.py"], "context_start_lineno": 0, "line_no": 174, "query_window": {"context": "    \"\"\"\n\n    def __init__(self, channels, use_conv=False, out_channels=None, padding=1, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.padding = padding\n        stride = 2\n        self.name = name\n\n        if use_conv:\n            conv = nn.Conv2d(self.channels, self.out_channels, 3, stride=stride, padding=padding)\n        else:\n            assert self.channels == self.out_channels\n            conv = nn.AvgPool2d(kernel_size=stride, stride=stride)\n\n        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n        if name == \"conv\":\n            self.Conv2d_0 = conv", "metadata": {"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "resnet.py"], "line_no": 174, "task_id": "huggingface_diffusers/132", "start_line_no": 154, "end_line_no": 174, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        # compute next hidden_states\n        hidden_states = self.proj_attn(hidden_states)\n        hidden_states = hidden_states.transpose(1, 2)\n        hidden_states = self.dropout(hidden_states)\n\n        output = hidden_states + residual\n\n        return output\n\n\nclass ResConvBlock(nn.Module):\n    def __init__(self, in_channels, mid_channels, out_channels, is_last=False):\n        super().__init__()\n        self.is_last = is_last\n        self.has_conv_skip = in_channels != out_channels\n\n        if self.has_conv_skip:\n            self.conv_skip = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n\n        self.conv_1 = nn.Conv1d(in_channels, mid_channels, 5, padding=2)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_1d_blocks.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.35398230088495575}, {"context": "    def __init__(self, num_groups_out, out_channels, embed_dim, act_fn):\n        super().__init__()\n        self.final_conv1d_1 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n        self.final_conv1d_gn = nn.GroupNorm(num_groups_out, embed_dim)\n        if act_fn == \"silu\":\n            self.final_conv1d_act = nn.SiLU()\n        if act_fn == \"mish\":\n            self.final_conv1d_act = nn.Mish()\n        self.final_conv1d_2 = nn.Conv1d(embed_dim, out_channels, 1)\n\n    def forward(self, hidden_states, temb=None):\n        hidden_states = self.final_conv1d_1(hidden_states)\n        hidden_states = rearrange_dims(hidden_states)\n        hidden_states = self.final_conv1d_gn(hidden_states)\n        hidden_states = rearrange_dims(hidden_states)\n        hidden_states = self.final_conv1d_act(hidden_states)\n        hidden_states = self.final_conv1d_2(hidden_states)\n        return hidden_states\n\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_1d_blocks.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.35398230088495575}, {"context": "\n        if self.upsample:\n            hidden_states = self.upsample(hidden_states)\n        if self.downsample:\n            self.downsample = self.downsample(hidden_states)\n\n        return hidden_states\n\n\nclass OutConv1DBlock(nn.Module):\n    def __init__(self, num_groups_out, out_channels, embed_dim, act_fn):\n        super().__init__()\n        self.final_conv1d_1 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n        self.final_conv1d_gn = nn.GroupNorm(num_groups_out, embed_dim)\n        if act_fn == \"silu\":\n            self.final_conv1d_act = nn.SiLU()\n        if act_fn == \"mish\":\n            self.final_conv1d_act = nn.Mish()\n        self.final_conv1d_2 = nn.Conv1d(embed_dim, out_channels, 1)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_1d_blocks.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3448275862068966}, {"context": "class ResConvBlock(nn.Module):\n    def __init__(self, in_channels, mid_channels, out_channels, is_last=False):\n        super().__init__()\n        self.is_last = is_last\n        self.has_conv_skip = in_channels != out_channels\n\n        if self.has_conv_skip:\n            self.conv_skip = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n\n        self.conv_1 = nn.Conv1d(in_channels, mid_channels, 5, padding=2)\n        self.group_norm_1 = nn.GroupNorm(1, mid_channels)\n        self.gelu_1 = nn.GELU()\n        self.conv_2 = nn.Conv1d(mid_channels, out_channels, 5, padding=2)\n\n        if not self.is_last:\n            self.group_norm_2 = nn.GroupNorm(1, out_channels)\n            self.gelu_2 = nn.GELU()\n\n    def forward(self, hidden_states):\n        residual = self.conv_skip(hidden_states) if self.has_conv_skip else hidden_states", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_1d_blocks.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "        )\n\n        use_nin_shortcut = self.in_channels != out_channels if self.use_nin_shortcut is None else self.use_nin_shortcut\n\n        self.conv_shortcut = None\n        if use_nin_shortcut:\n            self.conv_shortcut = nn.Conv(\n                out_channels,\n                kernel_size=(1, 1),\n                strides=(1, 1),\n                padding=\"VALID\",\n                dtype=self.dtype,\n            )\n\n    def __call__(self, hidden_states, deterministic=True):\n        residual = hidden_states\n        hidden_states = self.norm1(hidden_states)\n        hidden_states = nn.swish(hidden_states)\n        hidden_states = self.conv1(hidden_states)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "vae_flax.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.32432432432432434}, {"context": "\n        # out\n        self.conv_norm_out = nn.GroupNorm(num_channels=block_out_channels[-1], num_groups=norm_num_groups, eps=1e-6)\n        self.conv_act = nn.SiLU()\n\n        conv_out_channels = 2 * out_channels if double_z else out_channels\n        self.conv_out = nn.Conv2d(block_out_channels[-1], conv_out_channels, 3, padding=1)\n\n    def forward(self, x):\n        sample = x\n        sample = self.conv_in(sample)\n\n        # down\n        for down_block in self.down_blocks:\n            sample = down_block(sample)\n\n        # middle\n        sample = self.mid_block(sample)\n\n        # post-process", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "vae.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3217391304347826}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/exception/base.py\n# --------------------------------------------------\n#         Returns:\n#             - status_code (:obj:`int`): Http status code\n#         \"\"\"\n#         return self.__status_code\n# \n#     @property\n#     def success(self) -> bool:\n#         return self.__success\n# \n#     @property\n#     def code(self) -> int:\n#         return self.__code\n# \n#     @property\n#     def message(self) -> str:\n#         return self.__message\n# \n#     @property\n#     def data(self) -> Mapping[str, Any]:\n#         return self.__data\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/tests/loader/test_number.py\n# --------------------------------------------------\n#     def test_is_positive(self):\n#         _loader = is_positive()\n#         assert _loader(1) == 1\n#         with pytest.raises(ValueError):\n#             _loader(0)\n#         with pytest.raises(ValueError):\n#             _loader(-1)\n# \n#     def test_is_negative(self):\n#         _loader = is_negative()\n#         with pytest.raises(ValueError):\n#             _loader(1)\n#         with pytest.raises(ValueError):\n#             _loader(0)\n#         assert _loader(-1) == -1\n# \n#     def test_non_positive(self):\n#         _loader = non_positive()\n#         with pytest.raises(ValueError):\n#             _loader(1)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/base/test_network.py\n# --------------------------------------------------\n# \n#     @responses.activate\n#     def test_http_engine_with_path(self):\n#         with self.__yield_http_engine():\n#             engine = HttpEngine(host='example.com', port=7777, path='/this/is')\n#             response = engine.request('GET', '200')\n#             assert response.status_code == 200\n#             assert json.loads(response.content.decode()) == {\"success\": True}\n# \n#             with pytest.raises(HTTPError) as ei:\n#                 engine.request('GET', '404')\n# \n#             err = ei.value\n#             assert err.response.status_code == 404\n#             assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n# \n#     @responses.activate\n#     def test_get_http_engine_class(self):\n#         with self.__yield_http_engine():\n#             _token = '233'\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/tests/test_default_helper.py\n# --------------------------------------------------\n#         assert 'z' not in new3['b']\n# \n#     def test_flatten_dict(self):\n#         dict = {\n#             'a': 3,\n#             'b': {\n#                 'c': 3,\n#                 'd': {\n#                     'e': 6,\n#                     'f': 5,\n#                 },\n#                 'z': 4,\n#             }\n#         }\n#         flat = flatten_dict(dict)\n#         assert flat['a'] == 3\n#         assert flat['b/c'] == 3\n#         assert flat['b/d/e'] == 6\n#         assert flat['b/d/f'] == 5\n#         assert flat['b/z'] == 4\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/base/test_network.py\n# --------------------------------------------------\n# \n#             _http_engine_class = get_http_engine_class(\n#                 headers={'Token': lambda: _token},\n#                 data_processor=(lambda d: {\n#                     'data': json.dumps(d)\n#                 }),\n#                 http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n#             )()\n#             engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n# \n#             response = engine.request('GET', '200', {'a': 'skdjgflksdj'})\n#             assert response.status_code == 200\n#             assert json.loads(response.content.decode()) == {\"success\": True}\n#             assert response.request.headers['Token'] == '233'\n#             assert json.loads(response.request.body) == {'data': json.dumps({'a': 'skdjgflksdj'})}\n# \n#             with pytest.raises(RuntimeError) as ei:\n#                 engine.request('GET', '404', {'a': 'skdjgflksdj'})\n# \n#             err = ei.value\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/base/test_network.py\n# --------------------------------------------------\n#             _http_engine_class = get_http_engine_class(\n#                 headers={'Token': lambda: _token},\n#                 data_processor=(lambda d: {\n#                     'data': json.dumps(d)\n#                 }),\n#                 http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n#             )()\n#             engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n# \n#             response = engine.request('GET', '200', {'a': 'skdjgflksdj'})\n#             assert response.status_code == 200\n#             assert json.loads(response.content.decode()) == {\"success\": True}\n#             assert response.request.headers['Token'] == '233'\n#             assert json.loads(response.request.body) == {'data': json.dumps({'a': 'skdjgflksdj'})}\n# \n#             with pytest.raises(RuntimeError) as ei:\n#                 engine.request('GET', '404', {'a': 'skdjgflksdj'})\n# \n#             err = ei.value\n#             assert 'This is 404' in str(err)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/base/test_network.py\n# --------------------------------------------------\n#                 engine.request('GET', '404')\n# \n#             err = ei.value\n#             assert err.response.status_code == 404\n#             assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n# \n#     @responses.activate\n#     def test_get_http_engine_class(self):\n#         with self.__yield_http_engine():\n#             _token = '233'\n# \n#             _http_engine_class = get_http_engine_class(\n#                 headers={'Token': lambda: _token},\n#                 data_processor=(lambda d: {\n#                     'data': json.dumps(d)\n#                 }),\n#                 http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n#             )()\n#             engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport json\n\nimport pytest\nfrom flask import Flask\n\nfrom ...base import success_response, failure_response, get_values_from_response, ResponsibleException, responsible\n\n\n@pytest.mark.unittest\nclass TestInteractionBaseApp:\n\n    def test_success_response(self):\n        app = Flask('_test_success_response')\n\n        @app.route('/success', methods=['GET'])\n        def success_method():\n            return success_response(\n                data={\n                    'a': 1,\n                    'b': 2,\n                    'sum': 3,\n                },\n                message='This is success message.',\n            )\n\n        client = app.test_client()\n\n        response = client.get('/success')\n        assert response.status_code == 200\n        assert json.loads(response.data.decode()) == {\n            'success': True,\n            'code': 0,\n            'data': {\n                'a': 1,\n                'b': 2,\n                'sum': 3,\n            },\n            'message': 'This is success message.',\n        }\n\n    # noinspection DuplicatedCode\n    def test_failure_response(self):\n        app = Flask('_test_failure_response')\n\n        @app.route('/fail', methods=['GET'])\n        def fail_method():\n            return failure_response(\n                code=233,\n                message='This is failure message.',\n                data={\n                    'a': 2,\n                    'b': 3,\n                    'sum': 5,\n                },\n            ), 404\n\n        client = app.test_client()\n\n        response = client.get('/fail')\n        assert response.status_code == 404\n        assert json.loads(response.data.decode()) == {\n            'success': False,\n            'code': 233,\n            'data': {\n                'a': 2,\n                'b': 3,\n                'sum': 5,\n            },\n            'message': 'This is failure message.',\n        }\n\n    def test_get_values_from_response(self):\n        app = Flask('_test_get_values_from_response')\n\n        @app.route('/success', methods=['GET'])\n        def success_method():\n            return success_response(\n                data={\n                    'a': 1,\n                    'b': 2,\n                    'sum': 3,\n                },\n                message='This is success message.',\n            )\n\n        @app.route('/fail', methods=['GET'])\n        def fail_method():\n            return failure_response(\n                code=233,\n                message='This is failure message.',\n                data={\n                    'a': 2,\n                    'b': 3,\n                    'sum': 5,\n                },\n            ), 404\n\n        client = app.test_client()\n\n        response = client.get('/success')\n        assert response.status_code == 200\n        assert get_values_from_response(response) == (\n            200,\n            True,\n            0,\n            'This is success message.',", "choices": [{"text": "{"}], "metadata": {"task_id": "opendilab_ACE/155", "ground_truth": "            {", "fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_app.py"], "context_start_lineno": 0, "line_no": 106, "query_window": {"context": "        def fail_method():\n            return failure_response(\n                code=233,\n                message='This is failure message.',\n                data={\n                    'a': 2,\n                    'b': 3,\n                    'sum': 5,\n                },\n            ), 404\n\n        client = app.test_client()\n\n        response = client.get('/success')\n        assert response.status_code == 200\n        assert get_values_from_response(response) == (\n            200,\n            True,\n            0,\n            'This is success message.',", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_app.py"], "line_no": 106, "task_id": "opendilab_ACE/155", "start_line_no": 86, "end_line_no": 106, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "\n    @responses.activate\n    def test_http_engine_with_path(self):\n        with self.__yield_http_engine():\n            engine = HttpEngine(host='example.com', port=7777, path='/this/is')\n            response = engine.request('GET', '200')\n            assert response.status_code == 200\n            assert json.loads(response.content.decode()) == {\"success\": True}\n\n            with pytest.raises(HTTPError) as ei:\n                engine.request('GET', '404')\n\n            err = ei.value\n            assert err.response.status_code == 404\n            assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n\n    @responses.activate\n    def test_get_http_engine_class(self):\n        with self.__yield_http_engine():\n            _token = '233'", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_network.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2619047619047619}, {"context": "\n            _http_engine_class = get_http_engine_class(\n                headers={'Token': lambda: _token},\n                data_processor=(lambda d: {\n                    'data': json.dumps(d)\n                }),\n                http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n            )()\n            engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n\n            response = engine.request('GET', '200', {'a': 'skdjgflksdj'})\n            assert response.status_code == 200\n            assert json.loads(response.content.decode()) == {\"success\": True}\n            assert response.request.headers['Token'] == '233'\n            assert json.loads(response.request.body) == {'data': json.dumps({'a': 'skdjgflksdj'})}\n\n            with pytest.raises(RuntimeError) as ei:\n                engine.request('GET', '404', {'a': 'skdjgflksdj'})\n\n            err = ei.value", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_network.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2608695652173913}, {"context": "                engine.request('GET', '404')\n\n            err = ei.value\n            assert err.response.status_code == 404\n            assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n\n    @responses.activate\n    def test_get_http_engine_class(self):\n        with self.__yield_http_engine():\n            _token = '233'\n\n            _http_engine_class = get_http_engine_class(\n                headers={'Token': lambda: _token},\n                data_processor=(lambda d: {\n                    'data': json.dumps(d)\n                }),\n                http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n            )()\n            engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_network.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.25735294117647056}, {"context": "            'b': {\n                'c': 3,\n                'd': {\n                    'e': 6,\n                    'f': 5,\n                },\n                'z': 4,\n            }\n        }\n        flat = flatten_dict(dict)\n        assert flat['a'] == 3\n        assert flat['b/c'] == 3\n        assert flat['b/d/e'] == 6\n        assert flat['b/d/f'] == 5\n        assert flat['b/z'] == 4", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "tests", "test_default_helper.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 215, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2564102564102564}, {"context": "            response = engine.request('GET', '/this/is/200')\n            assert response.status_code == 200\n            assert json.loads(response.content.decode()) == {\"success\": True}\n\n            with pytest.raises(HTTPError) as ei:\n                engine.request('GET', '/this/is/404')\n\n            err = ei.value\n            assert err.response.status_code == 404\n            assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n\n    @responses.activate\n    def test_http_engine_with_path(self):\n        with self.__yield_http_engine():\n            engine = HttpEngine(host='example.com', port=7777, path='/this/is')\n            response = engine.request('GET', '200')\n            assert response.status_code == 200\n            assert json.loads(response.content.decode()) == {\"success\": True}\n\n            with pytest.raises(HTTPError) as ei:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_network.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.25}, {"context": "            _loader({'a': 0, 'b': -1})\n        with pytest.raises(ValueError):\n            _loader({'a': 1, 'b': 2})\n\n    def test_mcmp_invalid(self):\n        with pytest.raises(ValueError):\n            mcmp(1, '>', item('a'), '<=', item('b'), '==')\n        with pytest.raises(KeyError):\n            mcmp(1, '>', item('a'), '*=', item('b'))\n\n    def test_is_positive(self):\n        _loader = is_positive()\n        assert _loader(1) == 1\n        with pytest.raises(ValueError):\n            _loader(0)\n        with pytest.raises(ValueError):\n            _loader(-1)\n\n    def test_is_negative(self):\n        _loader = is_negative()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "tests", "loader", "test_number.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.25}, {"context": "        self.__status_code, self.__success, self.__code, self.__message, self.__data = \\\n            get_values_from_response(error.response)\n        Exception.__init__(self, self.__message)\n\n    @property\n    def status_code(self) -> int:\n        \"\"\"\n        Overview:\n            Get http status code of response\n        Returns:\n            - status_code (:obj:`int`): Http status code\n        \"\"\"\n        return self.__status_code\n\n    @property\n    def success(self) -> bool:\n        return self.__success\n\n    @property\n    def code(self) -> int:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "exception", "base.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.24731182795698925}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler_flax.py\n# --------------------------------------------------\n# \n#         num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n# \n#         for scheduler_class in self.scheduler_classes:\n#             sample, key = self.dummy_sample\n#             residual = 0.1 * sample\n# \n#             scheduler_config = self.get_scheduler_config()\n#             scheduler = scheduler_class(**scheduler_config)\n#             state = scheduler.create_state()\n# \n#             with tempfile.TemporaryDirectory() as tmpdirname:\n#                 scheduler.save_config(tmpdirname)\n#                 new_scheduler, new_state = scheduler_class.from_pretrained(tmpdirname)\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 state = scheduler.set_timesteps(state, num_inference_steps)\n#                 new_state = new_scheduler.set_timesteps(new_state, num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_pipelines_common.py\n# --------------------------------------------------\n#             if param == \"kwargs\":\n#                 # kwargs can be added if arguments of pipeline call function are deprecated\n#                 continue\n#             assert param in self.allowed_required_args\n# \n#         optional_parameters = set({k for k, v in parameters.items() if v.default != inspect._empty})\n# \n#         for param in self.required_optional_params:\n#             assert param in optional_parameters\n# \n#     def test_inference_batch_consistent(self):\n#         self._test_inference_batch_consistent()\n# \n#     def _test_inference_batch_consistent(self, batch_sizes=[2, 4, 13]):\n#         components = self.get_dummy_components()\n#         pipe = self.pipeline_class(**components)\n#         pipe.to(torch_device)\n#         pipe.set_progress_bar_config(disable=None)\n# \n#         inputs = self.get_dummy_inputs(torch_device)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/configuration_utils.py\n# --------------------------------------------------\n#     def _get_init_keys(cls):\n#         return set(dict(inspect.signature(cls.__init__).parameters).keys())\n# \n#     @classmethod\n#     def extract_init_dict(cls, config_dict, **kwargs):\n#         # 0. Copy origin config dict\n#         original_dict = {k: v for k, v in config_dict.items()}\n# \n#         # 1. Retrieve expected config attributes from __init__ signature\n#         expected_keys = cls._get_init_keys(cls)\n#         expected_keys.remove(\"self\")\n#         # remove general kwargs if present in dict\n#         if \"kwargs\" in expected_keys:\n#             expected_keys.remove(\"kwargs\")\n#         # remove flax internal keys\n#         if hasattr(cls, \"_flax_internal_args\"):\n#             for arg in cls._flax_internal_args:\n#                 expected_keys.remove(arg)\n# \n#         # 2. Remove attributes that cannot be expected from expected config attributes\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/configuration_utils.py\n# --------------------------------------------------\n#         orig_cls_name = config_dict.pop(\"_class_name\", cls.__name__)\n#         if orig_cls_name != cls.__name__ and hasattr(diffusers_library, orig_cls_name):\n#             orig_cls = getattr(diffusers_library, orig_cls_name)\n#             unexpected_keys_from_orig = cls._get_init_keys(orig_cls) - expected_keys\n#             config_dict = {k: v for k, v in config_dict.items() if k not in unexpected_keys_from_orig}\n# \n#         # remove private attributes\n#         config_dict = {k: v for k, v in config_dict.items() if not k.startswith(\"_\")}\n# \n#         # 3. Create keyword arguments that will be passed to __init__ from expected keyword arguments\n#         init_dict = {}\n#         for key in expected_keys:\n#             # if config param is passed to kwarg and is present in config dict\n#             # it should overwrite existing config dict key\n#             if key in kwargs and key in config_dict:\n#                 config_dict[key] = kwargs.pop(key)\n# \n#             if key in kwargs:\n#                 # overwrite key\n#                 init_dict[key] = kwargs.pop(key)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/configuration_utils.py\n# --------------------------------------------------\n#         expected_keys.remove(\"self\")\n#         # remove general kwargs if present in dict\n#         if \"kwargs\" in expected_keys:\n#             expected_keys.remove(\"kwargs\")\n#         # remove flax internal keys\n#         if hasattr(cls, \"_flax_internal_args\"):\n#             for arg in cls._flax_internal_args:\n#                 expected_keys.remove(arg)\n# \n#         # 2. Remove attributes that cannot be expected from expected config attributes\n#         # remove keys to be ignored\n#         if len(cls.ignore_for_config) > 0:\n#             expected_keys = expected_keys - set(cls.ignore_for_config)\n# \n#         # load diffusers library to import compatible and original scheduler\n#         diffusers_library = importlib.import_module(__name__.split(\".\")[0])\n# \n#         if cls.has_compatibles:\n#             compatible_classes = [c for c in cls._get_compatibles() if not isinstance(c, DummyObject)]\n#         else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/pipeline_utils.py\n# --------------------------------------------------\n#             if name in self._optional_components and value[0] is None:\n#                 return False\n#             return True\n# \n#         model_index_dict = {k: v for k, v in model_index_dict.items() if is_saveable_module(k, v)}\n# \n#         for pipeline_component_name in model_index_dict.keys():\n#             sub_model = getattr(self, pipeline_component_name)\n#             model_cls = sub_model.__class__\n# \n#             save_method_name = None\n#             # search for the model's base class in LOADABLE_CLASSES\n#             for library_name, library_classes in LOADABLE_CLASSES.items():\n#                 library = importlib.import_module(library_name)\n#                 for base_class, save_load_methods in library_classes.items():\n#                     class_candidate = getattr(library, base_class, None)\n#                     if class_candidate is not None and issubclass(model_cls, class_candidate):\n#                         # if we found a suitable base class in LOADABLE_CLASSES then grab its save method\n#                         save_method_name = save_load_methods[0]\n#                         break\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n = 0.1 * sample\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n                new_scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            # Set the seed before step() as some schedulers are stochastic like EulerAncestralDiscreteScheduler, EulerDiscreteScheduler\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            output = scheduler.step(residual, time_step, sample, **kwargs).prev_sample\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            new_output = new_scheduler.step(residual, time_step, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def check_over_forward(self, time_step=0, **forward_kwargs):\n        kwargs = dict(self.forward_default_kwargs)\n        kwargs.update(forward_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            if scheduler_class in (EulerAncestralDiscreteScheduler, EulerDiscreteScheduler, LMSDiscreteScheduler):\n                time_step = float(time_step)\n\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            if scheduler_class == VQDiffusionScheduler:\n                num_vec_classes = scheduler_config[\"num_vec_classes\"]\n                sample = self.dummy_sample(num_vec_classes)\n                model = self.dummy_model(num_vec_classes)\n                residual = model(sample, time_step)\n            else:\n                sample = self.dummy_sample\n                residual = 0.1 * sample\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n                new_scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            output = scheduler.step(residual, time_step, sample, **kwargs).prev_sample\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            new_output = new_scheduler.step(residual, time_step, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def test_from_save_pretrained(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            timestep = 1\n            if scheduler_class in (EulerAncestralDiscreteScheduler, EulerDiscreteScheduler, LMSDiscreteScheduler):\n                timestep = float(timestep)\n\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            if scheduler_class == VQDiffusionScheduler:\n                num_vec_classes = scheduler_config[\"num_vec_classes\"]\n                sample = self.dummy_sample(num_vec_classes)\n                model = self.dummy_model(num_vec_classes)\n                residual = model(sample, timestep)\n            else:\n                sample = self.dummy_sample\n                residual = 0.1 * sample\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n                new_scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            output = scheduler.step(residual, timestep, sample, **kwargs).prev_sample\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            new_output = new_scheduler.step(residual, timestep, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def test_compatibles(self):\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n\n            scheduler = scheduler_class(**scheduler_config)\n\n            assert all(c is not None for c in scheduler.compatibles)\n\n            for comp_scheduler_cls in scheduler.compatibles:\n                comp_scheduler = comp_scheduler_cls.from_config(scheduler.config)\n                assert comp_scheduler is not None\n\n            new_scheduler = scheduler_class.from_config(comp_scheduler.config)\n\n            new_scheduler_config = {k: v for k, v in new_scheduler.config.items() if k in scheduler.config}\n            scheduler_diff = {k: v for k, v in new_scheduler.config.items() if k not in scheduler.config}\n\n            # make sure that configs are essentially identical\n            assert new_scheduler_config == dict(scheduler.config)\n\n            # make sure that only differences are for configs that are not in init\n            init_keys = inspect.signature(scheduler_class.__init__).parameters.keys()\n            assert set(scheduler_diff.keys()).intersection(set(init_keys)) == set()\n\n    def test_from_pretrained(self):\n        for scheduler_class in self.scheduler_classes:", "choices": [{"text": "scheduler_config = self.get_scheduler_config()"}], "metadata": {"task_id": "huggingface_diffusers/56", "ground_truth": "            scheduler_config = self.get_scheduler_config()", "fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "context_start_lineno": 276, "line_no": 409, "query_window": {"context": "            assert all(c is not None for c in scheduler.compatibles)\n\n            for comp_scheduler_cls in scheduler.compatibles:\n                comp_scheduler = comp_scheduler_cls.from_config(scheduler.config)\n                assert comp_scheduler is not None\n\n            new_scheduler = scheduler_class.from_config(comp_scheduler.config)\n\n            new_scheduler_config = {k: v for k, v in new_scheduler.config.items() if k in scheduler.config}\n            scheduler_diff = {k: v for k, v in new_scheduler.config.items() if k not in scheduler.config}\n\n            # make sure that configs are essentially identical\n            assert new_scheduler_config == dict(scheduler.config)\n\n            # make sure that only differences are for configs that are not in init\n            init_keys = inspect.signature(scheduler_class.__init__).parameters.keys()\n            assert set(scheduler_diff.keys()).intersection(set(init_keys)) == set()\n\n    def test_from_pretrained(self):\n        for scheduler_class in self.scheduler_classes:", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 409, "task_id": "huggingface_diffusers/56", "start_line_no": 389, "end_line_no": 409, "window_size": 20, "context_start_lineno": 276, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        model_index_dict = dict(self.config)\n        model_index_dict.pop(\"_class_name\")\n        model_index_dict.pop(\"_diffusers_version\")\n        model_index_dict.pop(\"_module\", None)\n\n        expected_modules, optional_kwargs = self._get_signature_keys(self)\n\n        def is_saveable_module(name, value):\n            if name not in expected_modules:\n                return False\n            if name in self._optional_components and value[0] is None:\n                return False\n            return True\n\n        model_index_dict = {k: v for k, v in model_index_dict.items() if is_saveable_module(k, v)}\n\n        for pipeline_component_name in model_index_dict.keys():\n            sub_model = getattr(self, pipeline_component_name)\n            model_cls = sub_model.__class__\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "pipeline_utils.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3277310924369748}, {"context": "    def _get_init_keys(cls):\n        return set(dict(inspect.signature(cls.__init__).parameters).keys())\n\n    @classmethod\n    def extract_init_dict(cls, config_dict, **kwargs):\n        # 0. Copy origin config dict\n        original_dict = {k: v for k, v in config_dict.items()}\n\n        # 1. Retrieve expected config attributes from __init__ signature\n        expected_keys = cls._get_init_keys(cls)\n        expected_keys.remove(\"self\")\n        # remove general kwargs if present in dict\n        if \"kwargs\" in expected_keys:\n            expected_keys.remove(\"kwargs\")\n        # remove flax internal keys\n        if hasattr(cls, \"_flax_internal_args\"):\n            for arg in cls._flax_internal_args:\n                expected_keys.remove(arg)\n\n        # 2. Remove attributes that cannot be expected from expected config attributes", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "configuration_utils.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.32061068702290074}, {"context": "            compatible_classes = []\n\n        expected_keys_comp_cls = set()\n        for c in compatible_classes:\n            expected_keys_c = cls._get_init_keys(c)\n            expected_keys_comp_cls = expected_keys_comp_cls.union(expected_keys_c)\n        expected_keys_comp_cls = expected_keys_comp_cls - cls._get_init_keys(cls)\n        config_dict = {k: v for k, v in config_dict.items() if k not in expected_keys_comp_cls}\n\n        # remove attributes from orig class that cannot be expected\n        orig_cls_name = config_dict.pop(\"_class_name\", cls.__name__)\n        if orig_cls_name != cls.__name__ and hasattr(diffusers_library, orig_cls_name):\n            orig_cls = getattr(diffusers_library, orig_cls_name)\n            unexpected_keys_from_orig = cls._get_init_keys(orig_cls) - expected_keys\n            config_dict = {k: v for k, v in config_dict.items() if k not in unexpected_keys_from_orig}\n\n        # remove private attributes\n        config_dict = {k: v for k, v in config_dict.items() if not k.startswith(\"_\")}\n\n        # 3. Create keyword arguments that will be passed to __init__ from expected keyword arguments", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "configuration_utils.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3170731707317073}, {"context": "            config_dict = cls._dict_from_json_file(config_file)\n        except (json.JSONDecodeError, UnicodeDecodeError):\n            raise EnvironmentError(f\"It looks like the config file at '{config_file}' is not a valid JSON file.\")\n\n        if return_unused_kwargs:\n            return config_dict, kwargs\n\n        return config_dict\n\n    @staticmethod\n    def _get_init_keys(cls):\n        return set(dict(inspect.signature(cls.__init__).parameters).keys())\n\n    @classmethod\n    def extract_init_dict(cls, config_dict, **kwargs):\n        # 0. Copy origin config dict\n        original_dict = {k: v for k, v in config_dict.items()}\n\n        # 1. Retrieve expected config attributes from __init__ signature\n        expected_keys = cls._get_init_keys(cls)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "configuration_utils.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.31386861313868614}, {"context": "\n    def test_pipeline_call_implements_required_args(self):\n        assert hasattr(self.pipeline_class, \"__call__\"), f\"{self.pipeline_class} should have a `__call__` method\"\n        parameters = inspect.signature(self.pipeline_class.__call__).parameters\n        required_parameters = {k: v for k, v in parameters.items() if v.default == inspect._empty}\n        required_parameters.pop(\"self\")\n        required_parameters = set(required_parameters)\n        optional_parameters = set({k for k, v in parameters.items() if v.default != inspect._empty})\n\n        for param in required_parameters:\n            if param == \"kwargs\":\n                # kwargs can be added if arguments of pipeline call function are deprecated\n                continue\n            assert param in self.allowed_required_args\n\n        optional_parameters = set({k for k, v in parameters.items() if v.default != inspect._empty})\n\n        for param in self.required_optional_params:\n            assert param in optional_parameters\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_pipelines_common.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.31297709923664124}, {"context": "            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output = scheduler.step(state, residual, time_step, sample, key, **kwargs).prev_sample\n            new_output = new_scheduler.step(new_state, residual, time_step, sample, key, **kwargs).prev_sample\n\n            assert jnp.sum(jnp.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def test_from_save_pretrained(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            sample, key = self.dummy_sample\n            residual = 0.1 * sample\n\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3049645390070922}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# from __future__ import annotations\n# \n# import collections\n# import os\n# from typing import Any, Dict, Optional, Tuple, Union\n# \n# import numpy as np\n# import torch\n# \n# from torchrl.data import (\n#     BoundedTensorSpec,\n#     CompositeSpec,\n#     TensorSpec,\n#     UnboundedContinuousTensorSpec,\n#     UnboundedDiscreteTensorSpec,\n# )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# import argparse\n# import os\n# import tempfile\n# from argparse import Namespace\n# from collections import OrderedDict\n# from os import path, walk\n# from time import sleep\n# \n# import pytest\n# import torch\n# from torch import nn\n# \n# try:\n#     from tensorboard.backend.event_processing import event_accumulator\n#     from torchrl.record.loggers import TensorboardLogger\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# from __future__ import annotations\n# \n# import os\n# from collections import OrderedDict\n# from copy import deepcopy\n# from multiprocessing import connection\n# from multiprocessing.synchronize import Lock as MpLock\n# from time import sleep\n# from typing import Any, Callable, Dict, List, Optional, Sequence, Union\n# from warnings import warn\n# \n# import torch\n# from tensordict import TensorDict\n# from tensordict.tensordict import LazyStackedTensorDict, TensorDictBase\n# from torch import multiprocessing as mp\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import abc\n# import os\n# from collections import OrderedDict\n# from copy import copy\n# from typing import Any, Dict, Sequence, Union\n# \n# import torch\n# from tensordict.memmap import MemmapTensor\n# from tensordict.prototype import is_tensorclass\n# from tensordict.tensordict import TensorDict, TensorDictBase\n# \n# from torchrl._utils import _CKPT_BACKEND\n# from torchrl.data.replay_buffers.utils import INT_CLASSES\n# \n# try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import argparse\n# import os.path\n# from collections import defaultdict\n# \n# import numpy as np\n# import pytest\n# import torch\n# import yaml\n# from _utils_internal import (\n#     CARTPOLE_VERSIONED,\n#     get_available_devices,\n#     HALFCHEETAH_VERSIONED,\n#     PENDULUM_VERSIONED,\n#     PONG_VERSIONED,\n# )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/record/loggers/csv.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# import os\n# from collections import defaultdict\n# from pathlib import Path\n# from typing import Optional\n# \n# import torch\n# from torch import Tensor\n# \n# from .common import Logger\n# \n# \n# class CSVExperiment:\n#     \"\"\"A CSV logger experiment class.\"\"\"\n# \n#     def __init__(self, log_dir: str):\n#         self.scalars = defaultdict(lambda: [])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/_utils_internal.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import time\n# from functools import wraps\n# \n# # Get relative file path\n# # this returns relative path from current file.\n# import pytest\n# import torch.cuda\n# from torchrl._utils import implement_for, seed_generator\n# from torchrl.envs.libs.gym import _has_gym\n# \n# # Specified for test_utils.py\n# __version__ = \"0.3\"\n# \n# # Default versions of the environments.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_td_distributed.py\n# examples/torchrl_features/memmap_speed_distributed.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import time\n# \n# import configargparse\n# import torch\n# import torch.distributed.rpc as rpc\n# from tensordict import TensorDict\n# from tensordict.memmap import set_transfer_ownership\n# \n# parser = configargparse.ArgumentParser()\n# parser.add_argument(\"--world_size\", default=2, type=int)\n# parser.add_argument(\"--rank\", default=-1, type=int)\n# parser.add_argument(\"--task\", default=1, type=int)\n# parser.add_argument(\"--rank_var\", default=\"SLURM_JOB_ID\", type=str)\n# parser.add_argument(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb_distributed.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import sys\n# import time\n# \n# import pytest\n# import torch\n# import torch.distributed.rpc as rpc\n# import torch.multiprocessing as mp\n# from tensordict.tensordict import TensorDict\n# from torchrl.data.replay_buffers import RemoteTensorDictReplayBuffer\n# from torchrl.data.replay_buffers.samplers import RandomSampler\n# from torchrl.data.replay_buffers.storages import LazyMemmapStorage\n# from torchrl.data.replay_buffers.writers import RoundRobinWriter\n# \n# RETRY_COUNT = 3\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport collections\nimport math\nimport os\nimport time", "choices": [{"text": "import torch.nanquantile as nq"}], "metadata": {"task_id": "pytorch_rl/45", "ground_truth": "from functools import wraps", "fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "context_start_lineno": 0, "line_no": 4, "query_window": {"context": "import collections\nimport math\nimport os\nimport time", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "line_no": 4, "task_id": "pytorch_rl/45", "start_line_no": 0, "end_line_no": 4, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport sys\nimport time\n\nimport pytest", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.0975609756097561}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport time\n\nimport configargparse\nimport torch", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_td_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}, {"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_speed_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.09523809523809523}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport time\nfrom functools import wraps\n\n# Get relative file path", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "_utils_internal.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.0851063829787234}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport os\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import Optional\n\nimport torch", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "record", "loggers", "csv.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.08333333333333333}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport argparse\nimport os.path\nfrom collections import defaultdict\n\nimport numpy as np", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.08163265306122448}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport abc\nimport os\nfrom collections import OrderedDict\nfrom copy import copy\nfrom typing import Any, Dict, Sequence, Union", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.0784313725490196}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import OrderedDict\nfrom copy import deepcopy", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.0784313725490196}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport argparse\nimport os\nimport tempfile\nfrom argparse import Namespace\nfrom collections import OrderedDict\nfrom os import path, walk", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.07692307692307693}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nfrom __future__ import annotations\n\nimport collections\nimport os\nfrom typing import Any, Dict, Optional, Tuple, Union\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.07692307692307693}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/c51.py\n# --------------------------------------------------\n#         with torch.no_grad():\n#             output = self._collect_model.forward(data, eps=eps)\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n#         r\"\"\"\n#         Overview:\n#             Get the trajectory and the n step return data, then sample from the n_step return data\n#         Arguments:\n#             - data (:obj:`list`): The trajectory's cache\n#         Returns:\n#             - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/cql.py\n# --------------------------------------------------\n#         with torch.no_grad():\n#             output = self._collect_model.forward(data, eps=eps)\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n#         r\"\"\"\n#             Overview:\n#                 Get the trajectory and the n step return data, then sample from the n_step return data\n#             Arguments:\n#                 - data (:obj:`list`): The trajectory's cache\n#             Returns:\n#                 - samples (:obj:`dict`): The training samples generated\n#             \"\"\"\n#         data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/acer.py\n# --------------------------------------------------\n#             output = self._collect_model.forward(data, mode='compute_actor')\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         output = {i: d for i, d in zip(data_id, output)}\n#         return output\n# \n#     def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n#         r\"\"\"\n#         Overview:\n#             For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n#             can be used for training directly.\n#         Arguments:\n#             - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n#                 format as the return value of ``self._process_transition`` method.\n#         Returns:\n#             - samples (:obj:`dict`): List of training samples.\n#         .. note::\n#             We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n#             And the user can customize the this data processing procedure by overriding this two methods and collector \\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/impala.py\n# --------------------------------------------------\n#         return output\n# \n#     def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n#         r\"\"\"\n#         Overview:\n#             For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n#             can be used for training directly.\n#         Arguments:\n#             - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n#                 format as the return value of ``self._process_transition`` method.\n#         Returns:\n#             - samples (:obj:`dict`): List of training samples.\n#         .. note::\n#             We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n#             And the user can customize the this data processing procedure by overriding this two methods and collector \\\n#             itself.\n#         \"\"\"\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def _process_transition(self, obs: Any, policy_output: Dict[str, Any], timestep: namedtuple) -> Dict[str, Any]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/sql.py\n# --------------------------------------------------\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n#         \"\"\"\n#         Overview:\n#             For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n#             can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\\n#             or some continuous transitions(DRQN).\n#         Arguments:\n#             - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n#                 format as the return value of ``self._process_transition`` method.\n#         Returns:\n#             - samples (:obj:`dict`): The list of training samples.\n# \n#         .. note::\n#             We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n#             And the user can customize the this data processing procecure by overriding this two methods and collector \\\n#             itself.\n#         \"\"\"\n#         data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/dqn.py\n# --------------------------------------------------\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n#         \"\"\"\n#         Overview:\n#             For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n#             can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\\n#             or some continuous transitions(DRQN).\n#         Arguments:\n#             - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n#                 format as the return value of ``self._process_transition`` method.\n#         Returns:\n#             - samples (:obj:`dict`): The list of training samples.\n# \n#         .. note::\n#             We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n#             And the user can customize the this data processing procecure by overriding this two methods and collector \\\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n # [batch, agent, state_len - 25 - 1 - unit_type_bits]]\n            global_ally_label = (ally * local_label).sum(1) # [batch, state_len - 25 - 1 - unit_type_bits]\n            global_enemy_label = ((1 - ally) * local_label).sum(1) # [batch, state_len - 25 - 1 - unit_type_bits]\n            global_label = torch.cat([global_ally_label, global_enemy_label], dim=1)\n            if self._cfg.learn.get('aux_label_norm', False):\n                local_label = local_label/(local_label.abs().max(dim=1).values.unsqueeze(1)+1e-9)\n                global_label = global_label/(global_label.abs().max(dim=1).values.unsqueeze(1)+1e-9)\n            if self._cfg.learn.get('aux_class_balance', False):\n                local_loss = l2_balance(local_label, (local_label - local_pred).pow(2))\n            else:\n                local_loss = (local_label - local_pred).pow(2).mean()\n            global_loss = (global_label - global_pred).pow(2).mean()\n            aux_loss = local_loss + global_loss\n        elif self.cfg.learn.env == 'grf':\n            state, next_state = obs['states'][:, :, 4:11], next_obs['states'][:, :, 4:11]  # [batch, agent, state_len - 25]\n            local_pred, global_pred = aux_pred['local_pred'], aux_pred['global_pred']\n            ally = state[:, :, :1]  # [batch, agent, 1]\n            local_label = (next_state - state)  # [batch, agent, state_len - 25 - 1 - unit_type_bits]]\n            if self._cfg.learn.get('aux_label_norm', False):\n                local_label = local_label / (local_label.abs().max(dim=1).values.unsqueeze(1) + 1e-9)\n            if self._cfg.learn.get('aux_class_balance', False):\n                local_loss = l2_balance(local_label, (local_label - local_pred).pow(2))\n            else:\n                local_loss = (local_label - local_pred).pow(2).mean()\n            aux_loss = local_loss\n        # update\n        # cosine aux_loss_weight\n        tem = self._aux_loss_weight\n        cur = min(self._forward_learn_cnt/tem.T_max, 1)\n        aux_loss_weight = tem.end + 0.5*(tem.begin - tem.end) * (1 + math.cos(math.pi*cur))\n        loss = rl_loss + aux_loss_weight * aux_loss\n        self._optimizer.zero_grad()\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(self._model.parameters(), self._cfg.learn.clip_value)\n        self._optimizer.step()\n        if self._cfg.learn.learning_rate_type == 'cosine' and self._scheduler.last_epoch < self._scheduler.T_max:\n            self._scheduler.step()\n        # =============\n        # after update\n        # =============\n        self._forward_learn_cnt += 1\n        self._target_model.update(self._learn_model.state_dict())\n        ret = {\n            'lr': self._optimizer.param_groups[0]['lr'],\n            'loss': loss.item(),\n            'q': target_q.mean().item(),\n            'grad_norm': grad_norm,\n            'rl_loss': rl_loss.item(),\n            'aux_loss': aux_loss.item(),\n            'priority': td_error_per_sample.abs().tolist(),\n            'aux_loss_weight': aux_loss_weight,\n        }\n        return ret\n\n    def _state_dict_learn(self) -> Dict[str, Any]:\n        r\"\"\"\n        Overview:\n            Return the state_dict of learn mode, usually including model and optimizer.\n        Returns:\n            - state_dict (:obj:`Dict[str, Any]`): the dict of current policy learn state, for saving and restoring.\n        \"\"\"\n        return {\n            'model': self._learn_model.state_dict(),\n            'target_model': self._target_model.state_dict(),\n            'optimizer': self._optimizer.state_dict(),\n        }\n\n    def _load_state_dict_learn(self, state_dict: Dict[str, Any]) -> None:\n        \"\"\"\n        Overview:\n            Load the state_dict variable into policy learn mode.\n        Arguments:\n            - state_dict (:obj:`Dict[str, Any]`): the dict of policy learn state saved before.\n\n        .. tip::\n            If you want to only load some parts of model, you can simply set the ``strict`` argument in \\\n            load_state_dict to ``False``, or refer to ``ding.torch_utils.checkpoint_helper`` for more \\\n            complicated operation.\n        \"\"\"\n        self._learn_model.load_state_dict(state_dict['model'])\n        self._target_model.load_state_dict(state_dict['target_model'])\n        # self._optimizer.load_state_dict(state_dict['optimizer'])\n\n    def _init_collect(self) -> None:\n        r\"\"\"\n        Overview:\n            Collect mode init method. Called by ``self.__init__``.\n            Init traj and unroll length, collect model.\n            Enable the eps_greedy_sample and the hidden_state plugin.\n        \"\"\"\n        self._unroll_len = self._cfg.collect.unroll_len\n        # self._collect_model = model_wrap(self._model, wrapper_name='eps_greedy_sample')\n        self._collect_model = self._model\n        # self._collect_model.reset()\n\n    def _forward_collect(self, data: dict, eps: float) -> dict:\n        r\"\"\"\n        Overview:\n            Forward function for collect mode with eps_greedy\n        Arguments:\n            - data (:obj:`Dict[str, Any]`): Dict type data, stacked env data for predicting policy_output(action), \\\n                values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.\n            - eps (:obj:`float`): epsilon value for exploration, which is decayed by collected env step.\n        Returns:\n            - output (:obj:`Dict[int, Any]`): Dict type data, including at least inferred action according to input obs.\n        ReturnsKeys\n            - necessary: ``action``\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        if self._cfg.learn.shuffle:\n            action_ind_reverse, ally_ind_reverse = self._collect_shuffle_data(data)\n        self._collect_model.eval()\n        with torch.no_grad():\n            _, action = self._collect_model.forward(data, {'type': 'eps_greedy', 'eps': eps})\n            if self._cfg.learn.shuffle:\n                action = action_ind_reverse.gather(1, action.index_select(1, ally_ind_reverse))\n            output = {'action': action}\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\", "choices": [{"text": "can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\"}], "metadata": {"task_id": "opendilab_ACE/162", "ground_truth": "            can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\", "fpath_tuple": ["opendilab_ACE", "ding", "policy", "ace_dqn.py"], "context_start_lineno": 281, "line_no": 410, "query_window": {"context": "        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        if self._cfg.learn.shuffle:\n            action_ind_reverse, ally_ind_reverse = self._collect_shuffle_data(data)\n        self._collect_model.eval()\n        with torch.no_grad():\n            _, action = self._collect_model.forward(data, {'type': 'eps_greedy', 'eps': eps})\n            if self._cfg.learn.shuffle:\n                action = action_ind_reverse.gather(1, action.index_select(1, ally_ind_reverse))\n            output = {'action': action}\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "ace_dqn.py"], "line_no": 410, "task_id": "opendilab_ACE/162", "start_line_no": 390, "end_line_no": 410, "window_size": 20, "context_start_lineno": 281, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "        ReturnsKeys\n            - necessary: ``logit``, ``action``\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n            can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "dqn.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6642335766423357}, {"context": "        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps, alpha=self._cfg.learn.alpha)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n            can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\\n            or some continuous transitions(DRQN).\n        Arguments:\n            - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "sql.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6013071895424836}, {"context": "        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, mode='compute_actor')\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        output = {i: d for i, d in zip(data_id, output)}\n        return output\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        r\"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n            can be used for training directly.\n        Arguments:\n            - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n                format as the return value of ``self._process_transition`` method.", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "impala.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5838926174496645}, {"context": "            - output (:obj:`Dict[int, Dict[str,Any]]`): Dict of predicting policy_output(logit, action) for each env.\n        ReturnsKeys\n            - necessary: ``logit``, ``action``\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, mode='compute_actor')\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        output = {i: d for i, d in zip(data_id, output)}\n        return output\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        r\"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "acer.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5390070921985816}, {"context": "            Arguments:\n                - data (:obj:`dict`): Dict type data, including at least ['obs'].\n            Returns:\n                - data (:obj:`dict`): The collected data\n            \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n            Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "cql.py"], "line_no": 900, "start_line_no": 890, "end_line_no": 910, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5285714285714286}, {"context": "        Arguments:\n            - data (:obj:`dict`): Dict type data, including at least ['obs'].\n        Returns:\n            - data (:obj:`dict`): The collected data\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "c51.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5214285714285715}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/backdoor_trainer.py\n# --------------------------------------------------\n#                                             insert_pos=0)\n# \n#     return base_trainer\n# \n# \n# def hook_on_fit_start_init_local_opt(ctx):\n# \n#     ctx.original_epoch = ctx[\"num_train_epoch\"]\n#     ctx[\"num_train_epoch\"] = ctx.self_epoch\n# \n# \n# def hook_on_fit_end_reset_opt(ctx):\n# \n#     ctx[\"num_train_epoch\"] = ctx.original_epoch\n# \n# \n# def hook_on_fit_start_init_local_model(ctx):\n# \n#     # the original global model\n#     ctx.original_model = copy.deepcopy(ctx.model)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/backdoor_trainer.py\n# --------------------------------------------------\n#     if scale_poisoning or pgd_poisoning:\n# \n#         base_trainer.register_hook_in_train(\n#             new_hook=hook_on_fit_start_init_local_model,\n#             trigger='on_fit_start',\n#             insert_pos=-1)\n# \n#     if base_trainer.cfg.attack.scale_poisoning:\n# \n#         base_trainer.ctx.scale_para = base_trainer.cfg.attack.scale_para\n# \n#         base_trainer.register_hook_in_train(\n#             new_hook=hook_on_fit_end_scale_poisoning,\n#             trigger=\"on_fit_end\",\n#             insert_pos=-1)\n# \n#     if base_trainer.cfg.attack.pgd_poisoning:\n# \n#         base_trainer.ctx.self_epoch = base_trainer.cfg.attack.self_epoch\n#         base_trainer.ctx.pgd_lr = base_trainer.cfg.attack.pgd_lr\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/GAN_trainer.py\n# --------------------------------------------------\n#         new_hook=hook_on_data_injection_sav_data,\n#         trigger='on_fit_end',\n#         insert_mode=-1)\n# \n#     return base_trainer\n# \n# \n# def hood_on_fit_start_generator(ctx):\n#     '''\n#     count the FL training round before fitting\n#     Args:\n#         ctx ():\n# \n#     Returns:\n# \n#     '''\n#     ctx.gan_cra.round_num += 1\n#     logger.info('----- Round {}: GAN training ............'.format(\n#         ctx.gan_cra.round_num))\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/trainers/trainer_fedprox.py\n# --------------------------------------------------\n#                                         insert_pos=-1)\n# \n#     base_trainer.register_hook_in_eval(new_hook=_hook_del_initialization,\n#                                        trigger='on_fit_end',\n#                                        insert_pos=-1)\n# \n#     return base_trainer\n# \n# \n# def init_fedprox_ctx(base_trainer):\n#     \"\"\"Set proximal regularizer and the factor of regularizer\n# \n#     \"\"\"\n#     ctx = base_trainer.ctx\n#     cfg = base_trainer.cfg\n# \n#     cfg.defrost()\n#     cfg.regularizer.type = 'proximal_regularizer'\n#     cfg.regularizer.mu = cfg.fedprox.mu\n#     cfg.freeze()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/backdoor_trainer.py\n# --------------------------------------------------\n#             trigger='on_batch_end',\n#             insert_pos=-1)\n# \n#         base_trainer.register_hook_in_train(\n#             new_hook=hook_on_epoch_end_project_grad,\n#             trigger='on_epoch_end',\n#             insert_pos=-1)\n# \n#         base_trainer.register_hook_in_train(new_hook=hook_on_fit_end_reset_opt,\n#                                             trigger='on_fit_end',\n#                                             insert_pos=0)\n# \n#     return base_trainer\n# \n# \n# def hook_on_fit_start_init_local_opt(ctx):\n# \n#     ctx.original_epoch = ctx[\"num_train_epoch\"]\n#     ctx[\"num_train_epoch\"] = ctx.self_epoch\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/GAN_trainer.py\n# --------------------------------------------------\n#                                       sav_pth=base_trainer.cfg.outdir)\n# \n#     # ---- action-level plug-in -------\n# \n#     base_trainer.register_hook_in_train(new_hook=hood_on_fit_start_generator,\n#                                         trigger='on_fit_start',\n#                                         insert_mode=-1)\n#     base_trainer.register_hook_in_train(new_hook=hook_on_gan_cra_train,\n#                                         trigger='on_batch_start',\n#                                         insert_mode=-1)\n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_batch_injected_data_generation,\n#         trigger='on_batch_start',\n#         insert_mode=-1)\n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_batch_forward_injected_data,\n#         trigger='on_batch_forward',\n#         insert_mode=-1)\n# \n#     base_trainer.register_hook_in_train(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/GAN_trainer.py\n# --------------------------------------------------\n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_batch_injected_data_generation,\n#         trigger='on_batch_start',\n#         insert_mode=-1)\n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_batch_forward_injected_data,\n#         trigger='on_batch_forward',\n#         insert_mode=-1)\n# \n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_data_injection_sav_data,\n#         trigger='on_fit_end',\n#         insert_mode=-1)\n# \n#     return base_trainer\n# \n# \n# def hood_on_fit_start_generator(ctx):\n#     '''\n#     count the FL training round before fitting\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport logging\nfrom typing import Type\n\nimport torch\n\nfrom federatedscope.core.trainers import GeneralTorchTrainer\nfrom federatedscope.core.data.wrap_dataset import WrapDataset\nfrom federatedscope.attack.auxiliary.MIA_get_target_data import get_target_data\n\nlogger = logging.getLogger(__name__)\n\n\ndef wrap_GradientAscentTrainer(\n        base_trainer: Type[GeneralTorchTrainer]) -> Type[GeneralTorchTrainer]:\n    '''\n    wrap the gradient_invert trainer\n\n    Args:\n        base_trainer: Type: core.trainers.GeneralTorchTrainer\n\n    :returns:\n        The wrapped trainer; Type: core.trainers.GeneralTorchTrainer\n\n    '''\n\n    # base_trainer.ctx.target_data = get_target_data()\n    base_trainer.ctx.target_data_dataloader = WrapDataset(\n        get_target_data(base_trainer.cfg.data.type))\n    base_trainer.ctx.target_data = get_target_data(base_trainer.cfg.data.type)\n\n    base_trainer.ctx.is_target_batch = False\n    base_trainer.ctx.finish_injected = False\n\n    base_trainer.ctx.target_data_loss = []\n\n    base_trainer.ctx.outdir = base_trainer.cfg.outdir\n    base_trainer.ctx.round = -1\n    base_trainer.ctx.inject_round = base_trainer.cfg.attack.inject_round\n    base_trainer.ctx.mia_is_simulate_in = \\\n        base_trainer.cfg.attack.mia_is_simulate_in\n    base_trainer.ctx.mia_simulate_in_round = \\\n        base_trainer.cfg.attack.mia_simulate_in_round\n\n    base_trainer.register_hook_in_train(new_hook=hook_on_fit_start_count_round,\n                                        trigger='on_fit_start',\n                                        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(", "choices": [{"text": "new_hook=hook_on_epoch_end_project_grad,"}], "metadata": {"task_id": "alibaba_FederatedScope/163", "ground_truth": "        new_hook=hook_on_batch_start_replace_data_batch,", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "MIA_invert_gradient_trainer.py"], "context_start_lineno": 0, "line_no": 48, "query_window": {"context": "    base_trainer.ctx.target_data = get_target_data(base_trainer.cfg.data.type)\n\n    base_trainer.ctx.is_target_batch = False\n    base_trainer.ctx.finish_injected = False\n\n    base_trainer.ctx.target_data_loss = []\n\n    base_trainer.ctx.outdir = base_trainer.cfg.outdir\n    base_trainer.ctx.round = -1\n    base_trainer.ctx.inject_round = base_trainer.cfg.attack.inject_round\n    base_trainer.ctx.mia_is_simulate_in = \\\n        base_trainer.cfg.attack.mia_is_simulate_in\n    base_trainer.ctx.mia_simulate_in_round = \\\n        base_trainer.cfg.attack.mia_simulate_in_round\n\n    base_trainer.register_hook_in_train(new_hook=hook_on_fit_start_count_round,\n                                        trigger='on_fit_start',\n                                        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "MIA_invert_gradient_trainer.py"], "line_no": 48, "task_id": "alibaba_FederatedScope/163", "start_line_no": 28, "end_line_no": 48, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "                                      sav_pth=base_trainer.cfg.outdir)\n\n    # ---- action-level plug-in -------\n\n    base_trainer.register_hook_in_train(new_hook=hood_on_fit_start_generator,\n                                        trigger='on_fit_start',\n                                        insert_mode=-1)\n    base_trainer.register_hook_in_train(new_hook=hook_on_gan_cra_train,\n                                        trigger='on_batch_start',\n                                        insert_mode=-1)\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_injected_data_generation,\n        trigger='on_batch_start',\n        insert_mode=-1)\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_forward_injected_data,\n        trigger='on_batch_forward',\n        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "GAN_trainer.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4805194805194805}, {"context": "    '''\n\n    # ---------------- attribute-level plug-in -----------------------\n\n    base_trainer.ctx.target_label_ind = \\\n        base_trainer.cfg.attack.target_label_ind\n    base_trainer.ctx.gan_cra = GANCRA(base_trainer.cfg.attack.target_label_ind,\n                                      base_trainer.ctx.model,\n                                      dataset_name=base_trainer.cfg.data.type,\n                                      device=base_trainer.ctx.device,\n                                      sav_pth=base_trainer.cfg.outdir)\n\n    # ---- action-level plug-in -------\n\n    base_trainer.register_hook_in_train(new_hook=hood_on_fit_start_generator,\n                                        trigger='on_fit_start',\n                                        insert_mode=-1)\n    base_trainer.register_hook_in_train(new_hook=hook_on_gan_cra_train,\n                                        trigger='on_batch_start',\n                                        insert_mode=-1)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "GAN_trainer.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4666666666666667}, {"context": "        base_trainer.ctx.pgd_eps = base_trainer.cfg.attack.pgd_eps\n        base_trainer.ctx.batch_index = 0\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_fit_start_init_local_pgd,\n            trigger='on_fit_start',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_batch_end_project_grad,\n            trigger='on_batch_end',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_epoch_end_project_grad,\n            trigger='on_epoch_end',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(new_hook=hook_on_fit_end_reset_opt,\n                                            trigger='on_fit_end',", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "backdoor_trainer.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.43243243243243246}, {"context": "    base_trainer.register_hook_in_train(new_hook=_hook_record_initialization,\n                                        trigger='on_fit_start',\n                                        insert_pos=-1)\n\n    base_trainer.register_hook_in_eval(new_hook=_hook_record_initialization,\n                                       trigger='on_fit_start',\n                                       insert_pos=-1)\n\n    base_trainer.register_hook_in_train(new_hook=_hook_del_initialization,\n                                        trigger='on_fit_end',\n                                        insert_pos=-1)\n\n    base_trainer.register_hook_in_eval(new_hook=_hook_del_initialization,\n                                       trigger='on_fit_end',\n                                       insert_pos=-1)\n\n    return base_trainer\n\n\ndef init_fedprox_ctx(base_trainer):", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "trainers", "trainer_fedprox.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4166666666666667}, {"context": "    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_injected_data_generation,\n        trigger='on_batch_start',\n        insert_mode=-1)\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_forward_injected_data,\n        trigger='on_batch_forward',\n        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_data_injection_sav_data,\n        trigger='on_fit_end',\n        insert_mode=-1)\n\n    return base_trainer\n\n\ndef hood_on_fit_start_generator(ctx):\n    '''\n    count the FL training round before fitting", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "GAN_trainer.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3974358974358974}, {"context": "            trigger='on_fit_start',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(new_hook=hook_on_fit_end_reset_opt,\n                                            trigger='on_fit_end',\n                                            insert_pos=0)\n\n    scale_poisoning = base_trainer.cfg.attack.scale_poisoning\n    pgd_poisoning = base_trainer.cfg.attack.pgd_poisoning\n\n    if scale_poisoning or pgd_poisoning:\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_fit_start_init_local_model,\n            trigger='on_fit_start',\n            insert_pos=-1)\n\n    if base_trainer.cfg.attack.scale_poisoning:\n\n        base_trainer.ctx.scale_para = base_trainer.cfg.attack.scale_para", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "backdoor_trainer.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3950617283950617}, {"context": "            trigger='on_batch_end',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_epoch_end_project_grad,\n            trigger='on_epoch_end',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(new_hook=hook_on_fit_end_reset_opt,\n                                            trigger='on_fit_end',\n                                            insert_pos=0)\n\n    return base_trainer\n\n\ndef hook_on_fit_start_init_local_opt(ctx):\n\n    ctx.original_epoch = ctx[\"num_train_epoch\"]\n    ctx[\"num_train_epoch\"] = ctx.self_epoch\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "backdoor_trainer.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.38271604938271603}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_collector.py\n# --------------------------------------------------\n# class UnwrappablePolicy(nn.Module):\n#     def __init__(self, out_features: int):\n#         super().__init__()\n#         self.linear = nn.LazyLinear(out_features)\n# \n#     def forward(self, observation, other_stuff):\n#         return self.linear(observation), other_stuff.sum()\n# \n# \n# class ParametricPolicyNet(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.param = torch.nn.Parameter(torch.randn(1, requires_grad=True))\n# \n#     def forward(self, obs):\n#         max_obs = (obs == obs.max(dim=-1, keepdim=True)[0]).cumsum(-1).argmax(-1)\n#         k = obs.shape[-1]\n#         max_obs = (max_obs + 1) % k\n#         action = torch.nn.functional.one_hot(max_obs, k)\n#         return action\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                 self.linear = nn.Linear(hidden_dim + action_dim, 1)\n# \n#             def forward(self, hidden, act):\n#                 return self.linear(torch.cat([hidden, act], -1))\n# \n#         common = SafeModule(CommonClass(), in_keys=[\"observation\"], out_keys=[\"hidden\"])\n#         actor_subnet = ProbabilisticActor(\n#             SafeModule(ActorClass(), in_keys=[\"hidden\"], out_keys=[\"loc\", \"scale\"]),\n#             in_keys=[\"loc\", \"scale\"],\n#             distribution_class=TanhNormal,\n#             return_log_prob=True,\n#         )\n#         qvalue_subnet = ValueOperator(ValueClass(), in_keys=[\"hidden\", \"action\"])\n#         model = ActorCriticOperator(common, actor_subnet, qvalue_subnet)\n#         return model.to(device)\n# \n#     def _create_mock_data_redq(\n#         self, batch=16, obs_dim=3, action_dim=4, atoms=None, device=\"cpu\"\n#     ):\n#         # create a tensordict\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_collector.py\n# --------------------------------------------------\n#         self.out_keys = [\"action\"]\n#         self.linear = nn.LazyLinear(out_features)\n# \n#     def forward(self, tensordict):\n#         return TensorDict(\n#             {self.out_keys[0]: self.linear(tensordict.get(self.in_keys[0]))},\n#             [],\n#         )\n# \n# \n# class UnwrappablePolicy(nn.Module):\n#     def __init__(self, out_features: int):\n#         super().__init__()\n#         self.linear = nn.LazyLinear(out_features)\n# \n#     def forward(self, observation, other_stuff):\n#         return self.linear(observation), other_stuff.sum()\n# \n# \n# class ParametricPolicyNet(nn.Module):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# test/test_cost.py\n# --------------------------------------------------\n#     def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n#         # Actor\n#         class ValueClass(nn.Module):\n#             def __init__(self):\n#                 super().__init__()\n#                 self.linear = nn.Linear(obs_dim + action_dim, 1)\n# \n#             def forward(self, obs, act):\n#                 return self.linear(torch.cat([obs, act], -1))\n# \n#         module = ValueClass()\n#         value = ValueOperator(\n#             module=module,\n#             in_keys=[\"observation\", \"action\"],\n#         )\n#         return value.to(device)\n# \n#     def _create_mock_distributional_actor(\n#         self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n#     ):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# test/test_cost.py\n# --------------------------------------------------\n#         module = ValueClass()\n#         value = ValueOperator(\n#             module=module,\n#             in_keys=[\"observation\", \"action\"],\n#         )\n#         return value.to(device)\n# \n#     def _create_mock_distributional_actor(\n#         self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n#     ):\n#         raise NotImplementedError\n# \n#     def _create_mock_data_ddpg(\n#         self, batch=8, obs_dim=3, action_dim=4, atoms=None, device=\"cpu\"\n#     ):\n#         # create a tensordict\n#         obs = torch.randn(batch, obs_dim, device=device)\n#         next_obs = torch.randn(batch, obs_dim, device=device)\n#         if atoms:\n#             raise NotImplementedError\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n# \n#         module = ValueClass()\n#         qvalue = ValueOperator(\n#             module=module,\n#             in_keys=[\"observation\", \"action\"],\n#         )\n#         return qvalue.to(device)\n# \n#     def _create_shared_mock_actor_qvalue(\n#         self, batch=2, obs_dim=3, action_dim=4, hidden_dim=5, device=\"cpu\"\n#     ):\n#         class CommonClass(nn.Module):\n#             def __init__(self):\n#                 super().__init__()\n#                 self.linear = nn.Linear(obs_dim, hidden_dim)\n# \n#             def forward(self, obs):\n#                 return self.linear(obs)\n# \n#         class ActorClass(nn.Module):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#             in_keys=[\"observation\", \"action\"],\n#         )\n#         return qvalue.to(device)\n# \n#     def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n#         module = nn.Linear(obs_dim, 1)\n#         value = ValueOperator(\n#             module=module,\n#             in_keys=[\"observation\"],\n#         )\n#         return value.to(device)\n# \n#     def _create_mock_distributional_actor(\n#         self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n#     ):\n#         raise NotImplementedError\n# \n#     def _create_mock_data_sac(\n#         self, batch=16, obs_dim=3, action_dim=4, atoms=None, device=\"cpu\"\n#     ):\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n                shape=batch_size,\n            )\n\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            categorical_action_encoding=categorical_action_encoding,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1).unsqueeze(-1)\n        obs = obs.expand(*obs.shape[:-1], 3)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -2, -3)[..., 0, :]\n\n    def _obs_step(self, obs, a):\n        return obs + a.unsqueeze(-1) / self.maxstep\n\n\nclass ContinuousActionConvMockEnv(ContinuousActionVecMockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=True,\n        pixel_shape=None,\n        **kwargs,\n    ):\n        batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n        if pixel_shape is None:\n            pixel_shape = [1, 7, 7]\n        if observation_spec is None:\n            cls.out_key = \"pixels\"\n            observation_spec = CompositeSpec(\n                pixels=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, *pixel_shape])\n                ),\n                pixels_orig=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, *pixel_shape])\n                ),\n                shape=batch_size,\n            )\n\n        if action_spec is None:\n            action_spec = BoundedTensorSpec(-1, 1, [*batch_size, pixel_shape[-1]])\n\n        if reward_spec is None:\n            reward_spec = UnboundedContinuousTensorSpec(shape=(*batch_size, 1))\n        if input_spec is None:\n            cls._out_key = \"pixels_orig\"\n            input_spec = CompositeSpec(\n                **{cls._out_key: observation_spec[\"pixels\"], \"action\": action_spec},\n                shape=batch_size,\n            )\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -1, -2).squeeze()\n\n\nclass ContinuousActionConvMockEnvNumpy(ContinuousActionConvMockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=True,\n        **kwargs,\n    ):\n        batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n        if observation_spec is None:\n            cls.out_key = \"pixels\"\n            observation_spec = CompositeSpec(\n                pixels=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, 7, 7, 3])\n                ),\n                pixels_orig=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, 7, 7, 3])\n                ),\n            )\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1).unsqueeze(-1)\n        obs = obs.expand(*obs.shape[:-1], 3)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -2, -3)[..., 0, :]\n\n    def _obs_step(self, obs, a):\n        return obs + a / self.maxstep\n\n\nclass DiscreteActionConvPolicy(DiscreteActionVecPolicy):\n    in_keys = [\"pixels\"]\n    out_keys = [\"action\"]\n\n    def _get_in_obs(self, tensordict):\n        obs = tensordict.get(*self.in_keys).diagonal(0, -1, -2).squeeze()\n        return obs\n\n\nclass DummyModelBasedEnvBase(ModelBasedEnvBase):\n    \"\"\"Dummy environnement for Model Based RL algorithms.\n\n    This class is meant to be used to test the model based environnement.\n\n    Args:\n        world_model (WorldModel): the world model to use for the environnement.\n        device (str or torch.device, optional): the device to use for the environnement.\n        dtype (torch.dtype, optional): the dtype to use for the environnement.\n        batch_size (sequence of int, optional): the batch size to use for the environnement.\n    \"\"\"\n\n    def __init__(\n        self,\n        world_model,\n        device=\"cpu\",\n        dtype=None,\n        batch_size=None,\n    ):\n        super().__init__(\n            world_model,\n            device=device,\n            dtype=dtype,\n            batch_size=batch_size,\n        )\n        self.observation_spec = CompositeSpec(\n            hidden_observation=UnboundedContinuousTensorSpec(\n                (\n                    *self.batch_size,\n                    4,\n                )\n            ),\n            shape=self.batch_size,\n        )\n        self.input_spec = CompositeSpec(\n            hidden_observation=UnboundedContinuousTensorSpec(\n                (\n                    *self.batch_size,\n                    4,\n                )\n            ),\n            action=UnboundedContinuousTensorSpec(\n                (\n                    *self.batch_size,\n                    1,\n                )\n            ),\n            shape=self.batch_size,\n        )\n        self.reward_spec = UnboundedContinuousTensorSpec(\n            (\n                *self.batch_size,\n                1,\n            )\n        )\n\n    def _reset(self, tensordict: TensorDict, **kwargs) -> TensorDict:\n        td = TensorDict(\n            {\n                \"hidden_observation\": self.input_spec[\"hidden_observation\"].rand(),\n            },\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n        return td\n\n\nclass ActionObsMergeLinear(nn.Module):\n    def __init__(self, in_size, out_size):\n        super().__init__()\n        self.linear = nn.Linear(in_size, out_size)\n\n    def forward(self, observation, action):\n        return self.linear(torch.cat([observation, action], dim=-1))\n\n\nclass CountingEnv(EnvBase):\n    def __init__(self, max_steps: int = 5, **kwargs):\n        super().__init__(**kwargs)\n        self.max_steps = max_steps\n\n        self.observation_spec = CompositeSpec(", "choices": [{"text": "hidden=UnboundedContinuousTensorSpec(shape=(*self.batch_size, 4)),"}], "metadata": {"task_id": "pytorch_rl/13", "ground_truth": "            observation=UnboundedContinuousTensorSpec(", "fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "context_start_lineno": 632, "line_no": 851, "query_window": {"context": "            device=self.device,\n        )\n        return td\n\n\nclass ActionObsMergeLinear(nn.Module):\n    def __init__(self, in_size, out_size):\n        super().__init__()\n        self.linear = nn.Linear(in_size, out_size)\n\n    def forward(self, observation, action):\n        return self.linear(torch.cat([observation, action], dim=-1))\n\n\nclass CountingEnv(EnvBase):\n    def __init__(self, max_steps: int = 5, **kwargs):\n        super().__init__(**kwargs)\n        self.max_steps = max_steps\n\n        self.observation_spec = CompositeSpec(", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 851, "task_id": "pytorch_rl/13", "start_line_no": 831, "end_line_no": 851, "window_size": 20, "context_start_lineno": 632, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n\n        module = ValueClass()\n        qvalue = ValueOperator(\n            module=module,\n            in_keys=[\"observation\", \"action\"],\n        )\n        return qvalue.to(device)\n\n    def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        module = nn.Linear(obs_dim, 1)\n        value = ValueOperator(\n            module=module,\n            in_keys=[\"observation\"],\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 950, "start_line_no": 940, "end_line_no": 960, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3963963963963964}, {"context": "        return actor.to(device)\n\n    def _create_mock_qvalue(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n\n        module = ValueClass()\n        qvalue = ValueOperator(\n            module=module,\n            in_keys=[\"observation\", \"action\"],\n        )\n        return qvalue.to(device)\n\n    def _create_shared_mock_actor_qvalue(\n        self, batch=2, obs_dim=3, action_dim=4, hidden_dim=5, device=\"cpu\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 1350, "start_line_no": 1340, "end_line_no": 1360, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.39316239316239315}, {"context": "    def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        # Actor\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n\n        module = ValueClass()\n        value = ValueOperator(\n            module=module,\n            in_keys=[\"observation\", \"action\"],\n        )\n        return value.to(device)\n\n    def _create_mock_distributional_actor(\n        self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n    ):", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}, {"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 680, "start_line_no": 670, "end_line_no": 690, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38524590163934425}, {"context": "        action_spec = BoundedTensorSpec(\n            -torch.ones(action_dim), torch.ones(action_dim), (action_dim,)\n        )\n        module = nn.Linear(obs_dim, action_dim)\n        actor = Actor(\n            spec=action_spec,\n            module=module,\n        )\n        return actor.to(device)\n\n    def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        # Actor\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}, {"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 670, "start_line_no": 660, "end_line_no": 680, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3793103448275862}, {"context": "        output = self.linear(observation)\n        if self.multiple_outputs:\n            return output, output.sum(), output.min(), output.max()\n        return self.linear(observation)\n\n\nclass TensorDictCompatiblePolicy(nn.Module):\n    def __init__(self, out_features: int):\n        super().__init__()\n        self.in_keys = [\"observation\"]\n        self.out_keys = [\"action\"]\n        self.linear = nn.LazyLinear(out_features)\n\n    def forward(self, tensordict):\n        return TensorDict(\n            {self.out_keys[0]: self.linear(tensordict.get(self.in_keys[0]))},\n            [],\n        )\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_collector.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3783783783783784}, {"context": "            def __init__(self):\n                super().__init__()\n                self.linear = NormalParamWrapper(nn.Linear(hidden_dim, 2 * action_dim))\n\n            def forward(self, hidden):\n                return self.linear(hidden)\n\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(hidden_dim + action_dim, 1)\n\n            def forward(self, hidden, act):\n                return self.linear(torch.cat([hidden, act], -1))\n\n        common = SafeModule(CommonClass(), in_keys=[\"observation\"], out_keys=[\"hidden\"])\n        actor_subnet = ProbabilisticActor(\n            SafeModule(ActorClass(), in_keys=[\"hidden\"], out_keys=[\"loc\", \"scale\"]),\n            in_keys=[\"loc\", \"scale\"],\n            distribution_class=TanhNormal,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 1380, "start_line_no": 1370, "end_line_no": 1390, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.37606837606837606}, {"context": "        self.out_keys = [\"action\"]\n        self.linear = nn.LazyLinear(out_features)\n\n    def forward(self, tensordict):\n        return TensorDict(\n            {self.out_keys[0]: self.linear(tensordict.get(self.in_keys[0]))},\n            [],\n        )\n\n\nclass UnwrappablePolicy(nn.Module):\n    def __init__(self, out_features: int):\n        super().__init__()\n        self.linear = nn.LazyLinear(out_features)\n\n    def forward(self, observation, other_stuff):\n        return self.linear(observation), other_stuff.sum()\n\n\nclass ParametricPolicyNet(nn.Module):", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_collector.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.375}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n#         tensordict_out = tensordict_out.exclude(*obs_keys, inplace=True)\n#         tensordict_out.set(\"next\", tensordict_out_select)\n# \n#         reward = tensordict_out.get(\"reward\")\n#         # unsqueeze rewards if needed\n#         # the input tensordict may have more leading dimensions than the batch_size\n#         # e.g. in model-based contexts.\n#         batch_size = self.batch_size\n#         dims = len(batch_size)\n#         leading_batch_size = (\n#             tensordict_out.batch_size[:-dims] if dims else tensordict_out.shape\n#         )\n#         expected_reward_shape = torch.Size(\n#             [*leading_batch_size, *self.reward_spec.shape]\n#         )\n#         actual_reward_shape = reward.shape\n#         if actual_reward_shape != expected_reward_shape:\n#             reward = reward.view(expected_reward_shape)\n#             tensordict_out.set(\"reward\", reward)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/postprocs/postprocs.py\n# --------------------------------------------------\n#         done = tensordict.get(\"done\")\n#         if (\"collector\", \"mask\") in tensordict.keys(True):\n#             mask = tensordict.get((\"collector\", \"mask\")).view_as(done)\n#         else:\n#             mask = done.clone().flip(1).cumsum(1).flip(1).to(torch.bool)\n#         reward = tensordict.get(\"reward\")\n# \n#         b, T, *_ = mask.shape\n# \n#         terminal, post_terminal = _get_terminal(done, self.n_steps_max)\n# \n#         # Compute gamma for n-step value function\n#         gamma_masked = _get_gamma(self.gamma, reward, mask, self.n_steps_max)\n# \n#         # Discounted summed reward\n#         partial_return = _conv1d_reward(reward, self.gammas, self.n_steps_max)\n# \n#         # step_to_next_state\n#         nonterminal = ~post_terminal[:, :T]\n#         steps_to_next_obs = _get_steps_to_next_obs(nonterminal, self.n_steps_max)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n#                 obs = tensordict_out.get(key)\n#                 self.observation_spec.type_check(obs, key)\n# \n#             if tensordict_out.get(\"reward\").dtype is not self.reward_spec.dtype:\n#                 raise TypeError(\n#                     f\"expected reward.dtype to be {self.reward_spec.dtype} \"\n#                     f\"but got {tensordict_out.get('reward').dtype}\"\n#                 )\n# \n#             if tensordict_out.get(\"done\").dtype is not torch.bool:\n#                 raise TypeError(\n#                     f\"expected done.dtype to be torch.bool but got {tensordict_out.get('done').dtype}\"\n#                 )\n#         tensordict.update(tensordict_out, inplace=self._inplace_update)\n# \n#         return tensordict\n# \n#     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         raise NotImplementedError(\"EnvBase.forward is not implemented\")\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/value/advantages.py\n# --------------------------------------------------\n#             ... )\n#             >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n#             >>> reward = torch.randn(1, 10, 1)\n#             >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n#             >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n# \n#         \"\"\"\n#         if tensordict.batch_dims < 1:\n#             raise RuntimeError(\n#                 \"Expected input tensordict to have at least one dimensions, got\"\n#                 f\"tensordict.batch_size = {tensordict.batch_size}\"\n#             )\n#         reward = tensordict.get(\"reward\")\n#         if self.average_rewards:\n#             reward = reward - reward.mean()\n#             reward = reward / reward.std().clamp_min(1e-4)\n#             tensordict.set(\n#                 \"reward\", reward\n#             )  # we must update the rewards if they are used later in the code\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/value/advantages.py\n# --------------------------------------------------\n#         gamma = self.gamma\n#         kwargs = {}\n#         if self.is_functional and params is None:\n#             raise RuntimeError(\n#                 \"Expected params to be passed to advantage module but got none.\"\n#             )\n#         if params is not None:\n#             kwargs[\"params\"] = params.detach()\n#         with hold_out_net(self.value_network):\n#             self.value_network(tensordict, **kwargs)\n#             value = tensordict.get(self.value_key)\n# \n#         # we may still need to pass gradient, but we don't want to assign grads to\n#         # value net params\n#         step_td = step_mdp(tensordict)\n#         if target_params is not None:\n#             # we assume that target parameters are not differentiable\n#             kwargs[\"params\"] = target_params\n#         elif \"params\" in kwargs:\n#             kwargs[\"params\"] = kwargs[\"params\"].detach()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/value/advantages.py\n# --------------------------------------------------\n#                 f\"tensordict.batch_size = {tensordict.batch_size}\"\n#             )\n#         reward = tensordict.get(\"reward\")\n#         if self.average_rewards:\n#             reward = reward - reward.mean()\n#             reward = reward / reward.std().clamp_min(1e-4)\n#             tensordict.set(\n#                 \"reward\", reward\n#             )  # we must update the rewards if they are used later in the code\n# \n#         gamma = self.gamma\n#         kwargs = {}\n#         if self.is_functional and params is None:\n#             raise RuntimeError(\n#                 \"Expected params to be passed to advantage module but got none.\"\n#             )\n#         if params is not None:\n#             kwargs[\"params\"] = params.detach()\n#         with hold_out_net(self.value_network):\n#             self.value_network(tensordict, **kwargs)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n, but we don't want to assign grads to\n        # value net params\n        step_td = step_mdp(tensordict)\n        if target_params is not None:\n            # we assume that target parameters are not differentiable\n            kwargs[\"params\"] = target_params\n        elif \"params\" in kwargs:\n            kwargs[\"params\"] = kwargs[\"params\"].detach()\n        with hold_out_net(self.value_network):\n            self.value_network(step_td, **kwargs)\n            next_value = step_td.get(self.value_key)\n\n        done = tensordict.get(\"done\")\n        adv = td_advantage_estimate(gamma, value, next_value, reward, done)\n        tensordict.set(\"advantage\", adv)\n        tensordict.set(\"value_target\", adv + value)\n        return tensordict\n\n\nclass TDLambdaEstimate(nn.Module):\n    \"\"\"TD-Lambda estimate of advantage function.\n\n    Args:\n        gamma (scalar): exponential mean discount.\n        lmbda (scalar): trajectory discount.\n        value_network (SafeModule): value operator used to retrieve the value estimates.\n        average_rewards (bool, optional): if True, rewards will be standardized\n            before the TD is computed.\n        differentiable (bool, optional): if True, gradients are propagated throught\n            the computation of the value function. Default is :obj:`False`.\n        vectorized (bool, optional): whether to use the vectorized version of the\n            lambda return. Default is `True`.\n        advantage_key (str or tuple of str, optional): the key of the advantage entry.\n            Defaults to \"advantage\".\n        value_target_key (str or tuple of str, optional): the key of the advantage entry.\n            Defaults to \"value_target\".\n        value_key (str or tuple of str, optional): the value key to read from the input tensordict.\n            Defaults to \"state_value\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        gamma: Union[float, torch.Tensor],\n        lmbda: Union[float, torch.Tensor],\n        value_network: SafeModule,\n        average_rewards: bool = False,\n        differentiable: bool = False,\n        vectorized: bool = True,\n        advantage_key: Union[str, Tuple] = \"advantage\",\n        value_target_key: Union[str, Tuple] = \"value_target\",\n        value_key: Union[str, Tuple] = \"state_value\",\n    ):\n        super().__init__()\n        try:\n            device = next(value_network.parameters()).device\n        except StopIteration:\n            device = torch.device(\"cpu\")\n        self.register_buffer(\"gamma\", torch.tensor(gamma, device=device))\n        self.register_buffer(\"lmbda\", torch.tensor(lmbda, device=device))\n        self.value_network = value_network\n        self.vectorized = vectorized\n\n        self.average_rewards = average_rewards\n        self.differentiable = differentiable\n        self.value_key = value_key\n        if value_key not in value_network.out_keys:\n            raise KeyError(\n                f\"value key '{value_key}' not found in value network out_keys.\"\n            )\n\n        self.advantage_key = advantage_key\n        self.value_target_key = value_target_key\n\n        self.in_keys = (\n            value_network.in_keys\n            + [\"reward\", \"done\"]\n            + [(\"next\", in_key) for in_key in value_network.in_keys]\n        )\n        self.out_keys = [self.advantage_key, self.value_target_key]\n\n    @property\n    def is_functional(self):\n        return (\n            \"_is_stateless\" in self.value_network.__dict__\n            and self.value_network.__dict__[\"_is_stateless\"]\n        )\n\n    @_self_set_grad_enabled\n    @dispatch_kwargs\n    def forward(\n        self,\n        tensordict: TensorDictBase,\n        params: Optional[List[Tensor]] = None,\n        target_params: Optional[List[Tensor]] = None,\n    ) -> TensorDictBase:\n        \"\"\"Computes the TDLambdaEstimate given the data in tensordict.\n\n        If a functional module is provided, a nested TensorDict containing the parameters\n        (and if relevant the target parameters) can be passed to the module.\n\n        Args:\n            tensordict (TensorDictBase): A TensorDict containing the data\n                (an observation key, \"action\", \"reward\", \"done\" and \"next\" tensordict state\n                as returned by the environment) necessary to compute the value estimates and the TDLambdaEstimate.\n                The data passed to this module should be structured as :obj:`[*B, T, F]` where :obj:`B` are\n                the batch size, :obj:`T` the time dimension and :obj:`F` the feature dimension(s).\n            params (TensorDictBase, optional): A nested TensorDict containing the params\n                to be passed to the functional value network module.\n            target_params (TensorDictBase, optional): A nested TensorDict containing the\n                target params to be passed to the functional value network module.\n\n        Returns:\n            An updated TensorDict with an advantage and a value_error keys as defined in the constructor.\n\n        Examples:\n            >>> from tensordict import TensorDict\n            >>> value_net = SafeModule(\n            ...     nn.Linear(3, 1), in_keys=[\"obs\"], out_keys=[\"state_value\"]\n            ... )\n            >>> module = TDLambdaEstimate(\n            ...     gamma=0.98,\n            ...     lmbda=0.94,\n            ...     value_network=value_net,\n            ...     differentiable=False,\n            ... )\n            >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n            >>> reward = torch.randn(1, 10, 1)\n            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n            >>> tensordict = TensorDict({\"obs\": obs, \"next\": {\"obs\": next_obs}, \"done\": done, \"reward\": reward}, [1, 10])\n            >>> _ = module(tensordict)\n            >>> assert \"advantage\" in tensordict.keys()\n\n        The module supports non-tensordict (i.e. unpacked tensordict) inputs too:\n\n        Examples:\n            >>> value_net = SafeModule(\n            ...     nn.Linear(3, 1), in_keys=[\"obs\"], out_keys=[\"state_value\"]\n            ... )\n            >>> module = TDLambdaEstimate(\n            ...     gamma=0.98,\n            ...     lmbda=0.94,\n            ...     value_network=value_net,\n            ...     differentiable=False,\n            ... )\n            >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n            >>> reward = torch.randn(1, 10, 1)\n            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n\n        \"\"\"\n        if tensordict.batch_dims < 1:\n            raise RuntimeError(\n                \"Expected input tensordict to have at least one dimensions, got\"\n                f\"tensordict.batch_size = {tensordict.batch_size}\"\n            )\n        reward = tensordict.get(\"reward\")\n        if self.average_rewards:\n            reward = reward - reward.mean()\n            reward = reward / reward.std().clamp_min(1e-4)\n            tensordict.set(\n                \"reward\", reward\n            )  # we must update the rewards if they are used later in the code\n\n        gamma = self.gamma\n        lmbda = self.lmbda\n\n        kwargs = {}", "choices": [{"text": "return tensordict"}], "metadata": {"task_id": "pytorch_rl/56", "ground_truth": "        if self.is_functional and params is None:", "fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "context_start_lineno": 182, "line_no": 350, "query_window": {"context": "            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n\n        \"\"\"\n        if tensordict.batch_dims < 1:\n            raise RuntimeError(\n                \"Expected input tensordict to have at least one dimensions, got\"\n                f\"tensordict.batch_size = {tensordict.batch_size}\"\n            )\n        reward = tensordict.get(\"reward\")\n        if self.average_rewards:\n            reward = reward - reward.mean()\n            reward = reward / reward.std().clamp_min(1e-4)\n            tensordict.set(\n                \"reward\", reward\n            )  # we must update the rewards if they are used later in the code\n\n        gamma = self.gamma\n        lmbda = self.lmbda\n\n        kwargs = {}", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 350, "task_id": "pytorch_rl/56", "start_line_no": 330, "end_line_no": 350, "window_size": 20, "context_start_lineno": 182, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            ... )\n            >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n            >>> reward = torch.randn(1, 10, 1)\n            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n\n        \"\"\"\n        if tensordict.batch_dims < 1:\n            raise RuntimeError(\n                \"Expected input tensordict to have at least one dimensions, got\"\n                f\"tensordict.batch_size = {tensordict.batch_size}\"\n            )\n        reward = tensordict.get(\"reward\")\n        if self.average_rewards:\n            reward = reward - reward.mean()\n            reward = reward / reward.std().clamp_min(1e-4)\n            tensordict.set(\n                \"reward\", reward\n            )  # we must update the rewards if they are used later in the code\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7796610169491526}, {"context": "                f\"tensordict.batch_size = {tensordict.batch_size}\"\n            )\n        reward = tensordict.get(\"reward\")\n        if self.average_rewards:\n            reward = reward - reward.mean()\n            reward = reward / reward.std().clamp_min(1e-4)\n            tensordict.set(\n                \"reward\", reward\n            )  # we must update the rewards if they are used later in the code\n\n        gamma = self.gamma\n        kwargs = {}\n        if self.is_functional and params is None:\n            raise RuntimeError(\n                \"Expected params to be passed to advantage module but got none.\"\n            )\n        if params is not None:\n            kwargs[\"params\"] = params.detach()\n        with hold_out_net(self.value_network):\n            self.value_network(tensordict, **kwargs)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6076923076923076}, {"context": "        The module supports non-tensordict (i.e. unpacked tensordict) inputs too:\n\n        Examples:\n            >>> value_net = SafeModule(\n            ...     nn.Linear(3, 1), in_keys=[\"obs\"], out_keys=[\"state_value\"]\n            ... )\n            >>> module = TDEstimate(\n            ...     gamma=0.98,\n            ...     value_network=value_net,\n            ...     differentiable=False,\n            ... )\n            >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n            >>> reward = torch.randn(1, 10, 1)\n            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n\n        \"\"\"\n        if tensordict.batch_dims < 1:\n            raise RuntimeError(\n                \"Expected input tensordict to have at least one dimensions, got\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38311688311688313}, {"context": "        done = tensordict_out.get(\"done\")\n        # unsqueeze done if needed\n        expected_done_shape = torch.Size([*leading_batch_size, *batch_size, 1])\n        actual_done_shape = done.shape\n        if actual_done_shape != expected_done_shape:\n            done = done.view(expected_done_shape)\n            tensordict_out.set(\"done\", done)\n\n        if self.run_type_checks:\n            for key in self._select_observation_keys(tensordict_out):\n                obs = tensordict_out.get(key)\n                self.observation_spec.type_check(obs, key)\n\n            if tensordict_out.get(\"reward\").dtype is not self.reward_spec.dtype:\n                raise TypeError(\n                    f\"expected reward.dtype to be {self.reward_spec.dtype} \"\n                    f\"but got {tensordict_out.get('reward').dtype}\"\n                )\n\n            if tensordict_out.get(\"done\").dtype is not torch.bool:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30666666666666664}, {"context": "                rewards.\n\n\n        Returns:\n            in-place transformation of the input tensordict.\n\n        \"\"\"\n        if tensordict.batch_dims != 2:\n            raise RuntimeError(\"Expected a tensordict with B x T x ... dimensions\")\n\n        done = tensordict.get(\"done\")\n        if (\"collector\", \"mask\") in tensordict.keys(True):\n            mask = tensordict.get((\"collector\", \"mask\")).view_as(done)\n        else:\n            mask = done.clone().flip(1).cumsum(1).flip(1).to(torch.bool)\n        reward = tensordict.get(\"reward\")\n\n        b, T, *_ = mask.shape\n\n        terminal, post_terminal = _get_terminal(done, self.n_steps_max)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "postprocs", "postprocs.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2972972972972973}, {"context": "        if tensordict_out is tensordict:\n            raise RuntimeError(\n                \"EnvBase._step should return outplace changes to the input \"\n                \"tensordict. Consider emptying the TensorDict first (e.g. tensordict.empty() or \"\n                \"tensordict.select()) inside _step before writing new tensors onto this new instance.\"\n            )\n        tensordict.unlock()\n\n        obs_keys = set(self.observation_spec.keys())\n        tensordict_out_select = tensordict_out.select(*obs_keys)\n        tensordict_out = tensordict_out.exclude(*obs_keys, inplace=True)\n        tensordict_out.set(\"next\", tensordict_out_select)\n\n        reward = tensordict_out.get(\"reward\")\n        # unsqueeze rewards if needed\n        # the input tensordict may have more leading dimensions than the batch_size\n        # e.g. in model-based contexts.\n        batch_size = self.batch_size\n        dims = len(batch_size)\n        leading_batch_size = (", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28402366863905326}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n# \n#   assigned_worker: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   stopping_reason: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   _infeasibility_reason: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/context.py\n# --------------------------------------------------\n#       factory=dict,\n#       validator=attr.validators.deep_mapping(\n#           key_validator=attr.validators.instance_of(str),\n#           value_validator=attr.validators.instance_of(ParameterValue),\n#           mapping_validator=attr.validators.instance_of(dict)),\n#       on_setattr=attr.setters.validate)  # pytype: disable=wrong-arg-types\n# \n#   metadata: Metadata = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=Metadata(),\n#       validator=attr.validators.instance_of(Metadata),\n#       on_setattr=attr.setters.validate)\n# \n#   related_links: Dict[str, str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       factory=dict,\n#       validator=attr.validators.deep_mapping(\n#           key_validator=attr.validators.instance_of(str),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   _infeasibility_reason: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   description: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   related_links: Dict[str, str] = attr.ib(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/base_study_config.py\n# --------------------------------------------------\n#       # FYI: Converter is applied before validator.\n#       converter=lambda x: float(x) if x is not None else -np.inf,\n#       validator=[attr.validators.instance_of(float), _min_leq_max],\n#       kw_only=True)\n# \n#   # Maximum value of this metric can be optionally specified.\n#   max_value: float = attr.field(\n#       init=True,\n#       default=None,\n#       # FYI: Converter is applied before validator.\n#       converter=lambda x: float(x) if x is not None else np.inf,\n#       validator=[attr.validators.instance_of(float), _max_geq_min],\n#       on_setattr=attr.setters.validate,\n#       kw_only=True)\n# \n#   def min_value_or(self, default_value_fn: Callable[[], float]) -> float:\n#     \"\"\"Returns the minimum value if finite, or default_value_fn().\n# \n#     Avoids the common pitfalls of using\n#       `metric.min_value or default_value`\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#   )\n# \n#   description: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   related_links: Dict[str, str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       factory=dict,\n#       validator=attr.validators.deep_mapping(\n#           key_validator=attr.validators.instance_of(str),\n#           value_validator=attr.validators.instance_of(str),\n#           mapping_validator=attr.validators.instance_of(dict)),\n#   )  # pytype: disable=wrong-arg-types\n# \n#   final_measurement: Optional[Measurement] = attr.ib(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#       factory=list,\n#       validator=attr.validators.deep_iterable(\n#           member_validator=attr.validators.instance_of(Measurement),\n#           iterable_validator=attr.validators.instance_of(list)),\n#   )\n# \n#   creation_time: Optional[datetime.datetime] = attr.ib(\n#       init=True,\n#       default=datetime.datetime.now(),\n#       converter=_to_local_time,\n#       kw_only=True,\n#       repr=lambda v: v.strftime('%x %X') if v is not None else 'None',\n#       validator=attr.validators.optional(\n#           attr.validators.instance_of(datetime.datetime)),\n#   )\n# \n#   completion_time: Optional[datetime.datetime] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#       kw_only=True,\n#       repr=lambda v: v.strftime('%x %X') if v is not None else 'None',\n#       validator=attr.validators.optional(\n#           attr.validators.instance_of(datetime.datetime)),\n#   )\n# \n#   completion_time: Optional[datetime.datetime] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       repr=lambda v: v.strftime('%x %X') if v is not None else 'None',\n#       converter=_to_local_time,\n#       validator=attr.validators.optional(\n#           attr.validators.instance_of(datetime.datetime)),\n#   )\n# \n#   @property\n#   def duration(self) -> Optional[datetime.timedelta]:\n#     \"\"\"Returns the duration of this Trial if it is completed, or None.\"\"\"\n#     if self.completion_time:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"ParameterConfig wraps ParameterConfig and ParameterSpec protos.\"\"\"\n\nimport collections\nfrom typing import Sized, Collection, Set as AbstractSet\nimport copy\nimport enum\nimport json\nimport math\nimport re\nfrom typing import Generator, Iterator, List, Optional, Sequence, Tuple, Union, overload\n\nfrom absl import logging\nimport attr\nfrom vizier._src.pyvizier.shared import trial\n\nExternalType = trial.ExternalType\nParameterType = trial.ParameterType\n\n\nclass ScaleType(enum.Enum):\n  \"\"\"Valid Values for ParameterConfig.scale_type.\"\"\"\n  LINEAR = 'LINEAR'\n  LOG = 'LOG'\n  REVERSE_LOG = 'REVERSE_LOG'\n  UNIFORM_DISCRETE = 'UNIFORM_DISCRETE'\n\n  def is_nonlinear(self) -> bool:\n    return self in [self.LOG, self.REVERSE_LOG]\n\n\n# A sequence of possible internal parameter values.\nParameterValueTypes = Union[str, int, float, bool]\nMonotypeParameterSequence = Union[Sequence[Union[int, float]], Sequence[str]]\nMonotypeParameterList = Union[List[Union[int, float]], List[str]]\n\n\ndef _validate_bounds(bounds: Union[Tuple[int, int], Tuple[float, float]]):\n  \"\"\"Validates the bounds.\"\"\"\n  if len(bounds) != 2:\n    raise ValueError('Bounds must have length 2. Given: {}'.format(bounds))\n  lower = bounds[0]\n  upper = bounds[1]\n  if not all([math.isfinite(v) for v in (lower, upper)]):\n    raise ValueError(\n        'Both \"lower\" and \"upper\" must be finite. Given: (%f, %f)' %\n        (lower, upper))\n  if lower > upper:\n    raise ValueError(\n        'Lower cannot be greater than upper: given lower={} upper={}'.format(\n            lower, upper))\n\n\ndef _get_feasible_points_and_bounds(\n    feasible_values: Sequence[float]\n) -> Tuple[List[float], Union[Tuple[int, int], Tuple[float, float]]]:\n  \"\"\"Validates and converts feasible values to floats.\"\"\"\n  if not all([math.isfinite(p) for p in feasible_values]):\n    raise ValueError('Feasible values must all be finite. Given: {}' %\n                     feasible_values)\n\n  feasible_points = list(sorted(feasible_values))\n  bounds = (feasible_points[0], feasible_points[-1])\n  return feasible_points, bounds\n\n\ndef _get_categories(categories: Sequence[str]) -> List[str]:\n  \"\"\"Returns the categories.\"\"\"\n  return sorted(list(categories))\n\n\ndef _get_default_value(\n    param_type: ParameterType,\n    default_value: Union[float, int, str]) -> Union[float, int, str]:\n  \"\"\"Validates and converts the default_value to the right type.\"\"\"\n  if (param_type in (ParameterType.DOUBLE, ParameterType.DISCRETE) and\n      (isinstance(default_value, float) or isinstance(default_value, int))):\n    return float(default_value)\n  elif (param_type == ParameterType.INTEGER and\n        (isinstance(default_value, float) or isinstance(default_value, int))):\n    if isinstance(default_value, int):\n      return default_value\n    else:\n      # Check if the float rounds nicely.\n      default_int_value = round(default_value)\n      if not math.isclose(default_value, default_int_value):\n        raise ValueError('default_value for an INTEGER parameter should be an '\n                         'integer, got float: [{}]'.format(default_value))\n      return default_int_value\n  elif (param_type == ParameterType.CATEGORICAL and\n        isinstance(default_value, str)):\n    return default_value\n  raise ValueError(\n      'default_value has an incorrect type. ParameterType has type {}, '\n      'but default_value has type {}'.format(param_type.name,\n                                             type(default_value)))\n\n\n#######################\n# Experimental features\n#######################\nclass FidelityMode(enum.Enum):\n  \"\"\"Decides how the fidelity config should be interpreated.\n\n  SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower\n    fidelity measurement. Currently, no algorithms can take advatange of it, and\n    Vizier behaves exactly like NON_SEQUENTIAL case. This is for tracking\n    purposes only.\n\n  NOT_SEQUENTIAL: Each fidelity is separately measured. Example: Fidelity\n    is the fraction of dataset to train on.\n\n  STEPS: Fidelity determines the maximum value for Measurement.steps reported\n    to Vizier. There is one-to-one correspondence between steps and fidelity.\n    A high fideltiy Trial's measurements contain lower fidelity evaluations.\n    When this is enabled, suggestion models do not use\n    Trials' final_measurement. Instead, it reads the measurements whose\n    \"steps\" exactly match one of the fidelities, and treats them as if they\n    were separate Trials. Example: Fidelity is the number of total epochs\n    to train on.\n  \"\"\"\n  SEQUENTIAL = 'SEQUENTIAL'\n  NOT_SEQUENTIAL = 'NOT_SEQUENTIAL'\n  STEPS = 'STEPS'\n\n\n@attr.define\nclass FidelityConfig:\n  mode: FidelityMode = attr.field(converter=FidelityMode)\n  cost_ratio: Sequence[float] = attr.field(\n      converter=tuple, default=tuple(), kw_only=True)\n\n\n########################\n# Experimental features end here\n########################\n\n\n@attr.s(auto_attribs=True, frozen=False, init=True, slots=True, eq=True)\nclass ParameterConfig:\n  \"\"\"A Vizier ParameterConfig.\n\n  Use ParameterConfig.factory to create a valid instance.\n  \"\"\"\n  _name: str = attr.ib(\n      init=True, validator=attr.validators.instance_of(str), kw_only=True)\n  _type: ParameterType = attr.ib(\n      init=True,\n      validator=attr.validators.instance_of(ParameterType),\n      repr=lambda v: v.name if v is not None else 'None',\n      kw_only=True)\n  # Only one of _feasible_values, _bounds will be set at any given time.\n  _bounds: Optional[Union[Tuple[int, int], Tuple[float, float]]] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float)),\n              iterable_validator=attr.validators.instance_of(tuple))),\n      kw_only=True)\n  _feasible_values: Optional[MonotypeParameterList] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float, str)),\n              iterable_validator=attr.validators.instance_of((list, tuple)))),", "choices": [{"text": "metadata: Metadata = attr.ib("}], "metadata": {"task_id": "google_vizier/111", "ground_truth": "      kw_only=True)", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "context_start_lineno": 0, "line_no": 180, "query_window": {"context": "      init=True, validator=attr.validators.instance_of(str), kw_only=True)\n  _type: ParameterType = attr.ib(\n      init=True,\n      validator=attr.validators.instance_of(ParameterType),\n      repr=lambda v: v.name if v is not None else 'None',\n      kw_only=True)\n  # Only one of _feasible_values, _bounds will be set at any given time.\n  _bounds: Optional[Union[Tuple[int, int], Tuple[float, float]]] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float)),\n              iterable_validator=attr.validators.instance_of(tuple))),\n      kw_only=True)\n  _feasible_values: Optional[MonotypeParameterList] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float, str)),\n              iterable_validator=attr.validators.instance_of((list, tuple)))),", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 180, "task_id": "google_vizier/111", "start_line_no": 160, "end_line_no": 180, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "      factory=list,\n      validator=attr.validators.deep_iterable(\n          member_validator=attr.validators.instance_of(Measurement),\n          iterable_validator=attr.validators.instance_of(list)),\n  )\n\n  creation_time: Optional[datetime.datetime] = attr.ib(\n      init=True,\n      default=datetime.datetime.now(),\n      converter=_to_local_time,\n      kw_only=True,\n      repr=lambda v: v.strftime('%x %X') if v is not None else 'None',\n      validator=attr.validators.optional(\n          attr.validators.instance_of(datetime.datetime)),\n  )\n\n  completion_time: Optional[datetime.datetime] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 480, "start_line_no": 470, "end_line_no": 490, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.423728813559322}, {"context": "      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(\n          attr.validators.instance_of(Measurement)),\n  )\n\n  measurements: List[Measurement] = attr.ib(\n      init=True,\n      kw_only=True,\n      factory=list,\n      validator=attr.validators.deep_iterable(\n          member_validator=attr.validators.instance_of(Measurement),\n          iterable_validator=attr.validators.instance_of(list)),\n  )\n\n  creation_time: Optional[datetime.datetime] = attr.ib(\n      init=True,\n      default=datetime.datetime.now(),\n      converter=_to_local_time,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3482142857142857}, {"context": "      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  _infeasibility_reason: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  description: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  related_links: Dict[str, str] = attr.ib(", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.33962264150943394}, {"context": "          attr.validators.optional(attr.validators.instance_of(float)),\n          attr.validators.optional(attr.validators.le(1.0)),\n          attr.validators.optional(attr.validators.ge(0.0))\n      ],\n      kw_only=True)\n\n  # Minimum value of this metric can be optionally specified.\n  min_value: float = attr.field(\n      init=True,\n      default=None,\n      # FYI: Converter is applied before validator.\n      converter=lambda x: float(x) if x is not None else -np.inf,\n      validator=[attr.validators.instance_of(float), _min_leq_max],\n      kw_only=True)\n\n  # Maximum value of this metric can be optionally specified.\n  max_value: float = attr.field(\n      init=True,\n      default=None,\n      # FYI: Converter is applied before validator.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "base_study_config.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3384615384615385}, {"context": "\n  assigned_worker: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  stopping_reason: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  _infeasibility_reason: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.33653846153846156}, {"context": "  description: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n      on_setattr=attr.setters.validate)\n\n  parameters: Dict[str, ParameterValue] = attr.ib(\n      init=True,\n      kw_only=True,\n      factory=dict,\n      validator=attr.validators.deep_mapping(\n          key_validator=attr.validators.instance_of(str),\n          value_validator=attr.validators.instance_of(ParameterValue),\n          mapping_validator=attr.validators.instance_of(dict)),\n      on_setattr=attr.setters.validate)  # pytype: disable=wrong-arg-types\n\n  metadata: Metadata = attr.ib(\n      init=True,\n      kw_only=True,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "context.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3360655737704918}, {"context": "      kw_only=True,\n      default=0,\n      validator=attr.validators.instance_of(int),\n  )\n\n  is_requested: bool = attr.ib(\n      init=True,\n      kw_only=True,\n      default=False,\n      validator=attr.validators.instance_of(bool))\n\n  assigned_worker: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  stopping_reason: Optional[str] = attr.ib(\n      init=True,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3333333333333333}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_speed_distributed.py\n# --------------------------------------------------\n#     if rank == 0:\n#         rpc.init_rpc(\n#             AGENT_NAME,\n#             rank=rank,\n#             world_size=world_size,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n#         )\n#         # create tensor\n#         tensor = torch.zeros(10000, 10000)\n#         if tensortype == \"memmap\":\n#             tensor = MemmapTensor(tensor)\n#         elif tensortype == \"tensor\":\n#             pass\n#         else:\n#             raise NotImplementedError\n# \n#         # \u00a0send tensor\n#         w = 1\n#         fut0 = rpc.remote(f\"worker{w}\", send_tensor, args=(tensor,))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb_distributed.py\n# --------------------------------------------------\n#         pool.apply_async(shutdown)\n# \n# \n# def init_rpc(rank, name, world_size):\n#     os.environ[\"MASTER_ADDR\"] = \"localhost\"\n#     os.environ[\"MASTER_PORT\"] = \"29500\"\n#     str_init_method = \"tcp://localhost:10030\"\n#     options = rpc.TensorPipeRpcBackendOptions(\n#         num_worker_threads=16, init_method=str_init_method\n#     )\n#     rpc.init_rpc(\n#         name,\n#         rank=rank,\n#         backend=rpc.BackendType.TENSORPIPE,\n#         rpc_backend_options=options,\n#         world_size=world_size,\n#     )\n# \n# \n# def shutdown():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_td_distributed.py\n# --------------------------------------------------\n#             AGENT_NAME,\n#             rank=rank,\n#             world_size=world_size,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n#         )\n# \n#         if args.task == 0:\n#             time.sleep(1)\n#             t0 = time.time()\n#             for w in range(1, args.world_size):\n#                 fut0 = rpc.rpc_async(f\"worker{w}\", get_tensordict, args=())\n#                 fut0.wait()\n#                 fut1 = rpc.rpc_async(f\"worker{w}\", tensordict_add, args=())\n#                 tensordict2 = fut1.wait()\n#                 tensordict2.clone()\n#             print(\"time: \", time.time() - t0)\n#         elif args.task == 1:\n#             time.sleep(1)\n#             t0 = time.time()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb_distributed.py\n# --------------------------------------------------\n#     rpc.init_rpc(\n#         name,\n#         rank=rank,\n#         backend=rpc.BackendType.TENSORPIPE,\n#         rpc_backend_options=options,\n#         world_size=world_size,\n#     )\n# \n# \n# def shutdown():\n#     rpc.shutdown()\n# \n# \n# def _construct_buffer(target):\n#     for _ in range(RETRY_COUNT):\n#         try:\n#             buffer_rref = rpc.remote(target, ReplayBufferNode, args=(1000,))\n#             return buffer_rref\n#         except Exception as e:\n#             print(f\"Failed to connect: {e}\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmarks/storage/benchmark_sample_latency_over_rpc.py\n# --------------------------------------------------\n# if __name__ == \"__main__\":\n#     args = parser.parse_args()\n#     rank = args.rank\n#     storage_type = args.storage\n# \n#     print(f\"Rank: {rank}; Storage: {storage_type}\")\n# \n#     os.environ[\"MASTER_ADDR\"] = \"localhost\"\n#     os.environ[\"MASTER_PORT\"] = \"29500\"\n#     os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n#     options = rpc.TensorPipeRpcBackendOptions(\n#         num_worker_threads=16, init_method=\"tcp://localhost:10002\", rpc_timeout=120\n#     )\n#     if rank == 0:\n#         # rank 0 is the trainer\n#         rpc.init_rpc(\n#             TRAINER_NODE,\n#             rank=rank,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_td_distributed.py\n# --------------------------------------------------\n#     os.environ[\"MASTER_PORT\"] = \"29500\"\n# \n#     str_init_method = \"tcp://localhost:10000\"\n#     options = rpc.TensorPipeRpcBackendOptions(\n#         _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n#     )\n# \n#     if rank == 0:\n#         # rank0 is the trainer\n#         rpc.init_rpc(\n#             AGENT_NAME,\n#             rank=rank,\n#             world_size=world_size,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n#         )\n# \n#         if args.task == 0:\n#             time.sleep(1)\n#             t0 = time.time()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmarks/storage/benchmark_sample_latency_over_rpc.py\n# --------------------------------------------------\n#     options = rpc.TensorPipeRpcBackendOptions(\n#         num_worker_threads=16, init_method=\"tcp://localhost:10002\", rpc_timeout=120\n#     )\n#     if rank == 0:\n#         # rank 0 is the trainer\n#         rpc.init_rpc(\n#             TRAINER_NODE,\n#             rank=rank,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n#         )\n#         trainer = DummyTrainerNode()\n#         results = []\n#         for i in range(REPEATS):\n#             result = trainer.train(batch_size=BATCH_SIZE)\n#             if i == 0:\n#                 continue\n#             results.append(result)\n#             print(i, results[-1])\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\"\"\"\nExample use of a distributed replay buffer\n===========================\n\nThis example illustrates how a skeleton reinforcement learning algorithm can be implemented in a distributed fashion with communication between nodes/workers handled using `torch.rpc`.\nIt focusses on how to set up a replay buffer worker that accepts remote operation requests efficiently, and so omits any learning component such as parameter updates that may be required for a complete distributed reinforcement learning algorithm implementation.\nIn this model, >= 1 data collectors workers are responsible for collecting experiences in an environment, the replay buffer worker receives all of these experiences and exposes them to a trainer that is responsible for making parameter updates to any required models.\n\"\"\"\n\nimport argparse\nimport os\nimport random\nimport sys\nimport time\n\nimport torch\nimport torch.distributed.rpc as rpc\nfrom tensordict import TensorDict\nfrom torchrl.data.replay_buffers import RemoteTensorDictReplayBuffer\nfrom torchrl.data.replay_buffers.samplers import RandomSampler\nfrom torchrl.data.replay_buffers.storages import LazyMemmapStorage\nfrom torchrl.data.replay_buffers.utils import accept_remote_rref_invocation\nfrom torchrl.data.replay_buffers.writers import RoundRobinWriter\n\nRETRY_LIMIT = 2\nRETRY_DELAY_SECS = 3\nREPLAY_BUFFER_NODE = \"ReplayBuffer\"\nTRAINER_NODE = \"Trainer\"\n\nparser = argparse.ArgumentParser(\n    description=\"RPC Replay Buffer Example\",\n    formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n)\n\nparser.add_argument(\n    \"--rank\",\n    type=int,\n    default=-1,\n    help=\"Node Rank [0 = Replay Buffer, 1 = Dummy Trainer, 2+ = Dummy Data Collector]\",\n)\n\n\nclass DummyDataCollectorNode:\n    \"\"\"Data collector node responsible for collecting experiences used for learning.\n\n    Args:\n        replay_buffer (rpc.RRef): the RRef associated with the construction of the replay buffer\n    \"\"\"\n\n    def __init__(self, replay_buffer: rpc.RRef) -> None:\n        self.id = rpc.get_worker_info().id\n        self.replay_buffer = replay_buffer\n        print(\"Data Collector Node constructed\")\n\n    def _submit_random_item_async(self) -> rpc.RRef:\n        td = TensorDict({\"a\": torch.randint(100, (1,))}, [])\n        return rpc.remote(\n            self.replay_buffer.owner(),\n            ReplayBufferNode.add,\n            args=(\n                self.replay_buffer,\n                td,\n            ),\n        )\n\n    @accept_remote_rref_invocation\n    def collect(self):\n        \"\"\"Method that begins experience collection (we just generate random TensorDicts in this example). `accept_remote_rref_invocation` enables this method to be invoked remotely provided the class instantiation `rpc.RRef` is provided in place of the object reference.\"\"\"\n        for elem in range(50):\n            time.sleep(random.randint(1, 4))\n            print(\n                f\"Collector [{self.id}] submission {elem}: {self._submit_random_item_async().to_here()}\"\n            )\n\n\nclass DummyTrainerNode:\n    \"\"\"Trainer node responsible for learning from experiences sampled from an experience replay buffer.\"\"\"\n\n    def __init__(self) -> None:\n        print(\"DummyTrainerNode\")\n        self.id = rpc.get_worker_info().id\n        self.replay_buffer = self._create_replay_buffer()\n        self._create_and_launch_data_collectors()\n\n    def train(self, iterations: int) -> None:\n        for iteration in range(iterations):\n            print(f\"[{self.id}] Training Iteration: {iteration}\")\n            time.sleep(3)\n            batch = rpc.rpc_sync(\n                self.replay_buffer.owner(),\n                ReplayBufferNode.sample,\n                args=(self.replay_buffer, 16),\n            )\n            print(f\"[{self.id}] Sample Obtained Iteration: {iteration}\")\n            print(f\"{batch}\")\n\n    def _create_replay_buffer(self) -> rpc.RRef:\n        while True:\n            try:\n                replay_buffer_info = rpc.get_worker_info(REPLAY_BUFFER_NODE)\n                buffer_rref = rpc.remote(\n                    replay_buffer_info, ReplayBufferNode, args=(10000,)\n                )\n                print(f\"Connected to replay buffer {replay_buffer_info}\")\n                return buffer_rref\n            except Exception as e:\n                print(f\"Failed to connect to replay buffer: {e}\")\n                time.sleep(RETRY_DELAY_SECS)\n\n    def _create_and_launch_data_collectors(self) -> None:\n        data_collector_number = 2\n        retries = 0\n        data_collectors = []\n        data_collector_infos = []\n        # discover launched data collector nodes (with retry to allow collectors to dynamically join)\n        while True:\n            try:\n                data_collector_info = rpc.get_worker_info(\n                    f\"DataCollector{data_collector_number}\"\n                )\n                print(f\"Data collector info: {data_collector_info}\")\n                dc_ref = rpc.remote(\n                    data_collector_info,\n                    DummyDataCollectorNode,\n                    args=(self.replay_buffer,),\n                )\n                data_collectors.append(dc_ref)\n                data_collector_infos.append(data_collector_info)\n                data_collector_number += 1\n                retries = 0\n            except Exception:\n                retries += 1\n                print(\n                    f\"Failed to connect to DataCollector{data_collector_number} with {retries} retries\"\n                )\n                if retries >= RETRY_LIMIT:\n                    print(f\"{len(data_collectors)} data collectors\")\n                    for data_collector_info, data_collector in zip(\n                        data_collector_infos, data_collectors\n                    ):\n                        rpc.remote(\n                            data_collector_info,\n                            DummyDataCollectorNode.collect,\n                            args=(data_collector,),\n                        )\n                    break\n                else:\n                    time.sleep(RETRY_DELAY_SECS)\n\n\nclass ReplayBufferNode(RemoteTensorDictReplayBuffer):\n    \"\"\"Experience replay buffer node that is capable of accepting remote connections. Being a `RemoteTensorDictReplayBuffer` means all of it's public methods are remotely invokable using `torch.rpc`.\n    Using a LazyMemmapStorage is highly advised in distributed settings with shared storage due to the lower serialisation cost of MemmapTensors as well as the ability to specify file storage locations which can improve ability to recover from node failures.\n\n    Args:\n        capacity (int): the maximum number of elements that can be stored in the replay buffer.\n    \"\"\"\n\n    def __init__(self, capacity: int):\n        super().__init__(\n            storage=LazyMemmapStorage(\n                max_size=capacity, scratch_dir=\"/tmp/\", device=torch.device(\"cpu\")\n            ),\n            sampler=RandomSampler(),\n            writer=RoundRobinWriter(),\n            collate_fn=lambda x: x,\n        )\n\n\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    print(f\"Rank: {rank}\")\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n    str_init_method = \"tcp://localhost:10000\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=str_init_method\n    )", "choices": [{"text": "torch.rpc"}], "metadata": {"task_id": "pytorch_rl/112", "ground_truth": "    if rank == 0:", "fpath_tuple": ["pytorch_rl", "examples", "distributed", "distributed_replay_buffer.py"], "context_start_lineno": 0, "line_no": 181, "query_window": {"context": "                max_size=capacity, scratch_dir=\"/tmp/\", device=torch.device(\"cpu\")\n            ),\n            sampler=RandomSampler(),\n            writer=RoundRobinWriter(),\n            collate_fn=lambda x: x,\n        )\n\n\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    print(f\"Rank: {rank}\")\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n    str_init_method = \"tcp://localhost:10000\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=str_init_method\n    )", "metadata": {"fpath_tuple": ["pytorch_rl", "examples", "distributed", "distributed_replay_buffer.py"], "line_no": 181, "task_id": "pytorch_rl/112", "start_line_no": 161, "end_line_no": 181, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "if __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    storage_type = args.storage\n\n    print(f\"Rank: {rank}; Storage: {storage_type}\")\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=\"tcp://localhost:10002\", rpc_timeout=120\n    )\n    if rank == 0:\n        # rank 0 is the trainer\n        rpc.init_rpc(\n            TRAINER_NODE,\n            rank=rank,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,", "metadata": [{"fpath_tuple": ["pytorch_rl", "benchmarks", "storage", "benchmark_sample_latency_over_rpc.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5655172413793104}, {"context": "\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    if rank < 0:\n        rank = int(os.environ[args.rank_var])\n    print(\"rank: \", rank)\n    world_size = args.world_size\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n\n    str_init_method = \"tcp://localhost:10000\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n    )\n\n    if rank == 0:\n        # rank0 is the trainer\n        rpc.init_rpc(", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_td_distributed.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5}, {"context": "                \"next_observation\": torch.randn(\n                    BUFFER_SIZE,\n                    TENSOR_SIZE,\n                ),\n            },\n            batch_size=[BUFFER_SIZE],\n        )\n        self.extend(tds)\n\n\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    storage_type = args.storage\n\n    print(f\"Rank: {rank}; Storage: {storage_type}\")\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "benchmarks", "storage", "benchmark_sample_latency_over_rpc.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4405594405594406}, {"context": "        pool.apply_async(shutdown)\n\n\ndef init_rpc(rank, name, world_size):\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    str_init_method = \"tcp://localhost:10030\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=str_init_method\n    )\n    rpc.init_rpc(\n        name,\n        rank=rank,\n        backend=rpc.BackendType.TENSORPIPE,\n        rpc_backend_options=options,\n        world_size=world_size,\n    )\n\n\ndef shutdown():", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb_distributed.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38571428571428573}, {"context": "    os.environ[\"MASTER_PORT\"] = \"29500\"\n\n    str_init_method = \"tcp://localhost:10000\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n    )\n\n    if rank == 0:\n        # rank0 is the trainer\n        rpc.init_rpc(\n            AGENT_NAME,\n            rank=rank,\n            world_size=world_size,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,\n        )\n\n        if args.task == 0:\n            time.sleep(1)\n            t0 = time.time()", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_td_distributed.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38513513513513514}, {"context": ")\ndef test_funcs(names, func):\n    world_size = len(names)\n    with mp.Pool(world_size) as pool:\n        pool.starmap(\n            init_rpc, ((rank, name, world_size) for rank, name in enumerate(names))\n        )\n        pool.starmap(\n            func, ((rank, name, world_size) for rank, name in enumerate(names))\n        )\n        pool.apply_async(shutdown)\n\n\ndef init_rpc(rank, name, world_size):\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    str_init_method = \"tcp://localhost:10030\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=str_init_method\n    )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb_distributed.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3783783783783784}, {"context": "\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    world_size = args.world_size\n    tensortype = args.tensortype\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n\n    if rank == 0:\n        rpc.init_rpc(\n            AGENT_NAME,\n            rank=rank,\n            world_size=world_size,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,\n        )\n        # create tensor\n        tensor = torch.zeros(10000, 10000)", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_speed_distributed.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.36363636363636365}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_ddpg.py\n# --------------------------------------------------\n# \n#     # init: since we have lazy layers, we should run the network\n#     # once to initialize them\n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.rollout(max_steps=4)\n#         td = td.to(device)\n#         actor(td)\n#         qnet(td)\n# \n#     return actor, qnet\n# \n# \n# ###############################################################################\n# # Evaluator: building your recorder object\n# # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n# # As the training data is obtained using some exploration strategy, the true\n# # performance of our algorithm needs to be assessed in deterministic mode. We\n# # do this using a dedicated class, ``Recorder``, which executes the policy in\n# # the environment at a given frequency and returns some statistics obtained\n# # from these simulations. The following helper function builds this object:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#         )\n#         actor_value = ActorCriticWrapper(policy_po, value_po).to(device)\n# \n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.rollout(max_steps=1000)\n#         td_device = td.to(device)\n#         td_device = actor_value(td_device)  # for init\n#     return actor_value\n# \n# \n# def make_ppo_model(\n#     proof_environment: EnvBase,\n#     cfg: \"DictConfig\",  # noqa: F821\n#     device: DEVICE_TYPING,\n#     in_keys_actor: Optional[Sequence[str]] = None,\n#     observation_key=None,\n#     **kwargs,\n# ) -> ActorValueOperator:\n#     \"\"\"Actor-value model constructor helper function.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n# \n# \n# def make_dreamer(\n#     cfg: \"DictConfig\",  # noqa: F821\n#     proof_environment: EnvBase = None,\n#     device: DEVICE_TYPING = \"cpu\",\n#     action_key: str = \"action\",\n#     value_key: str = \"state_value\",\n#     use_decoder_in_env: bool = False,\n#     obs_norm_state_dict=None,\n# ) -> nn.ModuleList:\n#     \"\"\"Create Dreamer components.\n# \n#     Args:\n#         cfg (DictConfig): Config object.\n#         proof_environment (EnvBase): Environment to initialize the model.\n#         device (DEVICE_TYPING, optional): Device to use.\n#             Defaults to \"cpu\".\n#         action_key (str, optional): Key to use for the action.\n#             Defaults to \"action\".\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#         module=q_net,\n#     )\n# \n#     module = torch.nn.ModuleList([actor, value]).to(device)\n# \n#     # init\n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.rollout(max_steps=1000)\n#         td = td.to(device)\n#         module[0](td)\n#         module[1](td)\n# \n#     return module\n# \n# \n# def make_a2c_model(\n#     proof_environment: EnvBase,\n#     cfg: \"DictConfig\",  # noqa: F821\n#     device: DEVICE_TYPING,\n#     in_keys_actor: Optional[Sequence[str]] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#     del td\n# \n#     return model\n# \n# \n# def make_redq_model(\n#     proof_environment: EnvBase,\n#     cfg: \"DictConfig\",  # noqa: F821\n#     device: DEVICE_TYPING = \"cpu\",\n#     in_keys: Optional[Sequence[str]] = None,\n#     actor_net_kwargs=None,\n#     qvalue_net_kwargs=None,\n#     observation_key=None,\n#     **kwargs,\n# ) -> nn.ModuleList:\n#     \"\"\"Actor and Q-value model constructor helper function for REDQ.\n# \n#     Follows default parameters proposed in REDQ original paper: https://openreview.net/pdf?id=AY8zfZm0tDd.\n#     Other configurations can easily be implemented by modifying this function at will.\n#     A single instance of the Q-value model is returned. It will be multiplicated by the loss function.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#     model = nn.ModuleList([actor, qvalue]).to(device)\n# \n#     # init nets\n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.rollout(1000)\n#         td = td.to(device)\n#         for net in model:\n#             net(td)\n#     del td\n#     return model\n# \n# \n# def make_dreamer(\n#     cfg: \"DictConfig\",  # noqa: F821\n#     proof_environment: EnvBase = None,\n#     device: DEVICE_TYPING = \"cpu\",\n#     action_key: str = \"action\",\n#     value_key: str = \"state_value\",\n#     use_decoder_in_env: bool = False,\n#     obs_norm_state_dict=None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#         module=value_net,\n#     )\n#     model = nn.ModuleList([actor, qvalue, value]).to(device)\n# \n#     # init nets\n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.reset()\n#         td = td.to(device)\n#         for net in model:\n#             net(td)\n#     del td\n# \n#     return model\n# \n# \n# def make_redq_model(\n#     proof_environment: EnvBase,\n#     cfg: \"DictConfig\",  # noqa: F821\n#     device: DEVICE_TYPING = \"cpu\",\n#     in_keys: Optional[Sequence[str]] = None,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\nimport hydra\n\nimport numpy as np\nimport torch\nimport torch.cuda\nimport tqdm\n\nfrom torch import nn, optim\nfrom torchrl.collectors import MultiSyncDataCollector\nfrom torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\n\nfrom torchrl.data.replay_buffers.storages import LazyMemmapStorage\nfrom torchrl.envs import (\n    Compose,\n    DoubleToFloat,\n    EnvCreator,\n    ObservationNorm,\n    ParallelEnv,\n    TransformedEnv,\n)\nfrom torchrl.envs.libs.gym import GymEnv\nfrom torchrl.envs.transforms import RewardScaling\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import (\n    AdditiveGaussianWrapper,\n    MLP,\n    ProbabilisticActor,\n    SafeModule,\n    ValueOperator,\n)\nfrom torchrl.modules.distributions import TanhDelta\n\nfrom torchrl.objectives import SoftUpdate\nfrom torchrl.objectives.td3 import TD3Loss\nfrom torchrl.record.loggers import generate_exp_name, get_logger\n\n\ndef env_maker(task, frame_skip=1, device=\"cpu\", from_pixels=False):\n    return GymEnv(\n        task, \"run\", device=device, frame_skip=frame_skip, from_pixels=from_pixels\n    )\n\n\ndef apply_env_transforms(env, reward_scaling=1.0):\n    transformed_env = TransformedEnv(\n        env,\n        Compose(\n            RewardScaling(loc=0.0, scale=reward_scaling),\n            ObservationNorm(in_keys=[\"observation\"]),\n            DoubleToFloat(in_keys=[\"observation\"], in_keys_inv=[]),\n        ),\n    )\n    return transformed_env\n\n\ndef make_replay_buffer(\n    prb=False,\n    buffer_size=1000000,\n    buffer_scratch_dir=\"/tmp/\",\n    device=\"cpu\",\n    make_replay_buffer=3,\n):\n    if prb:\n        replay_buffer = TensorDictPrioritizedReplayBuffer(\n            buffer_size,\n            alpha=0.7,\n            beta=0.5,\n            pin_memory=False,\n            prefetch=make_replay_buffer,\n            storage=LazyMemmapStorage(\n                buffer_size,\n                scratch_dir=buffer_scratch_dir,\n                device=device,\n            ),\n        )\n    else:\n        replay_buffer = TensorDictReplayBuffer(\n            buffer_size,\n            pin_memory=False,\n            prefetch=make_replay_buffer,\n            storage=LazyMemmapStorage(\n                buffer_size,\n                scratch_dir=buffer_scratch_dir,\n                device=device,\n            ),\n        )\n    return replay_buffer\n\n\n@hydra.main(version_base=None, config_path=\".\", config_name=\"config\")\ndef main(cfg: \"DictConfig\"):  # noqa: F821\n\n    device = (\n        torch.device(\"cuda:0\")\n        if torch.cuda.is_available()\n        and torch.cuda.device_count() > 0\n        and cfg.device == \"cuda:0\"\n        else torch.device(\"cpu\")\n    )\n\n    exp_name = generate_exp_name(\"TD3\", cfg.exp_name)\n    logger = get_logger(\n        logger_type=cfg.logger, logger_name=\"td3_logging\", experiment_name=exp_name\n    )\n\n    torch.manual_seed(cfg.seed)\n    np.random.seed(cfg.seed)\n\n    parallel_env = ParallelEnv(\n        cfg.env_per_collector, EnvCreator(lambda: env_maker(task=cfg.env_name))\n    )\n    parallel_env.set_seed(cfg.seed)\n\n    train_env = apply_env_transforms(parallel_env)\n\n    train_env.transform[1].init_stats(\n        num_iter=cfg.init_env_steps, reduce_dim=(0, 1), cat_dim=0\n    )\n    # check the shape of our summary stats\n    print(\"normalization constant shape:\", train_env.transform[1].loc.shape)\n\n    eval_env = TransformedEnv(\n        ParallelEnv(\n            cfg.env_per_collector, EnvCreator(lambda: env_maker(task=cfg.env_name))\n        ),\n        train_env.transform.clone(),\n    )\n    assert (eval_env.transform[1].loc == train_env.transform[1].loc).all()\n\n    # Create Agent\n\n    # Define Actor Network\n    in_keys = [\"observation\"]\n    action_spec = train_env.action_spec\n    actor_net_kwargs = {\n        \"num_cells\": [256, 256],\n        \"out_features\": action_spec.shape[-1],\n        \"activation_class\": nn.ReLU,\n    }\n\n    actor_net = MLP(**actor_net_kwargs)\n\n    dist_class = TanhDelta\n    dist_kwargs = {\n        \"min\": action_spec.space.minimum,\n        \"max\": action_spec.space.maximum,\n        \"tanh_loc\": False,\n    }\n\n    in_keys_actor = in_keys\n    actor_module = SafeModule(\n        actor_net,\n        in_keys=in_keys_actor,\n        out_keys=[\n            \"param\",\n        ],\n    )\n    actor = ProbabilisticActor(\n        spec=action_spec,\n        in_keys=[\"param\"],\n        module=actor_module,\n        distribution_class=dist_class,\n        distribution_kwargs=dist_kwargs,\n        default_interaction_mode=\"random\",\n        return_log_prob=False,\n    )\n\n    # Define Critic Network\n    qvalue_net_kwargs = {\n        \"num_cells\": [256, 256],\n        \"out_features\": 1,\n        \"activation_class\": nn.ReLU,\n    }\n\n    qvalue_net = MLP(\n        **qvalue_net_kwargs,\n    )\n\n    qvalue = ValueOperator(\n        in_keys=[\"action\"] + in_keys,\n        module=qvalue_net,\n    )\n\n    model = nn.ModuleList([actor, qvalue]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = eval_env.reset()\n        td = td.to(device)\n        for net in model:\n            net(td)", "choices": [{"text": ""}], "metadata": {"task_id": "pytorch_rl/108", "ground_truth": "    del td", "fpath_tuple": ["pytorch_rl", "examples", "td3", "td3.py"], "context_start_lineno": 0, "line_no": 197, "query_window": {"context": "        \"activation_class\": nn.ReLU,\n    }\n\n    qvalue_net = MLP(\n        **qvalue_net_kwargs,\n    )\n\n    qvalue = ValueOperator(\n        in_keys=[\"action\"] + in_keys,\n        module=qvalue_net,\n    )\n\n    model = nn.ModuleList([actor, qvalue]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = eval_env.reset()\n        td = td.to(device)\n        for net in model:\n            net(td)", "metadata": {"fpath_tuple": ["pytorch_rl", "examples", "td3", "td3.py"], "line_no": 197, "task_id": "pytorch_rl/108", "start_line_no": 177, "end_line_no": 197, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        default_interaction_mode=\"random\",\n        return_log_prob=False,\n    )\n\n    qvalue = ValueOperator(\n        in_keys=[\"action\"] + in_keys,\n        module=qvalue_net,\n    )\n    value = ValueOperator(\n        in_keys=in_keys,\n        module=value_net,\n    )\n    model = nn.ModuleList([actor, qvalue, value]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.reset()\n        td = td.to(device)\n        for net in model:\n            net(td)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1210, "start_line_no": 1200, "end_line_no": 1220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6896551724137931}, {"context": "        module=actor_module,\n        distribution_class=dist_class,\n        distribution_kwargs=dist_kwargs,\n        default_interaction_mode=\"random\",\n        return_log_prob=True,\n    )\n    qvalue = ValueOperator(\n        in_keys=in_keys_qvalue,\n        module=qvalue_net,\n    )\n    model = nn.ModuleList([actor, qvalue]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(1000)\n        td = td.to(device)\n        for net in model:\n            net(td)\n    del td\n    return model", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1450, "start_line_no": 1440, "end_line_no": 1460, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6236559139784946}, {"context": "        module=value_net,\n    )\n    model = nn.ModuleList([actor, qvalue, value]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.reset()\n        td = td.to(device)\n        for net in model:\n            net(td)\n    del td\n\n    return model\n\n\ndef make_redq_model(\n    proof_environment: EnvBase,\n    cfg: \"DictConfig\",  # noqa: F821\n    device: DEVICE_TYPING = \"cpu\",\n    in_keys: Optional[Sequence[str]] = None,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1220, "start_line_no": 1210, "end_line_no": 1230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4954954954954955}, {"context": "        in_keys = [\"observation_vector\", \"action\"]\n        out_keys = [\"state_action_value\"]\n        q_net = DdpgMlpQNet(\n            mlp_net_kwargs_net1=value_net_default_kwargs1,\n            mlp_net_kwargs_net2=value_net_default_kwargs2,\n        )\n\n    value = state_class(\n        in_keys=in_keys,\n        out_keys=out_keys,\n        module=q_net,\n    )\n\n    module = torch.nn.ModuleList([actor, value]).to(device)\n\n    # init\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(max_steps=1000)\n        td = td.to(device)\n        module[0](td)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.46296296296296297}, {"context": "    model = nn.ModuleList([actor, qvalue]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(1000)\n        td = td.to(device)\n        for net in model:\n            net(td)\n    del td\n    return model\n\n\ndef make_dreamer(\n    cfg: \"DictConfig\",  # noqa: F821\n    proof_environment: EnvBase = None,\n    device: DEVICE_TYPING = \"cpu\",\n    action_key: str = \"action\",\n    value_key: str = \"state_value\",\n    use_decoder_in_env: bool = False,\n    obs_norm_state_dict=None,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1460, "start_line_no": 1450, "end_line_no": 1470, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4098360655737705}, {"context": "            default_interaction_mode=\"random\",\n        )\n\n        value_net = MLP(\n            num_cells=[64, 64],\n            out_features=1,\n        )\n        value_po = ValueOperator(\n            value_net,\n            in_keys=in_keys_critic,\n        )\n        actor_value = ActorCriticWrapper(policy_po, value_po).to(device)\n\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(max_steps=1000)\n        td_device = td.to(device)\n        td_device = actor_value(td_device)  # for init\n    return actor_value\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 700, "start_line_no": 690, "end_line_no": 710, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.39814814814814814}, {"context": "        num_cells=[num_cells] * num_layers,\n        activation_class=nn.Tanh,\n        out_features=1,\n    )\n\n    in_keys = in_keys + [\"action\"]\n    qnet = ValueOperator(\n        in_keys=in_keys,\n        module=q_net,\n    ).to(device)\n\n    # init: since we have lazy layers, we should run the network\n    # once to initialize them\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(max_steps=4)\n        td = td.to(device)\n        actor(td)\n        qnet(td)\n\n    return actor, qnet", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_ddpg.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.39473684210526316}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_transforms.py\n# --------------------------------------------------\n#         obs = obs.view(-1, obs.shape[-1])\n#         mean = obs.mean(0)\n#         assert (abs(mean) < thr).all()\n#         std = obs.std(0)\n#         assert (abs(std - 1) < thr).all()\n#         if not env_t.is_closed:\n#             env_t.close()\n#         self.SEED = 0\n# \n# \n# def test_added_transforms_are_in_eval_mode_trivial():\n#     base_env = ContinuousActionVecMockEnv()\n#     t = TransformedEnv(base_env)\n#     assert not t.transform.training\n# \n#     t.train()\n#     assert t.transform.training\n# \n# \n# def test_added_transforms_are_in_eval_mode():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#         td_device = env_serial.rollout(max_steps=10)\n#         assert td_device.device == torch.device(device), env_serial\n# \n#         if open_before:\n#             td_cpu = env_parallel.rollout(max_steps=10)\n#             assert td_cpu.device == torch.device(\"cpu\")\n#         env_parallel = env_parallel.to(device)\n#         assert env_parallel.observation_spec.device == torch.device(device)\n#         assert env_parallel.action_spec.device == torch.device(device)\n#         assert env_parallel.reward_spec.device == torch.device(device)\n#         assert env_parallel.device == torch.device(device)\n#         td_device = env_parallel.reset()\n#         assert td_device.device == torch.device(device), env_parallel\n#         td_device = env_parallel.rand_step()\n#         assert td_device.device == torch.device(device), env_parallel\n#         td_device = env_parallel.rollout(max_steps=10)\n#         assert td_device.device == torch.device(device), env_parallel\n# \n#         env_parallel.close()\n#         env_serial.close()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#             assert td_cpu.device == torch.device(\"cpu\")\n#         env_serial = env_serial.to(device)\n#         assert env_serial.observation_spec.device == torch.device(device)\n#         assert env_serial.action_spec.device == torch.device(device)\n#         assert env_serial.reward_spec.device == torch.device(device)\n#         assert env_serial.device == torch.device(device)\n#         td_device = env_serial.reset()\n#         assert td_device.device == torch.device(device), env_serial\n#         td_device = env_serial.rand_step()\n#         assert td_device.device == torch.device(device), env_serial\n#         td_device = env_serial.rollout(max_steps=10)\n#         assert td_device.device == torch.device(device), env_serial\n# \n#         if open_before:\n#             td_cpu = env_parallel.rollout(max_steps=10)\n#             assert td_cpu.device == torch.device(\"cpu\")\n#         env_parallel = env_parallel.to(device)\n#         assert env_parallel.observation_spec.device == torch.device(device)\n#         assert env_parallel.action_spec.device == torch.device(device)\n#         assert env_parallel.reward_spec.device == torch.device(device)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/utils.py\n# --------------------------------------------------\n#     if \"steps_to_next_obs\" in tensordict.keys():\n#         steps_to_next_obs = tensordict.get(\"steps_to_next_obs\").squeeze(-1)\n#     else:\n#         steps_to_next_obs = 1\n# \n#     rewards = tensordict.get(\"reward\").squeeze(-1)\n#     done = tensordict.get(\"done\").squeeze(-1)\n# \n#     if pred_next_val is None:\n#         next_td = step_mdp(tensordict)  # next_observation -> observation\n#         next_td = next_td.select(*operator.in_keys)\n#         operator(next_td, **kwargs)\n#         pred_next_val_detach = next_td.get(next_val_key).squeeze(-1)\n#     else:\n#         pred_next_val_detach = pred_next_val.squeeze(-1)\n#     done = done.to(torch.float)\n#     target_value = (1 - done) * pred_next_val_detach\n#     rewards = rewards.to(torch.float)\n#     target_value = rewards + (gamma**steps_to_next_obs) * target_value\n#     return target_value\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#     )\n#     assert (td[\"done\"] == 1).all()\n#     assert (td[\"next\"][\"observation\"] == max_steps + 1).all()\n# \n#     _reset = torch.randint(low=0, high=2, size=env.batch_size, dtype=torch.bool)\n#     td_reset = env.reset(\n#         TensorDict({\"_reset\": _reset}, batch_size=env.batch_size, device=env.device)\n#     )\n# \n#     assert (td_reset[\"done\"][_reset] == 0).all()\n#     assert (td_reset[\"observation\"][_reset] == 0).all()\n#     assert (td_reset[\"done\"][~_reset] == 1).all()\n#     assert (td_reset[\"observation\"][~_reset] == max_steps + 1).all()\n# \n# \n# @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n# def test_seed():\n#     torch.manual_seed(0)\n#     env1 = GymEnv(PENDULUM_VERSIONED)\n#     env1.set_seed(0)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/torchrl_demo.py\n# --------------------------------------------------\n#     if tensordict[\"done\"].any():\n#         break\n#     tensordict = step_mdp(tensordict)  # roughly equivalent to obs = next_obs\n# tensordicts_stack = torch.stack(tensordicts, 0)\n# print(\"total steps:\", i)\n# print(tensordicts_stack)\n# \n# ###############################################################################\n# \n# (tensordicts_stack == tensordicts_prealloc).all()\n# \n# ###############################################################################\n# \n# # helper\n# torch.manual_seed(0)\n# env.set_seed(0)\n# tensordict_rollout = env.rollout(policy=actor, max_steps=max_steps)\n# tensordict_rollout\n# \n# ###############################################################################\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport pkg_resources\nimport torch\nfrom tensordict.nn.probabilistic import (  # noqa\n    interaction_mode as exploration_mode,\n    set_interaction_mode as set_exploration_mode,\n)\nfrom tensordict.tensordict import TensorDictBase\n\nAVAILABLE_LIBRARIES = {pkg.key for pkg in pkg_resources.working_set}\n\n\nclass _classproperty(property):\n    def __get__(self, cls, owner):\n        return classmethod(self.fget).__get__(None, owner)()\n\n\ndef step_mdp(\n    tensordict: TensorDictBase,\n    next_tensordict: TensorDictBase = None,\n    keep_other: bool = True,\n    exclude_reward: bool = True,\n    exclude_done: bool = True,\n    exclude_action: bool = True,\n    _run_check: bool = True,\n) -> TensorDictBase:\n    \"\"\"Creates a new tensordict that reflects a step in time of the input tensordict.\n\n    Given a tensordict retrieved after a step, returns the :obj:`\"next\"` indexed-tensordict.\n\n    Args:\n        tensordict (TensorDictBase): tensordict with keys to be renamed\n        next_tensordict (TensorDictBase, optional): destination tensordict\n        keep_other (bool, optional): if True, all keys that do not start with :obj:`'next_'` will be kept.\n            Default is True.\n        exclude_reward (bool, optional): if True, the :obj:`\"reward\"` key will be discarded\n            from the resulting tensordict.\n            Default is True.\n        exclude_done (bool, optional): if True, the :obj:`\"done\"` key will be discarded\n            from the resulting tensordict.\n            Default is True.\n        exclude_action (bool, optional): if True, the :obj:`\"action\"` key will be discarded\n            from the resulting tensordict.\n            Default is True.\n\n    Returns:\n         A new tensordict (or next_tensordict) containing the tensors of the t+1 step.\n\n    Examples:\n    This funtion allows for this kind of loop to be used:\n        >>> td_out = []\n        >>> env = make_env()\n        >>> policy = make_policy()\n        >>> td = env.reset()\n        >>> for i in range(max_steps):\n        >>>     td = env.step(td)\n        >>>     next_td = step_mdp(td)\n        >>>     assert next_td is not td # make sure that keys are not overwritten\n        >>>     td_out.append(td)\n        >>>     td = next_td\n        >>> td_out = torch.stack(td_out, 0)\n        >>> print(td_out) # should contain keys 'observation', 'next_observation', 'action', 'reward', 'done' or similar\n\n    \"\"\"\n    other_keys = []\n    prohibited = set()\n    if exclude_done:", "choices": [{"text": "prohibited.add(\"done\")"}], "metadata": {"task_id": "pytorch_rl/28", "ground_truth": "        prohibited.add(\"done\")", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "utils.py"], "context_start_lineno": 0, "line_no": 71, "query_window": {"context": "\n    Examples:\n    This funtion allows for this kind of loop to be used:\n        >>> td_out = []\n        >>> env = make_env()\n        >>> policy = make_policy()\n        >>> td = env.reset()\n        >>> for i in range(max_steps):\n        >>>     td = env.step(td)\n        >>>     next_td = step_mdp(td)\n        >>>     assert next_td is not td # make sure that keys are not overwritten\n        >>>     td_out.append(td)\n        >>>     td = next_td\n        >>> td_out = torch.stack(td_out, 0)\n        >>> print(td_out) # should contain keys 'observation', 'next_observation', 'action', 'reward', 'done' or similar\n\n    \"\"\"\n    other_keys = []\n    prohibited = set()\n    if exclude_done:", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "utils.py"], "line_no": 71, "task_id": "pytorch_rl/28", "start_line_no": 51, "end_line_no": 71, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "# equivalent\ntorch.manual_seed(0)\nenv.set_seed(0)\n\nmax_steps = 100\ntensordict = env.reset()\ntensordicts = []\nfor _ in range(max_steps):\n    actor(tensordict)\n    tensordicts.append(env.step(tensordict))\n    if tensordict[\"done\"].any():\n        break\n    tensordict = step_mdp(tensordict)  # roughly equivalent to obs = next_obs\ntensordicts_stack = torch.stack(tensordicts, 0)\nprint(\"total steps:\", i)\nprint(tensordicts_stack)\n\n###############################################################################\n\n(tensordicts_stack == tensordicts_prealloc).all()", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "torchrl_demo.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26356589147286824}, {"context": "\n    for i in range(max_steps):\n        td = env.step(\n            TensorDict({\"action\": action}, batch_size=env.batch_size, device=env.device)\n        )\n        assert (td[\"done\"] == 0).all()\n        assert (td[\"next\"][\"observation\"] == i + 1).all()\n\n    td = env.step(\n        TensorDict({\"action\": action}, batch_size=env.batch_size, device=env.device)\n    )\n    assert (td[\"done\"] == 1).all()\n    assert (td[\"next\"][\"observation\"] == max_steps + 1).all()\n\n    _reset = torch.randint(low=0, high=2, size=env.batch_size, dtype=torch.bool)\n    td_reset = env.reset(\n        TensorDict({\"_reset\": _reset}, batch_size=env.batch_size, device=env.device)\n    )\n\n    assert (td_reset[\"done\"][_reset] == 0).all()", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 960, "start_line_no": 950, "end_line_no": 970, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2619047619047619}, {"context": "            Default: 'state_action_value'\n        gamma (float, optional): return discount rate.\n            default: 0.99\n        pred_next_val (Tensor, optional): the next state value can be provided if it is not computed with the operator.\n\n    Returns:\n        a Tensor of the size of the input tensordict containing the predicted value state.\n\n    \"\"\"\n    if \"steps_to_next_obs\" in tensordict.keys():\n        steps_to_next_obs = tensordict.get(\"steps_to_next_obs\").squeeze(-1)\n    else:\n        steps_to_next_obs = 1\n\n    rewards = tensordict.get(\"reward\").squeeze(-1)\n    done = tensordict.get(\"done\").squeeze(-1)\n\n    if pred_next_val is None:\n        next_td = step_mdp(tensordict)  # next_observation -> observation\n        next_td = next_td.select(*operator.in_keys)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "utils.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2550335570469799}, {"context": "        assert env0.device == torch.device(device)\n        td_device = env0.reset()\n        assert td_device.device == torch.device(device), env0\n        td_device = env0.rand_step()\n        assert td_device.device == torch.device(device), env0\n        td_device = env0.rollout(max_steps=10)\n        assert td_device.device == torch.device(device), env0\n\n        if open_before:\n            td_cpu = env_serial.rollout(max_steps=10)\n            assert td_cpu.device == torch.device(\"cpu\")\n        env_serial = env_serial.to(device)\n        assert env_serial.observation_spec.device == torch.device(device)\n        assert env_serial.action_spec.device == torch.device(device)\n        assert env_serial.reward_spec.device == torch.device(device)\n        assert env_serial.device == torch.device(device)\n        td_device = env_serial.reset()\n        assert td_device.device == torch.device(device), env_serial\n        td_device = env_serial.rand_step()\n        assert td_device.device == torch.device(device), env_serial", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2549019607843137}, {"context": "            assert td_cpu.device == torch.device(\"cpu\")\n        env_serial = env_serial.to(device)\n        assert env_serial.observation_spec.device == torch.device(device)\n        assert env_serial.action_spec.device == torch.device(device)\n        assert env_serial.reward_spec.device == torch.device(device)\n        assert env_serial.device == torch.device(device)\n        td_device = env_serial.reset()\n        assert td_device.device == torch.device(device), env_serial\n        td_device = env_serial.rand_step()\n        assert td_device.device == torch.device(device), env_serial\n        td_device = env_serial.rollout(max_steps=10)\n        assert td_device.device == torch.device(device), env_serial\n\n        if open_before:\n            td_cpu = env_parallel.rollout(max_steps=10)\n            assert td_cpu.device == torch.device(\"cpu\")\n        env_parallel = env_parallel.to(device)\n        assert env_parallel.observation_spec.device == torch.device(device)\n        assert env_parallel.action_spec.device == torch.device(device)\n        assert env_parallel.reward_spec.device == torch.device(device)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 750, "start_line_no": 740, "end_line_no": 760, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2524271844660194}, {"context": "        env_t = TransformedEnv(env, t)\n        td = env_t.reset()\n        tds = []\n        for _ in range(N):\n            td = env_t.rand_step(td)\n            tds.append(td.clone())\n            if td.get(\"done\").any():\n                td = env_t.reset()\n        tds = torch.stack(tds, 0)\n        obs = tds.get((\"next\", \"observation\"))\n        obs = obs.view(-1, obs.shape[-1])\n        mean = obs.mean(0)\n        assert (abs(mean) < thr).all()\n        std = obs.std(0)\n        assert (abs(std - 1) < thr).all()\n        if not env_t.is_closed:\n            env_t.close()\n        self.SEED = 0\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_transforms.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2518518518518518}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         ----------\n#         data_loader : DataLoader\n#             A data loader.\n# \n#         Returns\n#         -------\n#         TargetsLoader\n#             A targets loader.\n#         \"\"\"\n#         return cls(targets_loader=FromDataLoaderToTargetsLoader(data_loader))\n# \n#     @classmethod\n#     def from_array_targets(\n#         cls,\n#         targets: Array,\n#         batch_size: Optional[int] = None,\n#         shuffle: bool = False,\n#         prefetch: bool = False,\n#     ) -> TargetsLoader:\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/classification.py\n# --------------------------------------------------\n#         val_targets: Optional[Array]\n#             Validation target variables.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_outputs, calib_targets)\n#         if val_outputs is not None:\n#             self._check_output_dim(val_outputs, val_targets)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.mean,\n#             calib_outputs=calib_outputs,\n#             calib_targets=calib_targets,\n#             val_outputs=val_outputs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/regression.py\n# --------------------------------------------------\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_outputs, calib_targets)\n#         if val_outputs is not None:\n#             self._check_output_dim(val_outputs, val_targets)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.variance,\n#             calib_outputs=calib_outputs,\n#             calib_targets=calib_targets,\n#             val_outputs=val_outputs,\n#             val_targets=val_targets,\n#             calib_config=calib_config,\n#         )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/classification.py\n# --------------------------------------------------\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n#             self._check_output_dim(val_data_loader)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.mean,\n#             calib_data_loader=calib_data_loader,\n#             val_data_loader=val_data_loader,\n#             calib_config=calib_config,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/classification.py\n# --------------------------------------------------\n#         self._check_output_dim(calib_outputs, calib_targets)\n#         if val_outputs is not None:\n#             self._check_output_dim(val_outputs, val_targets)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.mean,\n#             calib_outputs=calib_outputs,\n#             calib_targets=calib_targets,\n#             val_outputs=val_outputs,\n#             val_targets=val_targets,\n#             calib_config=calib_config,\n#         )\n# \n#     def _check_output_dim(self, outputs: jnp.ndarray, targets: jnp.array):\n#         n_classes = len(np.unique(targets))\n#         if outputs.shape[1] != n_classes:\n#             raise ValueError(\n#                 f\"\"\"`outputs.shape[1]` must be the same as the dimension of the number of classes in `targets`. \n#                 However, `outputs.shape[1]={outputs.shape[1]}` and `len(np.unique(targets))={n_classes}`.\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/regression.py\n# --------------------------------------------------\n#         if val_outputs is not None:\n#             self._check_output_dim(val_outputs, val_targets)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.variance,\n#             calib_outputs=calib_outputs,\n#             calib_targets=calib_targets,\n#             val_outputs=val_outputs,\n#             val_targets=val_targets,\n#             calib_config=calib_config,\n#         )\n# \n#     def _check_output_dim(self, outputs: jnp.ndarray, targets: jnp.array):\n#         if outputs.shape[1] != 2 * targets.shape[1]:\n#             raise ValueError(\n#                 f\"\"\"`outputs.shape[1]` must be twice the dimension of the target variables in `targets`, with \n#                 first and second halves corresponding to the mean and log-variance of the likelihood, respectively. \n#                 However, `outputs.shape[1]={outputs.shape[1]}` and `targets.shape[1]={targets.shape[1]}`.\"\"\"\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/classification.py\n# --------------------------------------------------\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n#             self._check_output_dim(val_data_loader)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.mean,\n#             calib_data_loader=calib_data_loader,\n#             val_data_loader=val_data_loader,\n#             calib_config=calib_config,\n#         )\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n nn.Module,\n        likelihood_log_variance_model: nn.Module,\n        prior: Prior = IsotropicGaussianPrior(),\n        posterior_approximator: PosteriorApproximator = SWAGPosteriorApproximator(),\n        output_calibrator: Optional[nn.Module] = RegressionTemperatureScaler(),\n        seed: int = 0,\n    ):\n        r\"\"\"\n        A probabilistic regressor class.\n\n        Parameters\n        ----------\n        model : nn.Module\n            A model describing the deterministic relation between inputs and outputs. It characterizes the mean model\n            of the likelihood function. The outputs must belong to the same space as the target variables.\n            Let :math:`x` be input variables and :math:`w` the random model parameters. Then the model is described by\n            a function :math:`\\mu(w, x)`.\n        likelihood_log_variance_model: nn.Module\n            A model characterizing the log-variance of a Gaussian likelihood function. The outputs must belong to the\n            same space as the target variables. Let :math:`x` be input variables and :math:`w` the random model\n            parameters. Then the model is described by a function :math:`\\log\\sigma^2(w, x)`.\n        prior : Prior\n            A prior distribution object. The default is an isotropic standard Gaussian. Let :math:`w` be the random\n            model parameters. Then the prior is defined by a distribution :math:`p(w)`.\n        posterior_approximator : PosteriorApproximator\n            A posterior approximation method. The default method is SWAG.\n        output_calibrator : Optional[nn.Module]\n            An output calibrator object. The default is temperature scaling for regression, which inflates the variance\n            of the likelihood with a scalar temperature parameter. Given outputs :math:`o` of the model manager, the\n            output calibrator is described by a function :math:`g(\\phi, o)`, where `phi` are deterministic\n            calibration parameters.\n        seed: int\n            A random seed.\n\n        Attributes\n        ----------\n        model : nn.Module\n            See `model` in `Parameters`.\n        model_manager : RegressionModelManager\n            This object orchestrates the model's forward pass. Given a mean model :math:`\\mu(w, x)` and a log-variance\n            model :math:`\\log\\sigma^2`, the model manager concatenates the two into\n            :math:`f(w, x)=[\\mu(w, x), \\log\\sigma^2(w, x)]`.\n        output_calibrator : nn.Module\n            See `output_calibrator` in `Parameters`.\n        prob_output_layer : RegressionProbOutputLayer\n            This object characterizes the distribution of the target variable given the calibrated outputs. It is\n            defined by :math:`p(y|\\omega)=\\text{Categorical}(p=softmax(\\omega))`, where :math:`\\omega` denote the\n            calibrated outputs and :math:`y` denotes a target variable.\n        likelihood : RegressionLikelihood\n            The likelihood function. This is defined by\n            :math:`p(y|w, \\phi, x) = \\text{Categorical}(p=\\text{softmax}(g(\\phi, f(w, x)))`.\n        prior : Prior\n            See `prior` in `Parameters`.\n        joint : Joint\n            This object describes the joint distribution of the target variables and the random parameters\n            given the input variables and the calibration parameters, that is :math:`p(y, w|x, \\phi)`.\n        posterior_approximator : PosteriorApproximator\n            See `posterior_approximator` in `Parameters`.\n        posterior : Posterior\n            This is the posterior approximation of the random parameters given the training data and the\n            calibration parameters, that is :math:`p(w|\\mathcal{D}, \\phi)`, where :math:`\\mathcal{D}` denotes the\n            training data set and :math:`\\phi` the calibration parameters.\n        predictive : RegressionPredictive\n            This denotes the predictive distribution, that is :math:`p(y|\\phi, x, \\mathcal{D})`. Its statistics are\n            approximated via a Monte Carlo approach by sampling from the posterior approximation.\n        \"\"\"\n        self.model = model\n        self.lik_log_var = likelihood_log_variance_model\n        self.prior = prior\n        self.output_calibrator = output_calibrator\n\n        self.model_manager = RegressionModelManager(\n            model, likelihood_log_variance_model\n        )\n        self.output_calib_manager = OutputCalibManager(\n            output_calibrator=output_calibrator\n        )\n        self.prob_output_layer = RegressionProbOutputLayer()\n\n        self.likelihood = RegressionLikelihood(\n            self.model_manager, self.prob_output_layer, self.output_calib_manager\n        )\n        self.joint = Joint(self.prior, self.likelihood)\n\n        self.posterior = getattr(\n            PosteriorApproximations, posterior_approximator.__str__()\n        ).value(joint=self.joint, posterior_approximator=posterior_approximator)\n        self.predictive = RegressionPredictive(self.posterior)\n\n        super().__init__(seed=seed)\n\n    def _check_output_dim(self, data_loader: DataLoader):\n        output_dim = 0\n        for x, y in data_loader:\n            input_shape = x.shape[1:]\n            output_dim = y.shape[1]\n            break\n        if output_dim == 0:\n            raise ValueError(\n                \"\"\"`_data_loader` is either empty or incorrectly constructed.\"\"\"\n            )\n        s = self.joint.init(input_shape)\n        outputs = self.model_manager.apply(\n            params=s.params, inputs=np.zeros((1,) + input_shape), mutable=s.mutable\n        )\n        if outputs.shape[1] != 2 * output_dim:\n            raise ValueError(\n                f\"\"\"The outputs dimension of both `model` and `likelihood_log_variance_model` must be the same as\n                the dimension of the target variables in `_data_loader`. However, {outputs.shape[1] // 2} and \n                {output_dim} were found, respectively.\"\"\"\n            )\n\n    def train(\n        self,\n        train_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_data_loader: Optional[DataLoader] = None,\n        fit_config: FitConfig = FitConfig(),\n        calib_config: CalibConfig = CalibConfig(),\n        **fit_kwargs,\n    ) -> Dict[str, Status]:\n        self._check_output_dim(train_data_loader)\n        return super().train(\n            train_data_loader,\n            val_data_loader,\n            calib_data_loader,\n            fit_config,\n            calib_config,\n            **fit_kwargs,\n        )\n\n    def calibrate(\n        self,\n        calib_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_config: CalibConfig = CalibConfig(),\n    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_data_loader)\n        if val_data_loader is not None:\n            self._check_output_dim(val_data_loader)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.variance,", "choices": [{"text": "calib_data_loader=calib_data_loader,"}], "metadata": {"task_id": "awslabs_fortuna/94", "ground_truth": "            calib_data_loader=calib_data_loader,", "fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "regression.py"], "context_start_lineno": 30, "line_no": 191, "query_window": {"context": "        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_data_loader)\n        if val_data_loader is not None:\n            self._check_output_dim(val_data_loader)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.variance,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "regression.py"], "line_no": 191, "task_id": "awslabs_fortuna/94", "start_line_no": 171, "end_line_no": 191, "window_size": 20, "context_start_lineno": 30, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_data_loader)\n        if val_data_loader is not None:\n            self._check_output_dim(val_data_loader)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.mean,\n            calib_data_loader=calib_data_loader,\n            val_data_loader=val_data_loader,\n            calib_config=calib_config,\n        )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "classification.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 189, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.8493150684931506}, {"context": "\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_outputs, calib_targets)\n        if val_outputs is not None:\n            self._check_output_dim(val_outputs, val_targets)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.variance,\n            calib_outputs=calib_outputs,\n            calib_targets=calib_targets,\n            val_outputs=val_outputs,\n            val_targets=val_targets,\n            calib_config=calib_config,\n        )\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "regression.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7236842105263158}, {"context": "        val_targets: Optional[Array]\n            Validation target variables.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_outputs, calib_targets)\n        if val_outputs is not None:\n            self._check_output_dim(val_outputs, val_targets)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.mean,\n            calib_outputs=calib_outputs,\n            calib_targets=calib_targets,\n            val_outputs=val_outputs,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "classification.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7142857142857143}, {"context": "    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_data_loader)\n        if val_data_loader is not None:", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "classification.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6625}, {"context": "        calib_outputs: Array\n            Calibration model outputs.\n        calib_targets: Array\n            Calibration target variables.\n        val_outputs: Optional[Array]\n            Validation model outputs.\n        val_targets: Optional[Array]\n            Validation target variables.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_outputs, calib_targets)\n        if val_outputs is not None:\n            self._check_output_dim(val_outputs, val_targets)\n        return super()._calibrate(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "regression.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5632183908045977}, {"context": "        Calibrate the model outputs.\n\n        Parameters\n        ----------\n        calib_outputs: Array\n            Calibration model outputs.\n        calib_targets: Array\n            Calibration target variables.\n        val_outputs: Optional[Array]\n            Validation model outputs.\n        val_targets: Optional[Array]\n            Validation target variables.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "classification.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3977272727272727}, {"context": "\n    def __iter__(self):\n        yield from self._targets_loader()\n\n    @classmethod\n    def from_data_loader(cls, data_loader: DataLoader) -> TargetsLoader:\n        \"\"\"\n        Reduce a data loader to a targets loader.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader.\n\n        Returns\n        -------\n        TargetsLoader\n            A targets loader.\n        \"\"\"\n        return cls(targets_loader=FromDataLoaderToTargetsLoader(data_loader))", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.27722772277227725}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#                 metrics=metrics,\n#             )\n#             # keep track of training losses and metrics [granularity=batch]\n#             training_losses_and_metrics_epoch_all_steps.append(\n#                 training_losses_and_metrics_current_batch\n#             )\n#             # logging\n#             if verbose:\n#                 training_batch_metrics_str = \" | \".join(\n#                     [\n#                         f\"{m}: {round(float(v), 5)}\"\n#                         for m, v in training_losses_and_metrics_current_batch.items()\n#                     ]\n#                 )\n#                 progress_bar.set_description(\n#                     f\"Epoch: {current_epoch + 1} | \" + training_batch_metrics_str,\n#                     refresh=True,\n#                 )\n# \n#         # compute training losses and metrics avg for the current epoch + other ops (if needed)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#                 # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n#                 for k in val_losses_and_metrics_current_epoch.keys():\n#                     val_losses_and_metrics[k].append(\n#                         val_losses_and_metrics_current_epoch[k]\n#                     )\n#                 # check for early stopping\n#                 if self.is_early_stopping_active and self._early_stopping.should_stop:\n#                     logging.info(\"[Early Stopping] Stopping training...\")\n#                     break\n# \n#         # aggregate\n#         training_status = {\n#             k: jnp.array(v) for k, v in training_losses_and_metrics.items()\n#         }\n#         val_status = {k: jnp.array(v) for k, v in val_losses_and_metrics.items()}\n#         status = dict(**training_status, **val_status)\n# \n#         state = self.on_train_end(state)\n#         return state, status\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#                     metrics=metrics,\n#                     rng=rng,\n#                     state=state,\n#                     val_data_loader=val_data_loader,\n#                     val_outputs_loader=val_outputs_loader,\n#                     val_dataset_size=val_dataset_size,\n#                     verbose=verbose,\n#                 )\n#                 if verbose:\n#                     logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)\n#                 # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n#                 for k in val_losses_and_metrics_current_epoch.keys():\n#                     val_losses_and_metrics[k].append(\n#                         val_losses_and_metrics_current_epoch[k]\n#                     )\n#                 # check for early stopping\n#                 if self.is_early_stopping_active and self._early_stopping.should_stop:\n#                     logging.info(\"[Early Stopping] Stopping training...\")\n#                     break\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#                 calib_outputs_loader,\n#                 training_dataset_size,\n#                 verbose,\n#                 progress_bar,\n#             )\n#             # keep track of training losses and metrics [granularity=epoch]\n#             for k in training_losses_and_metrics_current_epoch.keys():\n#                 training_losses_and_metrics[k].append(\n#                     training_losses_and_metrics_current_epoch[k]\n#                 )\n# \n#             # validation loop\n#             if self.should_perform_validation(val_data_loader, epoch):\n#                 # performance evaluation on the whole validation dataset\n#                 state = self.on_val_start(state)\n#                 (\n#                     val_losses_and_metrics_current_epoch,\n#                     val_epoch_metrics_str,\n#                 ) = self._val_loop(\n#                     fun=fun,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/training/trainer.py\n# --------------------------------------------------\n#             )\n#             # keep track of training losses and metrics [granularity=epoch]\n#             for k in training_losses_and_metrics_current_epoch.keys():\n#                 training_losses_and_metrics[k].append(\n#                     training_losses_and_metrics_current_epoch[k]\n#                 )\n# \n#             # validation loop\n#             if self.should_perform_validation(validation_dataloader, epoch):\n#                 # performance evaluation on the whole validation dataset\n#                 state = self.on_validation_start(state)\n#                 (\n#                     validation_losses_and_metrics_current_epoch,\n#                     validation_epoch_metrics_str,\n#                 ) = self._validation_loop(\n#                     fun=fun,\n#                     metrics=metrics,\n#                     rng=rng,\n#                     state=state,\n#                     training_kwargs=training_kwargs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/training/trainer.py\n# --------------------------------------------------\n#                 state = self.on_validation_start(state)\n#                 (\n#                     validation_losses_and_metrics_current_epoch,\n#                     validation_epoch_metrics_str,\n#                 ) = self._validation_loop(\n#                     fun=fun,\n#                     metrics=metrics,\n#                     rng=rng,\n#                     state=state,\n#                     training_kwargs=training_kwargs,\n#                     validation_dataloader=validation_dataloader,\n#                     validation_dataset_size=validation_dataset_size,\n#                     verbose=verbose,\n#                     unravel=unravel,\n#                 )\n#                 if verbose:\n#                     logging.info(\n#                         f\"Epoch: {epoch + 1} | \" + validation_epoch_metrics_str\n#                     )\n#                 # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n# \n#             # validation loop\n#             if self.should_perform_validation(val_data_loader, epoch):\n#                 # performance evaluation on the whole validation dataset\n#                 state = self.on_val_start(state)\n#                 (\n#                     val_losses_and_metrics_current_epoch,\n#                     val_epoch_metrics_str,\n#                 ) = self._val_loop(\n#                     fun=fun,\n#                     metrics=metrics,\n#                     rng=rng,\n#                     state=state,\n#                     val_data_loader=val_data_loader,\n#                     val_outputs_loader=val_outputs_loader,\n#                     val_dataset_size=val_dataset_size,\n#                     verbose=verbose,\n#                 )\n#                 if verbose:\n#                     logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport abc\nimport collections\nimport logging\nfrom functools import partial\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Union\n\nimport jax\nimport jax.numpy as jnp\nfrom flax import jax_utils\nfrom flax.training.common_utils import stack_forest\nfrom jax import lax, random, value_and_grad\nfrom jax._src.prng import PRNGKeyArray\nfrom jax.tree_util import tree_map\nfrom tqdm import trange\nfrom tqdm.std import tqdm as TqdmDecorator\n\nfrom fortuna.calibration.state import CalibState\nfrom fortuna.data.loader import DataLoader, TargetsLoader\nfrom fortuna.training.mixin import (InputValidatorMixin,\n                                    WithCheckpointingMixin,\n                                    WithEarlyStoppingMixin)\nfrom fortuna.typing import Array, CalibMutable, CalibParams, Path, Status\nfrom fortuna.utils.builtins import HashableMixin\n\n\nclass CalibModelCalibrator(\n    HashableMixin,\n    WithCheckpointingMixin,\n    WithEarlyStoppingMixin,\n    InputValidatorMixin,\n    metaclass=abc.ABCMeta,\n):\n    def __init__(\n        self,\n        *args,\n        calib_outputs: Array,\n        calib_targets: Array,\n        predict_fn: Callable[[jnp.ndarray], jnp.ndarray],\n        uncertainty_fn: Callable[[jnp.ndarray], jnp.ndarray],\n        val_outputs: Array,\n        val_targets: Array,\n        save_checkpoint_dir: Optional[Path] = None,\n        save_every_n_steps: Optional[int] = None,\n        keep_top_n_checkpoints: int = 2,\n        disable_training_metrics_computation: bool = False,\n        eval_every_n_epochs: int = 1,\n        **kwargs,\n    ):\n        super(CalibModelCalibrator, self).__init__(*args, **kwargs)\n        self._calib_outputs = calib_outputs\n        self._calib_targets = calib_targets\n        self._val_outputs = val_outputs\n        self._val_targets = val_targets\n        self.predict_fn = predict_fn\n        self.uncertainty_fn = uncertainty_fn\n        self.save_checkpoint_dir = save_checkpoint_dir\n        self.save_every_n_steps = save_every_n_steps\n        self.keep_top_n_checkpoints = keep_top_n_checkpoints\n        self.disable_training_metrics_computation = disable_training_metrics_computation\n        self.eval_every_n_epochs = eval_every_n_epochs\n        self.multi_device = False\n\n    def train(\n        self,\n        rng: PRNGKeyArray,\n        state: CalibState,\n        fun: Callable,\n        n_epochs: int = 1,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ] = None,\n        verbose: bool = True,\n    ) -> Tuple[CalibState, Status]:\n        training_losses_and_metrics = collections.defaultdict(list)\n        val_losses_and_metrics = collections.defaultdict(list)\n\n        state, targets, outputs, rng = self.on_train_start(\n            state,\n            [self._calib_targets, self._val_targets],\n            [self._calib_outputs, self._val_outputs],\n            rng,\n        )\n        calib_targets, val_targets = targets\n        calib_outputs, val_outputs = outputs\n\n        progress_bar = trange(n_epochs, desc=\"Epoch\")\n        for epoch in progress_bar:\n            # training loop\n            (\n                state,\n                training_losses_and_metrics_current_epoch,\n                training_batch_metrics_str,\n            ) = self._training_loop(\n                epoch,\n                fun,\n                metrics,\n                rng,\n                state,\n                calib_targets,\n                calib_outputs,\n                verbose,\n                progress_bar,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(val_targets, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_val_start(state)", "choices": [{"text": "("}], "metadata": {"task_id": "awslabs_fortuna/123", "ground_truth": "                (", "fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "context_start_lineno": 0, "line_no": 113, "query_window": {"context": "                epoch,\n                fun,\n                metrics,\n                rng,\n                state,\n                calib_targets,\n                calib_outputs,\n                verbose,\n                progress_bar,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(val_targets, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_val_start(state)", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "line_no": 113, "task_id": "awslabs_fortuna/123", "start_line_no": 93, "end_line_no": 113, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "                calib_outputs_loader,\n                training_dataset_size,\n                verbose,\n                progress_bar,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(val_data_loader, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_val_start(state)\n                (\n                    val_losses_and_metrics_current_epoch,\n                    val_epoch_metrics_str,\n                ) = self._val_loop(\n                    fun=fun,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.8089887640449438}, {"context": "            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(validation_dataloader, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_validation_start(state)\n                (\n                    validation_losses_and_metrics_current_epoch,\n                    validation_epoch_metrics_str,\n                ) = self._validation_loop(\n                    fun=fun,\n                    metrics=metrics,\n                    rng=rng,\n                    state=state,\n                    training_kwargs=training_kwargs,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "training", "trainer.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7333333333333333}, {"context": "                fun,\n                metrics,\n                rng,\n                state,\n                training_dataloader,\n                training_dataset_size,\n                training_kwargs,\n                verbose,\n                progress_bar,\n                unravel=unravel,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(validation_dataloader, epoch):\n                # performance evaluation on the whole validation dataset", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "training", "trainer.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7222222222222222}, {"context": "                state,\n                training_losses_and_metrics_current_epoch,\n                training_batch_metrics_str,\n            ) = self._training_loop(\n                epoch,\n                fun,\n                metrics,\n                rng,\n                state,\n                training_data_loader,\n                calib_outputs_loader,\n                training_dataset_size,\n                verbose,\n                progress_bar,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6022727272727273}, {"context": "\n            # validation loop\n            if self.should_perform_validation(val_data_loader, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_val_start(state)\n                (\n                    val_losses_and_metrics_current_epoch,\n                    val_epoch_metrics_str,\n                ) = self._val_loop(\n                    fun=fun,\n                    metrics=metrics,\n                    rng=rng,\n                    state=state,\n                    val_data_loader=val_data_loader,\n                    val_outputs_loader=val_outputs_loader,\n                    val_dataset_size=val_dataset_size,\n                    verbose=verbose,\n                )\n                if verbose:\n                    logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.49514563106796117}, {"context": "                    metrics=metrics,\n                    rng=rng,\n                    state=state,\n                    val_data_loader=val_data_loader,\n                    val_outputs_loader=val_outputs_loader,\n                    val_dataset_size=val_dataset_size,\n                    verbose=verbose,\n                )\n                if verbose:\n                    logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)\n                # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n                for k in val_losses_and_metrics_current_epoch.keys():\n                    val_losses_and_metrics[k].append(\n                        val_losses_and_metrics_current_epoch[k]\n                    )\n                # check for early stopping\n                if self.is_early_stopping_active and self._early_stopping.should_stop:\n                    logging.info(\"[Early Stopping] Stopping training...\")\n                    break\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4396551724137931}, {"context": "            # forward and backward pass\n            state, aux = self.training_step(\n                state, batch, outputs, fun, rng, training_dataset_size\n            )\n            # compute training losses and metrics for the current batch\n            training_losses_and_metrics_current_batch = self.training_step_end(\n                current_epoch=current_epoch,\n                state=state,\n                aux=aux,\n                batch=batch,\n                metrics=metrics,\n            )\n            # keep track of training losses and metrics [granularity=batch]\n            training_losses_and_metrics_epoch_all_steps.append(\n                training_losses_and_metrics_current_batch\n            )\n            # logging\n            if verbose:\n                training_batch_metrics_str = \" | \".join(\n                    [", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4174757281553398}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/server.py\n# --------------------------------------------------\n#         # [ICLR'22, What Do We Mean by Generalization in Federated Learning?]\n#         self.unseen_clients_id = [] if unseen_clients_id is None \\\n#             else unseen_clients_id\n# \n#         # Server state\n#         self.is_finish = False\n# \n#         # Sampler\n#         if self._cfg.federate.sampler in ['uniform']:\n#             self.sampler = get_sampler(\n#                 sample_strategy=self._cfg.federate.sampler,\n#                 client_num=self.client_num,\n#                 client_info=None)\n#         else:\n#             # Some type of sampler would be instantiated in trigger_for_start,\n#             # since they need more information\n#             self.sampler = None\n# \n#         # Current Timestamp\n#         self.cur_timestamp = 0\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/client.py\n# --------------------------------------------------\n#         # Otherwise, we set patience=0 to deactivate the local early-stopper\n#         patience = self._cfg.early_stop.patience if \\\n#             self._cfg.federate.method in [\n#                 \"local\", \"global\"\n#             ] else 0\n#         self.early_stopper = EarlyStopper(\n#             patience, self._cfg.early_stop.delta,\n#             self._cfg.early_stop.improve_indicator_mode,\n#             self._monitor.the_larger_the_better)\n# \n#         # Secret Sharing Manager and message buffer\n#         self.ss_manager = AdditiveSecretSharing(\n#             shared_party_num=int(self._cfg.federate.sample_client_num\n#                                  )) if self._cfg.federate.use_ss else None\n#         self.msg_buffer = {'train': dict(), 'eval': dict()}\n# \n#         # Communication and communication ability\n#         if 'resource_info' in kwargs and kwargs['resource_info'] is not None:\n#             self.comp_speed = float(\n#                 kwargs['resource_info']['computation']) / 1000.  # (s/sample)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/data/base_data.py\n# --------------------------------------------------\n#                         and len(datadict[0]) != 0, \\\n#                         \"You specified cfg.data.server_holds_all=True \" \\\n#                         \"but data[0] is None. Please check whether you \" \\\n#                         \"pre-process the data[0] correctly\"\n#                     datadict[1] = datadict[0]\n#                 else:\n#                     logger.info(f\"Will merge data from clients whose ids in \"\n#                                 f\"[1, {self.global_cfg.federate.client_num}]\")\n#                     merged_data = merge_data(\n#                         all_data=datadict,\n#                         merged_max_data_id=self.global_cfg.federate.client_num)\n#                     datadict[1] = ClientData(self.global_cfg, **merged_data)\n#         datadict = self.attack(datadict)\n#         return datadict\n# \n#     def attack(self, datadict):\n#         \"\"\"\n#         Apply attack to ``StandaloneDataDict``.\n#         \"\"\"\n#         if 'backdoor' in self.global_cfg.attack.attack_method and 'edge' in \\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/fed_runner.py\n# --------------------------------------------------\n#             self.cfg.defrost()\n#             self.cfg.federate.client_num = 1\n#             self.cfg.federate.sample_client_num = 1\n#             self.cfg.freeze()\n# \n#         # sample resource information\n#         if self.resource_info is not None:\n#             if len(self.resource_info) < self.cfg.federate.client_num + 1:\n#                 replace = True\n#                 logger.warning(\n#                     f\"Because the provided the number of resource information \"\n#                     f\"{len(self.resource_info)} is less than the number of \"\n#                     f\"participants {self.cfg.federate.client_num + 1}, one \"\n#                     f\"candidate might be selected multiple times.\")\n#             else:\n#                 replace = False\n#             sampled_index = np.random.choice(\n#                 list(self.resource_info.keys()),\n#                 size=self.cfg.federate.client_num + 1,\n#                 replace=replace)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/configs/cfg_asyn.py\n# --------------------------------------------------\n#        \"but {} is got\".format(\n#         type(cfg.asyn.time_budget))\n# \n#     # min received num pre-process\n#     min_received_num_valid = (0 < cfg.asyn.min_received_num <=\n#                               cfg.federate.sample_client_num)\n#     min_received_rate_valid = (0 < cfg.asyn.min_received_rate <= 1)\n#     # (a) sampling case\n#     if min_received_rate_valid:\n#         # (a.1) use min_received_rate\n#         old_min_received_num = cfg.asyn.min_received_num\n#         cfg.asyn.min_received_num = max(\n#             1,\n#             int(cfg.asyn.min_received_rate * cfg.federate.sample_client_num))\n#         if min_received_num_valid:\n#             logging.warning(\n#                 f\"Users specify both valid min_received_rate as\"\n#                 f\" {cfg.asyn.min_received_rate} \"\n#                 f\"and min_received_num as {old_min_received_num}.\\n\"\n#                 f\"\\t\\tWe will use the min_received_rate value to calculate \"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/configs/cfg_asyn.py\n# --------------------------------------------------\n#         old_min_received_num = cfg.asyn.min_received_num\n#         cfg.asyn.min_received_num = max(\n#             1,\n#             int(cfg.asyn.min_received_rate * cfg.federate.sample_client_num))\n#         if min_received_num_valid:\n#             logging.warning(\n#                 f\"Users specify both valid min_received_rate as\"\n#                 f\" {cfg.asyn.min_received_rate} \"\n#                 f\"and min_received_num as {old_min_received_num}.\\n\"\n#                 f\"\\t\\tWe will use the min_received_rate value to calculate \"\n#                 f\"the actual number of participated clients as\"\n#                 f\" {cfg.asyn.min_received_num}.\")\n#     # (a.2) use min_received_num, commented since the below two lines do not\n#     # change anything elif min_received_rate:\n#     #     cfg.asyn.min_received_num = cfg.asyn.min_received_num\n#     if not (min_received_num_valid or min_received_rate_valid):\n#         # (b) non-sampling case, use all clients\n#         cfg.asyn.min_received_num = cfg.federate.sample_client_num\n# \n#     # to ensure a valid staleness toleation\n# --------------------------------------------------\n\nimport logging\n\nfrom federatedscope.core.configs.config import CN\nfrom federatedscope.register import register_config\n\nlogger = logging.getLogger(__name__)\n\n\ndef extend_fl_setting_cfg(cfg):\n    # ---------------------------------------------------------------------- #\n    # Federate learning related options\n    # ---------------------------------------------------------------------- #\n    cfg.federate = CN()\n\n    cfg.federate.client_num = 0\n    cfg.federate.sample_client_num = -1\n    cfg.federate.sample_client_rate = -1.0\n    cfg.federate.unseen_clients_rate = 0.0\n    cfg.federate.total_round_num = 50\n    cfg.federate.mode = 'standalone'\n    cfg.federate.share_local_model = False\n    cfg.federate.data_weighted_aggr = False  # If True, the weight of aggr is\n    # the number of training samples in dataset.\n    cfg.federate.online_aggr = False\n    cfg.federate.make_global_eval = False\n    cfg.federate.use_diff = False\n    cfg.federate.merge_test_data = False  # For efficient simulation, users\n    # can choose to merge the test data and perform global evaluation,\n    # instead of perform test at each client\n\n    # the method name is used to internally determine composition of\n    # different aggregators, messages, handlers, etc.,\n    cfg.federate.method = \"FedAvg\"\n    cfg.federate.ignore_weight = False\n    cfg.federate.use_ss = False  # Whether to apply Secret Sharing\n    cfg.federate.restore_from = ''\n    cfg.federate.save_to = ''\n    cfg.federate.join_in_info = [\n    ]  # The information requirements (from server) for join_in\n    cfg.federate.sampler = 'uniform'  # the strategy for sampling client\n    # in each training round, ['uniform', 'group']\n    cfg.federate.resource_info_file = \"\"  # the device information file to\n    # record computation and communication ability\n\n    # atc (TODO: merge later)\n    cfg.federate.atc_vanilla = False\n    cfg.federate.atc_load_from = ''\n\n    # ---------------------------------------------------------------------- #\n    # Distribute training related options\n    # ---------------------------------------------------------------------- #\n    cfg.distribute = CN()\n\n    cfg.distribute.use = False\n    cfg.distribute.server_host = '0.0.0.0'\n    cfg.distribute.server_port = 50050\n    cfg.distribute.client_host = '0.0.0.0'\n    cfg.distribute.client_port = 50050\n    cfg.distribute.role = 'client'\n    cfg.distribute.data_file = 'data'\n    cfg.distribute.data_idx = -1  # data_idx is used to specify the data\n    # index in distributed mode when adopting a centralized dataset for\n    # simulation (formatted as {data_idx: data/dataloader}).\n    # data_idx = -1 means that the whole dataset is owned by the participant.\n    # when data_idx is other invalid values excepted for -1, we randomly\n    # sample the data_idx for simulation\n    cfg.distribute.grpc_max_send_message_length = 100 * 1024 * 1024\n    cfg.distribute.grpc_max_receive_message_length = 100 * 1024 * 1024\n    cfg.distribute.grpc_enable_http_proxy = False\n\n    # ---------------------------------------------------------------------- #\n    # Vertical FL related options (for demo)\n    # --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"-------------------- #\n    cfg.vertical = CN()\n    cfg.vertical.use = False\n    cfg.vertical.dims = [5, 10]  # TODO: we need to explain dims\n    cfg.vertical.encryption = 'paillier'\n    cfg.vertical.key_size = 3072\n    cfg.vertical.algo = 'lr'  # ['lr', 'xgb']\n    cfg.vertical.xgb_use_bin = False\n\n    # --------------- register corresponding check function ----------\n    cfg.register_cfg_check_fun(assert_fl_setting_cfg)\n\n\ndef assert_fl_setting_cfg(cfg):\n    assert cfg.federate.mode in [\"standalone\", \"distributed\"], \\\n        f\"Please specify the cfg.federate.mode as the string standalone or \" \\\n        f\"distributed. But got {cfg.federate.mode}.\"\n\n    # =============  client num related  ==============\n    assert not (cfg.federate.client_num == 0\n                and cfg.federate.mode == 'distributed'\n                ), \"Please configure the cfg.federate. in distributed mode. \"\n\n    assert 0 <= cfg.federate.unseen_clients_rate < 1, \\\n        \"You specified in-valid cfg.federate.unseen_clients_rate\"\n    if 0 < cfg.federate.unseen_clients_rate < 1 and cfg.federate.method in [\n            \"local\", \"global\"\n    ]:\n        logger.warning(\n            \"In local/global training mode, the unseen_clients_rate is \"\n            \"in-valid, plz check your config\")\n        unseen_clients_rate = 0.0\n        cfg.federate.unseen_clients_rate = unseen_clients_rate\n    else:\n        unseen_clients_rate = cfg.federate.unseen_clients_rate\n    participated_client_num = max(\n        1, int((1 - unseen_clients_rate) * cfg.federate.client_num))\n\n    # sample client num pre-process\n    sample_client_num_valid = (\n        0 < cfg.federate.sample_client_num <=\n        cfg.federate.client_num) and cfg.federate.client_num != 0\n    sample_client_rate_valid = (0 < cfg.federate.sample_client_rate <= 1)\n\n    sample_cfg_valid = sample_client_rate_valid or sample_client_num_valid", "choices": [{"text": "cfg.federate.client_num is the total number of clients participating in federated learning."}], "metadata": {"task_id": "alibaba_FederatedScope/81", "ground_truth": "    non_sample_case = cfg.federate.method in [\"local\", \"global\"]", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "configs", "cfg_fl_setting.py"], "context_start_lineno": 0, "line_no": 117, "query_window": {"context": "    if 0 < cfg.federate.unseen_clients_rate < 1 and cfg.federate.method in [\n            \"local\", \"global\"\n    ]:\n        logger.warning(\n            \"In local/global training mode, the unseen_clients_rate is \"\n            \"in-valid, plz check your config\")\n        unseen_clients_rate = 0.0\n        cfg.federate.unseen_clients_rate = unseen_clients_rate\n    else:\n        unseen_clients_rate = cfg.federate.unseen_clients_rate\n    participated_client_num = max(\n        1, int((1 - unseen_clients_rate) * cfg.federate.client_num))\n\n    # sample client num pre-process\n    sample_client_num_valid = (\n        0 < cfg.federate.sample_client_num <=\n        cfg.federate.client_num) and cfg.federate.client_num != 0\n    sample_client_rate_valid = (0 < cfg.federate.sample_client_rate <= 1)\n\n    sample_cfg_valid = sample_client_rate_valid or sample_client_num_valid", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "configs", "cfg_fl_setting.py"], "line_no": 117, "task_id": "alibaba_FederatedScope/81", "start_line_no": 97, "end_line_no": 117, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "       \"but {} is got\".format(\n        type(cfg.asyn.time_budget))\n\n    # min received num pre-process\n    min_received_num_valid = (0 < cfg.asyn.min_received_num <=\n                              cfg.federate.sample_client_num)\n    min_received_rate_valid = (0 < cfg.asyn.min_received_rate <= 1)\n    # (a) sampling case\n    if min_received_rate_valid:\n        # (a.1) use min_received_rate\n        old_min_received_num = cfg.asyn.min_received_num\n        cfg.asyn.min_received_num = max(\n            1,\n            int(cfg.asyn.min_received_rate * cfg.federate.sample_client_num))\n        if min_received_num_valid:\n            logging.warning(\n                f\"Users specify both valid min_received_rate as\"\n                f\" {cfg.asyn.min_received_rate} \"\n                f\"and min_received_num as {old_min_received_num}.\\n\"\n                f\"\\t\\tWe will use the min_received_rate value to calculate \"", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "configs", "cfg_asyn.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.36065573770491804}, {"context": "    cfg.register_cfg_check_fun(assert_asyn_cfg)\n\n\ndef assert_asyn_cfg(cfg):\n    if not cfg.asyn.use:\n        return True\n    # to ensure a valid time budget\n    assert isinstance(cfg.asyn.time_budget, int) or isinstance(\n        cfg.asyn.time_budget, float\n    ), \"The time budget (seconds) must be an int or a float value, \" \\\n       \"but {} is got\".format(\n        type(cfg.asyn.time_budget))\n\n    # min received num pre-process\n    min_received_num_valid = (0 < cfg.asyn.min_received_num <=\n                              cfg.federate.sample_client_num)\n    min_received_rate_valid = (0 < cfg.asyn.min_received_rate <= 1)\n    # (a) sampling case\n    if min_received_rate_valid:\n        # (a.1) use min_received_rate", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "configs", "cfg_asyn.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.30708661417322836}, {"context": "            import torch\n            torch.set_num_threads(1)\n\n        assert self.cfg.federate.client_num != 0, \\\n            \"In standalone mode, self.cfg.federate.client_num should be \" \\\n            \"non-zero. \" \\\n            \"This is usually cased by using synthetic data and users not \" \\\n            \"specify a non-zero value for client_num\"\n\n        if self.cfg.federate.method == \"global\":\n            self.cfg.defrost()\n            self.cfg.federate.client_num = 1\n            self.cfg.federate.sample_client_num = 1\n            self.cfg.freeze()\n\n        # sample resource information\n        if self.resource_info is not None:\n            if len(self.resource_info) < self.cfg.federate.client_num + 1:\n                replace = True\n                logger.warning(", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "fed_runner.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.30158730158730157}, {"context": "                all_data=datadict,\n                merged_max_data_id=self.global_cfg.federate.client_num,\n                specified_dataset_name=['test'])\n            # `0` indicate Server\n            datadict[0] = ClientData(self.global_cfg, **server_data)\n\n        if self.global_cfg.federate.method == \"global\":\n            if self.global_cfg.federate.client_num != 1:\n                if self.global_cfg.data.server_holds_all:\n                    assert datadict[0] is not None \\\n                        and len(datadict[0]) != 0, \\\n                        \"You specified cfg.data.server_holds_all=True \" \\\n                        \"but data[0] is None. Please check whether you \" \\\n                        \"pre-process the data[0] correctly\"\n                    datadict[1] = datadict[0]\n                else:\n                    logger.info(f\"Will merge data from clients whose ids in \"\n                                f\"[1, {self.global_cfg.federate.client_num}]\")\n                    merged_data = merge_data(\n                        all_data=datadict,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "data", "base_data.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2777777777777778}, {"context": "                                   data=data,\n                                   device=device,\n                                   config=self._cfg,\n                                   is_attacker=self.is_attacker,\n                                   monitor=self._monitor)\n\n        # For client-side evaluation\n        self.best_results = dict()\n        self.history_results = dict()\n        # in local or global training mode, we do use the early stopper.\n        # Otherwise, we set patience=0 to deactivate the local early-stopper\n        patience = self._cfg.early_stop.patience if \\\n            self._cfg.federate.method in [\n                \"local\", \"global\"\n            ] else 0\n        self.early_stopper = EarlyStopper(\n            patience, self._cfg.early_stop.delta,\n            self._cfg.early_stop.improve_indicator_mode,\n            self._monitor.the_larger_the_better)\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "client.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2740740740740741}, {"context": "        # Initialize the number of joined-in clients\n        self._client_num = client_num\n        self._total_round_num = total_round_num\n        self.sample_client_num = int(self._cfg.federate.sample_client_num)\n        self.join_in_client_num = 0\n        self.join_in_info = dict()\n        # the unseen clients indicate the ones that do not contribute to FL\n        # process by training on their local data and uploading their local\n        # model update. The splitting is useful to check participation\n        # generalization gap in\n        # [ICLR'22, What Do We Mean by Generalization in Federated Learning?]\n        self.unseen_clients_id = [] if unseen_clients_id is None \\\n            else unseen_clients_id\n\n        # Server state\n        self.is_finish = False\n\n        # Sampler\n        if self._cfg.federate.sampler in ['uniform']:\n            self.sampler = get_sampler(", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "server.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.25675675675675674}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/_utils_internal.py\n# --------------------------------------------------\n#     CARTPOLE_VERSIONED = \"CartPole-v0\"\n#     HALFCHEETAH_VERSIONED = \"HalfCheetah-v2\"\n#     PENDULUM_VERSIONED = \"Pendulum-v0\"\n#     PONG_VERSIONED = \"Pong-v4\"\n# \n# \n# @implement_for(\"gym\", \"0.21.0\", None)\n# def _set_gym_environments():  # noqa: F811\n#     global CARTPOLE_VERSIONED, HALFCHEETAH_VERSIONED, PENDULUM_VERSIONED, PONG_VERSIONED\n# \n#     CARTPOLE_VERSIONED = \"CartPole-v1\"\n#     HALFCHEETAH_VERSIONED = \"HalfCheetah-v4\"\n#     PENDULUM_VERSIONED = \"Pendulum-v1\"\n#     PONG_VERSIONED = \"ALE/Pong-v5\"\n# \n# \n# if _has_gym:\n#     _set_gym_environments()\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/_utils.py\n# --------------------------------------------------\n#         try:\n#             module = import_module(self.module_name)\n#         except ModuleNotFoundError:\n#             return unsupported\n# \n#         func_name = f\"{fn.__module__}.{fn.__name__}\"\n#         implementations = implement_for._implementations\n# \n#         # Return fitting implementation if it was encountered before.\n#         if func_name in implementations:\n#             return implementations[func_name]\n# \n#         version = module.__version__\n# \n#         if (self.from_version is None or version >= self.from_version) and (\n#             self.to_version is None or version < self.to_version\n#         ):\n#             implementations[func_name] = fn\n#             return fn\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#         self, kwargs, disable_env_checker: bool = None\n#     ) -> None:\n#         if disable_env_checker is not None:\n#             raise RuntimeError(\n#                 \"disable_env_checker should only be set if gym version is > 0.24\"\n#             )\n# \n#     @implement_for(\"gym\", \"0.24.0\", None)\n#     def _set_gym_args(  # noqa: F811\n#         self, kwargs, disable_env_checker: bool = None\n#     ) -> None:\n#         kwargs[\"disable_env_checker\"] = (\n#             disable_env_checker if disable_env_checker is not None else True\n#         )\n# \n#     def _build_env(\n#         self,\n#         env_name: str,\n#         **kwargs,\n#     ) -> \"gym.core.Env\":\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#         return seed\n# \n#     @implement_for(\"gym\", None, \"0.19.0\")\n#     def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n#         self._seed_calls_reset = False\n#         self._env.seed(seed=seed)\n# \n#     @implement_for(\"gym\", \"0.19.0\", None)\n#     def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n#         try:\n#             self.reset(seed=seed)\n#             self._seed_calls_reset = True\n#         except TypeError as err:\n#             warnings.warn(\n#                 f\"reset with seed kwarg returned an exception: {err}.\\n\"\n#                 f\"Calling env.seed from now on.\"\n#             )\n#             self._seed_calls_reset = False\n#             self._env.seed(seed=seed)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n# \n# @implement_for(\"gym\", \"0.26.0\", None)\n# def _get_gym_envs():  # noqa: F811\n#     return gym.envs.registration.registry.keys()\n# \n# \n# def _get_gym():\n#     if _has_gym:\n#         return gym\n#     else:\n#         return None\n# \n# \n# def _is_from_pixels(env):\n#     observation_spec = env.observation_space\n#     if isinstance(observation_spec, (Dict,)):\n#         if \"pixels\" in set(observation_spec.keys()):\n#             return True\n#     if isinstance(observation_spec, (gym.spaces.dict.Dict,)):\n#         if \"pixels\" in set(observation_spec.spaces.keys()):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#         return env\n# \n#     @implement_for(\"gym\", None, \"0.26.0\")\n#     def _build_gym_env(self, env, pixels_only):  # noqa: F811\n#         return PixelObservationWrapper(env, pixels_only=pixels_only)\n# \n#     @implement_for(\"gym\", \"0.26.0\", None)\n#     def _build_gym_env(self, env, pixels_only):  # noqa: F811\n#         from gym.wrappers.compatibility import EnvCompatibility\n# \n#         if env.render_mode:\n#             return PixelObservationWrapper(env, pixels_only=pixels_only)\n# \n#         warnings.warn(\n#             \"Environments provided to GymWrapper that need to be wrapped in PixelObservationWrapper \"\n#             \"should be created with `gym.make(env_name, render_mode=mode)` where possible,\"\n#             'where mode is either \"rgb_array\" or any other supported mode.'\n#         )\n#         # resetting as 0.26 comes with a very 'nice' OrderEnforcing wrapper\n#         env = EnvCompatibility(env)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#             self.reset(seed=seed)\n#             self._seed_calls_reset = True\n#         except TypeError as err:\n#             warnings.warn(\n#                 f\"reset with seed kwarg returned an exception: {err}.\\n\"\n#                 f\"Calling env.seed from now on.\"\n#             )\n#             self._seed_calls_reset = False\n#             self._env.seed(seed=seed)\n# \n#     def _make_specs(self, env: \"gym.Env\") -> None:\n#         self.action_spec = _gym_to_torchrl_spec_transform(\n#             env.action_space,\n#             device=self.device,\n#             categorical_action_encoding=self._categorical_action_encoding,\n#         )\n#         observation_spec = _gym_to_torchrl_spec_transform(\n#             env.observation_space,\n#             device=self.device,\n#             categorical_action_encoding=self._categorical_action_encoding,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\n\nimport pytest\nfrom torchrl._utils import get_binary_env_var, implement_for\n\n\n@pytest.mark.parametrize(\"value\", [\"True\", \"1\", \"true\"])\ndef test_get_binary_env_var_positive(value):\n    try:\n        key = \"SOME_ENVIRONMENT_VARIABLE_UNLIKELY_TO_BE_IN_ENVIRONMENT\"\n\n        assert key not in os.environ\n\n        os.environ[key] = value\n        assert get_binary_env_var(key)\n\n    finally:\n        if key in os.environ:\n            del os.environ[key]\n\n\n@pytest.mark.parametrize(\"value\", [\"False\", \"0\", \"false\"])\ndef test_get_binary_env_var_negative(value):\n    try:\n        key = \"SOME_ENVIRONMENT_VARIABLE_UNLIKELY_TO_BE_IN_ENVIRONMENT\"\n\n        assert key not in os.environ\n\n        os.environ[key] = \"True\"\n        assert get_binary_env_var(key)\n        os.environ[key] = value\n        assert not get_binary_env_var(key)\n\n    finally:\n        if key in os.environ:\n            del os.environ[key]\n\n\ndef test_get_binary_env_var_missing():\n    try:\n        key = \"SOME_ENVIRONMENT_VARIABLE_UNLIKELY_TO_BE_IN_ENVIRONMENT\"\n\n        assert key not in os.environ\n        assert not get_binary_env_var(key)\n\n    finally:\n        if key in os.environ:\n            del os.environ[key]\n\n\ndef test_get_binary_env_var_wrong_value():\n    try:\n        key = \"SOME_ENVIRONMENT_VARIABLE_UNLIKELY_TO_BE_IN_ENVIRONMENT\"\n\n        assert key not in os.environ\n        os.environ[key] = \"smthwrong\"\n        with pytest.raises(ValueError):\n            get_binary_env_var(key)\n\n    finally:\n        if key in os.environ:\n            del os.environ[key]\n\n\nclass implement_for_test_functions:\n    \"\"\"\n    Groups functions that are used in tests for `implement_for` decorator.\n    \"\"\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.3\")\n    def select_correct_version():\n        \"\"\"To test from+ range and that this function is correctly selected as the implementation.\"\"\"\n        return \"0.3+\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.2\", \"0.3\")\n    def select_correct_version():  # noqa: F811\n        \"\"\"To test that right bound is not included.\"\"\"\n        return \"0.2-0.3\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.1\", \"0.2\")\n    def select_correct_version():  # noqa: F811\n        \"\"\"To test that function with missing from-to range is ignored.\"\"\"\n        return \"0.1-0.2\"\n\n    @staticmethod\n    @implement_for(\"missing_module\")\n    def missing_module():\n        \"\"\"To test that calling decorated function with missing module raises an exception.\"\"\"", "choices": [{"text": "raise ModuleNotFoundError"}], "metadata": {"task_id": "pytorch_rl/79", "ground_truth": "        return \"missing\"", "fpath_tuple": ["pytorch_rl", "test", "test_utils.py"], "context_start_lineno": 0, "line_no": 96, "query_window": {"context": "    def select_correct_version():\n        \"\"\"To test from+ range and that this function is correctly selected as the implementation.\"\"\"\n        return \"0.3+\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.2\", \"0.3\")\n    def select_correct_version():  # noqa: F811\n        \"\"\"To test that right bound is not included.\"\"\"\n        return \"0.2-0.3\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.1\", \"0.2\")\n    def select_correct_version():  # noqa: F811\n        \"\"\"To test that function with missing from-to range is ignored.\"\"\"\n        return \"0.1-0.2\"\n\n    @staticmethod\n    @implement_for(\"missing_module\")\n    def missing_module():\n        \"\"\"To test that calling decorated function with missing module raises an exception.\"\"\"", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_utils.py"], "line_no": 96, "task_id": "pytorch_rl/79", "start_line_no": 76, "end_line_no": 96, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        return seed\n\n    @implement_for(\"gym\", None, \"0.19.0\")\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        self._seed_calls_reset = False\n        self._env.seed(seed=seed)\n\n    @implement_for(\"gym\", \"0.19.0\", None)\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        try:\n            self.reset(seed=seed)\n            self._seed_calls_reset = True\n        except TypeError as err:\n            warnings.warn(\n                f\"reset with seed kwarg returned an exception: {err}.\\n\"\n                f\"Calling env.seed from now on.\"\n            )\n            self._seed_calls_reset = False\n            self._env.seed(seed=seed)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2644628099173554}, {"context": "        from_pixels = from_pixels or env_from_pixels\n        self.from_pixels = from_pixels\n        self.pixels_only = pixels_only\n        if from_pixels and not env_from_pixels:\n            if isinstance(env, PixelObservationWrapper):\n                raise TypeError(\n                    \"PixelObservationWrapper cannot be used to wrap an environment\"\n                    \"that is already a PixelObservationWrapper instance.\"\n                )\n            env = self._build_gym_env(env, pixels_only)\n        return env\n\n    @implement_for(\"gym\", None, \"0.26.0\")\n    def _build_gym_env(self, env, pixels_only):  # noqa: F811\n        return PixelObservationWrapper(env, pixels_only=pixels_only)\n\n    @implement_for(\"gym\", \"0.26.0\", None)\n    def _build_gym_env(self, env, pixels_only):  # noqa: F811\n        from gym.wrappers.compatibility import EnvCompatibility\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.24806201550387597}, {"context": "    envs = _get_gym_envs()\n    envs = list(envs)\n    envs = sorted(envs)\n    return envs\n\n\n@implement_for(\"gym\", None, \"0.26.0\")\ndef _get_gym_envs():  # noqa: F811\n    return gym.envs.registration.registry.env_specs.keys()\n\n\n@implement_for(\"gym\", \"0.26.0\", None)\ndef _get_gym_envs():  # noqa: F811\n    return gym.envs.registration.registry.keys()\n\n\ndef _get_gym():\n    if _has_gym:\n        return gym\n    else:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2376237623762376}, {"context": "\n    def _set_seed(self, seed: int) -> int:  # noqa: F811\n        if self._seed_calls_reset is None:\n            # Determine basing on gym version whether `reset` is called when setting seed.\n            self._set_seed_initial(seed)\n        elif self._seed_calls_reset:\n            self.reset(seed=seed)\n        else:\n            self._env.seed(seed=seed)\n\n        return seed\n\n    @implement_for(\"gym\", None, \"0.19.0\")\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        self._seed_calls_reset = False\n        self._env.seed(seed=seed)\n\n    @implement_for(\"gym\", \"0.19.0\", None)\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        try:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.22608695652173913}, {"context": "\n    \"\"\"\n\n    def __init__(self, env_name, disable_env_checker=None, **kwargs):\n        kwargs[\"env_name\"] = env_name\n        self._set_gym_args(kwargs, disable_env_checker)\n        super().__init__(**kwargs)\n\n    @implement_for(\"gym\", None, \"0.24.0\")\n    def _set_gym_args(  # noqa: F811\n        self, kwargs, disable_env_checker: bool = None\n    ) -> None:\n        if disable_env_checker is not None:\n            raise RuntimeError(\n                \"disable_env_checker should only be set if gym version is > 0.24\"\n            )\n\n    @implement_for(\"gym\", \"0.24.0\", None)\n    def _set_gym_args(  # noqa: F811\n        self, kwargs, disable_env_checker: bool = None", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.224}, {"context": "        self.to_version = to_version\n\n    def __call__(self, fn):\n        @wraps(fn)\n        def unsupported():\n            raise ModuleNotFoundError(\n                f\"Supported version of '{self.module_name}' has not been found.\"\n            )\n\n        # If the module is missing replace the function with the mock.\n        try:\n            module = import_module(self.module_name)\n        except ModuleNotFoundError:\n            return unsupported\n\n        func_name = f\"{fn.__module__}.{fn.__name__}\"\n        implementations = implement_for._implementations\n\n        # Return fitting implementation if it was encountered before.\n        if func_name in implementations:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21705426356589147}, {"context": "CARTPOLE_VERSIONED = \"CartPole-v1\"\nHALFCHEETAH_VERSIONED = \"HalfCheetah-v4\"\nPENDULUM_VERSIONED = \"Pendulum-v1\"\nPONG_VERSIONED = \"ALE/Pong-v5\"\n\n\n@implement_for(\"gym\", None, \"0.21.0\")\ndef _set_gym_environments():  # noqa: F811\n    global CARTPOLE_VERSIONED, HALFCHEETAH_VERSIONED, PENDULUM_VERSIONED, PONG_VERSIONED\n\n    CARTPOLE_VERSIONED = \"CartPole-v0\"\n    HALFCHEETAH_VERSIONED = \"HalfCheetah-v2\"\n    PENDULUM_VERSIONED = \"Pendulum-v0\"\n    PONG_VERSIONED = \"Pong-v4\"\n\n\n@implement_for(\"gym\", \"0.21.0\", None)\ndef _set_gym_environments():  # noqa: F811\n    global CARTPOLE_VERSIONED, HALFCHEETAH_VERSIONED, PENDULUM_VERSIONED, PONG_VERSIONED\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "_utils_internal.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21487603305785125}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/jumanji.py\n# --------------------------------------------------\n#         tensordict_out.set(\"done\", done)\n#         tensordict_out[\"state\"] = state_dict\n# \n#         return tensordict_out\n# \n# \n# class JumanjiEnv(JumanjiWrapper):\n#     \"\"\"Jumanji environment wrapper.\n# \n#     Examples:\n#         >>> env = JumanjiEnv(env_name=\"Snake-6x6-v0\", frame_skip=4)\n#         >>> td = env.rand_step()\n#         >>> print(td)\n#         >>> print(env.available_envs)\n#     \"\"\"\n# \n#     def __init__(self, env_name, **kwargs):\n#         kwargs[\"env_name\"] = env_name\n#         super().__init__(**kwargs)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n# \n#     def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         step_count = tensordict.get(\n#             \"step_count\",\n#             torch.zeros(\n#                 tensordict.batch_size,\n#                 dtype=torch.int64,\n#                 device=tensordict.device,\n#             ),\n#         )\n#         next_step_count = step_count + 1\n#         tensordict.set(\"step_count\", next_step_count)\n#         if self.max_steps is not None:\n#             done = tensordict.get(\"done\")\n#             done = done | (next_step_count >= self.max_steps).unsqueeze(-1)\n#             tensordict.set(\"done\", done)\n#         return tensordict\n# \n#     def transform_observation_spec(\n#         self, observation_spec: CompositeSpec\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#     ) -> TensorDictBase:\n#         tensordict = tensordict.to(self.device)\n#         a = tensordict.get(\"action\")\n# \n#         if not self.categorical_action_encoding:\n#             assert (a.sum(-1) == 1).all()\n# \n#         obs = self._get_in_obs(tensordict.get(self._out_key)) + a / self.maxstep\n#         tensordict = tensordict.select()  # empty tensordict\n# \n#         tensordict.set(self.out_key, self._get_out_obs(obs))\n#         tensordict.set(self._out_key, self._get_out_obs(obs))\n# \n#         done = torch.isclose(obs, torch.ones_like(obs) * (self.counter + 1))\n#         reward = done.any(-1).unsqueeze(-1)\n#         # set done to False\n#         done = torch.zeros_like(done).all(-1).unsqueeze(-1)\n#         tensordict.set(\"reward\", reward.to(torch.get_default_dtype()))\n#         tensordict.set(\"done\", done)\n#         return tensordict\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#         tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n#         return tensordict\n# \n#     def _step(\n#         self,\n#         tensordict: TensorDictBase,\n#     ) -> TensorDictBase:\n#         self.step_count += 1\n#         tensordict = tensordict.to(self.device)\n#         a = tensordict.get(\"action\")\n# \n#         obs = self._obs_step(self._get_in_obs(tensordict.get(self._out_key)), a)\n#         tensordict = tensordict.select()  # empty tensordict\n# \n#         tensordict.set(self.out_key, self._get_out_obs(obs))\n#         tensordict.set(self._out_key, self._get_out_obs(obs))\n# \n#         done = torch.isclose(obs, torch.ones_like(obs) * (self.counter + 1))\n#         while done.shape != tensordict.shape:\n#             done = done.any(-1)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/jumanji.py\n# --------------------------------------------------\n#         tensordict_out.set(\"done\", done)\n#         tensordict_out[\"state\"] = state_dict\n# \n#         return tensordict_out\n# \n#     def _reset(\n#         self, tensordict: Optional[TensorDictBase] = None, **kwargs\n#     ) -> TensorDictBase:\n# \n#         # generate random keys\n#         self.key, *keys = jax.random.split(self.key, self.numel() + 1)\n# \n#         # jax vectorizing map on env.reset\n#         state, timestep = jax.vmap(self._env.reset)(jnp.stack(keys))\n# \n#         # reshape batch size from vector\n#         state = _tree_reshape(state, self.batch_size)\n#         timestep = _tree_reshape(timestep, self.batch_size)\n# \n#         # collect outputs\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#         if tensordict is None:\n#             tensordict = TensorDict({}, self.batch_size, device=self.device)\n#         tensordict = tensordict.select().set(self.out_key, self._get_out_obs(state))\n#         tensordict = tensordict.set(self._out_key, self._get_out_obs(state))\n#         tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n#         return tensordict\n# \n#     def _step(\n#         self,\n#         tensordict: TensorDictBase,\n#     ) -> TensorDictBase:\n#         tensordict = tensordict.to(self.device)\n#         a = tensordict.get(\"action\")\n# \n#         if not self.categorical_action_encoding:\n#             assert (a.sum(-1) == 1).all()\n# \n#         obs = self._get_in_obs(tensordict.get(self._out_key)) + a / self.maxstep\n#         tensordict = tensordict.select()  # empty tensordict\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n        >>> reader = default_info_dict_reader([\"my_info_key\"])\n        >>> # assuming \"some_env-v0\" returns a dict with a key \"my_info_key\"\n        >>> env = GymWrapper(gym.make(\"some_env-v0\"))\n        >>> env.set_info_dict_reader(info_dict_reader=reader)\n        >>> tensordict = env.reset()\n        >>> tensordict = env.rand_step(tensordict)\n        >>> assert \"my_info_key\" in tensordict.keys()\n\n    \"\"\"\n\n    def __init__(\n        self,\n        keys: List[str] = None,\n        spec: Union[Sequence[TensorSpec], Dict[str, TensorSpec]] = None,\n    ):\n        if keys is None:\n            keys = []\n        self.keys = keys\n\n        if isinstance(spec, Sequence):\n            if len(spec) != len(self.keys):\n                raise ValueError(\n                    \"If specifying specs for info keys with a sequence, the \"\n                    \"length of the sequence must match the number of keys\"\n                )\n            self._info_spec = dict(zip(self.keys, spec))\n        else:\n            if spec is None:\n                spec = {}\n\n            self._info_spec = {\n                key: spec.get(key, UnboundedContinuousTensorSpec()) for key in self.keys\n            }\n\n    def __call__(\n        self, info_dict: Dict[str, Any], tensordict: TensorDictBase\n    ) -> TensorDictBase:\n        if not isinstance(info_dict, dict) and len(self.keys):\n            warnings.warn(\n                f\"Found an info_dict of type {type(info_dict)} \"\n                f\"but expected type or subtype `dict`.\"\n            )\n        for key in self.keys:\n            if key in info_dict:\n                tensordict[key] = info_dict[key]\n        return tensordict\n\n    @property\n    def info_spec(self) -> Dict[str, TensorSpec]:\n        return self._info_spec\n\n\nclass GymLikeEnv(_EnvWrapper):\n    \"\"\"A gym-like env is an environment.\n\n    Its behaviour is similar to gym environments in what common methods (specifically reset and step) are expected to do.\n\n    A :obj:`GymLikeEnv` has a :obj:`.step()` method with the following signature:\n\n        ``env.step(action: np.ndarray) -> Tuple[Union[np.ndarray, dict], double, bool, *info]``\n\n    where the outputs are the observation, reward and done state respectively.\n    In this implementation, the info output is discarded (but specific keys can be read\n    by updating info_dict_reader, see :obj:`set_info_dict_reader` class method).\n\n    By default, the first output is written at the \"observation\" key-value pair in the output tensordict, unless\n    the first output is a dictionary. In that case, each observation output will be put at the corresponding\n    :obj:`f\"{key}\"` location for each :obj:`f\"{key}\"` of the dictionary.\n\n    It is also expected that env.reset() returns an observation similar to the one observed after a step is completed.\n    \"\"\"\n\n    _info_dict_reader: BaseInfoDictReader\n\n    @classmethod\n    def __new__(cls, *args, **kwargs):\n        cls._info_dict_reader = None\n        return super().__new__(cls, *args, _batch_locked=True, **kwargs)\n\n    def read_action(self, action):\n        \"\"\"Reads the action obtained from the input TensorDict and transforms it in the format expected by the contained environment.\n\n        Args:\n            action (Tensor or TensorDict): an action to be taken in the environment\n\n        Returns: an action in a format compatible with the contained environment.\n\n        \"\"\"\n        return self.action_spec.to_numpy(action, safe=False)\n\n    def read_done(self, done):\n        \"\"\"Done state reader.\n\n        Reads a done state and returns a tuple containing:\n        - a done state to be set in the environment\n        - a boolean value indicating whether the frame_skip loop should be broken\n\n        Args:\n            done (np.ndarray, boolean or other format): done state obtained from the environment\n\n        \"\"\"\n        return done, done\n\n    def read_reward(self, total_reward, step_reward):\n        \"\"\"Reads a reward and the total reward so far (in the frame skip loop) and returns a sum of the two.\n\n        Args:\n            total_reward (torch.Tensor or TensorDict): total reward so far in the step\n            step_reward (reward in the format provided by the inner env): reward of this particular step\n\n        \"\"\"\n        return total_reward + self.reward_spec.encode(step_reward)\n\n    def read_obs(\n        self, observations: Union[Dict[str, Any], torch.Tensor, np.ndarray]\n    ) -> Dict[str, Any]:\n        \"\"\"Reads an observation from the environment and returns an observation compatible with the output TensorDict.\n\n        Args:\n            observations (observation under a format dictated by the inner env): observation to be read.\n\n        \"\"\"\n        if isinstance(observations, dict):\n            observations = {key: value for key, value in observations.items()}\n        if not isinstance(observations, (TensorDict, dict)):\n            (key,) = itertools.islice(self.observation_spec.keys(), 1)\n            observations = {key: observations}\n        observations = self.observation_spec.encode(observations)\n        return observations\n\n    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n        action = tensordict.get(\"action\")\n        action_np = self.read_action(action)\n\n        reward = self.reward_spec.zero()\n        for _ in range(self.wrapper_frame_skip):\n            obs, _reward, done, *info = self._output_transform(\n                self._env.step(action_np)\n            )\n            if isinstance(obs, list) and len(obs) == 1:\n                # Until gym 0.25.2 we had rendered frames returned in lists of length 1\n                obs = obs[0]\n            if len(info) == 2:\n                # gym 0.26\n                truncation, info = info\n            elif len(info) == 1:\n                info = info[0]\n            elif len(info) == 0:\n                info = None\n            else:\n                raise ValueError(\n                    \"the environment output is expected to be either\"\n                    \"obs, reward, done, truncation, info (gym >= 0.26) or \"\n                    f\"obs, reward, done, info. Got info with types = ({[type(x) for x in info]})\"\n                )\n\n            if _reward is None:\n                _reward = self.reward_spec.zero()\n\n            reward = self.read_reward(reward, _reward)\n\n            if isinstance(done, bool) or (\n                isinstance(done, np.ndarray) and not len(done)\n            ):\n                done = torch.tensor([done], device=self.device)\n\n            done, do_break = self.read_done(done)\n            if do_break:\n                break\n\n        obs_dict = self.read_obs(obs)\n\n        if reward is None:\n            reward = np.nan\n        reward = self._to_tensor(reward, dtype=self.reward_spec.dtype)\n        done = self._to_tensor(done, dtype=torch.bool)\n\n        tensordict_out = TensorDict(\n            obs_dict, batch_size=tensordict.batch_size, device=self.device\n        )\n\n        tensordict_out.set(\"reward\", reward)\n        tensordict_out.set(\"done\", done)\n        if self.info_dict_reader is not None and info is not None:\n            self.info_dict_reader(info, tensordict_out)\n\n        return tensordict_out\n\n    def _reset(", "choices": [{"text": "self, tensordict: Optional[TensorDictBase] = None, **kwargs"}], "metadata": {"task_id": "pytorch_rl/101", "ground_truth": "        self, tensordict: Optional[TensorDictBase] = None, **kwargs", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "context_start_lineno": 45, "line_no": 234, "query_window": {"context": "\n        obs_dict = self.read_obs(obs)\n\n        if reward is None:\n            reward = np.nan\n        reward = self._to_tensor(reward, dtype=self.reward_spec.dtype)\n        done = self._to_tensor(done, dtype=torch.bool)\n\n        tensordict_out = TensorDict(\n            obs_dict, batch_size=tensordict.batch_size, device=self.device\n        )\n\n        tensordict_out.set(\"reward\", reward)\n        tensordict_out.set(\"done\", done)\n        if self.info_dict_reader is not None and info is not None:\n            self.info_dict_reader(info, tensordict_out)\n\n        return tensordict_out\n\n    def _reset(", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 234, "task_id": "pytorch_rl/101", "start_line_no": 214, "end_line_no": 234, "window_size": 20, "context_start_lineno": 45, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "\n    def _get_in_obs(self, obs):\n        return obs\n\n    def _get_out_obs(self, obs):\n        return obs\n\n    def _reset(self, tensordict: TensorDictBase = None) -> TensorDictBase:\n        self.counter += 1\n        state = torch.zeros(self.size) + self.counter\n        if tensordict is None:\n            tensordict = TensorDict({}, self.batch_size, device=self.device)\n        tensordict = tensordict.select().set(self.out_key, self._get_out_obs(state))\n        tensordict = tensordict.set(self._out_key, self._get_out_obs(state))\n        tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n        return tensordict\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5340909090909091}, {"context": "        done = timestep.step_type == self.lib.types.StepType.LAST\n        done = _ndarray_to_tensor(done).view(torch.bool).to(self.device)\n\n        # build results\n        tensordict_out = TensorDict(\n            source=obs_dict,\n            batch_size=tensordict.batch_size,\n            device=self.device,\n        )\n        tensordict_out.set(\"reward\", reward)\n        tensordict_out.set(\"done\", done)\n        tensordict_out[\"state\"] = state_dict\n\n        return tensordict_out\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:\n\n        # generate random keys", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "jumanji.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5}, {"context": "    def _reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n        self.counter += 1\n        self.step_count = 0\n        # state = torch.zeros(self.size) + self.counter\n        if tensordict is None:\n            tensordict = TensorDict({}, self.batch_size, device=self.device)\n        tensordict = tensordict.select()\n        tensordict.update(self.observation_spec.rand())\n        # tensordict.set(\"next_\" + self.out_key, self._get_out_obs(state))\n        # tensordict.set(\"next_\" + self._out_key, self._get_out_obs(state))\n        tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n        return tensordict\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,\n    ) -> TensorDictBase:\n        self.step_count += 1\n        tensordict = tensordict.to(self.device)\n        a = tensordict.get(\"action\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.49}, {"context": "        if tensordict is None:\n            tensordict = TensorDict({}, self.batch_size, device=self.device)\n        tensordict = tensordict.select().set(self.out_key, self._get_out_obs(state))\n        tensordict = tensordict.set(self._out_key, self._get_out_obs(state))\n        tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n        return tensordict\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,\n    ) -> TensorDictBase:\n        tensordict = tensordict.to(self.device)\n        a = tensordict.get(\"action\")\n\n        if not self.categorical_action_encoding:\n            assert (a.sum(-1) == 1).all()\n\n        obs = self._get_in_obs(tensordict.get(self._out_key)) + a / self.maxstep\n        tensordict = tensordict.select()  # empty tensordict\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45794392523364486}, {"context": "                dtype=torch.int64,\n                device=tensordict.device,\n            ),\n        )\n        step_count[_reset] = 0\n        tensordict.set(\n            \"step_count\",\n            step_count,\n        )\n        return tensordict\n\n    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n        step_count = tensordict.get(\n            \"step_count\",\n            torch.zeros(\n                tensordict.batch_size,\n                dtype=torch.int64,\n                device=tensordict.device,\n            ),\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 2710, "start_line_no": 2700, "end_line_no": 2720, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45121951219512196}, {"context": "        state_dict = self.read_state(state)\n        obs_dict = self.read_obs(timestep.observation)\n        done = torch.zeros(self.batch_size, dtype=torch.bool)\n\n        # build results\n        tensordict_out = TensorDict(\n            source=obs_dict,\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n        tensordict_out.set(\"done\", done)\n        tensordict_out[\"state\"] = state_dict\n\n        return tensordict_out\n\n\nclass JumanjiEnv(JumanjiWrapper):\n    \"\"\"Jumanji environment wrapper.\n\n    Examples:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "jumanji.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4479166666666667}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/preprocess/instance_norm.py\n# --------------------------------------------------\n#     worker.register_handlers(\n#         'ss_instance_sum_norm_square',\n#         worker.callback_func_for_ss_instance_sum_norm_square)\n#     return worker\n# \n# \n# def wrap_instance_norm_client(worker):\n#     \"\"\"\n#     This function is to perform instance norm vfl tabular data for client.\n#     Args:\n#         worker: ``federatedscope.core.workers.Worker`` to be wrapped\n# \n#     Returns:\n#         Wrap vfl client with instance norm.\n#     \"\"\"\n#     def callback_func_for_ask_for_instance_sum(self, message: Message):\n#         self.ss_manager = AdditiveSecretSharing(\n#             shared_party_num=int(self._cfg.federate.client_num))\n#         self.msg_buffer['ss_instance_sum'] = {}\n#         content = {}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/selection/correlation_filter.py\n# --------------------------------------------------\n#         callback_funcs_for_encrypted_norm_feat, worker)\n#     worker.callbacks_funcs_for_feat_corrcoef = types.MethodType(\n#         callbacks_funcs_for_feat_corrcoef, worker)\n#     worker.callback_funcs_for_vertical_dims = types.MethodType(\n#         callback_funcs_for_vertical_dims, worker)\n# \n#     # Register handlers functions\n#     worker.register_handlers('feat_engr_public_keys',\n#                              worker.callback_funcs_for_feat_engr_public_keys)\n#     worker.register_handlers(\n#         'ask_for_encrypted_norm_feat',\n#         worker.callback_funcs_for_ask_for_encrypted_norm_feat)\n#     worker.register_handlers('encrypted_norm_feat',\n#                              worker.callback_funcs_for_encrypted_norm_feat)\n#     worker.register_handlers('feat_corrcoef',\n#                              worker.callbacks_funcs_for_feat_corrcoef)\n#     worker.register_handlers('vertical_dims',\n#                              worker.callback_funcs_for_vertical_dims)\n# \n#     return worker\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/xgb_base/worker/train_wrapper.py\n# --------------------------------------------------\n#     client.train = types.MethodType(train, client)\n#     client.callback_func_for_split = types.MethodType(callback_func_for_split,\n#                                                       client)\n#     client.callback_funcs_for_continue_training = types.MethodType(\n#         callback_funcs_for_continue_training, client)\n#     client._find_and_send_split = types.MethodType(_find_and_send_split,\n#                                                    client)\n#     client._check_eval_finish = types.MethodType(_check_eval_finish, client)\n# \n#     # Register handler functions\n#     client.register_handlers('split', client.callback_func_for_split)\n#     client.register_handlers('continue_training',\n#                              client.callback_funcs_for_continue_training)\n# \n#     return client\n# \n# \n# def wrap_server_for_train(server):\n# \n#     return server\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/selection/iv_filter.py\n# --------------------------------------------------\n#     worker.callback_funcs_for_binning = types.MethodType(\n#         callback_funcs_for_binning, worker)\n#     worker.callback_func_for_en_y = types.MethodType(callback_func_for_en_y,\n#                                                      worker)\n#     worker.callback_func_for_sum_en_y = types.MethodType(\n#         callback_func_for_sum_en_y, worker)\n#     worker.callback_func_for_iv_list = types.MethodType(\n#         callback_func_for_iv_list, worker)\n#     worker.callback_funcs_for_vertical_dims = types.MethodType(\n#         callback_funcs_for_vertical_dims, worker)\n# \n#     # Register handlers functions\n#     worker.register_handlers('binning', worker.callback_funcs_for_binning)\n#     worker.register_handlers('en_y', worker.callback_func_for_en_y)\n#     worker.register_handlers('sum_en_y', worker.callback_func_for_sum_en_y)\n#     worker.register_handlers('iv_list', worker.callback_func_for_iv_list)\n#     worker.register_handlers('vertical_dims',\n#                              worker.callback_funcs_for_vertical_dims)\n# \n#     return worker\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/preprocess/instance_norm.py\n# --------------------------------------------------\n#     worker.callback_func_for_instance_mean = types.MethodType(\n#         callback_func_for_instance_mean, worker)\n#     worker.callback_func_for_ss_instance_sum_norm_square = types.MethodType(\n#         callback_func_for_ss_instance_sum_norm_square, worker)\n#     worker.callback_func_for_instance_var = types.MethodType(\n#         callback_func_for_instance_var, worker)\n# \n#     # Register handlers functions\n#     worker.register_handlers('ask_for_instance_sum',\n#                              worker.callback_func_for_ask_for_instance_sum)\n#     worker.register_handlers('ss_instance_sum',\n#                              worker.callback_func_ss_instance_sum)\n#     worker.register_handlers('instance_mean',\n#                              worker.callback_func_for_instance_mean)\n#     worker.register_handlers(\n#         'ss_instance_sum_norm_square',\n#         worker.callback_func_for_ss_instance_sum_norm_square)\n#     worker.register_handlers('instance_var',\n#                              worker.callback_func_for_instance_var)\n#     return worker\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/xgb_base/worker/train_wrapper.py\n# --------------------------------------------------\n#     client.train = types.MethodType(train, client)\n#     client.callback_func_for_split = types.MethodType(callback_func_for_split,\n#                                                       client)\n#     client.callback_funcs_for_continue_training = types.MethodType(\n#         callback_funcs_for_continue_training, client)\n#     client._find_and_send_split = types.MethodType(_find_and_send_split,\n#                                                    client)\n#     client._check_eval_finish = types.MethodType(_check_eval_finish, client)\n# \n#     # Register handler functions\n#     client.register_handlers('split', client.callback_func_for_split)\n#     client.register_handlers('continue_training',\n#                              client.callback_funcs_for_continue_training)\n# \n#     return client\n# \n# \n# def wrap_server_for_train(server):\n# \n#     return server\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport types\nimport logging\nimport numpy as np\n\nfrom federatedscope.vertical_fl.loss.utils import get_vertical_loss\nfrom federatedscope.core.message import Message\n\nlogger = logging.getLogger(__name__)\n\n\ndef wrap_client_for_evaluation(client):\n    def eval(self, tree_num):\n        self.criterion = get_vertical_loss(self._cfg.criterion.type)\n        if self.test_x is None:\n            self.test_x, self.test_y = self._fetch_test_data()\n            self.test_result = np.zeros(self.test_x.shape[0])\n        self.model[tree_num][0].indicator = np.ones(self.test_x.shape[0])\n        self._test_for_node(tree_num, node_num=0)\n\n    def _fetch_test_data(self):\n        test_x = self.data['test']['x']\n        test_y = self.data['test']['y'] if 'y' in self.data['test'] else None\n\n        return test_x, test_y\n\n    def _feedback_eval_metrics(self):\n        test_loss = self.criterion.get_loss(self.test_y, self.test_result)\n        metrics = self.criterion.get_metric(self.test_y, self.test_result)\n        modified_metrics = dict()\n        for key in metrics.keys():\n            if 'test' not in key:\n                modified_metrics['test_' + key] = metrics[key]\n            else:\n                modified_metrics[key] = metrics[key]\n        modified_metrics.update({\n            'test_loss': test_loss,\n            'test_total': len(self.test_y)\n        })\n\n        self.comm_manager.send(\n            Message(msg_type='eval_metric',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[self.server_id],\n                    content=modified_metrics))\n        self.comm_manager.send(\n            Message(msg_type='feature_importance',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[self.server_id],\n                    content=self.feature_importance))\n        self.comm_manager.send(\n            Message(msg_type='ask_for_feature_importance',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[\n                        each\n                        for each in list(self.comm_manager.neighbors.keys())\n                        if each != self.server_id\n                    ],\n                    content='None'))\n\n    def _test_for_node(self, tree_num, node_num):\n        # All nodes have been traversed\n        if node_num >= 2**self.model.max_depth - 1:\n            if (\n                    tree_num + 1\n            ) % self._cfg.eval.freq == 0 or \\\n                    tree_num + 1 == self._cfg.model.num_of_trees:\n                self._feedback_eval_metrics()\n            self.eval_finish_flag = True\n            self._check_eval_finish(tree_num)\n        # The client owns the weight\n        elif self.model[tree_num][node_num].weight:\n            self.test_result += self.model[tree_num][\n                node_num].indicator * self.model[tree_num][\n                    node_num].weight * self._cfg.train.optimizer.eta\n            self._test_for_node(tree_num, node_num + 1)\n        # Other client owns the weight, need to communicate\n        elif self.model[tree_num][node_num].member:\n            self.comm_manager.send(\n                Message(msg_type='split_request',\n                        sender=self.ID,\n                        state=self.state,\n                        receiver=[self.model[tree_num][node_num].member],\n                        content=(tree_num, node_num)))\n        else:\n            self._test_for_node(tree_num, node_num + 1)\n\n    def callback_func_for_split_request(self, message: Message):\n        if self.test_x is None:\n            self.test_x, self.test_y = self._fetch_test_data()\n            self.test_result = np.zeros(self.test_x.shape[0])\n        tree_num, node_num = message.content\n        sender = message.sender\n        feature_idx = self.model[tree_num][node_num].feature_idx\n        feature_value = self.model[tree_num][node_num].feature_value\n        left_child, right_child = self.model[tree_num].split_childern(\n            self.test_x[:, feature_idx], feature_value)\n        self.comm_manager.send(\n            Message(msg_type='split_result',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[sender],\n                    content=(tree_num, node_num, left_child, right_child)))\n\n    def callback_func_for_split_result(self, message: Message):\n        tree_num, node_num, left_child, right_child = message.content\n        self.model[tree_num][2 * node_num + 1].indicator = self.model[\n            tree_num][node_num].indicator * left_child\n        self.model[tree_num][2 * node_num + 2].indicator = self.model[\n            tree_num][node_num].indicator * right_child\n        self._test_for_node(tree_num, node_num + 1)\n\n    def callback_func_for_feature_importance(self, message: Message):\n        state = message.state\n        self.comm_manager.send(\n            Message(msg_type='feature_importance',\n                    sender=self.ID,\n                    state=state,\n                    receiver=[self.server_id],\n                    content=self.feature_importance))\n\n    # Bind method to instance\n    client.eval = types.MethodType(eval, client)\n    client._fetch_test_data = types.MethodType(_fetch_test_data, client)\n    client._test_for_node = types.MethodType(_test_for_node, client)\n    client._feedback_eval_metrics = types.MethodType(_feedback_eval_metrics,\n                                                     client)\n    client.callback_func_for_split_request = types.MethodType(\n        callback_func_for_split_request, client)\n    client.callback_func_for_split_result = types.MethodType(\n        callback_func_for_split_result, client)\n    client.callback_func_for_feature_importance = types.MethodType(\n        callback_func_for_feature_importance, client)\n\n    # Register handler functions\n    client.register_handlers('split_request',\n                             client.callback_func_for_split_request)\n    client.register_handlers('split_result',\n                             client.callback_func_for_split_result)\n    client.register_handlers('ask_for_feature_importance',\n                             client.callback_func_for_feature_importance)\n\n    return client\n\n\ndef wrap_server_for_evaluation(server):\n    def _check_and_save_result(self):\n\n        state = max(self.msg_buffer['eval'].keys())", "choices": [{"text": "self.comm_manager.send("}], "metadata": {"task_id": "alibaba_FederatedScope/196", "ground_truth": "        buffer = self.msg_buffer['eval'][state]", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "evaluation_wrapper.py"], "context_start_lineno": 0, "line_no": 151, "query_window": {"context": "    client.callback_func_for_split_result = types.MethodType(\n        callback_func_for_split_result, client)\n    client.callback_func_for_feature_importance = types.MethodType(\n        callback_func_for_feature_importance, client)\n\n    # Register handler functions\n    client.register_handlers('split_request',\n                             client.callback_func_for_split_request)\n    client.register_handlers('split_result',\n                             client.callback_func_for_split_result)\n    client.register_handlers('ask_for_feature_importance',\n                             client.callback_func_for_feature_importance)\n\n    return client\n\n\ndef wrap_server_for_evaluation(server):\n    def _check_and_save_result(self):\n\n        state = max(self.msg_buffer['eval'].keys())", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "evaluation_wrapper.py"], "line_no": 151, "task_id": "alibaba_FederatedScope/196", "start_line_no": 131, "end_line_no": 151, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "    client.callback_func_for_split = types.MethodType(callback_func_for_split,\n                                                      client)\n    client.callback_funcs_for_continue_training = types.MethodType(\n        callback_funcs_for_continue_training, client)\n    client._find_and_send_split = types.MethodType(_find_and_send_split,\n                                                   client)\n    client._check_eval_finish = types.MethodType(_check_eval_finish, client)\n\n    # Register handler functions\n    client.register_handlers('split', client.callback_func_for_split)\n    client.register_handlers('continue_training',\n                             client.callback_funcs_for_continue_training)\n\n    return client\n\n\ndef wrap_server_for_train(server):\n\n    return server", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "train_wrapper.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 99, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.5277777777777778}, {"context": "        callback_func_for_ss_instance_sum_norm_square, worker)\n    worker.callback_func_for_instance_var = types.MethodType(\n        callback_func_for_instance_var, worker)\n\n    # Register handlers functions\n    worker.register_handlers('ask_for_instance_sum',\n                             worker.callback_func_for_ask_for_instance_sum)\n    worker.register_handlers('ss_instance_sum',\n                             worker.callback_func_ss_instance_sum)\n    worker.register_handlers('instance_mean',\n                             worker.callback_func_for_instance_mean)\n    worker.register_handlers(\n        'ss_instance_sum_norm_square',\n        worker.callback_func_for_ss_instance_sum_norm_square)\n    worker.register_handlers('instance_var',\n                             worker.callback_func_for_instance_var)\n    return worker", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "preprocess", "instance_norm.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 307, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4264705882352941}, {"context": "    worker.callback_func_for_iv_list = types.MethodType(\n        callback_func_for_iv_list, worker)\n    worker.callback_funcs_for_vertical_dims = types.MethodType(\n        callback_funcs_for_vertical_dims, worker)\n\n    # Register handlers functions\n    worker.register_handlers('binning', worker.callback_funcs_for_binning)\n    worker.register_handlers('en_y', worker.callback_func_for_en_y)\n    worker.register_handlers('sum_en_y', worker.callback_func_for_sum_en_y)\n    worker.register_handlers('iv_list', worker.callback_func_for_iv_list)\n    worker.register_handlers('vertical_dims',\n                             worker.callback_funcs_for_vertical_dims)\n\n    return worker", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "selection", "iv_filter.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 264, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3835616438356164}, {"context": "                    state=self.state,\n                    receiver=[sender],\n                    content=(tree_num, node_num)))\n\n    def callback_funcs_for_continue_training(self, message: Message):\n        tree_num, node_num = message.content\n        self.train(tree_num=tree_num, node_num=node_num + 1)\n\n    # Bind method to instance\n    client.train = types.MethodType(train, client)\n    client.callback_func_for_split = types.MethodType(callback_func_for_split,\n                                                      client)\n    client.callback_funcs_for_continue_training = types.MethodType(\n        callback_funcs_for_continue_training, client)\n    client._find_and_send_split = types.MethodType(_find_and_send_split,\n                                                   client)\n    client._check_eval_finish = types.MethodType(_check_eval_finish, client)\n\n    # Register handler functions\n    client.register_handlers('split', client.callback_func_for_split)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "train_wrapper.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3673469387755102}, {"context": "        callback_funcs_for_encrypted_norm_feat, worker)\n    worker.callbacks_funcs_for_feat_corrcoef = types.MethodType(\n        callbacks_funcs_for_feat_corrcoef, worker)\n    worker.callback_funcs_for_vertical_dims = types.MethodType(\n        callback_funcs_for_vertical_dims, worker)\n\n    # Register handlers functions\n    worker.register_handlers('feat_engr_public_keys',\n                             worker.callback_funcs_for_feat_engr_public_keys)\n    worker.register_handlers(\n        'ask_for_encrypted_norm_feat',\n        worker.callback_funcs_for_ask_for_encrypted_norm_feat)\n    worker.register_handlers('encrypted_norm_feat',\n                             worker.callback_funcs_for_encrypted_norm_feat)\n    worker.register_handlers('feat_corrcoef',\n                             worker.callbacks_funcs_for_feat_corrcoef)\n    worker.register_handlers('vertical_dims',\n                             worker.callback_funcs_for_vertical_dims)\n\n    return worker", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "selection", "correlation_filter.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3670886075949367}, {"context": "    worker.trigger_for_feat_engr = types.MethodType(trigger_for_feat_engr,\n                                                    worker)\n    worker.callback_func_for_ss_instance_sum = types.MethodType(\n        callback_func_for_ss_instance_sum, worker)\n    worker.callback_func_for_ss_instance_sum_norm_square = types.MethodType(\n        callback_func_for_ss_instance_sum_norm_square, worker)\n\n    # Register handlers functions\n    worker.register_handlers('ss_instance_sum',\n                             worker.callback_func_for_ss_instance_sum)\n    worker.register_handlers(\n        'ss_instance_sum_norm_square',\n        worker.callback_func_for_ss_instance_sum_norm_square)\n    return worker\n\n\ndef wrap_instance_norm_client(worker):\n    \"\"\"\n    This function is to perform instance norm vfl tabular data for client.\n    Args:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "preprocess", "instance_norm.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.35555555555555557}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/lenet.py\n# --------------------------------------------------\n#     dtype: Any = jnp.float32\n# \n#     @nn.compact\n#     def __call__(self, x: jnp.ndarray):\n#         \"\"\"\n#         Forward pass.\n# \n#         Parameters\n#         ----------\n#         x: jnp.ndarray\n#             Outputs of the deep feature extractor sub-network.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Model outputs.\n#         \"\"\"\n#         x = nn.relu(x)\n#         x = nn.Dense(features=self.output_dim, dtype=self.dtype)(x)\n#         return x\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Deep feature extractor subnetwork forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Deep feature extractor representation.\n#         \"\"\"\n#         conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n#         norm = partial(\n#             nn.BatchNorm,\n#             use_running_average=not train,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         self.dfe_subnet = DeepFeatureExtractorSubNet(\n#             stage_sizes=self.stage_sizes,\n#             block_cls=self.block_cls,\n#             num_filters=self.num_filters,\n#             dtype=self.dtype,\n#             activation=self.activation,\n#             conv=self.conv,\n#         )\n#         self.output_subnet = OutputSubNet(output_dim=self.output_dim, dtype=self.dtype)\n# \n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/cnn.py\n# --------------------------------------------------\n#     \"\"\"\n#     A CNN model.\n#     \n#     :param output_dim: int\n#         Output dimension.\n#     :param dropout_rate: Optional[float]\n#         Dropout rate.\n#     :param dtype: Any\n#         Data type. Default: `float32`.\n#     \"\"\"\n# \n#     def setup(self):\n#         self.hidden_layers = CNNHiddenLayers(\n#             dropout_rate=self.dropout_rate, dtype=self.dtype\n#         )\n#         self.last_layer = CNNLastLayer(output_dim=self.output_dim, dtype=self.dtype)\n# \n#     def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n#         x = self.hidden_layers(x, train)\n#         x = self.last_layer(x, train)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/cnn.py\n# --------------------------------------------------\n# from typing import Any\n# \n# import flax.linen as nn\n# import jax.numpy as jnp\n# \n# \n# class CNN(nn.Module):\n#     output_dim: int\n#     dropout_rate: float\n#     dtype: Any = jnp.float32\n#     \"\"\"\n#     A CNN model.\n#     \n#     :param output_dim: int\n#         Output dimension.\n#     :param dropout_rate: Optional[float]\n#         Dropout rate.\n#     :param dtype: Any\n#         Data type. Default: `float32`.\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#     block_cls: ModuleDef\n#         Block class.\n#     num_filters: int\n#         Number of filters.\n#     dtype: Any\n#         Layers' dtype.\n#     activation: Callable\n#         Activation function.\n#     conv: ModuleDef\n#         Convolution module.\n#     \"\"\"\n# \n#     stage_sizes: Sequence[int]\n#     block_cls: ModuleDef\n#     num_filters: int = 64\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     @nn.compact\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         Output dimension.\n#     num_filters: int\n#         Number of filters.\n#     dtype: Any\n#         Layers' dtype.\n#     activation: Callable\n#         Activation function.\n#     conv: ModuleDef\n#         Convolution module.\n#     \"\"\"\n# \n#     stage_sizes: Sequence[int]\n#     block_cls: ModuleDef\n#     output_dim: int\n#     num_filters: int = 64\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     def setup(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#     \"\"\"\n# \n#     stage_sizes: Sequence[int]\n#     block_cls: ModuleDef\n#     num_filters: int = 64\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     @nn.compact\n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Deep feature extractor subnetwork forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n# \n#     stage_sizes: Sequence[int]\n#     block_cls: ModuleDef\n#     output_dim: int\n#     num_filters: int = 64\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     def setup(self):\n#         self.dfe_subnet = DeepFeatureExtractorSubNet(\n#             stage_sizes=self.stage_sizes,\n#             block_cls=self.block_cls,\n#             num_filters=self.num_filters,\n#             dtype=self.dtype,\n#             activation=self.activation,\n#             conv=self.conv,\n#         )\n#         self.output_subnet = OutputSubNet(output_dim=self.output_dim, dtype=self.dtype)\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n WideResnetBlock(nn.Module):\n    \"\"\"\n    A wide residual network block.\n\n    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    filters: int\n        Number of filters.\n    strides: Tuple[int, int]\n        Strides.\n    :param dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Block forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Block inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Block outputs.\n        \"\"\"\n        dropout = nn.Dropout(rate=self.dropout_rate)\n\n        y = self.norm(name=\"bn1\")(x)\n        y = nn.relu(y)\n        y = self.conv(self.filters, (3, 3), self.strides, name=\"conv1\")(y)\n        y = self.norm(name=\"bn2\")(y)\n        y = nn.relu(y)\n        if self.dropout_rate > 0.0:\n            y = dropout(y, deterministic=not train)\n        y = self.conv(self.filters, (3, 3), name=\"conv2\")(y)\n\n        # Apply an up projection in case of channel mismatch\n        if (x.shape[-1] != self.filters) or self.strides != (1, 1):\n            x = self.conv(self.filters, (3, 3), self.strides)(x)\n        return x + y\n\n\nclass WideResnetGroup(nn.Module):\n    \"\"\"\n    A wide residual network group.\n\n    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    blocks_per_group: int\n        Number of blocks per group.\n    strides: Tuple[int, int]\n        Strides.\n    dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    blocks_per_group: int\n    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Group forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Group inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Group outputs.\n        \"\"\"\n        for i in range(self.blocks_per_group):\n            x = WideResnetBlock(\n                conv=self.conv,\n                norm=self.norm,\n                activation=self.activation,\n                filters=self.filters,\n                strides=self.strides if i == 0 else (1, 1),\n                dropout_rate=self.dropout_rate,\n            )(x, train=train)\n        return x\n\n\nclass DeepFeatureExtractorSubNet(nn.Module):\n    \"\"\"\n    Deep feature extractor subnetwork.\n\n    Attributes\n    ----------\n    depth: int\n        Depth of the subnetwork.\n    widen_factor: int\n        Widening factor.\n    dropout_rate: float\n        Dropout rate.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    depth: int = 28\n    widen_factor: int = 10\n    dropout_rate: float = 0.0\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    @nn.compact\n    def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Deep feature extractor subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: Array\n            Input data.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Deep feature extractor representation.\n        \"\"\"\n        blocks_per_group = (self.depth - 4) // 6\n\n        conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n        norm = partial(\n            nn.BatchNorm,\n            use_running_average=not train,\n            momentum=0.9,\n            epsilon=1e-5,\n            dtype=self.dtype,\n        )\n\n        x = conv(16, (3, 3), name=\"init_conv\")(x)\n        x = WideResnetGroup(\n            conv=conv,\n            norm=norm,\n            activation=self.activation,\n            blocks_per_group=blocks_per_group,\n            filters=16 * self.widen_factor,\n            strides=(1, 1),\n            dropout_rate=self.dropout_rate,\n        )(x, train=train)\n        x = WideResnetGroup(\n            conv=conv,\n            norm=norm,\n            activation=self.activation,\n            blocks_per_group=blocks_per_group,\n            filters=32 * self.widen_factor,\n            strides=(2, 2),\n            dropout_rate=self.dropout_rate,\n        )(x, train=train)\n        x = WideResnetGroup(\n            conv=conv,\n            norm=norm,\n            activation=self.activation,\n            blocks_per_group=blocks_per_group,\n            filters=64 * self.widen_factor,\n            strides=(2, 2),\n            dropout_rate=self.dropout_rate,\n        )(x, train=train)\n        x = norm()(x)\n        x = nn.relu(x)\n        x = nn.avg_pool(x, (8, 8))\n        x = x.reshape((x.shape[0], -1))\n        return x\n\n\nclass OutputSubNet(nn.Module):\n    \"\"\"\n    Output subnetwork.\n\n    Parameters\n    ----------\n    output_dim: int\n        Output dimension.\n    dtype: Any\n        Layers' dtype.\n    \"\"\"\n\n    output_dim: int\n    dtype: Any = jnp.float32\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Output subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Subnetwork inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Outputs.\n        \"\"\"\n        x = nn.Dense(self.output_dim, dtype=self.dtype)(x)\n        return x\n\n\nclass WideResNet(nn.Module):\n    \"\"\"\n    Wide residual network class.\n\n    Attributes\n    ----------\n    output_dim: int\n        Output dimension.\n    depth: int\n        Depth of the subnetwork.\n    widen_factor: int\n        Widening factor.\n    dropout_rate: float\n        Dropout rate.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    output_dim: int\n    depth: int = 28\n    widen_factor: int = 10\n    dropout_rate: float = 0.0\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu", "choices": [{"text": "conv: ModuleDef = nn.Conv"}], "metadata": {"task_id": "awslabs_fortuna/54", "ground_truth": "    conv: ModuleDef = nn.Conv", "fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "context_start_lineno": 15, "line_no": 287, "query_window": {"context": "    depth: int\n        Depth of the subnetwork.\n    widen_factor: int\n        Widening factor.\n    dropout_rate: float\n        Dropout rate.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    output_dim: int\n    depth: int = 28\n    widen_factor: int = 10\n    dropout_rate: float = 0.0\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 287, "task_id": "awslabs_fortuna/54", "start_line_no": 267, "end_line_no": 287, "window_size": 20, "context_start_lineno": 15, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        Output dimension.\n    num_filters: int\n        Number of filters.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    stage_sizes: Sequence[int]\n    block_cls: ModuleDef\n    output_dim: int\n    num_filters: int = 64\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    def setup(self):", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.46987951807228917}, {"context": "    block_cls: ModuleDef\n        Block class.\n    num_filters: int\n        Number of filters.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    stage_sizes: Sequence[int]\n    block_cls: ModuleDef\n    num_filters: int = 64\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    @nn.compact", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.45121951219512196}, {"context": "    \"\"\"\n     Deep feature extractor subnetwork.\n\n    Attributes\n    ----------\n    stage_sizes: Sequence[int]\n        Sizes for each stage.\n    block_cls: ModuleDef\n        Block class.\n    output_dim: int\n        Output dimension.\n    num_filters: int\n        Number of filters.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.36363636363636365}, {"context": "\n\nclass DeepFeatureExtractorSubNet(nn.Module):\n    \"\"\"\n     Deep feature extractor subnetwork.\n\n    Attributes\n    ----------\n    stage_sizes: Sequence[int]\n        Sizes for each stage.\n    block_cls: ModuleDef\n        Block class.\n    num_filters: int\n        Number of filters.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3125}, {"context": "from typing import Any\n\nimport flax.linen as nn\nimport jax.numpy as jnp\n\n\nclass CNN(nn.Module):\n    output_dim: int\n    dropout_rate: float\n    dtype: Any = jnp.float32", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "cnn.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.30666666666666664}, {"context": "from typing import Any\n\nimport flax.linen as nn\nimport jax.numpy as jnp\n\n\nclass CNN(nn.Module):\n    output_dim: int\n    dropout_rate: float\n    dtype: Any = jnp.float32\n    \"\"\"\n    A CNN model.\n    \n    :param output_dim: int\n        Output dimension.\n    :param dropout_rate: Optional[float]\n        Dropout rate.\n    :param dtype: Any\n        Data type. Default: `float32`.\n    \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "cnn.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3}, {"context": "\n    stage_sizes: Sequence[int]\n    block_cls: ModuleDef\n    output_dim: int\n    num_filters: int = 64\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    def setup(self):\n        self.dfe_subnet = DeepFeatureExtractorSubNet(\n            stage_sizes=self.stage_sizes,\n            block_cls=self.block_cls,\n            num_filters=self.num_filters,\n            dtype=self.dtype,\n            activation=self.activation,\n            conv=self.conv,\n        )\n        self.output_subnet = OutputSubNet(output_dim=self.output_dim, dtype=self.dtype)\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.27450980392156865}, {"context": "    \"\"\"\n\n    stage_sizes: Sequence[int]\n    block_cls: ModuleDef\n    num_filters: int = 64\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    @nn.compact\n    def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Deep feature extractor subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: Array\n            Input data.\n        train: bool\n            Whether the call is performed during training.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.26785714285714285}, {"context": "\n    Attributes\n    ----------\n    output_dim: int\n        The output model dimension.\n    dtype: Any\n        Layers' dtype.\n    \"\"\"\n\n    output_dim: int\n    dtype: Any = jnp.float32\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray):\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "lenet.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.26506024096385544}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/coma.py\n# --------------------------------------------------\n# from .base_policy import Policy\n# \n# \n# @POLICY_REGISTRY.register('coma')\n# class COMAPolicy(Policy):\n#     r\"\"\"\n#     Overview:\n#         Policy class of COMA algorithm. COMA is a multi model reinforcement learning algorithm\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n#             _reset_eval, _get_train_sample, default_model, _monitor_vars_learn\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      coma           | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n#         2  ``cuda``             bool     False          | Whether to use cuda for network        | this arg can be diff-\n#                                                                                                  | erent from modes\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/ace_dqn.py\n# --------------------------------------------------\n# from ding.utils.data import timestep_collate, default_collate, default_decollate\n# from .base_policy import Policy\n# \n# @POLICY_REGISTRY.register('smac_ace_dqn')\n# class SMACACEDQNPolicy(Policy):\n#     \"\"\"\n#     Overview:\n#         Policy class of ACE algorithm. ACE is a multi agent reinforcement learning algorithm, \\\n#             you can view the paper in the following link https://arxiv.org/abs/2211.16068\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn \\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval \\\n#             _reset_eval, _get_train_sample, default_model\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      qmix           | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n#         2  ``cuda``             bool     True           | Whether to use cuda for network        | this arg can be diff-\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/collaq.py\n# --------------------------------------------------\n# from .base_policy import Policy\n# \n# \n# @POLICY_REGISTRY.register('collaq')\n# class CollaQPolicy(Policy):\n#     r\"\"\"\n#     Overview:\n#         Policy class of CollaQ algorithm. CollaQ is a multi-agent reinforcement learning algorithm\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n#             _reset_eval, _get_train_sample, default_model\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      collaq         | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n#         2  ``cuda``             bool     True           | Whether to use cuda for network        | this arg can be diff-\n#                                                                                                  | erent from modes\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/wqmix.py\n# --------------------------------------------------\n# from .base_policy import Policy\n# from ding.policy.qmix import QMIXPolicy\n# \n# \n# @POLICY_REGISTRY.register('wqmix')\n# class WQMIXPolicy(QMIXPolicy):\n#     r\"\"\"\n#     Overview:\n#         Policy class of WQMIX algorithm. WQMIX is a reinforcement learning algorithm modified from Qmix, \\\n#             you can view the paper in the following link https://arxiv.org/abs/2006.10800\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n#             _reset_eval, _get_train_sample, default_model\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      qmix           | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/qmix.py\n# --------------------------------------------------\n# from .base_policy import Policy\n# \n# \n# @POLICY_REGISTRY.register('qmix')\n# class QMIXPolicy(Policy):\n#     r\"\"\"\n#     Overview:\n#         Policy class of QMIX algorithm. QMIX is a multi model reinforcement learning algorithm, \\\n#             you can view the paper in the following link https://arxiv.org/abs/1803.11485\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n#             _reset_eval, _get_train_sample, default_model\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      qmix           | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n#         2  ``cuda``             bool     True           | Whether to use cuda for network        | this arg can be diff-\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport torch.nn.functional as F\nimport copy\nfrom easydict import EasyDict\n\nfrom ding.torch_utils import Adam, RMSprop, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_epsilon_greedy_fn, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('qtran')\nclass QTRANPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of QTRAN algorithm. QTRAN is a multi model reinforcement learning algorithm, \\\n            you can view the paper in the following link https://arxiv.org/abs/1803.11485\n    Interface:\n        _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\", "choices": [{"text": "_init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\"}], "metadata": {"task_id": "opendilab_ACE/112", "ground_truth": "            _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\", "fpath_tuple": ["opendilab_ACE", "ding", "policy", "qtran.py"], "context_start_lineno": 0, "line_no": 23, "query_window": {"context": "import torch.nn.functional as F\nimport copy\nfrom easydict import EasyDict\n\nfrom ding.torch_utils import Adam, RMSprop, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_epsilon_greedy_fn, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('qtran')\nclass QTRANPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of QTRAN algorithm. QTRAN is a multi model reinforcement learning algorithm, \\\n            you can view the paper in the following link https://arxiv.org/abs/1803.11485\n    Interface:\n        _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "qtran.py"], "line_no": 23, "task_id": "opendilab_ACE/112", "start_line_no": 3, "end_line_no": 23, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\n\nfrom ding.torch_utils import RMSprop, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('qmix')\nclass QMIXPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of QMIX algorithm. QMIX is a multi model reinforcement learning algorithm, \\\n            you can view the paper in the following link https://arxiv.org/abs/1803.11485\n    Interface:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "qmix.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6923076923076923}, {"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\n\nfrom ding.torch_utils import RMSprop, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\nfrom ding.policy.qmix import QMIXPolicy\n\n\n@POLICY_REGISTRY.register('wqmix')\nclass WQMIXPolicy(QMIXPolicy):\n    r\"\"\"\n    Overview:\n        Policy class of WQMIX algorithm. WQMIX is a reinforcement learning algorithm modified from Qmix, \\\n            you can view the paper in the following link https://arxiv.org/abs/2006.10800", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "wqmix.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.609271523178808}, {"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\n\nfrom ding.torch_utils import to_device, RMSprop\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('collaq')\nclass CollaQPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of CollaQ algorithm. CollaQ is a multi-agent reinforcement learning algorithm\n    Interface:\n        _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "collaq.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5972222222222222}, {"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\nimport math\n\nfrom ding.torch_utils import Adam, RMSprop, to_device\nfrom ding.rl_utils import q_nstep_td_data, q_nstep_td_error, get_nstep_return_data, get_train_sample, l2_balance\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n@POLICY_REGISTRY.register('smac_ace_dqn')\nclass SMACACEDQNPolicy(Policy):\n    \"\"\"\n    Overview:\n        Policy class of ACE algorithm. ACE is a multi agent reinforcement learning algorithm, \\\n            you can view the paper in the following link https://arxiv.org/abs/2211.16068\n    Interface:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "ace_dqn.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5590062111801242}, {"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\n\nfrom ding.torch_utils import Adam, to_device\nfrom ding.rl_utils import coma_data, coma_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import default_collate, default_decollate, timestep_collate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('coma')\nclass COMAPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of COMA algorithm. COMA is a multi model reinforcement learning algorithm\n    Interface:\n        _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "coma.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5517241379310345}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#             spec = UnboundedContinuousTensorSpec(4)\n#         else:\n#             raise NotImplementedError\n# \n#         kwargs = {\"distribution_class\": TanhNormal}\n#         if out_keys == [\"loc\", \"scale\"]:\n#             dist_in_keys = [\"loc\", \"scale\"]\n#         elif out_keys == [\"loc_1\", \"scale_1\"]:\n#             dist_in_keys = {\"loc\": \"loc_1\", \"scale\": \"scale_1\"}\n#         else:\n#             raise NotImplementedError\n# \n#         if safe and spec is None:\n#             with pytest.raises(\n#                 RuntimeError,\n#                 match=\"is not a valid configuration as the tensor specs are not \"\n#                 \"specified\",\n#             ):\n#                 prob_module = SafeProbabilisticModule(\n#                     in_keys=dist_in_keys,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#             },\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n# \n#     def _step(\n#         self,\n#         tensordict: TensorDictBase,\n#     ) -> TensorDictBase:\n#         action = tensordict.get(\"action\")\n#         self.count += action.to(torch.int)\n#         return TensorDict(\n#             source={\n#                 \"observation\": self.count,\n#                 \"done\": self.count > self.max_steps,\n#                 \"reward\": torch.zeros_like(self.count, dtype=torch.float),\n#             },\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/vmas.py\n# --------------------------------------------------\n# \n#     def _init_env(self) -> Optional[int]:\n#         pass\n# \n#     def _set_seed(self, seed: Optional[int]):\n#         self._env.seed(seed)\n# \n#     def _reset(\n#         self, tensordict: Optional[TensorDictBase] = None, **kwargs\n#     ) -> TensorDictBase:\n#         if tensordict is not None and \"_reset\" in tensordict.keys():\n#             _reset = tensordict.get(\"_reset\")\n#             envs_to_reset = _reset.any(dim=0)\n#             for env_index, to_reset in enumerate(envs_to_reset):\n#                 if to_reset:\n#                     self._env.reset_at(env_index)\n#             done = _selective_unsqueeze(self._env.done(), batch_size=(self.num_envs,))\n#             obs = []\n#             infos = []\n#             dones = []\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#                 self._storage.load_state_dict(_storage)\n#             elif self._storage is None:\n#                 batch_size = _storage.pop(\"__batch_size\")\n#                 device = _storage.pop(\"__device\")\n#                 self._storage = TensorDict(\n#                     _storage, batch_size=batch_size, device=device\n#                 )\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         else:\n#             raise TypeError(\n#                 f\"Objects of type {type(_storage)} are not supported by ListStorage.load_state_dict\"\n#             )\n#         self.initialized = state_dict[\"initialized\"]\n#         self._len = state_dict[\"_len\"]\n# \n#     def _init(self, data: Union[TensorDictBase, torch.Tensor]) -> None:\n#         print(\"Creating a TensorStorage...\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#             )\n#         return {\n#             \"_storage\": _storage,\n#             \"initialized\": self.initialized,\n#             \"_len\": self._len,\n#         }\n# \n#     def load_state_dict(self, state_dict):\n#         _storage = copy(state_dict[\"_storage\"])\n#         if isinstance(_storage, torch.Tensor):\n#             if isinstance(self._storage, torch.Tensor):\n#                 self._storage.copy_(_storage)\n#             elif self._storage is None:\n#                 self._storage = _storage\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         elif isinstance(_storage, (dict, OrderedDict)):\n#             if isinstance(self._storage, TensorDictBase):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/collectors/collectors.py\n# --------------------------------------------------\n#             if self._td_env is None:\n#                 self._td_env = td.to(env_device)\n#             else:\n#                 self._td_env.update(td, inplace=True)\n#             return self._td_env\n#         else:\n#             return dest.update(td, inplace=True)\n# \n#     def _reset_if_necessary(self) -> None:\n#         done = self._tensordict.get(\"done\")\n#         if not self.reset_when_done:\n#             done = torch.zeros_like(done)\n#         steps = self._tensordict.get((\"collector\", \"step_count\"))\n#         done_or_terminated = done.squeeze(-1) | (steps == self.max_frames_per_traj)\n#         if self._has_been_done is None:\n#             self._has_been_done = done_or_terminated\n#         else:\n#             self._has_been_done = self._has_been_done | done_or_terminated\n#         if not self._has_been_done.all() and self.init_with_lag:\n#             _reset = torch.zeros_like(done_or_terminated).bernoulli_(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#             if isinstance(self._storage, torch.Tensor):\n#                 self._storage.copy_(_storage)\n#             elif self._storage is None:\n#                 self._storage = _storage\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         elif isinstance(_storage, (dict, OrderedDict)):\n#             if isinstance(self._storage, TensorDictBase):\n#                 self._storage.load_state_dict(_storage)\n#             elif self._storage is None:\n#                 batch_size = _storage.pop(\"__batch_size\")\n#                 device = _storage.pop(\"__device\")\n#                 self._storage = TensorDict(\n#                     _storage, batch_size=batch_size, device=device\n#                 )\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nsteps_ops = []\n        self._post_steps_log_ops = []\n        self._pre_steps_log_ops = []\n        self._post_optim_log_ops = []\n        self._pre_optim_ops = []\n        self._post_loss_ops = []\n        self._optimizer_ops = []\n        self._process_optim_batch_ops = []\n        self._post_optim_ops = []\n        self._modules = {}\n\n        if self.optimizer is not None:\n            optimizer_hook = OptimizerHook(self.optimizer)\n            optimizer_hook.register(self)\n\n    def register_module(self, module_name: str, module: Any) -> None:\n        if module_name in self._modules:\n            raise RuntimeError(\n                f\"{module_name} is already registered, choose a different name.\"\n            )\n        self._modules[module_name] = module\n\n    def _get_state(self):\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            state = StateDict(\n                collected_frames=self.collected_frames,\n                _last_log=self._last_log,\n                _last_save=self._last_save,\n                _optim_count=self._optim_count,\n            )\n        else:\n            state = OrderedDict(\n                collected_frames=self.collected_frames,\n                _last_log=self._last_log,\n                _last_save=self._last_save,\n                _optim_count=self._optim_count,\n            )\n        return state\n\n    @property\n    def app_state(self):\n        self._app_state = {\n            \"state\": StateDict(**self._get_state()),\n            \"collector\": self.collector,\n            \"loss_module\": self.loss_module,\n            **{k: item for k, item in self._modules.items()},\n        }\n        return self._app_state\n\n    def state_dict(self) -> Dict:\n        state = self._get_state()\n        state_dict = OrderedDict(\n            collector=self.collector.state_dict(),\n            loss_module=self.loss_module.state_dict(),\n            state=state,\n            **{k: item.state_dict() for k, item in self._modules.items()},\n        )\n        return state_dict\n\n    def load_state_dict(self, state_dict: Dict) -> None:\n        model_state_dict = state_dict[\"loss_module\"]\n        collector_state_dict = state_dict[\"collector\"]\n\n        self.loss_module.load_state_dict(model_state_dict)\n        self.collector.load_state_dict(collector_state_dict)\n        for key, item in self._modules.items():\n            item.load_state_dict(state_dict[key])\n\n        self.collected_frames = state_dict[\"state\"][\"collected_frames\"]\n        self._last_log = state_dict[\"state\"][\"_last_log\"]\n        self._last_save = state_dict[\"state\"][\"_last_save\"]\n        self._optim_count = state_dict[\"state\"][\"_optim_count\"]\n\n    def _save_trainer(self) -> None:\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            if not _has_ts:\n                raise ImportError(\n                    \"torchsnapshot not found. Consider installing torchsnapshot or \"\n                    \"using the torch checkpointing backend (`CKPT_BACKEND=torch`)\"\n                )\n            Snapshot.take(app_state=self.app_state, path=self.save_trainer_file)\n        elif _CKPT_BACKEND == \"torch\":\n            torch.save(self.state_dict(), self.save_trainer_file)\n        else:\n            raise NotImplementedError(\n                f\"CKPT_BACKEND should be one of {_CKPT_BACKEND.backends}, got {_CKPT_BACKEND}.\"\n            )\n\n    def save_trainer(self, force_save: bool = False) -> None:\n        _save = force_save\n        if self.save_trainer_file is not None:\n            if (self.collected_frames - self._last_save) > self.save_trainer_interval:\n                self._last_save = self.collected_frames\n                _save = True\n        if _save and self.save_trainer_file:\n            self._save_trainer()\n\n    def load_from_file(self, file: Union[str, pathlib.Path]) -> Trainer:\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            snapshot = Snapshot(path=file)\n            snapshot.restore(app_state=self.app_state)\n        elif _CKPT_BACKEND == \"torch\":\n            loaded_dict: OrderedDict = torch.load(file)\n            self.load_state_dict(loaded_dict)\n        return self\n\n    def set_seed(self):\n        seed = self.collector.set_seed(self.seed, static_seed=False)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n\n    @property\n    def collector(self) -> _DataCollector:\n        return self._collector\n\n    @collector.setter\n    def collector(self, collector: _DataCollector) -> None:\n        self._collector = collector\n\n    def register_op(self, dest: str, op: Callable, **kwargs) -> None:\n        if dest == \"batch_process\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._batch_process_ops.append((op, kwargs))\n\n        elif dest == \"pre_optim_steps\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._pre_optim_ops.append((op, kwargs))\n\n        elif dest == \"process_optim_batch\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._process_optim_batch_ops.append((op, kwargs))\n\n        elif dest == \"post_loss\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._post_loss_ops.append((op, kwargs))\n\n        elif dest == \"optimizer\":\n            _check_input_output_typehint(\n                op, input=[TensorDictBase, bool, float, int], output=TensorDictBase\n            )\n            self._optimizer_ops.append((op, kwargs))\n\n        elif dest == \"post_steps\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._post_steps_ops.append((op, kwargs))\n\n        elif dest == \"post_optim\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._post_optim_ops.append((op, kwargs))\n\n        elif dest == \"pre_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._pre_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_optim_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_optim_log_ops.append((op, kwargs))\n\n        else:\n            raise RuntimeError(", "choices": [{"text": "f\"Invalid op destination '{dest}'. Please choose one of the following: \""}], "metadata": {"task_id": "pytorch_rl/163", "ground_truth": "                f\"The hook collection {dest} is not recognised. Choose from:\"", "fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "context_start_lineno": 175, "line_no": 351, "query_window": {"context": "        elif dest == \"pre_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._pre_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_optim_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_optim_log_ops.append((op, kwargs))\n\n        else:\n            raise RuntimeError(", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "line_no": 351, "task_id": "pytorch_rl/163", "start_line_no": 331, "end_line_no": 351, "window_size": 20, "context_start_lineno": 175, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            )\n        return {\n            \"_storage\": _storage,\n            \"initialized\": self.initialized,\n            \"_len\": self._len,\n        }\n\n    def load_state_dict(self, state_dict):\n        _storage = copy(state_dict[\"_storage\"])\n        if isinstance(_storage, torch.Tensor):\n            if isinstance(self._storage, torch.Tensor):\n                self._storage.copy_(_storage)\n            elif self._storage is None:\n                self._storage = _storage\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n                )\n        elif isinstance(_storage, (dict, OrderedDict)):\n            if isinstance(self._storage, TensorDictBase):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.27722772277227725}, {"context": "            if td.device == torch.device(\"cpu\") and self.pin_memory:\n                td.pin_memory()\n            self._td_policy.update(td, inplace=True)\n        return self._td_policy\n\n    def _cast_to_env(\n        self, td: TensorDictBase, dest: Optional[TensorDictBase] = None\n    ) -> TensorDictBase:\n        env_device = self.env_device\n        if dest is None:\n            if self._td_env is None:\n                self._td_env = td.to(env_device)\n            else:\n                self._td_env.update(td, inplace=True)\n            return self._td_env\n        else:\n            return dest.update(td, inplace=True)\n\n    def _reset_if_necessary(self) -> None:\n        done = self._tensordict.get(\"done\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "collectors", "collectors.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26804123711340205}, {"context": "        _storage = self._storage\n        if isinstance(_storage, torch.Tensor):\n            pass\n        elif isinstance(_storage, TensorDictBase):\n            _storage = _storage.state_dict()\n        elif _storage is None:\n            _storage = {}\n        else:\n            raise TypeError(\n                f\"Objects of type {type(_storage)} are not supported by LazyTensorStorage.state_dict\"\n            )\n        return {\n            \"_storage\": _storage,\n            \"initialized\": self.initialized,\n            \"_len\": self._len,\n        }\n\n    def load_state_dict(self, state_dict):\n        _storage = copy(state_dict[\"_storage\"])\n        if isinstance(_storage, torch.Tensor):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2647058823529412}, {"context": "            if isinstance(self._storage, torch.Tensor):\n                self._storage.copy_(_storage)\n            elif self._storage is None:\n                self._storage = _storage\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n                )\n        elif isinstance(_storage, (dict, OrderedDict)):\n            if isinstance(self._storage, TensorDictBase):\n                self._storage.load_state_dict(_storage)\n            elif self._storage is None:\n                batch_size = _storage.pop(\"__batch_size\")\n                device = _storage.pop(\"__device\")\n                self._storage = TensorDict(\n                    _storage, batch_size=batch_size, device=device\n                )\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26}, {"context": "        ).expand(self.batch_size)\n\n    def _check_kwargs(self, kwargs: Dict):\n        if \"env\" not in kwargs:\n            raise TypeError(\"Could not find environment key 'env' in kwargs.\")\n        env = kwargs[\"env\"]\n        if not isinstance(env, vmas.simulator.environment.Environment):\n            raise TypeError(\n                \"env is not of type 'vmas.simulator.environment.Environment'.\"\n            )\n\n    def _init_env(self) -> Optional[int]:\n        pass\n\n    def _set_seed(self, seed: Optional[int]):\n        self._env.seed(seed)\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "vmas.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.25663716814159293}, {"context": "            self.count[_reset] = 0\n        else:\n            self.count[:] = 0\n        return TensorDict(\n            source={\n                \"observation\": self.count.clone(),\n                \"done\": self.count > self.max_steps,\n            },\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,\n    ) -> TensorDictBase:\n        action = tensordict.get(\"action\")\n        self.count += action.to(torch.int)\n        return TensorDict(\n            source={", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 890, "start_line_no": 880, "end_line_no": 900, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.25510204081632654}, {"context": "            spec=None,\n            in_keys=in_keys,\n            out_keys=out_keys,\n        )\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n        else:\n            raise NotImplementedError\n\n        kwargs = {\"distribution_class\": TanhNormal}\n        if out_keys == [\"loc\", \"scale\"]:\n            dist_in_keys = [\"loc\", \"scale\"]\n        elif out_keys == [\"loc_1\", \"scale_1\"]:\n            dist_in_keys = {\"loc\": \"loc_1\", \"scale\": \"scale_1\"}\n        else:", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2524271844660194}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_qrdqn():\n#     config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_ppo():\n#     config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_a2c():\n#     config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_rainbow():\n#     config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_c51():\n#     config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_qrdqn():\n#     config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_rainbow():\n#     config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_iqn():\n#     config = [deepcopy(cartpole_iqn_config), deepcopy(cartpole_iqn_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_a2c_with_nstep_return():\n#     config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n#     config[0].policy.collect.discount_factor = 0.9\n#     config[0].policy.collect.nstep = 3\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n# def test_impala():\n#     config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_her_dqn():\n#     bitflip_her_dqn_config.policy.cuda = False\n#     try:\n#         bitflip_dqn_main(bitflip_her_dqn_config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_collaq():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#     config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n#     config[0].policy.collect.discount_factor = 0.9\n#     config[0].policy.collect.nstep = 3\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_impala():\n#     config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n_config, cooperative_navigation_wqmix_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_vdn_config, cooperative_navigation_vdn_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_coma_config, cooperative_navigation_coma_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_collaq_config, cooperative_navigation_collaq_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_atoc_config, cooperative_navigation_atoc_create_config  # noqa\nfrom dizoo.league_demo.league_demo_ppo_config import league_demo_ppo_config\nfrom dizoo.league_demo.selfplay_demo_ppo_main import main as selfplay_main\nfrom dizoo.league_demo.league_demo_ppo_main import main as league_main\nfrom dizoo.classic_control.pendulum.config.pendulum_sac_data_generation_default_config import pendulum_sac_data_genearation_default_config, pendulum_sac_data_genearation_default_create_config  # noqa\nfrom dizoo.classic_control.pendulum.config.pendulum_cql_config import pendulum_cql_default_config, pendulum_cql_default_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_qrdqn_generation_data_config import cartpole_qrdqn_generation_data_config, cartpole_qrdqn_generation_data_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_cql_config import cartpole_discrete_cql_config, cartpole_discrete_cql_create_config  # noqa\n\nwith open(\"./algo_record.log\", \"w+\") as f:\n    f.write(\"ALGO TEST STARTS\\n\")\n\n\n@pytest.mark.algotest\ndef test_dqn():\n    config = [deepcopy(cartpole_dqn_config), deepcopy(cartpole_dqn_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"1. dqn\\n\")\n\n\n@pytest.mark.algotest\ndef test_ddpg():\n    config = [deepcopy(pendulum_ddpg_config), deepcopy(pendulum_ddpg_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"2. ddpg\\n\")\n\n\n@pytest.mark.algotest\ndef test_td3():\n    config = [deepcopy(pendulum_td3_config), deepcopy(pendulum_td3_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"3. td3\\n\")\n\n\n@pytest.mark.algotest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"4. a2c\\n\")\n\n\n@pytest.mark.algotest\ndef test_rainbow():\n    config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"5. rainbow\\n\")\n\n\n@pytest.mark.algotest\ndef test_ppo():\n    config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n    try:\n        ppo_main(config[0], seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"6. ppo\\n\")\n\n\n# @pytest.mark.algotest\ndef test_collaq():\n    config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"7. collaq\\n\")\n\n\n# @pytest.mark.algotest\ndef test_coma():\n    config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"8. coma\\n\")\n\n\n@pytest.mark.algotest\ndef test_sac():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"9. sac\\n\")\n\n\n@pytest.mark.algotest\ndef test_c51():\n    config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"10. c51\\n\")\n\n\n@pytest.mark.algotest\ndef test_r2d2():\n    config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"11. r2d2\\n\")\n\n\n@pytest.mark.algotest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"12. a2c with nstep return\\n\")\n\n\n# @pytest.mark.algotest", "choices": [{"text": "def test_her_dqn():"}], "metadata": {"task_id": "opendilab_ACE/83", "ground_truth": "def test_atoc():", "fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "context_start_lineno": 32, "line_no": 185, "query_window": {"context": "        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"11. r2d2\\n\")\n\n\n@pytest.mark.algotest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"12. a2c with nstep return\\n\")\n\n\n# @pytest.mark.algotest", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 185, "task_id": "opendilab_ACE/83", "start_line_no": 165, "end_line_no": 185, "window_size": 20, "context_start_lineno": 32, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.64}, {"context": "    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_impala():\n    config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5882352941176471}, {"context": "    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_r2d2():\n    config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5742574257425742}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_rainbow():\n    config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5196078431372549}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_iqn():\n    config = [deepcopy(cartpole_iqn_config), deepcopy(cartpole_iqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_c51():\n    config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5098039215686274}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_td3():\n    config = [deepcopy(pendulum_td3_config), deepcopy(pendulum_td3_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5096153846153846}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_c51():\n    config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_qrdqn():\n    config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5048543689320388}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#       with self._lock:\n#         trial_protos = (\n#             self._owners[resource.owner_id]\n#             .studies[resource.study_id]\n#             .trial_protos\n#         )\n#         if resource.trial_id not in trial_protos:\n#           raise custom_errors.NotFoundError(\n#               'Trial %s does not exist.' % trial.name\n#           )\n#         trial_protos[resource.trial_id] = copy.deepcopy(trial)\n#       return resource\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not update Trial with name:', resource.name\n#       ) from err\n# \n#   def list_trials(self, study_name: str) -> List[study_pb2.Trial]:\n#     resource = resources.StudyResource.from_name(study_name)\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#         trial_protos[resource.trial_id] = copy.deepcopy(trial)\n#       return resource\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not update Trial with name:', resource.name\n#       ) from err\n# \n#   def list_trials(self, study_name: str) -> List[study_pb2.Trial]:\n#     resource = resources.StudyResource.from_name(study_name)\n#     try:\n#       with self._lock:\n#         return copy.deepcopy(\n#             list(\n#                 self._owners[resource.owner_id]\n#                 .studies[resource.study_id]\n#                 .trial_protos.values()\n#             )\n#         )\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#             .trial_protos[resource.trial_id]\n#         )\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not get Trial with name:', resource.name\n#       ) from err\n# \n#   def update_trial(self, trial: study_pb2.Trial) -> resources.TrialResource:\n#     resource = resources.TrialResource.from_name(trial.name)\n#     try:\n#       with self._lock:\n#         trial_protos = (\n#             self._owners[resource.owner_id]\n#             .studies[resource.study_id]\n#             .trial_protos\n#         )\n#         if resource.trial_id not in trial_protos:\n#           raise custom_errors.NotFoundError(\n#               'Trial %s does not exist.' % trial.name\n#           )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#         trial_protos[resource.trial_id] = copy.deepcopy(trial)\n#     return resource\n# \n#   def get_trial(self, trial_name: str) -> study_pb2.Trial:\n#     resource = resources.TrialResource.from_name(trial_name)\n#     try:\n#       with self._lock:\n#         return copy.deepcopy(\n#             self._owners[resource.owner_id]\n#             .studies[resource.study_id]\n#             .trial_protos[resource.trial_id]\n#         )\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not get Trial with name:', resource.name\n#       ) from err\n# \n#   def update_trial(self, trial: study_pb2.Trial) -> resources.TrialResource:\n#     resource = resources.TrialResource.from_name(trial.name)\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#       with self._lock:\n#         return copy.deepcopy(\n#             self._owners[resource.owner_id]\n#             .studies[resource.study_id]\n#             .study_proto\n#         )\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not get Study with name:', resource.name\n#       ) from err\n# \n#   def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n#     resource = resources.StudyResource.from_name(study.name)\n#     try:\n#       with self._lock:\n#         self._owners[resource.owner_id].studies[\n#             resource.study_id\n#         ].study_proto.CopyFrom(study)\n#       return resource\n#     except KeyError as err:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n# \n#   def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n#     resource = resources.StudyResource.from_name(study.name)\n#     try:\n#       with self._lock:\n#         self._owners[resource.owner_id].studies[\n#             resource.study_id\n#         ].study_proto.CopyFrom(study)\n#       return resource\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not update Study with name:', resource.name\n#       ) from err\n# \n#   def delete_study(self, study_name: str) -> None:\n#     resource = resources.StudyResource.from_name(study_name)\n#     try:\n#       with self._lock:\n#         del self._owners[resource.owner_id].studies[resource.study_id]\n#     except KeyError as err:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#       raise custom_errors.NotFoundError(\n#           'Could not update Study with name:', resource.name\n#       ) from err\n# \n#   def delete_study(self, study_name: str) -> None:\n#     resource = resources.StudyResource.from_name(study_name)\n#     try:\n#       with self._lock:\n#         del self._owners[resource.owner_id].studies[resource.study_id]\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Study does not exist:', study_name\n#       ) from err\n# \n#   def list_studies(self, owner_name: str) -> List[study_pb2.Study]:\n#     resource = resources.OwnerResource.from_name(owner_name)\n#     try:\n#       with self._lock:\n#         study_nodes = list(self._owners[resource.owner_id].studies.values())\n#         return copy.deepcopy(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"Implementation of SQL Datastore.\"\"\"\nimport collections\nimport threading\nfrom typing import Callable, DefaultDict, Iterable, List, Optional\nfrom absl import logging\n\nimport sqlalchemy as sqla\n\nfrom vizier.service import custom_errors\nfrom vizier.service import datastore\nfrom vizier.service import key_value_pb2\nfrom vizier.service import resources\nfrom vizier.service import study_pb2\nfrom vizier.service import vizier_oss_pb2\nfrom google.longrunning import operations_pb2\n\n\n# TODO: Consider using ORM API (when fixed) to reduce code length.\nclass SQLDataStore(datastore.DataStore):\n  \"\"\"SQL Datastore.\"\"\"\n\n  def __init__(self, engine):\n    self._engine = engine\n    self._connection = self._engine.connect()\n    self._root_metadata = sqla.MetaData()\n    self._owners_table = sqla.Table(\n        'owners',\n        self._root_metadata,\n        sqla.Column('owner_name', sqla.String, primary_key=True),\n    )\n    self._studies_table = sqla.Table(\n        'studies',\n        self._root_metadata,\n        sqla.Column('study_name', sqla.String, primary_key=True),\n        sqla.Column('owner_id', sqla.String),\n        sqla.Column('study_id', sqla.String),\n        sqla.Column('serialized_study', sqla.String),\n    )\n    self._trials_table = sqla.Table(\n        'trials',\n        self._root_metadata,\n        sqla.Column('trial_name', sqla.String, primary_key=True),\n        sqla.Column('owner_id', sqla.String),\n        sqla.Column('study_id', sqla.String),\n        sqla.Column('trial_id', sqla.INTEGER),\n        sqla.Column('serialized_trial', sqla.String),\n    )\n    self._suggestion_operations_table = sqla.Table(\n        'suggestion_operations',\n        self._root_metadata,\n        sqla.Column('operation_name', sqla.String, primary_key=True),\n        sqla.Column('owner_id', sqla.String),\n        sqla.Column('study_id', sqla.String),\n        sqla.Column('client_id', sqla.String),\n        sqla.Column('operation_number', sqla.INTEGER),\n        sqla.Column('serialized_op', sqla.String),\n    )\n    self._early_stopping_operations_table = sqla.Table(\n        'early_stopping_operations',\n        self._root_metadata,\n        sqla.Column('operation_name', sqla.String, primary_key=True),\n        sqla.Column('owner_id', sqla.String),\n        sqla.Column('study_id', sqla.String),\n        sqla.Column('trial_id', sqla.INTEGER),\n        sqla.Column('serialized_op', sqla.String),\n    )\n    # This lock is meant to lock `execute()` calls for database types which\n    # don't support multi-threading, like SQLite.\n    self._lock = threading.Lock()\n    self._root_metadata.create_all(self._engine)\n\n  def create_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    study_resource = resources.StudyResource.from_name(study.name)\n    owner_name = study_resource.owner_resource.name\n    owner_query = self._owners_table.insert().values(owner_name=owner_name)\n    study_query = self._studies_table.insert().values(\n        study_name=study.name,\n        owner_id=study_resource.owner_id,\n        study_id=study_resource.study_id,\n        serialized_study=study.SerializeToString(),\n    )\n\n    with self._lock:\n      try:\n        self._connection.execute(owner_query)\n      except sqla.exc.IntegrityError:\n        logging.info('Owner with name %s currently exists.', owner_name)\n      try:\n        self._connection.execute(study_query)\n        return study_resource\n      except sqla.exc.IntegrityError as integrity_error:\n        raise custom_errors.AlreadyExistsError(\n            'Study with name %s already exists.' % study.name\n        ) from integrity_error\n\n  def load_study(self, study_name: str) -> study_pb2.Study:\n    query = sqla.select([self._studies_table])\n    query = query.where(self._studies_table.c.study_name == study_name)\n\n    with self._lock:\n      result = self._connection.execute(query)\n\n    row = result.fetchone()\n    if not row:\n      raise custom_errors.NotFoundError(\n          'Failed to find study name: %s' % study_name\n      )\n    return study_pb2.Study.FromString(row['serialized_study'])\n\n  def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    study_resource = resources.StudyResource.from_name(study.name)\n    exists_query = sqla.exists(\n        sqla.select([self._studies_table]).where(", "choices": [{"text": "owner_id == study_resource.owner_id and"}], "metadata": {"task_id": "google_vizier/106", "ground_truth": "            self._studies_table.c.study_name == study.name", "fpath_tuple": ["google_vizier", "vizier", "service", "sql_datastore.py"], "context_start_lineno": 0, "line_no": 129, "query_window": {"context": "        ) from integrity_error\n\n  def load_study(self, study_name: str) -> study_pb2.Study:\n    query = sqla.select([self._studies_table])\n    query = query.where(self._studies_table.c.study_name == study_name)\n\n    with self._lock:\n      result = self._connection.execute(query)\n\n    row = result.fetchone()\n    if not row:\n      raise custom_errors.NotFoundError(\n          'Failed to find study name: %s' % study_name\n      )\n    return study_pb2.Study.FromString(row['serialized_study'])\n\n  def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    study_resource = resources.StudyResource.from_name(study.name)\n    exists_query = sqla.exists(\n        sqla.select([self._studies_table]).where(", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "service", "sql_datastore.py"], "line_no": 129, "task_id": "google_vizier/106", "start_line_no": 109, "end_line_no": 129, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "\n  def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    resource = resources.StudyResource.from_name(study.name)\n    try:\n      with self._lock:\n        self._owners[resource.owner_id].studies[\n            resource.study_id\n        ].study_proto.CopyFrom(study)\n      return resource\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not update Study with name:', resource.name\n      ) from err\n\n  def delete_study(self, study_name: str) -> None:\n    resource = resources.StudyResource.from_name(study_name)\n    try:\n      with self._lock:\n        del self._owners[resource.owner_id].studies[resource.study_id]\n    except KeyError as err:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.43636363636363634}, {"context": "      with self._lock:\n        return copy.deepcopy(\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .study_proto\n        )\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not get Study with name:', resource.name\n      ) from err\n\n  def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    resource = resources.StudyResource.from_name(study.name)\n    try:\n      with self._lock:\n        self._owners[resource.owner_id].studies[\n            resource.study_id\n        ].study_proto.CopyFrom(study)\n      return resource\n    except KeyError as err:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.41964285714285715}, {"context": "          study_dict.update(temp_dict)\n        else:\n          raise custom_errors.AlreadyExistsError(\n              'Study with that name already exists.', study.name\n          )\n    return resource\n\n  def load_study(self, study_name: str) -> study_pb2.Study:\n    resource = resources.StudyResource.from_name(study_name)\n    try:\n      with self._lock:\n        return copy.deepcopy(\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .study_proto\n        )\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not get Study with name:', resource.name\n      ) from err", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4117647058823529}, {"context": "      trial_protos = (\n          self._owners[resource.owner_id]\n          .studies[resource.study_id]\n          .trial_protos\n      )\n      if resource.trial_id in trial_protos:\n        raise custom_errors.AlreadyExistsError(\n            'Trial %s already exists' % trial.name\n        )\n      else:\n        trial_protos[resource.trial_id] = copy.deepcopy(trial)\n    return resource\n\n  def get_trial(self, trial_name: str) -> study_pb2.Trial:\n    resource = resources.TrialResource.from_name(trial_name)\n    try:\n      with self._lock:\n        return copy.deepcopy(\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4107142857142857}, {"context": "        trial_protos[resource.trial_id] = copy.deepcopy(trial)\n    return resource\n\n  def get_trial(self, trial_name: str) -> study_pb2.Trial:\n    resource = resources.TrialResource.from_name(trial_name)\n    try:\n      with self._lock:\n        return copy.deepcopy(\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .trial_protos[resource.trial_id]\n        )\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not get Trial with name:', resource.name\n      ) from err\n\n  def update_trial(self, trial: study_pb2.Trial) -> resources.TrialResource:\n    resource = resources.TrialResource.from_name(trial.name)\n    try:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.40707964601769914}, {"context": "      with self._lock:\n        trial_protos = (\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .trial_protos\n        )\n        if resource.trial_id not in trial_protos:\n          raise custom_errors.NotFoundError(\n              'Trial %s does not exist.' % trial.name\n          )\n        trial_protos[resource.trial_id] = copy.deepcopy(trial)\n      return resource\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not update Trial with name:', resource.name\n      ) from err\n\n  def list_trials(self, study_name: str) -> List[study_pb2.Trial]:\n    resource = resources.StudyResource.from_name(study_name)\n    try:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4065040650406504}, {"context": "            .trial_protos[resource.trial_id]\n        )\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not get Trial with name:', resource.name\n      ) from err\n\n  def update_trial(self, trial: study_pb2.Trial) -> resources.TrialResource:\n    resource = resources.TrialResource.from_name(trial.name)\n    try:\n      with self._lock:\n        trial_protos = (\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .trial_protos\n        )\n        if resource.trial_id not in trial_protos:\n          raise custom_errors.NotFoundError(\n              'Trial %s does not exist.' % trial.name\n          )", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4051724137931034}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         jnp.ndarray\n#             The estimated variance for each output.\n#         \"\"\"\n#         return super().variance(outputs, calibrated, **kwargs)\n# \n#     def std(\n#         self,\n#         outputs: jnp.ndarray,\n#         variances: Optional[jnp.ndarray] = None,\n#         calibrated: bool = True,\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the standard deviation of the one-hot encoded target variable given the output, with respect to the\n#         predictive distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         variances: Optional[jnp.ndarray]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n#         jnp.ndarray\n#             The estimated quantiles for each output.\n#         \"\"\"\n#         if calibrated:\n#             self._check_calibrated()\n#             state = self.state.get()\n#             outputs = self.output_calib_manager.apply(\n#                 params=state.params[\"output_calibrator\"],\n#                 outputs=outputs,\n#                 mutable=state.mutable[\"output_calibrator\"],\n#             )\n#         return self.prob_output_layer.quantile(q, outputs, n_target_samples, rng)\n# \n#     def credible_interval(\n#         self,\n#         outputs: Array,\n#         n_target_samples: int = 30,\n#         error: float = 0.05,\n#         interval_type: str = \"two-tailed\",\n#         rng: Optional[PRNGKeyArray] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated credible interval for each output.\n#         \"\"\"\n#         if calibrated:\n#             self._check_calibrated()\n#             state = self.state.get()\n#             outputs = self.output_calib_manager.apply(\n#                 params=state.params[\"output_calibrator\"],\n#                 outputs=outputs,\n#                 mutable=state.mutable[\"output_calibrator\"],\n#             )\n#         return self.prob_output_layer.credible_interval(\n#             outputs, n_target_samples, error, interval_type, rng\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         \"\"\"\n#         return super().mean(outputs, calibrated, **kwargs)\n# \n#     def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mode for each output.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mode for each output.\n#         \"\"\"\n#         return super().mode(outputs, calibrated, **kwargs)\n# \n#     def variance(\n#         self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         \"\"\"\n#         return super().mode(outputs, calibrated, **kwargs)\n# \n#     def variance(\n#         self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mean for each output.\n#         \"\"\"\n#         return super().mean(outputs, calibrated, **kwargs)\n# \n#     def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated variance for each output.\n#         \"\"\"\n#         return super().variance(outputs, calibrated, **kwargs)\n# \n#     def std(\n#         self,\n#         outputs: jnp.ndarray,\n#         variances: Optional[jnp.ndarray] = None,\n#         calibrated: bool = True,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport abc\nfrom typing import Any, List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG, abc.ABC):\n    def __init__(\n        self,\n        output_calib_manager: OutputCalibManager,\n        prob_output_layer: ProbOutputLayer,\n    ):\n        r\"\"\"\n        Abstract predictive distribution. It characterizes the distribution of the target variable given the\n        calibrated outputs. It can be see as :math:`p(y|\\omega)`, where :math:`y` is a target variable and\n        :math:`\\omega` a calibrated output.\n        \"\"\"\n        self.output_calib_manager = output_calib_manager\n        self.prob_output_layer = prob_output_layer\n        self.state = None\n\n    def log_prob(\n        self, outputs: Array, targets: Array, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Evaluate the log-probability density function (a.k.a. log-pdf) given the outputs and target data.\n\n        Parameters\n        ----------\n        outputs : Array\n            Calibrated outputs.\n        targets : Array\n            Target data points.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            An evaluation of the log-pdf for each data point.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.log_prob(outputs, targets, **kwargs)\n\n    def sample(\n        self,\n        n_target_samples: int,\n        outputs: Array,\n        rng: Optional[PRNGKeyArray] = None,\n        calibrated: bool = True,\n        **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Sample target variables for each outputs.\n\n        Parameters\n        ----------\n        n_target_samples: int\n            The number of target samples to draw for each of the outputs.\n        outputs : Array\n            Calibrated outputs.\n        rng : Optional[PRNGKeyArray]\n            A random number generator. If not passed, this will be taken from the attributes of this class.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            Samples of the target variable for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.sample(n_target_samples, outputs, rng, **kwargs)\n\n    def mean(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mean of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mean for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.mean(outputs, **kwargs)\n\n    def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mode of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mode for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.mode(outputs, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the", "choices": [{"text": "model must have been calibrated beforehand."}], "metadata": {"task_id": "awslabs_fortuna/98", "ground_truth": "            model must have been calibrated beforehand.", "fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "base.py"], "context_start_lineno": 0, "line_no": 163, "query_window": {"context": "            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.mode(outputs, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "base.py"], "line_no": 163, "task_id": "awslabs_fortuna/98", "start_line_no": 143, "end_line_no": 163, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        \"\"\"\n        return super().mode(outputs, calibrated, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.65}, {"context": "            prob_output_layer=prob_output_layer,\n        )\n\n    def mean(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mean of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mean for each output.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6132075471698113}, {"context": "        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mode for each output.\n        \"\"\"\n        return super().mode(outputs, calibrated, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5849056603773585}, {"context": "        \"\"\"\n        return super().mean(outputs, calibrated, **kwargs)\n\n    def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mode for each output.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5648148148148148}, {"context": "        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mean for each output.\n        \"\"\"\n        return super().mean(outputs, calibrated, **kwargs)\n\n    def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5596330275229358}, {"context": "            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated credible interval for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.credible_interval(\n            outputs, n_target_samples, error, interval_type, rng\n        )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 109, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.543859649122807}, {"context": "        n_target_samples: Optional[int]\n            Number of target samples to draw when computing quantiles.\n        rng: Optional[PRNGKeyArray]\n            A random number generator.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated quantiles for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4959349593495935}, {"context": "        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated variance for each output.\n        \"\"\"\n        return super().variance(outputs, calibrated, **kwargs)\n\n    def std(\n        self,\n        outputs: jnp.ndarray,\n        variances: Optional[jnp.ndarray] = None,\n        calibrated: bool = True,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4727272727272727}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#         Bounds and feasible_values, if provided, must consist of\n#         elements of the same type.\n#       TypeError: If children's matching_parent_values are not compatible with\n#         the ParameterConfig being created.\n#     \"\"\"\n#     if not name:\n#       raise ValueError('Parameter name cannot be empty.')\n# \n#     if bool(feasible_values) == bool(bounds):\n#       raise ValueError(\n#           'While creating Parameter with name={}: exactly one of '\n#           '\"feasible_values\" or \"bounds\" must be provided, but given '\n#           'feasible_values={} and bounds={}.'.format(name, feasible_values,\n#                                                      bounds))\n#     if feasible_values:\n#       if len(set(feasible_values)) != len(feasible_values):\n#         counter = collections.Counter(feasible_values)\n#         duplicate_dict = {k: v for k, v in counter.items() if v > 1}\n#         raise ValueError(\n#             'Feasible values cannot have duplicates: {}'.format(duplicate_dict))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#       bounds: REQUIRED for INTEGER or DOUBLE type. Specifies (min, max). The\n#         type of (min, max) determines the created ParameterConfig's type.\n#       feasible_values: REQUIRED for DISCRETE or CATEGORICAL type. The elements'\n#         type determines the created ParameterConfig's type.\n#       children: sequence of tuples formatted as: (matching_parent_values,\n#         ParameterConfig). ONLY THE TYPES ARE VALIDATED. If the child\n#         ParameterConfig protos already have parent values set, they will be\n#         overridden by the provided matching_parent_values.\n#       fidelity_config: Fidelity config.  NOT VALIDATED.\n#       scale_type: Scaling to be applied. NOT VALIDATED.\n#       default_value: A default value for the Parameter.\n#       external_type: An annotation indicating the type this parameter should be\n#         cast to.\n# \n#     Returns:\n#       A ParameterConfig object which wraps a partially validated proto.\n# \n#     Raises:\n#       ValueError: Exactly one of feasible_values and bounds must be convertible\n#         to Boolean true. Bounds and numeric feasible_values must be finite.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config.py\n# --------------------------------------------------\n#       raise ValueError('Invalid trial for this search space: failed to convert '\n#                        'all trial parameters: {}'.format(pytrial))\n# \n#     # Combine multi-dimensional parameter values to a list of values.\n#     trial_final_values: Dict[str, ParameterValueSequence] = {}\n#     # multi_dim_params: Dict[str, List[Tuple[int, ParameterValueSequence]]]\n#     multi_dim_params = collections.defaultdict(list)\n#     for name in trial_external_values:\n#       base_index = (\n#           vz.SearchSpaceSelector.parse_multi_dimensional_parameter_name(name)\n#       )\n#       if base_index is None:\n#         trial_final_values[name] = trial_external_values[name]\n#       else:\n#         base_name, index = base_index\n#         multi_dim_params[base_name].append((index, trial_external_values[name]))\n#     for name in multi_dim_params:\n#       multi_dim_params[name].sort(key=lambda x: x[0])\n#       trial_final_values[name] = [x[1] for x in multi_dim_params[name]]\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#       default_value: A default value for the Parameter.\n#       external_type: An annotation indicating the type this parameter should be\n#         cast to.\n# \n#     Returns:\n#       A ParameterConfig object which wraps a partially validated proto.\n# \n#     Raises:\n#       ValueError: Exactly one of feasible_values and bounds must be convertible\n#         to Boolean true. Bounds and numeric feasible_values must be finite.\n#         Bounds and feasible_values, if provided, must consist of\n#         elements of the same type.\n#       TypeError: If children's matching_parent_values are not compatible with\n#         the ParameterConfig being created.\n#     \"\"\"\n#     if not name:\n#       raise ValueError('Parameter name cannot be empty.')\n# \n#     if bool(feasible_values) == bool(bounds):\n#       raise ValueError(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#       if not math.isclose(default_value, default_int_value):\n#         raise ValueError('default_value for an INTEGER parameter should be an '\n#                          'integer, got float: [{}]'.format(default_value))\n#       return default_int_value\n#   elif (param_type == ParameterType.CATEGORICAL and\n#         isinstance(default_value, str)):\n#     return default_value\n#   raise ValueError(\n#       'default_value has an incorrect type. ParameterType has type {}, '\n#       'but default_value has type {}'.format(param_type.name,\n#                                              type(default_value)))\n# \n# \n# #######################\n# # Experimental features\n# #######################\n# class FidelityMode(enum.Enum):\n#   \"\"\"Decides how the fidelity config should be interpreated.\n# \n#   SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#                                              type(default_value)))\n# \n# \n# #######################\n# # Experimental features\n# #######################\n# class FidelityMode(enum.Enum):\n#   \"\"\"Decides how the fidelity config should be interpreated.\n# \n#   SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower\n#     fidelity measurement. Currently, no algorithms can take advatange of it, and\n#     Vizier behaves exactly like NON_SEQUENTIAL case. This is for tracking\n#     purposes only.\n# \n#   NOT_SEQUENTIAL: Each fidelity is separately measured. Example: Fidelity\n#     is the fraction of dataset to train on.\n# \n#   STEPS: Fidelity determines the maximum value for Measurement.steps reported\n#     to Vizier. There is one-to-one correspondence between steps and fidelity.\n#     A high fideltiy Trial's measurements contain lower fidelity evaluations.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n    try:\n      self.type.assert_correct_type(value)\n    except TypeError as e:\n      raise TypeError(\n          f'Parameter {self.name} is not compatible with value: {value}') from e\n\n    # TODO: We should be able to directly use \"value\" without\n    # casting to the internal type.\n    value = trial.ParameterValue(value)\n    if self.type == ParameterType.DOUBLE:\n      self._assert_bounds(value.as_float)\n    elif self.type == ParameterType.INTEGER:\n      self._assert_bounds(value.as_int)\n    elif self.type == ParameterType.DISCRETE:\n      self._assert_in_feasible_values(value.as_float)\n    elif self.type == ParameterType.CATEGORICAL:\n      self._assert_in_feasible_values(value.as_str)\n    else:\n      raise RuntimeError(\n          f'Parameter {self.name} has unknown parameter type: {self.type}')\n\n  def get_subspace_deepcopy(self, value: ParameterValueTypes) -> 'SearchSpace':\n    \"\"\"Get a deep copy of the subspace.\n\n    Validates the feasibility of value.\n\n    Args:\n      value: Must be a feasible value per this parameter config.\n\n    Returns:\n      Subspace conditioned on the value. Note that an empty search space is\n      returned if the parameter config is continuous and thus cannot have\n      a subspace.\n    \"\"\"\n    if not math.isfinite(self.num_feasible_values):\n      return SearchSpace()\n    value = trial.ParameterValue(value).cast_as_internal(self.type)\n    self._assert_feasible(value)\n    return copy.deepcopy(self._children.get(value, SearchSpace()))\n\n  def subspace(self, value: ParameterValueTypes) -> 'SearchSpace':\n    \"\"\"Selects the subspace for a specified parent value.\"\"\"\n    if not math.isfinite(self.num_feasible_values):\n      raise TypeError('DOUBLE type cannot have child parameters')\n\n    # TODO: We should be able to directly use \"value\".\n    value = trial.ParameterValue(value).cast_as_internal(self.type)\n    self._assert_feasible(value)\n    if value not in self._children:\n      self._children[value] = SearchSpace(parent_values=[value])\n    return self._children[value]\n\n\nParameterConfigOrConfigs = Union[ParameterConfig, Collection[ParameterConfig]]\n\n\n@attr.define(init=False)\nclass ParameterConfigSelector(Sized):\n  \"\"\"Holds a reference to ParameterConfigs.\"\"\"\n\n  # Selected configs.\n  _selected: tuple[ParameterConfig] = attr.field(init=True)\n\n  def __len__(self) -> int:\n    return len(self._selected)\n\n  def __init__(self, selected: ParameterConfigOrConfigs):\n    if isinstance(selected, Collection):\n      self.__attrs_init__(tuple(selected))\n    else:\n      self.__attrs_init__(tuple([selected]))\n\n  def select_values(self,\n                    values: MonotypeParameterSequence) -> 'SearchSpaceSelector':\n    \"\"\"Select values.\"\"\"\n    values = tuple(values)\n\n    for value in values:\n      for config in self._selected:\n        if not config.contains(value):\n          # Validate first so we don't create a lot of unnecessary empty\n          # search space upon failure.\n          raise ValueError(f'{value} is not feasible in {self}')\n\n    spaces = []\n    for value in values:\n      for config in self._selected:\n        spaces.append(config.subspace(value))\n    return SearchSpaceSelector(spaces)\n\n\nclass InvalidParameterError(Exception):\n  \"\"\"Error thrown when parameter values are invalid.\"\"\"\n\n\n################### Main Classes ###################\nSearchSpaceOrSpaces = Union['SearchSpace', Collection['SearchSpace']]\n\n\n@attr.define(init=False)\nclass SearchSpaceSelector:\n  \"\"\"Holds a reference to (sub) spaces.\"\"\"\n\n  # Selected (sub)-spaces.\n  # TODO: Consider switching the order of SearchSpaceSelector and\n  # SearchSpace.\n  _selected: tuple['SearchSpace'] = attr.field(init=True)\n\n  def __len__(self) -> int:\n    return len(self._selected)\n\n  def __init__(self, selected: SearchSpaceOrSpaces):\n    if isinstance(selected, Collection):\n      self.__attrs_init__(tuple(selected))\n    else:\n      self.__attrs_init__(tuple([selected]))\n\n  def add_float_param(self,\n                      name: str,\n                      min_value: float,\n                      max_value: float,\n                      *,\n                      default_value: Optional[float] = None,\n                      scale_type: Optional[ScaleType] = ScaleType.LINEAR,\n                      index: Optional[int] = None) -> 'ParameterConfigSelector':\n    \"\"\"Adds floating point parameter config(s) to the selected search space(s).\n\n    Args:\n      name: The parameter's name. Cannot be empty.\n      min_value: Inclusive lower bound for the parameter.\n      max_value: Inclusive upper bound for the parameter.\n      default_value: A default value for the Parameter.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      index: Specifies the multi-dimensional index for this parameter. E.g. if\n        name='rate' and index=0, then a single ParameterConfig with name\n        'rate[0]' is added. `index` should be >= 0.\n\n    Returns:\n      SearchSpaceSelector(s) for the newly added parameter(s):\n      One SearchSpaceSelector if one parameter was added, or a list of\n      SearchSpaceSelector if multiple parameters were added.\n\n    Raises:\n      ValueError: If `index` is invalid (e.g. negative).\n    \"\"\"\n    bounds = (float(min_value), float(max_value))\n    param_names = self._get_parameter_names_to_create(name=name, index=index)\n\n    new_params = []\n    for param_name in param_names:\n      new_pc = ParameterConfig.factory(\n          name=param_name,\n          bounds=bounds,\n          scale_type=scale_type,\n          default_value=default_value)\n      new_params.append(new_pc)\n    return self._add_parameters(new_params)\n\n  def add_int_param(\n      self,\n      name: str,\n      min_value: int,\n      max_value: int,\n      *,\n      default_value: Optional[int] = None,\n      scale_type: Optional[ScaleType] = None,\n      index: Optional[int] = None,\n      experimental_fidelity_config: Optional[FidelityConfig] = None,\n  ) -> 'ParameterConfigSelector':\n    \"\"\"Adds integer parameter config(s) to the selected search space(s).\n\n    Args:\n      name: The parameter's name. Cannot be empty.\n      min_value: Inclusive lower bound for the parameter.\n      max_value: Inclusive upper bound for the parameter.\n      default_value: A default value for the Parameter.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      index: Specifies the multi-dimensional index for this parameter. E.g. if\n        name='hidden_units' and index=0, then a single ParameterConfig with name\n        'hidden_units[0]' is added. `index` should be >= 0.\n      experimental_fidelity_config: EXPERIMENTAL. See FidelityConfig doc.\n\n    Returns:\n      ParameterConfigSelector for the newly added parameter(s).\n\n    Raises:\n      ValueError: If min_value or max_value are not integers.\n      ValueError: If `index` is invalid (e.g. negative).\n    \"\"\"\n    int_min_value = int(min_value)\n    if not math.isclose(min_value, int_min_value):\n      raise ValueError('min_value for an INTEGER parameter should be an integer'\n                       ', got: [{}]'.format(min_value))", "choices": [{"text": "int_max_value = int(max_value)"}], "metadata": {"task_id": "google_vizier/165", "ground_truth": "    int_max_value = int(max_value)", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "context_start_lineno": 575, "line_no": 768, "query_window": {"context": "      min_value: Inclusive lower bound for the parameter.\n      max_value: Inclusive upper bound for the parameter.\n      default_value: A default value for the Parameter.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      index: Specifies the multi-dimensional index for this parameter. E.g. if\n        name='hidden_units' and index=0, then a single ParameterConfig with name\n        'hidden_units[0]' is added. `index` should be >= 0.\n      experimental_fidelity_config: EXPERIMENTAL. See FidelityConfig doc.\n\n    Returns:\n      ParameterConfigSelector for the newly added parameter(s).\n\n    Raises:\n      ValueError: If min_value or max_value are not integers.\n      ValueError: If `index` is invalid (e.g. negative).\n    \"\"\"\n    int_min_value = int(min_value)\n    if not math.isclose(min_value, int_min_value):\n      raise ValueError('min_value for an INTEGER parameter should be an integer'\n                       ', got: [{}]'.format(min_value))", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 768, "task_id": "google_vizier/165", "start_line_no": 748, "end_line_no": 768, "window_size": 20, "context_start_lineno": 575, "repo": "google_vizier"}}, "top_k_context": [{"context": "      if not math.isclose(default_value, default_int_value):\n        raise ValueError('default_value for an INTEGER parameter should be an '\n                         'integer, got float: [{}]'.format(default_value))\n      return default_int_value\n  elif (param_type == ParameterType.CATEGORICAL and\n        isinstance(default_value, str)):\n    return default_value\n  raise ValueError(\n      'default_value has an incorrect type. ParameterType has type {}, '\n      'but default_value has type {}'.format(param_type.name,\n                                             type(default_value)))\n\n\n#######################\n# Experimental features\n#######################\nclass FidelityMode(enum.Enum):\n  \"\"\"Decides how the fidelity config should be interpreated.\n\n  SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.29411764705882354}, {"context": "  if (param_type in (ParameterType.DOUBLE, ParameterType.DISCRETE) and\n      (isinstance(default_value, float) or isinstance(default_value, int))):\n    return float(default_value)\n  elif (param_type == ParameterType.INTEGER and\n        (isinstance(default_value, float) or isinstance(default_value, int))):\n    if isinstance(default_value, int):\n      return default_value\n    else:\n      # Check if the float rounds nicely.\n      default_int_value = round(default_value)\n      if not math.isclose(default_value, default_int_value):\n        raise ValueError('default_value for an INTEGER parameter should be an '\n                         'integer, got float: [{}]'.format(default_value))\n      return default_int_value\n  elif (param_type == ParameterType.CATEGORICAL and\n        isinstance(default_value, str)):\n    return default_value\n  raise ValueError(\n      'default_value has an incorrect type. ParameterType has type {}, '\n      'but default_value has type {}'.format(param_type.name,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.28823529411764703}, {"context": "      bounds: REQUIRED for INTEGER or DOUBLE type. Specifies (min, max). The\n        type of (min, max) determines the created ParameterConfig's type.\n      feasible_values: REQUIRED for DISCRETE or CATEGORICAL type. The elements'\n        type determines the created ParameterConfig's type.\n      children: sequence of tuples formatted as: (matching_parent_values,\n        ParameterConfig). ONLY THE TYPES ARE VALIDATED. If the child\n        ParameterConfig protos already have parent values set, they will be\n        overridden by the provided matching_parent_values.\n      fidelity_config: Fidelity config.  NOT VALIDATED.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      default_value: A default value for the Parameter.\n      external_type: An annotation indicating the type this parameter should be\n        cast to.\n\n    Returns:\n      A ParameterConfig object which wraps a partially validated proto.\n\n    Raises:\n      ValueError: Exactly one of feasible_values and bounds must be convertible\n        to Boolean true. Bounds and numeric feasible_values must be finite.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2669902912621359}, {"context": "      NOTE that the values in the dict may be a Sequence as opposed to a single\n      element.\n\n    Raises:\n      ValueError: If the trial parameters do not exist in this search space.\n      ValueError: If the trial contains duplicate parameters.\n    \"\"\"\n    trial_external_values: Dict[str, Union[float, int, str, bool]] = (\n        self._trial_to_external_values(pytrial))\n    if len(trial_external_values) != len(pytrial.parameters):\n      raise ValueError('Invalid trial for this search space: failed to convert '\n                       'all trial parameters: {}'.format(pytrial))\n\n    # Combine multi-dimensional parameter values to a list of values.\n    trial_final_values: Dict[str, ParameterValueSequence] = {}\n    # multi_dim_params: Dict[str, List[Tuple[int, ParameterValueSequence]]]\n    multi_dim_params = collections.defaultdict(list)\n    for name in trial_external_values:\n      base_index = (\n          vz.SearchSpaceSelector.parse_multi_dimensional_parameter_name(name)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config.py"], "line_no": 360, "start_line_no": 350, "end_line_no": 370, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.24873096446700507}, {"context": "                                        'ParameterConfig']]] = None,\n      fidelity_config: Optional[FidelityConfig] = None,\n      scale_type: Optional[ScaleType] = None,\n      default_value: Optional[Union[float, int, str]] = None,\n      external_type: Optional[ExternalType] = ExternalType.INTERNAL\n  ) -> 'ParameterConfig':\n    \"\"\"Factory method.\n\n    Args:\n      name: The parameter's name. Cannot be empty.\n      bounds: REQUIRED for INTEGER or DOUBLE type. Specifies (min, max). The\n        type of (min, max) determines the created ParameterConfig's type.\n      feasible_values: REQUIRED for DISCRETE or CATEGORICAL type. The elements'\n        type determines the created ParameterConfig's type.\n      children: sequence of tuples formatted as: (matching_parent_values,\n        ParameterConfig). ONLY THE TYPES ARE VALIDATED. If the child\n        ParameterConfig protos already have parent values set, they will be\n        overridden by the provided matching_parent_values.\n      fidelity_config: Fidelity config.  NOT VALIDATED.\n      scale_type: Scaling to be applied. NOT VALIDATED.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.24644549763033174}, {"context": "      default_value: A default value for the Parameter.\n      external_type: An annotation indicating the type this parameter should be\n        cast to.\n\n    Returns:\n      A ParameterConfig object which wraps a partially validated proto.\n\n    Raises:\n      ValueError: Exactly one of feasible_values and bounds must be convertible\n        to Boolean true. Bounds and numeric feasible_values must be finite.\n        Bounds and feasible_values, if provided, must consist of\n        elements of the same type.\n      TypeError: If children's matching_parent_values are not compatible with\n        the ParameterConfig being created.\n    \"\"\"\n    if not name:\n      raise ValueError('Parameter name cannot be empty.')\n\n    if bool(feasible_values) == bool(bounds):\n      raise ValueError(", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.24431818181818182}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/vip.py\n# --------------------------------------------------\n#         else:\n#             self._device = dest\n#         return super().to(dest)\n# \n#     @property\n#     def device(self):\n#         return self._device\n# \n#     @property\n#     def dtype(self):\n#         return self._dtype\n# \n# \n# class VIPRewardTransform(VIPTransform):\n#     \"\"\"A VIP transform to compute rewards based on embedded similarity.\n# \n#     This class will update the reward computation\n#     \"\"\"\n# \n#     def reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/r3m.py\n# --------------------------------------------------\n# \n#         if self._device is not None:\n#             self.to(self._device)\n#         if self._dtype is not None:\n#             self.to(self._dtype)\n# \n#     def to(self, dest: Union[DEVICE_TYPING, torch.dtype]):\n#         if isinstance(dest, torch.dtype):\n#             self._dtype = dest\n#         else:\n#             self._device = dest\n#         return super().to(dest)\n# \n#     @property\n#     def device(self):\n#         return self._device\n# \n#     @property\n#     def dtype(self):\n#         return self._dtype\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#             minimum = torch.tensor(minimum, dtype=dtype, device=device)\n#         if not isinstance(maximum, torch.Tensor):\n#             maximum = torch.tensor(maximum, dtype=dtype, device=device)\n#         if maximum.device != device:\n#             maximum = maximum.to(device)\n#         if minimum.device != device:\n#             minimum = minimum.to(device)\n#         if dtype is not None and minimum.dtype is not dtype:\n#             minimum = minimum.to(dtype)\n#         if dtype is not None and maximum.dtype is not dtype:\n#             maximum = maximum.to(dtype)\n#         err_msg = (\n#             \"BoundedTensorSpec requires the shape to be explicitely (via \"\n#             \"the shape argument) or implicitely defined (via either the \"\n#             \"minimum or the maximum or both). If the maximum and/or the \"\n#             \"minimum have a non-singleton shape, they must match the \"\n#             \"provided shape if this one is set explicitely.\"\n#         )\n#         if shape is not None and not isinstance(shape, torch.Size):\n#             if isinstance(shape, int):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#         dtype: Optional[Union[str, torch.dtype]] = torch.long,\n#     ):\n#         if shape is None:\n#             shape = torch.Size([])\n#         dtype, device = _default_dtype_and_device(dtype, device)\n#         space = DiscreteBox(n)\n#         super().__init__(shape, space, device, dtype, domain=\"discrete\")\n# \n#     def rand(self, shape=None) -> torch.Tensor:\n#         if shape is None:\n#             shape = torch.Size([])\n#         return torch.randint(\n#             0,\n#             self.space.n,\n#             torch.Size([*shape, *self.shape]),\n#             device=self.device,\n#             dtype=self.dtype,\n#         )\n# \n#     def _project(self, val: torch.Tensor) -> torch.Tensor:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#         dtype: Optional[Union[str, torch.dtype]] = torch.long,\n#         use_register: bool = False,\n#     ):\n# \n#         dtype, device = _default_dtype_and_device(dtype, device)\n#         self.use_register = use_register\n#         space = DiscreteBox(\n#             n,\n#         )\n#         if shape is None:\n#             shape = torch.Size((space.n,))\n#         else:\n#             shape = torch.Size(shape)\n#             if not len(shape) or shape[-1] != space.n:\n#                 raise ValueError(\n#                     f\"The last value of the shape must match n for transform of type {self.__class__}. \"\n#                     f\"Got n={space.n} and shape={shape}.\"\n#                 )\n#         super().__init__(shape, space, device, dtype, \"discrete\")\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#         device: Optional[DEVICE_TYPING] = None,\n#         dtype: Optional[Union[torch.dtype, str]] = None,\n#     ):\n#         dtype, device = _default_dtype_and_device(dtype, device)\n#         if dtype is None:\n#             dtype = torch.get_default_dtype()\n#         if device is None:\n#             device = torch._get_default_device()\n# \n#         if not isinstance(minimum, torch.Tensor):\n#             minimum = torch.tensor(minimum, dtype=dtype, device=device)\n#         if not isinstance(maximum, torch.Tensor):\n#             maximum = torch.tensor(maximum, dtype=dtype, device=device)\n#         if maximum.device != device:\n#             maximum = maximum.to(device)\n#         if minimum.device != device:\n#             minimum = minimum.to(device)\n#         if dtype is not None and minimum.dtype is not dtype:\n#             minimum = minimum.to(dtype)\n#         if dtype is not None and maximum.dtype is not dtype:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/model_based/common.py\n# --------------------------------------------------\n#         run_type_checks: bool = False,\n#     ):\n#         super(ModelBasedEnvBase, self).__init__(\n#             device=device,\n#             dtype=dtype,\n#             batch_size=batch_size,\n#             run_type_checks=run_type_checks,\n#         )\n#         self.world_model = world_model.to(self.device)\n#         self.world_model_params = params\n#         self.world_model_buffers = buffers\n# \n#     @classmethod\n#     def __new__(cls, *args, **kwargs):\n#         return super().__new__(\n#             cls, *args, _inplace_update=False, _batch_locked=False, **kwargs\n#         )\n# \n#     def set_specs_from_env(self, env: EnvBase):\n#         \"\"\"Sets the specs of the environment from the specs of the given environment.\"\"\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n,\n        batch_locked: bool = True,\n    ):\n        self.device = device\n        self.tensordict = tensordict\n        self.specs = specs\n        self.batch_size = batch_size\n        self.env_str = env_str\n        self.batch_locked = batch_locked\n\n    @property\n    def tensordict(self):\n        return self._tensordict.to(self.device)\n\n    @property\n    def specs(self):\n        return self._specs.to(self.device)\n\n    @tensordict.setter\n    def tensordict(self, value: TensorDictBase):\n        self._tensordict = value.to(\"cpu\")\n\n    @specs.setter\n    def specs(self, value: CompositeSpec):\n        self._specs = value.to(\"cpu\")\n\n    @staticmethod\n    def build_metadata_from_env(env) -> EnvMetaData:\n        tensordict = env.fake_tensordict().clone()\n        specs = {\n            \"input_spec\": env.input_spec,\n            \"observation_spec\": env.observation_spec,\n            \"reward_spec\": env.reward_spec,\n        }\n        specs = CompositeSpec(**specs, shape=env.batch_size).to(\"cpu\")\n\n        batch_size = env.batch_size\n        env_str = str(env)\n        device = env.device\n        specs = specs.to(\"cpu\")\n        batch_locked = env.batch_locked\n        return EnvMetaData(tensordict, specs, batch_size, env_str, device, batch_locked)\n\n    def expand(self, *size: int) -> EnvMetaData:\n        tensordict = self.tensordict.expand(*size).to_tensordict()\n        batch_size = torch.Size(list(size))\n        return EnvMetaData(\n            tensordict,\n            self.specs.expand(*size),\n            batch_size,\n            self.env_str,\n            self.device,\n            self.batch_locked,\n        )\n\n    def clone(self):\n        return EnvMetaData(\n            self.tensordict.clone(),\n            self.specs.clone(),\n            torch.Size([*self.batch_size]),\n            deepcopy(self.env_str),\n            self.device,\n            self.batch_locked,\n        )\n\n    def to(self, device: DEVICE_TYPING) -> EnvMetaData:\n        tensordict = self.tensordict.contiguous().to(device)\n        specs = self.specs.to(device)\n        return EnvMetaData(\n            tensordict, specs, self.batch_size, self.env_str, device, self.batch_locked\n        )\n\n\nclass Specs:\n    \"\"\"Container for action, observation and reward specs.\n\n    This class allows one to create an environment, retrieve all of the specs\n    in a single data container (and access them in one place) before erasing\n    the environment from the workspace.\n\n    Args:\n        env (EnvBase): environment from which the specs have to be read.\n\n    \"\"\"\n\n    _keys = {\n        \"action_spec\",\n        \"observation_spec\",\n        \"reward_spec\",\n        \"input_spec\",\n        \"from_pixels\",\n    }\n\n    def __init__(self, env: EnvBase):\n        self.env = env\n\n    def __getitem__(self, item: str) -> Any:\n        if item not in self._keys:\n            raise KeyError(f\"item must be one of {self._keys}\")\n        return getattr(self.env, item)\n\n    def keys(self) -> Sequence[str]:\n        return self._keys\n\n    def build_tensordict(\n        self, next_observation: bool = True, log_prob: bool = False\n    ) -> TensorDictBase:\n        \"\"\"Returns a TensorDict with empty tensors of the desired shape.\n\n        Args:\n            next_observation (bool, optional): if False, the observation returned\n                will be of the current step only (no :obj:`\"next\"` nested tensordict will be present).\n                Default is True.\n            log_prob (bool, optional): If True, a log_prob key-value pair will be added\n                to the tensordict.\n\n        Returns: A tensordict populated according to the env specs.\n\n        \"\"\"\n        # build a tensordict from specs\n        td = TensorDict({}, batch_size=torch.Size([]), _run_checks=False)\n        action_placeholder = torch.zeros(\n            self[\"action_spec\"].shape, dtype=self[\"action_spec\"].dtype\n        )\n        if not isinstance(self[\"observation_spec\"], CompositeSpec):\n            raise RuntimeError(\"observation_spec is expected to be of Composite type.\")\n        else:\n            for (key, item) in self[\"observation_spec\"].items():\n                observation_placeholder = torch.zeros(item.shape, dtype=item.dtype)\n                if next_observation:\n                    td.update({\"next\": {key: observation_placeholder}})\n                td.set(\n                    key,\n                    observation_placeholder.clone(),\n                )\n\n        reward_placeholder = torch.zeros(\n            self[\"reward_spec\"].shape, dtype=self[\"reward_spec\"].dtype\n        )\n        done_placeholder = torch.zeros_like(reward_placeholder, dtype=torch.bool)\n\n        td.set(\"action\", action_placeholder)\n        td.set(\"reward\", reward_placeholder)\n\n        if log_prob:\n            td.set(\n                \"log_prob\",\n                torch.zeros_like(reward_placeholder, dtype=torch.float32),\n            )  # we assume log_prob to be of type float32\n        td.set(\"done\", done_placeholder)\n        return td\n\n\nclass EnvBase(nn.Module, metaclass=abc.ABCMeta):\n    \"\"\"Abstract environment parent class.\n\n    Properties:\n        - observation_spec (CompositeSpec): sampling spec of the observations;\n        - action_spec (TensorSpec): sampling spec of the actions;\n        - input_spec (CompositeSpec): sampling spec of the actions and/or other inputs;\n        - reward_spec (TensorSpec): sampling spec of the rewards;\n        - batch_size (torch.Size): number of environments contained in the instance;\n        - device (torch.device): device where the env input and output are expected to live\n        - run_type_checks (bool): if True, the observation and reward dtypes\n            will be compared against their respective spec and an exception\n            will be raised if they don't match.\n\n    Methods:\n        step (TensorDictBase -> TensorDictBase): step in the environment\n        reset (TensorDictBase, optional -> TensorDictBase): reset the environment\n        set_seed (int -> int): sets the seed of the environment\n        rand_step (TensorDictBase, optional -> TensorDictBase): random step given the action spec\n        rollout (Callable, ... -> TensorDictBase): executes a rollout in the environment with the given policy (or random\n            steps if no policy is provided)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        device: DEVICE_TYPING = \"cpu\",\n        dtype: Optional[Union[torch.dtype, np.dtype]] = None,\n        batch_size: Optional[torch.Size] = None,\n        run_type_checks: bool = True,\n    ):\n        super().__init__()\n        if device is not None:\n            self.device = torch.device(device)\n        self.dtype = dtype_map.get(dtype, dtype)\n        if \"is_closed\" not in self.__dir__():\n            self.is_closed = True\n        if \"_input_spec\" not in self.__dir__():\n            self.__dict__[\"_input_spec\"] = None\n        if \"_reward_spec\" not in self.__dir__():\n            self.__dict__[\"_reward_spec\"] = None", "choices": [{"text": "class VIPRewardTransform(VIPTransform):"}], "metadata": {"task_id": "pytorch_rl/53", "ground_truth": "        if \"_observation_spec\" not in self.__dir__():", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "context_start_lineno": 46, "line_no": 240, "query_window": {"context": "\n    \"\"\"\n\n    def __init__(\n        self,\n        device: DEVICE_TYPING = \"cpu\",\n        dtype: Optional[Union[torch.dtype, np.dtype]] = None,\n        batch_size: Optional[torch.Size] = None,\n        run_type_checks: bool = True,\n    ):\n        super().__init__()\n        if device is not None:\n            self.device = torch.device(device)\n        self.dtype = dtype_map.get(dtype, dtype)\n        if \"is_closed\" not in self.__dir__():\n            self.is_closed = True\n        if \"_input_spec\" not in self.__dir__():\n            self.__dict__[\"_input_spec\"] = None\n        if \"_reward_spec\" not in self.__dir__():\n            self.__dict__[\"_reward_spec\"] = None", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 240, "task_id": "pytorch_rl/53", "start_line_no": 220, "end_line_no": 240, "window_size": 20, "context_start_lineno": 46, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    \"\"\"\n\n    def __init__(\n        self,\n        world_model: SafeModule,\n        params: Optional[List[torch.Tensor]] = None,\n        buffers: Optional[List[torch.Tensor]] = None,\n        device: DEVICE_TYPING = \"cpu\",\n        dtype: Optional[Union[torch.dtype, np.dtype]] = None,\n        batch_size: Optional[torch.Size] = None,\n        run_type_checks: bool = False,\n    ):\n        super(ModelBasedEnvBase, self).__init__(\n            device=device,\n            dtype=dtype,\n            batch_size=batch_size,\n            run_type_checks=run_type_checks,\n        )\n        self.world_model = world_model.to(self.device)\n        self.world_model_params = params", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "model_based", "common.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5052631578947369}, {"context": "        device (str, int or torch.device, optional): device of the tensors.\n        dtype (str or torch.dtype, optional): dtype of the tensors.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        minimum: Union[float, torch.Tensor, np.ndarray],\n        maximum: Union[float, torch.Tensor, np.ndarray],\n        shape: Optional[Union[torch.Size, int]] = None,\n        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[torch.dtype, str]] = None,\n    ):\n        dtype, device = _default_dtype_and_device(dtype, device)\n        if dtype is None:\n            dtype = torch.get_default_dtype()\n        if device is None:\n            device = torch._get_default_device()\n\n        if not isinstance(minimum, torch.Tensor):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 630, "start_line_no": 620, "end_line_no": 640, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4444444444444444}, {"context": "    space: DiscreteBox\n    device: torch.device = torch.device(\"cpu\")\n    dtype: torch.dtype = torch.float\n    domain: str = \"\"\n\n    def __init__(\n        self,\n        n: int,\n        shape: Optional[torch.Size] = None,\n        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[str, torch.dtype]] = torch.long,\n        use_register: bool = False,\n    ):\n\n        dtype, device = _default_dtype_and_device(dtype, device)\n        self.use_register = use_register\n        space = DiscreteBox(\n            n,\n        )\n        if shape is None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.43157894736842106}, {"context": "    space: DiscreteBox\n    device: torch.device = torch.device(\"cpu\")\n    dtype: torch.dtype = torch.float\n    domain: str = \"\"\n\n    def __init__(\n        self,\n        n: int,\n        shape: Optional[torch.Size] = None,\n        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[str, torch.dtype]] = torch.long,\n    ):\n        if shape is None:\n            shape = torch.Size([])\n        dtype, device = _default_dtype_and_device(dtype, device)\n        space = DiscreteBox(n)\n        super().__init__(shape, space, device, dtype, domain=\"discrete\")\n\n    def rand(self, shape=None) -> torch.Tensor:\n        if shape is None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 1270, "start_line_no": 1260, "end_line_no": 1280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4077669902912621}, {"context": "        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[torch.dtype, str]] = None,\n    ):\n        dtype, device = _default_dtype_and_device(dtype, device)\n        if dtype is None:\n            dtype = torch.get_default_dtype()\n        if device is None:\n            device = torch._get_default_device()\n\n        if not isinstance(minimum, torch.Tensor):\n            minimum = torch.tensor(minimum, dtype=dtype, device=device)\n        if not isinstance(maximum, torch.Tensor):\n            maximum = torch.tensor(maximum, dtype=dtype, device=device)\n        if maximum.device != device:\n            maximum = maximum.to(device)\n        if minimum.device != device:\n            minimum = minimum.to(device)\n        if dtype is not None and minimum.dtype is not dtype:\n            minimum = minimum.to(dtype)\n        if dtype is not None and maximum.dtype is not dtype:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4}, {"context": "            self.to(self._device)\n        if self._dtype is not None:\n            self.to(self._dtype)\n\n    def to(self, dest: Union[DEVICE_TYPING, torch.dtype]):\n        if isinstance(dest, torch.dtype):\n            self._dtype = dest\n        else:\n            self._device = dest\n        return super().to(dest)\n\n    @property\n    def device(self):\n        return self._device\n\n    @property\n    def dtype(self):\n        return self._dtype", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "r3m.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 378, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3764705882352941}, {"context": "            )\n\n        if self._device is not None:\n            self.to(self._device)\n        if self._dtype is not None:\n            self.to(self._dtype)\n\n    def to(self, dest: Union[DEVICE_TYPING, torch.dtype]):\n        if isinstance(dest, torch.dtype):\n            self._dtype = dest\n        else:\n            self._device = dest\n        return super().to(dest)\n\n    @property\n    def device(self):\n        return self._device\n\n    @property\n    def dtype(self):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "vip.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.37209302325581395}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 fit_config=self.reg_fit_config_nodir_nodump,\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n# \n#             # no save dir but dump\n#             with self.assertRaises(ValueError):\n#                 status = prob_reg.train(\n#                     train_data_loader=self.reg_train_data_loader,\n#                     calib_data_loader=self.reg_val_data_loader,\n#                     val_data_loader=self.reg_val_data_loader,\n#                     fit_config=self.reg_fit_config_nodir_dump,\n#                     calib_config=self.reg_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#             prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_restore(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n# \n#             # load state\n#             prob_reg.load_state(checkpoint_path=tmp_dir)\n# \n#             # save state\n#             prob_reg.save_state(checkpoint_path=tmp_dir)\n# \n#     def test_dryrun_class_advi(self):\n#         with tempfile.TemporaryDirectory() as tmp_dir:\n#             prob_class = ProbClassifier(\n#                 model=MyModel(self.class_output_dim),\n#                 posterior_approximator=ADVIPosteriorApproximator(),\n#                 output_calibrator=ClassificationTemperatureScaler(),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_nodir_nodump,\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n# \n#             # no save dir but dump\n#             with self.assertRaises(ValueError):\n#                 status = prob_reg.train(\n#                     train_data_loader=self.reg_train_data_loader,\n#                     calib_data_loader=self.reg_val_data_loader,\n#                     val_data_loader=self.reg_val_data_loader,\n#                     fit_config=self.reg_fit_config_nodir_dump,\n#                     calib_config=self.reg_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#             )\n# \n#             # restore from map\n#             prob_class_map = ProbClassifier(\n#                 model=MyModel(self.class_output_dim),\n#                 posterior_approximator=MAPPosteriorApproximator(),\n#                 output_calibrator=ClassificationTemperatureScaler(),\n#             )\n#             status = prob_class_map.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_restore(tmp_dir),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_restore(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n# \n#             # load state\n#             prob_class.load_state(checkpoint_path=tmp_dir)\n# \n#             # save state\n#             prob_class.save_state(checkpoint_path=tmp_dir)\n# \n#     def test_dryrun_reg_deep_ensemble(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 posterior_approximator=MAPPosteriorApproximator(),\n#                 output_calibrator=RegressionTemperatureScaler(),\n#             )\n#             status = prob_reg_map.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_restore(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n# \n#             # load state\n#             prob_reg.load_state(checkpoint_path=tmp_dir)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n tempfile.TemporaryDirectory() as tmp_dir:\n            prob_class = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=DeepEnsemblePosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_nodir_nodump,\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_dump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # restore\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_restore(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_class.load_state(checkpoint_path=tmp_dir)\n\n            # save state\n            prob_class.save_state(checkpoint_path=tmp_dir)\n\n    def test_dryrun_reg_laplace(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            prob_reg = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=LaplacePosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    map_fit_config=self.reg_fit_config_nodir_nodump,\n                    fit_config=self.reg_fit_config_nodir_dump,\n                    calib_config=self.reg_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # restore from laplace\n            prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # restore from map\n            prob_reg_map = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,", "choices": [{"text": "val_data_loader=self.reg_val_data_loader,"}], "metadata": {"task_id": "awslabs_fortuna/1", "ground_truth": "                val_data_loader=self.reg_val_data_loader,", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "context_start_lineno": 515, "line_no": 660, "query_window": {"context": "            )\n\n            # restore from map\n            prob_reg_map = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 660, "task_id": "awslabs_fortuna/1", "start_line_no": 640, "end_line_no": 660, "window_size": 20, "context_start_lineno": 515, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # restore from map\n            prob_reg_map = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9722222222222222}, {"context": "            )\n\n            # restore from map\n            prob_class_map = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            status = prob_class_map.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_dump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_restore(tmp_dir),", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.8026315789473685}, {"context": "            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # restore from advi\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_restore(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n\n            # restore from map\n            prob_class_map = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            status = prob_class_map.train(\n                train_data_loader=self.class_train_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7058823529411765}, {"context": "            prob_reg = ProbRegressor(\n                model=MLP(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7}, {"context": "                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_reg.load_state(checkpoint_path=tmp_dir)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6875}, {"context": "                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=ADVIPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6483516483516484}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/record/recorder.py\n# --------------------------------------------------\n#         out_file_base: str,\n#         skip_reset: bool = True,\n#         skip: int = 4,\n#         in_keys: Optional[Sequence[str]] = None,\n#     ) -> None:\n#         if in_keys is None:\n#             in_keys = []\n# \n#         super().__init__(in_keys=in_keys)\n#         self.iter = 0\n#         self.out_file_base = out_file_base\n#         self.td = []\n#         self.skip_reset = skip_reset\n#         self.skip = skip\n#         self.count = 0\n# \n#     def _call(self, td: TensorDictBase) -> TensorDictBase:\n#         self.count += 1\n#         if self.count % self.skip == 0:\n#             _td = td\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#     def _reset(self, tensordict: TensorDictBase, **kwargs) -> TensorDictBase:\n# \n#         if tensordict is not None and \"_reset\" in tensordict.keys():\n#             self._assert_tensordict_shape(tensordict)\n#             _reset = tensordict.get(\"_reset\")\n#         else:\n#             _reset = torch.ones(self.batch_size, dtype=torch.bool)\n# \n#         keys = set()\n#         for i, _env in enumerate(self._envs):\n#             if not _reset[i].any():\n#                 continue\n#             _tensordict = tensordict[i] if tensordict is not None else None\n#             _td = _env._reset(tensordict=_tensordict, **kwargs)\n#             if \"_reset\" in _td.keys():\n#                 _td.del_(\"_reset\")\n#             keys = keys.union(_td.keys())\n#             self.shared_tensordicts[i].update_(_td)\n# \n#         return self.shared_tensordict_parent.select(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n# \n#         \"\"\"\n#         if tensordict is None:\n#             tensordict = TensorDict(\n#                 {}, device=self.device, batch_size=self.batch_size, _run_checks=False\n#             )\n#         action = self.action_spec.rand()\n#         tensordict.set(\"action\", action)\n#         return self.step(tensordict)\n# \n#     @property\n#     def specs(self) -> Specs:\n#         \"\"\"Returns a Specs container where all the environment specs are contained.\n# \n#         This feature allows one to create an environment, retrieve all of the specs in a single data container and then\n#         erase the environment from the workspace.\n# \n#         \"\"\"\n#         return Specs(self)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/vip.py\n# --------------------------------------------------\n#         if \"goal_embedding\" not in tensordict.keys():\n#             tensordict = self._embed_goal(tensordict)\n#         return super().reset(tensordict)\n# \n#     def _embed_goal(self, tensordict):\n#         if \"goal_image\" not in tensordict.keys():\n#             raise KeyError(\n#                 f\"{self.__class__.__name__}.reset() requires a `'goal_image'` key to be \"\n#                 f\"present in the input tensordict.\"\n#             )\n#         tensordict_in = tensordict.select(\"goal_image\").rename_key(\n#             \"goal_image\", self.in_keys[0]\n#         )\n#         tensordict_in = super(VIPRewardTransform, self).forward(tensordict_in)\n#         tensordict = tensordict.update(\n#             tensordict_in.rename_key(self.out_keys[0], \"goal_embedding\")\n#         )\n#         return tensordict\n# \n#     def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/gym_like.py\n# --------------------------------------------------\n#         info = None\n#         if len(other) == 1:\n#             info = other\n# \n#         tensordict_out = TensorDict(\n#             source=self.read_obs(obs),\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n#         if self.info_dict_reader is not None and info is not None:\n#             self.info_dict_reader(info, tensordict_out)\n#         elif info is None and self.info_dict_reader is not None:\n#             # populate the reset with the items we have not seen from info\n#             for key, item in self.observation_spec.items():\n#                 if key not in tensordict_out.keys():\n#                     tensordict_out[key] = item.zero()\n#         tensordict_out.set(\"done\", torch.zeros(*self.batch_size, 1, dtype=torch.bool))\n#         return tensordict_out\n# \n#     def _output_transform(self, step_outputs_tuple: Tuple) -> Tuple:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/gym_like.py\n# --------------------------------------------------\n# \n#         return tensordict_out\n# \n#     def _reset(\n#         self, tensordict: Optional[TensorDictBase] = None, **kwargs\n#     ) -> TensorDictBase:\n#         reset_data = self._env.reset(**kwargs)\n#         if not isinstance(reset_data, tuple):\n#             reset_data = (reset_data,)\n#         obs, *other = self._output_transform(reset_data)\n#         info = None\n#         if len(other) == 1:\n#             info = other\n# \n#         tensordict_out = TensorDict(\n#             source=self.read_obs(obs),\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n#         if self.info_dict_reader is not None and info is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n# \n#     def _apply_transform(self, obs: torch.Tensor) -> torch.Tensor:\n#         return obs.to(torch.float)\n# \n#     def _inv_apply_transform(self, obs: torch.Tensor) -> torch.Tensor:\n#         return obs.to(torch.double)\n# \n#     def _transform_spec(self, spec: TensorSpec) -> None:\n#         if isinstance(spec, CompositeSpec):\n#             for key in spec:\n#                 self._transform_spec(spec[key])\n#         else:\n#             spec.dtype = torch.float\n#             space = spec.space\n#             if isinstance(space, ContinuousBox):\n#                 space.minimum = space.minimum.to(torch.float)\n#                 space.maximum = space.maximum.to(torch.float)\n# \n#     def transform_input_spec(self, input_spec: TensorSpec) -> TensorSpec:\n#         for key in self.in_keys_inv:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\n            f\"sampler={self._sampler}, \"\n            f\"writer={self._writer}\"\n            \")\"\n        )\n\n    @pin_memory_output\n    def __getitem__(self, index: Union[int, torch.Tensor]) -> Any:\n        index = _to_numpy(index)\n        with self._replay_lock:\n            data = self._storage[index]\n\n        if not isinstance(index, INT_CLASSES):\n            data = self._collate_fn(data)\n\n        return data\n\n    def state_dict(self) -> Dict[str, Any]:\n        return {\n            \"_storage\": self._storage.state_dict(),\n            \"_sampler\": self._sampler.state_dict(),\n            \"_writer\": self._writer.state_dict(),\n        }\n\n    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:\n        self._storage.load_state_dict(state_dict[\"_storage\"])\n        self._sampler.load_state_dict(state_dict[\"_sampler\"])\n        self._writer.load_state_dict(state_dict[\"_writer\"])\n\n    def add(self, data: Any) -> int:\n        \"\"\"Add a single element to the replay buffer.\n\n        Args:\n            data (Any): data to be added to the replay buffer\n\n        Returns:\n            index where the data lives in the replay buffer.\n        \"\"\"\n        with self._replay_lock:\n            index = self._writer.add(data)\n            self._sampler.add(index)\n        return index\n\n    def extend(self, data: Sequence) -> torch.Tensor:\n        \"\"\"Extends the replay buffer with one or more elements contained in an iterable.\n\n        Args:\n            data (iterable): collection of data to be added to the replay\n                buffer.\n\n        Returns:\n            Indices of the data aded to the replay buffer.\n        \"\"\"\n        with self._replay_lock:\n            index = self._writer.extend(data)\n            self._sampler.extend(index)\n        return index\n\n    def update_priority(\n        self,\n        index: Union[int, torch.Tensor],\n        priority: Union[int, torch.Tensor],\n    ) -> None:\n        with self._replay_lock:\n            self._sampler.update_priority(index, priority)\n\n    @pin_memory_output\n    def _sample(self, batch_size: int) -> Tuple[Any, dict]:\n        with self._replay_lock:\n            index, info = self._sampler.sample(self._storage, batch_size)\n            data = self._storage[index]\n        if not isinstance(index, INT_CLASSES):\n            data = self._collate_fn(data)\n        data = self._transform(data)\n        return data, info\n\n    def sample(self, batch_size: int, return_info: bool = False) -> Any:\n        \"\"\"Samples a batch of data from the replay buffer.\n\n        Uses Sampler to sample indices, and retrieves them from Storage.\n\n        Args:\n            batch_size (int): size of data to be collected.\n            return_info (bool): whether to return info. If True, the result\n                is a tuple (data, info). If False, the result is the data.\n\n        Returns:\n            A batch of data selected in the replay buffer.\n            A tuple containing this batch and info if return_info flag is set to True.\n        \"\"\"\n        if not self._prefetch:\n            ret = self._sample(batch_size)\n        else:\n            if len(self._prefetch_queue) == 0:\n                ret = self._sample(batch_size)\n            else:\n                with self._futures_lock:\n                    ret = self._prefetch_queue.popleft().result()\n\n            with self._futures_lock:\n                while len(self._prefetch_queue) < self._prefetch_cap:\n                    fut = self._prefetch_executor.submit(self._sample, batch_size)\n                    self._prefetch_queue.append(fut)\n\n        if return_info:\n            return ret\n        return ret[0]\n\n    def mark_update(self, index: Union[int, torch.Tensor]) -> None:\n        self._sampler.mark_update(index)\n\n    def append_transform(self, transform: \"Transform\") -> None:  # noqa-F821\n        \"\"\"Appends transform at the end.\n\n        Transforms are applied in order when `sample` is called.\n\n        Args:\n            transform (Transform): The transform to be appended\n        \"\"\"\n        transform.eval()\n        self._transform.append(transform)\n\n    def insert_transform(self, index: int, transform: \"Transform\") -> None:  # noqa-F821\n        \"\"\"Inserts transform.\n\n        Transforms are executed in order when `sample` is called.\n\n        Args:\n            index (int): Position to insert the transform.\n            transform (Transform): The transform to be appended\n        \"\"\"\n        transform.eval()\n        self._transform.insert(index, transform)\n\n\nclass PrioritizedReplayBuffer(ReplayBuffer):\n    \"\"\"Prioritized replay buffer.\n\n    Presented in\n        \"Schaul, T.; Quan, J.; Antonoglou, I.; and Silver, D. 2015.\n        Prioritized experience replay.\"\n        (https://arxiv.org/abs/1511.05952)\n\n    Args:\n        alpha (float): exponent \u03b1 determines how much prioritization is used,\n            with \u03b1 = 0 corresponding to the uniform case.\n        beta (float): importance sampling negative exponent.\n        eps (float): delta added to the priorities to ensure that the buffer\n            does not contain null priorities.\n        dtype (torch.dtype): type of the data. Can be torch.float or torch.double.\n        storage (Storage, optional): the storage to be used. If none is provided\n            a default ListStorage with max_size of 1_000 will be created.\n        collate_fn (callable, optional): merges a list of samples to form a\n            mini-batch of Tensor(s)/outputs.  Used when using batched\n            loading from a map-style dataset.\n        pin_memory (bool): whether pin_memory() should be called on the rb\n            samples.\n        prefetch (int, optional): number of next batches to be prefetched\n            using multithreading.\n        transform (Transform, optional): Transform to be executed when sample() is called.\n            To chain transforms use the :obj:`Compose` class.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float,\n        beta: float,\n        eps: float = 1e-8,\n        dtype: torch.dtype = torch.float,\n        storage: Optional[Storage] = None,\n        collate_fn: Optional[Callable] = None,\n        pin_memory: bool = False,\n        prefetch: Optional[int] = None,\n        transform: Optional[\"Transform\"] = None,  # noqa-F821\n    ) -> None:\n        if storage is None:\n            storage = ListStorage(max_size=1_000)\n        sampler = PrioritizedSampler(storage.max_size, alpha, beta, eps, dtype)\n        super(PrioritizedReplayBuffer, self).__init__(\n            storage=storage,\n            sampler=sampler,\n            collate_fn=collate_fn,\n            pin_memory=pin_memory,\n            prefetch=prefetch,\n            transform=transform,\n        )\n\n\nclass TensorDictReplayBuffer(ReplayBuffer):\n    \"\"\"TensorDict-specific wrapper around the ReplayBuffer class.\n\n    Args:\n        priority_key (str): the key at which priority is assumed to be stored\n            within TensorDicts added to this ReplayBuffer.\n    \"\"\"\n\n    def __init__(self, priority_key: str = \"td_error\", **kw) -> None:\n        super().__init__(**kw)\n        self.priority_key = priority_key\n\n    def _get_priority(self, tensordict: TensorDictBase) -> Optional[torch.Tensor]:\n        if self.priority_key not in tensordict.keys():\n            return self._sampler.default_priority\n        if tensordict.batch_dims:", "choices": [{"text": "tensordict = tensordict.move_dim(*tensordict.batch_dims, -2)"}], "metadata": {"task_id": "pytorch_rl/60", "ground_truth": "            tensordict = tensordict.clone(recurse=False)", "fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "replay_buffers.py"], "context_start_lineno": 145, "line_no": 349, "query_window": {"context": "            transform=transform,\n        )\n\n\nclass TensorDictReplayBuffer(ReplayBuffer):\n    \"\"\"TensorDict-specific wrapper around the ReplayBuffer class.\n\n    Args:\n        priority_key (str): the key at which priority is assumed to be stored\n            within TensorDicts added to this ReplayBuffer.\n    \"\"\"\n\n    def __init__(self, priority_key: str = \"td_error\", **kw) -> None:\n        super().__init__(**kw)\n        self.priority_key = priority_key\n\n    def _get_priority(self, tensordict: TensorDictBase) -> Optional[torch.Tensor]:\n        if self.priority_key not in tensordict.keys():\n            return self._sampler.default_priority\n        if tensordict.batch_dims:", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "replay_buffers.py"], "line_no": 349, "task_id": "pytorch_rl/60", "start_line_no": 329, "end_line_no": 349, "window_size": 20, "context_start_lineno": 145, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    \"\"\"\n\n    invertible = True\n\n    def __init__(\n        self,\n        in_keys: Optional[Sequence[str]] = None,\n        in_keys_inv: Optional[Sequence[str]] = None,\n    ):\n        super().__init__(in_keys=in_keys, in_keys_inv=in_keys_inv)\n\n    def _apply_transform(self, obs: torch.Tensor) -> torch.Tensor:\n        return obs.to(torch.float)\n\n    def _inv_apply_transform(self, obs: torch.Tensor) -> torch.Tensor:\n        return obs.to(torch.double)\n\n    def _transform_spec(self, spec: TensorSpec) -> None:\n        if isinstance(spec, CompositeSpec):\n            for key in spec:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 1720, "start_line_no": 1710, "end_line_no": 1730, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3565217391304348}, {"context": "        done = self._to_tensor(done, dtype=torch.bool)\n\n        tensordict_out = TensorDict(\n            obs_dict, batch_size=tensordict.batch_size, device=self.device\n        )\n\n        tensordict_out.set(\"reward\", reward)\n        tensordict_out.set(\"done\", done)\n        if self.info_dict_reader is not None and info is not None:\n            self.info_dict_reader(info, tensordict_out)\n\n        return tensordict_out\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:\n        reset_data = self._env.reset(**kwargs)\n        if not isinstance(reset_data, tuple):\n            reset_data = (reset_data,)\n        obs, *other = self._output_transform(reset_data)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.34615384615384615}, {"context": "\n        return tensordict_out\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:\n        reset_data = self._env.reset(**kwargs)\n        if not isinstance(reset_data, tuple):\n            reset_data = (reset_data,)\n        obs, *other = self._output_transform(reset_data)\n        info = None\n        if len(other) == 1:\n            info = other\n\n        tensordict_out = TensorDict(\n            source=self.read_obs(obs),\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n        if self.info_dict_reader is not None and info is not None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.336}, {"context": "        return self._dtype\n\n\nclass VIPRewardTransform(VIPTransform):\n    \"\"\"A VIP transform to compute rewards based on embedded similarity.\n\n    This class will update the reward computation\n    \"\"\"\n\n    def reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n        if \"goal_embedding\" not in tensordict.keys():\n            tensordict = self._embed_goal(tensordict)\n        return super().reset(tensordict)\n\n    def _embed_goal(self, tensordict):\n        if \"goal_image\" not in tensordict.keys():\n            raise KeyError(\n                f\"{self.__class__.__name__}.reset() requires a `'goal_image'` key to be \"\n                f\"present in the input tensordict.\"\n            )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "vip.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "\n    def rand_step(self, tensordict: Optional[TensorDictBase] = None) -> TensorDictBase:\n        \"\"\"Performs a random step in the environment given the action_spec attribute.\n\n        Args:\n            tensordict (TensorDictBase, optional): tensordict where the resulting info should be written.\n\n        Returns:\n            a tensordict object with the new observation after a random step in the environment. The action will\n            be stored with the \"action\" key.\n\n        \"\"\"\n        if tensordict is None:\n            tensordict = TensorDict(\n                {}, device=self.device, batch_size=self.batch_size, _run_checks=False\n            )\n        action = self.action_spec.rand()\n        tensordict.set(\"action\", action)\n        return self.step(tensordict)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 580, "start_line_no": 570, "end_line_no": 590, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.33093525179856115}, {"context": "    @_check_start\n    def set_seed(\n        self, seed: Optional[int] = None, static_seed: bool = False\n    ) -> Optional[int]:\n        for env in self._envs:\n            new_seed = env.set_seed(seed, static_seed=static_seed)\n            seed = new_seed\n        return seed\n\n    @_check_start\n    def _reset(self, tensordict: TensorDictBase, **kwargs) -> TensorDictBase:\n\n        if tensordict is not None and \"_reset\" in tensordict.keys():\n            self._assert_tensordict_shape(tensordict)\n            _reset = tensordict.get(\"_reset\")\n        else:\n            _reset = torch.ones(self.batch_size, dtype=torch.bool)\n\n        keys = set()\n        for i, _env in enumerate(self._envs):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.33088235294117646}, {"context": "        skip_reset (bool): if True, the first TensorDict of the list will be discarded (usually the tensordict\n            resulting from the call to :obj:`env.reset()`)\n            default: True\n        skip (int): frame interval for the saved tensordict.\n            default: 4\n\n    \"\"\"\n\n    def __init__(\n        self,\n        out_file_base: str,\n        skip_reset: bool = True,\n        skip: int = 4,\n        in_keys: Optional[Sequence[str]] = None,\n    ) -> None:\n        if in_keys is None:\n            in_keys = []\n\n        super().__init__(in_keys=in_keys)\n        self.iter = 0", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "record", "recorder.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3282442748091603}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/coordinator/comm_coordinator.py\n# --------------------------------------------------\n#                     continue\n#                 result = get_data_task.result\n#                 task_id, buffer_id, batch_size = result['task_id'], result['buffer_id'], result['batch_size']\n#                 cur_learner_iter = result['cur_learner_iter']\n#                 sleep_count = 1\n#                 while True:\n#                     data = self._callback_fn['deal_with_learner_get_data'](\n#                         task_id, buffer_id, batch_size, cur_learner_iter\n#                     )\n#                     if self._end_flag or data is not None:\n#                         self._logger.info('sample result is ok')\n#                         break\n#                     else:\n#                         self._logger.info('sample result is None')\n#                         time.sleep(sleep_count)\n#                         sleep_count += 2\n#                 if self._end_flag:\n#                     break\n# \n#                 # learn task\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/adapter/learner_aggregator.py\n# --------------------------------------------------\n#         start = 0\n#         for item in self._data_demand.values():\n#             end = item['batch_size'] + start\n#             split_data.append(merged_data[start:end])\n#             start = end\n#         for (k, v), d in zip(self._learner_connection.items(), split_data):\n#             learn_task[k] = v.new_task({'name': task['name'], 'data': d})\n#             learn_task[k].start()\n#         for k, v in learn_task.items():\n#             v.join()\n#         # TODO deal with task fail\n#         info_list = [v.result for v in learn_task.values()]\n#         # Merge learn info through ``merge_info`` method.\n#         merged_info = self.merge_info(info_list)\n#         return merged_info\n# \n#     @staticmethod\n#     def merge_info(info: list) -> dict:\n#         homogeneous_keys = ['learner_step', 'buffer_id', 'task_id', 'learner_done']\n#         elem = info[0]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/data/dataloader.py\n# --------------------------------------------------\n#                     data = self.collate_fn(data)\n#                     self.async_train_queue.put(data)\n#                     p.send('pass')\n#                 else:\n#                     p.send(data)\n#         p.close()\n# \n#     def _async_loop(self, p: tm.multiprocessing.connection, c: tm.multiprocessing.connection) -> None:\n#         \"\"\"\n#         Overview:\n#             Main worker process. Run through ``self.async_process``.\n#             Firstly, get data from ``self.get_data_thread``.\n#             If multiple workers, put data in ``self.job_queue`` for further multiprocessing operation;\n#             If only one worker, process data and put directly into ``self.async_train_queue``.\n#         Arguments:\n#             - p (:obj:`tm.multiprocessing.connection`): Parent connection.\n#             - c (:obj:`tm.multiprocessing.connection`): Child connection.\n#         \"\"\"\n#         p.close()  # Close unused p, only use c\n#         while not self.end_flag:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/adapter/learner_aggregator.py\n# --------------------------------------------------\n#         # TODO deal with task fail\n#         info_list = [v.result for v in learn_task.values()]\n#         # Merge learn info through ``merge_info`` method.\n#         merged_info = self.merge_info(info_list)\n#         return merged_info\n# \n#     @staticmethod\n#     def merge_info(info: list) -> dict:\n#         homogeneous_keys = ['learner_step', 'buffer_id', 'task_id', 'learner_done']\n#         elem = info[0]\n#         if elem is None:\n#             return info\n#         elif isinstance(elem, numbers.Integral) or isinstance(elem, str) or isinstance(elem, float):\n#             return info\n#         elif isinstance(elem, list) or isinstance(elem, tuple):\n#             return list(reduce(lambda x, y: x + y, info))\n#         elif isinstance(elem, dict):\n#             ret = {}\n#             for k in elem.keys():\n#                 if k in homogeneous_keys:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/wrapper/model_wrappers.py\n# --------------------------------------------------\n#         assert len(state) == len(state_id), '{}/{}'.format(len(state), len(state_id))\n#         for idx, s in zip(state_id, state):\n#             self._state[idx] = s\n# \n#     def before_forward(self, data: dict, state_id: Optional[list]) -> Tuple[dict, dict]:\n#         if state_id is None:\n#             state_id = [i for i in range(self._state_num)]\n# \n#         state_info = {idx: self._state[idx] for idx in state_id}\n#         data['prev_state'] = list(state_info.values())\n#         return data, state_info\n# \n#     def after_forward(self, h: Any, state_info: dict, valid_id: Optional[list] = None) -> None:\n#         assert len(h) == len(state_info), '{}/{}'.format(len(h), len(state_info))\n#         for i, idx in enumerate(state_info.keys()):\n#             if valid_id is None:\n#                 self._state[idx] = h[i]\n#             else:\n#                 if idx in valid_id:\n#                     self._state[idx] = h[i]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/adapter/learner_aggregator.py\n# --------------------------------------------------\n#         # Merge data demand info by adding up all learners' demand batch size.\n#         merged_demand = copy.deepcopy(demand_list[0])\n#         merged_demand['batch_size'] = sum([d['batch_size'] for d in demand_list])\n#         return merged_demand\n# \n#     def deal_with_learn(self, task: dict) -> dict:\n#         learn_task = {}\n#         merged_data = task['data']\n#         # Split training data for each learner according to ``self._data_demand``.\n#         split_data = []\n#         start = 0\n#         for item in self._data_demand.values():\n#             end = item['batch_size'] + start\n#             split_data.append(merged_data[start:end])\n#             start = end\n#         for (k, v), d in zip(self._learner_connection.items(), split_data):\n#             learn_task[k] = v.new_task({'name': task['name'], 'data': d})\n#             learn_task[k].start()\n#         for k, v in learn_task.items():\n#             v.join()\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n_demand_queue = Queue(maxsize=1)\n        self._data_result_queue = Queue(maxsize=1)\n        self._learn_info_queue = Queue(maxsize=1)\n\n        # Task-level learner and policy will only be set once received the task.\n        self._learner = None\n        self._policy_id = None\n\n    def start(self) -> None:\n        \"\"\"\n        Overview:\n            Start comm learner itself and the learner slave.\n        \"\"\"\n        BaseCommLearner.start(self)\n        self._slave.start()\n\n    def close(self) -> None:\n        \"\"\"\n        Overview:\n            Join learner thread and close learner if still running.\n            Then close learner slave and comm learner itself.\n        \"\"\"\n        if self._end_flag:\n            return\n        if self._learner is not None:\n            self.deal_with_learner_close()\n        self._slave.close()\n        BaseCommLearner.close(self)\n\n    def __del__(self) -> None:\n        \"\"\"\n        Overview:\n            Call ``close`` for deletion.\n        \"\"\"\n        self.close()\n\n    def deal_with_resource(self) -> dict:\n        \"\"\"\n        Overview:\n            Callback function. Return how many resources are needed to start current learner.\n        Returns:\n            - resource (:obj:`dict`): Resource info dict, including [\"gpu\"].\n        \"\"\"\n        return {'gpu': self._world_size}\n\n    def deal_with_learner_start(self, task_info: dict) -> None:\n        \"\"\"\n        Overview:\n            Callback function. Create a learner and help register its hooks. Start a learner thread of the created one.\n        Arguments:\n            - task_info (:obj:`dict`): Task info dict.\n\n        .. note::\n            In ``_create_learner`` method in base class ``BaseCommLearner``, 3 methods\n            ('get_data', 'send_policy', 'send_learn_info'), dataloader and policy are set.\n            You can refer to it for details.\n        \"\"\"\n        self._policy_id = task_info['policy_id']\n        self._league_save_checkpoint_path = task_info.get('league_save_checkpoint_path', None)\n        self._learner = self._create_learner(task_info)\n        for h in self.hooks4call:\n            self._learner.register_hook(h)\n        self._learner_thread = Thread(target=self._learner.start, args=(), daemon=True, name='learner_start')\n        self._learner_thread.start()\n\n    def deal_with_get_data(self) -> Any:\n        \"\"\"\n        Overview:\n            Callback function. Get data demand info dict from ``_data_demand_queue``,\n            which will be sent to coordinator afterwards.\n        Returns:\n            - data_demand (:obj:`Any`): Data demand info dict.\n        \"\"\"\n        data_demand = self._data_demand_queue.get()\n        return data_demand\n\n    def deal_with_learner_learn(self, data: dict) -> dict:\n        \"\"\"\n        Overview:\n            Callback function. Put training data info dict (i.e. meta data), which is received from coordinator, into\n            ``_data_result_queue``, and wait for ``get_data`` to retrieve. Wait for learner training and\n            get learn info dict from ``_learn_info_queue``. If task is finished, join the learner thread and\n            close the learner.\n        Returns:\n            - learn_info (:obj:`Any`): Learn info dict.\n        \"\"\"\n        self._data_result_queue.put(data)\n        learn_info = self._learn_info_queue.get()\n        return learn_info\n\n    def deal_with_learner_close(self) -> None:\n        self._learner.close()\n        self._learner_thread.join()\n        del self._learner_thread\n        self._learner = None\n        self._policy_id = None\n\n    # override\n    def send_policy(self, state_dict: dict) -> None:\n        \"\"\"\n        Overview:\n            Save learner's policy in corresponding path, called by ``SendPolicyHook``.\n        Arguments:\n            - state_dict (:obj:`dict`): State dict of the policy.\n        \"\"\"\n        if not os.path.exists(self._path_policy):\n            os.mkdir(self._path_policy)\n        path = self._policy_id\n        if self._path_policy not in path:\n            path = os.path.join(self._path_policy, path)\n        setattr(self, \"_latest_policy_path\", path)\n        save_file(path, state_dict, use_lock=True)\n\n        if self._league_save_checkpoint_path is not None:\n            save_file(self._league_save_checkpoint_path, state_dict, use_lock=True)\n\n    @staticmethod\n    def load_data_fn(path, meta: Dict[str, Any], decompressor: Callable) -> Any:\n        \"\"\"\n        Overview:\n            The function that is used to load data file.\n        Arguments:\n            - meta (:obj:`Dict[str, Any]`): Meta data info dict.\n            - decompressor (:obj:`Callable`): Decompress function.\n        Returns:\n            - s (:obj:`Any`): Data which is read from file.\n        \"\"\"\n        # Due to read-write conflict, read_file raise an error, therefore we set a while loop.\n        while True:\n            try:\n                s = read_from_di_store(path) if read_from_di_store else read_file(path, use_lock=False)\n                s = decompressor(s)\n                break\n            except Exception:\n                time.sleep(0.01)\n        unroll_len = meta.get('unroll_len', 1)\n        if 'unroll_split_begin' in meta:\n            begin = meta['unroll_split_begin']\n            if unroll_len == 1:\n                s = s[begin]\n                s.update(meta)\n            else:\n                end = begin + unroll_len\n                s = s[begin:end]\n                # add metadata key-value to stepdata\n                for i in range(len(s)):\n                    s[i].update(meta)\n        else:\n            s.update(meta)\n        return s\n\n    # override\n    def get_data(self, batch_size: int) -> List[Callable]:\n        \"\"\"\n        Overview:\n            Get a list of data loading function, which can be implemented by dataloader to read data from files.\n        Arguments:\n            - batch_size (:obj:`int`): Batch size.\n        Returns:\n            - data (:obj:`List[Callable]`): A list of callable data loading function.\n        \"\"\"\n        while self._learner is None:\n            time.sleep(1)\n        # Tell coordinator that we need training data, by putting info dict in data_demand_queue.\n        assert self._data_demand_queue.qsize() == 0\n        self._data_demand_queue.put({'batch_size': batch_size, 'cur_learner_iter': self._learner.last_iter.val})\n        # Get a list of meta data (data info dict) from coordinator, by getting info dict from data_result_queue.\n        data = self._data_result_queue.get()\n        assert isinstance(data, list)\n        assert len(data) == batch_size, '{}/{}'.format(len(data), batch_size)\n        # Transform meta data to callable data loading function (partial ``load_data_fn``).\n        decompressor = get_data_decompressor(data[0].get('compressor', 'none'))\n        data = [\n            partial(\n                FlaskFileSystemLearner.load_data_fn,\n                path=m['object_ref'] if read_from_di_store else os.path.join(self._path_data, m['data_id']),\n                meta=m,\n                decompressor=decompressor,\n            ) for m in data\n        ]\n        return data\n\n    # override", "choices": [{"text": "if __name__ == \"__main__\":"}], "metadata": {"task_id": "opendilab_ACE/38", "ground_truth": "    def send_learn_info(self, learn_info: dict) -> None:", "fpath_tuple": ["opendilab_ACE", "ding", "worker", "learner", "comm", "flask_fs_learner.py"], "context_start_lineno": 110, "line_no": 293, "query_window": {"context": "        # Tell coordinator that we need training data, by putting info dict in data_demand_queue.\n        assert self._data_demand_queue.qsize() == 0\n        self._data_demand_queue.put({'batch_size': batch_size, 'cur_learner_iter': self._learner.last_iter.val})\n        # Get a list of meta data (data info dict) from coordinator, by getting info dict from data_result_queue.\n        data = self._data_result_queue.get()\n        assert isinstance(data, list)\n        assert len(data) == batch_size, '{}/{}'.format(len(data), batch_size)\n        # Transform meta data to callable data loading function (partial ``load_data_fn``).\n        decompressor = get_data_decompressor(data[0].get('compressor', 'none'))\n        data = [\n            partial(\n                FlaskFileSystemLearner.load_data_fn,\n                path=m['object_ref'] if read_from_di_store else os.path.join(self._path_data, m['data_id']),\n                meta=m,\n                decompressor=decompressor,\n            ) for m in data\n        ]\n        return data\n\n    # override", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "worker", "learner", "comm", "flask_fs_learner.py"], "line_no": 293, "task_id": "opendilab_ACE/38", "start_line_no": 273, "end_line_no": 293, "window_size": 20, "context_start_lineno": 110, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "    def deal_with_get_data(self, task: dict) -> dict:\n        data_task = {}\n        for k, v in self._learner_connection.items():\n            data_task[k] = v.new_task({'name': task['name']})\n            data_task[k].start()\n        for k, v in data_task.items():\n            v.join()\n        # TODO deal with task fail\n        self._data_demand = {k: v.result for k, v in data_task.items()}\n        demand_list = list(self._data_demand.values())\n        # Merge data demand info by adding up all learners' demand batch size.\n        merged_demand = copy.deepcopy(demand_list[0])\n        merged_demand['batch_size'] = sum([d['batch_size'] for d in demand_list])\n        return merged_demand\n\n    def deal_with_learn(self, task: dict) -> dict:\n        learn_task = {}\n        merged_data = task['data']\n        # Split training data for each learner according to ``self._data_demand``.\n        split_data = []", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "adapter", "learner_aggregator.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2742857142857143}, {"context": "        state_id = kwargs.get('data_id', None)\n        self.reset_state(state, state_id)\n        if hasattr(self._model, 'reset'):\n            return self._model.reset(*args, **kwargs)\n\n    def reset_state(self, state: Optional[list] = None, state_id: Optional[list] = None) -> None:\n        if state_id is None:\n            state_id = [i for i in range(self._state_num)]\n        if state is None:\n            state = [self._init_fn() for i in range(len(state_id))]\n        assert len(state) == len(state_id), '{}/{}'.format(len(state), len(state_id))\n        for idx, s in zip(state_id, state):\n            self._state[idx] = s\n\n    def before_forward(self, data: dict, state_id: Optional[list]) -> Tuple[dict, dict]:\n        if state_id is None:\n            state_id = [i for i in range(self._state_num)]\n\n        state_info = {idx: self._state[idx] for idx in state_id}\n        data['prev_state'] = list(state_info.values())", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "wrapper", "model_wrappers.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.27380952380952384}, {"context": "        start = 0\n        for item in self._data_demand.values():\n            end = item['batch_size'] + start\n            split_data.append(merged_data[start:end])\n            start = end\n        for (k, v), d in zip(self._learner_connection.items(), split_data):\n            learn_task[k] = v.new_task({'name': task['name'], 'data': d})\n            learn_task[k].start()\n        for k, v in learn_task.items():\n            v.join()\n        # TODO deal with task fail\n        info_list = [v.result for v in learn_task.values()]\n        # Merge learn info through ``merge_info`` method.\n        merged_info = self.merge_info(info_list)\n        return merged_info\n\n    @staticmethod\n    def merge_info(info: list) -> dict:\n        homogeneous_keys = ['learner_step', 'buffer_id', 'task_id', 'learner_done']\n        elem = info[0]", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "adapter", "learner_aggregator.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2692307692307692}, {"context": "                break\n            if cmd == 'get_data':\n                # Main worker asks for data.\n                data = self.data_source(self.batch_size)\n                # ``data`` can be callable, e.g. a function to read data from file, therefore we can divide\n                # this job to pieces, assign to every slave worker and accomplish jobs asynchronously.\n                # But if we get a list of dicts, which means the data has already been processed and\n                # can be used directly, we can put it directly in async_train_queue and wait it\n                # to be accessed by a user, e.g. learner.\n                if isinstance(data[0], dict):\n                    data = self.collate_fn(data)\n                    self.async_train_queue.put(data)\n                    p.send('pass')\n                else:\n                    p.send(data)\n        p.close()\n\n    def _async_loop(self, p: tm.multiprocessing.connection, c: tm.multiprocessing.connection) -> None:\n        \"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "dataloader.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.26903553299492383}, {"context": "        # Merge data demand info by adding up all learners' demand batch size.\n        merged_demand = copy.deepcopy(demand_list[0])\n        merged_demand['batch_size'] = sum([d['batch_size'] for d in demand_list])\n        return merged_demand\n\n    def deal_with_learn(self, task: dict) -> dict:\n        learn_task = {}\n        merged_data = task['data']\n        # Split training data for each learner according to ``self._data_demand``.\n        split_data = []\n        start = 0\n        for item in self._data_demand.values():\n            end = item['batch_size'] + start\n            split_data.append(merged_data[start:end])\n            start = end\n        for (k, v), d in zip(self._learner_connection.items(), split_data):\n            learn_task[k] = v.new_task({'name': task['name'], 'data': d})\n            learn_task[k].start()\n        for k, v in learn_task.items():\n            v.join()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "adapter", "learner_aggregator.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.26519337016574585}, {"context": "        close_flag = False\n        learner_id = learner_task['learner_id']\n        while not self._end_flag:\n            try:\n                # get data\n                get_data_task = self._connection_learner[learner_id].new_task({'name': 'learner_get_data_task'})\n                get_data_task.start().join()\n                if get_data_task.status != TaskStatus.COMPLETED:\n                    # TODO(deal with fail task)\n                    self._logger.error('learner get_data_task failed: {}'.format(get_data_task.result))\n                    continue\n                result = get_data_task.result\n                task_id, buffer_id, batch_size = result['task_id'], result['buffer_id'], result['batch_size']\n                cur_learner_iter = result['cur_learner_iter']\n                sleep_count = 1\n                while True:\n                    data = self._callback_fn['deal_with_learner_get_data'](\n                        task_id, buffer_id, batch_size, cur_learner_iter\n                    )\n                    if self._end_flag or data is not None:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "comm_coordinator.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.25862068965517243}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/unclip/pipeline_unclip.py\n# --------------------------------------------------\n#             super_res_latents = self.super_res_scheduler.step(\n#                 noise_pred, t, super_res_latents, prev_timestep=prev_timestep, generator=generator\n#             ).prev_sample\n# \n#         image = super_res_latents\n#         # done super res\n# \n#         # post processing\n# \n#         image = image * 0.5 + 0.5\n#         image = image.clamp(0, 1)\n#         image = image.cpu().permute(0, 2, 3, 1).float().numpy()\n# \n#         if output_type == \"pil\":\n#             image = self.numpy_to_pil(image)\n# \n#         if not return_dict:\n#             return (image,)\n# \n#         return ImagePipelineOutput(images=image)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/stable_unclip.py\n# --------------------------------------------------\n#                 prev_timestep = prior_timesteps_tensor[i + 1]\n# \n#             prior_latents = self.prior_scheduler.step(\n#                 predicted_image_embedding,\n#                 timestep=t,\n#                 sample=prior_latents,\n#                 generator=generator,\n#                 prev_timestep=prev_timestep,\n#             ).prev_sample\n# \n#         prior_latents = self.prior.post_process_latents(prior_latents)\n# \n#         image_embeddings = prior_latents\n# \n#         output = self.decoder_pipe(\n#             image=image_embeddings,\n#             height=height,\n#             width=width,\n#             num_inference_steps=decoder_num_inference_steps,\n#             guidance_scale=decoder_guidance_scale,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/score_sde_ve/pipeline_score_sde_ve.py\n# --------------------------------------------------\n#             # correction step\n#             for _ in range(self.scheduler.config.correct_steps):\n#                 model_output = self.unet(sample, sigma_t).sample\n#                 sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n# \n#             # prediction step\n#             model_output = model(sample, sigma_t).sample\n#             output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n# \n#             sample, sample_mean = output.prev_sample, output.prev_sample_mean\n# \n#         sample = sample_mean.clamp(0, 1)\n#         sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n#         if output_type == \"pil\":\n#             sample = self.numpy_to_pil(sample)\n# \n#         if not return_dict:\n#             return (sample,)\n# \n#         return ImagePipelineOutput(images=sample)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/unclip/pipeline_unclip.py\n# --------------------------------------------------\n# \n#             prior_latents = self.prior_scheduler.step(\n#                 predicted_image_embedding,\n#                 timestep=t,\n#                 sample=prior_latents,\n#                 generator=generator,\n#                 prev_timestep=prev_timestep,\n#             ).prev_sample\n# \n#         prior_latents = self.prior.post_process_latents(prior_latents)\n# \n#         image_embeddings = prior_latents\n# \n#         # done prior\n# \n#         # decoder\n# \n#         text_encoder_hidden_states, additive_clip_time_embeddings = self.text_proj(\n#             image_embeddings=image_embeddings,\n#             prompt_embeds=prompt_embeds,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/stochastic_karras_ve/pipeline_stochastic_karras_ve.py\n# --------------------------------------------------\n#                 model_output = (sigma_prev / 2) * model((step_output.prev_sample + 1) / 2, sigma_prev / 2).sample\n#                 step_output = self.scheduler.step_correct(\n#                     model_output,\n#                     sigma_hat,\n#                     sigma_prev,\n#                     sample_hat,\n#                     step_output.prev_sample,\n#                     step_output[\"derivative\"],\n#                 )\n#             sample = step_output.prev_sample\n# \n#         sample = (sample / 2 + 0.5).clamp(0, 1)\n#         image = sample.cpu().permute(0, 2, 3, 1).numpy()\n#         if output_type == \"pil\":\n#             image = self.numpy_to_pil(sample)\n# \n#         if not return_dict:\n#             return (image,)\n# \n#         return ImagePipelineOutput(images=image)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/dit/pipeline_dit.py\n# --------------------------------------------------\n#         if guidance_scale > 1:\n#             latents, _ = latent_model_input.chunk(2, dim=0)\n#         else:\n#             latents = latent_model_input\n# \n#         latents = 1 / self.vae.config.scaling_factor * latents\n#         samples = self.vae.decode(latents).sample\n# \n#         samples = (samples / 2 + 0.5).clamp(0, 1)\n# \n#         # we always cast to float32 as this does not cause significant overhead and is compatible with bfloat16\n#         samples = samples.cpu().permute(0, 2, 3, 1).float().numpy()\n# \n#         if output_type == \"pil\":\n#             samples = self.numpy_to_pil(samples)\n# \n#         if not return_dict:\n#             return (samples,)\n# \n#         return ImagePipelineOutput(images=samples)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/vq_diffusion/pipeline_vq_diffusion.py\n# --------------------------------------------------\n#             # call the callback, if provided\n#             if callback is not None and i % callback_steps == 0:\n#                 callback(i, t, sample)\n# \n#         embedding_channels = self.vqvae.config.vq_embed_dim\n#         embeddings_shape = (batch_size, self.transformer.height, self.transformer.width, embedding_channels)\n#         embeddings = self.vqvae.quantize.get_codebook_entry(sample, shape=embeddings_shape)\n#         image = self.vqvae.decode(embeddings, force_not_quantize=True).sample\n# \n#         image = (image / 2 + 0.5).clamp(0, 1)\n#         image = image.cpu().permute(0, 2, 3, 1).numpy()\n# \n#         if output_type == \"pil\":\n#             image = self.numpy_to_pil(image)\n# \n#         if not return_dict:\n#             return (image,)\n# \n#         return ImagePipelineOutput(images=image)\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\ncheduler` or `DDPMScheduler`]): de-noising scheduler\n    \"\"\"\n\n    _optional_components = [\"vqvae\"]\n\n    def __init__(\n        self,\n        vqvae: AutoencoderKL,\n        unet: UNet2DConditionModel,\n        mel: Mel,\n        scheduler: Union[DDIMScheduler, DDPMScheduler],\n    ):\n        super().__init__()\n        self.register_modules(unet=unet, scheduler=scheduler, mel=mel, vqvae=vqvae)\n\n    def get_input_dims(self) -> Tuple:\n        \"\"\"Returns dimension of input image\n\n        Returns:\n            `Tuple`: (height, width)\n        \"\"\"\n        input_module = self.vqvae if self.vqvae is not None else self.unet\n        # For backwards compatibility\n        sample_size = (\n            (input_module.sample_size, input_module.sample_size)\n            if type(input_module.sample_size) == int\n            else input_module.sample_size\n        )\n        return sample_size\n\n    def get_default_steps(self) -> int:\n        \"\"\"Returns default number of steps recommended for inference\n\n        Returns:\n            `int`: number of steps\n        \"\"\"\n        return 50 if isinstance(self.scheduler, DDIMScheduler) else 1000\n\n    @torch.no_grad()\n    def __call__(\n        self,\n        batch_size: int = 1,\n        audio_file: str = None,\n        raw_audio: np.ndarray = None,\n        slice: int = 0,\n        start_step: int = 0,\n        steps: int = None,\n        generator: torch.Generator = None,\n        mask_start_secs: float = 0,\n        mask_end_secs: float = 0,\n        step_generator: torch.Generator = None,\n        eta: float = 0,\n        noise: torch.Tensor = None,\n        encoding: torch.Tensor = None,\n        return_dict=True,\n    ) -> Union[\n        Union[AudioPipelineOutput, ImagePipelineOutput],\n        Tuple[List[Image.Image], Tuple[int, List[np.ndarray]]],\n    ]:\n        \"\"\"Generate random mel spectrogram from audio input and convert to audio.\n\n        Args:\n            batch_size (`int`): number of samples to generate\n            audio_file (`str`): must be a file on disk due to Librosa limitation or\n            raw_audio (`np.ndarray`): audio as numpy array\n            slice (`int`): slice number of audio to convert\n            start_step (int): step to start from\n            steps (`int`): number of de-noising steps (defaults to 50 for DDIM, 1000 for DDPM)\n            generator (`torch.Generator`): random number generator or None\n            mask_start_secs (`float`): number of seconds of audio to mask (not generate) at start\n            mask_end_secs (`float`): number of seconds of audio to mask (not generate) at end\n            step_generator (`torch.Generator`): random number generator used to de-noise or None\n            eta (`float`): parameter between 0 and 1 used with DDIM scheduler\n            noise (`torch.Tensor`): noise tensor of shape (batch_size, 1, height, width) or None\n            encoding (`torch.Tensor`): for UNet2DConditionModel shape (batch_size, seq_length, cross_attention_dim)\n            return_dict (`bool`): if True return AudioPipelineOutput, ImagePipelineOutput else Tuple\n\n        Returns:\n            `List[PIL Image]`: mel spectrograms (`float`, `List[np.ndarray]`): sample rate and raw audios\n        \"\"\"\n\n        steps = steps or self.get_default_steps()\n        self.scheduler.set_timesteps(steps)\n        step_generator = step_generator or generator\n        # For backwards compatibility\n        if type(self.unet.sample_size) == int:\n            self.unet.sample_size = (self.unet.sample_size, self.unet.sample_size)\n        input_dims = self.get_input_dims()\n        self.mel.set_resolution(x_res=input_dims[1], y_res=input_dims[0])\n        if noise is None:\n            noise = randn_tensor(\n                (\n                    batch_size,\n                    self.unet.in_channels,\n                    self.unet.sample_size[0],\n                    self.unet.sample_size[1],\n                ),\n                generator=generator,\n                device=self.device,\n            )\n        images = noise\n        mask = None\n\n        if audio_file is not None or raw_audio is not None:\n            self.mel.load_audio(audio_file, raw_audio)\n            input_image = self.mel.audio_slice_to_image(slice)\n            input_image = np.frombuffer(input_image.tobytes(), dtype=\"uint8\").reshape(\n                (input_image.height, input_image.width)\n            )\n            input_image = (input_image / 255) * 2 - 1\n            input_images = torch.tensor(input_image[np.newaxis, :, :], dtype=torch.float).to(self.device)\n\n            if self.vqvae is not None:\n                input_images = self.vqvae.encode(torch.unsqueeze(input_images, 0)).latent_dist.sample(\n                    generator=generator\n                )[0]\n                input_images = self.vqvae.config.scaling_factor * input_images\n\n            if start_step > 0:\n                images[0, 0] = self.scheduler.add_noise(input_images, noise, self.scheduler.timesteps[start_step - 1])\n\n            pixels_per_second = (\n                self.unet.sample_size[1] * self.mel.get_sample_rate() / self.mel.x_res / self.mel.hop_length\n            )\n            mask_start = int(mask_start_secs * pixels_per_second)\n            mask_end = int(mask_end_secs * pixels_per_second)\n            mask = self.scheduler.add_noise(input_images, noise, torch.tensor(self.scheduler.timesteps[start_step:]))\n\n        for step, t in enumerate(self.progress_bar(self.scheduler.timesteps[start_step:])):\n            if isinstance(self.unet, UNet2DConditionModel):\n                model_output = self.unet(images, t, encoding)[\"sample\"]\n            else:\n                model_output = self.unet(images, t)[\"sample\"]\n\n            if isinstance(self.scheduler, DDIMScheduler):\n                images = self.scheduler.step(\n                    model_output=model_output,\n                    timestep=t,\n                    sample=images,\n                    eta=eta,\n                    generator=step_generator,\n                )[\"prev_sample\"]\n            else:\n                images = self.scheduler.step(\n                    model_output=model_output,\n                    timestep=t,\n                    sample=images,\n                    generator=step_generator,\n                )[\"prev_sample\"]\n\n            if mask is not None:\n                if mask_start > 0:\n                    images[:, :, :, :mask_start] = mask[:, step, :, :mask_start]\n                if mask_end > 0:\n                    images[:, :, :, -mask_end:] = mask[:, step, :, -mask_end:]\n\n        if self.vqvae is not None:\n            # 0.18215 was scaling factor used in training to ensure unit variance\n            images = 1 / self.vqvae.config.scaling_factor * images\n            images = self.vqvae.decode(images)[\"sample\"]\n\n        images = (images / 2 + 0.5).clamp(0, 1)", "choices": [{"text": "images = images.cpu().permute(0, 2, 3, 1).numpy()"}], "metadata": {"task_id": "huggingface_diffusers/173", "ground_truth": "        images = images.cpu().permute(0, 2, 3, 1).numpy()", "fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "audio_diffusion", "pipeline_audio_diffusion.py"], "context_start_lineno": 39, "line_no": 201, "query_window": {"context": "            else:\n                images = self.scheduler.step(\n                    model_output=model_output,\n                    timestep=t,\n                    sample=images,\n                    generator=step_generator,\n                )[\"prev_sample\"]\n\n            if mask is not None:\n                if mask_start > 0:\n                    images[:, :, :, :mask_start] = mask[:, step, :, :mask_start]\n                if mask_end > 0:\n                    images[:, :, :, -mask_end:] = mask[:, step, :, -mask_end:]\n\n        if self.vqvae is not None:\n            # 0.18215 was scaling factor used in training to ensure unit variance\n            images = 1 / self.vqvae.config.scaling_factor * images\n            images = self.vqvae.decode(images)[\"sample\"]\n\n        images = (images / 2 + 0.5).clamp(0, 1)", "metadata": {"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "audio_diffusion", "pipeline_audio_diffusion.py"], "line_no": 201, "task_id": "huggingface_diffusers/173", "start_line_no": 181, "end_line_no": 201, "window_size": 20, "context_start_lineno": 39, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "                model_output -= torch.logsumexp(model_output, dim=1, keepdim=True)\n\n            model_output = self.truncate(model_output, truncation_rate)\n\n            # remove `log(0)`'s (`-inf`s)\n            model_output = model_output.clamp(-70)\n\n            # compute the previous noisy sample x_t -> x_t-1\n            sample = self.scheduler.step(model_output, timestep=t, sample=sample, generator=generator).prev_sample\n\n            # call the callback, if provided\n            if callback is not None and i % callback_steps == 0:\n                callback(i, t, sample)\n\n        embedding_channels = self.vqvae.config.vq_embed_dim\n        embeddings_shape = (batch_size, self.transformer.height, self.transformer.width, embedding_channels)\n        embeddings = self.vqvae.quantize.get_codebook_entry(sample, shape=embeddings_shape)\n        image = self.vqvae.decode(embeddings, force_not_quantize=True).sample\n\n        image = (image / 2 + 0.5).clamp(0, 1)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "vq_diffusion", "pipeline_vq_diffusion.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3464052287581699}, {"context": "            # learned sigma\n            if self.transformer.config.out_channels // 2 == latent_channels:\n                model_output, _ = torch.split(noise_pred, latent_channels, dim=1)\n            else:\n                model_output = noise_pred\n\n            # compute previous image: x_t -> x_t-1\n            latent_model_input = self.scheduler.step(model_output, t, latent_model_input).prev_sample\n\n        if guidance_scale > 1:\n            latents, _ = latent_model_input.chunk(2, dim=0)\n        else:\n            latents = latent_model_input\n\n        latents = 1 / self.vae.config.scaling_factor * latents\n        samples = self.vae.decode(latents).sample\n\n        samples = (samples / 2 + 0.5).clamp(0, 1)\n\n        # we always cast to float32 as this does not cause significant overhead and is compatible with bfloat16", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "dit", "pipeline_dit.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.34507042253521125}, {"context": "\n            # 4. Evaluate dx/dt at sigma_hat\n            # 5. Take Euler step from sigma to sigma_prev\n            step_output = self.scheduler.step(model_output, sigma_hat, sigma_prev, sample_hat)\n\n            if sigma_prev != 0:\n                # 6. Apply 2nd order correction\n                # The model inputs and output are adjusted by following eq. (213) in [1].\n                model_output = (sigma_prev / 2) * model((step_output.prev_sample + 1) / 2, sigma_prev / 2).sample\n                step_output = self.scheduler.step_correct(\n                    model_output,\n                    sigma_hat,\n                    sigma_prev,\n                    sample_hat,\n                    step_output.prev_sample,\n                    step_output[\"derivative\"],\n                )\n            sample = step_output.prev_sample\n\n        sample = (sample / 2 + 0.5).clamp(0, 1)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stochastic_karras_ve", "pipeline_stochastic_karras_ve.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.33858267716535434}, {"context": "            if do_classifier_free_guidance:\n                predicted_image_embedding_uncond, predicted_image_embedding_text = predicted_image_embedding.chunk(2)\n                predicted_image_embedding = predicted_image_embedding_uncond + prior_guidance_scale * (\n                    predicted_image_embedding_text - predicted_image_embedding_uncond\n                )\n\n            if i + 1 == prior_timesteps_tensor.shape[0]:\n                prev_timestep = None\n            else:\n                prev_timestep = prior_timesteps_tensor[i + 1]\n\n            prior_latents = self.prior_scheduler.step(\n                predicted_image_embedding,\n                timestep=t,\n                sample=prior_latents,\n                generator=generator,\n                prev_timestep=prev_timestep,\n            ).prev_sample\n\n        prior_latents = self.prior.post_process_latents(prior_latents)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "unclip", "pipeline_unclip.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3360655737704918}, {"context": "\n            # correction step\n            for _ in range(self.scheduler.config.correct_steps):\n                model_output = self.unet(sample, sigma_t).sample\n                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n\n            # prediction step\n            model_output = model(sample, sigma_t).sample\n            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n\n            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n\n        sample = sample_mean.clamp(0, 1)\n        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n        if output_type == \"pil\":\n            sample = self.numpy_to_pil(sample)\n\n        if not return_dict:\n            return (sample,)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "score_sde_ve", "pipeline_score_sde_ve.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3360655737704918}, {"context": "\n            if do_classifier_free_guidance:\n                predicted_image_embedding_uncond, predicted_image_embedding_text = predicted_image_embedding.chunk(2)\n                predicted_image_embedding = predicted_image_embedding_uncond + prior_guidance_scale * (\n                    predicted_image_embedding_text - predicted_image_embedding_uncond\n                )\n\n            if i + 1 == prior_timesteps_tensor.shape[0]:\n                prev_timestep = None\n            else:\n                prev_timestep = prior_timesteps_tensor[i + 1]\n\n            prior_latents = self.prior_scheduler.step(\n                predicted_image_embedding,\n                timestep=t,\n                sample=prior_latents,\n                generator=generator,\n                prev_timestep=prev_timestep,\n            ).prev_sample\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "stable_unclip.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "                prev_timestep = None\n            else:\n                prev_timestep = super_res_timesteps_tensor[i + 1]\n\n            # compute the previous noisy sample x_t -> x_t-1\n            super_res_latents = self.super_res_scheduler.step(\n                noise_pred, t, super_res_latents, prev_timestep=prev_timestep, generator=generator\n            ).prev_sample\n\n        image = super_res_latents\n        # done super res\n\n        # post processing\n\n        image = image * 0.5 + 0.5\n        image = image.clamp(0, 1)\n        image = image.cpu().permute(0, 2, 3, 1).float().numpy()\n\n        if output_type == \"pil\":\n            image = self.numpy_to_pil(image)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "unclip", "pipeline_unclip.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.32575757575757575}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/network/nn_module.py\n# --------------------------------------------------\n# import math\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# from torch.nn.init import xavier_normal_, kaiming_normal_, orthogonal_\n# from typing import Union, Tuple, List, Callable\n# \n# from .normalization import build_normalization\n# \n# \n# def weight_init_(weight: torch.Tensor, init_type: str = \"xavier\", activation: str = None) -> None:\n#     r\"\"\"\n#     Overview:\n#         Init weight according to the specified type.\n#     Arguments:\n#         - weight (:obj:`torch.Tensor`): the weight that needed to init\n#         - init_type (:obj:`str`): the type of init to implement, supports [\"xavier\", \"kaiming\", \"orthogonal\"]\n#         - activation (:obj:`str`): the activation function name, recommend that use only with \\\n#             ['relu', 'leaky_relu'].\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env_manager/base_env_manager.py\n# --------------------------------------------------\n# from types import MethodType\n# from typing import Union, Any, List, Callable, Dict, Optional\n# from functools import partial, wraps\n# from easydict import EasyDict\n# import copy\n# import platform\n# from collections import namedtuple\n# import numbers\n# import logging\n# import enum\n# import time\n# import traceback\n# from ding.utils import ENV_MANAGER_REGISTRY, import_module, one_time_warning\n# from ding.envs.env.base_env import BaseEnvTimestep\n# from ding.utils.time_helper import WatchDog\n# \n# \n# class EnvState(enum.IntEnum):\n#     VOID = 0\n#     INIT = 1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/exception/test_base.py\n# --------------------------------------------------\n# import json\n# from contextlib import contextmanager\n# from typing import Optional, Mapping, Any\n# \n# import pytest\n# import requests\n# import responses\n# from requests import HTTPError\n# \n# \n# class _HTTPErrorGenerator:\n# \n#     @classmethod\n#     def _generate_exception(\n#         cls, code: int, message: str, data: Optional[Mapping[str, Any]] = None, success: bool = False\n#     ):\n# \n#         @contextmanager\n#         def _yield_func():\n#             with responses.RequestsMock(assert_all_requests_are_fired=False) as rsp:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/hpc_rl/__init__.py\n# --------------------------------------------------\n# from .wrapper import hpc_wrapper\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/__init__.py\n# --------------------------------------------------\n# from .master import *\n# from .slave import *\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/test_utils/__init__.py\n# --------------------------------------------------\n# from .random import random_port, random_channel\n# from .stream import silence, silence_function\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/file_helper.py\n# --------------------------------------------------\n# import io\n# import logging\n# import os\n# import pickle\n# import time\n# from functools import lru_cache\n# from typing import NoReturn, Union\n# \n# import torch\n# \n# from .import_helper import try_import_ceph, try_import_redis, try_import_rediscluster, try_import_mc\n# from .lock_helper import get_file_lock\n# \n# _memcached = None\n# _redis_cluster = None\n# \n# if os.environ.get('DI_STORE', 'off').lower() == 'on':\n#     print('Enable DI-store')\n#     from di_store import Client\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/data/structure/__init__.py\n# --------------------------------------------------\n# from .cache import Cache\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/master/__init__.py\n# --------------------------------------------------\n# from .master import Master\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/type_helper.py\n# --------------------------------------------------\n# from collections import namedtuple\n# from typing import List, Dict, TypeVar\n# \n# SequenceType = TypeVar('SequenceType', List, Dict, namedtuple)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import Union, List", "choices": [{"text": "from ding.interaction.master import Master"}], "metadata": {"task_id": "opendilab_ACE/76", "ground_truth": "import torch", "fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "qmix.py"], "context_start_lineno": 0, "line_no": 1, "query_window": {"context": "from typing import Union, List", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "qmix.py"], "line_no": 1, "task_id": "opendilab_ACE/76", "start_line_no": 0, "end_line_no": 1, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "from collections import namedtuple\nfrom typing import List, Dict, TypeVar\n\nSequenceType = TypeVar('SequenceType', List, Dict, namedtuple)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "type_helper.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 4, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.22727272727272727}, {"context": "from .master import Master", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "master", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 1, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2222222222222222}, {"context": "from .cache import Cache", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "structure", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 1, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2222222222222222}, {"context": "import io\nimport logging\nimport os\nimport pickle\nimport time\nfrom functools import lru_cache\nfrom typing import NoReturn, Union\n\nimport torch\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "file_helper.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.20833333333333334}, {"context": "from .random import random_port, random_channel\nfrom .stream import silence, silence_function", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "test_utils", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 2, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.1875}, {"context": "from .master import *\nfrom .slave import *", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 2, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.18181818181818182}, {"context": "from .wrapper import hpc_wrapper", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 1, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.18181818181818182}, {"context": "import json\nfrom contextlib import contextmanager\nfrom typing import Optional, Mapping, Any\n\nimport pytest\nimport requests\nimport responses\nfrom requests import HTTPError\n\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "exception", "test_base.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.17391304347826086}, {"context": "from types import MethodType\nfrom typing import Union, Any, List, Callable, Dict, Optional\nfrom functools import partial, wraps\nfrom easydict import EasyDict\nimport copy\nimport platform\nfrom collections import namedtuple\nimport numbers\nimport logging\nimport enum", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "base_env_manager.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.17142857142857143}, {"context": "import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.init import xavier_normal_, kaiming_normal_, orthogonal_\nfrom typing import Union, Tuple, List, Callable\n\nfrom .normalization import build_normalization\n\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "network", "nn_module.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.16666666666666666}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyglove/core.py\n# --------------------------------------------------\n# \n#   @property\n#   def metadata(self) -> dict[str, Any]:\n#     \"\"\"Gets metadata for current sampling.\"\"\"\n#     return self._metadata\n# \n#   @property\n#   def best_trial(self) -> Optional[pg.tuning.Trial]:\n#     \"\"\"Returns the best trial.\"\"\"\n#     return self._best_trial\n# \n#   @property\n#   def trials(self) -> Sequence[pg.tuning.Trial]:\n#     \"\"\"Returns trials.\"\"\"\n#     return self._trials\n# \n#   def format(self,\n#              compact: bool = False,\n#              verbose: bool = True,\n#              root_indent: int = 0,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config.py\n# --------------------------------------------------\n# \n#     If the trial is not completed, or infeasible, no metrics are returned.\n#     By default, only metrics configured in the StudyConfig are returned\n#     (e.g. only objective and safety metrics).\n# \n#     Args:\n#       pytrial:\n#       include_all_metrics: If True, all metrics in the final measurements are\n#         returned. If False, only metrics configured in the StudyConfig are\n#         returned.\n# \n#     Returns:\n#       Dict[metric name, metric value]\n#     \"\"\"\n#     configured_metrics = [m.name for m in self.metric_information]\n# \n#     metrics: Dict[str, float] = {}\n#     if pytrial.is_completed and not pytrial.infeasible:\n#       for name in pytrial.final_measurement.metrics:\n#         if (include_all_metrics or\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config.py\n# --------------------------------------------------\n#     \"\"\"\n#     pytrial = proto_converters.TrialConverter.from_proto(proto)\n#     return self._pytrial_metrics(\n#         pytrial, include_all_metrics=include_all_metrics)\n# \n#   def _pytrial_metrics(self,\n#                        pytrial: vz.Trial,\n#                        *,\n#                        include_all_metrics=False) -> Dict[str, float]:\n#     \"\"\"Returns the trial's final measurement metric values.\n# \n#     If the trial is not completed, or infeasible, no metrics are returned.\n#     By default, only metrics configured in the StudyConfig are returned\n#     (e.g. only objective and safety metrics).\n# \n#     Args:\n#       pytrial:\n#       include_all_metrics: If True, all metrics in the final measurements are\n#         returned. If False, only metrics configured in the StudyConfig are\n#         returned.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyglove/core.py\n# --------------------------------------------------\n# \n#   @property\n#   def id(self) -> int:\n#     \"\"\"Gets Trial ID as ID.\"\"\"\n#     return self._trial_client.id\n# \n#   @property\n#   def dna(self) -> pg.DNA:\n#     \"\"\"Gets DNA of current trial.\"\"\"\n#     return self._converter.to_dna(self._trial)\n# \n#   def get_trial(self) -> pg.tuning.Trial:\n#     \"\"\"Gets current trial with all fields up-to-date.\"\"\"\n#     self._trial = self._trial_client.materialize()\n#     return VizierTrial(self._converter, self._trial)\n# \n#   @property\n#   def checkpoint_to_warm_start_from(self) -> Optional[str]:\n#     \"\"\"Gets checkpoint path to warm start from. Refreshes `_trial`.\"\"\"\n#     # TODO: Add official support.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#                *,\n#                infeasibility_reason: Optional[str] = None,\n#                inplace: bool = True) -> 'Trial':\n#     \"\"\"Completes the trial and returns it.\n# \n#     Args:\n#       measurement: Measurement to complete the trial with.\n#       infeasibility_reason: If set, completes the trial as infeasible. If the\n#         trial was already infeasible and infeasibility_reason is not set, the\n#         trial remains infeasible.\n#       inplace: If True, Trial is modified in place. If False, which is the\n#         default, then the operation is performed and it returns a copy of the\n#         object.\n# \n#     Returns:\n#       Completed Trial.\n#     \"\"\"\n#     if inplace:\n#       # Use setattr. If we assign to self.final_measurement, then hyperref\n#       # mechanisms think this line is where `final_measurement` property\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyglove/backend.py\n# --------------------------------------------------\n#         self.tuner.pythia_supporter(self._study),\n#         self._converter,\n#         self._algorithm,\n#         early_stopping_policy=early_stopping_policy,\n#     )\n# \n#   def _get_chief_tuner_id(self) -> str:\n#     metadata = self._study.materialize_problem_statement().metadata.ns(\n#         constants.METADATA_NAMESPACE\n#     )\n#     try:\n#       return str(metadata[constants.STUDY_METADATA_KEY_TUNER_ID])\n#     except KeyError as e:\n#       raise RuntimeError(\n#           f'Metadata does not exist in study: {self._study.resource_name}'\n#       ) from e\n# \n#   def _register_self_as_primary(self) -> str:\n#     metadata = vz.Metadata()\n#     tuner_id = self.tuner.get_tuner_id(self._algorithm)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyglove/backend.py\n# --------------------------------------------------\n#         for trial in vizier_trials:\n#           tuner_trial = core.VizierTrial(self._converter, trial)\n#           reward = tuner_trial.get_reward_for_feedback(\n#               self._converter.metrics_to_optimize\n#           )\n#           yield (tuner_trial.dna, reward)\n# \n#       self._algorithm.recover(get_trial_history(prior_trials))\n# \n#     return TunerPolicy(\n#         self.tuner.pythia_supporter(self._study),\n#         self._converter,\n#         self._algorithm,\n#         early_stopping_policy=early_stopping_policy,\n#     )\n# \n#   def _get_chief_tuner_id(self) -> str:\n#     metadata = self._study.materialize_problem_statement().metadata.ns(\n#         constants.METADATA_NAMESPACE\n#     )\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"TunerPolicy.\"\"\"\n\nfrom typing import Optional, Sequence\n\nfrom absl import logging\nimport attr\nimport pyglove as pg\nfrom vizier import pythia\nfrom vizier import pyvizier as vz\nfrom vizier._src.pyglove import constants\nfrom vizier._src.pyglove import converters\nfrom vizier._src.pyglove import core\n\n\n@attr.define\nclass TunerPolicy(pythia.Policy):\n  \"\"\"Pythia policy for custom multi-trial tuner algorithm.\n\n  Note that study_config should be used if the user needs the Trials to\n  faithfully use the parameter names from the original StudyConfig.\n  \"\"\"\n\n  supporter: pythia.PolicySupporter = attr.field()\n  _converter: converters.VizierConverter = attr.field()\n  _algorithm: pg.geno.DNAGenerator = attr.field()\n  _incorporated_trial_ids: set[int] = attr.field(factory=set)\n  _early_stopping_policy: Optional[pg.tuning.EarlyStoppingPolicy] = attr.field(\n      default=None\n  )\n\n  @property\n  def algorithm(self) -> pg.geno.DNAGenerator:\n    return self._algorithm\n\n  @property\n  def early_stopping_policy(self) -> Optional[pg.tuning.EarlyStoppingPolicy]:\n    return self._early_stopping_policy\n\n  @property\n  def _metric_names(self) -> Sequence[str]:\n    return self._converter.metrics_to_optimize\n\n  def update(self, tuner_trial: pg.tuning.Trial) -> bool:\n    \"\"\"Update a single tuner Trial.\n\n    Args:\n      tuner_trial: If the trial id was previously seen, update is no-op.\n\n    Returns:\n      True if the trial was added.\n    \"\"\"\n    if tuner_trial.id in self._incorporated_trial_ids:\n      return False\n    logging.info(\n        'Updating TunerTrial %s to algorithm: %s', tuner_trial, self._algorithm\n    )\n    reward = tuner_trial.get_reward_for_feedback(self._metric_names)\n    if reward is not None:", "choices": [{"text": "self._algorithm.push(tuner_trial.dna, reward)"}], "metadata": {"task_id": "google_vizier/112", "ground_truth": "      self._algorithm.feedback(tuner_trial.dna, reward)", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "pythia.py"], "context_start_lineno": 0, "line_no": 74, "query_window": {"context": "  @property\n  def _metric_names(self) -> Sequence[str]:\n    return self._converter.metrics_to_optimize\n\n  def update(self, tuner_trial: pg.tuning.Trial) -> bool:\n    \"\"\"Update a single tuner Trial.\n\n    Args:\n      tuner_trial: If the trial id was previously seen, update is no-op.\n\n    Returns:\n      True if the trial was added.\n    \"\"\"\n    if tuner_trial.id in self._incorporated_trial_ids:\n      return False\n    logging.info(\n        'Updating TunerTrial %s to algorithm: %s', tuner_trial, self._algorithm\n    )\n    reward = tuner_trial.get_reward_for_feedback(self._metric_names)\n    if reward is not None:", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "pythia.py"], "line_no": 74, "task_id": "google_vizier/112", "start_line_no": 54, "end_line_no": 74, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "    Args:\n      early_stopping_policy:\n      prior_trials:\n\n    Returns:\n      Policy.\n    \"\"\"\n    if prior_trials:\n\n      def get_trial_history(vizier_trials):\n        for trial in vizier_trials:\n          tuner_trial = core.VizierTrial(self._converter, trial)\n          reward = tuner_trial.get_reward_for_feedback(\n              self._converter.metrics_to_optimize\n          )\n          yield (tuner_trial.dna, reward)\n\n      self._algorithm.recover(get_trial_history(prior_trials))\n\n    return TunerPolicy(", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "backend.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3888888888888889}, {"context": "        for trial in vizier_trials:\n          tuner_trial = core.VizierTrial(self._converter, trial)\n          reward = tuner_trial.get_reward_for_feedback(\n              self._converter.metrics_to_optimize\n          )\n          yield (tuner_trial.dna, reward)\n\n      self._algorithm.recover(get_trial_history(prior_trials))\n\n    return TunerPolicy(\n        self.tuner.pythia_supporter(self._study),\n        self._converter,\n        self._algorithm,\n        early_stopping_policy=early_stopping_policy,\n    )\n\n  def _get_chief_tuner_id(self) -> str:\n    metadata = self._study.materialize_problem_statement().metadata.ns(\n        constants.METADATA_NAMESPACE\n    )", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "backend.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.32653061224489793}, {"context": "    \"\"\"Returns True if this Trial is infeasible.\"\"\"\n    return self._infeasibility_reason is not None\n\n  @property\n  def infeasibility_reason(self) -> Optional[str]:\n    \"\"\"Returns this Trial's infeasibility reason, if set.\"\"\"\n    return self._infeasibility_reason\n\n  def complete(self,\n               measurement: Measurement,\n               *,\n               infeasibility_reason: Optional[str] = None,\n               inplace: bool = True) -> 'Trial':\n    \"\"\"Completes the trial and returns it.\n\n    Args:\n      measurement: Measurement to complete the trial with.\n      infeasibility_reason: If set, completes the trial as infeasible. If the\n        trial was already infeasible and infeasibility_reason is not set, the\n        trial remains infeasible.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 550, "start_line_no": 540, "end_line_no": 560, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3233082706766917}, {"context": "    Args:\n      vizier_trial: Vizier trial (cross-platform).\n      converter: Vizier-Pyglove converter.\n    \"\"\"\n    super().__init__(converter.metrics_to_optimize)\n    self._converter = converter\n    self._trial_client = vizier_trial\n    self._trial = self._trial_client.materialize()\n    self._dna_spec = converter.dna_spec\n    self._discard_reward = 'reward' not in converter.metrics_to_optimize\n\n  @property\n  def id(self) -> int:\n    \"\"\"Gets Trial ID as ID.\"\"\"\n    return self._trial_client.id\n\n  @property\n  def dna(self) -> pg.DNA:\n    \"\"\"Gets DNA of current trial.\"\"\"\n    return self._converter.to_dna(self._trial)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "core.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3157894736842105}, {"context": "    (e.g. only objective and safety metrics).\n\n    Args:\n      proto:\n      include_all_metrics: If True, all metrics in the final measurements are\n        returned. If False, only metrics configured in the StudyConfig are\n        returned.\n\n    Returns:\n      Dict[metric name, metric value]\n    \"\"\"\n    pytrial = proto_converters.TrialConverter.from_proto(proto)\n    return self._pytrial_metrics(\n        pytrial, include_all_metrics=include_all_metrics)\n\n  def _pytrial_metrics(self,\n                       pytrial: vz.Trial,\n                       *,\n                       include_all_metrics=False) -> Dict[str, float]:\n    \"\"\"Returns the trial's final measurement metric values.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3049645390070922}, {"context": "    \"\"\"\n    pytrial = proto_converters.TrialConverter.from_proto(proto)\n    return self._pytrial_metrics(\n        pytrial, include_all_metrics=include_all_metrics)\n\n  def _pytrial_metrics(self,\n                       pytrial: vz.Trial,\n                       *,\n                       include_all_metrics=False) -> Dict[str, float]:\n    \"\"\"Returns the trial's final measurement metric values.\n\n    If the trial is not completed, or infeasible, no metrics are returned.\n    By default, only metrics configured in the StudyConfig are returned\n    (e.g. only objective and safety metrics).\n\n    Args:\n      pytrial:\n      include_all_metrics: If True, all metrics in the final measurements are\n        returned. If False, only metrics configured in the StudyConfig are\n        returned.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.30344827586206896}, {"context": "    \"\"\"Last update time.\"\"\"\n    return self._last_update_time\n\n  @property\n  def is_active(self) -> bool:\n    \"\"\"Returns whether tuner is active.\"\"\"\n    state = self._study.materialize_state()\n    active = state == vz.StudyState.ACTIVE\n    logging.info('is_active was called. state:%s, active:%s', state, active)\n    return active\n\n  @property\n  def metadata(self) -> dict[str, Any]:\n    \"\"\"Gets metadata for current sampling.\"\"\"\n    return self._metadata\n\n  @property\n  def best_trial(self) -> Optional[pg.tuning.Trial]:\n    \"\"\"Returns the best trial.\"\"\"\n    return self._best_trial", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "core.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.29927007299270075}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n# \n#     Metrics codes are cached inside the the dynamic modules cache to allow easy import (avoid ugly sys.path tweaks).\n# \n#     Args:\n# \n#         path (str): Path or name of the metric script.\n# \n#             - if ``path`` is a local metric script or a directory containing a local metric script (if the script has the same name as the directory):\n#               -> load the module from the metric script\n#               e.g. ``'./metrics/accuracy'`` or ``'./metrics/accuracy/accuracy.py'``.\n#             - if ``path`` is a metric on the Hugging Face Hub (ex: `glue`, `squad`)\n#               -> load the module from the metric script in the github repository at huggingface/datasets\n#               e.g. ``'accuracy'`` or ``'rouge'``.\n# \n#         revision (Optional ``Union[str, datasets.Version]``):\n#             If specified, the module will be loaded from the datasets repository at this version.\n#             By default:\n#             - it is set to the local version of the lib.\n#             - it will also try to load it from the master branch if it's not available at the local version of the lib.\n#             Specifying a version that is different from your local version of the lib might cause compatibility issues.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/module.py\n# --------------------------------------------------\n# \n#         ```py\n#         >>> import evaluate\n#         >>> accuracy = evaluate.load(\"accuracy\")\n#         >>> f1 = evaluate.load(\"f1\")\n#         >>> clf_metrics = combine([\"accuracy\", \"f1\"])\n#         >>> clf_metrics.compute(predictions=[0,1], references=[1,1])\n#         {'accuracy': 0.5, 'f1': 0.6666666666666666}\n#         ```\n#         \"\"\"\n#         results = []\n# \n#         for evaluation_module in self.evaluation_modules:\n#             batch = {\"predictions\": predictions, \"references\": references, **kwargs}\n#             batch = {input_name: batch[input_name] for input_name in evaluation_module._feature_names()}\n#             results.append(evaluation_module.compute(**batch))\n# \n#         return self._merge_results(results)\n# \n#     def _merge_results(self, results):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/evaluation_suite/__init__.py\n# --------------------------------------------------\n#         download_config: Optional[DownloadConfig] = None,\n#     ):\n#         download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)\n#         evaluation_module = evaluation_module_factory(\n#             path, module_type=None, revision=revision, download_config=download_config, download_mode=download_mode\n#         )\n#         name = Path(path).stem\n#         evaluation_cls = import_main_class(evaluation_module.module_path)\n#         evaluation_instance = evaluation_cls(name)\n# \n#         return evaluation_instance\n# \n#     def __repr__(self):\n#         self.tasks = [str(task) for task in self.suite]\n#         return f'EvaluationSuite name: \"{self.name}\", ' f\"Tasks: {self.tasks})\"\n# \n#     def assert_suite_nonempty(self):\n#         if not self.suite:\n#             raise ValueError(\n#                 \"No evaluation tasks found. The EvaluationSuite must include at least one SubTask definition.\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/module.py\n# --------------------------------------------------\n#     Args:\n#         evaluations (`Union[list, dict]`):\n#             A list or dictionary of evaluation modules. The modules can either be passed\n#             as strings or loaded `EvaluationModule`s. If a dictionary is passed its keys are the names used and the values the modules.\n#             The names are used as prefix in case there are name overlaps in the returned results of each module or if `force_prefix=True`.\n#         force_prefix (`bool`, *optional*, defaults to `False`):\n#             If `True` all scores from the modules are prefixed with their name. If\n#             a dictionary is passed the keys are used as name otherwise the module's name.\n# \n#     Examples:\n# \n#     ```py\n#     >>> import evaluate\n#     >>> accuracy = evaluate.load(\"accuracy\")\n#     >>> f1 = evaluate.load(\"f1\")\n#     >>> clf_metrics = combine([\"accuracy\", \"f1\"])\n#     ```\n#     \"\"\"\n# \n#     return CombinedEvaluations(evaluations, force_prefix=force_prefix)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/evaluator/base.py\n# --------------------------------------------------\n# \n#         Example:\n# \n#         ```py\n#         >>> from evaluate import evaluator\n#         >>> evaluator(\"text-classification\").prepare_metric(\"accuracy\")\n#         ```\n#         \"\"\"\n#         # Prepare metric.\n#         if metric is None:\n#             if self.default_metric_name is None:\n#                 raise ValueError(\n#                     \"`Evaluator` doesn't specify a default metric. Please specify a valid `metric` argument.\"\n#                 )\n#             metric = load(self.default_metric_name)\n#         elif isinstance(metric, str):\n#             metric = load(metric)\n# \n#         return metric\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n#             - if ``path`` is a metric on the Hugging Face Hub (ex: `glue`, `squad`)\n#               -> load the module from the metric script in the github repository at huggingface/datasets\n#               e.g. ``'accuracy'`` or ``'rouge'``.\n# \n#         revision (Optional ``Union[str, datasets.Version]``):\n#             If specified, the module will be loaded from the datasets repository at this version.\n#             By default:\n#             - it is set to the local version of the lib.\n#             - it will also try to load it from the master branch if it's not available at the local version of the lib.\n#             Specifying a version that is different from your local version of the lib might cause compatibility issues.\n#         download_config (:class:`DownloadConfig`, optional): Specific download configuration parameters.\n#         download_mode (:class:`DownloadMode`, default ``REUSE_DATASET_IF_EXISTS``): Download/generate mode.\n#         force_local_path (Optional str): Optional path to a local path to download and prepare the script to.\n#             Used to inspect or modify the script folder.\n#         dynamic_modules_path (Optional str, defaults to HF_MODULES_CACHE / \"datasets_modules\", i.e. ~/.cache/huggingface/modules/datasets_modules):\n#             Optional path to the directory in which the dynamic modules are saved. It must have been initialized with :obj:`init_dynamic_modules`.\n#             By default the datasets and metrics are stored inside the `datasets_modules` module.\n#         download_kwargs: optional attributes for DownloadConfig() which will override the attributes in download_config if supplied.\n# \n#     Returns:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\", i.e. ~/.cache/huggingface/modules/datasets_modules):\n            Optional path to the directory in which the dynamic modules are saved. It must have been initialized with :obj:`init_dynamic_modules`.\n            By default the datasets and metrics are stored inside the `datasets_modules` module.\n        download_kwargs: optional attributes for DownloadConfig() which will override the attributes in download_config if supplied.\n\n    Returns:\n        ImportableModule\n    \"\"\"\n    if download_config is None:\n        download_config = DownloadConfig(**download_kwargs)\n    download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)\n    download_config.extract_compressed_file = True\n    download_config.force_extract = True\n\n    filename = list(filter(lambda x: x, path.replace(os.sep, \"/\").split(\"/\")))[-1]\n    if not filename.endswith(\".py\"):\n        filename = filename + \".py\"\n    combined_path = os.path.join(path, filename)\n    # Try locally\n    if path.endswith(filename):\n        if os.path.isfile(path):\n            return LocalEvaluationModuleFactory(\n                path, download_mode=download_mode, dynamic_modules_path=dynamic_modules_path\n            ).get_module()\n        else:\n            raise FileNotFoundError(f\"Couldn't find a metric script at {relative_to_absolute_path(path)}\")\n    elif os.path.isfile(combined_path):\n        return LocalEvaluationModuleFactory(\n            combined_path, download_mode=download_mode, dynamic_modules_path=dynamic_modules_path\n        ).get_module()\n    elif is_relative_path(path) and path.count(\"/\") <= 1 and not force_local_path:\n        try:\n            # load a canonical evaluation module from hub\n            if path.count(\"/\") == 0:\n                # if no type provided look through all possible modules\n                if module_type is None:\n                    for current_type in [\"metric\", \"comparison\", \"measurement\"]:\n                        try:\n                            return HubEvaluationModuleFactory(\n                                f\"evaluate-{current_type}/{path}\",\n                                revision=revision,\n                                download_config=download_config,\n                                download_mode=download_mode,\n                                dynamic_modules_path=dynamic_modules_path,\n                            ).get_module()\n                        except ConnectionError:\n                            pass\n                    raise FileNotFoundError\n                # if module_type provided load specific module_type\n                else:\n                    return HubEvaluationModuleFactory(\n                        f\"evaluate-{module_type}/{path}\",\n                        revision=revision,\n                        download_config=download_config,\n                        download_mode=download_mode,\n                        dynamic_modules_path=dynamic_modules_path,\n                    ).get_module()\n            # load community evaluation module from hub\n            elif path.count(\"/\") == 1:\n                return HubEvaluationModuleFactory(\n                    path,\n                    revision=revision,\n                    download_config=download_config,\n                    download_mode=download_mode,\n                    dynamic_modules_path=dynamic_modules_path,\n                ).get_module()\n        except Exception as e1:  # noqa: all the attempts failed, before raising the error we should check if the module is already cached.\n            # if it's a canonical module we need to check if it's any of the types\n            if path.count(\"/\") == 0:\n                for current_type in [\"metric\", \"comparison\", \"measurement\"]:\n                    try:\n                        return CachedEvaluationModuleFactory(\n                            f\"evaluate-{current_type}--{path}\", dynamic_modules_path=dynamic_modules_path\n                        ).get_module()\n                    except Exception as e2:  # noqa: if it's not in the cache, then it doesn't exist.\n                        pass\n            # if it's a community module we just need to check on path\n            elif path.count(\"/\") == 1:\n                try:\n                    return CachedEvaluationModuleFactory(\n                        path.replace(\"/\", \"--\"), dynamic_modules_path=dynamic_modules_path\n                    ).get_module()\n                except Exception as e2:  # noqa: if it's not in the cache, then it doesn't exist.\n                    pass\n            if not isinstance(e1, (ConnectionError, FileNotFoundError)):\n                raise e1 from None\n            raise FileNotFoundError(\n                f\"Couldn't find a module script at {relative_to_absolute_path(combined_path)}. \"\n                f\"Module '{path}' doesn't exist on the Hugging Face Hub either.\"\n            ) from None\n    else:\n        raise FileNotFoundError(f\"Couldn't find a module script at {relative_to_absolute_path(combined_path)}.\")\n\n\ndef load(\n    path: str,\n    config_name: Optional[str] = None,\n    module_type: Optional[str] = None,\n    process_id: int = 0,\n    num_process: int = 1,\n    cache_dir: Optional[str] = None,\n    experiment_id: Optional[str] = None,\n    keep_in_memory: bool = False,\n    download_config: Optional[DownloadConfig] = None,\n    download_mode: Optional[DownloadMode] = None,\n    revision: Optional[Union[str, Version]] = None,\n    **init_kwargs,\n) -> EvaluationModule:\n    \"\"\"Load a [`~evaluate.EvaluationModule`].\n\n    Args:\n\n        path (`str`):\n            Path to the evaluation processing script with the evaluation builder. Can be either:\n                - a local path to processing script or the directory containing the script (if the script has the same name as the directory),\n                    e.g. `'./metrics/rouge'` or `'./metrics/rouge/rouge.py'`\n                - a evaluation module identifier on the HuggingFace evaluate repo e.g. `'rouge'` or `'bleu'` that are in either `'metrics/'`,\n                    `'comparisons/'`, or `'measurements/'` depending on the provided `module_type`\n        config_name (`str`, *optional*):\n            Selecting a configuration for the metric (e.g. the GLUE metric has a configuration for each subset).\n        module_type (`str`, default `'metric'`):\n            Type of evaluation module, can be one of `'metric'`, `'comparison'`, or `'measurement'`.\n        process_id (`int`, *optional*):\n            For distributed evaluation: id of the process.\n        num_process (`int`, *optional*):\n            For distributed evaluation: total number of processes.\n        cache_dir (`str`, *optional*):\n            Path to store the temporary predictions and references (default to `~/.cache/huggingface/evaluate/`).\n        experiment_id (`str`):\n            A specific experiment id. This is used if several distributed evaluations share the same file system.\n            This is useful to compute metrics in distributed setups (in particular non-additive metrics like F1).\n        keep_in_memory (`bool`):\n            Whether to store the temporary results in memory (defaults to `False`).\n        download_config ([`~evaluate.DownloadConfig`], *optional*):\n            Specific download configuration parameters.\n        download_mode ([`DownloadMode`], defaults to `REUSE_DATASET_IF_EXISTS`):\n            Download/generate mode.\n        revision (`Union[str, evaluate.Version]`, *optional*):\n            If specified, the module will be loaded from the datasets repository\n            at this version. By default it is set to the local version of the lib. Specifying a version that is different from\n            your local version of the lib might cause compatibility issues.\n\n    Returns:\n        [`evaluate.EvaluationModule`]\n\n    Example:\n\n        ```py\n        >>> from evaluate import load\n        >>> accuracy = evaluate.load(\"accuracy\")\n        ```\n    \"\"\"\n    download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)", "choices": [{"text": ""}], "metadata": {"task_id": "huggingface_evaluate/142", "ground_truth": "    evaluation_module = evaluation_module_factory(", "fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "context_start_lineno": 594, "line_no": 747, "query_window": {"context": "        download_config ([`~evaluate.DownloadConfig`], *optional*):\n            Specific download configuration parameters.\n        download_mode ([`DownloadMode`], defaults to `REUSE_DATASET_IF_EXISTS`):\n            Download/generate mode.\n        revision (`Union[str, evaluate.Version]`, *optional*):\n            If specified, the module will be loaded from the datasets repository\n            at this version. By default it is set to the local version of the lib. Specifying a version that is different from\n            your local version of the lib might cause compatibility issues.\n\n    Returns:\n        [`evaluate.EvaluationModule`]\n\n    Example:\n\n        ```py\n        >>> from evaluate import load\n        >>> accuracy = evaluate.load(\"accuracy\")\n        ```\n    \"\"\"\n    download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)", "metadata": {"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 747, "task_id": "huggingface_evaluate/142", "start_line_no": 727, "end_line_no": 747, "window_size": 20, "context_start_lineno": 594, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "\n    Metrics codes are cached inside the the dynamic modules cache to allow easy import (avoid ugly sys.path tweaks).\n\n    Args:\n\n        path (str): Path or name of the metric script.\n\n            - if ``path`` is a local metric script or a directory containing a local metric script (if the script has the same name as the directory):\n              -> load the module from the metric script\n              e.g. ``'./metrics/accuracy'`` or ``'./metrics/accuracy/accuracy.py'``.\n            - if ``path`` is a metric on the Hugging Face Hub (ex: `glue`, `squad`)\n              -> load the module from the metric script in the github repository at huggingface/datasets\n              e.g. ``'accuracy'`` or ``'rouge'``.\n\n        revision (Optional ``Union[str, datasets.Version]``):\n            If specified, the module will be loaded from the datasets repository at this version.\n            By default:\n            - it is set to the local version of the lib.\n            - it will also try to load it from the master branch if it's not available at the local version of the lib.\n            Specifying a version that is different from your local version of the lib might cause compatibility issues.", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 580, "start_line_no": 570, "end_line_no": 590, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3409090909090909}, {"context": "        \"\"\"\n        Prepare metric.\n\n        Args:\n            metric (`str` or [`EvaluationModule`], defaults to `None`):\n                Specifies the metric we use in evaluator. If it is of type `str`, we treat it as the metric name, and\n                load it. Otherwise we assume it represents a pre-loaded metric.\n\n        Returns:\n            The loaded metric.\n\n        Example:\n\n        ```py\n        >>> from evaluate import evaluator\n        >>> evaluator(\"text-classification\").prepare_metric(\"accuracy\")\n        ```\n        \"\"\"\n        # Prepare metric.\n        if metric is None:", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluator", "base.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3103448275862069}, {"context": "\n    Args:\n        evaluations (`Union[list, dict]`):\n            A list or dictionary of evaluation modules. The modules can either be passed\n            as strings or loaded `EvaluationModule`s. If a dictionary is passed its keys are the names used and the values the modules.\n            The names are used as prefix in case there are name overlaps in the returned results of each module or if `force_prefix=True`.\n        force_prefix (`bool`, *optional*, defaults to `False`):\n            If `True` all scores from the modules are prefixed with their name. If\n            a dictionary is passed the keys are used as name otherwise the module's name.\n\n    Examples:\n\n    ```py\n    >>> import evaluate\n    >>> accuracy = evaluate.load(\"accuracy\")\n    >>> f1 = evaluate.load(\"f1\")\n    >>> clf_metrics = combine([\"accuracy\", \"f1\"])\n    ```\n    \"\"\"\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "line_no": 1020, "start_line_no": 1010, "end_line_no": 1030, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.28901734104046245}, {"context": "    \"\"\"\n\n    def __init__(self, name):\n        self.name = name\n\n    @staticmethod\n    def load(\n        path: str,\n        download_mode: Optional[DownloadMode] = None,\n        revision: Optional[Union[str, Version]] = None,\n        download_config: Optional[DownloadConfig] = None,\n    ):\n        download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)\n        evaluation_module = evaluation_module_factory(\n            path, module_type=None, revision=revision, download_config=download_config, download_mode=download_mode\n        )\n        name = Path(path).stem\n        evaluation_cls = import_main_class(evaluation_module.module_path)\n        evaluation_instance = evaluation_cls(name)\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluation_suite", "__init__.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2857142857142857}, {"context": "                Keyword arguments that will be forwarded to the evaluation module [`~evaluate.EvaluationModule.compute`]\n                method (see details in the docstring).\n\n        Return:\n            `dict` or `None`\n\n            - Dictionary with the results if this evaluation module is run on the main process (`process_id == 0`).\n            - `None` if the evaluation module is not run on the main process (`process_id != 0`).\n\n        Example:\n\n        ```py\n        >>> import evaluate\n        >>> accuracy = evaluate.load(\"accuracy\")\n        >>> f1 = evaluate.load(\"f1\")\n        >>> clf_metrics = combine([\"accuracy\", \"f1\"])\n        >>> clf_metrics.compute(predictions=[0,1], references=[1,1])\n        {'accuracy': 0.5, 'f1': 0.6666666666666666}\n        ```\n        \"\"\"", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "line_no": 960, "start_line_no": 950, "end_line_no": 970, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2710843373493976}, {"context": "    module_type: Optional[str] = None,\n    revision: Optional[Union[str, Version]] = None,\n    download_config: Optional[DownloadConfig] = None,\n    download_mode: Optional[DownloadMode] = None,\n    force_local_path: Optional[str] = None,\n    dynamic_modules_path: Optional[str] = None,\n    **download_kwargs,\n) -> ImportableModule:\n    \"\"\"\n    Download/extract/cache a metric module.\n\n    Metrics codes are cached inside the the dynamic modules cache to allow easy import (avoid ugly sys.path tweaks).\n\n    Args:\n\n        path (str): Path or name of the metric script.\n\n            - if ``path`` is a local metric script or a directory containing a local metric script (if the script has the same name as the directory):\n              -> load the module from the metric script\n              e.g. ``'./metrics/accuracy'`` or ``'./metrics/accuracy/accuracy.py'``.", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 570, "start_line_no": 560, "end_line_no": 580, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.26666666666666666}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n# \n#     def test_betas(self):\n#         for beta_start, beta_end in zip([0.0001, 0.001, 0.01, 0.1], [0.002, 0.02, 0.2, 2]):\n#             self.check_over_configs(beta_start=beta_start, beta_end=beta_end)\n# \n#     def test_schedules(self):\n#         for schedule in [\"linear\", \"squaredcos_cap_v2\"]:\n#             self.check_over_configs(beta_schedule=schedule)\n# \n#     def test_prediction_type(self):\n#         for prediction_type in [\"epsilon\", \"v_prediction\"]:\n#             self.check_over_configs(prediction_type=prediction_type)\n# \n#     def test_clip_sample(self):\n#         for clip_sample in [True, False]:\n#             self.check_over_configs(clip_sample=clip_sample)\n# \n#     def test_time_indices(self):\n#         for t in [1, 10, 49]:\n#             self.check_over_forward(time_step=t)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n# \n#     def test_schedules(self):\n#         for schedule in [\"linear\", \"squaredcos_cap_v2\"]:\n#             self.check_over_configs(beta_schedule=schedule)\n# \n#     def test_variance_type(self):\n#         for variance in [\"fixed_small\", \"fixed_large\", \"other\"]:\n#             self.check_over_configs(variance_type=variance)\n# \n#     def test_clip_sample(self):\n#         for clip_sample in [True, False]:\n#             self.check_over_configs(clip_sample=clip_sample)\n# \n#     def test_prediction_type(self):\n#         for prediction_type in [\"epsilon\", \"sample\", \"v_prediction\"]:\n#             self.check_over_configs(prediction_type=prediction_type)\n# \n#     def test_time_indices(self):\n#         for t in [0, 500, 999]:\n#             self.check_over_forward(time_step=t)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n# \n#     def test_variance(self):\n#         scheduler_class = self.scheduler_classes[0]\n#         scheduler_config = self.get_scheduler_config()\n#         scheduler = scheduler_class(**scheduler_config)\n# \n#         assert torch.sum(torch.abs(scheduler._get_variance(0) - 0.0)) < 1e-5\n#         assert torch.sum(torch.abs(scheduler._get_variance(487) - 0.00979)) < 1e-5\n#         assert torch.sum(torch.abs(scheduler._get_variance(999) - 0.02)) < 1e-5\n# \n#     def test_full_loop_no_noise(self):\n#         scheduler_class = self.scheduler_classes[0]\n#         scheduler_config = self.get_scheduler_config()\n#         scheduler = scheduler_class(**scheduler_config)\n# \n#         num_trained_timesteps = len(scheduler)\n# \n#         model = self.dummy_model()\n#         sample = self.dummy_sample_deter\n#         generator = torch.manual_seed(0)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n#         for prediction_type in [\"epsilon\", \"v_prediction\"]:\n#             self.check_over_configs(prediction_type=prediction_type)\n# \n#     def test_clip_sample(self):\n#         for clip_sample in [True, False]:\n#             self.check_over_configs(clip_sample=clip_sample)\n# \n#     def test_time_indices(self):\n#         for t in [1, 10, 49]:\n#             self.check_over_forward(time_step=t)\n# \n#     def test_inference_steps(self):\n#         for t, num_inference_steps in zip([1, 10, 50], [10, 50, 500]):\n#             self.check_over_forward(time_step=t, num_inference_steps=num_inference_steps)\n# \n#     def test_eta(self):\n#         for t, eta in zip([1, 10, 49], [0.0, 0.5, 1.0]):\n#             self.check_over_forward(time_step=t, eta=eta)\n# \n#     def test_variance(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n#         for t in [0, 500, 800]:\n#             self.check_over_forward(time_step=t)\n# \n#     def test_full_loop_no_noise(self):\n#         scheduler_class = self.scheduler_classes[0]\n#         scheduler_config = self.get_scheduler_config()\n#         scheduler = scheduler_class(**scheduler_config)\n# \n#         scheduler.set_timesteps(self.num_inference_steps)\n# \n#         model = self.dummy_model()\n#         sample = self.dummy_sample_deter * scheduler.init_noise_sigma\n# \n#         for i, t in enumerate(scheduler.timesteps):\n#             sample = scheduler.scale_model_input(sample, t)\n# \n#             model_output = model(sample, t)\n# \n#             output = scheduler.step(model_output, t, sample)\n#             sample = output.prev_sample\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n#         for clip_sample in [True, False]:\n#             self.check_over_configs(clip_sample=clip_sample)\n# \n#     def test_prediction_type(self):\n#         for prediction_type in [\"epsilon\", \"sample\", \"v_prediction\"]:\n#             self.check_over_configs(prediction_type=prediction_type)\n# \n#     def test_time_indices(self):\n#         for t in [0, 500, 999]:\n#             self.check_over_forward(time_step=t)\n# \n#     def test_variance(self):\n#         scheduler_class = self.scheduler_classes[0]\n#         scheduler_config = self.get_scheduler_config()\n#         scheduler = scheduler_class(**scheduler_config)\n# \n#         assert torch.sum(torch.abs(scheduler._get_variance(0) - 0.0)) < 1e-5\n#         assert torch.sum(torch.abs(scheduler._get_variance(487) - 0.00979)) < 1e-5\n#         assert torch.sum(torch.abs(scheduler._get_variance(999) - 0.02)) < 1e-5\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n_shape(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()\n\n            sample, key = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                state = scheduler.set_timesteps(state, num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output_0 = scheduler.step(state, residual, 0, sample, key, **kwargs).prev_sample\n            output_1 = scheduler.step(state, residual, 1, sample, key, **kwargs).prev_sample\n\n            self.assertEqual(output_0.shape, sample.shape)\n            self.assertEqual(output_0.shape, output_1.shape)\n\n    def test_scheduler_outputs_equivalence(self):\n        def set_nan_tensor_to_zero(t):\n            return t.at[t != t].set(0)\n\n        def recursive_check(tuple_object, dict_object):\n            if isinstance(tuple_object, (List, Tuple)):\n                for tuple_iterable_value, dict_iterable_value in zip(tuple_object, dict_object.values()):\n                    recursive_check(tuple_iterable_value, dict_iterable_value)\n            elif isinstance(tuple_object, Dict):\n                for tuple_iterable_value, dict_iterable_value in zip(tuple_object.values(), dict_object.values()):\n                    recursive_check(tuple_iterable_value, dict_iterable_value)\n            elif tuple_object is None:\n                return\n            else:\n                self.assertTrue(\n                    jnp.allclose(set_nan_tensor_to_zero(tuple_object), set_nan_tensor_to_zero(dict_object), atol=1e-5),\n                    msg=(\n                        \"Tuple and dict output are not equal. Difference:\"\n                        f\" {jnp.max(jnp.abs(tuple_object - dict_object))}. Tuple has `nan`:\"\n                        f\" {jnp.isnan(tuple_object).any()} and `inf`: {jnp.isinf(tuple_object)}. Dict has\"\n                        f\" `nan`: {jnp.isnan(dict_object).any()} and `inf`: {jnp.isinf(dict_object)}.\"\n                    ),\n                )\n\n        kwargs = dict(self.forward_default_kwargs)\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()\n\n            sample, key = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                state = scheduler.set_timesteps(state, num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            outputs_dict = scheduler.step(state, residual, 0, sample, key, **kwargs)\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                state = scheduler.set_timesteps(state, num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            outputs_tuple = scheduler.step(state, residual, 0, sample, key, return_dict=False, **kwargs)\n\n            recursive_check(outputs_tuple[0], outputs_dict.prev_sample)\n\n    def test_deprecated_kwargs(self):\n        for scheduler_class in self.scheduler_classes:\n            has_kwarg_in_model_class = \"kwargs\" in inspect.signature(scheduler_class.__init__).parameters\n            has_deprecated_kwarg = len(scheduler_class._deprecated_kwargs) > 0\n\n            if has_kwarg_in_model_class and not has_deprecated_kwarg:\n                raise ValueError(\n                    f\"{scheduler_class} has `**kwargs` in its __init__ method but has not defined any deprecated\"\n                    \" kwargs under the `_deprecated_kwargs` class attribute. Make sure to either remove `**kwargs` if\"\n                    \" there are no deprecated arguments or add the deprecated argument with `_deprecated_kwargs =\"\n                    \" [<deprecated_argument>]`\"\n                )\n\n            if not has_kwarg_in_model_class and has_deprecated_kwarg:\n                raise ValueError(\n                    f\"{scheduler_class} doesn't have `**kwargs` in its __init__ method but has defined deprecated\"\n                    \" kwargs under the `_deprecated_kwargs` class attribute. Make sure to either add the `**kwargs`\"\n                    f\" argument to {self.model_class}.__init__ if there are deprecated arguments or remove the\"\n                    \" deprecated argument from `_deprecated_kwargs = [<deprecated_argument>]`\"\n                )\n\n\n@require_flax\nclass FlaxDDPMSchedulerTest(FlaxSchedulerCommonTest):\n    scheduler_classes = (FlaxDDPMScheduler,)\n\n    def get_scheduler_config(self, **kwargs):\n        config = {\n            \"num_train_timesteps\": 1000,\n            \"beta_start\": 0.0001,\n            \"beta_end\": 0.02,\n            \"beta_schedule\": \"linear\",\n            \"variance_type\": \"fixed_small\",\n            \"clip_sample\": True,\n        }\n\n        config.update(**kwargs)\n        return config\n\n    def test_timesteps(self):\n        for timesteps in [1, 5, 100, 1000]:\n            self.check_over_configs(num_train_timesteps=timesteps)\n\n    def test_betas(self):\n        for beta_start, beta_end in zip([0.0001, 0.001, 0.01, 0.1], [0.002, 0.02, 0.2, 2]):\n            self.check_over_configs(beta_start=beta_start, beta_end=beta_end)\n\n    def test_schedules(self):\n        for schedule in [\"linear\", \"squaredcos_cap_v2\"]:\n            self.check_over_configs(beta_schedule=schedule)\n\n    def test_variance_type(self):\n        for variance in [\"fixed_small\", \"fixed_large\", \"other\"]:\n            self.check_over_configs(variance_type=variance)\n\n    def test_clip_sample(self):\n        for clip_sample in [True, False]:\n            self.check_over_configs(clip_sample=clip_sample)\n\n    def test_time_indices(self):\n        for t in [0, 500, 999]:\n            self.check_over_forward(time_step=t)\n\n    def test_variance(self):\n        scheduler_class = self.scheduler_classes[0]\n        scheduler_config = self.get_scheduler_config()", "choices": [{"text": "scheduler = scheduler_class(**scheduler_config)"}], "metadata": {"task_id": "huggingface_diffusers/158", "ground_truth": "        scheduler = scheduler_class(**scheduler_config)", "fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "context_start_lineno": 156, "line_no": 297, "query_window": {"context": "\n    def test_schedules(self):\n        for schedule in [\"linear\", \"squaredcos_cap_v2\"]:\n            self.check_over_configs(beta_schedule=schedule)\n\n    def test_variance_type(self):\n        for variance in [\"fixed_small\", \"fixed_large\", \"other\"]:\n            self.check_over_configs(variance_type=variance)\n\n    def test_clip_sample(self):\n        for clip_sample in [True, False]:\n            self.check_over_configs(clip_sample=clip_sample)\n\n    def test_time_indices(self):\n        for t in [0, 500, 999]:\n            self.check_over_forward(time_step=t)\n\n    def test_variance(self):\n        scheduler_class = self.scheduler_classes[0]\n        scheduler_config = self.get_scheduler_config()", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "line_no": 297, "task_id": "huggingface_diffusers/158", "start_line_no": 277, "end_line_no": 297, "window_size": 20, "context_start_lineno": 156, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "\n    def test_schedules(self):\n        for schedule in [\"linear\", \"squaredcos_cap_v2\"]:\n            self.check_over_configs(beta_schedule=schedule)\n\n    def test_variance_type(self):\n        for variance in [\"fixed_small\", \"fixed_large\", \"other\"]:\n            self.check_over_configs(variance_type=variance)\n\n    def test_clip_sample(self):\n        for clip_sample in [True, False]:\n            self.check_over_configs(clip_sample=clip_sample)\n\n    def test_prediction_type(self):\n        for prediction_type in [\"epsilon\", \"sample\", \"v_prediction\"]:\n            self.check_over_configs(prediction_type=prediction_type)\n\n    def test_time_indices(self):\n        for t in [0, 500, 999]:\n            self.check_over_forward(time_step=t)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.8125}, {"context": "\n    def test_schedules(self):\n        for schedule in [\"linear\", \"scaled_linear\"]:\n            self.check_over_configs(beta_schedule=schedule)\n\n    def test_prediction_type(self):\n        for prediction_type in [\"epsilon\", \"v_prediction\"]:\n            self.check_over_configs(prediction_type=prediction_type)\n\n    def test_time_indices(self):\n        for t in [0, 500, 800]:\n            self.check_over_forward(time_step=t)\n\n    def test_full_loop_no_noise(self):\n        scheduler_class = self.scheduler_classes[0]\n        scheduler_config = self.get_scheduler_config()\n        scheduler = scheduler_class(**scheduler_config)\n\n        scheduler.set_timesteps(self.num_inference_steps)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 1680, "start_line_no": 1670, "end_line_no": 1690, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5894736842105263}, {"context": "\n    def test_betas(self):\n        for beta_start, beta_end in zip([0.0001, 0.001, 0.01, 0.1], [0.002, 0.02, 0.2, 2]):\n            self.check_over_configs(beta_start=beta_start, beta_end=beta_end)\n\n    def test_schedules(self):\n        for schedule in [\"linear\", \"squaredcos_cap_v2\"]:\n            self.check_over_configs(beta_schedule=schedule)\n\n    def test_prediction_type(self):\n        for prediction_type in [\"epsilon\", \"v_prediction\"]:\n            self.check_over_configs(prediction_type=prediction_type)\n\n    def test_clip_sample(self):\n        for clip_sample in [True, False]:\n            self.check_over_configs(clip_sample=clip_sample)\n\n    def test_time_indices(self):\n        for t in [1, 10, 49]:\n            self.check_over_forward(time_step=t)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 780, "start_line_no": 770, "end_line_no": 790, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5816326530612245}, {"context": "        for clip_sample in [True, False]:\n            self.check_over_configs(clip_sample=clip_sample)\n\n    def test_prediction_type(self):\n        for prediction_type in [\"epsilon\", \"sample\", \"v_prediction\"]:\n            self.check_over_configs(prediction_type=prediction_type)\n\n    def test_time_indices(self):\n        for t in [0, 500, 999]:\n            self.check_over_forward(time_step=t)\n\n    def test_variance(self):\n        scheduler_class = self.scheduler_classes[0]\n        scheduler_config = self.get_scheduler_config()\n        scheduler = scheduler_class(**scheduler_config)\n\n        assert torch.sum(torch.abs(scheduler._get_variance(0) - 0.0)) < 1e-5\n        assert torch.sum(torch.abs(scheduler._get_variance(487) - 0.00979)) < 1e-5\n        assert torch.sum(torch.abs(scheduler._get_variance(999) - 0.02)) < 1e-5\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 650, "start_line_no": 640, "end_line_no": 660, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5742574257425742}, {"context": "        config.update(**kwargs)\n        return config\n\n    def test_timesteps(self):\n        for timesteps in [1, 5, 100, 1000]:\n            self.check_over_configs(num_train_timesteps=timesteps)\n\n    def test_betas(self):\n        for beta_start, beta_end in zip([0.0001, 0.001, 0.01, 0.1], [0.002, 0.02, 0.2, 2]):\n            self.check_over_configs(beta_start=beta_start, beta_end=beta_end)\n\n    def test_schedules(self):\n        for schedule in [\"linear\", \"squaredcos_cap_v2\"]:\n            self.check_over_configs(beta_schedule=schedule)\n\n    def test_variance_type(self):\n        for variance in [\"fixed_small\", \"fixed_large\", \"other\"]:\n            self.check_over_configs(variance_type=variance)\n\n    def test_clip_sample(self):", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 630, "start_line_no": 620, "end_line_no": 640, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5142857142857142}, {"context": "\n    def test_steps_offset(self):\n        for steps_offset in [0, 1]:\n            self.check_over_configs(steps_offset=steps_offset)\n\n        scheduler_class = self.scheduler_classes[0]\n        scheduler_config = self.get_scheduler_config(steps_offset=1)\n        scheduler = scheduler_class(**scheduler_config)\n        scheduler.set_timesteps(5)\n        assert torch.equal(scheduler.timesteps, torch.LongTensor([801, 601, 401, 201, 1]))\n\n    def test_betas(self):\n        for beta_start, beta_end in zip([0.0001, 0.001, 0.01, 0.1], [0.002, 0.02, 0.2, 2]):\n            self.check_over_configs(beta_start=beta_start, beta_end=beta_end)\n\n    def test_schedules(self):\n        for schedule in [\"linear\", \"squaredcos_cap_v2\"]:\n            self.check_over_configs(beta_schedule=schedule)\n\n    def test_prediction_type(self):", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 770, "start_line_no": 760, "end_line_no": 780, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.46017699115044247}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/calib_model_calibrator.py\n# --------------------------------------------------\n#         ] = None,\n#         verbose: bool = True,\n#     ) -> Tuple[CalibState, Status]:\n#         training_losses_and_metrics = collections.defaultdict(list)\n#         val_losses_and_metrics = collections.defaultdict(list)\n# \n#         state, targets, outputs, rng = self.on_train_start(\n#             state,\n#             [self._calib_targets, self._val_targets],\n#             [self._calib_outputs, self._val_outputs],\n#             rng,\n#         )\n#         calib_targets, val_targets = targets\n#         calib_outputs, val_outputs = outputs\n# \n#         progress_bar = trange(n_epochs, desc=\"Epoch\")\n#         for epoch in progress_bar:\n#             # training loop\n#             (\n#                 state,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#     def _training_loop(\n#         self,\n#         current_epoch: int,\n#         fun: Callable,\n#         metrics: Optional[\n#             Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n#         ],\n#         rng: PRNGKeyArray,\n#         state: CalibState,\n#         training_data_loader: DataLoader,\n#         calib_outputs_loader: TargetsLoader,\n#         training_dataset_size: int,\n#         verbose: bool,\n#         progress_bar: TqdmDecorator,\n#     ) -> Tuple[CalibState, Dict[str, float], str]:\n#         training_losses_and_metrics_epoch_all_steps = []\n#         training_batch_metrics_str = \"\"\n#         for step, (batch, outputs) in enumerate(\n#             zip(training_data_loader, calib_outputs_loader)\n#         ):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/calib_model_calibrator.py\n# --------------------------------------------------\n#         fun: Callable,\n#         metrics: Optional[\n#             Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n#         ],\n#         rng: PRNGKeyArray,\n#         state: CalibState,\n#         targets: Array,\n#         outputs: Array,\n#         verbose: bool,\n#         progress_bar: TqdmDecorator,\n#     ) -> Tuple[CalibState, Dict[str, float], str]:\n#         training_losses_and_metrics_epoch_all_steps = []\n#         training_batch_metrics_str = \"\"\n#         # forward and backward pass\n#         state, aux = self.training_step(state, targets, outputs, fun, rng)\n#         # compute training losses and metrics for the current batch\n#         training_losses_and_metrics_current_batch = self.training_step_end(\n#             current_epoch=current_epoch,\n#             state=state,\n#             aux=aux,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/calib_model_calibrator.py\n# --------------------------------------------------\n#         self,\n#         fun: Callable,\n#         metrics: Optional[\n#             Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n#         ],\n#         rng: PRNGKeyArray,\n#         state: CalibState,\n#         targets: Array,\n#         outputs: Array,\n#         verbose: bool = True,\n#     ) -> Tuple[Dict[str, float], str]:\n#         val_losses_and_metrics_epoch_all_steps = []\n#         val_epoch_metrics_str = \"\"\n#         val_losses_and_metrics_current_batch = self.val_step(\n#             state, targets, outputs, fun, rng, metrics,\n#         )\n#         val_losses_and_metrics_epoch_all_steps.append(\n#             val_losses_and_metrics_current_batch\n#         )\n#         # compute validation losses and metrics for the current epoch\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/calib_model_calibrator.py\n# --------------------------------------------------\n#         val_losses_and_metrics_current_epoch = self.val_epoch_end(\n#             val_losses_and_metrics_epoch_all_steps, state\n#         )\n#         # logging\n#         if verbose:\n#             val_epoch_metrics_str = \" | \".join(\n#                 [\n#                     f\"{m}: {round(float(v), 5)}\"\n#                     for m, v in val_losses_and_metrics_current_epoch.items()\n#                 ]\n#             )\n#         return val_losses_and_metrics_current_epoch, val_epoch_metrics_str\n# \n#     def val_step(\n#         self,\n#         state: CalibState,\n#         targets: Array,\n#         outputs: Array,\n#         fun: Callable,\n#         rng: PRNGKeyArray,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/calib_model_calibrator.py\n# --------------------------------------------------\n#         metrics: Optional[\n#             Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n#         ] = None,\n#     ) -> Dict[str, jnp.ndarray]:\n#         val_loss, aux = self.val_loss_step(state, targets, outputs, fun, rng)\n#         val_metrics = self.val_metrics_step(aux, targets, metrics)\n#         return {\"val_loss\": val_loss, **val_metrics}\n# \n#     def val_loss_step(\n#         self,\n#         state: CalibState,\n#         targets: Array,\n#         outputs: Array,\n#         fun: Callable,\n#         rng: PRNGKeyArray,\n#     ) -> Tuple[jnp.ndarray, Dict[str, jnp.ndarray]]:\n#         log_joint_probs, aux = fun(\n#             params=state.params,\n#             targets=targets,\n#             outputs=outputs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/calib_model_calibrator.py\n# --------------------------------------------------\n#             )\n#         return val_losses_and_metrics_current_epoch, val_epoch_metrics_str\n# \n#     def val_step(\n#         self,\n#         state: CalibState,\n#         targets: Array,\n#         outputs: Array,\n#         fun: Callable,\n#         rng: PRNGKeyArray,\n#         metrics: Optional[\n#             Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n#         ] = None,\n#     ) -> Dict[str, jnp.ndarray]:\n#         val_loss, aux = self.val_loss_step(state, targets, outputs, fun, rng)\n#         val_metrics = self.val_metrics_step(aux, targets, metrics)\n#         return {\"val_loss\": val_loss, **val_metrics}\n# \n#     def val_loss_step(\n#         self,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n        calib_outputs_loader: TargetsLoader,\n        training_dataset_size: int,\n        verbose: bool,\n        progress_bar: TqdmDecorator,\n    ) -> Tuple[CalibState, Dict[str, float], str]:\n        training_losses_and_metrics_epoch_all_steps = []\n        training_batch_metrics_str = \"\"\n        for step, (batch, outputs) in enumerate(\n            zip(training_data_loader, calib_outputs_loader)\n        ):\n            # forward and backward pass\n            state, aux = self.training_step(\n                state, batch, outputs, fun, rng, training_dataset_size\n            )\n            # compute training losses and metrics for the current batch\n            training_losses_and_metrics_current_batch = self.training_step_end(\n                current_epoch=current_epoch,\n                state=state,\n                aux=aux,\n                batch=batch,\n                metrics=metrics,\n            )\n            # keep track of training losses and metrics [granularity=batch]\n            training_losses_and_metrics_epoch_all_steps.append(\n                training_losses_and_metrics_current_batch\n            )\n            # logging\n            if verbose:\n                training_batch_metrics_str = \" | \".join(\n                    [\n                        f\"{m}: {round(float(v), 5)}\"\n                        for m, v in training_losses_and_metrics_current_batch.items()\n                    ]\n                )\n                progress_bar.set_description(\n                    f\"Epoch: {current_epoch + 1} | \" + training_batch_metrics_str,\n                    refresh=True,\n                )\n\n        # compute training losses and metrics avg for the current epoch + other ops (if needed)\n        training_losses_and_metrics_current_epoch = self.training_epoch_end(\n            training_losses_and_metrics_epoch_all_steps\n        )\n\n        return (\n            state,\n            training_losses_and_metrics_current_epoch,\n            training_batch_metrics_str,\n        )\n\n    def training_step(\n        self,\n        state: CalibState,\n        batch: Batch,\n        outputs: Array,\n        fun: Callable,\n        rng: PRNGKeyArray,\n        n_data: int,\n    ) -> Tuple[CalibState, Dict[str, Any]]:\n        # ensure to use a different key at each step\n        model_key = random.fold_in(rng, state.step)\n\n        grad_fn = value_and_grad(\n            lambda params: self.training_loss_step(\n                fun, params, batch, outputs, state.mutable, model_key, n_data\n            ),\n            has_aux=True,\n        )\n        (loss, aux), grad = grad_fn(state.params)\n        grad, loss = self.sync_gradients_and_loss(grad, loss)\n\n        state = state.apply_gradients(grads=grad, mutable=aux[\"mutable\"])\n        return (\n            state,\n            {\n                \"loss\": loss,\n                \"outputs\": aux[\"outputs\"],\n                \"logging_kwargs\": aux[\"logging_kwargs\"],\n            },\n        )\n\n    @abc.abstractmethod\n    def training_loss_step(\n        self,\n        fun: Callable[[Any], Union[float, Tuple[float, dict]]],\n        params: CalibParams,\n        batch: Batch,\n        outputs: Array,\n        mutable: CalibMutable,\n        rng: PRNGKeyArray,\n        n_data: int,\n    ) -> Tuple[jnp.ndarray, Dict[str, Any]]:\n        pass\n\n    def training_step_end(\n        self,\n        current_epoch: int,\n        state: CalibState,\n        aux: Dict[str, Any],\n        batch: Batch,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ],\n    ) -> Dict[str, jnp.ndarray]:\n        if (\n            self.save_checkpoint_dir\n            and self.save_every_n_steps\n            and current_epoch % self.save_every_n_steps == 0\n        ):\n            self.save_checkpoint(\n                state, self.save_checkpoint_dir, keep=self.keep_top_n_checkpoints\n            )\n        training_losses_and_metrics = {\"loss\": aux[\"loss\"]}\n\n        if aux[\"logging_kwargs\"] is not None:\n            for k, v in aux[\"logging_kwargs\"].items():\n                training_losses_and_metrics[k] = v\n\n        if not self.disable_training_metrics_computation and metrics is not None:\n            preds = self.predict_fn(aux[\"outputs\"])\n            uncertainties = self.uncertainty_fn(aux[\"outputs\"])\n            if self.multi_device:\n                training_batch_metrics = self.compute_metrics(\n                    preds.reshape((preds.shape[0] * preds.shape[1],) + preds.shape[2:]),\n                    uncertainties.reshape(\n                        (uncertainties.shape[0] * uncertainties.shape[1],)\n                        + uncertainties.shape[2:]\n                    ),\n                    batch[1].reshape(\n                        (batch[1].shape[0] * batch[1].shape[1],) + batch[1].shape[2:]\n                    ),\n                    metrics,\n                )\n            else:\n                training_batch_metrics = self.compute_metrics(\n                    preds, uncertainties, batch[1], metrics\n                )\n            for k, v in training_batch_metrics.items():\n                training_losses_and_metrics[k] = v\n        return training_losses_and_metrics\n\n    def _val_loop(\n        self,\n        fun: Callable,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ],\n        rng: PRNGKeyArray,\n        state: CalibState,\n        val_data_loader: DataLoader,\n        val_outputs_loader: TargetsLoader,\n        val_dataset_size: int,\n        verbose: bool = True,\n    ) -> Tuple[Dict[str, float], str]:\n        val_losses_and_metrics_epoch_all_steps = []\n        val_epoch_metrics_str = \"\"\n        for batch, outputs in zip(val_data_loader, val_outputs_loader):\n            val_losses_and_metrics_current_batch = self.val_step(\n                state, batch, outputs, fun, rng, val_dataset_size, metrics,\n            )\n            val_losses_and_metrics_epoch_all_steps.append(\n                val_losses_and_metrics_current_batch\n            )\n        # compute validation losses and metrics for the current epoch\n        val_losses_and_metrics_current_epoch = self.val_epoch_end(\n            val_losses_and_metrics_epoch_all_steps, state\n        )\n        # logging\n        if verbose:\n            val_epoch_metrics_str = \" | \".join(\n                [\n                    f\"{m}: {round(float(v), 5)}\"\n                    for m, v in val_losses_and_metrics_current_epoch.items()\n                ]\n            )\n        return val_losses_and_metrics_current_epoch, val_epoch_metrics_str\n\n    def val_step(\n        self,\n        state: CalibState,\n        batch: Batch,\n        outputs: Array,\n        fun: Callable,\n        rng: PRNGKeyArray,\n        n_data: int,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ] = None,", "choices": [{"text": ") -> Dict[str, jnp.ndarray]:"}], "metadata": {"task_id": "awslabs_fortuna/87", "ground_truth": "    ) -> Dict[str, jnp.ndarray]:", "fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "context_start_lineno": 160, "line_no": 348, "query_window": {"context": "        if verbose:\n            val_epoch_metrics_str = \" | \".join(\n                [\n                    f\"{m}: {round(float(v), 5)}\"\n                    for m, v in val_losses_and_metrics_current_epoch.items()\n                ]\n            )\n        return val_losses_and_metrics_current_epoch, val_epoch_metrics_str\n\n    def val_step(\n        self,\n        state: CalibState,\n        batch: Batch,\n        outputs: Array,\n        fun: Callable,\n        rng: PRNGKeyArray,\n        n_data: int,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ] = None,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 348, "task_id": "awslabs_fortuna/87", "start_line_no": 328, "end_line_no": 348, "window_size": 20, "context_start_lineno": 160, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        val_losses_and_metrics_current_epoch = self.val_epoch_end(\n            val_losses_and_metrics_epoch_all_steps, state\n        )\n        # logging\n        if verbose:\n            val_epoch_metrics_str = \" | \".join(\n                [\n                    f\"{m}: {round(float(v), 5)}\"\n                    for m, v in val_losses_and_metrics_current_epoch.items()\n                ]\n            )\n        return val_losses_and_metrics_current_epoch, val_epoch_metrics_str\n\n    def val_step(\n        self,\n        state: CalibState,\n        targets: Array,\n        outputs: Array,\n        fun: Callable,\n        rng: PRNGKeyArray,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.71}, {"context": "            )\n        return val_losses_and_metrics_current_epoch, val_epoch_metrics_str\n\n    def val_step(\n        self,\n        state: CalibState,\n        targets: Array,\n        outputs: Array,\n        fun: Callable,\n        rng: PRNGKeyArray,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ] = None,\n    ) -> Dict[str, jnp.ndarray]:\n        val_loss, aux = self.val_loss_step(state, targets, outputs, fun, rng)\n        val_metrics = self.val_metrics_step(aux, targets, metrics)\n        return {\"val_loss\": val_loss, **val_metrics}\n\n    def val_loss_step(\n        self,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5566037735849056}, {"context": "    ) -> Tuple[Dict[str, float], str]:\n        val_losses_and_metrics_epoch_all_steps = []\n        val_epoch_metrics_str = \"\"\n        val_losses_and_metrics_current_batch = self.val_step(\n            state, targets, outputs, fun, rng, metrics,\n        )\n        val_losses_and_metrics_epoch_all_steps.append(\n            val_losses_and_metrics_current_batch\n        )\n        # compute validation losses and metrics for the current epoch\n        val_losses_and_metrics_current_epoch = self.val_epoch_end(\n            val_losses_and_metrics_epoch_all_steps, state\n        )\n        # logging\n        if verbose:\n            val_epoch_metrics_str = \" | \".join(\n                [\n                    f\"{m}: {round(float(v), 5)}\"\n                    for m, v in val_losses_and_metrics_current_epoch.items()\n                ]", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5384615384615384}, {"context": "                )\n            else:\n                training_batch_metrics = self.compute_metrics(\n                    preds, uncertainties, targets, metrics\n                )\n            for k, v in training_batch_metrics.items():\n                training_losses_and_metrics[k] = v\n        return training_losses_and_metrics\n\n    def _val_loop(\n        self,\n        fun: Callable,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ],\n        rng: PRNGKeyArray,\n        state: CalibState,\n        targets: Array,\n        outputs: Array,\n        verbose: bool = True,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5225225225225225}, {"context": "        }\n        val_status = {k: jnp.array(v) for k, v in val_losses_and_metrics.items()}\n        status = dict(**training_status, **val_status)\n\n        state = self.on_train_end(state)\n        return state, status\n\n    def _training_loop(\n        self,\n        current_epoch: int,\n        fun: Callable,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ],\n        rng: PRNGKeyArray,\n        state: CalibState,\n        targets: Array,\n        outputs: Array,\n        verbose: bool,\n        progress_bar: TqdmDecorator,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5206611570247934}, {"context": "        # aggregate\n        training_status = {\n            k: jnp.array(v) for k, v in training_losses_and_metrics.items()\n        }\n        val_status = {k: jnp.array(v) for k, v in val_losses_and_metrics.items()}\n        status = dict(**training_status, **val_status)\n\n        state = self.on_train_end(state)\n        return state, status\n\n    def _training_loop(\n        self,\n        current_epoch: int,\n        fun: Callable,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ],\n        rng: PRNGKeyArray,\n        state: CalibState,\n        training_data_loader: DataLoader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5169491525423728}, {"context": "        self.multi_device = False\n\n    def train(\n        self,\n        rng: PRNGKeyArray,\n        state: CalibState,\n        fun: Callable,\n        n_epochs: int = 1,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ] = None,\n        verbose: bool = True,\n    ) -> Tuple[CalibState, Status]:\n        training_losses_and_metrics = collections.defaultdict(list)\n        val_losses_and_metrics = collections.defaultdict(list)\n\n        state, targets, outputs, rng = self.on_train_start(\n            state,\n            [self._calib_targets, self._val_targets],\n            [self._calib_outputs, self._val_outputs],", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4918032786885246}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/hpc_rl/tests/test_tdlambda.py\n# --------------------------------------------------\n#     hpc_weight = ori_weight.clone().detach()\n#     hpc_td = TDLambda(T, B)\n# \n#     if use_cuda:\n#         ori_value = ori_value.cuda()\n#         ori_reward = ori_reward.cuda()\n#         ori_weight = ori_weight.cuda()\n# \n#         hpc_value = hpc_value.cuda()\n#         hpc_reward = hpc_reward.cuda()\n#         hpc_weight = hpc_weight.cuda()\n#         hpc_td = hpc_td.cuda()\n# \n#     ori_value.requires_grad_(True)\n#     ori_loss = td_lambda_error(td_lambda_data(ori_value, ori_reward, ori_weight))\n#     ori_loss = ori_loss.mean()\n#     ori_loss.backward()\n#     if use_cuda:\n#         torch.cuda.synchronize()\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/hpc_rl/tests/test_qntd.py\n# --------------------------------------------------\n#     hpc_weight = ori_weight.clone().detach()\n#     hpc_qntd = QNStepTD(T, B, N)\n# \n#     if use_cuda:\n#         ori_q = ori_q.cuda()\n#         ori_next_n_q = ori_next_n_q.cuda()\n#         ori_action = ori_action.cuda()\n#         ori_next_n_action = ori_next_n_action.cuda()\n#         ori_reward = ori_reward.cuda()\n#         ori_done = ori_done.cuda()\n#         ori_weight = ori_weight.cuda()\n# \n#         hpc_q = hpc_q.cuda()\n#         hpc_next_n_q = hpc_next_n_q.cuda()\n#         hpc_action = hpc_action.cuda()\n#         hpc_next_n_action = hpc_next_n_action.cuda()\n#         hpc_reward = hpc_reward.cuda()\n#         hpc_done = hpc_done.cuda()\n#         hpc_weight = hpc_weight.cuda()\n#         hpc_qntd = hpc_qntd.cuda()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/hpc_rl/tests/test_tdlambda.py\n# --------------------------------------------------\n#         ori_value = ori_value.cuda()\n#         ori_reward = ori_reward.cuda()\n#         ori_weight = ori_weight.cuda()\n# \n#         hpc_value = hpc_value.cuda()\n#         hpc_reward = hpc_reward.cuda()\n#         hpc_weight = hpc_weight.cuda()\n#         hpc_td = hpc_td.cuda()\n# \n#     ori_value.requires_grad_(True)\n#     for i in range(times):\n#         t = time.time()\n#         ori_loss = td_lambda_error(td_lambda_data(ori_value, ori_reward, ori_weight))\n#         ori_loss = ori_loss.mean()\n#         ori_loss.backward()\n#         if use_cuda:\n#             torch.cuda.synchronize()\n#         print('epoch: {}, original td cost time: {}'.format(i, time.time() - t))\n# \n#     hpc_value.requires_grad_(True)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/hpc_rl/tests/test_vtrace.py\n# --------------------------------------------------\n#         ori_behaviour_output = ori_behaviour_output.cuda()\n#         ori_action = ori_action.cuda()\n#         ori_value = ori_value.cuda()\n#         ori_reward = ori_reward.cuda()\n# \n#         hpc_target_output = hpc_target_output.cuda()\n#         hpc_behaviour_output = hpc_behaviour_output.cuda()\n#         hpc_action = hpc_action.cuda()\n#         hpc_value = hpc_value.cuda()\n#         hpc_reward = hpc_reward.cuda()\n#         hpc_vtrace = hpc_vtrace.cuda()\n# \n#     ori_target_output.requires_grad_(True)\n#     ori_value.requires_grad_(True)\n#     for i in range(times):\n#         t = time.time()\n#         ori_loss = vtrace_error(\n#             vtrace_data(ori_target_output, ori_behaviour_output, ori_action, ori_value, ori_reward, None)\n#         )\n#         ori_loss = sum(ori_loss)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/hpc_rl/tests/test_vtrace.py\n# --------------------------------------------------\n# \n#     hpc_target_output = ori_target_output.clone().detach()\n#     hpc_behaviour_output = ori_behaviour_output.clone().detach()\n#     hpc_action = ori_action.clone().detach()\n#     hpc_value = ori_value.clone().detach()\n#     hpc_reward = ori_reward.clone().detach()\n#     hpc_vtrace = VTrace(T, B, N)\n# \n#     if use_cuda:\n#         ori_target_output = ori_target_output.cuda()\n#         ori_behaviour_output = ori_behaviour_output.cuda()\n#         ori_action = ori_action.cuda()\n#         ori_value = ori_value.cuda()\n#         ori_reward = ori_reward.cuda()\n# \n#         hpc_target_output = hpc_target_output.cuda()\n#         hpc_behaviour_output = hpc_behaviour_output.cuda()\n#         hpc_action = hpc_action.cuda()\n#         hpc_value = hpc_value.cuda()\n#         hpc_reward = hpc_reward.cuda()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/hpc_rl/tests/test_vtrace.py\n# --------------------------------------------------\n#     hpc_value = ori_value.clone().detach()\n#     hpc_reward = ori_reward.clone().detach()\n#     hpc_vtrace = VTrace(T, B, N)\n# \n#     if use_cuda:\n#         ori_target_output = ori_target_output.cuda()\n#         ori_behaviour_output = ori_behaviour_output.cuda()\n#         ori_action = ori_action.cuda()\n#         ori_value = ori_value.cuda()\n#         ori_reward = ori_reward.cuda()\n# \n#         hpc_target_output = hpc_target_output.cuda()\n#         hpc_behaviour_output = hpc_behaviour_output.cuda()\n#         hpc_action = hpc_action.cuda()\n#         hpc_value = hpc_value.cuda()\n#         hpc_reward = hpc_reward.cuda()\n#         hpc_vtrace = hpc_vtrace.cuda()\n# \n#     ori_target_output.requires_grad_(True)\n#     ori_value.requires_grad_(True)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport time\nimport torch\nfrom hpc_rll.origin.upgo import upgo_loss\nfrom hpc_rll.rl_utils.upgo import UPGO\nfrom testbase import mean_relative_error, times\n\nassert torch.cuda.is_available()\nuse_cuda = True\n\nT = 256\nB = 256\nN = 256\n\n\ndef upgo_val():\n    ori_target_output = torch.randn(T, B, N)\n    ori_rhos = torch.randn(T, B)\n    ori_action = torch.randint(\n        0, N, size=(\n            T,\n            B,\n        )\n    )\n    ori_rewards = torch.randn(T, B)\n    ori_bootstrap_values = torch.randn(T + 1, B)\n\n    hpc_target_output = ori_target_output.clone().detach()\n    hpc_rhos = ori_rhos.clone().detach()\n    hpc_action = ori_action.clone().detach()\n    hpc_rewards = ori_rewards.clone().detach()\n    hpc_bootstrap_values = ori_bootstrap_values.clone().detach()\n    hpc_upgo = UPGO(T, B, N)\n\n    if use_cuda:\n        ori_target_output = ori_target_output.cuda()\n        ori_rhos = ori_rhos.cuda()\n        ori_action = ori_action.cuda()\n        ori_rewards = ori_rewards.cuda()\n        ori_bootstrap_values = ori_bootstrap_values.cuda()\n\n        hpc_target_output = hpc_target_output.cuda()\n        hpc_rhos = hpc_rhos.cuda()\n        hpc_action = hpc_action.cuda()\n        hpc_rewards = hpc_rewards.cuda()\n        hpc_bootstrap_values = hpc_bootstrap_values.cuda()\n        hpc_upgo = hpc_upgo.cuda()\n\n    ori_target_output.requires_grad_(True)\n    ori_loss = upgo_loss(ori_target_output, ori_rhos, ori_action, ori_rewards, ori_bootstrap_values)\n    ori_loss = ori_loss.mean()\n    ori_loss.backward()\n    if use_cuda:\n        torch.cuda.synchronize()\n\n    hpc_target_output.requires_grad_(True)\n    hpc_loss = hpc_upgo(hpc_target_output, hpc_rhos, hpc_action, hpc_rewards, hpc_bootstrap_values)\n    hpc_loss = hpc_loss.mean()\n    hpc_loss.backward()\n    if use_cuda:\n        torch.cuda.synchronize()\n\n    mre = mean_relative_error(\n        torch.flatten(ori_loss).cpu().detach().numpy(),\n        torch.flatten(hpc_loss).cpu().detach().numpy()\n    )\n    print(\"upgo fp mean_relative_error: \" + str(mre))\n    mre = mean_relative_error(\n        torch.flatten(ori_target_output.grad).cpu().detach().numpy(),\n        torch.flatten(hpc_target_output.grad).cpu().detach().numpy()\n    )\n    print(\"upgo bp mean_relative_error: \" + str(mre))\n\n\ndef upgo_perf():\n    ori_target_output = torch.randn(T, B, N)\n    ori_rhos = torch.randn(T, B)\n    ori_action = torch.randint(\n        0, N, size=(\n            T,\n            B,\n        )\n    )\n    ori_rewards = torch.randn(T, B)\n    ori_bootstrap_values = torch.randn(T + 1, B)\n\n    hpc_target_output = ori_target_output.clone().detach()\n    hpc_rhos = ori_rhos.clone().detach()\n    hpc_action = ori_action.clone().detach()\n    hpc_rewards = ori_rewards.clone().detach()\n    hpc_bootstrap_values = ori_bootstrap_values.clone().detach()\n    hpc_upgo = UPGO(T, B, N)\n\n    if use_cuda:\n        ori_target_output = ori_target_output.cuda()\n        ori_rhos = ori_rhos.cuda()\n        ori_action = ori_action.cuda()\n        ori_rewards = ori_rewards.cuda()\n        ori_bootstrap_values = ori_bootstrap_values.cuda()\n\n        hpc_target_output = hpc_target_output.cuda()\n        hpc_rhos = hpc_rhos.cuda()", "choices": [{"text": "hpc_action = hpc_action.cuda()"}], "metadata": {"task_id": "opendilab_ACE/12", "ground_truth": "        hpc_action = hpc_action.cuda()", "fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "tests", "test_upgo.py"], "context_start_lineno": 0, "line_no": 101, "query_window": {"context": "    )\n    ori_rewards = torch.randn(T, B)\n    ori_bootstrap_values = torch.randn(T + 1, B)\n\n    hpc_target_output = ori_target_output.clone().detach()\n    hpc_rhos = ori_rhos.clone().detach()\n    hpc_action = ori_action.clone().detach()\n    hpc_rewards = ori_rewards.clone().detach()\n    hpc_bootstrap_values = ori_bootstrap_values.clone().detach()\n    hpc_upgo = UPGO(T, B, N)\n\n    if use_cuda:\n        ori_target_output = ori_target_output.cuda()\n        ori_rhos = ori_rhos.cuda()\n        ori_action = ori_action.cuda()\n        ori_rewards = ori_rewards.cuda()\n        ori_bootstrap_values = ori_bootstrap_values.cuda()\n\n        hpc_target_output = hpc_target_output.cuda()\n        hpc_rhos = hpc_rhos.cuda()", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "tests", "test_upgo.py"], "line_no": 101, "task_id": "opendilab_ACE/12", "start_line_no": 81, "end_line_no": 101, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "            T,\n            B,\n        )\n    )\n    ori_value = torch.randn(T + 1, B)\n    ori_reward = torch.randn(T, B)\n\n    hpc_target_output = ori_target_output.clone().detach()\n    hpc_behaviour_output = ori_behaviour_output.clone().detach()\n    hpc_action = ori_action.clone().detach()\n    hpc_value = ori_value.clone().detach()\n    hpc_reward = ori_reward.clone().detach()\n    hpc_vtrace = VTrace(T, B, N)\n\n    if use_cuda:\n        ori_target_output = ori_target_output.cuda()\n        ori_behaviour_output = ori_behaviour_output.cuda()\n        ori_action = ori_action.cuda()\n        ori_value = ori_value.cuda()\n        ori_reward = ori_reward.cuda()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "tests", "test_vtrace.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6206896551724138}, {"context": "    ori_target_output = torch.randn(T, B, N)\n    ori_behaviour_output = torch.randn(T, B, N)\n    ori_action = torch.randint(\n        0, N, size=(\n            T,\n            B,\n        )\n    )\n    ori_value = torch.randn(T + 1, B)\n    ori_reward = torch.randn(T, B)\n\n    hpc_target_output = ori_target_output.clone().detach()\n    hpc_behaviour_output = ori_behaviour_output.clone().detach()\n    hpc_action = ori_action.clone().detach()\n    hpc_value = ori_value.clone().detach()\n    hpc_reward = ori_reward.clone().detach()\n    hpc_vtrace = VTrace(T, B, N)\n\n    if use_cuda:\n        ori_target_output = ori_target_output.cuda()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "tests", "test_vtrace.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5806451612903226}, {"context": "\n    hpc_target_output = ori_target_output.clone().detach()\n    hpc_behaviour_output = ori_behaviour_output.clone().detach()\n    hpc_action = ori_action.clone().detach()\n    hpc_value = ori_value.clone().detach()\n    hpc_reward = ori_reward.clone().detach()\n    hpc_vtrace = VTrace(T, B, N)\n\n    if use_cuda:\n        ori_target_output = ori_target_output.cuda()\n        ori_behaviour_output = ori_behaviour_output.cuda()\n        ori_action = ori_action.cuda()\n        ori_value = ori_value.cuda()\n        ori_reward = ori_reward.cuda()\n\n        hpc_target_output = hpc_target_output.cuda()\n        hpc_behaviour_output = hpc_behaviour_output.cuda()\n        hpc_action = hpc_action.cuda()\n        hpc_value = hpc_value.cuda()\n        hpc_reward = hpc_reward.cuda()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "tests", "test_vtrace.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5357142857142857}, {"context": "    ori_value = torch.randn(T + 1, B)\n    ori_reward = torch.randn(T, B)\n    ori_weight = torch.randn(T, B)\n\n    hpc_value = ori_value.clone().detach()\n    hpc_reward = ori_reward.clone().detach()\n    hpc_weight = ori_weight.clone().detach()\n    hpc_td = TDLambda(T, B)\n\n    if use_cuda:\n        ori_value = ori_value.cuda()\n        ori_reward = ori_reward.cuda()\n        ori_weight = ori_weight.cuda()\n\n        hpc_value = hpc_value.cuda()\n        hpc_reward = hpc_reward.cuda()\n        hpc_weight = hpc_weight.cuda()\n        hpc_td = hpc_td.cuda()\n\n    ori_value.requires_grad_(True)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "tests", "test_tdlambda.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5254237288135594}, {"context": "    ori_reward = torch.randn(T, B)\n    ori_done = torch.randn(B)\n    ori_weight = torch.randn(B)\n\n    hpc_q = ori_q.clone().detach()\n    hpc_next_n_q = ori_next_n_q.clone().detach()\n    hpc_action = ori_action.clone().detach()\n    hpc_next_n_action = ori_next_n_action.clone().detach()\n    hpc_reward = ori_reward.clone().detach()\n    hpc_done = ori_done.clone().detach()\n    hpc_weight = ori_weight.clone().detach()\n    hpc_qntd = QNStepTD(T, B, N)\n\n    if use_cuda:\n        ori_q = ori_q.cuda()\n        ori_next_n_q = ori_next_n_q.cuda()\n        ori_action = ori_action.cuda()\n        ori_next_n_action = ori_next_n_action.cuda()\n        ori_reward = ori_reward.cuda()\n        ori_done = ori_done.cuda()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "tests", "test_qntd.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5254237288135594}, {"context": "B = 64\n\n\ndef td_val():\n    ori_value = torch.randn(T + 1, B)\n    ori_reward = torch.randn(T, B)\n    ori_weight = torch.randn(T, B)\n\n    hpc_value = ori_value.clone().detach()\n    hpc_reward = ori_reward.clone().detach()\n    hpc_weight = ori_weight.clone().detach()\n    hpc_td = TDLambda(T, B)\n\n    if use_cuda:\n        ori_value = ori_value.cuda()\n        ori_reward = ori_reward.cuda()\n        ori_weight = ori_weight.cuda()\n\n        hpc_value = hpc_value.cuda()\n        hpc_reward = hpc_reward.cuda()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "hpc_rl", "tests", "test_tdlambda.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5081967213114754}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n# \n# \n# class HubEvaluationModuleFactory(_EvaluationModuleFactory):\n#     \"\"\"Get the module of a metric from a metric repository on the Hub.\"\"\"\n# \n#     def __init__(\n#         self,\n#         name: str,\n#         module_type: str = \"metrics\",\n#         revision: Optional[Union[str, Version]] = None,\n#         download_config: Optional[DownloadConfig] = None,\n#         download_mode: Optional[DownloadMode] = None,\n#         dynamic_modules_path: Optional[str] = None,\n#     ):\n#         self.name = name\n#         self.module_type = module_type\n#         self.revision = revision\n#         self.download_config = download_config or DownloadConfig()\n#         self.download_mode = download_mode\n#         self.dynamic_modules_path = dynamic_modules_path\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n#         dynamic_modules_path: Optional[str] = None,\n#     ):\n#         self.name = name\n#         self.module_type = module_type\n#         self.dynamic_modules_path = dynamic_modules_path\n#         assert self.name.count(\"/\") == 0\n# \n#     def get_module(self) -> ImportableModule:\n#         dynamic_modules_path = self.dynamic_modules_path if self.dynamic_modules_path else init_dynamic_modules()\n#         importable_directory_path = os.path.join(dynamic_modules_path, self.module_type, self.name)\n#         hashes = (\n#             [h for h in os.listdir(importable_directory_path) if len(h) == 64]\n#             if os.path.isdir(importable_directory_path)\n#             else None\n#         )\n#         if not hashes:\n#             raise FileNotFoundError(f\"Metric {self.name} is not cached in {dynamic_modules_path}\")\n#         # get most recent\n# \n#         def _get_modification_time(module_hash):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/evaluator/base.py\n# --------------------------------------------------\n#             if self.default_metric_name is None:\n#                 raise ValueError(\n#                     \"`Evaluator` doesn't specify a default metric. Please specify a valid `metric` argument.\"\n#                 )\n#             metric = load(self.default_metric_name)\n#         elif isinstance(metric, str):\n#             metric = load(metric)\n# \n#         return metric\n# \n#     def call_pipeline(self, pipe, *args, **kwargs):\n#         start_time = perf_counter()\n#         pipe_output = pipe(*args, **kwargs, **self.PIPELINE_KWARGS)\n#         end_time = perf_counter()\n#         return pipe_output, self._compute_time_perf(start_time, end_time, len(pipe_output))\n# \n#     def compute_metric(\n#         self,\n#         metric: EvaluationModule,\n#         metric_inputs: Dict,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n#     \"\"\"Get the module of a local metric. The metric script is loaded from a local script.\"\"\"\n# \n#     def __init__(\n#         self,\n#         path: str,\n#         module_type: str = \"metrics\",\n#         download_config: Optional[DownloadConfig] = None,\n#         download_mode: Optional[DownloadMode] = None,\n#         dynamic_modules_path: Optional[str] = None,\n#     ):\n#         self.path = path\n#         self.module_type = module_type\n#         self.name = Path(path).stem\n#         self.download_config = download_config or DownloadConfig()\n#         self.download_mode = download_mode\n#         self.dynamic_modules_path = dynamic_modules_path\n# \n#     def get_module(self) -> ImportableModule:\n#         # get script and other files\n#         imports = get_imports(self.path)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n# class CachedEvaluationModuleFactory(_EvaluationModuleFactory):\n#     \"\"\"\n#     Get the module of a metric that has been loaded once already and cached.\n#     The script that is loaded from the cache is the most recent one with a matching name.\n#     \"\"\"\n# \n#     def __init__(\n#         self,\n#         name: str,\n#         module_type: str = \"metrics\",\n#         dynamic_modules_path: Optional[str] = None,\n#     ):\n#         self.name = name\n#         self.module_type = module_type\n#         self.dynamic_modules_path = dynamic_modules_path\n#         assert self.name.count(\"/\") == 0\n# \n#     def get_module(self) -> ImportableModule:\n#         dynamic_modules_path = self.dynamic_modules_path if self.dynamic_modules_path else init_dynamic_modules()\n#         importable_directory_path = os.path.join(dynamic_modules_path, self.module_type, self.name)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/evaluation_suite/__init__.py\n# --------------------------------------------------\n#         download_config: Optional[DownloadConfig] = None,\n#     ):\n#         download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)\n#         evaluation_module = evaluation_module_factory(\n#             path, module_type=None, revision=revision, download_config=download_config, download_mode=download_mode\n#         )\n#         name = Path(path).stem\n#         evaluation_cls = import_main_class(evaluation_module.module_path)\n#         evaluation_instance = evaluation_cls(name)\n# \n#         return evaluation_instance\n# \n#     def __repr__(self):\n#         self.tasks = [str(task) for task in self.suite]\n#         return f'EvaluationSuite name: \"{self.name}\", ' f\"Tasks: {self.tasks})\"\n# \n#     def assert_suite_nonempty(self):\n#         if not self.suite:\n#             raise ValueError(\n#                 \"No evaluation tasks found. The EvaluationSuite must include at least one SubTask definition.\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/module.py\n# --------------------------------------------------\n# \n#     @property\n#     def name(self) -> str:\n#         return self._module_info.module_name\n# \n#     @property\n#     def experiment_id(self) -> Optional[str]:\n#         return self._module_info.experiment_id\n# \n#     @property\n#     def description(self) -> str:\n#         return self._module_info.description\n# \n#     @property\n#     def citation(self) -> str:\n#         return self._module_info.citation\n# \n#     @property\n#     def features(self) -> Features:\n#         return self._module_info.features\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n            return [self._enforce_nested_string_type(sub_schema, o) for k, (sub_schema, o) in zip_dict(schema, obj)]\n\n        elif isinstance(schema, (list, tuple)):\n            sub_schema = schema[0]\n            return [self._enforce_nested_string_type(sub_schema, o) for o in obj]\n        elif isinstance(schema, Sequence):\n            # We allow to reverse list of dict => dict of list for compatiblity with tfds\n            if isinstance(schema.feature, dict):\n                if isinstance(obj, (list, tuple)):\n                    # obj is a list of dict\n                    for k, dict_tuples in zip_dict(schema.feature, *obj):\n                        for sub_obj in dict_tuples[1:]:\n                            if _check_non_null_non_empty_recursive(sub_obj, dict_tuples[0]):\n                                self._enforce_nested_string_type(dict_tuples[0], sub_obj)\n                                break\n                    return None\n                else:\n                    # obj is a single dict\n                    for k, (sub_schema, sub_objs) in zip_dict(schema.feature, obj):\n                        for sub_obj in sub_objs:\n                            if _check_non_null_non_empty_recursive(sub_obj, sub_schema):\n                                self._enforce_nested_string_type(sub_schema, sub_obj)\n                                break\n                    return None\n            # schema.feature is not a dict\n            if isinstance(obj, str):  # don't interpret a string as a list\n                raise ValueError(f\"Got a string but expected a list instead: '{obj}'\")\n            if obj is None:\n                return None\n            else:\n                if len(obj) > 0:\n                    for first_elmt in obj:\n                        if _check_non_null_non_empty_recursive(first_elmt, schema.feature):\n                            break\n                    if not isinstance(first_elmt, list):\n                        return self._enforce_nested_string_type(schema.feature, first_elmt)\n\n        elif isinstance(schema, Value):\n            if pa.types.is_string(schema.pa_type) and not isinstance(obj, str):\n                raise TypeError(f\"Expected type str but got {type(obj)}.\")\n\n\nclass Metric(EvaluationModule):\n    \"\"\"A Metric is the base class and common API for all metrics.\n\n    Args:\n        config_name (`str`):\n            This is used to define a hash specific to a metric computation script and prevents the metric's data\n            to be overridden when the metric loading script is modified.\n        keep_in_memory (`bool`):\n            Keep all predictions and references in memory. Not possible in distributed settings.\n        cache_dir (`str`):\n            Path to a directory in which temporary prediction/references data will be stored.\n            The data directory should be located on a shared file-system in distributed setups.\n        num_process (`int`):\n            Specify the total number of nodes in a distributed settings.\n            This is useful to compute metrics in distributed setups (in particular non-additive metrics like F1).\n        process_id (`int`):\n            Specify the id of the current process in a distributed setup (between 0 and num_process-1)\n            This is useful to compute metrics in distributed setups (in particular non-additive metrics like F1).\n        seed (`int`, *optional*):\n            If specified, this will temporarily set numpy's random seed when [`~evaluate.Metric.compute`] is run.\n        experiment_id (`str`):\n            A specific experiment id. This is used if several distributed evaluations share the same file system.\n            This is useful to compute metrics in distributed setups (in particular non-additive metrics like F1).\n        max_concurrent_cache_files (`int`):\n            Max number of concurrent metric cache files (default `10000`).\n        timeout (`Union[int, float]`):\n            Timeout in second for distributed setting synchronization.\n    \"\"\"\n\n\nclass Comparison(EvaluationModule):\n    \"\"\"A Comparison is the base class and common API for all comparisons.\n\n    Args:\n        config_name (`str`):\n            This is used to define a hash specific to a comparison computation script and prevents the comparison's data\n            to be overridden when the comparison loading script is modified.\n        keep_in_memory (`bool`):\n            Keep all predictions and references in memory. Not possible in distributed settings.\n        cache_dir (`str`):\n            Path to a directory in which temporary prediction/references data will be stored.\n            The data directory should be located on a shared file-system in distributed setups.\n        num_process (`int`):\n            Specify the total number of nodes in a distributed settings.\n            This is useful to compute  comparisons in distributed setups (in particular non-additive comparisons).\n        process_id (`int`):\n            Specify the id of the current process in a distributed setup (between 0 and num_process-1)\n            This is useful to compute  comparisons in distributed setups (in particular non-additive comparisons).\n        seed (`int`, *optional*):\n            If specified, this will temporarily set numpy's random seed when [`~evaluate.Comparison.compute`] is run.\n        experiment_id (`str`):\n            A specific experiment id. This is used if several distributed evaluations share the same file system.\n            This is useful to compute  comparisons in distributed setups (in particular non-additive comparisons).\n        max_concurrent_cache_files (`int`):\n            Max number of concurrent comparison cache files (default `10000`).\n        timeout (`Union[int, float]`):\n            Timeout in second for distributed setting synchronization.\n    \"\"\"\n\n\nclass Measurement(EvaluationModule):\n    \"\"\"A Measurement is the base class and common API for all measurements.\n\n    Args:\n        config_name (`str`):\n            This is used to define a hash specific to a measurement computation script and prevents the measurement's data\n            to be overridden when the measurement loading script is modified.\n        keep_in_memory (`bool`):\n            Keep all predictions and references in memory. Not possible in distributed settings.\n        cache_dir (`str`):\n            Path to a directory in which temporary prediction/references data will be stored.\n            The data directory should be located on a shared file-system in distributed setups.\n        num_process (`int`):\n            Specify the total number of nodes in a distributed settings.\n            This is useful to compute measurements in distributed setups (in particular non-additive measurements).\n        process_id (`int`):\n            Specify the id of the current process in a distributed setup (between 0 and num_process-1)\n            This is useful to compute measurements in distributed setups (in particular non-additive measurements).\n        seed (`int`, *optional*):\n            If specified, this will temporarily set numpy's random seed when [`~evaluate.Measurement.compute`] is run.\n        experiment_id (`str`):\n            A specific experiment id. This is used if several distributed evaluations share the same file system.\n            This is useful to compute measurements in distributed setups (in particular non-additive measurements).\n        max_concurrent_cache_files (`int`):\n            Max number of concurrent measurement cache files (default `10000`).\n        timeout (`Union[int, float]`):\n            Timeout in second for distributed setting synchronization.\n    \"\"\"\n\n\nclass CombinedEvaluations:\n    def __init__(self, evaluation_modules, force_prefix=False):\n        from .loading import load  # avoid circular imports\n\n        self.evaluation_module_names = None\n        if isinstance(evaluation_modules, list):\n            self.evaluation_modules = evaluation_modules\n        elif isinstance(evaluation_modules, dict):\n            self.evaluation_modules = list(evaluation_modules.values())\n            self.evaluation_module_names = list(evaluation_modules.keys())\n        loaded_modules = []\n\n        for module in self.evaluation_modules:\n            if isinstance(module, str):\n                module = load(module)\n            loaded_modules.append(module)\n        self.evaluation_modules = loaded_modules\n\n        if self.evaluation_module_names is None:", "choices": [{"text": "self.evaluation_module_names = [module.name for module in self.evaluation_modules]"}], "metadata": {"task_id": "huggingface_evaluate/135", "ground_truth": "            self.evaluation_module_names = [module.name for module in self.evaluation_modules]", "fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "context_start_lineno": 735, "line_no": 886, "query_window": {"context": "\nclass CombinedEvaluations:\n    def __init__(self, evaluation_modules, force_prefix=False):\n        from .loading import load  # avoid circular imports\n\n        self.evaluation_module_names = None\n        if isinstance(evaluation_modules, list):\n            self.evaluation_modules = evaluation_modules\n        elif isinstance(evaluation_modules, dict):\n            self.evaluation_modules = list(evaluation_modules.values())\n            self.evaluation_module_names = list(evaluation_modules.keys())\n        loaded_modules = []\n\n        for module in self.evaluation_modules:\n            if isinstance(module, str):\n                module = load(module)\n            loaded_modules.append(module)\n        self.evaluation_modules = loaded_modules\n\n        if self.evaluation_module_names is None:", "metadata": {"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "line_no": 886, "task_id": "huggingface_evaluate/135", "start_line_no": 866, "end_line_no": 886, "window_size": 20, "context_start_lineno": 735, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "    at the base level of the EvaluationModule for easy access.\n    \"\"\"\n\n    def __init__(self, info: EvaluationModuleInfo):\n        self._module_info = info\n\n    @property\n    def info(self):\n        \"\"\":class:`evaluate.EvaluationModuleInfo` object containing all the metadata in the evaluation module.\"\"\"\n        return self._module_info\n\n    @property\n    def name(self) -> str:\n        return self._module_info.module_name\n\n    @property\n    def experiment_id(self) -> Optional[str]:\n        return self._module_info.experiment_id\n\n    @property", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.27722772277227725}, {"context": "    \"\"\"\n\n    def __init__(self, name):\n        self.name = name\n\n    @staticmethod\n    def load(\n        path: str,\n        download_mode: Optional[DownloadMode] = None,\n        revision: Optional[Union[str, Version]] = None,\n        download_config: Optional[DownloadConfig] = None,\n    ):\n        download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)\n        evaluation_module = evaluation_module_factory(\n            path, module_type=None, revision=revision, download_config=download_config, download_mode=download_mode\n        )\n        name = Path(path).stem\n        evaluation_cls = import_main_class(evaluation_module.module_path)\n        evaluation_instance = evaluation_cls(name)\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluation_suite", "__init__.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2767857142857143}, {"context": "            dynamic_modules_path=dynamic_modules_path,\n            module_namespace=self.module_type,\n            name=self.name,\n            download_mode=self.download_mode,\n        )\n        # make the new module to be noticed by the import system\n        importlib.invalidate_caches()\n        return ImportableModule(module_path, hash)\n\n\nclass CachedEvaluationModuleFactory(_EvaluationModuleFactory):\n    \"\"\"\n    Get the module of a metric that has been loaded once already and cached.\n    The script that is loaded from the cache is the most recent one with a matching name.\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        module_type: str = \"metrics\",", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2764227642276423}, {"context": "    module_path: str\n    hash: str\n\n\nclass _EvaluationModuleFactory:\n    def get_module(self) -> ImportableModule:\n        raise NotImplementedError\n\n\nclass LocalEvaluationModuleFactory(_EvaluationModuleFactory):\n    \"\"\"Get the module of a local metric. The metric script is loaded from a local script.\"\"\"\n\n    def __init__(\n        self,\n        path: str,\n        module_type: str = \"metrics\",\n        download_config: Optional[DownloadConfig] = None,\n        download_mode: Optional[DownloadMode] = None,\n        dynamic_modules_path: Optional[str] = None,\n    ):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.27522935779816515}, {"context": "\n        Example:\n\n        ```py\n        >>> from evaluate import evaluator\n        >>> evaluator(\"text-classification\").prepare_metric(\"accuracy\")\n        ```\n        \"\"\"\n        # Prepare metric.\n        if metric is None:\n            if self.default_metric_name is None:\n                raise ValueError(\n                    \"`Evaluator` doesn't specify a default metric. Please specify a valid `metric` argument.\"\n                )\n            metric = load(self.default_metric_name)\n        elif isinstance(metric, str):\n            metric = load(metric)\n\n        return metric\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluator", "base.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.27358490566037735}, {"context": "class CachedEvaluationModuleFactory(_EvaluationModuleFactory):\n    \"\"\"\n    Get the module of a metric that has been loaded once already and cached.\n    The script that is loaded from the cache is the most recent one with a matching name.\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        module_type: str = \"metrics\",\n        dynamic_modules_path: Optional[str] = None,\n    ):\n        self.name = name\n        self.module_type = module_type\n        self.dynamic_modules_path = dynamic_modules_path\n        assert self.name.count(\"/\") == 0\n\n    def get_module(self) -> ImportableModule:\n        dynamic_modules_path = self.dynamic_modules_path if self.dynamic_modules_path else init_dynamic_modules()\n        importable_directory_path = os.path.join(dynamic_modules_path, self.module_type, self.name)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.26229508196721313}, {"context": "            local_imports=local_imports,\n            additional_files=[],\n            dynamic_modules_path=dynamic_modules_path,\n            module_namespace=self.module_type,\n            name=self.name,\n            download_mode=self.download_mode,\n        )\n        # make the new module to be noticed by the import system\n        importlib.invalidate_caches()\n        return ImportableModule(module_path, hash)\n\n\nclass HubEvaluationModuleFactory(_EvaluationModuleFactory):\n    \"\"\"Get the module of a metric from a metric repository on the Hub.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        module_type: str = \"metrics\",\n        revision: Optional[Union[str, Version]] = None,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2619047619047619}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/td3/td3.py\n# --------------------------------------------------\n#             buffer_size,\n#             alpha=0.7,\n#             beta=0.5,\n#             pin_memory=False,\n#             prefetch=make_replay_buffer,\n#             storage=LazyMemmapStorage(\n#                 buffer_size,\n#                 scratch_dir=buffer_scratch_dir,\n#                 device=device,\n#             ),\n#         )\n#     else:\n#         replay_buffer = TensorDictReplayBuffer(\n#             buffer_size,\n#             pin_memory=False,\n#             prefetch=make_replay_buffer,\n#             storage=LazyMemmapStorage(\n#                 buffer_size,\n#                 scratch_dir=buffer_scratch_dir,\n#                 device=device,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb_distributed.py\n# --------------------------------------------------\n#             writer=RoundRobinWriter(),\n#             collate_fn=lambda x: x,\n#         )\n# \n# \n# def construct_buffer_test(rank, name, world_size):\n#     if name == \"TRAINER\":\n#         buffer = _construct_buffer(\"BUFFER\")\n#         assert type(buffer) is torch._C._distributed_rpc.PyRRef\n# \n# \n# def add_to_buffer_remotely_test(rank, name, world_size):\n#     if name == \"TRAINER\":\n#         buffer = _construct_buffer(\"BUFFER\")\n#         res, _ = _add_random_tensor_dict_to_buffer(buffer)\n#         assert type(res) is int\n#         assert res == 0\n# \n# \n# def sample_from_buffer_remotely_returns_correct_tensordict_test(rank, name, world_size):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_speed_distributed.py\n# --------------------------------------------------\n# import torch.distributed.rpc as rpc\n# from tensordict import MemmapTensor\n# \n# parser = configargparse.ArgumentParser()\n# parser.add_argument(\"--rank\", default=-1, type=int)\n# parser.add_argument(\"--world_size\", default=2, type=int)\n# parser.add_argument(\"--tensortype\", default=\"memmap\", type=str)\n# \n# AGENT_NAME = \"main\"\n# OBSERVER_NAME = \"worker{}\"\n# \n# str_init_method = \"tcp://localhost:10000\"\n# options = rpc.TensorPipeRpcBackendOptions(\n#     _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n# )\n# \n# global tensor\n# \n# \n# def send_tensor(t):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#             _storage = _storage.apply(_mem_map_tensor_as_tensor).state_dict()\n#         elif _storage is None:\n#             _storage = {}\n#         else:\n#             raise TypeError(\n#                 f\"Objects of type {type(_storage)} are not supported by LazyTensorStorage.state_dict\"\n#             )\n#         return {\n#             \"_storage\": _storage,\n#             \"initialized\": self.initialized,\n#             \"_len\": self._len,\n#         }\n# \n#     def load_state_dict(self, state_dict):\n#         _storage = copy(state_dict[\"_storage\"])\n#         if isinstance(_storage, torch.Tensor):\n#             if isinstance(self._storage, torch.Tensor):\n#                 _mem_map_tensor_as_tensor(self._storage).copy_(_storage)\n#             elif self._storage is None:\n#                 self._storage = MemmapTensor(_storage)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_td_distributed.py\n# --------------------------------------------------\n#     \"--master_addr\",\n#     type=str,\n#     default=\"localhost\",\n#     help=\"\"\"Address of master, will default to localhost if not provided.\n#     Master must be able to accept network traffic on the address + port.\"\"\",\n# )\n# parser.add_argument(\n#     \"--master_port\",\n#     type=str,\n#     default=\"29500\",\n#     help=\"\"\"Port that master is listening on, will default to 29500 if not\n#     provided. Master must be able to accept network traffic on the host and port.\"\"\",\n# )\n# parser.add_argument(\"--memmap\", action=\"store_true\")\n# parser.add_argument(\"--cuda\", action=\"store_true\")\n# parser.add_argument(\"--shared_mem\", action=\"store_true\")\n# \n# AGENT_NAME = \"main\"\n# OBSERVER_NAME = \"worker{}\"\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_speed_distributed.py\n# --------------------------------------------------\n# \n# str_init_method = \"tcp://localhost:10000\"\n# options = rpc.TensorPipeRpcBackendOptions(\n#     _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n# )\n# \n# global tensor\n# \n# \n# def send_tensor(t):\n#     global tensor\n#     tensor = t\n#     print(tensor)\n# \n# \n# def op_on_tensor(idx):\n#     tensor[idx] += 1\n#     if isinstance(tensor, torch.Tensor):\n#         return tensor\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/distributed/distributed_replay_buffer.py\n# --------------------------------------------------\n# \n# \n# class DummyDataCollectorNode:\n#     \"\"\"Data collector node responsible for collecting experiences used for learning.\n# \n#     Args:\n#         replay_buffer (rpc.RRef): the RRef associated with the construction of the replay buffer\n#     \"\"\"\n# \n#     def __init__(self, replay_buffer: rpc.RRef) -> None:\n#         self.id = rpc.get_worker_info().id\n#         self.replay_buffer = replay_buffer\n#         print(\"Data Collector Node constructed\")\n# \n#     def _submit_random_item_async(self) -> rpc.RRef:\n#         td = TensorDict({\"a\": torch.randint(100, (1,))}, [])\n#         return rpc.remote(\n#             self.replay_buffer.owner(),\n#             ReplayBufferNode.add,\n#             args=(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/distributed/distributed_replay_buffer.py\n# --------------------------------------------------\n#     description=\"RPC Replay Buffer Example\",\n#     formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n# )\n# \n# parser.add_argument(\n#     \"--rank\",\n#     type=int,\n#     default=-1,\n#     help=\"Node Rank [0 = Replay Buffer, 1 = Dummy Trainer, 2+ = Dummy Data Collector]\",\n# )\n# \n# \n# class DummyDataCollectorNode:\n#     \"\"\"Data collector node responsible for collecting experiences used for learning.\n# \n#     Args:\n#         replay_buffer (rpc.RRef): the RRef associated with the construction of the replay buffer\n#     \"\"\"\n# \n#     def __init__(self, replay_buffer: rpc.RRef) -> None:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\"\"\"\nSample latency benchmarking (using RPC)\n======================================\nA rough benchmark of sample latency using different storage types over the network using `torch.rpc`.\nRun this script with --rank=0 and --rank=1 flags set in separate processes - these ranks correspond to the trainer worker and buffer worker respectively, and both need to be initialised.\ne.g. to benchmark LazyMemmapStorage, run the following commands using either two separate shells or multiprocessing.\n    - python3 benchmark_sample_latency_over_rpc.py --rank=0 --storage=LazyMemmapStorage\n    - python3 benchmark_sample_latency_over_rpc.py --rank=1 --storage=LazyMemmapStorage\nThis code is based on examples/distributed/distributed_replay_buffer.py.\n\"\"\"\nimport argparse\nimport os\nimport pickle\nimport sys\nimport time\nimport timeit\nfrom datetime import datetime\n\nimport torch\nimport torch.distributed.rpc as rpc\nfrom tensordict import TensorDict\nfrom torchrl.data.replay_buffers import RemoteTensorDictReplayBuffer\nfrom torchrl.data.replay_buffers.samplers import RandomSampler\nfrom torchrl.data.replay_buffers.storages import (\n    LazyMemmapStorage,\n    LazyTensorStorage,\n    ListStorage,\n)\nfrom torchrl.data.replay_buffers.writers import RoundRobinWriter\n\nRETRY_LIMIT = 2\nRETRY_DELAY_SECS = 3\nREPLAY_BUFFER_NODE = \"ReplayBuffer\"\nTRAINER_NODE = \"Trainer\"\nTENSOR_SIZE = 3 * 86 * 86\nBUFFER_SIZE = 1001\nBATCH_SIZE = 256\nREPEATS = 1000\n\nstorage_options = {\n    \"LazyMemmapStorage\": LazyMemmapStorage,\n    \"LazyTensorStorage\": LazyTensorStorage,\n    \"ListStorage\": ListStorage,\n}\n\nstorage_arg_options = {\n    \"LazyMemmapStorage\": {\"scratch_dir\": \"/tmp/\", \"device\": torch.device(\"cpu\")},\n    \"LazyTensorStorage\": {},\n    \"ListStorage\": {},\n}\nparser = argparse.ArgumentParser(\n    description=\"RPC Replay Buffer Example\",\n    formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n)\n\nparser.add_argument(\n    \"--rank\",\n    type=int,\n    default=-1,\n    help=\"Node Rank [0 = Replay Buffer, 1 = Dummy Trainer, 2+ = Dummy Data Collector]\",\n)\n\nparser.add_argument(\n    \"--storage\",\n    type=str,", "choices": [{"text": "default=\"LazyMemmapStorage\", choices=list(storage_options.keys()),"}], "metadata": {"task_id": "pytorch_rl/9", "ground_truth": "    default=\"LazyMemmapStorage\",", "fpath_tuple": ["pytorch_rl", "benchmarks", "storage", "benchmark_sample_latency_over_rpc.py"], "context_start_lineno": 0, "line_no": 70, "query_window": {"context": "storage_arg_options = {\n    \"LazyMemmapStorage\": {\"scratch_dir\": \"/tmp/\", \"device\": torch.device(\"cpu\")},\n    \"LazyTensorStorage\": {},\n    \"ListStorage\": {},\n}\nparser = argparse.ArgumentParser(\n    description=\"RPC Replay Buffer Example\",\n    formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n)\n\nparser.add_argument(\n    \"--rank\",\n    type=int,\n    default=-1,\n    help=\"Node Rank [0 = Replay Buffer, 1 = Dummy Trainer, 2+ = Dummy Data Collector]\",\n)\n\nparser.add_argument(\n    \"--storage\",\n    type=str,", "metadata": {"fpath_tuple": ["pytorch_rl", "benchmarks", "storage", "benchmark_sample_latency_over_rpc.py"], "line_no": 70, "task_id": "pytorch_rl/9", "start_line_no": 50, "end_line_no": 70, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "from torchrl.data.replay_buffers.storages import LazyMemmapStorage\nfrom torchrl.data.replay_buffers.utils import accept_remote_rref_invocation\nfrom torchrl.data.replay_buffers.writers import RoundRobinWriter\n\nRETRY_LIMIT = 2\nRETRY_DELAY_SECS = 3\nREPLAY_BUFFER_NODE = \"ReplayBuffer\"\nTRAINER_NODE = \"Trainer\"\n\nparser = argparse.ArgumentParser(\n    description=\"RPC Replay Buffer Example\",\n    formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n)\n\nparser.add_argument(\n    \"--rank\",\n    type=int,\n    default=-1,\n    help=\"Node Rank [0 = Replay Buffer, 1 = Dummy Trainer, 2+ = Dummy Data Collector]\",\n)", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "distributed", "distributed_replay_buffer.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.484375}, {"context": "    description=\"RPC Replay Buffer Example\",\n    formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n)\n\nparser.add_argument(\n    \"--rank\",\n    type=int,\n    default=-1,\n    help=\"Node Rank [0 = Replay Buffer, 1 = Dummy Trainer, 2+ = Dummy Data Collector]\",\n)\n\n\nclass DummyDataCollectorNode:\n    \"\"\"Data collector node responsible for collecting experiences used for learning.\n\n    Args:\n        replay_buffer (rpc.RRef): the RRef associated with the construction of the replay buffer\n    \"\"\"\n\n    def __init__(self, replay_buffer: rpc.RRef) -> None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "distributed", "distributed_replay_buffer.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4380165289256198}, {"context": "import torch.distributed.rpc as rpc\nfrom tensordict import MemmapTensor\n\nparser = configargparse.ArgumentParser()\nparser.add_argument(\"--rank\", default=-1, type=int)\nparser.add_argument(\"--world_size\", default=2, type=int)\nparser.add_argument(\"--tensortype\", default=\"memmap\", type=str)\n\nAGENT_NAME = \"main\"\nOBSERVER_NAME = \"worker{}\"\n\nstr_init_method = \"tcp://localhost:10000\"\noptions = rpc.TensorPipeRpcBackendOptions(\n    _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n)\n\nglobal tensor\n\n\ndef send_tensor(t):", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_speed_distributed.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.23972602739726026}, {"context": "import torch.distributed.rpc as rpc\nfrom tensordict import TensorDict\nfrom tensordict.memmap import set_transfer_ownership\n\nparser = configargparse.ArgumentParser()\nparser.add_argument(\"--world_size\", default=2, type=int)\nparser.add_argument(\"--rank\", default=-1, type=int)\nparser.add_argument(\"--task\", default=1, type=int)\nparser.add_argument(\"--rank_var\", default=\"SLURM_JOB_ID\", type=str)\nparser.add_argument(\n    \"--master_addr\",\n    type=str,\n    default=\"localhost\",\n    help=\"\"\"Address of master, will default to localhost if not provided.\n    Master must be able to accept network traffic on the address + port.\"\"\",\n)\nparser.add_argument(\n    \"--master_port\",\n    type=str,\n    default=\"29500\",", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_td_distributed.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.22916666666666666}, {"context": "            if self.scratch_dir[-1] != \"/\":\n                self.scratch_dir += \"/\"\n        self.device = device if device else torch.device(\"cpu\")\n        self._len = 0\n\n    def state_dict(self) -> Dict[str, Any]:\n        _storage = self._storage\n        if isinstance(_storage, torch.Tensor):\n            _storage = _mem_map_tensor_as_tensor(_storage)\n        elif isinstance(_storage, TensorDictBase):\n            _storage = _storage.apply(_mem_map_tensor_as_tensor).state_dict()\n        elif _storage is None:\n            _storage = {}\n        else:\n            raise TypeError(\n                f\"Objects of type {type(_storage)} are not supported by LazyTensorStorage.state_dict\"\n            )\n        return {\n            \"_storage\": _storage,\n            \"initialized\": self.initialized,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2152777777777778}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport time\n\nimport configargparse\nimport torch\nimport torch.distributed.rpc as rpc\nfrom tensordict import MemmapTensor\n\nparser = configargparse.ArgumentParser()\nparser.add_argument(\"--rank\", default=-1, type=int)\nparser.add_argument(\"--world_size\", default=2, type=int)\nparser.add_argument(\"--tensortype\", default=\"memmap\", type=str)\n\nAGENT_NAME = \"main\"\nOBSERVER_NAME = \"worker{}\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_speed_distributed.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20945945945945946}, {"context": "RETRY_BACKOFF = 3\n\n\nclass ReplayBufferNode(RemoteTensorDictReplayBuffer):\n    def __init__(self, capacity: int):\n        super().__init__(\n            storage=LazyMemmapStorage(\n                max_size=capacity, scratch_dir=\"/tmp/\", device=torch.device(\"cpu\")\n            ),\n            sampler=RandomSampler(),\n            writer=RoundRobinWriter(),\n            collate_fn=lambda x: x,\n        )\n\n\ndef construct_buffer_test(rank, name, world_size):\n    if name == \"TRAINER\":\n        buffer = _construct_buffer(\"BUFFER\")\n        assert type(buffer) is torch._C._distributed_rpc.PyRRef\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb_distributed.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20754716981132076}, {"context": "\ndef make_replay_buffer(\n    prb=False,\n    buffer_size=1000000,\n    buffer_scratch_dir=\"/tmp/\",\n    device=\"cpu\",\n    make_replay_buffer=3,\n):\n    if prb:\n        replay_buffer = TensorDictPrioritizedReplayBuffer(\n            buffer_size,\n            alpha=0.7,\n            beta=0.5,\n            pin_memory=False,\n            prefetch=make_replay_buffer,\n            storage=LazyMemmapStorage(\n                buffer_size,\n                scratch_dir=buffer_scratch_dir,\n                device=device,\n            ),", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "td3", "td3.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20491803278688525}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/code_eval/code_eval.py\n# --------------------------------------------------\n# (https://arxiv.org/abs/2107.03374).\n# \"\"\"\n# \n# \n# _KWARGS_DESCRIPTION = \"\"\"\n# Calculates how good are predictions given some references, using certain scores\n# Args:\n#     predictions: list of candidates to evaluate. Each candidates should be a list\n#         of strings with several code candidates to solve the problem.\n#     references: a list with a test for each prediction. Each test should evaluate the\n#         correctness of a code candidate.\n#     k: number of code candidates to consider in the evaluation (Default: [1, 10, 100])\n#     num_workers: number of workers used to evaluate the canidate programs (Default: 4).\n#     timeout:\n# Returns:\n#     pass_at_k: dict with pass rates for each k\n#     results: dict with granular results of each unittest\n# Examples:\n#     >>> code_eval = evaluate.load(\"code_eval\")\n#     >>> test_cases = [\"assert add(2,3)==5\"]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/code_eval/code_eval.py\n# --------------------------------------------------\n#         correctness of a code candidate.\n#     k: number of code candidates to consider in the evaluation (Default: [1, 10, 100])\n#     num_workers: number of workers used to evaluate the canidate programs (Default: 4).\n#     timeout:\n# Returns:\n#     pass_at_k: dict with pass rates for each k\n#     results: dict with granular results of each unittest\n# Examples:\n#     >>> code_eval = evaluate.load(\"code_eval\")\n#     >>> test_cases = [\"assert add(2,3)==5\"]\n#     >>> candidates = [[\"def add(a,b): return a*b\", \"def add(a, b): return a+b\"]]\n#     >>> pass_at_k, results = code_eval.compute(references=test_cases, predictions=candidates, k=[1, 2])\n#     >>> print(pass_at_k)\n#     {'pass@1': 0.5, 'pass@2': 1.0}\n# \"\"\"\n# \n# \n# _WARNING = \"\"\"\n# ################################################################################\n#                                   !!!WARNING!!!\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/sacrebleu/sacrebleu.py\n# --------------------------------------------------\n#     references (`list` of `list` of `str`): A list of lists of references. The contents of the first sub-list are the references for the first prediction, the contents of the second sub-list are for the second prediction, etc. Note that there must be the same number of references for each prediction (i.e. all sub-lists must be of the same length).\n#     smooth_method (`str`): The smoothing method to use, defaults to `'exp'`. Possible values are:\n#         - `'none'`: no smoothing\n#         - `'floor'`: increment zero counts\n#         - `'add-k'`: increment num/denom by k for n>1\n#         - `'exp'`: exponential decay\n#     smooth_value (`float`): The smoothing value. Only valid when `smooth_method='floor'` (in which case `smooth_value` defaults to `0.1`) or `smooth_method='add-k'` (in which case `smooth_value` defaults to `1`).\n#     tokenize (`str`): Tokenization method to use for BLEU. If not provided, defaults to `'zh'` for Chinese, `'ja-mecab'` for Japanese and `'13a'` (mteval) otherwise. Possible values are:\n#         - `'none'`: No tokenization.\n#         - `'zh'`: Chinese tokenization.\n#         - `'13a'`: mimics the `mteval-v13a` script from Moses.\n#         - `'intl'`: International tokenization, mimics the `mteval-v14` script from Moses\n#         - `'char'`: Language-agnostic character-level tokenization.\n#         - `'ja-mecab'`: Japanese tokenization. Uses the [MeCab tokenizer](https://pypi.org/project/mecab-python3).\n#     lowercase (`bool`): If `True`, lowercases the input, enabling case-insensitivity. Defaults to `False`.\n#     force (`bool`): If `True`, insists that your tokenized input is actually detokenized. Defaults to `False`.\n#     use_effective_order (`bool`): If `True`, stops including n-gram orders for which precision is 0. This should be `True`, if sentence-level BLEU will be computed. Defaults to `False`.\n# \n# Returns:\n#     'score': BLEU score,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/rouge/rouge.py\n# --------------------------------------------------\n# \n# _KWARGS_DESCRIPTION = \"\"\"\n# Calculates average rouge scores for a list of hypotheses and references\n# Args:\n#     predictions: list of predictions to score. Each prediction\n#         should be a string with tokens separated by spaces.\n#     references: list of reference for each prediction. Each\n#         reference should be a string with tokens separated by spaces.\n#     rouge_types: A list of rouge types to calculate.\n#         Valid names:\n#         `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n#         `\"rougeL\"`: Longest common subsequence based scoring.\n#         `\"rougeLsum\"`: rougeLsum splits text using `\"\\n\"`.\n#         See details in https://github.com/huggingface/datasets/issues/617\n#     use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n#     use_aggregator: Return aggregates if this is set to True\n# Returns:\n#     rouge1: rouge_1 (f1),\n#     rouge2: rouge_2 (f1),\n#     rougeL: rouge_l (f1),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/rouge/rouge.py\n# --------------------------------------------------\n#         `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n#         `\"rougeL\"`: Longest common subsequence based scoring.\n#         `\"rougeLsum\"`: rougeLsum splits text using `\"\\n\"`.\n#         See details in https://github.com/huggingface/datasets/issues/617\n#     use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n#     use_aggregator: Return aggregates if this is set to True\n# Returns:\n#     rouge1: rouge_1 (f1),\n#     rouge2: rouge_2 (f1),\n#     rougeL: rouge_l (f1),\n#     rougeLsum: rouge_lsum (f1)\n# Examples:\n# \n#     >>> rouge = evaluate.load('rouge')\n#     >>> predictions = [\"hello there\", \"general kenobi\"]\n#     >>> references = [\"hello there\", \"general kenobi\"]\n#     >>> results = rouge.compute(predictions=predictions, references=references)\n#     >>> print(results)\n#     {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n# \"\"\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# coding=utf-8\n# Copyright 2020 The HuggingFace Evaluate Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\" MAUVE metric from https://github.com/krishnap25/mauve. \"\"\"\n\nimport datasets\nimport faiss  # Here to have a nice missing dependency error message early on\nimport numpy  # Here to have a nice missing dependency error message early on\nimport requests  # Here to have a nice missing dependency error message early on\nimport sklearn  # Here to have a nice missing dependency error message early on\nimport tqdm  # Here to have a nice missing dependency error message early on\nfrom mauve import compute_mauve  # From: mauve-text\n\nimport evaluate\n\n\n_CITATION = \"\"\"\\\n@inproceedings{pillutla-etal:mauve:neurips2021,\n  title={MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers},\n  author={Pillutla, Krishna and Swayamdipta, Swabha and Zellers, Rowan and Thickstun, John and Welleck, Sean and Choi, Yejin and Harchaoui, Zaid},\n  booktitle = {NeurIPS},\n  year      = {2021}\n}\n\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nMAUVE is a library built on PyTorch and HuggingFace Transformers to measure the gap between neural text and human text with the eponymous MAUVE measure.\n\nMAUVE summarizes both Type I and Type II errors measured softly using Kullback\u2013Leibler (KL) divergences.\n\nFor details, see the MAUVE paper: https://arxiv.org/abs/2102.01454 (Neurips, 2021).\n\nThis metrics is a wrapper around the official implementation of MAUVE:\nhttps://github.com/krishnap25/mauve\n\"\"\"\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates MAUVE scores between two lists of generated text and reference text.\nArgs:\n    predictions: list of generated text to score. Each predictions\n        should be a string with tokens separated by spaces.\n    references: list of reference for each prediction. Each\n        reference should be a string with tokens separated by spaces.\nOptional Args:\n    num_buckets: the size of the histogram to quantize P and Q. Options: 'auto' (default) or an integer\n    pca_max_data: the number data points to use for PCA dimensionality reduction prior to clustering. If -1, use all the data. Default -1\n    kmeans_explained_var: amount of variance of the data to keep in dimensionality reduction by PCA. Default 0.9\n    kmeans_num_redo: number of times to redo k-means clustering (the best objective is kept). Default 5\n    kmeans_max_iter: maximum number of k-means iterations. Default 500\n    featurize_model_name: name of the model from which features are obtained. Default 'gpt2-large' Use one of ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'].", "choices": [{"text": "def mauve_metric(predictions, references, num_buckets='auto', pca_max_data=-1, kmeans_explained_var=0.9, kmeans_num_redo=5, kmeans_max_iter=500, featurize_model_name='gpt2-large'):"}], "metadata": {"task_id": "huggingface_evaluate/7", "ground_truth": "    device_id: Device for featurization. Supply a GPU id (e.g. 0 or 3) to use GPU. If no GPU with this id is found, use CPU", "fpath_tuple": ["huggingface_evaluate", "metrics", "mauve", "mauve.py"], "context_start_lineno": 0, "line_no": 62, "query_window": {"context": "For details, see the MAUVE paper: https://arxiv.org/abs/2102.01454 (Neurips, 2021).\n\nThis metrics is a wrapper around the official implementation of MAUVE:\nhttps://github.com/krishnap25/mauve\n\"\"\"\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates MAUVE scores between two lists of generated text and reference text.\nArgs:\n    predictions: list of generated text to score. Each predictions\n        should be a string with tokens separated by spaces.\n    references: list of reference for each prediction. Each\n        reference should be a string with tokens separated by spaces.\nOptional Args:\n    num_buckets: the size of the histogram to quantize P and Q. Options: 'auto' (default) or an integer\n    pca_max_data: the number data points to use for PCA dimensionality reduction prior to clustering. If -1, use all the data. Default -1\n    kmeans_explained_var: amount of variance of the data to keep in dimensionality reduction by PCA. Default 0.9\n    kmeans_num_redo: number of times to redo k-means clustering (the best objective is kept). Default 5\n    kmeans_max_iter: maximum number of k-means iterations. Default 500\n    featurize_model_name: name of the model from which features are obtained. Default 'gpt2-large' Use one of ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'].", "metadata": {"fpath_tuple": ["huggingface_evaluate", "metrics", "mauve", "mauve.py"], "line_no": 62, "task_id": "huggingface_evaluate/7", "start_line_no": 42, "end_line_no": 62, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates average rouge scores for a list of hypotheses and references\nArgs:\n    predictions: list of predictions to score. Each prediction\n        should be a string with tokens separated by spaces.\n    references: list of reference for each prediction. Each\n        reference should be a string with tokens separated by spaces.\n    rouge_types: A list of rouge types to calculate.\n        Valid names:\n        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n        `\"rougeL\"`: Longest common subsequence based scoring.\n        `\"rougeLsum\"`: rougeLsum splits text using `\"\\n\"`.\n        See details in https://github.com/huggingface/datasets/issues/617\n    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n    use_aggregator: Return aggregates if this is set to True\nReturns:\n    rouge1: rouge_1 (f1),\n    rouge2: rouge_2 (f1),\n    rougeL: rouge_l (f1),", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "rouge", "rouge.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.24}, {"context": "_DESCRIPTION = \"\"\"\\\nROUGE, or Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics and a software package used for\nevaluating automatic summarization and machine translation software in natural language processing.\nThe metrics compare an automatically produced summary or translation against a reference or a set of references (human-produced) summary or translation.\n\nNote that ROUGE is case insensitive, meaning that upper case letters are treated the same way as lower case letters.\n\nThis metrics is a wrapper around Google Research reimplementation of ROUGE:\nhttps://github.com/google-research/google-research/tree/master/rouge\n\"\"\"\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates average rouge scores for a list of hypotheses and references\nArgs:\n    predictions: list of predictions to score. Each prediction\n        should be a string with tokens separated by spaces.\n    references: list of reference for each prediction. Each\n        reference should be a string with tokens separated by spaces.\n    rouge_types: A list of rouge types to calculate.\n        Valid names:", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "rouge", "rouge.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2388663967611336}, {"context": "\nSee the [README.md] file at https://github.com/mjpost/sacreBLEU for more information.\n\"\"\"\n\n_KWARGS_DESCRIPTION = \"\"\"\nProduces BLEU scores along with its sufficient statistics\nfrom a source against one or more references.\n\nArgs:\n    predictions (`list` of `str`): list of translations to score. Each translation should be tokenized into a list of tokens.\n    references (`list` of `list` of `str`): A list of lists of references. The contents of the first sub-list are the references for the first prediction, the contents of the second sub-list are for the second prediction, etc. Note that there must be the same number of references for each prediction (i.e. all sub-lists must be of the same length).\n    smooth_method (`str`): The smoothing method to use, defaults to `'exp'`. Possible values are:\n        - `'none'`: no smoothing\n        - `'floor'`: increment zero counts\n        - `'add-k'`: increment num/denom by k for n>1\n        - `'exp'`: exponential decay\n    smooth_value (`float`): The smoothing value. Only valid when `smooth_method='floor'` (in which case `smooth_value` defaults to `0.1`) or `smooth_method='add-k'` (in which case `smooth_value` defaults to `1`).\n    tokenize (`str`): Tokenization method to use for BLEU. If not provided, defaults to `'zh'` for Chinese, `'ja-mecab'` for Japanese and `'13a'` (mteval) otherwise. Possible values are:\n        - `'none'`: No tokenization.\n        - `'zh'`: Chinese tokenization.", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "sacrebleu", "sacrebleu.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.21908127208480566}, {"context": "(https://arxiv.org/abs/2107.03374).\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good are predictions given some references, using certain scores\nArgs:\n    predictions: list of candidates to evaluate. Each candidates should be a list\n        of strings with several code candidates to solve the problem.\n    references: a list with a test for each prediction. Each test should evaluate the\n        correctness of a code candidate.\n    k: number of code candidates to consider in the evaluation (Default: [1, 10, 100])\n    num_workers: number of workers used to evaluate the canidate programs (Default: 4).\n    timeout:\nReturns:\n    pass_at_k: dict with pass rates for each k\n    results: dict with granular results of each unittest\nExamples:\n    >>> code_eval = evaluate.load(\"code_eval\")\n    >>> test_cases = [\"assert add(2,3)==5\"]", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "code_eval.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2190082644628099}, {"context": "      year={2021},\n      eprint={2107.03374},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nThis metric implements the evaluation harness for the HumanEval problem solving dataset\ndescribed in the paper \"Evaluating Large Language Models Trained on Code\"\n(https://arxiv.org/abs/2107.03374).\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good are predictions given some references, using certain scores\nArgs:\n    predictions: list of candidates to evaluate. Each candidates should be a list\n        of strings with several code candidates to solve the problem.\n    references: a list with a test for each prediction. Each test should evaluate the", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "code_eval.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2076271186440678}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_shared.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# import argparse\n# import time\n# import warnings\n# \n# import pytest\n# import torch\n# from tensordict import TensorDict\n# from torch import multiprocessing as mp\n# \n# \n# class TestShared:\n#     @staticmethod\n#     def remote_process(command_pipe_child, command_pipe_parent, tensordict):\n#         command_pipe_parent.close()\n#         assert tensordict.is_shared()\n#         t0 = time.time()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/td3/td3.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# \n# import hydra\n# \n# import numpy as np\n# import torch\n# import torch.cuda\n# import tqdm\n# \n# from torch import nn, optim\n# from torchrl.collectors import MultiSyncDataCollector\n# from torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\n# \n# from torchrl.data.replay_buffers.storages import LazyMemmapStorage\n# from torchrl.envs import (\n#     Compose,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/record/loggers/wandb.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import warnings\n# from typing import Optional\n# \n# from torch import Tensor\n# \n# from .common import Logger\n# \n# \n# try:\n#     import wandb\n# \n#     _has_wandb = True\n# except ImportError:\n#     _has_wandb = False\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_loggers.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import argparse\n# import os\n# import os.path\n# import pathlib\n# import tempfile\n# from time import sleep\n# \n# import pytest\n# import torch\n# from torchrl.record.loggers import (\n#     CSVLogger,\n#     MLFlowLogger,\n#     TensorboardLogger,\n#     WandbLogger,\n# )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# setup.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# import argparse\n# import distutils.command.clean\n# import glob\n# import os\n# import shutil\n# import subprocess\n# import sys\n# from datetime import date\n# from pathlib import Path\n# from typing import List\n# \n# from setuptools import find_packages, setup\n# from torch.utils.cpp_extension import BuildExtension, CppExtension\n# \n# cwd = os.path.dirname(os.path.abspath(__file__))\n# try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_recipe.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import argparse\n# \n# import pytest\n# \n# \n# if __name__ == \"__main__\":\n#     args, unknown = argparse.ArgumentParser().parse_known_args()\n#     pytest.main([__file__, \"--capture\", \"no\", \"--exitfirst\"] + unknown)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/collectors/collectors.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import _pickle\n# import abc\n# import inspect\n# import os\n# import queue\n# import time\n# from collections import OrderedDict\n# from copy import deepcopy\n# from multiprocessing import connection, queues\n# from textwrap import indent\n# from typing import Any, Callable, Dict, Iterator, Optional, Sequence, Tuple, Union\n# \n# import numpy as np\n# import torch\n# import torch.nn as nn\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_td_distributed.py\n# examples/torchrl_features/memmap_speed_distributed.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import time\n# \n# import configargparse\n# import torch\n# import torch.distributed.rpc as rpc\n# from tensordict import TensorDict\n# from tensordict.memmap import set_transfer_ownership\n# \n# parser = configargparse.ArgumentParser()\n# parser.add_argument(\"--world_size\", default=2, type=int)\n# parser.add_argument(\"--rank\", default=-1, type=int)\n# parser.add_argument(\"--task\", default=1, type=int)\n# parser.add_argument(\"--rank_var\", default=\"SLURM_JOB_ID\", type=str)\n# parser.add_argument(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb_distributed.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import sys\n# import time\n# \n# import pytest\n# import torch\n# import torch.distributed.rpc as rpc\n# import torch.multiprocessing as mp\n# from tensordict.tensordict import TensorDict\n# from torchrl.data.replay_buffers import RemoteTensorDictReplayBuffer\n# from torchrl.data.replay_buffers.samplers import RandomSampler\n# from torchrl.data.replay_buffers.storages import LazyMemmapStorage\n# from torchrl.data.replay_buffers.writers import RoundRobinWriter\n# \n# RETRY_COUNT = 3\n# --------------------------------------------------\n# the below code fragment can be found in:\n# build_tools/__init__.py\n# torchrl/envs/libs/__init__.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport distutils.sysconfig\nimport os", "choices": [{"text": ".path.abspath(__file__)"}], "metadata": {"task_id": "pytorch_rl/46", "ground_truth": "import platform", "fpath_tuple": ["pytorch_rl", "build_tools", "setup_helpers", "extension.py"], "context_start_lineno": 0, "line_no": 7, "query_window": {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport distutils.sysconfig\nimport os", "metadata": {"fpath_tuple": ["pytorch_rl", "build_tools", "setup_helpers", "extension.py"], "line_no": 7, "task_id": "pytorch_rl/46", "start_line_no": 0, "end_line_no": 7, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.", "metadata": [{"fpath_tuple": ["pytorch_rl", "build_tools", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 4, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}, {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 4, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.8461538461538461}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport sys\nimport time\n\nimport pytest", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.813953488372093}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport time\n\nimport configargparse\nimport torch", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_td_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}, {"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_speed_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7954545454545454}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport _pickle\nimport abc\nimport inspect\nimport os\nimport queue", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "collectors", "collectors.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7777777777777778}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport argparse\n\nimport pytest\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_recipe.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7727272727272727}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport argparse\nimport distutils.command.clean\nimport glob\nimport os\nimport shutil\nimport subprocess", "metadata": [{"fpath_tuple": ["pytorch_rl", "setup.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7708333333333334}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport argparse\nimport os\nimport os.path\nimport pathlib\nimport tempfile", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_loggers.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7608695652173914}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport warnings\nfrom typing import Optional\n\nfrom torch import Tensor", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "record", "loggers", "wandb.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7446808510638298}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\nimport hydra\n\nimport numpy as np\nimport torch", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "td3", "td3.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7391304347826086}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport argparse\nimport time\nimport warnings\n\nimport pytest\nimport torch", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_shared.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7391304347826086}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/trec_eval/trec_eval.py\n# --------------------------------------------------\n# _KWARGS_DESCRIPTION = \"\"\"\n# Calculates TREC evaluation scores based on a run and qrel.\n# Args:\n#     predictions: list containing a single run.\n#     references: list containing a single qrel.\n# Returns:\n#     dict: TREC evaluation scores.\n# Examples:\n#     >>> trec = evaluate.load(\"trec_eval\")\n#     >>> qrel = {\n#     ...     \"query\": [0],\n#     ...     \"q0\": [\"0\"],\n#     ...     \"docid\": [\"doc_1\"],\n#     ...     \"rel\": [2]\n#     ... }\n#     >>> run = {\n#     ...     \"query\": [0, 0],\n#     ...     \"q0\": [\"q0\", \"q0\"],\n#     ...     \"docid\": [\"doc_2\", \"doc_1\"],\n#     ...     \"rank\": [0, 1],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/code_eval/code_eval.py\n# --------------------------------------------------\n#         correctness of a code candidate.\n#     k: number of code candidates to consider in the evaluation (Default: [1, 10, 100])\n#     num_workers: number of workers used to evaluate the canidate programs (Default: 4).\n#     timeout:\n# Returns:\n#     pass_at_k: dict with pass rates for each k\n#     results: dict with granular results of each unittest\n# Examples:\n#     >>> code_eval = evaluate.load(\"code_eval\")\n#     >>> test_cases = [\"assert add(2,3)==5\"]\n#     >>> candidates = [[\"def add(a,b): return a*b\", \"def add(a, b): return a+b\"]]\n#     >>> pass_at_k, results = code_eval.compute(references=test_cases, predictions=candidates, k=[1, 2])\n#     >>> print(pass_at_k)\n#     {'pass@1': 0.5, 'pass@2': 1.0}\n# \"\"\"\n# \n# \n# _WARNING = \"\"\"\n# ################################################################################\n#                                   !!!WARNING!!!\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/charcut_mt/charcut_mt.py\n# --------------------------------------------------\n# search for longest common substrings, combined with a length-based threshold that limits short and noisy character\n# matches. As a similarity metric this is not new, but to the best of our knowledge it was never applied to highlighting\n# and scoring of MT outputs. It has the neat effect of keeping character-based differences readable by humans.\"\"\"\n# \n# _KWARGS_DESCRIPTION = \"\"\"\n# Calculates how good predictions are given some references.\n# Args:\n#     predictions: a list of predictions to score. Each prediction should be a string with\n#      tokens separated by spaces.\n#     references: a list of reference for each prediction. Each reference should be a string with\n#      tokens separated by spaces.\n# Returns:\n#     charcut_mt: the CharCut score\n# Examples:\n#     >>> charcut_mt = evaluate.load(\"charcut_mt\")\n#     >>> preds = [\"this week the saudis denied information published in the new york times\",\n#     ...          \"this is in fact an estimate\"]\n#     >>> refs = [\"saudi arabia denied this week information published in the american new york times\",\n#     ...         \"this is actually an estimate\"]\n#     >>> charcut_mt.compute(references=refs, predictions=preds)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# templates/{{ cookiecutter.module_slug }}/{{ cookiecutter.module_slug }}.py\n# --------------------------------------------------\n#     references: list of reference for each prediction. Each\n#         reference should be a string with tokens separated by spaces.\n# Returns:\n#     accuracy: description of the first score,\n#     another_score: description of the second score,\n# Examples:\n#     Examples should be written in doctest format, and should illustrate how\n#     to use the function.\n# \n#     >>> my_new_module = evaluate.load(\"my_new_module\")\n#     >>> results = my_new_module.compute(references=[0, 1], predictions=[0, 1])\n#     >>> print(results)\n#     {'accuracy': 1.0}\n# \"\"\"\n# \n# # TODO: Define external resources urls if needed\n# BAD_WORDS_URL = \"http://url/to/external/resource/bad_words.txt\"\n# \n# \n# @evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# templates/{{ cookiecutter.module_slug }}/{{ cookiecutter.module_slug }}.py\n# --------------------------------------------------\n# This new module is designed to solve this great ML task and is crafted with a lot of care.\n# \"\"\"\n# \n# \n# # TODO: Add description of the arguments of the module here\n# _KWARGS_DESCRIPTION = \"\"\"\n# Calculates how good are predictions given some references, using certain scores\n# Args:\n#     predictions: list of predictions to score. Each predictions\n#         should be a string with tokens separated by spaces.\n#     references: list of reference for each prediction. Each\n#         reference should be a string with tokens separated by spaces.\n# Returns:\n#     accuracy: description of the first score,\n#     another_score: description of the second score,\n# Examples:\n#     Examples should be written in doctest format, and should illustrate how\n#     to use the function.\n# \n#     >>> my_new_module = evaluate.load(\"my_new_module\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/competition_math/competition_math.py\n# --------------------------------------------------\n# It first canonicalizes the inputs (e.g., converting \"1/2\" to \"\\\\frac{1}{2}\") and then computes accuracy.\n# \"\"\"\n# \n# \n# _KWARGS_DESCRIPTION = r\"\"\"\n# Calculates accuracy after canonicalizing inputs.\n# \n# Args:\n#     predictions: list of predictions to score. Each prediction\n#         is a string that contains natural language and LaTex.\n#     references: list of reference for each prediction. Each\n#         reference is a string that contains natural language\n#         and LaTex.\n# Returns:\n#     accuracy: accuracy after canonicalizing inputs\n#         (e.g., converting \"1/2\" to \"\\\\frac{1}{2}\")\n# \n# Examples:\n#     >>> metric = evaluate.load(\"competition_math\")\n#     >>> results = metric.compute(references=[\"\\\\frac{1}{2}\"], predictions=[\"1/2\"])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/code_eval/code_eval.py\n# --------------------------------------------------\n# (https://arxiv.org/abs/2107.03374).\n# \"\"\"\n# \n# \n# _KWARGS_DESCRIPTION = \"\"\"\n# Calculates how good are predictions given some references, using certain scores\n# Args:\n#     predictions: list of candidates to evaluate. Each candidates should be a list\n#         of strings with several code candidates to solve the problem.\n#     references: a list with a test for each prediction. Each test should evaluate the\n#         correctness of a code candidate.\n#     k: number of code candidates to consider in the evaluation (Default: [1, 10, 100])\n#     num_workers: number of workers used to evaluate the canidate programs (Default: 4).\n#     timeout:\n# Returns:\n#     pass_at_k: dict with pass rates for each k\n#     results: dict with granular results of each unittest\n# Examples:\n#     >>> code_eval = evaluate.load(\"code_eval\")\n#     >>> test_cases = [\"assert add(2,3)==5\"]\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2022 The HuggingFace Datasets Authors and the current metric script contributor.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"FrugalScore metric.\"\"\"\n\nimport datasets\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n\nimport evaluate\n\n\n_CITATION = \"\"\"\\\n@article{eddine2021frugalscore,\n  title={FrugalScore: Learning Cheaper, Lighter and Faster Evaluation Metrics for Automatic Text Generation},\n  author={Eddine, Moussa Kamal and Shang, Guokan and Tixier, Antoine J-P and Vazirgiannis, Michalis},\n  journal={arXiv preprint arXiv:2110.08559},\n  year={2021}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nFrugalScore is a reference-based metric for NLG models evaluation. It is based on a distillation approach that allows to learn a fixed, low cost version of any expensive NLG metric, while retaining most of its original performance.\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good are predictions given some references, using certain scores.\nArgs:\n    predictions (list of str): list of predictions to score. Each predictions\n        should be a string.\n    references (list of str): list of reference for each prediction. Each\n        reference should be a string.\n    batch_size (int): the batch size for predictions.", "choices": [{"text": "The batch size for predictions."}], "metadata": {"task_id": "huggingface_evaluate/182", "ground_truth": "    max_length (int): maximum sequence length.", "fpath_tuple": ["huggingface_evaluate", "metrics", "frugalscore", "frugalscore.py"], "context_start_lineno": 0, "line_no": 44, "query_window": {"context": "  title={FrugalScore: Learning Cheaper, Lighter and Faster Evaluation Metrics for Automatic Text Generation},\n  author={Eddine, Moussa Kamal and Shang, Guokan and Tixier, Antoine J-P and Vazirgiannis, Michalis},\n  journal={arXiv preprint arXiv:2110.08559},\n  year={2021}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nFrugalScore is a reference-based metric for NLG models evaluation. It is based on a distillation approach that allows to learn a fixed, low cost version of any expensive NLG metric, while retaining most of its original performance.\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good are predictions given some references, using certain scores.\nArgs:\n    predictions (list of str): list of predictions to score. Each predictions\n        should be a string.\n    references (list of str): list of reference for each prediction. Each\n        reference should be a string.\n    batch_size (int): the batch size for predictions.", "metadata": {"fpath_tuple": ["huggingface_evaluate", "metrics", "frugalscore", "frugalscore.py"], "line_no": 44, "task_id": "huggingface_evaluate/182", "start_line_no": 24, "end_line_no": 44, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "      year={2021},\n      eprint={2107.03374},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nThis metric implements the evaluation harness for the HumanEval problem solving dataset\ndescribed in the paper \"Evaluating Large Language Models Trained on Code\"\n(https://arxiv.org/abs/2107.03374).\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good are predictions given some references, using certain scores\nArgs:\n    predictions: list of candidates to evaluate. Each candidates should be a list\n        of strings with several code candidates to solve the problem.\n    references: a list with a test for each prediction. Each test should evaluate the", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "code_eval.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3}, {"context": "    and Dawn Song\n    and Jacob Steinhardt},\n  journal={arXiv preprint arXiv:2103.03874},\n  year={2021}\n}\n\"\"\"\n\n\n_DESCRIPTION = \"\"\"\\\nThis metric is used to assess performance on the Mathematics Aptitude Test of Heuristics (MATH) dataset.\nIt first canonicalizes the inputs (e.g., converting \"1/2\" to \"\\\\frac{1}{2}\") and then computes accuracy.\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = r\"\"\"\nCalculates accuracy after canonicalizing inputs.\n\nArgs:\n    predictions: list of predictions to score. Each prediction\n        is a string that contains natural language and LaTex.", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "competition_math", "competition_math.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.25888324873096447}, {"context": "_CITATION = \"\"\"\\\n@InProceedings{huggingface:module,\ntitle = {A great new module},\nauthors={huggingface, Inc.},\nyear={2020}\n}\n\"\"\"\n\n# TODO: Add description of the module here\n_DESCRIPTION = \"\"\"\\\nThis new module is designed to solve this great ML task and is crafted with a lot of care.\n\"\"\"\n\n\n# TODO: Add description of the arguments of the module here\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good are predictions given some references, using certain scores\nArgs:\n    predictions: list of predictions to score. Each predictions\n        should be a string with tokens separated by spaces.", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "templates", "{{ cookiecutter.module_slug }}", "{{ cookiecutter.module_slug }}.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.24598930481283424}, {"context": "This new module is designed to solve this great ML task and is crafted with a lot of care.\n\"\"\"\n\n\n# TODO: Add description of the arguments of the module here\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good are predictions given some references, using certain scores\nArgs:\n    predictions: list of predictions to score. Each predictions\n        should be a string with tokens separated by spaces.\n    references: list of reference for each prediction. Each\n        reference should be a string with tokens separated by spaces.\nReturns:\n    accuracy: description of the first score,\n    another_score: description of the second score,\nExamples:\n    Examples should be written in doctest format, and should illustrate how\n    to use the function.\n\n    >>> my_new_module = evaluate.load(\"my_new_module\")", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "templates", "{{ cookiecutter.module_slug }}", "{{ cookiecutter.module_slug }}.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.24083769633507854}, {"context": "    year = \"2017\",\n    address = \"Tokyo, Japan\",\n    publisher = \"International Workshop on Spoken Language Translation\",\n    url = \"https://aclanthology.org/2017.iwslt-1.20\",\n    pages = \"146--153\"\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nCharCut compares outputs of MT systems with reference translations. The matching algorithm is based on an iterative\nsearch for longest common substrings, combined with a length-based threshold that limits short and noisy character\nmatches. As a similarity metric this is not new, but to the best of our knowledge it was never applied to highlighting\nand scoring of MT outputs. It has the neat effect of keeping character-based differences readable by humans.\"\"\"\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good predictions are given some references.\nArgs:\n    predictions: a list of predictions to score. Each prediction should be a string with\n     tokens separated by spaces.\n    references: a list of reference for each prediction. Each reference should be a string with", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "charcut_mt", "charcut_mt.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.22413793103448276}, {"context": "(https://arxiv.org/abs/2107.03374).\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates how good are predictions given some references, using certain scores\nArgs:\n    predictions: list of candidates to evaluate. Each candidates should be a list\n        of strings with several code candidates to solve the problem.\n    references: a list with a test for each prediction. Each test should evaluate the\n        correctness of a code candidate.\n    k: number of code candidates to consider in the evaluation (Default: [1, 10, 100])\n    num_workers: number of workers used to evaluate the canidate programs (Default: 4).\n    timeout:\nReturns:\n    pass_at_k: dict with pass rates for each k\n    results: dict with granular results of each unittest\nExamples:\n    >>> code_eval = evaluate.load(\"code_eval\")\n    >>> test_cases = [\"assert add(2,3)==5\"]", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "code_eval.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.21226415094339623}, {"context": "}\n\"\"\"\n\n# TODO: Add description of the module here\n_DESCRIPTION = \"\"\"\\\nThe TREC Eval metric combines a number of information retrieval metrics such as \\\nprecision and nDCG. It is used to score rankings of retrieved documents with reference values.\"\"\"\n\n\n# TODO: Add description of the arguments of the module here\n_KWARGS_DESCRIPTION = \"\"\"\nCalculates TREC evaluation scores based on a run and qrel.\nArgs:\n    predictions: list containing a single run.\n    references: list containing a single qrel.\nReturns:\n    dict: TREC evaluation scores.\nExamples:\n    >>> trec = evaluate.load(\"trec_eval\")\n    >>> qrel = {", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "trec_eval", "trec_eval.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.203125}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/precision/precision.py\n# --------------------------------------------------\n# \n#     Example 4-A multiclass example, with different values for the `average` input.\n#         >>> predictions = [0, 2, 1, 0, 0, 1]\n#         >>> references = [0, 1, 2, 0, 1, 2]\n#         >>> results = precision_metric.compute(predictions=predictions, references=references, average='macro')\n#         >>> print(results)\n#         {'precision': 0.2222222222222222}\n#         >>> results = precision_metric.compute(predictions=predictions, references=references, average='micro')\n#         >>> print(results)\n#         {'precision': 0.3333333333333333}\n#         >>> results = precision_metric.compute(predictions=predictions, references=references, average='weighted')\n#         >>> print(results)\n#         {'precision': 0.2222222222222222}\n#         >>> results = precision_metric.compute(predictions=predictions, references=references, average=None)\n#         >>> print([round(res, 2) for res in results['precision']])\n#         [0.67, 0.0, 0.0]\n# \"\"\"\n# \n# \n# _CITATION = \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/precision/precision.py\n# --------------------------------------------------\n# \n# Examples:\n# \n#     Example 1-A simple binary example\n#         >>> precision_metric = evaluate.load(\"precision\")\n#         >>> results = precision_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0])\n#         >>> print(results)\n#         {'precision': 0.5}\n# \n#     Example 2-The same simple binary example as in Example 1, but with `pos_label` set to `0`.\n#         >>> precision_metric = evaluate.load(\"precision\")\n#         >>> results = precision_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], pos_label=0)\n#         >>> print(round(results['precision'], 2))\n#         0.67\n# \n#     Example 3-The same simple binary example as in Example 1, but with `sample_weight` included.\n#         >>> precision_metric = evaluate.load(\"precision\")\n#         >>> results = precision_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], sample_weight=[0.9, 0.5, 3.9, 1.2, 0.3])\n#         >>> print(results)\n#         {'precision': 0.23529411764705882}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/f1/f1.py\n# --------------------------------------------------\n#         >>> f1_metric = evaluate.load(\"f1\")\n#         >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], sample_weight=[0.9, 0.5, 3.9, 1.2, 0.3])\n#         >>> print(round(results['f1'], 2))\n#         0.35\n# \n#     Example 4-A multiclass example, with different values for the `average` input.\n#         >>> predictions = [0, 2, 1, 0, 0, 1]\n#         >>> references = [0, 1, 2, 0, 1, 2]\n#         >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"macro\")\n#         >>> print(round(results['f1'], 2))\n#         0.27\n#         >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"micro\")\n#         >>> print(round(results['f1'], 2))\n#         0.33\n#         >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"weighted\")\n#         >>> print(round(results['f1'], 2))\n#         0.27\n#         >>> results = f1_metric.compute(predictions=predictions, references=references, average=None)\n#         >>> print(results)\n#         {'f1': array([0.8, 0. , 0. ])}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/accuracy/accuracy.py\n# --------------------------------------------------\n#     Example 2-The same as Example 1, except with `normalize` set to `False`.\n#         >>> accuracy_metric = evaluate.load(\"accuracy\")\n#         >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n#         >>> print(results)\n#         {'accuracy': 3.0}\n# \n#     Example 3-The same as Example 1, except with `sample_weight` set.\n#         >>> accuracy_metric = evaluate.load(\"accuracy\")\n#         >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n#         >>> print(results)\n#         {'accuracy': 0.8778625954198473}\n# \"\"\"\n# \n# \n# _CITATION = \"\"\"\n# @article{scikit-learn,\n#   title={Scikit-learn: Machine Learning in {P}ython},\n#   author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n#          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n#          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/f1/f1.py\n# --------------------------------------------------\n#         >>> print(results)\n#         {'f1': 0.5}\n# \n#     Example 2-The same simple binary example as in Example 1, but with `pos_label` set to `0`.\n#         >>> f1_metric = evaluate.load(\"f1\")\n#         >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], pos_label=0)\n#         >>> print(round(results['f1'], 2))\n#         0.67\n# \n#     Example 3-The same simple binary example as in Example 1, but with `sample_weight` included.\n#         >>> f1_metric = evaluate.load(\"f1\")\n#         >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], sample_weight=[0.9, 0.5, 3.9, 1.2, 0.3])\n#         >>> print(round(results['f1'], 2))\n#         0.35\n# \n#     Example 4-A multiclass example, with different values for the `average` input.\n#         >>> predictions = [0, 2, 1, 0, 0, 1]\n#         >>> references = [0, 1, 2, 0, 1, 2]\n#         >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"macro\")\n#         >>> print(round(results['f1'], 2))\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2020 The HuggingFace Datasets Authors and the current dataset script contributor.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Recall metric.\"\"\"\n\nimport datasets\nfrom sklearn.metrics import recall_score\n\nimport evaluate\n\n\n_DESCRIPTION = \"\"\"\nRecall is the fraction of the positive examples that were correctly labeled by the model as positive. It can be computed with the equation:\nRecall = TP / (TP + FN)\nWhere TP is the true positives and FN is the false negatives.\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nArgs:\n- **predictions** (`list` of `int`): The predicted labels.\n- **references** (`list` of `int`): The ground truth labels.\n- **labels** (`list` of `int`): The set of labels to include when `average` is not set to `binary`, and their order when average is `None`. Labels present in the data can be excluded in this input, for example to calculate a multiclass average ignoring a majority negative class, while labels not present in the data will result in 0 components in a macro average. For multilabel targets, labels are column indices. By default, all labels in y_true and y_pred are used in sorted order. Defaults to None.\n- **pos_label** (`int`): The class label to use as the 'positive class' when calculating the recall. Defaults to `1`.\n- **average** (`string`): This parameter is required for multiclass/multilabel targets. If None, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data. Defaults to `'binary'`.\n    - `'binary'`: Only report results for the class specified by `pos_label`. This is applicable only if the target labels and predictions are binary.\n    - `'micro'`: Calculate metrics globally by counting the total true positives, false negatives, and false positives.\n    - `'macro'`: Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n    - `'weighted'`: Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters `'macro'` to account for label imbalance. Note that it can result in an F-score that is not between precision and recall.\n    - `'samples'`: Calculate metrics for each instance, and find their average (only meaningful for multilabel classification).\n- **sample_weight** (`list` of `float`): Sample weights Defaults to `None`.\n- **zero_division** (): Sets the value to return when there is a zero division. Defaults to .\n    - `'warn'`: If there is a zero division, the return value is `0`, but warnings are also raised.\n    - `0`: If there is a zero division, the return value is `0`.\n    - `1`: If there is a zero division, the return value is `1`.\n\nReturns:\n- **recall** (`float`, or `array` of `float`): Either the general recall score, or the recall scores for individual classes, depending on the values input to `labels` and `average`. Minimum possible value is 0. Maximum possible value is 1. A higher recall means that more of the positive examples have been labeled correctly. Therefore, a higher recall is generally considered better.\n\nExamples:\n\n    Example 1-A simple example with some errors\n        >>> recall_metric = evaluate.load('recall')\n        >>> results = recall_metric.compute(references=[0, 0, 1, 1, 1], predictions=[0, 1, 0, 1, 1])\n        >>> print(results)\n        {'recall': 0.6666666666666666}\n\n    Example 2-The same example as Example 1, but with `pos_label=0` instead of the default `pos_label=1`.\n        >>> recall_metric = evaluate.load('recall')\n        >>> results = recall_metric.compute(references=[0, 0, 1, 1, 1], predictions=[0, 1, 0, 1, 1], pos_label=0)\n        >>> print(results)\n        {'recall': 0.5}\n\n    Example 3-The same example as Example 1, but with `sample_weight` included.\n        >>> recall_metric = evaluate.load('recall')\n        >>> sample_weight = [0.9, 0.2, 0.9, 0.3, 0.8]", "choices": [{"text": "average"}], "metadata": {"task_id": "huggingface_evaluate/133", "ground_truth": "        >>> results = recall_metric.compute(references=[0, 0, 1, 1, 1], predictions=[0, 1, 0, 1, 1], sample_weight=sample_weight)", "fpath_tuple": ["huggingface_evaluate", "metrics", "recall", "recall.py"], "context_start_lineno": 0, "line_no": 66, "query_window": {"context": "Returns:\n- **recall** (`float`, or `array` of `float`): Either the general recall score, or the recall scores for individual classes, depending on the values input to `labels` and `average`. Minimum possible value is 0. Maximum possible value is 1. A higher recall means that more of the positive examples have been labeled correctly. Therefore, a higher recall is generally considered better.\n\nExamples:\n\n    Example 1-A simple example with some errors\n        >>> recall_metric = evaluate.load('recall')\n        >>> results = recall_metric.compute(references=[0, 0, 1, 1, 1], predictions=[0, 1, 0, 1, 1])\n        >>> print(results)\n        {'recall': 0.6666666666666666}\n\n    Example 2-The same example as Example 1, but with `pos_label=0` instead of the default `pos_label=1`.\n        >>> recall_metric = evaluate.load('recall')\n        >>> results = recall_metric.compute(references=[0, 0, 1, 1, 1], predictions=[0, 1, 0, 1, 1], pos_label=0)\n        >>> print(results)\n        {'recall': 0.5}\n\n    Example 3-The same example as Example 1, but with `sample_weight` included.\n        >>> recall_metric = evaluate.load('recall')\n        >>> sample_weight = [0.9, 0.2, 0.9, 0.3, 0.8]", "metadata": {"fpath_tuple": ["huggingface_evaluate", "metrics", "recall", "recall.py"], "line_no": 66, "task_id": "huggingface_evaluate/133", "start_line_no": 46, "end_line_no": 66, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n\nReturns:\n    f1 (`float` or `array` of `float`): F1 score or list of f1 scores, depending on the value passed to `average`. Minimum possible value is 0. Maximum possible value is 1. Higher f1 scores are better.\n\nExamples:\n\n    Example 1-A simple binary example\n        >>> f1_metric = evaluate.load(\"f1\")\n        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0])\n        >>> print(results)\n        {'f1': 0.5}\n\n    Example 2-The same simple binary example as in Example 1, but with `pos_label` set to `0`.\n        >>> f1_metric = evaluate.load(\"f1\")\n        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], pos_label=0)\n        >>> print(round(results['f1'], 2))\n        0.67\n\n    Example 3-The same simple binary example as in Example 1, but with `sample_weight` included.", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "f1", "f1.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.547945205479452}, {"context": "    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.\n\nExamples:\n\n    Example 1-A simple example\n        >>> accuracy_metric = evaluate.load(\"accuracy\")\n        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n        >>> print(results)\n        {'accuracy': 0.5}\n\n    Example 2-The same as Example 1, except with `normalize` set to `False`.\n        >>> accuracy_metric = evaluate.load(\"accuracy\")\n        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n        >>> print(results)\n        {'accuracy': 3.0}\n\n    Example 3-The same as Example 1, except with `sample_weight` set.\n        >>> accuracy_metric = evaluate.load(\"accuracy\")\n        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n        >>> print(results)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "accuracy", "accuracy.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.5}, {"context": "        >>> print(results)\n        {'f1': 0.5}\n\n    Example 2-The same simple binary example as in Example 1, but with `pos_label` set to `0`.\n        >>> f1_metric = evaluate.load(\"f1\")\n        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], pos_label=0)\n        >>> print(round(results['f1'], 2))\n        0.67\n\n    Example 3-The same simple binary example as in Example 1, but with `sample_weight` included.\n        >>> f1_metric = evaluate.load(\"f1\")\n        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], sample_weight=[0.9, 0.5, 3.9, 1.2, 0.3])\n        >>> print(round(results['f1'], 2))\n        0.35\n\n    Example 4-A multiclass example, with different values for the `average` input.\n        >>> predictions = [0, 2, 1, 0, 0, 1]\n        >>> references = [0, 1, 2, 0, 1, 2]\n        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"macro\")\n        >>> print(round(results['f1'], 2))", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "f1", "f1.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.46938775510204084}, {"context": "        - 'samples': Calculate metrics for each instance, and find their average (only meaningful for multilabel classification).\n    sample_weight (`list` of `float`): Sample weights Defaults to None.\n    zero_division (`int` or `string`): Sets the value to return when there is a zero division. Defaults to 'warn'.\n\n        - 0: Returns 0 when there is a zero division.\n        - 1: Returns 1 when there is a zero division.\n        - 'warn': Raises warnings and then returns 0 when there is a zero division.\n\nReturns:\n    precision (`float` or `array` of `float`): Precision score or list of precision scores, depending on the value passed to `average`. Minimum possible value is 0. Maximum possible value is 1. Higher values indicate that fewer negative examples were incorrectly labeled as positive, which means that, generally, higher scores are better.\n\nExamples:\n\n    Example 1-A simple binary example\n        >>> precision_metric = evaluate.load(\"precision\")\n        >>> results = precision_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0])\n        >>> print(results)\n        {'precision': 0.5}\n\n    Example 2-The same simple binary example as in Example 1, but with `pos_label` set to `0`.", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "precision", "precision.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.4594594594594595}, {"context": "        >>> precision_metric = evaluate.load(\"precision\")\n        >>> results = precision_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], pos_label=0)\n        >>> print(round(results['precision'], 2))\n        0.67\n\n    Example 3-The same simple binary example as in Example 1, but with `sample_weight` included.\n        >>> precision_metric = evaluate.load(\"precision\")\n        >>> results = precision_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], sample_weight=[0.9, 0.5, 3.9, 1.2, 0.3])\n        >>> print(results)\n        {'precision': 0.23529411764705882}\n\n    Example 4-A multiclass example, with different values for the `average` input.\n        >>> predictions = [0, 2, 1, 0, 0, 1]\n        >>> references = [0, 1, 2, 0, 1, 2]\n        >>> results = precision_metric.compute(predictions=predictions, references=references, average='macro')\n        >>> print(results)\n        {'precision': 0.2222222222222222}\n        >>> results = precision_metric.compute(predictions=predictions, references=references, average='micro')\n        >>> print(results)\n        {'precision': 0.3333333333333333}", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "precision", "precision.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.4230769230769231}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_transforms.py\n# --------------------------------------------------\n#         \"keys\",\n#         [[\"next_observation\", \"some_other_key\"], [(\"next\", \"observation_pixels\")]],\n#     )\n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     def test_compose(self, keys, batch, device, nchannels=1, N=4):\n#         torch.manual_seed(0)\n#         t1 = CatFrames(\n#             in_keys=keys,\n#             N=4,\n#             dim=-3,\n#         )\n#         t2 = FiniteTensorDictCheck()\n#         compose = Compose(t1, t2)\n#         dont_touch = torch.randn(*batch, nchannels, 16, 16, device=device)\n#         td = TensorDict(\n#             {\n#                 key: torch.randint(255, (*batch, nchannels, 16, 16), device=device)\n#                 for key in keys\n#             },\n#             batch,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_specs.py\n# --------------------------------------------------\n#         ],\n#     )\n#     def test_bounded(self, shape1, shape2, mini, maxi):\n#         spec = BoundedTensorSpec(\n#             mini, maxi, shape=shape1, device=\"cpu\", dtype=torch.bool\n#         )\n#         shape1 = spec.shape\n#         assert shape1 == torch.Size([10])\n#         shape2_real = (*shape2, *shape1)\n# \n#         spec2 = spec.expand(shape2_real)\n#         assert spec2 is not spec\n#         assert spec2.dtype == spec.dtype\n#         assert (spec2.zero() == spec.zero()).all()\n#         assert spec2.rand().shape == spec2.shape\n#         assert spec2.zero().shape == spec2.shape\n#         spec2 = spec.expand(*shape2_real)\n#         assert spec2 is not spec\n#         assert spec2.dtype == spec.dtype\n#         assert (spec2.zero() == spec.zero()).all()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_distributions.py\n# --------------------------------------------------\n# )\n# @pytest.mark.parametrize(\n#     \"vecs\",\n#     [\n#         (torch.tensor([0.1, 10.0, 5.0]), torch.tensor([0.1, 10.0, 5.0])),\n#         (torch.zeros(7, 3), torch.ones(7, 3)),\n#     ],\n# )\n# @pytest.mark.parametrize(\n#     \"upscale\", [torch.ones(3), 1, 3 * torch.tensor([1.0, 2.0, 0.5]), 3]\n# )\n# @pytest.mark.parametrize(\"shape\", [torch.Size([]), torch.Size([3, 4])])\n# @pytest.mark.parametrize(\"device\", get_available_devices())\n# def test_truncnormal(min, max, vecs, upscale, shape, device):\n#     torch.manual_seed(0)\n#     min, max, vecs, upscale, shape = _map_all(\n#         min, max, vecs, upscale, shape, device=device\n#     )\n#     d = TruncatedNormal(\n#         *vecs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_transforms.py\n# --------------------------------------------------\n#                     result[key].space.minimum[i], observation_spec[key].space.minimum[0]\n#                 )\n# \n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     @pytest.mark.parametrize(\"batch_size\", [(), (1,), (1, 2)])\n#     @pytest.mark.parametrize(\"d\", range(1, 4))\n#     @pytest.mark.parametrize(\"dim\", [-3, -2, 1])\n#     @pytest.mark.parametrize(\"N\", [2, 4])\n#     def test_catframes_buffer_check_latest_frame(self, device, d, batch_size, dim, N):\n#         key1 = \"first key\"\n#         key2 = \"second key\"\n#         keys = [key1, key2]\n#         extra_d = (3,) * (-dim - 1)\n#         key1_tensor = torch.ones(*batch_size, d, *extra_d, device=device) * 2\n#         key2_tensor = torch.ones(*batch_size, d, *extra_d, device=device)\n#         key_tensors = [key1_tensor, key2_tensor]\n#         td = TensorDict(dict(zip(keys, key_tensors)), batch_size, device=device)\n#         if dim > 0:\n#             with pytest.raises(\n#                 ValueError, match=\"dim must be > 0 to accomodate for tensordict\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_distributions.py\n# --------------------------------------------------\n# @pytest.mark.parametrize(\n#     \"max\", [torch.ones(3), 1, 3 * torch.tensor([1.0, 2.0, 0.5]), 0.1]\n# )\n# @pytest.mark.parametrize(\n#     \"vecs\",\n#     [\n#         (torch.tensor([0.1, 10.0, 5.0]), torch.tensor([0.1, 10.0, 5.0])),\n#         (torch.zeros(7, 3), torch.ones(7, 3)),\n#     ],\n# )\n# @pytest.mark.parametrize(\n#     \"upscale\", [torch.ones(3), 1, 3 * torch.tensor([1.0, 2.0, 0.5]), 3]\n# )\n# @pytest.mark.parametrize(\"shape\", [torch.Size([]), torch.Size([3, 4])])\n# @pytest.mark.parametrize(\"device\", get_available_devices())\n# def test_tanhnormal(min, max, vecs, upscale, shape, device):\n#     min, max, vecs, upscale, shape = _map_all(\n#         min, max, vecs, upscale, shape, device=device\n#     )\n#     torch.manual_seed(0)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/tensordict_module/actors.py\n# --------------------------------------------------\n#         return torch.argmax(value, dim=-1).to(torch.long)\n# \n#     def _mult_one_hot(self, value: torch.Tensor, support: torch.Tensor) -> torch.Tensor:\n#         values = value.split(self.var_nums, dim=-1)\n#         return torch.cat(\n#             [\n#                 QValueHook._one_hot(\n#                     _value,\n#                 )\n#                 for _value in values\n#             ],\n#             -1,\n#         )\n# \n#     @staticmethod\n#     def _binary(value: torch.Tensor, support: torch.Tensor) -> torch.Tensor:\n#         raise NotImplementedError\n# \n#     @staticmethod\n#     def _default_action_value(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport pytest\nimport torch\nfrom torchrl.modules.tensordict_module.actors import (\n    DistributionalQValueHook,\n    QValueHook,\n)\n\n\nclass TestQValue:\n    def test_qvalue_hook_wrong_action_space(self):\n        with pytest.raises(ValueError) as exc:\n            QValueHook(action_space=\"wrong_value\")\n        assert \"action_space must be one of\" in str(exc.value)\n\n    def test_distributional_qvalue_hook_wrong_action_space(self):\n        with pytest.raises(ValueError) as exc:\n            DistributionalQValueHook(action_space=\"wrong_value\", support=None)\n        assert \"action_space must be one of\" in str(exc.value)\n\n    @pytest.mark.parametrize(\n        \"action_space, expected_action\",\n        (\n            (\"one_hot\", [0, 0, 1, 0, 0]),\n            (\"categorical\", 2),\n        ),\n    )\n    def test_qvalue_hook_0_dim_batch(self, action_space, expected_action):\n        hook = QValueHook(action_space=action_space)\n\n        in_values = torch.tensor([1.0, -1.0, 100.0, -2.0, -3.0])\n        action, values, chosen_action_value = hook(\n            net=None, observation=None, values=in_values\n        )\n\n        assert (torch.tensor(expected_action, dtype=torch.long) == action).all()\n        assert (values == in_values).all()\n        assert (torch.tensor([100.0]) == chosen_action_value).all()\n\n    @pytest.mark.parametrize(\n        \"action_space, expected_action\",\n        (\n            (\"one_hot\", [[0, 0, 1, 0, 0], [1, 0, 0, 0, 0]]),\n            (\"categorical\", [2, 0]),\n        ),\n    )\n    def test_qvalue_hook_1_dim_batch(self, action_space, expected_action):\n        hook = QValueHook(action_space=action_space)\n\n        in_values = torch.tensor(\n            [\n                [1.0, -1.0, 100.0, -2.0, -3.0],\n                [5.0, 4.0, 3.0, 2.0, -5.0],\n            ]\n        )\n        action, values, chosen_action_value = hook(\n            net=None, observation=None, values=in_values\n        )\n\n        assert (torch.tensor(expected_action, dtype=torch.long) == action).all()\n        assert (values == in_values).all()\n        assert (torch.tensor([[100.0], [5.0]]) == chosen_action_value).all()\n\n    @pytest.mark.parametrize(\n        \"action_space, expected_action\",\n        (\n            (\"one_hot\", [0, 0, 1, 0, 0]),\n            (\"categorical\", 2),\n        ),\n    )\n    def test_distributional_qvalue_hook_0_dim_batch(\n        self, action_space, expected_action\n    ):\n        support = torch.tensor([-2.0, 0.0, 2.0])\n        hook = DistributionalQValueHook(action_space=action_space, support=support)\n\n        in_values = torch.nn.LogSoftmax(dim=-1)(\n            torch.tensor(\n                [\n                    [1.0, -1.0, 11.0, -2.0, 30.0],\n                    [1.0, -1.0, 1.0, -2.0, -3.0],\n                    [1.0, -1.0, 10.0, -2.0, -3.0],\n                ]\n            )\n        )\n        action, values = hook(net=None, observation=None, values=in_values)\n        expected_action = torch.tensor(expected_action, dtype=torch.long)\n\n        assert action.shape == expected_action.shape\n        assert (action == expected_action).all()\n        assert values.shape == in_values.shape\n        assert (values == in_values).all()\n\n    @pytest.mark.parametrize(\n        \"action_space, expected_action\",\n        (\n            (\"one_hot\", [[0, 0, 1, 0, 0], [1, 0, 0, 0, 0]]),\n            (\"categorical\", [2, 0]),\n        ),\n    )\n    def test_qvalue_hook_categorical_1_dim_batch(self, action_space, expected_action):\n        support = torch.tensor([-2.0, 0.0, 2.0])\n        hook = DistributionalQValueHook(action_space=action_space, support=support)\n\n        in_values = torch.nn.LogSoftmax(dim=-1)(\n            torch.tensor(\n                [\n                    [\n                        [1.0, -1.0, 11.0, -2.0, 30.0],\n                        [1.0, -1.0, 1.0, -2.0, -3.0],\n                        [1.0, -1.0, 10.0, -2.0, -3.0],\n                    ],\n                    [", "choices": [{"text": "5.0, 4.0, 3.0, 2.0, -5.0],"}], "metadata": {"task_id": "pytorch_rl/83", "ground_truth": "                        [11.0, -1.0, 7.0, -1.0, 20.0],", "fpath_tuple": ["pytorch_rl", "test", "test_actors.py"], "context_start_lineno": 0, "line_no": 117, "query_window": {"context": "    @pytest.mark.parametrize(\n        \"action_space, expected_action\",\n        (\n            (\"one_hot\", [[0, 0, 1, 0, 0], [1, 0, 0, 0, 0]]),\n            (\"categorical\", [2, 0]),\n        ),\n    )\n    def test_qvalue_hook_categorical_1_dim_batch(self, action_space, expected_action):\n        support = torch.tensor([-2.0, 0.0, 2.0])\n        hook = DistributionalQValueHook(action_space=action_space, support=support)\n\n        in_values = torch.nn.LogSoftmax(dim=-1)(\n            torch.tensor(\n                [\n                    [\n                        [1.0, -1.0, 11.0, -2.0, 30.0],\n                        [1.0, -1.0, 1.0, -2.0, -3.0],\n                        [1.0, -1.0, 10.0, -2.0, -3.0],\n                    ],\n                    [", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_actors.py"], "line_no": 117, "task_id": "pytorch_rl/83", "start_line_no": 97, "end_line_no": 117, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        chosen_action_value = action_value_func(values, action)\n        return action, values, chosen_action_value\n\n    @staticmethod\n    def _one_hot(value: torch.Tensor) -> torch.Tensor:\n        out = (value == value.max(dim=-1, keepdim=True)[0]).to(torch.long)\n        return out\n\n    @staticmethod\n    def _categorical(value: torch.Tensor) -> torch.Tensor:\n        return torch.argmax(value, dim=-1).to(torch.long)\n\n    def _mult_one_hot(self, value: torch.Tensor, support: torch.Tensor) -> torch.Tensor:\n        values = value.split(self.var_nums, dim=-1)\n        return torch.cat(\n            [\n                QValueHook._one_hot(\n                    _value,\n                )\n                for _value in values", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "actors.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.33884297520661155}, {"context": "    for t in tensors_or_other:\n        if isinstance(t, (torch.Tensor, TensorDictBase)):\n            yield t.to(device)\n        else:\n            yield t\n\n\n@pytest.mark.parametrize(\n    \"min\", [-torch.ones(3), -1, 3 * torch.tensor([-1.0, -2.0, -0.5]), -0.1]\n)\n@pytest.mark.parametrize(\n    \"max\", [torch.ones(3), 1, 3 * torch.tensor([1.0, 2.0, 0.5]), 0.1]\n)\n@pytest.mark.parametrize(\n    \"vecs\",\n    [\n        (torch.tensor([0.1, 10.0, 5.0]), torch.tensor([0.1, 10.0, 5.0])),\n        (torch.zeros(7, 3), torch.ones(7, 3)),\n    ],\n)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_distributions.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3387096774193548}, {"context": "        )\n\n        final_spec = result[key2]\n        assert final_spec.shape[0] == N\n        for key in keys:\n            for i in range(N):\n                assert torch.equal(\n                    result[key].space.maximum[i], observation_spec[key].space.maximum[0]\n                )\n                assert torch.equal(\n                    result[key].space.minimum[i], observation_spec[key].space.minimum[0]\n                )\n\n    @pytest.mark.parametrize(\"device\", get_available_devices())\n    @pytest.mark.parametrize(\"batch_size\", [(), (1,), (1, 2)])\n    @pytest.mark.parametrize(\"d\", range(1, 4))\n    @pytest.mark.parametrize(\"dim\", [-3, -2, 1])\n    @pytest.mark.parametrize(\"N\", [2, 4])\n    def test_catframes_buffer_check_latest_frame(self, device, d, batch_size, dim, N):\n        key1 = \"first key\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_transforms.py"], "line_no": 1300, "start_line_no": 1290, "end_line_no": 1310, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "        assert (a <= d.max).all()\n        lp = d.log_prob(a)\n        assert torch.isfinite(lp).all()\n\n\n@pytest.mark.parametrize(\n    \"min\", [-torch.ones(3), -1, 3 * torch.tensor([-1.0, -2.0, -0.5]), -0.1]\n)\n@pytest.mark.parametrize(\n    \"max\", [torch.ones(3), 1, 3 * torch.tensor([1.0, 2.0, 0.5]), 0.1]\n)\n@pytest.mark.parametrize(\n    \"vecs\",\n    [\n        (torch.tensor([0.1, 10.0, 5.0]), torch.tensor([0.1, 10.0, 5.0])),\n        (torch.zeros(7, 3), torch.ones(7, 3)),\n    ],\n)\n@pytest.mark.parametrize(\n    \"upscale\", [torch.ones(3), 1, 3 * torch.tensor([1.0, 2.0, 0.5]), 3]", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_distributions.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.32786885245901637}, {"context": "    @pytest.mark.parametrize(\"shape2\", [(), (5,)])\n    @pytest.mark.parametrize(\n        \"shape1,mini,maxi\",\n        [\n            [(10,), -torch.ones([]), torch.ones([])],\n            [None, -torch.ones([10]), torch.ones([])],\n            [None, -torch.ones([]), torch.ones([10])],\n            [(10,), -torch.ones([]), torch.ones([10])],\n            [(10,), -torch.ones([10]), torch.ones([])],\n            [(10,), -torch.ones([10]), torch.ones([10])],\n        ],\n    )\n    def test_bounded(self, shape1, shape2, mini, maxi):\n        spec = BoundedTensorSpec(\n            mini, maxi, shape=shape1, device=\"cpu\", dtype=torch.bool\n        )\n        shape1 = spec.shape\n        assert shape1 == torch.Size([10])\n        shape2_real = (*shape2, *shape1)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_specs.py"], "line_no": 1160, "start_line_no": 1150, "end_line_no": 1170, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3252032520325203}, {"context": "            observation_spec = totensorimage.transform_observation_spec(\n                observation_spec\n            )\n            for key in keys:\n                assert observation_spec[key].shape == torch.Size([3, 16, 16])\n                assert (observation_spec[key].space.minimum == 0).all()\n                assert (observation_spec[key].space.maximum == 1).all()\n\n    @pytest.mark.parametrize(\"batch\", [[], [1], [3, 2]])\n    @pytest.mark.parametrize(\n        \"keys\",\n        [[\"next_observation\", \"some_other_key\"], [(\"next\", \"observation_pixels\")]],\n    )\n    @pytest.mark.parametrize(\"device\", get_available_devices())\n    def test_compose(self, keys, batch, device, nchannels=1, N=4):\n        torch.manual_seed(0)\n        t1 = CatFrames(\n            in_keys=keys,\n            N=4,\n            dim=-3,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_transforms.py"], "line_no": 940, "start_line_no": 930, "end_line_no": 950, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.32413793103448274}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n# \n# \n# class DataLoader:\n#     def __init__(\n#         self,\n#         data_loader: Union[\n#             FromIterableToDataLoader,\n#             FromCallableIterableToDataLoader,\n#             FromArrayDataToDataLoader,\n#             FromTensorFlowDataLoaderToDataLoader,\n#             FromTorchDataLoaderToDataLoader,\n#             ChoppedDataLoader\n#         ],\n#     ):\n#         \"\"\"\n#         A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n#         are arrays, with different data points over the first dimension.\n# \n#         Parameters\n#         ----------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         fun: Callable[[], Iterable[Batch]]\n#             A callable iterable of tuples of input and target arrays.\n# \n#         Returns\n#         -------\n#         DataLoader\n#             A data loader object.\n#         \"\"\"\n#         return cls(data_loader=FromCallableIterableToDataLoader(fun))\n# \n#     @classmethod\n#     def from_iterable(cls, iterable: Iterable[Batch],) -> DataLoader:\n#         \"\"\"\n#         Transform an iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n# \n#         Parameters\n#         ----------\n#         iterable: Iterable[Batch]\n#             An iterable of tuples of input and target arrays.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#             )\n#         )\n# \n#     @classmethod\n#     def from_callable_iterable(cls, fun: Callable[[], Iterable[Batch],],) -> DataLoader:\n#         \"\"\"\n#         Transform a callable iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n# \n#         Parameters\n#         ----------\n#         fun: Callable[[], Iterable[Batch]]\n#             A callable iterable of tuples of input and target arrays.\n# \n#         Returns\n#         -------\n#         DataLoader\n#             A data loader object.\n#         \"\"\"\n#         return cls(data_loader=FromCallableIterableToDataLoader(fun))\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#             DataLoaderWrapper(data_loader) if data_loader is not None else data_loader\n#         )\n# \n#     @staticmethod\n#     def _add_device_dim_to_outputs_loader(\n#         outputs_loader: TargetsLoader,\n#     ) -> TargetsLoader:\n#         def _reshape_batch(batch):\n#             n_devices = jax.local_device_count()\n#             if batch.shape[0] % n_devices != 0:\n#                 raise ValueError(\n#                     f\"The size of all output batches must be a multiple of {n_devices}, that is the number of \"\n#                     f\"available devices. However, a batch of outputs with shape {batch.shape[0]} was found. \"\n#                     f\"Please set an appropriate batch size.\"\n#                 )\n#             return batch.reshape((n_devices, -1) + batch.shape[1:])\n# \n#         class TargetsLoaderWrapper:\n#             def __init__(self, outputs_loader: TargetsLoader):\n#                 self._outputs_loader = outputs_loader\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#             inputs.append(batch_inputs)\n#         return np.concatenate(inputs, 0)\n# \n#     @classmethod\n#     def from_callable_iterable(\n#         cls, fun: Callable[[], Iterable[Array]],\n#     ) -> InputsLoader:\n#         \"\"\"\n#         Transform a callable iterable into a :class:`~fortuna.data.loader.InputsLoader` object.\n# \n#         Parameters\n#         ----------\n#         fun: Callable[[], Iterable[Array]]\n#             A callable iterable of input arrays.\n# \n#         Returns\n#         -------\n#         InputsLoader\n#             An inputs loader object.\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/prob_model_calibrator.py\n# --------------------------------------------------\n#             def __iter__(self):\n#                 outputs_loader = map(\n#                     lambda batch: tree_map(_reshape_batch, batch), self._outputs_loader\n#                 )\n#                 outputs_loader = jax_utils.prefetch_to_device(outputs_loader, 2)\n#                 yield from outputs_loader\n# \n#         return (\n#             TargetsLoaderWrapper(outputs_loader)\n#             if outputs_loader is not None\n#             else outputs_loader\n#         )\n# \n# \n# class JittedProbModelCalibrator(JittedMixin, ProbModelCalibrator):\n#     pass\n# \n# \n# class MultiDeviceProbModelCalibrator(ProbModelMultiDeviceMixin, ProbModelCalibrator):\n#     pass\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#     def from_array_data(\n#         cls,\n#         data: Batch,\n#         batch_size: Optional[int] = None,\n#         shuffle: bool = False,\n#         prefetch: bool = False,\n#     ) -> DataLoader:\n#         \"\"\"\n#         Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n#         respectively.\n# \n#         Parameters\n#         ----------\n#         data: Batch\n#             Input and target arrays of data.\n#         batch_size: Optional[int]\n#             The batch size. If not given, the data will not be batched.\n#         shuffle: bool\n#             Whether the data loader should shuffle at every call.\n#         prefetch: bool\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#     def from_data_loader(cls, data_loader: DataLoader) -> InputsLoader:\n#         \"\"\"\n#         Reduce a data loader to an inputs loader.\n# \n#         Parameters\n#         ----------\n#         data_loader : DataLoader\n#             A data loader.\n# \n#         Returns\n#         -------\n#         InputsLoader\n#             An inputs loader.\n#         \"\"\"\n#         return cls(inputs_loader=FromDataLoaderToInputsLoader(data_loader))\n# \n#     @classmethod\n#     def from_array_inputs(\n#         cls,\n#         inputs: Array,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         ----------\n#         inputs_loader : Union[FromArrayInputsToInputsLoader, FromDataLoaderToInputsLoader]\n#             An inputs loader.\n#         \"\"\"\n#         self._inputs_loader = inputs_loader\n# \n#     def __iter__(self):\n#         yield from self._inputs_loader()\n# \n#     @classmethod\n#     def from_data_loader(cls, data_loader: DataLoader) -> InputsLoader:\n#         \"\"\"\n#         Reduce a data loader to an inputs loader.\n# \n#         Parameters\n#         ----------\n#         data_loader : DataLoader\n#             A data loader.\n# \n#         Returns\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader object.\n        \"\"\"\n        return cls(inputs_loader=FromIterableToInputsLoader(iterable))\n\n    @classmethod\n    def chop(cls, inputs_loader: InputsLoader, divisor: int) -> InputsLoader:\n        \"\"\"\n        Chop the last part of each batch of the inputs loader, to make sure the number od data points per batch divides\n        `divisor`.\n\n        Parameters\n        ----------\n        inputs_loader : InputsLoader\n            An inputs loader.\n        divisor : int\n            Number of data points that each batched must divide.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader with chopped batches.\n        \"\"\"\n        return cls(inputs_loader=ChoppedInputsLoader(inputs_loader=inputs_loader, divisor=divisor))\n\n\nclass TargetsLoader:\n    def __init__(\n        self,\n        targets_loader: Union[\n            FromArrayTargetsToTargetsLoader,\n            FromDataLoaderToTargetsLoader,\n            FromCallableIterableToTargetsLoader,\n            FromIterableToTargetsLoader,\n            ChoppedTargetsLoader\n        ],\n    ):\n        \"\"\"\n        A targets loader class. Each batch is an array of targets, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        targets_loader : Union[FromArrayTargetsToTargetsLoader, FromDataLoaderToTargetsLoader]\n            A targets loader.\n        \"\"\"\n        self._targets_loader = targets_loader\n\n    def __iter__(self):\n        yield from self._targets_loader()\n\n    @classmethod\n    def from_data_loader(cls, data_loader: DataLoader) -> TargetsLoader:\n        \"\"\"\n        Reduce a data loader to a targets loader.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader.\n\n        Returns\n        -------\n        TargetsLoader\n            A targets loader.\n        \"\"\"\n        return cls(targets_loader=FromDataLoaderToTargetsLoader(data_loader))\n\n    @classmethod\n    def from_array_targets(\n        cls,\n        targets: Array,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ) -> TargetsLoader:\n        \"\"\"\n        Build a :class:`~fortuna.data.loader.TargetsLoader` object from an array of target data.\n\n        Parameters\n        ----------\n        targets: Array\n            Target array of data.\n        batch_size: Optional[int]\n            The batch size. If not given, the targets will not be batched.\n        shuffle: bool\n            Whether the target loader should shuffle at every call.\n        prefetch: bool\n            Whether to prefetch the next batch.\n\n        Returns\n        -------\n        TargetsLoader\n            A targets loader built out of the array of targets.\n        \"\"\"\n        return cls(\n            targets_loader=FromArrayTargetsToTargetsLoader(\n                targets, batch_size=batch_size, shuffle=shuffle, prefetch=prefetch\n            )\n        )\n\n    def to_array_targets(self) -> Array:\n        \"\"\"\n        Reduce a targets loader to an array of targets.\n\n        Returns\n        -------\n        Array\n            Array of target data.\n        \"\"\"\n        targets = []\n        for batch_targets in self._targets_loader():\n            targets.append(batch_targets)\n        return np.concatenate(targets, 0)\n\n    @classmethod\n    def from_callable_iterable(\n        cls, fun: Callable[[], Iterable[Array]],\n    ) -> TargetsLoader:\n        \"\"\"\n        Transform a callable iterable into a :class:`~fortuna.data.loader.TargetsLoader` object.\n\n        Parameters\n        ----------\n        fun: Callable[[], Iterable[Array]]\n            A callable iterable of target arrays.\n\n        Returns\n        -------\n        TargetsLoader\n            A targets loader object.\n        \"\"\"\n        return cls(targets_loader=FromCallableIterableToTargetsLoader(fun))\n\n    @classmethod\n    def from_iterable(cls, iterable: Iterable[Array],) -> TargetsLoader:\n        \"\"\"\n        Transform an iterable into a :class:`~fortuna.data.loader.TargetsLoader` object.\n\n        Parameters\n        ----------\n        iterable: Iterable[Array]\n            An iterable of target arrays.\n\n        Returns\n        -------\n        TargetsLoader\n            A targets loader object.\n        \"\"\"\n        return cls(targets_loader=FromIterableToTargetsLoader(iterable))\n\n    @classmethod\n    def chop(cls, targets_loader: TargetsLoader, divisor: int) -> TargetsLoader:\n        \"\"\"\n        Chop the last part of each batch of the targets loader, to make sure the number od data points per batch divides\n        `divisor`.\n\n        Parameters\n        ----------\n        targets_loader : TargetsLoader\n            A targets loader.\n        divisor : int\n            Number of data points that each batched must divide.\n\n        Returns\n        -------\n        InputsLoader\n            A targets loader with chopped batches.\n        \"\"\"\n        return cls(targets_loader=ChoppedTargetsLoader(targets_loader=targets_loader, divisor=divisor))\n\n\nclass FromDataLoaderToArrayData:\n    def __init__(self, data_loader: DataLoader):\n        self._data_loader = data_loader\n\n    def __call__(self, *args, **kwargs):\n        data = []\n        for batch in self._data_loader:\n            data.append(batch)\n        return np.concatenate(data, 0)\n\n\nclass FromDataLoaderToInputsTargetsLoaders:\n    def __init__(self, data_loader: DataLoader):\n        self._data_loader = data_loader\n\n    def __call__(self, *args, **kwargs):\n        for x_batch, y_batch in self._data_loader:\n            yield x_batch, y_batch\n\n\nclass FromArrayDataToDataLoader:\n    def __init__(\n        self,\n        data: Batch,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ):\n        self._data = data\n        self._batch_size = batch_size\n        self._shuflle = shuffle\n        self._prefetch = prefetch\n\n    def __call__(self, *args, **kwargs):\n        if self._shuflle:\n            perm = np.random.choice(\n                self._data[0].shape[0], self._data[0].shape[0], replace=False\n            )\n        if self._batch_size is None:\n            yield self._data\n        else:\n            x_batches = np.split(\n                self._data[0][perm] if self._shuflle else self._data[0],\n                np.arange(self._batch_size, self._data[0].shape[0], self._batch_size),\n                axis=0,\n            )\n            y_batches = np.split(\n                self._data[1][perm] if self._shuflle else self._data[1],\n                np.arange(self._batch_size, self._data[1].shape[0], self._batch_size),\n                axis=0,\n            )\n\n            def make_gen():\n                for x_batch, y_batch in zip(x_batches, y_batches):\n                    yield x_batch, y_batch\n\n            yield from PrefetchedGenerator(make_gen()) if self._prefetch else make_gen()\n\n\nclass FromCallableIterableToDataLoader:\n    def __init__(\n        self, fun: Callable[[], Iterable[Batch],],\n    ):\n        self._fun = fun\n\n    def __call__(self, *args, **kwargs):\n        return self._fun()\n\n\nclass FromCallableIterableToInputsLoader:\n    def __init__(\n        self, fun: Callable[[], Iterable[Array]],\n    ):", "choices": [{"text": "self._fun = fun"}], "metadata": {"task_id": "awslabs_fortuna/188", "ground_truth": "        self._fun = fun", "fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "context_start_lineno": 352, "line_no": 598, "query_window": {"context": "                for x_batch, y_batch in zip(x_batches, y_batches):\n                    yield x_batch, y_batch\n\n            yield from PrefetchedGenerator(make_gen()) if self._prefetch else make_gen()\n\n\nclass FromCallableIterableToDataLoader:\n    def __init__(\n        self, fun: Callable[[], Iterable[Batch],],\n    ):\n        self._fun = fun\n\n    def __call__(self, *args, **kwargs):\n        return self._fun()\n\n\nclass FromCallableIterableToInputsLoader:\n    def __init__(\n        self, fun: Callable[[], Iterable[Array]],\n    ):", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 598, "task_id": "awslabs_fortuna/188", "start_line_no": 578, "end_line_no": 598, "window_size": 20, "context_start_lineno": 352, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            FromDataLoaderToInputsLoader,\n            FromCallableIterableToInputsLoader,\n            FromIterableToInputsLoader,\n            ChoppedInputsLoader\n        ],\n    ):\n        \"\"\"\n        An inputs loader class. Each batch is an array of inputs, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        inputs_loader : Union[FromArrayInputsToInputsLoader, FromDataLoaderToInputsLoader]\n            An inputs loader.\n        \"\"\"\n        self._inputs_loader = inputs_loader\n\n    def __iter__(self):\n        yield from self._inputs_loader()\n\n    @classmethod", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.308411214953271}, {"context": "        ----------\n        inputs_loader : Union[FromArrayInputsToInputsLoader, FromDataLoaderToInputsLoader]\n            An inputs loader.\n        \"\"\"\n        self._inputs_loader = inputs_loader\n\n    def __iter__(self):\n        yield from self._inputs_loader()\n\n    @classmethod\n    def from_data_loader(cls, data_loader: DataLoader) -> InputsLoader:\n        \"\"\"\n        Reduce a data loader to an inputs loader.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader.\n\n        Returns", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.29411764705882354}, {"context": "        data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n        FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n            A data loader.\n        \"\"\"\n        self._data_loader = data_loader\n\n    def __iter__(self):\n        yield from self._data_loader()\n\n    @classmethod\n    def from_array_data(\n        cls,\n        data: Batch,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ) -> DataLoader:\n        \"\"\"\n        Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n        respectively.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2892561983471074}, {"context": "                .reshape(n_devices, shape[1] // n_devices, shape[0], shape[2])\n                .swapaxes(1, 2)\n            )\n\n        class TargetsLoaderWrapper:\n            def __init__(self, outputs_loader: TargetsLoader):\n                self._outputs_loader = outputs_loader\n\n            def __iter__(self):\n                outputs_loader = map(\n                    lambda batch: tree_map(_reshape_batch, batch), self._outputs_loader\n                )\n                outputs_loader = jax_utils.prefetch_to_device(outputs_loader, 2)\n                yield from outputs_loader\n\n        return (\n            TargetsLoaderWrapper(outputs_loader)\n            if outputs_loader is not None\n            else outputs_loader\n        )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "prob_model_calibrator.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.28205128205128205}, {"context": "        \"\"\"\n        Reduce an inputs loader to an array of inputs.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        inputs = []\n        for batch_inputs in self._inputs_loader():\n            inputs.append(batch_inputs)\n        return np.concatenate(inputs, 0)\n\n    @classmethod\n    def from_callable_iterable(\n        cls, fun: Callable[[], Iterable[Array]],\n    ) -> InputsLoader:\n        \"\"\"\n        Transform a callable iterable into a :class:`~fortuna.data.loader.InputsLoader` object.\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2773109243697479}, {"context": "                self._data_loader = data_loader\n\n            def __iter__(self):\n                data_loader = map(\n                    lambda batch: tree_map(_reshape_batch, batch), self._data_loader\n                )\n                data_loader = jax_utils.prefetch_to_device(data_loader, 2)\n                yield from data_loader\n\n        return (\n            DataLoaderWrapper(data_loader) if data_loader is not None else data_loader\n        )\n\n    @staticmethod\n    def _add_device_dim_to_outputs_loader(\n        outputs_loader: TargetsLoader,\n    ) -> TargetsLoader:\n        def _reshape_batch(batch):\n            n_devices = jax.local_device_count()\n            if batch.shape[0] % n_devices != 0:", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.27049180327868855}, {"context": "            Whether to prefetch the next batch.\n\n        Returns\n        -------\n        DataLoader\n            A data loader built out of the tuple of arrays.\n        \"\"\"\n        return cls(\n            data_loader=FromArrayDataToDataLoader(\n                data, batch_size=batch_size, shuffle=shuffle, prefetch=prefetch\n            )\n        )\n\n    @classmethod\n    def from_callable_iterable(cls, fun: Callable[[], Iterable[Batch],],) -> DataLoader:\n        \"\"\"\n        Transform a callable iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.27049180327868855}, {"context": "            )\n        )\n\n    @classmethod\n    def from_callable_iterable(cls, fun: Callable[[], Iterable[Batch],],) -> DataLoader:\n        \"\"\"\n        Transform a callable iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        fun: Callable[[], Iterable[Batch]]\n            A callable iterable of tuples of input and target arrays.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromCallableIterableToDataLoader(fun))\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2672413793103448}, {"context": "from __future__ import annotations\n\nfrom typing import Callable, Iterable, Optional, Union\n\nimport jax\nimport numpy as np\nfrom flax import jax_utils\nfrom jax.tree_util import tree_map\n\nfrom fortuna.typing import Array, Batch\n\n\nclass DataLoader:\n    def __init__(\n        self,\n        data_loader: Union[\n            FromIterableToDataLoader,\n            FromCallableIterableToDataLoader,\n            FromArrayDataToDataLoader,\n            FromTensorFlowDataLoaderToDataLoader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.25471698113207547}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/_utils.py\n# --------------------------------------------------\n#     def __exit__(self, exc_type, exc_val, exc_tb):\n#         t = time.time() - self.t0\n#         val = self._REG.setdefault(self.name, [0.0, 0.0, 0])\n# \n#         count = val[2]\n#         N = count + 1\n#         val[0] = val[0] * (count / N) + t / N\n#         val[1] += t\n#         val[2] = N\n# \n#     @staticmethod\n#     def print(prefix=None):\n#         keys = list(timeit._REG)\n#         keys.sort()\n#         for name in keys:\n#             strings = []\n#             if prefix:\n#                 strings.append(prefix)\n#             strings.append(\n#                 f\"{name} took {timeit._REG[name][0] * 1000:4.4} msec (total = {timeit._REG[name][1]} sec)\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n#         if prioritized:\n#             td_out.set(replay_buffer.priority_key, torch.rand(N))\n# \n#         td_out = trainer._post_loss_hook(td_out)\n#         if prioritized:\n#             for idx in range(min(S, batch)):\n#                 if idx in td_out.get(\"index\"):\n#                     assert replay_buffer._sampler._sum_tree[idx] != 1.0\n#                 else:\n#                     assert replay_buffer._sampler._sum_tree[idx] == 1.0\n# \n#     @pytest.mark.parametrize(\n#         \"storage_type\",\n#         [\n#             \"memmap\",\n#             \"list\",\n#         ],\n#     )\n#     def test_rb_trainer_state_dict(self, prioritized, storage_type):\n#         torch.manual_seed(0)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n# \n#     @pytest.mark.parametrize(\n#         \"storage_type\",\n#         [\n#             \"memmap\",\n#             \"list\",\n#         ],\n#     )\n#     def test_rb_trainer_state_dict(self, prioritized, storage_type):\n#         torch.manual_seed(0)\n#         trainer = mocking_trainer()\n#         S = 100\n#         if storage_type == \"list\":\n#             storage = ListStorage(S)\n#         elif storage_type == \"memmap\":\n#             storage = LazyMemmapStorage(S)\n#         else:\n#             raise NotImplementedError\n# \n#         if prioritized:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_libs.py\n# --------------------------------------------------\n# \n#     @pytest.mark.parametrize(\"batch_size\", [(), (5,), (5, 4)])\n#     def test_brax_batch_size(self, envname, batch_size):\n#         env = BraxEnv(envname, batch_size=batch_size)\n#         env.set_seed(0)\n#         tdreset = env.reset()\n#         tdrollout = env.rollout(max_steps=50)\n#         env.close()\n#         del env\n#         assert tdreset.batch_size == batch_size\n#         assert tdrollout.batch_size[:-1] == batch_size\n# \n#     @pytest.mark.parametrize(\"batch_size\", [(), (5,), (5, 4)])\n#     def test_brax_spec_rollout(self, envname, batch_size):\n#         env = BraxEnv(envname, batch_size=batch_size)\n#         env.set_seed(0)\n#         check_env_specs(env)\n# \n#     @pytest.mark.parametrize(\"batch_size\", [(), (5,), (5, 4)])\n#     @pytest.mark.parametrize(\"requires_grad\", [False, True])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_specs.py\n# --------------------------------------------------\n#         )\n#     )\n#     projection = ts._project(rand)\n# \n#     assert rand.shape == projection.shape\n#     assert ts.is_in(projection)\n#     if projection.ndim < 1:\n#         projection.fill_(-1)\n#     else:\n#         projection[..., 0] = -1\n#     assert not ts.is_in(projection)\n# \n# \n# @pytest.mark.parametrize(\n#     \"n\",\n#     [\n#         1,\n#         4,\n#         7,\n#         99,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#             )\n#         x = self._rand(space=self.space, shape=shape, i=self.nvec.ndim)\n#         if self.shape == torch.Size([1]):\n#             x = x.squeeze(-1)\n#         return x\n# \n#     def _project(self, val: torch.Tensor) -> torch.Tensor:\n#         val_is_scalar = val.ndim < 1\n#         if val_is_scalar:\n#             val = val.unsqueeze(0)\n#         if not self.dtype.is_floating_point:\n#             val = torch.round(val)\n#         val = val.type(self.dtype)\n#         val[val >= self.nvec] = (self.nvec.expand_as(val)[val >= self.nvec] - 1).type(\n#             self.dtype\n#         )\n#         return val.squeeze(0) if val_is_scalar else val\n# \n#     def is_in(self, val: torch.Tensor) -> bool:\n#         if val.ndim < 1:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#                 )\n#         return torch.stack(x, -1)\n# \n#     def rand(self, shape: Optional[torch.Size] = None) -> torch.Tensor:\n#         if shape is None:\n#             shape = self.shape[:-1]\n#         else:\n#             shape = (\n#                 *shape,\n#                 *self.shape[:-1],\n#             )\n#         x = self._rand(space=self.space, shape=shape, i=self.nvec.ndim)\n#         if self.shape == torch.Size([1]):\n#             x = x.squeeze(-1)\n#         return x\n# \n#     def _project(self, val: torch.Tensor) -> torch.Tensor:\n#         val_is_scalar = val.ndim < 1\n#         if val_is_scalar:\n#             val = val.unsqueeze(0)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nictReplayBuffer or rb_type is RemoteTensorDictReplayBuffer\n        ):\n            data = TensorDict(\n                {\n                    \"a\": torch.randint(100, (size,)),\n                    \"b\": TensorDict({\"c\": torch.randint(100, (size,))}, [size]),\n                },\n                [size],\n            )\n        else:\n            raise NotImplementedError(rb_type)\n        return data\n\n    def test_add(self, rb_type, sampler, writer, storage, size):\n        if rb_type is RemoteTensorDictReplayBuffer and _os_is_windows:\n            pytest.skip(\n                \"Distributed package support on Windows is a prototype feature and is subject to changes.\"\n            )\n        torch.manual_seed(0)\n        rb = self._get_rb(\n            rb_type=rb_type, sampler=sampler, writer=writer, storage=storage, size=size\n        )\n        data = self._get_datum(rb_type)\n        rb.add(data)\n        s = rb._storage[0]\n        if isinstance(s, TensorDictBase):\n            assert (s == data.select(*s.keys())).all()\n        else:\n            assert (s == data).all()\n\n    def test_cursor_position(self, rb_type, sampler, writer, storage, size):\n        storage = storage(size)\n        writer = writer()\n        writer.register_storage(storage)\n        batch1 = self._get_data(rb_type, size=5)\n        writer.extend(batch1)\n\n        # Added less data than storage max size\n        if size > 5:\n            assert writer._cursor == 5\n        # Added more data than storage max size\n        elif size < 5:\n            assert writer._cursor == 5 - size\n        # Added as data as storage max size\n        else:\n            assert writer._cursor == 0\n            batch2 = self._get_data(rb_type, size=size - 1)\n            writer.extend(batch2)\n            assert writer._cursor == size - 1\n\n    def test_extend(self, rb_type, sampler, writer, storage, size):\n        if rb_type is RemoteTensorDictReplayBuffer and _os_is_windows:\n            pytest.skip(\n                \"Distributed package support on Windows is a prototype feature and is subject to changes.\"\n            )\n        torch.manual_seed(0)\n        rb = self._get_rb(\n            rb_type=rb_type, sampler=sampler, writer=writer, storage=storage, size=size\n        )\n        data = self._get_data(rb_type, size=5)\n        rb.extend(data)\n        length = len(rb)\n        for d in data[-length:]:\n            found_similar = False\n            for b in rb._storage:\n                if isinstance(b, TensorDictBase):\n                    keys = set(d.keys()).intersection(b.keys())\n                    b = b.exclude(\"index\").select(*keys, strict=False)\n                    keys = set(d.keys()).intersection(b.keys())\n                    d = d.select(*keys, strict=False)\n\n                value = b == d\n                if isinstance(value, (torch.Tensor, TensorDictBase)):\n                    value = value.all()\n                if value:\n                    break\n            else:\n                raise RuntimeError(\"did not find match\")\n\n    def test_sample(self, rb_type, sampler, writer, storage, size):\n        if rb_type is RemoteTensorDictReplayBuffer and _os_is_windows:\n            pytest.skip(\n                \"Distributed package support on Windows is a prototype feature and is subject to changes.\"\n            )\n        torch.manual_seed(0)\n        rb = self._get_rb(\n            rb_type=rb_type, sampler=sampler, writer=writer, storage=storage, size=size\n        )\n        data = self._get_data(rb_type, size=5)\n        rb.extend(data)\n        new_data = rb.sample(3)\n        if not isinstance(new_data, (torch.Tensor, TensorDictBase)):\n            new_data = new_data[0]\n\n        for d in new_data:\n            for b in data:\n                if isinstance(b, TensorDictBase):\n                    keys = set(d.keys()).intersection(b.keys())\n                    b = b.exclude(\"index\").select(*keys, strict=False)\n                    keys = set(d.keys()).intersection(b.keys())\n                    d = d.select(*keys, strict=False)\n\n                value = b == d\n                if isinstance(value, (torch.Tensor, TensorDictBase)):\n                    value = value.all()\n                if value:\n                    break\n            else:\n                raise RuntimeError(\"did not find match\")\n\n    def test_index(self, rb_type, sampler, writer, storage, size):\n        if rb_type is RemoteTensorDictReplayBuffer and _os_is_windows:\n            pytest.skip(\n                \"Distributed package support on Windows is a prototype feature and is subject to changes.\"\n            )\n        torch.manual_seed(0)\n        rb = self._get_rb(\n            rb_type=rb_type, sampler=sampler, writer=writer, storage=storage, size=size\n        )\n        data = self._get_data(rb_type, size=5)\n        rb.extend(data)\n        d1 = rb[2]\n        d2 = rb._storage[2]\n        if type(d1) is not type(d2):\n            d1 = d1[0]\n        b = d1 == d2\n        if not isinstance(b, bool):\n            b = b.all()\n        assert b\n\n\n@pytest.mark.parametrize(\"max_size\", [1000])\n@pytest.mark.parametrize(\"shape\", [[3, 4]])\n@pytest.mark.parametrize(\"storage\", [LazyTensorStorage, LazyMemmapStorage])\nclass TestStorages:\n    def _get_nested_tensorclass(self, shape):\n        @tensorclass\n        class NestedTensorClass:\n            key1: torch.Tensor\n            key2: torch.Tensor\n\n        @tensorclass\n        class TensorClass:\n            key1: torch.Tensor\n            key2: torch.Tensor\n            next: NestedTensorClass\n\n        return TensorClass(\n            key1=torch.ones(*shape),\n            key2=torch.ones(*shape),\n            next=NestedTensorClass(\n                key1=torch.ones(*shape), key2=torch.ones(*shape), batch_size=shape\n            ),\n            batch_size=shape,\n        )\n\n    def _get_nested_td(self, shape):\n        nested_td = TensorDict(\n            {\n                \"key1\": torch.ones(*shape),\n                \"key2\": torch.ones(*shape),\n                \"next\": TensorDict(\n                    {\n                        \"key1\": torch.ones(*shape),\n                        \"key2\": torch.ones(*shape),\n                    },\n                    shape,\n                ),\n            },\n            shape,\n        )\n        return nested_td\n\n    def test_init(self, max_size, shape, storage):\n        td = self._get_nested_td(shape)\n        mystorage = storage(max_size=max_size)\n        mystorage._init(td)\n        assert mystorage._storage.shape == (max_size, *shape)\n\n    def test_set(self, max_size, shape, storage):\n        td = self._get_nested_td(shape)\n        mystorage = storage(max_size=max_size)\n        mystorage.set(list(range(td.shape[0])), td)\n        assert mystorage._storage.shape == (max_size, *shape[1:])\n        idx = list(range(1, td.shape[0] - 1))", "choices": [{"text": "assert (mystorage.get(idx) == td[1:-1]).all()"}], "metadata": {"task_id": "pytorch_rl/135", "ground_truth": "        tc_sample = mystorage.get(idx)", "fpath_tuple": ["pytorch_rl", "test", "test_rb.py"], "context_start_lineno": 107, "line_no": 292, "query_window": {"context": "                    },\n                    shape,\n                ),\n            },\n            shape,\n        )\n        return nested_td\n\n    def test_init(self, max_size, shape, storage):\n        td = self._get_nested_td(shape)\n        mystorage = storage(max_size=max_size)\n        mystorage._init(td)\n        assert mystorage._storage.shape == (max_size, *shape)\n\n    def test_set(self, max_size, shape, storage):\n        td = self._get_nested_td(shape)\n        mystorage = storage(max_size=max_size)\n        mystorage.set(list(range(td.shape[0])), td)\n        assert mystorage._storage.shape == (max_size, *shape[1:])\n        idx = list(range(1, td.shape[0] - 1))", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_rb.py"], "line_no": 292, "task_id": "pytorch_rl/135", "start_line_no": 272, "end_line_no": 292, "window_size": 20, "context_start_lineno": 107, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "                x.append(self._rand(_s, shape[:-1], i - 1))\n            else:\n                x.append(\n                    torch.randint(\n                        0,\n                        _s.n,\n                        shape,\n                        device=self.device,\n                        dtype=self.dtype,\n                    )\n                )\n        return torch.stack(x, -1)\n\n    def rand(self, shape: Optional[torch.Size] = None) -> torch.Tensor:\n        if shape is None:\n            shape = self.shape[:-1]\n        else:\n            shape = (\n                *shape,\n                *self.shape[:-1],", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 1440, "start_line_no": 1430, "end_line_no": 1450, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3516483516483517}, {"context": "                )\n        return torch.stack(x, -1)\n\n    def rand(self, shape: Optional[torch.Size] = None) -> torch.Tensor:\n        if shape is None:\n            shape = self.shape[:-1]\n        else:\n            shape = (\n                *shape,\n                *self.shape[:-1],\n            )\n        x = self._rand(space=self.space, shape=shape, i=self.nvec.ndim)\n        if self.shape == torch.Size([1]):\n            x = x.squeeze(-1)\n        return x\n\n    def _project(self, val: torch.Tensor) -> torch.Tensor:\n        val_is_scalar = val.ndim < 1\n        if val_is_scalar:\n            val = val.unsqueeze(0)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 1450, "start_line_no": 1440, "end_line_no": 1460, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3469387755102041}, {"context": "                *nvec_shape,\n            ]\n        ), (r.shape, ns, shape, _real_shape, nvec_shape)\n        assert ts.is_in(r), (r, r.shape, ns)\n    rand = torch.rand(\n        torch.Size(\n            [\n                *_real_shape,\n                *nvec_shape,\n            ]\n        )\n    )\n    projection = ts._project(rand)\n\n    assert rand.shape == projection.shape\n    assert ts.is_in(projection)\n    if projection.ndim < 1:\n        projection.fill_(-1)\n    else:\n        projection[..., 0] = -1", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_specs.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.32954545454545453}, {"context": "            torch.manual_seed(0)\n            np.random.seed(0)\n            final_seed.append(env.set_seed(0))\n            tdreset.append(env.reset())\n            tdrollout.append(env.rollout(max_steps=50))\n            env.close()\n            del env\n        assert final_seed[0] == final_seed[1]\n        assert_allclose_td(*tdreset)\n        assert_allclose_td(*tdrollout)\n\n    @pytest.mark.parametrize(\"batch_size\", [(), (5,), (5, 4)])\n    def test_brax_batch_size(self, envname, batch_size):\n        env = BraxEnv(envname, batch_size=batch_size)\n        env.set_seed(0)\n        tdreset = env.reset()\n        tdrollout = env.rollout(max_steps=50)\n        env.close()\n        del env\n        assert tdreset.batch_size == batch_size", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_libs.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3137254901960784}, {"context": "        if prioritized:\n            td_out.set(replay_buffer.priority_key, torch.rand(N))\n\n        td_out = trainer._post_loss_hook(td_out)\n        if prioritized:\n            for idx in range(min(S, batch)):\n                if idx in td_out.get(\"index\"):\n                    assert replay_buffer._sampler._sum_tree[idx] != 1.0\n                else:\n                    assert replay_buffer._sampler._sum_tree[idx] == 1.0\n\n    @pytest.mark.parametrize(\n        \"storage_type\",\n        [\n            \"memmap\",\n            \"list\",\n        ],\n    )\n    def test_rb_trainer_state_dict(self, prioritized, storage_type):\n        torch.manual_seed(0)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3103448275862069}, {"context": "            },\n            [batch],\n        )\n        td_out = trainer._process_batch_hook(td)\n        assert td_out is td\n\n        td_out = trainer._process_optim_batch_hook(td)\n        assert td_out is not td\n        assert td_out.shape[0] == N\n\n        if prioritized:\n            td_out.set(replay_buffer.priority_key, torch.rand(N))\n\n        td_out = trainer._post_loss_hook(td_out)\n        if prioritized:\n            for idx in range(min(S, batch)):\n                if idx in td_out.get(\"index\"):\n                    assert replay_buffer._sampler._sum_tree[idx] != 1.0\n                else:\n                    assert replay_buffer._sampler._sum_tree[idx] == 1.0", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3069306930693069}, {"context": "        def decorated_fn(*args, **kwargs):\n            with self:\n                out = fn(*args, **kwargs)\n                return out\n\n        return decorated_fn\n\n    def __enter__(self):\n        self.t0 = time.time()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        t = time.time() - self.t0\n        val = self._REG.setdefault(self.name, [0.0, 0.0, 0])\n\n        count = val[2]\n        N = count + 1\n        val[0] = val[0] * (count / N) + t / N\n        val[1] += t\n        val[2] = N\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30526315789473685}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/serial_entry_onpolicy.py\n# --------------------------------------------------\n# from ding.config import read_config, compile_config\n# from ding.policy import create_policy, PolicyFactory\n# from ding.utils import set_pkg_seed\n# \n# \n# def serial_pipeline_onpolicy(\n#         input_cfg: Union[str, Tuple[dict, dict]],\n#         seed: int = 0,\n#         env_setting: Optional[List[Any]] = None,\n#         model: Optional[torch.nn.Module] = None,\n#         max_iterations: Optional[int] = int(1e10),\n# ) -> 'Policy':  # noqa\n#     \"\"\"\n#     Overview:\n#         Serial pipeline entry for onpolicy algorithm(such as PPO).\n#     Arguments:\n#         - input_cfg (:obj:`Union[str, Tuple[dict, dict]]`): Config in dict type. \\\n#             ``str`` type means config file path. \\\n#             ``Tuple[dict, dict]`` type means [user_config, create_cfg].\n#         - seed (:obj:`int`): Random seed.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/serial_entry.py\n# --------------------------------------------------\n# from ding.config import read_config, compile_config\n# from ding.policy import create_policy, PolicyFactory\n# from ding.utils import set_pkg_seed\n# \n# \n# def serial_pipeline(\n#         input_cfg: Union[str, Tuple[dict, dict]],\n#         seed: int = 0,\n#         env_setting: Optional[List[Any]] = None,\n#         model: Optional[torch.nn.Module] = None,\n#         max_iterations: Optional[int] = int(1e20),\n# ) -> 'Policy':  # noqa\n#     \"\"\"\n#     Overview:\n#         Serial pipeline entry.\n#     Arguments:\n#         - input_cfg (:obj:`Union[str, Tuple[dict, dict]]`): Config in dict type. \\\n#             ``str`` type means config file path. \\\n#             ``Tuple[dict, dict]`` type means [user_config, create_cfg].\n#         - seed (:obj:`int`): Random seed.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/serial_entry_reward_model.py\n# --------------------------------------------------\n# from ding.config import read_config, compile_config\n# from ding.policy import create_policy, PolicyFactory\n# from ding.reward_model import create_reward_model\n# from ding.utils import set_pkg_seed\n# \n# \n# def serial_pipeline_reward_model(\n#         input_cfg: Union[str, Tuple[dict, dict]],\n#         seed: int = 0,\n#         env_setting: Optional[List[Any]] = None,\n#         model: Optional[torch.nn.Module] = None,\n#         max_iterations: Optional[int] = int(1e10),\n# ) -> 'Policy':  # noqa\n#     \"\"\"\n#     Overview:\n#         Serial pipeline entry with reward model.\n#     Arguments:\n#         - input_cfg (:obj:`Union[str, Tuple[dict, dict]]`): Config in dict type. \\\n#             ``str`` type means config file path. \\\n#             ``Tuple[dict, dict]`` type means [user_config, create_cfg].\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/serial_entry_sqil.py\n# --------------------------------------------------\n#     create_serial_collector\n# from ding.config import read_config, compile_config\n# from ding.policy import create_policy, PolicyFactory\n# from ding.utils import set_pkg_seed\n# \n# \n# def serial_pipeline_sqil(\n#         input_cfg: Union[str, Tuple[dict, dict]],\n#         expert_cfg: Union[str, Tuple[dict, dict]],\n#         seed: int = 0,\n#         env_setting: Optional[List[Any]] = None,\n#         model: Optional[torch.nn.Module] = None,\n#         expert_model: Optional[torch.nn.Module] = None,\n#         max_iterations: Optional[int] = int(1e10),\n# ) -> 'Policy':  # noqa\n#     \"\"\"\n#     Overview:\n#         Serial pipeline sqil entry: we create this serial pipeline in order to\\\n#             implement SQIL in DI-engine. For now, we support the following envs\\\n#             Cartpole, Lunarlander, Pong, Spaceinvader, Qbert. The demonstration\\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/serial_entry_il.py\n# --------------------------------------------------\n# from typing import Union, Optional, Tuple\n# import os\n# import torch\n# from functools import partial\n# from tensorboardX import SummaryWriter\n# from torch.utils.data import DataLoader\n# \n# from ding.worker import BaseLearner, InteractionSerialEvaluator\n# from ding.envs import get_vec_env_setting, create_env_manager\n# from ding.config import read_config, compile_config\n# from ding.policy import create_policy\n# from ding.utils import set_pkg_seed\n# from ding.utils.data import NaiveRLDataset\n# \n# \n# def serial_pipeline_il(\n#         input_cfg: Union[str, Tuple[dict, dict]],\n#         seed: int,\n#         data_path: str,\n#         model: Optional[torch.nn.Module] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/serial_entry_sqil.py\n# --------------------------------------------------\n# from ding.policy.base_policy import Policy\n# from typing import Union, Optional, List, Any, Tuple\n# import os\n# import torch\n# import logging\n# from functools import partial\n# from tensorboardX import SummaryWriter\n# \n# from ding.envs import get_vec_env_setting, create_env_manager\n# from ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n#     create_serial_collector\n# from ding.config import read_config, compile_config\n# from ding.policy import create_policy, PolicyFactory\n# from ding.utils import set_pkg_seed\n# \n# \n# def serial_pipeline_sqil(\n#         input_cfg: Union[str, Tuple[dict, dict]],\n#         expert_cfg: Union[str, Tuple[dict, dict]],\n#         seed: int = 0,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/serial_entry_offline.py\n# ding/entry/serial_entry_onpolicy.py\n# ding/entry/serial_entry.py\n# ding/entry/serial_entry_reward_model.py\n# --------------------------------------------------\n# from typing import Union, Optional, List, Any, Tuple\n# import os\n# import torch\n# import logging\n# from functools import partial\n# from tensorboardX import SummaryWriter\n# \n# from ding.envs import get_vec_env_setting, create_env_manager\n# from ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n#     create_serial_collector\n# from ding.config import read_config, compile_config\n# from ding.policy import create_policy, PolicyFactory\n# from ding.utils import set_pkg_seed\n# from ding.utils.data import create_dataset\n# \n# from torch.utils.data import DataLoader\n# \n# \n# def serial_pipeline_offline(\n#         input_cfg: Union[str, Tuple[dict, dict]],\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import Union, Optional, List, Any, Tuple\nimport os\nimport torch\nimport logging\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\n\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n    create_serial_collector", "choices": [{"text": "from ding.config import read_config, compile_config"}], "metadata": {"task_id": "opendilab_ACE/141", "ground_truth": "from ding.config import read_config, compile_config", "fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_offline.py"], "context_start_lineno": 0, "line_no": 10, "query_window": {"context": "from typing import Union, Optional, List, Any, Tuple\nimport os\nimport torch\nimport logging\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\n\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n    create_serial_collector", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_offline.py"], "line_no": 10, "task_id": "opendilab_ACE/141", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "from typing import Union, Optional, List, Any, Tuple\nimport os\nimport torch\nimport logging\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\n\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n    create_serial_collector", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_offline.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}, {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_onpolicy.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}, {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}, {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_reward_model.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 1.0}, {"context": "from ding.policy.base_policy import Policy\nfrom typing import Union, Optional, List, Any, Tuple\nimport os\nimport torch\nimport logging\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\n\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_sqil.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.8947368421052632}, {"context": "from typing import Union, Optional, Tuple\nimport os\nimport torch\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\nfrom torch.utils.data import DataLoader\n\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.config import read_config, compile_config", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_il.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.7213114754098361}, {"context": "from ding.policy.base_policy import Policy\nfrom typing import Union, Optional, List, Any, Tuple\nimport os\nimport torch\nimport logging\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\n\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n    create_serial_collector\nfrom ding.config import read_config, compile_config\nfrom ding.policy import create_policy, PolicyFactory\nfrom ding.utils import set_pkg_seed\n\n\ndef serial_pipeline_sqil(\n        input_cfg: Union[str, Tuple[dict, dict]],\n        expert_cfg: Union[str, Tuple[dict, dict]],\n        seed: int = 0,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_sqil.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6067415730337079}, {"context": "from typing import Union, Optional, List, Any, Tuple\nimport os\nimport torch\nimport logging\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\n\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n    create_serial_collector\nfrom ding.config import read_config, compile_config\nfrom ding.policy import create_policy, PolicyFactory\nfrom ding.reward_model import create_reward_model\nfrom ding.utils import set_pkg_seed\n\n\ndef serial_pipeline_reward_model(\n        input_cfg: Union[str, Tuple[dict, dict]],\n        seed: int = 0,\n        env_setting: Optional[List[Any]] = None,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_reward_model.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5806451612903226}, {"context": "from typing import Union, Optional, List, Any, Tuple\nimport os\nimport torch\nimport logging\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\n\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n    create_serial_collector\nfrom ding.config import read_config, compile_config\nfrom ding.policy import create_policy, PolicyFactory\nfrom ding.utils import set_pkg_seed\n\n\ndef serial_pipeline(\n        input_cfg: Union[str, Tuple[dict, dict]],\n        seed: int = 0,\n        env_setting: Optional[List[Any]] = None,\n        model: Optional[torch.nn.Module] = None,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5684210526315789}, {"context": "from typing import Union, Optional, List, Any, Tuple\nimport os\nimport torch\nimport logging\nfrom functools import partial\nfrom tensorboardX import SummaryWriter\n\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.worker import BaseLearner, InteractionSerialEvaluator, BaseSerialCommander, create_buffer, \\\n    create_serial_collector\nfrom ding.config import read_config, compile_config\nfrom ding.policy import create_policy, PolicyFactory\nfrom ding.utils import set_pkg_seed\n\n\ndef serial_pipeline_onpolicy(\n        input_cfg: Union[str, Tuple[dict, dict]],\n        seed: int = 0,\n        env_setting: Optional[List[Any]] = None,\n        model: Optional[torch.nn.Module] = None,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "serial_entry_onpolicy.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5625}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/stochastic_process_model.py\n# --------------------------------------------------\n#   coro = GaussianProcessARD(dimension=dim)\n#   gp_model = StochasticProcessModel(coroutine=coro)\n# \n#   # Initialize the Flax parameters.\n#   init_params = gp_model.init(random.PRNGKey(1), x_observed)\n# \n#   # Build a GP with `x_observed` as index points. By default, `apply` invokes\n#   # the Flax module's `__call__` method.\n#   gp, regularization_losses = gp_model.apply(\n#       init_params,\n#       x_observed,\n#       mutable=('losses',))\n# \n#   # Run the expensive computation (often a Cholesky decomposition) necessary to\n#   # compute the GP posterior predictive, and return the predictive distribution\n#   # as mutable state.\n#   _, pp_state = gp_model.apply(\n#       {'params': init_state['params']},\n#       x_observed,\n#       y_observed,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/stochastic_process_model.py\n# --------------------------------------------------\n#       method=gp_model.predict)\n#   ```\n#   \"\"\"\n# \n#   coroutine: ModelCoroutine\n#   mean_fn: Callable[[_In], Array] = lambda _: 0.0\n# \n#   def setup(self):\n#     \"\"\"Builds module parameters.\"\"\"\n#     generator = self.coroutine()\n#     try:\n#       p: ModelParameter = next(generator)\n#       while True:\n#         # Declare a Flax variable with the name and initialization function from\n#         # the `ModelParameter`.\n#         param: Array = self.param(p.name, p.init_fn)\n#         p: ModelParameter = generator.send(param)\n#     except StopIteration:\n#       # Ignore the return value from the generator since this method only builds\n#       # the Flax parameters.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/gaussian_process_ard_test.py\n# --------------------------------------------------\n#     gp, param_vals = _run_coroutine(coro(x), seed=coro_key)\n#     samples = gp.sample(100, seed=sample_key)\n#     self.assertSequenceEqual(gp.event_shape, [num_obs])\n#     self.assertEmpty(gp.batch_shape)\n#     self.assertTrue(np.isfinite(gp.log_prob(samples)).all())\n#     self.assertSameElements(\n#         param_vals.keys(),\n#         ('amplitude', 'inverse_length_scale', 'observation_noise_variance'))\n#     self.assertEmpty(param_vals['amplitude'].shape)\n#     self.assertEmpty(param_vals['observation_noise_variance'].shape)\n#     self.assertSequenceEqual(param_vals['inverse_length_scale'].shape, [dim])\n# \n# \n# def _run_coroutine(g, seed):\n#   param = next(g)\n#   param_vals = {}\n#   try:\n#     while True:\n#       seed, current_seed = random.split(seed)\n#       v = param.init_fn(current_seed)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/models/tuned_gp_models.py\n# --------------------------------------------------\n#       # how many examples we have.\n#       loss = (-gp.log_prob(labels) + jax.tree_util.tree_reduce(\n#           jax.numpy.add, mutables['losses'])) / features.shape[0]\n#       return loss, dict()\n# \n#     return model, loss_fn\n# \n#   def _log_uniform_init(\n#       self, low: float, high: float, shape: tuple[int,\n#                                                   ...] = tuple()) -> sp.InitFn:\n#     r\"\"\"Take log-uniform sample in the constraint and map it back to \\R.\n# \n#     Args:\n#       low: Parameter lower bound.\n#       high: Parameter upper bound.\n#       shape: Returned array has this shape. Each entry in the returned array is\n#         an i.i.d sample.\n# \n#     Returns:\n#       Randomly sampled array.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/models/hebo_gp_model_test.py\n# --------------------------------------------------\n#     init_params = setup(key)\n#     optimize = optimizers.OptaxTrainWithRandomRestarts(\n#         optax.adam(5e-3), epochs=500, verbose=True, random_restarts=20\n#     )\n#     constraints = sp.get_constraints(model.coroutine)\n#     params, metrics = optimize(setup, loss_fn, key, constraints=constraints)\n# \n#     init_gp = model.apply({'params': init_params}, self.x_obs)\n#     gp = model.apply({'params': params}, self.x_obs)\n#     self.assertGreater(gp.log_prob(self.y_obs), init_gp.log_prob(self.y_obs))\n#     losses_every_50 = metrics['loss'][::50]\n#     self.assertTrue((losses_every_50[1:] < losses_every_50[:-1]).all())\n# \n#     logging.info('Optimal parameters: %s', params)\n#     logging.info('Optimal loss fn: %s', loss_fn(params)[0])\n#     self.assertLess(loss_fn(params)[0], 0.3)\n# \n# \n# if __name__ == '__main__':\n#   absltest.main()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/stochastic_process_model.py\n# --------------------------------------------------\n#       x_observed,\n#       mutable=('losses',))\n# \n#   # Run the expensive computation (often a Cholesky decomposition) necessary to\n#   # compute the GP posterior predictive, and return the predictive distribution\n#   # as mutable state.\n#   _, pp_state = gp_model.apply(\n#       {'params': init_state['params']},\n#       x_observed,\n#       y_observed,\n#       method=gp_model.precompute_predictive,\n#       mutable=('predictive'))\n# \n#   # Now, posterior predictive GPs over different sets of index points,\n#   # conditioned on the observed data `x_observed` and `y_observed`, can be built\n#   # without recomputing the Cholesky decomposition.\n#   x_predicted = random.uniform(random.PRNGKey(2), shape=(5, dim))\n#   pp_dist = gp_model.apply(\n#       {'params': init_state['params'], **pp_state},\n#       x_predicted,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"Tests for stochastic_process_model.\"\"\"\n\nimport functools\n\nfrom absl.testing import parameterized\nfrom flax import linen as nn\n\nimport jax\nfrom jax import numpy as jnp\nfrom jax import random\nfrom jax.config import config\nimport numpy as np\nfrom tensorflow_probability.substrates import jax as tfp\nimport tree\nfrom vizier._src.jax import stochastic_process_model as sp_model\nfrom absl.testing import absltest\n\nconfig.update('jax_enable_x64', True)\n\ntfb = tfp.bijectors\ntfd = tfp.distributions\ntfpk = tfp.math.psd_kernels\n\n\ndef _test_coroutine(inputs=None, dtype=np.float64):\n  \"\"\"A coroutine that follows the `ModelCoroutine` protocol.\"\"\"\n  constraint = sp_model.Constraint(\n      bounds=(np.zeros([], dtype=dtype), None), bijector=tfb.Exp()\n  )\n  amplitude = yield sp_model.ModelParameter(\n      init_fn=lambda k: random.exponential(k, dtype=dtype),\n      regularizer=lambda x: dtype(1e-3) * x**2,\n      constraint=constraint,\n      name='amplitude',\n  )\n  inverse_length_scale = yield sp_model.ModelParameter.from_prior(\n      tfd.Exponential(\n          rate=np.ones([], dtype=dtype), name='inverse_length_scale'\n      ),\n      constraint=constraint,\n  )\n  kernel = tfpk.ExponentiatedQuadratic(\n      amplitude=amplitude,\n      inverse_length_scale=inverse_length_scale,\n      validate_args=True)\n  return tfd.StudentTProcess(\n      df=dtype(5.0), kernel=kernel, index_points=inputs, validate_args=True\n  )\n\n\ndef _make_inputs(key, dtype):\n  obs_key, pred_key = random.split(key)\n  dim = 3\n  num_observed = 20\n  x_observed = random.uniform(obs_key, shape=(num_observed, dim), dtype=dtype)\n  y_observed = x_observed.sum(axis=-1)\n  x_predictive = random.uniform(pred_key, shape=(100, 5, dim), dtype=dtype)\n  return x_observed, y_observed, x_predictive\n\n\nclass StochasticProcessModelTest(parameterized.TestCase):\n\n  @parameterized.named_parameters(\n      # TODO: Add a test case with categorical data.\n      # TODO: Fix support for f32.\n      {\n          'testcase_name': 'continuous_only',\n          'model_coroutine': _test_coroutine,\n          'test_data_fn': _make_inputs,\n          'dtype': np.float64,\n      },\n  )\n  def test_stochastic_process_model(self, model_coroutine, test_data_fn, dtype):\n    init_key, data_key, sample_key = jax.random.split(random.PRNGKey(0), num=3)\n    x_observed, y_observed, x_predictive = test_data_fn(data_key, dtype)\n    model = sp_model.StochasticProcessModel(\n        coroutine=functools.partial(model_coroutine, dtype=dtype)\n    )\n\n    init_state = model.init(init_key, x_observed)\n    dist, losses = model.apply(init_state, x_observed, mutable=('losses',))\n    lp = dist.log_prob(y_observed)", "choices": [{"text": "gp_model.apply("}], "metadata": {"task_id": "google_vizier/187", "ground_truth": "    self.assertTrue(np.isfinite(lp))", "fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model_test.py"], "context_start_lineno": 0, "line_no": 98, "query_window": {"context": "  @parameterized.named_parameters(\n      # TODO: Add a test case with categorical data.\n      # TODO: Fix support for f32.\n      {\n          'testcase_name': 'continuous_only',\n          'model_coroutine': _test_coroutine,\n          'test_data_fn': _make_inputs,\n          'dtype': np.float64,\n      },\n  )\n  def test_stochastic_process_model(self, model_coroutine, test_data_fn, dtype):\n    init_key, data_key, sample_key = jax.random.split(random.PRNGKey(0), num=3)\n    x_observed, y_observed, x_predictive = test_data_fn(data_key, dtype)\n    model = sp_model.StochasticProcessModel(\n        coroutine=functools.partial(model_coroutine, dtype=dtype)\n    )\n\n    init_state = model.init(init_key, x_observed)\n    dist, losses = model.apply(init_state, x_observed, mutable=('losses',))\n    lp = dist.log_prob(y_observed)", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model_test.py"], "line_no": 98, "task_id": "google_vizier/187", "start_line_no": 78, "end_line_no": 98, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "  coro = GaussianProcessARD(dimension=dim)\n  gp_model = StochasticProcessModel(coroutine=coro)\n\n  # Initialize the Flax parameters.\n  init_params = gp_model.init(random.PRNGKey(1), x_observed)\n\n  # Build a GP with `x_observed` as index points. By default, `apply` invokes\n  # the Flax module's `__call__` method.\n  gp, regularization_losses = gp_model.apply(\n      init_params,\n      x_observed,\n      mutable=('losses',))\n\n  # Run the expensive computation (often a Cholesky decomposition) necessary to\n  # compute the GP posterior predictive, and return the predictive distribution\n  # as mutable state.\n  _, pp_state = gp_model.apply(\n      {'params': init_state['params']},\n      x_observed,\n      y_observed,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.26136363636363635}, {"context": "                           dtype=jnp.float64)\n\n  def test_log_prob_and_loss(self):\n    model, loss_fn = VizierHeboGaussianProcess.model_and_loss_fn(\n        features=self.x_obs, labels=self.y_obs)\n    setup = lambda rng: model.init(rng, self.x_obs)['params']\n    key = jax.random.PRNGKey(2)\n    init_params = setup(key)\n    optimize = optimizers.OptaxTrainWithRandomRestarts(\n        optax.adam(5e-3), epochs=500, verbose=True, random_restarts=20\n    )\n    constraints = sp.get_constraints(model.coroutine)\n    params, metrics = optimize(setup, loss_fn, key, constraints=constraints)\n\n    init_gp = model.apply({'params': init_params}, self.x_obs)\n    gp = model.apply({'params': params}, self.x_obs)\n    self.assertGreater(gp.log_prob(self.y_obs), init_gp.log_prob(self.y_obs))\n    losses_every_50 = metrics['loss'][::50]\n    self.assertTrue((losses_every_50[1:] < losses_every_50[:-1]).all())\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "models", "hebo_gp_model_test.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.25757575757575757}, {"context": "        features.shape[-1], use_retrying_cholesky=use_retrying_cholesky\n    )\n    model = sp.StochasticProcessModel(gp_coroutine)\n\n    # Run ARD.\n    def loss_fn(params):\n      gp, mutables = model.apply({'params': params},\n                                 features,\n                                 mutable=['losses', 'predictive'])\n      # Normalize so we can use the same learning rate regardless of\n      # how many examples we have.\n      loss = (-gp.log_prob(labels) + jax.tree_util.tree_reduce(\n          jax.numpy.add, mutables['losses'])) / features.shape[0]\n      return loss, dict()\n\n    return model, loss_fn\n\n  def _log_uniform_init(\n      self, low: float, high: float, shape: tuple[int,\n                                                  ...] = tuple()) -> sp.InitFn:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "models", "tuned_gp_models.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2538860103626943}, {"context": "  def test_gaussian_process_ard(self):\n    dim = 5\n    num_obs = 10\n    coro = gp_ard.GaussianProcessARD(\n        dimension=dim,\n        kernel_class=tfpk.ExponentiatedQuadratic,\n        use_tfp_runtime_validation=True)\n\n    obs_key, coro_key, sample_key = random.split(random.PRNGKey(0), num=3)\n    x = random.uniform(obs_key, shape=(num_obs, dim), dtype=np.float32)\n    gp, param_vals = _run_coroutine(coro(x), seed=coro_key)\n    samples = gp.sample(100, seed=sample_key)\n    self.assertSequenceEqual(gp.event_shape, [num_obs])\n    self.assertEmpty(gp.batch_shape)\n    self.assertTrue(np.isfinite(gp.log_prob(samples)).all())\n    self.assertSameElements(\n        param_vals.keys(),\n        ('amplitude', 'inverse_length_scale', 'observation_noise_variance'))\n    self.assertEmpty(param_vals['amplitude'].shape)\n    self.assertEmpty(param_vals['observation_noise_variance'].shape)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "gaussian_process_ard_test.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.23880597014925373}, {"context": "      method=gp_model.precompute_predictive,\n      mutable=('predictive'))\n\n  # Now, posterior predictive GPs over different sets of index points,\n  # conditioned on the observed data `x_observed` and `y_observed`, can be built\n  # without recomputing the Cholesky decomposition.\n  x_predicted = random.uniform(random.PRNGKey(2), shape=(5, dim))\n  pp_dist = gp_model.apply(\n      {'params': init_state['params'], **pp_state},\n      x_predicted,\n      method=gp_model.predict)\n  ```\n  \"\"\"\n\n  coroutine: ModelCoroutine\n  mean_fn: Callable[[_In], Array] = lambda _: 0.0\n\n  def setup(self):\n    \"\"\"Builds module parameters.\"\"\"\n    generator = self.coroutine()", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.23857868020304568}, {"context": "\n  ```python\n  from jax import random\n\n  # Simulate some observed data.\n  dim = 3\n  x_observed = random.uniform(random.PRNGKey(0), shape=(20, dim))\n  y_observed = x_observed.sum(axis=-1)\n\n  # Build a GP module. `coro` follows the `ModelCoroutine` protocol.\n  coro = GaussianProcessARD(dimension=dim)\n  gp_model = StochasticProcessModel(coroutine=coro)\n\n  # Initialize the Flax parameters.\n  init_params = gp_model.init(random.PRNGKey(1), x_observed)\n\n  # Build a GP with `x_observed` as index points. By default, `apply` invokes\n  # the Flax module's `__call__` method.\n  gp, regularization_losses = gp_model.apply(\n      init_params,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.23563218390804597}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_yaml.py\n# --------------------------------------------------\n# # Copyright (c) Alibaba, Inc. and its affiliates.\n# import os\n# import logging\n# import unittest\n# \n# from federatedscope.core.configs.config import global_cfg\n# \n# logger = logging.getLogger(__name__)\n# \n# \n# class YAMLTest(unittest.TestCase):\n#     def setUp(self):\n#         self.exclude_all = ['benchmark', 'scripts', 'federatedscope/autotune']\n#         self.exclude_file = [\n#             '.pre-commit-config.yaml', 'meta.yaml',\n#             'federatedscope/gfl/baseline/isolated_gin_minibatch_on_cikmcup_per_client.yaml',\n#             'federatedscope/gfl/baseline/fedavg_gin_minibatch_on_cikmcup_per_client.yaml',\n#             'federatedscope/gfl/baseline/mini_graph_dc/fedavg_per_client.yaml'\n#         ]\n#         self.exclude_str = ['config.yaml', 'config_client']\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_simclr_cifar10.py\n# --------------------------------------------------\n# # Copyright (c) Alibaba, Inc. and its affiliates.\n# import unittest\n# \n# from federatedscope.core.auxiliaries.data_builder import get_data\n# from federatedscope.core.auxiliaries.utils import setup_seed\n# from federatedscope.core.auxiliaries.logging import update_logger\n# from federatedscope.core.configs.config import global_cfg\n# from federatedscope.core.fed_runner import FedRunner\n# from federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n# \n# SAMPLE_CLIENT_NUM = 5\n# \n# \n# class SimCLR_CIFAR10Test(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config_simclr_cifar10(self, cfg):\n#         backup_cfg = cfg.clone()\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_trainer_property.py\n# tests/test_local_train_lr.py\n# --------------------------------------------------\n# # Copyright (c) Alibaba, Inc. and its affiliates.\n# import unittest\n# \n# from federatedscope.core.auxiliaries.data_builder import get_data\n# from federatedscope.core.auxiliaries.utils import setup_seed\n# from federatedscope.core.auxiliaries.logging import update_logger\n# from federatedscope.core.configs.config import global_cfg\n# from federatedscope.core.auxiliaries.runner_builder import get_runner\n# from federatedscope.core.auxiliaries.worker_builder import get_server_cls, \\\n#     get_client_cls\n# \n# \n# class TrainerCfgTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config_trainer_cfg_test(self, cfg):\n#         backup_cfg = cfg.clone()\n# \n#         import torch\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_xgb.py\n# tests/test_vertical_fl.py\n# --------------------------------------------------\n# # Copyright (c) Alibaba, Inc. and its affiliates.\n# import unittest\n# \n# from federatedscope.core.auxiliaries.data_builder import get_data\n# from federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\n# from federatedscope.core.auxiliaries.utils import setup_seed\n# from federatedscope.core.auxiliaries.logging import update_logger\n# from federatedscope.core.configs.config import global_cfg\n# from federatedscope.core.auxiliaries.runner_builder import get_runner\n# \n# \n# class XGBTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config(self, cfg):\n#         backup_cfg = cfg.clone()\n# \n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_fedsageplus.py\n# tests/test_finetune_lr.py\n# tests/test_fedopt.py\n# tests/test_backdoor_attack.py\n# tests/test_PIA_toy.py\n# tests/test_pfedme.py\n# tests/test_unseen_clients_lr.py\n# tests/test_asyn_cifar10.py\n# tests/test_graph_node_trainer.py\n# tests/test_femnist.py\n# tests/test_MIA_gradient_ascent.py\n# tests/test_optimizer.py\n# tests/test_CRA_gan_attack.py\n# tests/test_efficient_simulation.py\n# tests/test_toy_lr.py\n# tests/test_external_dataset.py\n# tests/test_global_train_lr.py\n# tests/test_nbafl.py\n# tests/test_fedprox.py\n# tests/test_fedem.py\n# tests/test_rec_opt_attack.py\n# tests/test_mf.py\n# tests/test_rec_IG_opt_attack.py\n# tests/test_ditto.py\n# --------------------------------------------------\n# # Copyright (c) Alibaba, Inc. and its affiliates.\n# import unittest\n# \n# from federatedscope.core.auxiliaries.data_builder import get_data\n# from federatedscope.core.auxiliaries.utils import setup_seed\n# from federatedscope.core.auxiliaries.logging import update_logger\n# from federatedscope.core.configs.config import global_cfg\n# from federatedscope.core.auxiliaries.runner_builder import get_runner\n# from federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n# \n# \n# class FedSagePlusTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config_fedsageplus(self, cfg):\n#         backup_cfg = cfg.clone()\n# \n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg", "choices": [{"text": "from federatedscope.core.auxiliaries.runner_builder import get_runner"}], "metadata": {"task_id": "alibaba_FederatedScope/145", "ground_truth": "from federatedscope.core.auxiliaries.runner_builder import get_runner", "fpath_tuple": ["alibaba_FederatedScope", "tests", "test_vertical_fl.py"], "context_start_lineno": 0, "line_no": 8, "query_window": {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_vertical_fl.py"], "line_no": 8, "task_id": "alibaba_FederatedScope/145", "start_line_no": 0, "end_line_no": 8, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_fedsageplus.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_finetune_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_fedopt.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_backdoor_attack.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_PIA_toy.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_pfedme.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_unseen_clients_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_asyn_cifar10.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_graph_node_trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_femnist.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_MIA_gradient_ascent.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_optimizer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_CRA_gan_attack.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_efficient_simulation.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_toy_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_external_dataset.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_global_train_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_nbafl.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_fedprox.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_fedem.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_rec_opt_attack.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_mf.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_rec_IG_opt_attack.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_ditto.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.9782608695652174}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_xgb.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_vertical_fl.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.9782608695652174}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, \\\n    get_client_cls", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_trainer_property.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_local_train_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.9375}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.fed_runner import FedRunner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_simclr_cifar10.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.9183673469387755}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport os\nimport logging\nimport unittest\n\nfrom federatedscope.core.configs.config import global_cfg\n\nlogger = logging.getLogger(__name__)\n\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_yaml.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.5555555555555556}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion.py\n# --------------------------------------------------\n#         inputs = self.get_inputs(torch_device, dtype=torch.float16)\n#         inputs[\"prompt\"] = [inputs[\"prompt\"]] * 4\n#         inputs[\"latents\"] = torch.cat([inputs[\"latents\"]] * 4)\n#         image = pipe(**inputs).images\n# \n#         # make sure that more than 4 GB is allocated\n#         mem_bytes = torch.cuda.max_memory_allocated()\n#         assert mem_bytes > 4e9\n#         # There is a small discrepancy at the image borders vs. a fully batched version.\n#         assert np.abs(image_sliced - image).max() < 1e-2\n# \n#     def test_stable_diffusion_fp16_vs_autocast(self):\n#         # this test makes sure that the original model with autocast\n#         # and the new model with fp16 yield the same result\n#         pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n#         pipe = pipe.to(torch_device)\n#         pipe.set_progress_bar_config(disable=None)\n# \n#         inputs = self.get_inputs(torch_device, dtype=torch.float16)\n#         image_fp16 = pipe(**inputs).images\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion.py\n# --------------------------------------------------\n# \n#     def test_stable_diffusion_intermediate_state(self):\n#         number_of_steps = 0\n# \n#         def callback_fn(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n#             callback_fn.has_been_called = True\n#             nonlocal number_of_steps\n#             number_of_steps += 1\n#             if step == 1:\n#                 latents = latents.detach().cpu().numpy()\n#                 assert latents.shape == (1, 4, 64, 64)\n#                 latents_slice = latents[0, -3:, -3:, -1]\n#                 expected_slice = np.array(\n#                     [-0.5693, -0.3018, -0.9746, 0.0518, -0.8770, 0.7559, -1.7402, 0.1022, 1.1582]\n#                 )\n# \n#                 assert np.abs(latents_slice.flatten() - expected_slice).max() < 5e-2\n#             elif step == 2:\n#                 latents = latents.detach().cpu().numpy()\n#                 assert latents.shape == (1, 4, 64, 64)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion.py\n# --------------------------------------------------\n#         torch.cuda.reset_peak_memory_stats()\n#         pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n#         pipe = pipe.to(torch_device)\n#         pipe.set_progress_bar_config(disable=None)\n#         pipe.enable_attention_slicing()\n# \n#         # enable vae slicing\n#         pipe.enable_vae_slicing()\n#         inputs = self.get_inputs(torch_device, dtype=torch.float16)\n#         inputs[\"prompt\"] = [inputs[\"prompt\"]] * 4\n#         inputs[\"latents\"] = torch.cat([inputs[\"latents\"]] * 4)\n#         image_sliced = pipe(**inputs).images\n# \n#         mem_bytes = torch.cuda.max_memory_allocated()\n#         torch.cuda.reset_peak_memory_stats()\n#         # make sure that less than 4 GB is allocated\n#         assert mem_bytes < 4e9\n# \n#         # disable vae slicing\n#         pipe.disable_vae_slicing()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_instruction_pix2pix.py\n# --------------------------------------------------\n#         expected_slice = np.array([0.3828, 0.3834, 0.3818, 0.3792, 0.3865, 0.3752, 0.3792, 0.3847, 0.3753])\n# \n#         assert np.abs(expected_slice - image_slice).max() < 1e-3\n# \n#     def test_stable_diffusion_pix2pix_intermediate_state(self):\n#         number_of_steps = 0\n# \n#         def callback_fn(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n#             callback_fn.has_been_called = True\n#             nonlocal number_of_steps\n#             number_of_steps += 1\n#             if step == 1:\n#                 latents = latents.detach().cpu().numpy()\n#                 assert latents.shape == (1, 4, 64, 64)\n#                 latents_slice = latents[0, -3:, -3:, -1]\n#                 expected_slice = np.array([-0.2463, -0.4644, -0.9756, 1.5176, 1.4414, 0.7866, 0.9897, 0.8521, 0.7983])\n# \n#                 assert np.abs(latents_slice.flatten() - expected_slice).max() < 5e-2\n#             elif step == 2:\n#                 latents = latents.detach().cpu().numpy()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion.py\n# --------------------------------------------------\n#         pipe.disable_attention_slicing()\n#         inputs = self.get_inputs(torch_device, dtype=torch.float16)\n#         image = pipe(**inputs).images\n# \n#         # make sure that more than 3.75 GB is allocated\n#         mem_bytes = torch.cuda.max_memory_allocated()\n#         assert mem_bytes > 3.75 * 10**9\n#         assert np.abs(image_sliced - image).max() < 1e-3\n# \n#     def test_stable_diffusion_vae_slicing(self):\n#         torch.cuda.reset_peak_memory_stats()\n#         pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n#         pipe = pipe.to(torch_device)\n#         pipe.set_progress_bar_config(disable=None)\n#         pipe.enable_attention_slicing()\n# \n#         # enable vae slicing\n#         pipe.enable_vae_slicing()\n#         inputs = self.get_inputs(torch_device, dtype=torch.float16)\n#         inputs[\"prompt\"] = [inputs[\"prompt\"]] * 4\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n376, 0.4568, 0.5225, 0.5734, 0.4797, 0.5467, 0.5074, 0.5043])\n\n        assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2\n\n    def test_stable_diffusion_long_prompt(self):\n        components = self.get_dummy_components()\n        components[\"scheduler\"] = LMSDiscreteScheduler.from_config(components[\"scheduler\"].config)\n        sd_pipe = StableDiffusionPipeline(**components)\n        sd_pipe = sd_pipe.to(torch_device)\n        sd_pipe.set_progress_bar_config(disable=None)\n\n        do_classifier_free_guidance = True\n        negative_prompt = None\n        num_images_per_prompt = 1\n        logger = logging.get_logger(\"diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion\")\n\n        prompt = 25 * \"@\"\n        with CaptureLogger(logger) as cap_logger_3:\n            text_embeddings_3 = sd_pipe._encode_prompt(\n                prompt, torch_device, num_images_per_prompt, do_classifier_free_guidance, negative_prompt\n            )\n\n        prompt = 100 * \"@\"\n        with CaptureLogger(logger) as cap_logger:\n            text_embeddings = sd_pipe._encode_prompt(\n                prompt, torch_device, num_images_per_prompt, do_classifier_free_guidance, negative_prompt\n            )\n\n        negative_prompt = \"Hello\"\n        with CaptureLogger(logger) as cap_logger_2:\n            text_embeddings_2 = sd_pipe._encode_prompt(\n                prompt, torch_device, num_images_per_prompt, do_classifier_free_guidance, negative_prompt\n            )\n\n        assert text_embeddings_3.shape == text_embeddings_2.shape == text_embeddings.shape\n        assert text_embeddings.shape[1] == 77\n\n        assert cap_logger.out == cap_logger_2.out\n        # 100 - 77 + 1 (BOS token) + 1 (EOS token) = 25\n        assert cap_logger.out.count(\"@\") == 25\n        assert cap_logger_3.out == \"\"\n\n\n@slow\n@require_torch_gpu\nclass StableDiffusion2PipelineSlowTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        latents = np.random.RandomState(seed).standard_normal((1, 4, 64, 64))\n        latents = torch.from_numpy(latents).to(device=device, dtype=dtype)\n        inputs = {\n            \"prompt\": \"a photograph of an astronaut riding a horse\",\n            \"latents\": latents,\n            \"generator\": generator,\n            \"num_inference_steps\": 3,\n            \"guidance_scale\": 7.5,\n            \"output_type\": \"numpy\",\n        }\n        return inputs\n\n    def test_stable_diffusion_default_ddim(self):\n        pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-base\")\n        pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n\n        inputs = self.get_inputs(torch_device)\n        image = pipe(**inputs).images\n        image_slice = image[0, -3:, -3:, -1].flatten()\n\n        assert image.shape == (1, 512, 512, 3)\n        expected_slice = np.array([0.49493, 0.47896, 0.40798, 0.54214, 0.53212, 0.48202, 0.47656, 0.46329, 0.48506])\n        assert np.abs(image_slice - expected_slice).max() < 1e-4\n\n    def test_stable_diffusion_pndm(self):\n        pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-base\")\n        pipe.scheduler = PNDMScheduler.from_config(pipe.scheduler.config)\n        pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n\n        inputs = self.get_inputs(torch_device)\n        image = pipe(**inputs).images\n        image_slice = image[0, -3:, -3:, -1].flatten()\n\n        assert image.shape == (1, 512, 512, 3)\n        expected_slice = np.array([0.49493, 0.47896, 0.40798, 0.54214, 0.53212, 0.48202, 0.47656, 0.46329, 0.48506])\n        assert np.abs(image_slice - expected_slice).max() < 1e-4\n\n    def test_stable_diffusion_k_lms(self):\n        pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-base\")\n        pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n        pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n\n        inputs = self.get_inputs(torch_device)\n        image = pipe(**inputs).images\n        image_slice = image[0, -3:, -3:, -1].flatten()\n\n        assert image.shape == (1, 512, 512, 3)\n        expected_slice = np.array([0.10440, 0.13115, 0.11100, 0.10141, 0.11440, 0.07215, 0.11332, 0.09693, 0.10006])\n        assert np.abs(image_slice - expected_slice).max() < 1e-4\n\n    def test_stable_diffusion_attention_slicing(self):\n        torch.cuda.reset_peak_memory_stats()\n        pipe = StableDiffusionPipeline.from_pretrained(\n            \"stabilityai/stable-diffusion-2-base\", torch_dtype=torch.float16\n        )\n        pipe = pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n\n        # enable attention slicing\n        pipe.enable_attention_slicing()\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        image_sliced = pipe(**inputs).images\n\n        mem_bytes = torch.cuda.max_memory_allocated()\n        torch.cuda.reset_peak_memory_stats()\n        # make sure that less than 3.3 GB is allocated\n        assert mem_bytes < 3.3 * 10**9\n\n        # disable slicing\n        pipe.disable_attention_slicing()\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        image = pipe(**inputs).images\n\n        # make sure that more than 3.3 GB is allocated\n        mem_bytes = torch.cuda.max_memory_allocated()\n        assert mem_bytes > 3.3 * 10**9\n        assert np.abs(image_sliced - image).max() < 1e-3\n\n    def test_stable_diffusion_text2img_intermediate_state(self):\n        number_of_steps = 0\n\n        def callback_fn(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n            callback_fn.has_been_called = True\n            nonlocal number_of_steps\n            number_of_steps += 1", "choices": [{"text": ""}], "metadata": {"task_id": "huggingface_diffusers/101", "ground_truth": "            if step == 1:", "fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion_2", "test_stable_diffusion.py"], "context_start_lineno": 201, "line_no": 342, "query_window": {"context": "        # make sure that less than 3.3 GB is allocated\n        assert mem_bytes < 3.3 * 10**9\n\n        # disable slicing\n        pipe.disable_attention_slicing()\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        image = pipe(**inputs).images\n\n        # make sure that more than 3.3 GB is allocated\n        mem_bytes = torch.cuda.max_memory_allocated()\n        assert mem_bytes > 3.3 * 10**9\n        assert np.abs(image_sliced - image).max() < 1e-3\n\n    def test_stable_diffusion_text2img_intermediate_state(self):\n        number_of_steps = 0\n\n        def callback_fn(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n            callback_fn.has_been_called = True\n            nonlocal number_of_steps\n            number_of_steps += 1", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion_2", "test_stable_diffusion.py"], "line_no": 342, "task_id": "huggingface_diffusers/101", "start_line_no": 322, "end_line_no": 342, "window_size": 20, "context_start_lineno": 201, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        pipe.enable_attention_slicing()\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        image_sliced = pipe(**inputs).images\n\n        mem_bytes = torch.cuda.max_memory_allocated()\n        torch.cuda.reset_peak_memory_stats()\n        # make sure that less than 3.75 GB is allocated\n        assert mem_bytes < 3.75 * 10**9\n\n        # disable slicing\n        pipe.disable_attention_slicing()\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        image = pipe(**inputs).images\n\n        # make sure that more than 3.75 GB is allocated\n        mem_bytes = torch.cuda.max_memory_allocated()\n        assert mem_bytes > 3.75 * 10**9\n        assert np.abs(image_sliced - image).max() < 1e-3\n\n    def test_stable_diffusion_vae_slicing(self):", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion.py"], "line_no": 660, "start_line_no": 650, "end_line_no": 670, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6666666666666666}, {"context": "        pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n        pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n        pipe.enable_attention_slicing()\n\n        inputs = self.get_inputs()\n        image = pipe(**inputs).images\n        image_slice = image[0, -3:, -3:, -1].flatten()\n\n        assert image.shape == (1, 512, 512, 3)\n        expected_slice = np.array([0.3828, 0.3834, 0.3818, 0.3792, 0.3865, 0.3752, 0.3792, 0.3847, 0.3753])\n\n        assert np.abs(expected_slice - image_slice).max() < 1e-3\n\n    def test_stable_diffusion_pix2pix_intermediate_state(self):\n        number_of_steps = 0\n\n        def callback_fn(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n            callback_fn.has_been_called = True\n            nonlocal number_of_steps", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_instruction_pix2pix.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5096774193548387}, {"context": "        pipe.disable_attention_slicing()\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        image = pipe(**inputs).images\n\n        # make sure that more than 3.75 GB is allocated\n        mem_bytes = torch.cuda.max_memory_allocated()\n        assert mem_bytes > 3.75 * 10**9\n        assert np.abs(image_sliced - image).max() < 1e-3\n\n    def test_stable_diffusion_vae_slicing(self):\n        torch.cuda.reset_peak_memory_stats()\n        pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n        pipe = pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n        pipe.enable_attention_slicing()\n\n        # enable vae slicing\n        pipe.enable_vae_slicing()\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        inputs[\"prompt\"] = [inputs[\"prompt\"]] * 4", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion.py"], "line_no": 670, "start_line_no": 660, "end_line_no": 680, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5033112582781457}, {"context": "\n        with torch.autocast(torch_device):\n            inputs = self.get_inputs(torch_device)\n            image_autocast = pipe(**inputs).images\n\n        # Make sure results are close enough\n        diff = np.abs(image_fp16.flatten() - image_autocast.flatten())\n        # They ARE different since ops are not run always at the same precision\n        # however, they should be extremely close.\n        assert diff.mean() < 2e-2\n\n    def test_stable_diffusion_intermediate_state(self):\n        number_of_steps = 0\n\n        def callback_fn(step: int, timestep: int, latents: torch.FloatTensor) -> None:\n            callback_fn.has_been_called = True\n            nonlocal number_of_steps\n            number_of_steps += 1\n            if step == 1:\n                latents = latents.detach().cpu().numpy()", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion.py"], "line_no": 720, "start_line_no": 710, "end_line_no": 730, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.487012987012987}, {"context": "        inputs[\"latents\"] = torch.cat([inputs[\"latents\"]] * 4)\n        image_sliced = pipe(**inputs).images\n\n        mem_bytes = torch.cuda.max_memory_allocated()\n        torch.cuda.reset_peak_memory_stats()\n        # make sure that less than 4 GB is allocated\n        assert mem_bytes < 4e9\n\n        # disable vae slicing\n        pipe.disable_vae_slicing()\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        inputs[\"prompt\"] = [inputs[\"prompt\"]] * 4\n        inputs[\"latents\"] = torch.cat([inputs[\"latents\"]] * 4)\n        image = pipe(**inputs).images\n\n        # make sure that more than 4 GB is allocated\n        mem_bytes = torch.cuda.max_memory_allocated()\n        assert mem_bytes > 4e9\n        # There is a small discrepancy at the image borders vs. a fully batched version.\n        assert np.abs(image_sliced - image).max() < 1e-2", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion.py"], "line_no": 690, "start_line_no": 680, "end_line_no": 700, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.48201438848920863}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_metric.py\n# --------------------------------------------------\n#         )\n#         metric.add_batch(predictions=preds, references=refs)\n#         other_metric.add_batch(predictions=other_preds, references=other_refs)\n#         self.assertDictEqual(expected_results, metric.compute())\n#         self.assertDictEqual(other_expected_results, other_metric.compute())\n# \n#         for pred, ref, other_pred, other_ref in zip(preds, refs, other_preds, other_refs):\n#             metric.add(prediction=pred, reference=ref)\n#             other_metric.add(prediction=other_pred, reference=other_ref)\n#         self.assertDictEqual(expected_results, metric.compute())\n#         self.assertDictEqual(other_expected_results, other_metric.compute())\n#         del metric, other_metric\n# \n#         # With keep_in_memory\n#         metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n#         other_metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n# \n#         self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n#         self.assertDictEqual(\n#             other_expected_results, other_metric.compute(predictions=other_preds, references=other_refs)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_metric.py\n# --------------------------------------------------\n#         other_preds, other_refs = DummyMetric.other_predictions_and_references()\n#         expected_results = DummyMetric.expected_results()\n#         other_expected_results = DummyMetric.other_expected_results()\n# \n#         metric = DummyMetric(experiment_id=\"test_concurrent_metrics\")\n#         other_metric = DummyMetric(\n#             experiment_id=\"test_concurrent_metrics\",\n#         )\n# \n#         self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n#         self.assertDictEqual(\n#             other_expected_results, other_metric.compute(predictions=other_preds, references=other_refs)\n#         )\n#         del metric, other_metric\n# \n#         metric = DummyMetric(\n#             experiment_id=\"test_concurrent_metrics\",\n#         )\n#         other_metric = DummyMetric(\n#             experiment_id=\"test_concurrent_metrics\",\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_metric.py\n# --------------------------------------------------\n#             metric.add(prediction=pred, reference=ref)\n#         self.assertDictEqual(expected_results, metric.compute())\n#         del metric\n# \n#         # With keep_in_memory\n#         metric = DummyMetric(keep_in_memory=True, experiment_id=\"test_dummy_metric\")\n#         self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n#         del metric\n# \n#         metric = DummyMetric(keep_in_memory=True, experiment_id=\"test_dummy_metric\")\n#         metric.add_batch(predictions=preds, references=refs)\n#         self.assertDictEqual(expected_results, metric.compute())\n#         del metric\n# \n#         metric = DummyMetric(keep_in_memory=True, experiment_id=\"test_dummy_metric\")\n#         for pred, ref in zip(preds, refs):\n#             metric.add(prediction=pred, reference=ref)\n#         self.assertDictEqual(expected_results, metric.compute())\n#         del metric\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_metric.py\n# --------------------------------------------------\n#         self.assertDictEqual(other_expected_results, other_metric.compute())\n#         del metric, other_metric\n# \n#         # With keep_in_memory\n#         metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n#         other_metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n# \n#         self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n#         self.assertDictEqual(\n#             other_expected_results, other_metric.compute(predictions=other_preds, references=other_refs)\n#         )\n# \n#         metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n#         other_metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n#         metric.add_batch(predictions=preds, references=refs)\n#         other_metric.add_batch(predictions=other_preds, references=other_refs)\n#         self.assertDictEqual(expected_results, metric.compute())\n#         self.assertDictEqual(other_expected_results, other_metric.compute())\n# \n#         for pred, ref, other_pred, other_ref in zip(preds, refs, other_preds, other_refs):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_metric.py\n# --------------------------------------------------\n#         )\n# \n#         metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n#         other_metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n#         metric.add_batch(predictions=preds, references=refs)\n#         other_metric.add_batch(predictions=other_preds, references=other_refs)\n#         self.assertDictEqual(expected_results, metric.compute())\n#         self.assertDictEqual(other_expected_results, other_metric.compute())\n# \n#         for pred, ref, other_pred, other_ref in zip(preds, refs, other_preds, other_refs):\n#             metric.add(prediction=pred, reference=ref)\n#             other_metric.add(prediction=other_pred, reference=other_ref)\n#         self.assertDictEqual(expected_results, metric.compute())\n#         self.assertDictEqual(other_expected_results, other_metric.compute())\n#         del metric, other_metric\n# \n#     def test_separate_experiments_in_parallel(self):\n#         with tempfile.TemporaryDirectory() as tmp_dir:\n#             (preds_0, refs_0), (preds_1, refs_1) = DummyMetric.separate_predictions_and_references()\n#             expected_results = DummyMetric.separate_expected_results()\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n3\", tmp_dir, 0),\n                        (2, 1, preds_1, refs_1, \"test_distributed_metrics_3\", tmp_dir, 0),\n                        (2, 0, preds_0, refs_0, \"test_distributed_metrics_3\", tmp_dir, 0),\n                        (2, 1, preds_1, refs_1, \"test_distributed_metrics_3\", tmp_dir, 0),\n                    ],\n                )\n            except ValueError:\n                # We are fine with either raising a ValueError or computing well the metric\n                # Being sure we raise the error would means making the dummy dataset bigger\n                # and the test longer...\n                pass\n            else:\n                self.assertDictEqual(expected_results, results[0])\n                self.assertDictEqual(expected_results, results[2])\n                self.assertIsNone(results[1])\n                self.assertIsNone(results[3])\n                del results\n\n            results = pool.map(\n                metric_add_and_compute,\n                [\n                    (2, 0, preds_0, refs_0, \"exp_0\", tmp_dir, 0),\n                    (2, 1, preds_1, refs_1, \"exp_0\", tmp_dir, 0),\n                    (2, 0, preds_0, refs_0, \"exp_1\", tmp_dir, 0),\n                    (2, 1, preds_1, refs_1, \"exp_1\", tmp_dir, 0),\n                ],\n            )\n            self.assertDictEqual(expected_results, results[0])\n            self.assertDictEqual(expected_results, results[2])\n            self.assertIsNone(results[1])\n            self.assertIsNone(results[3])\n            del results\n\n            # With keep_in_memory is not allowed\n            with self.assertRaises(ValueError):\n                DummyMetric(\n                    experiment_id=\"test_distributed_metrics_4\",\n                    keep_in_memory=True,\n                    num_process=2,\n                    process_id=0,\n                    cache_dir=tmp_dir,\n                )\n\n    def test_dummy_metric_pickle(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            tmp_file = os.path.join(tmp_dir, \"metric.pt\")\n            preds, refs = DummyMetric.predictions_and_references()\n            expected_results = DummyMetric.expected_results()\n\n            metric = DummyMetric(experiment_id=\"test_dummy_metric_pickle\")\n\n            with open(tmp_file, \"wb\") as f:\n                pickle.dump(metric, f)\n            del metric\n\n            with open(tmp_file, \"rb\") as f:\n                metric = pickle.load(f)\n            self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n            del metric\n\n    def test_input_numpy(self):\n        import numpy as np\n\n        preds, refs = DummyMetric.predictions_and_references()\n        expected_results = DummyMetric.expected_results()\n        preds, refs = np.array(preds), np.array(refs)\n\n        metric = DummyMetric(experiment_id=\"test_input_numpy\")\n        self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n        del metric\n\n        metric = DummyMetric(experiment_id=\"test_input_numpy\")\n        metric.add_batch(predictions=preds, references=refs)\n        self.assertDictEqual(expected_results, metric.compute())\n        del metric\n\n        metric = DummyMetric(experiment_id=\"test_input_numpy\")\n        for pred, ref in zip(preds, refs):\n            metric.add(prediction=pred, reference=ref)\n        self.assertDictEqual(expected_results, metric.compute())\n        del metric\n\n    @require_torch\n    def test_input_torch(self):\n        import torch\n\n        preds, refs = DummyMetric.predictions_and_references()\n        expected_results = DummyMetric.expected_results()\n        preds, refs = torch.tensor(preds), torch.tensor(refs)\n\n        metric = DummyMetric(experiment_id=\"test_input_torch\")\n        self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n        del metric\n\n        metric = DummyMetric(experiment_id=\"test_input_torch\")\n        metric.add_batch(predictions=preds, references=refs)\n        self.assertDictEqual(expected_results, metric.compute())\n        del metric\n\n        metric = DummyMetric(experiment_id=\"test_input_torch\")\n        for pred, ref in zip(preds, refs):\n            metric.add(prediction=pred, reference=ref)\n        self.assertDictEqual(expected_results, metric.compute())\n        del metric\n\n    @require_tf\n    def test_input_tf(self):\n        import tensorflow as tf\n\n        preds, refs = DummyMetric.predictions_and_references()\n        expected_results = DummyMetric.expected_results()\n        preds, refs = tf.constant(preds), tf.constant(refs)\n\n        metric = DummyMetric(experiment_id=\"test_input_tf\")\n        self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n        del metric\n\n        metric = DummyMetric(experiment_id=\"test_input_tf\")\n        metric.add_batch(predictions=preds, references=refs)\n        self.assertDictEqual(expected_results, metric.compute())\n        del metric\n\n        metric = DummyMetric(experiment_id=\"test_input_tf\")\n        for pred, ref in zip(preds, refs):\n            metric.add(prediction=pred, reference=ref)\n        self.assertDictEqual(expected_results, metric.compute())\n        del metric\n\n    def test_string_casting(self):\n        metric = DummyMetric(experiment_id=\"test_string_casting\")\n        metric.info.features = Features({\"predictions\": Value(\"string\"), \"references\": Value(\"string\")})\n        metric.compute(predictions=[\"a\"], references=[\"a\"])\n        with self.assertRaises(ValueError):\n            metric.compute(predictions=[1], references=[1])\n\n        metric = DummyMetric(experiment_id=\"test_string_casting_2\")\n        metric.info.features = Features(\n            {\"predictions\": Sequence(Value(\"string\")), \"references\": Sequence(Value(\"string\"))}\n        )\n        metric.compute(predictions=[[\"a\"]], references=[[\"a\"]])\n        with self.assertRaises(ValueError):\n            metric.compute(predictions=[\"a\"], references=[\"a\"])\n\n    def test_string_casting_tested_once(self):\n\n        self.counter = 0\n\n        def checked_fct(fct):  # wrapper function that increases a counter on each call\n            def wrapped(*args, **kwargs):\n                self.counter += 1\n                return fct(*args, **kwargs)\n\n            return wrapped\n\n        with mock.patch(\n            \"evaluate.EvaluationModule._enforce_nested_string_type\",\n            checked_fct(DummyMetric._enforce_nested_string_type),\n        ):\n            metric = DummyMetric(experiment_id=\"test_string_casting_called_once\")\n            metric.info.features = Features(\n                {\"references\": Sequence(Value(\"string\")), \"predictions\": Sequence(Value(\"string\"))}\n            )\n            refs = [[\"test\"] * 10] * 10\n            preds = [[\"test\"] * 10] * 10\n\n            metric.add_batch(references=refs, predictions=preds)", "choices": [{"text": "self.assertDictEqual(expected_results, metric.compute())"}], "metadata": {"task_id": "huggingface_evaluate/3", "ground_truth": "            metric.add_batch(references=refs, predictions=preds)", "fpath_tuple": ["huggingface_evaluate", "tests", "test_metric.py"], "context_start_lineno": 374, "line_no": 540, "query_window": {"context": "\n        def checked_fct(fct):  # wrapper function that increases a counter on each call\n            def wrapped(*args, **kwargs):\n                self.counter += 1\n                return fct(*args, **kwargs)\n\n            return wrapped\n\n        with mock.patch(\n            \"evaluate.EvaluationModule._enforce_nested_string_type\",\n            checked_fct(DummyMetric._enforce_nested_string_type),\n        ):\n            metric = DummyMetric(experiment_id=\"test_string_casting_called_once\")\n            metric.info.features = Features(\n                {\"references\": Sequence(Value(\"string\")), \"predictions\": Sequence(Value(\"string\"))}\n            )\n            refs = [[\"test\"] * 10] * 10\n            preds = [[\"test\"] * 10] * 10\n\n            metric.add_batch(references=refs, predictions=preds)", "metadata": {"fpath_tuple": ["huggingface_evaluate", "tests", "test_metric.py"], "line_no": 540, "task_id": "huggingface_evaluate/3", "start_line_no": 520, "end_line_no": 540, "window_size": 20, "context_start_lineno": 374, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "        self.assertDictEqual(other_expected_results, other_metric.compute())\n        del metric, other_metric\n\n        # With keep_in_memory\n        metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n        other_metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n\n        self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n        self.assertDictEqual(\n            other_expected_results, other_metric.compute(predictions=other_preds, references=other_refs)\n        )\n\n        metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n        other_metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n        metric.add_batch(predictions=preds, references=refs)\n        other_metric.add_batch(predictions=other_preds, references=other_refs)\n        self.assertDictEqual(expected_results, metric.compute())\n        self.assertDictEqual(other_expected_results, other_metric.compute())\n\n        for pred, ref, other_pred, other_ref in zip(preds, refs, other_preds, other_refs):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_metric.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.288}, {"context": "        )\n        metric.add_batch(predictions=preds, references=refs)\n        other_metric.add_batch(predictions=other_preds, references=other_refs)\n        self.assertDictEqual(expected_results, metric.compute())\n        self.assertDictEqual(other_expected_results, other_metric.compute())\n\n        for pred, ref, other_pred, other_ref in zip(preds, refs, other_preds, other_refs):\n            metric.add(prediction=pred, reference=ref)\n            other_metric.add(prediction=other_pred, reference=other_ref)\n        self.assertDictEqual(expected_results, metric.compute())\n        self.assertDictEqual(other_expected_results, other_metric.compute())\n        del metric, other_metric\n\n        # With keep_in_memory\n        metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n        other_metric = DummyMetric(experiment_id=\"test_concurrent_metrics\", keep_in_memory=True)\n\n        self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n        self.assertDictEqual(\n            other_expected_results, other_metric.compute(predictions=other_preds, references=other_refs)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_metric.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.28346456692913385}, {"context": "        self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n        del metric\n\n        metric = DummyMetric(experiment_id=\"test_dummy_metric\")\n        metric.add_batch(predictions=preds, references=refs)\n        self.assertDictEqual(expected_results, metric.compute())\n        del metric\n\n        metric = DummyMetric(experiment_id=\"test_dummy_metric\")\n        for pred, ref in zip(preds, refs):\n            metric.add(prediction=pred, reference=ref)\n        self.assertDictEqual(expected_results, metric.compute())\n        del metric\n\n        # With keep_in_memory\n        metric = DummyMetric(keep_in_memory=True, experiment_id=\"test_dummy_metric\")\n        self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n        del metric\n\n        metric = DummyMetric(keep_in_memory=True, experiment_id=\"test_dummy_metric\")", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_metric.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.28}, {"context": "        preds, refs = DummyMetric.predictions_and_references()\n        expected_results = DummyMetric.expected_results()\n\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            metric = DummyMetric(experiment_id=\"test_dummy_metric\", cache_dir=tmp_dir)\n            self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))\n            del metric\n\n    def test_concurrent_metrics(self):\n        preds, refs = DummyMetric.predictions_and_references()\n        other_preds, other_refs = DummyMetric.other_predictions_and_references()\n        expected_results = DummyMetric.expected_results()\n        other_expected_results = DummyMetric.other_expected_results()\n\n        metric = DummyMetric(experiment_id=\"test_concurrent_metrics\")\n        other_metric = DummyMetric(\n            experiment_id=\"test_concurrent_metrics\",\n        )\n\n        self.assertDictEqual(expected_results, metric.compute(predictions=preds, references=refs))", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_metric.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2740740740740741}, {"context": "        self.assertDictEqual(\n            other_expected_results, other_metric.compute(predictions=other_preds, references=other_refs)\n        )\n        del metric, other_metric\n\n        metric = DummyMetric(\n            experiment_id=\"test_concurrent_metrics\",\n        )\n        other_metric = DummyMetric(\n            experiment_id=\"test_concurrent_metrics\",\n        )\n        metric.add_batch(predictions=preds, references=refs)\n        other_metric.add_batch(predictions=other_preds, references=other_refs)\n        self.assertDictEqual(expected_results, metric.compute())\n        self.assertDictEqual(other_expected_results, other_metric.compute())\n\n        for pred, ref, other_pred, other_ref in zip(preds, refs, other_preds, other_refs):\n            metric.add(prediction=pred, reference=ref)\n            other_metric.add(prediction=other_pred, reference=other_ref)\n        self.assertDictEqual(expected_results, metric.compute())", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_metric.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.27049180327868855}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/ppo.py\n# --------------------------------------------------\n#         entropy_bonus: bool = True,\n#         samples_mc_entropy: int = 1,\n#         entropy_coef: float = 0.01,\n#         critic_coef: float = 1.0,\n#         gamma: float = 0.99,\n#         loss_critic_type: str = \"smooth_l1\",\n#         normalize_advantage: bool = True,\n#     ):\n#         super().__init__()\n#         self.convert_to_functional(\n#             actor, \"actor\", funs_to_decorate=[\"forward\", \"get_dist\"]\n#         )\n#         # we want to make sure there are no duplicates in the params: the\n#         # params of critic must be refs to actor if they're shared\n#         self.convert_to_functional(critic, \"critic\", compare_against=self.actor_params)\n#         self.advantage_key = advantage_key\n#         self.value_target_key = value_target_key\n#         self.samples_mc_entropy = samples_mc_entropy\n#         self.entropy_bonus = entropy_bonus and entropy_coef\n#         self.register_buffer(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/a2c.py\n# --------------------------------------------------\n# \n#     def __init__(\n#         self,\n#         actor: SafeProbabilisticSequential,\n#         critic: SafeModule,\n#         advantage_key: str = \"advantage\",\n#         value_target_key: str = \"value_target\",\n#         entropy_bonus: bool = True,\n#         samples_mc_entropy: int = 1,\n#         entropy_coef: float = 0.01,\n#         critic_coef: float = 1.0,\n#         gamma: float = 0.99,\n#         loss_critic_type: str = \"smooth_l1\",\n#     ):\n#         super().__init__()\n#         self.convert_to_functional(\n#             actor, \"actor\", funs_to_decorate=[\"forward\", \"get_dist\"]\n#         )\n#         self.convert_to_functional(critic, \"critic\", compare_against=self.actor_params)\n#         self.advantage_key = advantage_key\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/dqn.py\n# --------------------------------------------------\n# \n#         super().__init__()\n#         self.delay_value = delay_value\n# \n#         value_network = ensure_tensordict_compatible(\n#             module=value_network, wrapper_type=QValueActor\n#         )\n# \n#         self.convert_to_functional(\n#             value_network,\n#             \"value_network\",\n#             create_target_params=self.delay_value,\n#         )\n# \n#         self.value_network_in_keys = value_network.in_keys\n# \n#         self.register_buffer(\"gamma\", torch.tensor(gamma))\n#         self.loss_function = loss_function\n#         self.priority_key = priority_key\n#         self.action_space = self.value_network.action_space\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#         device: Optional[DEVICE_TYPING] = None,\n#         dtype: Optional[Union[torch.dtype, str]] = None,\n#     ):\n#         dtype, device = _default_dtype_and_device(dtype, device)\n#         if dtype is None:\n#             dtype = torch.get_default_dtype()\n#         if device is None:\n#             device = torch._get_default_device()\n# \n#         if not isinstance(minimum, torch.Tensor):\n#             minimum = torch.tensor(minimum, dtype=dtype, device=device)\n#         if not isinstance(maximum, torch.Tensor):\n#             maximum = torch.tensor(maximum, dtype=dtype, device=device)\n#         if maximum.device != device:\n#             maximum = maximum.to(device)\n#         if minimum.device != device:\n#             minimum = minimum.to(device)\n#         if dtype is not None and minimum.dtype is not dtype:\n#             minimum = minimum.to(dtype)\n#         if dtype is not None and maximum.dtype is not dtype:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/ddpg.py\n# --------------------------------------------------\n#         self,\n#         actor_network: SafeModule,\n#         value_network: SafeModule,\n#         gamma: float,\n#         loss_function: str = \"l2\",\n#         delay_actor: bool = False,\n#         delay_value: bool = False,\n#     ) -> None:\n#         super().__init__()\n#         self.delay_actor = delay_actor\n#         self.delay_value = delay_value\n# \n#         actor_critic = ActorCriticWrapper(actor_network, value_network)\n#         params = make_functional(actor_critic)\n#         self.actor_critic = deepcopy(actor_critic)\n#         repopulate_module(actor_network, params[\"module\", \"0\"])\n#         repopulate_module(value_network, params[\"module\", \"1\"])\n# \n#         self.convert_to_functional(\n#             actor_network,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/dreamer.py\n# --------------------------------------------------\n#         value_model: SafeModule,\n#         value_loss: Optional[str] = None,\n#         gamma: int = 0.99,\n#         discount_loss: bool = False,  # for consistency with paper\n#     ):\n#         super().__init__()\n#         self.value_model = value_model\n#         self.value_loss = value_loss if value_loss is not None else \"l2\"\n#         self.gamma = gamma\n#         self.discount_loss = discount_loss\n# \n#     def forward(self, fake_data) -> torch.Tensor:\n#         lambda_target = fake_data.get(\"lambda_target\")\n#         tensordict_select = fake_data.select(*self.value_model.in_keys)\n#         self.value_model(tensordict_select)\n#         if self.discount_loss:\n#             discount = self.gamma * torch.ones_like(\n#                 lambda_target, device=lambda_target.device\n#             )\n#             discount[..., 0, :] = 1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/reinforce.py\n# --------------------------------------------------\n#         value_target_key: str = \"value_target\",\n#         loss_critic_type: str = \"smooth_l1\",\n#     ) -> None:\n#         super().__init__()\n# \n#         self.delay_value = delay_value\n#         self.advantage_key = advantage_key\n#         self.value_target_key = value_target_key\n#         self.loss_critic_type = loss_critic_type\n#         self.register_buffer(\"gamma\", torch.tensor(gamma))\n# \n#         # Actor\n#         self.convert_to_functional(\n#             actor_network,\n#             \"actor_network\",\n#             create_target_params=False,\n#         )\n# \n#         # Value\n#         if critic is not None:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom functools import wraps\nfrom typing import List, Optional, Tuple, Union\n\nimport torch\nfrom tensordict.nn import dispatch_kwargs\nfrom tensordict.tensordict import TensorDictBase\nfrom torch import nn, Tensor\n\nfrom torchrl.envs.utils import step_mdp\nfrom torchrl.modules import SafeModule\n\nfrom torchrl.objectives.utils import hold_out_net\nfrom torchrl.objectives.value.functional import (\n    td_advantage_estimate,\n    td_lambda_advantage_estimate,\n    vec_generalized_advantage_estimate,\n    vec_td_lambda_advantage_estimate,\n)\n\n\ndef _self_set_grad_enabled(fun):\n    @wraps(fun)\n    def new_fun(self, *args, **kwargs):\n        with torch.set_grad_enabled(self.differentiable):\n            return fun(self, *args, **kwargs)\n\n    return new_fun\n\n\nclass TDEstimate(nn.Module):\n    \"\"\"Temporal Difference estimate of advantage function.\n\n    Args:\n        gamma (scalar): exponential mean discount.\n        value_network (SafeModule): value operator used to retrieve the value estimates.\n        average_rewards (bool, optional): if True, rewards will be standardized\n            before the TD is computed.\n        differentiable (bool, optional): if True, gradients are propagated throught\n            the computation of the value function. Default is :obj:`False`.\n        advantage_key (str or tuple of str, optional): the key of the advantage entry.\n            Defaults to \"advantage\".\n        value_target_key (str or tuple of str, optional): the key of the advantage entry.\n            Defaults to \"value_target\".\n        value_key (str or tuple of str, optional): the value key to read from the input tensordict.\n            Defaults to \"state_value\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        gamma: Union[float, torch.Tensor],\n        value_network: SafeModule,\n        average_rewards: bool = False,\n        differentiable: bool = False,\n        advantage_key: Union[str, Tuple] = \"advantage\",\n        value_target_key: Union[str, Tuple] = \"value_target\",\n        value_key: Union[str, Tuple] = \"state_value\",\n    ):\n        super().__init__()\n        try:\n            device = next(value_network.parameters()).device", "choices": [{"text": "self.gamma = gamma"}], "metadata": {"task_id": "pytorch_rl/30", "ground_truth": "        except StopIteration:", "fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "context_start_lineno": 0, "line_no": 66, "query_window": {"context": "        value_target_key (str or tuple of str, optional): the key of the advantage entry.\n            Defaults to \"value_target\".\n        value_key (str or tuple of str, optional): the value key to read from the input tensordict.\n            Defaults to \"state_value\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        gamma: Union[float, torch.Tensor],\n        value_network: SafeModule,\n        average_rewards: bool = False,\n        differentiable: bool = False,\n        advantage_key: Union[str, Tuple] = \"advantage\",\n        value_target_key: Union[str, Tuple] = \"value_target\",\n        value_key: Union[str, Tuple] = \"state_value\",\n    ):\n        super().__init__()\n        try:\n            device = next(value_network.parameters()).device", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 66, "task_id": "pytorch_rl/30", "start_line_no": 46, "end_line_no": 66, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "\n    \"\"\"\n\n    def __init__(\n        self,\n        actor_network: SafeProbabilisticSequential,\n        critic: Optional[SafeModule] = None,\n        delay_value: bool = False,\n        gamma: float = 0.99,\n        advantage_key: str = \"advantage\",\n        value_target_key: str = \"value_target\",\n        loss_critic_type: str = \"smooth_l1\",\n    ) -> None:\n        super().__init__()\n\n        self.delay_value = delay_value\n        self.advantage_key = advantage_key\n        self.value_target_key = value_target_key\n        self.loss_critic_type = loss_critic_type\n        self.register_buffer(\"gamma\", torch.tensor(gamma))", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "reinforce.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.34210526315789475}, {"context": "        value_model (SafeModule): the value model.\n        value_loss (str, optional): the loss to use for the value loss. Default: \"l2\".\n        gamma (float, optional): the gamma discount factor. Default: 0.99.\n        discount_loss (bool, optional): if True, the loss is discounted with a\n            gamma discount factor. Default: False.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        value_model: SafeModule,\n        value_loss: Optional[str] = None,\n        gamma: int = 0.99,\n        discount_loss: bool = False,  # for consistency with paper\n    ):\n        super().__init__()\n        self.value_model = value_model\n        self.value_loss = value_loss if value_loss is not None else \"l2\"\n        self.gamma = gamma\n        self.discount_loss = discount_loss", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "dreamer.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3391304347826087}, {"context": "        device (str, int or torch.device, optional): a device where the losses will be computed, if it can't be found\n            via the value operator.\n        loss_function (str): loss function for the value discrepancy. Can be one of \"l1\", \"l2\" or \"smooth_l1\".\n        delay_actor (bool, optional): whether to separate the target actor networks from the actor networks used for\n            data collection. Default is :obj:`False`.\n        delay_value (bool, optional): whether to separate the target value networks from the value networks used for\n            data collection. Default is :obj:`False`.\n    \"\"\"\n\n    def __init__(\n        self,\n        actor_network: SafeModule,\n        value_network: SafeModule,\n        gamma: float,\n        loss_function: str = \"l2\",\n        delay_actor: bool = False,\n        delay_value: bool = False,\n    ) -> None:\n        super().__init__()\n        self.delay_actor = delay_actor", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "ddpg.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3384615384615385}, {"context": "        device (str, int or torch.device, optional): device of the tensors.\n        dtype (str or torch.dtype, optional): dtype of the tensors.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        minimum: Union[float, torch.Tensor, np.ndarray],\n        maximum: Union[float, torch.Tensor, np.ndarray],\n        shape: Optional[Union[torch.Size, int]] = None,\n        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[torch.dtype, str]] = None,\n    ):\n        dtype, device = _default_dtype_and_device(dtype, device)\n        if dtype is None:\n            dtype = torch.get_default_dtype()\n        if device is None:\n            device = torch._get_default_device()\n\n        if not isinstance(minimum, torch.Tensor):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 630, "start_line_no": 620, "end_line_no": 640, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "    \"\"\"\n\n    def __init__(\n        self,\n        value_network: Union[QValueActor, nn.Module],\n        gamma: float,\n        loss_function: str = \"l2\",\n        priority_key: str = \"td_error\",\n        delay_value: bool = False,\n    ) -> None:\n\n        super().__init__()\n        self.delay_value = delay_value\n\n        value_network = ensure_tensordict_compatible(\n            module=value_network, wrapper_type=QValueActor\n        )\n\n        self.convert_to_functional(\n            value_network,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "dqn.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.32727272727272727}, {"context": "        advantage_key (str): the input tensordict key where the advantage is expected to be written.\n            default: \"advantage\"\n        advantage_diff_key (str): the input tensordict key where advantage_diff is expected to be written.\n            default: \"value_error\"\n        entropy_coef (float): the weight of the entropy loss.\n        critic_coef (float): the weight of the critic loss.\n        gamma (scalar): a discount factor for return computation.\n        loss_function_type (str): loss function for the value discrepancy. Can be one of \"l1\", \"l2\" or \"smooth_l1\".\n        advantage_module (nn.Module): SafeModule used to compute tha advantage function.\n    \"\"\"\n\n    def __init__(\n        self,\n        actor: SafeProbabilisticSequential,\n        critic: SafeModule,\n        advantage_key: str = \"advantage\",\n        value_target_key: str = \"value_target\",\n        entropy_bonus: bool = True,\n        samples_mc_entropy: int = 1,\n        entropy_coef: float = 0.01,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "a2c.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3237410071942446}, {"context": "            Defaults to True.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        actor: SafeProbabilisticSequential,\n        critic: SafeModule,\n        advantage_key: str = \"advantage\",\n        value_target_key: str = \"value_target\",\n        entropy_bonus: bool = True,\n        samples_mc_entropy: int = 1,\n        entropy_coef: float = 0.01,\n        critic_coef: float = 1.0,\n        gamma: float = 0.99,\n        loss_critic_type: str = \"smooth_l1\",\n        normalize_advantage: bool = True,\n    ):\n        super().__init__()\n        self.convert_to_functional(", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "ppo.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.31932773109243695}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/dataloader/dataloader_graph.py\n# --------------------------------------------------\n#             'TOX21', 'TOXCAST', 'SIDER', 'CLINTOX'\n#     ]:\n#         dataset = MoleculeNet(path, name, **transforms_funcs)\n#         return dataset, config\n#     elif name.startswith('graph_multi_domain'.upper()):\n#         \"\"\"\n#             The `graph_multi_domain` datasets follows GCFL\n#             Federated Graph Classification over Non-IID Graphs (NeurIPS 2021)\n#         \"\"\"\n#         if name.endswith('mol'.upper()):\n#             dnames = ['MUTAG', 'BZR', 'COX2', 'DHFR', 'PTC_MR', 'AIDS', 'NCI1']\n#         elif name.endswith('small'.upper()):\n#             dnames = [\n#                 'MUTAG', 'BZR', 'COX2', 'DHFR', 'PTC_MR', 'ENZYMES', 'DD',\n#                 'PROTEINS'\n#             ]\n#         elif name.endswith('mix'.upper()):\n#             if 'pre_transform' not in transforms_funcs:\n#                 raise ValueError('pre_transform is None!')\n#             dnames = [\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/model/fedsageplus.py\n# --------------------------------------------------\n#                                  dtype=torch.int64).T\n#         new_edges = new_edges.to(device)\n#         if len(new_edges) > 0:\n#             fill_edges = torch.hstack((edge_index, new_edges))\n#         else:\n#             fill_edges = torch.clone(edge_index)\n#         return fill_feats, fill_edges\n# \n#     def forward(self, x, edge_index, pred_missing, gen_feats):\n#         fill_feats, fill_edges = self.mend_graph(x, edge_index, pred_missing,\n#                                                  gen_feats)\n# \n#         return fill_feats, fill_edges\n# \n# \n# class LocalSage_Plus(nn.Module):\n#     def __init__(self,\n#                  in_channels,\n#                  out_channels,\n#                  hidden,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmark/FedHPOBench/fedhpobench/utils/draw.py\n# --------------------------------------------------\n#     family_rank = []\n#     family_rank_bbo = []\n#     family_rank_mf = []\n#     for dataset in traj:\n#         if loss:\n#             print(dataset)\n#             xs, mean_ranks, mean_ranks_bbo, mean_ranks_mf = get_mean_loss(\n#                 traj[dataset])\n#             Y_label = 'Loss'\n#         else:\n#             xs, mean_ranks, mean_ranks_bbo, mean_ranks_mf = get_mean_rank(\n#                 traj[dataset])\n#             Y_label = 'Mean_rank'\n#         if len(family_rank):\n#             family_rank += mean_ranks\n#             family_rank_bbo += mean_ranks_bbo\n#             family_rank_mf += mean_ranks_mf\n#         else:\n#             family_rank, family_rank_bbo, family_rank_mf = mean_ranks, \\\n#                                                            mean_ranks_bbo, \\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/data/utils.py\n# --------------------------------------------------\n#                               padding=True,\n#                               truncation=True,\n#                               max_length=raw_args['max_len'])\n#             data = [{key: value[i]\n#                      for key, value in x_all.items()}\n#                     for i in range(len(next(iter(x_all.values()))))]\n#             dataset[split] = (data, targets)\n#         data_split_dict = {\n#             'train': [(x, y)\n#                       for x, y in zip(dataset['train'][0], dataset['train'][1])\n#                       ],\n#             'val': [(x, y) for x, y in zip(dataset['validation'][0],\n#                                            dataset['validation'][1])],\n#             'test': [\n#                 (x, y) for x, y in zip(dataset['test'][0], dataset['test'][1])\n#             ] if (set(dataset['test'][1]) - set([-1])) else None,\n#         }\n#         original_train_size = len(data_split_dict[\"train\"])\n# \n#         if \"half_val_dummy_test\" in raw_args and raw_args[\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/splitters/graph/scaffold_lda_splitter.py\n# --------------------------------------------------\n# \n#     Returns:\n#          List(List(PyG.data)): data_list of split dataset via scaffold split.\n# \n#     \"\"\"\n#     def __init__(self, client_num, alpha):\n#         super(ScaffoldLdaSplitter, self).__init__(client_num)\n#         self.alpha = alpha\n# \n#     def __call__(self, dataset):\n#         featurizer = GenFeatures()\n#         data = []\n#         for ds in dataset:\n#             ds = featurizer(ds)\n#             data.append(ds)\n#         dataset = data\n#         idx_slice = gen_scaffold_lda_split(dataset, self.client_num,\n#                                            self.alpha)\n#         data_list = [[dataset[idx] for idx in idxs] for idxs in idx_slice]\n#         return data_list\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/splitters/graph/randchunk_splitter.py\n# --------------------------------------------------\n#     def __init__(self, client_num):\n#         BaseSplitter.__init__(self, client_num)\n# \n#     def __call__(self, dataset, **kwargs):\n#         data_list = []\n#         dataset = [ds for ds in dataset]\n#         num_graph = len(dataset)\n# \n#         # Split dataset\n#         num_graph = len(dataset)\n#         min_size = min(50, int(num_graph / self.client_num))\n# \n#         for i in range(self.client_num):\n#             data_list.append(dataset[i * min_size:(i + 1) * min_size])\n#         for graph in dataset[self.client_num * min_size:]:\n#             client_idx = np.random.randint(low=0, high=self.client_num,\n#                                            size=1)[0]\n#             data_list[client_idx].append(graph)\n# \n#         return data_list\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport os\nimport numpy as np\n\nfrom federatedscope.register import register_data\n\n# Run with mini_graph_dt:\n# python federatedscope/main.py --cfg \\\n# federatedscope/gfl/baseline/mini_graph_dc/fedavg.yaml --client_cfg \\\n# federatedscope/gfl/baseline/mini_graph_dc/fedavg_per_client.yaml\n# Test Accuracy: ~0.7\n\n\ndef load_mini_graph_dt(config, client_cfgs=None):\n    import torch\n    from torch_geometric.data import InMemoryDataset, Data\n    from torch_geometric.datasets import TUDataset, MoleculeNet\n    from federatedscope.core.splitters.graph.scaffold_lda_splitter import \\\n        GenFeatures\n    from federatedscope.core.data import DummyDataTranslator\n\n    class MiniGraphDCDataset(InMemoryDataset):\n        NAME = 'mini_graph_dt'\n        DATA_NAME = ['BACE', 'BBBP', 'CLINTOX', 'ENZYMES', 'PROTEINS_full']\n        IN_MEMORY_DATA = {}\n\n        def __init__(self, root, splits=[0.8, 0.1, 0.1]):\n            self.root = root\n            self.splits = splits\n            super(MiniGraphDCDataset, self).__init__(root)\n\n        @property\n        def processed_dir(self):\n            return os.path.join(self.root, self.NAME, 'processed')\n\n        @property\n        def processed_file_names(self):\n            return ['pre_transform.pt', 'pre_filter.pt']\n\n        def __len__(self):\n            return len(self.DATA_NAME)\n\n        def __getitem__(self, idx):\n            if idx not in self.IN_MEMORY_DATA:\n                self.IN_MEMORY_DATA[idx] = {}\n                for split in ['train', 'val', 'test']:\n                    split_data = self._load(idx, split)\n                    if split_data:\n                        self.IN_MEMORY_DATA[idx][split] = split_data\n            return self.IN_MEMORY_DATA[idx]\n\n        def _load(self, idx, split):\n            try:\n                data = torch.load(\n                    os.path.join(self.processed_dir, str(idx), f'{split}.pt'))\n            except:\n                data = None\n            return data\n\n        def process(self):\n            np.random.seed(0)\n            for idx, name in enumerate(self.DATA_NAME):\n                if name in ['BACE', 'BBBP', 'CLINTOX']:\n                    dataset = MoleculeNet(self.root, name)\n                    featurizer = GenFeatures()\n                    ds = []\n                    for graph in dataset:\n                        graph = featurizer(graph)\n                        ds.append(\n                            Data(edge_index=graph.edge_index,\n                                 x=graph.x,\n                                 y=graph.y))\n                    dataset = ds\n                    if name in ['BACE', 'BBBP']:\n                        for i in range(len(dataset)):\n                            dataset[i].y = dataset[i].y.long()\n                    if name in ['CLINTOX']:\n                        for i in range(len(dataset)):\n                            dataset[i].y = torch.argmax(\n                                dataset[i].y).view(-1).unsqueeze(0)\n                else:\n                    # Classification", "choices": [{"text": "dataset = TUDataset(self.root, name, pre_transform=self.pre_transform)"}], "metadata": {"task_id": "alibaba_FederatedScope/177", "ground_truth": "                    dataset = TUDataset(self.root, name)", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "contrib", "data", "mini_graph_dt.py"], "context_start_lineno": 0, "line_no": 81, "query_window": {"context": "                if name in ['BACE', 'BBBP', 'CLINTOX']:\n                    dataset = MoleculeNet(self.root, name)\n                    featurizer = GenFeatures()\n                    ds = []\n                    for graph in dataset:\n                        graph = featurizer(graph)\n                        ds.append(\n                            Data(edge_index=graph.edge_index,\n                                 x=graph.x,\n                                 y=graph.y))\n                    dataset = ds\n                    if name in ['BACE', 'BBBP']:\n                        for i in range(len(dataset)):\n                            dataset[i].y = dataset[i].y.long()\n                    if name in ['CLINTOX']:\n                        for i in range(len(dataset)):\n                            dataset[i].y = torch.argmax(\n                                dataset[i].y).view(-1).unsqueeze(0)\n                else:\n                    # Classification", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "contrib", "data", "mini_graph_dt.py"], "line_no": 81, "task_id": "alibaba_FederatedScope/177", "start_line_no": 61, "end_line_no": 81, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "\n        # Split dataset\n        num_graph = len(dataset)\n        min_size = min(50, int(num_graph / self.client_num))\n\n        for i in range(self.client_num):\n            data_list.append(dataset[i * min_size:(i + 1) * min_size])\n        for graph in dataset[self.client_num * min_size:]:\n            client_idx = np.random.randint(low=0, high=self.client_num,\n                                           size=1)[0]\n            data_list[client_idx].append(graph)\n\n        return data_list", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "splitters", "graph", "randchunk_splitter.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 33, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.28448275862068967}, {"context": "\n    def __call__(self, dataset):\n        featurizer = GenFeatures()\n        data = []\n        for ds in dataset:\n            ds = featurizer(ds)\n            data.append(ds)\n        dataset = data\n        idx_slice = gen_scaffold_lda_split(dataset, self.client_num,\n                                           self.alpha)\n        data_list = [[dataset[idx] for idx in idxs] for idxs in idx_slice]\n        return data_list", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "splitters", "graph", "scaffold_lda_splitter.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 182, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2727272727272727}, {"context": "                    element for i, element in enumerate(x_all)\n                    if i in selected_idx\n                ]\n                targets = [\n                    element for i, element in enumerate(targets)\n                    if i in selected_idx\n                ]\n\n            x_all = tokenizer(x_all,\n                              return_tensors='pt',\n                              padding=True,\n                              truncation=True,\n                              max_length=raw_args['max_len'])\n            data = [{key: value[i]\n                     for key, value in x_all.items()}\n                    for i in range(len(next(iter(x_all.values()))))]\n            dataset[split] = (data, targets)\n        data_split_dict = {\n            'train': [(x, y)\n                      for x, y in zip(dataset['train'][0], dataset['train'][1])", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "data", "utils.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.26811594202898553}, {"context": "        for i in range(repeat):\n            files_i = [file for file in files if f'repeat{i}' in file]\n            traj[dataset][i] = []\n            for opt in opt_all:\n                for file in files_i:\n                    if file.startswith(f'{opt.lower()}_'):\n                        traj[dataset][i].append(\n                            logloader(os.path.join(path, file)))\n\n    # Draw over dataset\n    family_rank = []\n    family_rank_bbo = []\n    family_rank_mf = []\n    for dataset in traj:\n        if loss:\n            print(dataset)\n            xs, mean_ranks, mean_ranks_bbo, mean_ranks_mf = get_mean_loss(\n                traj[dataset])\n            Y_label = 'Loss'\n        else:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "benchmark", "FedHPOBench", "fedhpobench", "utils", "draw.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.26119402985074625}, {"context": "        pred_degree = torch._cast_Int(torch.round(pred_degree)).detach()\n        x = x.detach()\n        fill_feats = torch.vstack((x, gen_feats.view(-1, num_feature)))\n\n        for i in range(num_node):\n            for j in range(min(self.num_pred, max(0, pred_degree[i]))):\n                new_edges.append(\n                    np.asarray([i, num_node + i * self.num_pred + j]))\n\n        new_edges = torch.tensor(np.asarray(new_edges).reshape((-1, 2)),\n                                 dtype=torch.int64).T\n        new_edges = new_edges.to(device)\n        if len(new_edges) > 0:\n            fill_edges = torch.hstack((edge_index, new_edges))\n        else:\n            fill_edges = torch.clone(edge_index)\n        return fill_feats, fill_edges\n\n    def forward(self, x, edge_index, pred_missing, gen_feats):\n        fill_feats, fill_edges = self.mend_graph(x, edge_index, pred_missing,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "model", "fedsageplus.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.26}, {"context": "    ]:\n        # Add feat for datasets without attrubute\n        if name in ['IMDB-BINARY', 'IMDB-MULTI'\n                    ] and 'pre_transform' not in transforms_funcs:\n            transforms_funcs['pre_transform'] = transforms.Constant(value=1.0,\n                                                                    cat=False)\n        dataset = TUDataset(path, name, **transforms_funcs)\n\n    elif name in [\n            'HIV', 'ESOL', 'FREESOLV', 'LIPO', 'PCBA', 'MUV', 'BACE', 'BBBP',\n            'TOX21', 'TOXCAST', 'SIDER', 'CLINTOX'\n    ]:\n        dataset = MoleculeNet(path, name, **transforms_funcs)\n        return dataset, config\n    elif name.startswith('graph_multi_domain'.upper()):\n        \"\"\"\n            The `graph_multi_domain` datasets follows GCFL\n            Federated Graph Classification over Non-IID Graphs (NeurIPS 2021)\n        \"\"\"\n        if name.endswith('mol'.upper()):", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "dataloader", "dataloader_graph.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.25882352941176473}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/evaluator/base.py\n# --------------------------------------------------\n#         \"\"\"\n#         Load dataset with given subset and split.\n#         Args:\n#             data ([`Dataset`] or `str`, defaults to `None`):\n#                 Specifies the dataset we will run evaluation on. If it is of\n#                 type `str`, we treat it as the dataset name, and load it. Otherwise we assume it represents a pre-loaded dataset.\n#             subset (`str`, defaults to `None`):\n#                 Specifies dataset subset to be passed to `name` in `load_dataset`. To be\n#                 used with datasets with several configurations (e.g. glue/sst2).\n#             split (`str`, defaults to `None`):\n#                 User-defined dataset split by name (e.g. train, validation, test). Supports slice-split (`test[:n]`).\n#                 If not defined and data is a `str` type, will automatically select the best one via `choose_split()`.\n#         Returns:\n#             data ([`Dataset`]): Loaded dataset which will be used for evaluation.\n# \n#         Example:\n# \n#         ```py\n#         >>> from evaluate import evaluator\n#         >>> evaluator(\"text-classification\").load_data(data=\"rotten_tomatoes\", split=\"train\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/inspect.py\n# --------------------------------------------------\n# \n#     Args:\n#         path (``str``): path to the evaluation script. Can be either:\n# \n#             - a local path to script or the directory containing the script (if the script has the same name as the directory),\n#                 e.g. ``'./metrics/accuracy'`` or ``'./metrics/accuracy/accuracy.py'``\n#             - a dataset identifier on the Hugging Face Hub (list all available datasets and ids with ``evaluate.list_evaluation_modules()``)\n#                 e.g. ``'accuracy'``, ``'bleu'`` or ``'word_length'``\n#         local_path (``str``): path to the local folder to copy the datset script to.\n#         download_config (Optional ``datasets.DownloadConfig``: specific download configuration parameters.\n#         **download_kwargs: optional attributes for DownloadConfig() which will override the attributes in download_config if supplied.\n#     \"\"\"\n#     evaluation_module = evaluation_module_factory(\n#         path, download_config=download_config, force_local_path=local_path, **download_kwargs\n#     )\n#     print(\n#         f\"The processing scripts for metric {path} can be inspected at {local_path}. \"\n#         f\"The main class is in {evaluation_module.module_path}. \"\n#         f\"You can modify this processing scripts and use it with `evaluate.load({local_path})`.\"\n#     )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#     if download_config.extract_compressed_file:\n#         output_path = ExtractManager(cache_dir=download_config.cache_dir).extract(\n#             output_path, force_extract=download_config.force_extract\n#         )\n# \n#     return output_path\n# \n# \n# def get_datasets_user_agent(user_agent: Optional[Union[str, dict]] = None) -> str:\n#     ua = f\"datasets/{__version__}; python/{config.PY_VERSION}\"\n#     ua += f\"; pyarrow/{config.PYARROW_VERSION}\"\n#     if config.TORCH_AVAILABLE:\n#         ua += f\"; torch/{config.TORCH_VERSION}\"\n#     if config.TF_AVAILABLE:\n#         ua += f\"; tensorflow/{config.TF_VERSION}\"\n#     if config.JAX_AVAILABLE:\n#         ua += f\"; jax/{config.JAX_VERSION}\"\n#     if isinstance(user_agent, dict):\n#         ua += f\"; {'; '.join(f'{k}/{v}' for k, v in user_agent.items())}\"\n#     elif isinstance(user_agent, str):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#         with open(meta_path, \"w\", encoding=\"utf-8\") as meta_file:\n#             json.dump(meta, meta_file)\n# \n#     return cache_path\n# \n# \n# def add_start_docstrings(*docstr):\n#     def docstring_decorator(fn):\n#         fn.__doc__ = \"\".join(docstr) + \"\\n\\n\" + (fn.__doc__ if fn.__doc__ is not None else \"\")\n#         return fn\n# \n#     return docstring_decorator\n# \n# \n# def add_end_docstrings(*docstr):\n#     def docstring_decorator(fn):\n#         fn.__doc__ = (fn.__doc__ if fn.__doc__ is not None else \"\") + \"\\n\\n\" + \"\".join(docstr)\n#         return fn\n# \n#     return docstring_decorator\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#     if etag:\n#         etag_bytes = etag.encode(\"utf-8\")\n#         etag_hash = sha256(etag_bytes)\n#         filename += \".\" + etag_hash.hexdigest()\n# \n#     if url.endswith(\".py\"):\n#         filename += \".py\"\n# \n#     return filename\n# \n# \n# @dataclass\n# class DownloadConfig:\n#     \"\"\"Configuration for our cached path manager.\n# \n#     Attributes:\n#         cache_dir (:obj:`str` or :obj:`Path`, optional): Specify a cache directory to save the file to (overwrite the\n#             default cache dir).\n#         force_download (:obj:`bool`, default ``False``): If True, re-dowload the file even if it's already cached in\n#             the cache dir.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#     If `etag` is specified, append its hash to the url's, delimited\n#     by a period.\n#     If the url ends with .h5 (Keras HDF5 weights) adds '.h5' to the name\n#     so that TF 2.0 can identify it as a HDF5 file\n#     (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n#     \"\"\"\n#     url_bytes = url.encode(\"utf-8\")\n#     url_hash = sha256(url_bytes)\n#     filename = url_hash.hexdigest()\n# \n#     if etag:\n#         etag_bytes = etag.encode(\"utf-8\")\n#         etag_hash = sha256(etag_bytes)\n#         filename += \".\" + etag_hash.hexdigest()\n# \n#     if url.endswith(\".py\"):\n#         filename += \".py\"\n# \n#     return filename\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Lint as: python3\n\"\"\"Access datasets.\"\"\"\nimport filecmp\nimport importlib\nimport inspect\nimport json\nimport os\nimport re\nimport shutil\nimport time\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import List, Optional, Tuple, Type, Union\nfrom urllib.parse import urlparse\n\nfrom datasets import DownloadMode\nfrom datasets.builder import DatasetBuilder\nfrom datasets.packaged_modules import _EXTENSION_TO_MODULE, _hash_python_lines\nfrom datasets.utils.filelock import FileLock\nfrom datasets.utils.version import Version\n\nfrom . import SCRIPTS_VERSION, config\nfrom .module import EvaluationModule\nfrom .utils.file_utils import (\n    DownloadConfig,\n    cached_path,\n    head_hf_s3,\n    hf_hub_url,\n    init_hf_modules,\n    is_relative_path,\n    relative_to_absolute_path,\n    url_or_path_join,\n)\nfrom .utils.logging import get_logger\n\n\nlogger = get_logger(__name__)\n\n\nALL_ALLOWED_EXTENSIONS = list(_EXTENSION_TO_MODULE.keys()) + [\"zip\"]\n\n\ndef init_dynamic_modules(\n    name: str = config.MODULE_NAME_FOR_DYNAMIC_MODULES, hf_modules_cache: Optional[Union[Path, str]] = None\n):\n    \"\"\"\n    Create a module with name `name` in which you can add dynamic modules\n    such as metrics or datasets. The module can be imported using its name.\n    The module is created in the HF_MODULE_CACHE directory by default (~/.cache/huggingface/modules) but it can\n    be overriden by specifying a path to another directory in `hf_modules_cache`.\n    \"\"\"\n    hf_modules_cache = init_hf_modules(hf_modules_cache)\n    dynamic_modules_path = os.path.join(hf_modules_cache, name)\n    os.makedirs(dynamic_modules_path, exist_ok=True)\n    if not os.path.exists(os.path.join(dynamic_modules_path, \"__init__.py\")):\n        with open(os.path.join(dynamic_modules_path, \"__init__.py\"), \"w\"):\n            pass\n    return dynamic_modules_path\n\n\ndef import_main_class(module_path) -> Optional[Union[Type[DatasetBuilder], Type[EvaluationModule]]]:\n    \"\"\"Import a module at module_path and return its main class, a Metric by default\"\"\"\n    module = importlib.import_module(module_path)\n    main_cls_type = EvaluationModule\n\n    # Find the main class in our imported module\n    module_main_cls = None\n    for name, obj in module.__dict__.items():\n        if isinstance(obj, type) and issubclass(obj, main_cls_type):\n            if inspect.isabstract(obj):\n                continue\n            module_main_cls = obj\n            break\n\n    return module_main_cls\n\n\ndef files_to_hash(file_paths: List[str]) -> str:\n    \"\"\"\n    Convert a list of scripts or text files provided in file_paths into a hashed filename in a repeatable way.\n    \"\"\"\n    # List all python files in directories if directories are supplied as part of external imports\n    to_use_files: List[Union[Path, str]] = []\n    for file_path in file_paths:\n        if os.path.isdir(file_path):\n            to_use_files.extend(list(Path(file_path).rglob(\"*.[pP][yY]\")))\n        else:\n            to_use_files.append(file_path)\n\n    # Get the code from all these files\n    lines = []\n    for file_path in to_use_files:\n        with open(file_path, encoding=\"utf-8\") as f:\n            lines.extend(f.readlines())\n    return _hash_python_lines(lines)\n\n\ndef convert_github_url(url_path: str) -> Tuple[str, Optional[str]]:\n    \"\"\"Convert a link to a file on a github repo in a link to the raw github object.\"\"\"\n    parsed = urlparse(url_path)\n    sub_directory = None\n    if parsed.scheme in (\"http\", \"https\", \"s3\") and parsed.netloc == \"github.com\":\n        if \"blob\" in url_path:\n            if not url_path.endswith(\".py\"):\n                raise ValueError(f\"External import from github at {url_path} should point to a file ending with '.py'\")\n            url_path = url_path.replace(\"blob\", \"raw\")  # Point to the raw file\n        else:\n            # Parse github url to point to zip\n            github_path = parsed.path[1:]\n            repo_info, branch = github_path.split(\"/tree/\") if \"/tree/\" in github_path else (github_path, \"master\")\n            repo_owner, repo_name = repo_info.split(\"/\")\n            url_path = f\"https://github.com/{repo_owner}/{repo_name}/archive/{branch}.zip\"\n            sub_directory = f\"{repo_name}-{branch}\"\n    return url_path, sub_directory\n\n\ndef increase_load_count(name: str, resource_type: str):\n    \"\"\"Update the download count of a dataset or metric.\"\"\"\n    if not config.HF_EVALUATE_OFFLINE and config.HF_UPDATE_DOWNLOAD_COUNTS:\n        try:\n            head_hf_s3(name, filename=name + \".py\", dataset=(resource_type == \"dataset\"))\n        except Exception:\n            pass\n\n\ndef get_imports(file_path: str) -> Tuple[str, str, str, str]:\n    \"\"\"Find whether we should import or clone additional files for a given processing script.\n        And list the import.\n\n    We allow:\n    - library dependencies,\n    - local dependencies and\n    - external dependencies whose url is specified with a comment starting from \"# From:' followed by the raw url to a file, an archive or a github repository.\n        external dependencies will be downloaded (and extracted if needed in the dataset folder).\n        We also add an `__init__.py` to each sub-folder of a downloaded folder so the user can import from them in the script.\n\n    Note that only direct import in the dataset processing script will be handled\n    We don't recursively explore the additional import to download further files.\n\n    Example::\n\n        import tensorflow\n        import .c4_utils\n        import .clicr.dataset-code.build_json_dataset  # From: https://raw.githubusercontent.com/clips/clicr/master/dataset-code/build_json_dataset\n    \"\"\"\n    lines = []\n    with open(file_path, encoding=\"utf-8\") as f:\n        lines.extend(f.readlines())\n\n    logger.debug(f\"Checking {file_path} for additional imports.\")\n    imports: List[Tuple[str, str, str, Optional[str]]] = []\n    is_in_docstring = False", "choices": [{"text": ".."}], "metadata": {"task_id": "huggingface_evaluate/26", "ground_truth": "    for line in lines:", "fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "context_start_lineno": 0, "line_no": 166, "query_window": {"context": "    - external dependencies whose url is specified with a comment starting from \"# From:' followed by the raw url to a file, an archive or a github repository.\n        external dependencies will be downloaded (and extracted if needed in the dataset folder).\n        We also add an `__init__.py` to each sub-folder of a downloaded folder so the user can import from them in the script.\n\n    Note that only direct import in the dataset processing script will be handled\n    We don't recursively explore the additional import to download further files.\n\n    Example::\n\n        import tensorflow\n        import .c4_utils\n        import .clicr.dataset-code.build_json_dataset  # From: https://raw.githubusercontent.com/clips/clicr/master/dataset-code/build_json_dataset\n    \"\"\"\n    lines = []\n    with open(file_path, encoding=\"utf-8\") as f:\n        lines.extend(f.readlines())\n\n    logger.debug(f\"Checking {file_path} for additional imports.\")\n    imports: List[Tuple[str, str, str, Optional[str]]] = []\n    is_in_docstring = False", "metadata": {"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 166, "task_id": "huggingface_evaluate/26", "start_line_no": 146, "end_line_no": 166, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "def url_or_path_parent(url_or_path: str) -> str:\n    if is_remote_url(url_or_path):\n        return url_or_path[: url_or_path.rindex(\"/\")]\n    else:\n        return os.path.dirname(url_or_path)\n\n\ndef hash_url_to_filename(url, etag=None):\n    \"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    If the url ends with .h5 (Keras HDF5 weights) adds '.h5' to the name\n    so that TF 2.0 can identify it as a HDF5 file\n    (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n    \"\"\"\n    url_bytes = url.encode(\"utf-8\")\n    url_hash = sha256(url_bytes)\n    filename = url_hash.hexdigest()\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.21224489795918366}, {"context": "    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    If the url ends with .h5 (Keras HDF5 weights) adds '.h5' to the name\n    so that TF 2.0 can identify it as a HDF5 file\n    (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n    \"\"\"\n    url_bytes = url.encode(\"utf-8\")\n    url_hash = sha256(url_bytes)\n    filename = url_hash.hexdigest()\n\n    if etag:\n        etag_bytes = etag.encode(\"utf-8\")\n        etag_hash = sha256(etag_bytes)\n        filename += \".\" + etag_hash.hexdigest()\n\n    if url.endswith(\".py\"):\n        filename += \".py\"\n\n    return filename\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2017167381974249}, {"context": "                    max_retries=max_retries,\n                    desc=download_desc,\n                )\n\n        logger.info(f\"storing {url} in cache at {cache_path}\")\n        shutil.move(temp_file.name, cache_path)\n\n        logger.info(f\"creating metadata file for {cache_path}\")\n        meta = {\"url\": url, \"etag\": etag}\n        meta_path = cache_path + \".json\"\n        with open(meta_path, \"w\", encoding=\"utf-8\") as meta_file:\n            json.dump(meta, meta_file)\n\n    return cache_path\n\n\ndef add_start_docstrings(*docstr):\n    def docstring_decorator(fn):\n        fn.__doc__ = \"\".join(docstr) + \"\\n\\n\" + (fn.__doc__ if fn.__doc__ is not None else \"\")\n        return fn", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 630, "start_line_no": 620, "end_line_no": 640, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.19626168224299065}, {"context": "    elif is_local_path(url_or_filename):\n        # File, but it doesn't exist.\n        raise FileNotFoundError(f\"Local file {url_or_filename} doesn't exist\")\n    else:\n        # Something unknown\n        raise ValueError(f\"unable to parse {url_or_filename} as a URL or as a local path\")\n\n    if output_path is None:\n        return output_path\n\n    if download_config.extract_compressed_file:\n        output_path = ExtractManager(cache_dir=download_config.cache_dir).extract(\n            output_path, force_extract=download_config.force_extract\n        )\n\n    return output_path\n\n\ndef get_datasets_user_agent(user_agent: Optional[Union[str, dict]] = None) -> str:\n    ua = f\"datasets/{__version__}; python/{config.PY_VERSION}\"", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.18518518518518517}, {"context": "    Args:\n        path (``str``): path to the evaluation script. Can be either:\n\n            - a local path to script or the directory containing the script (if the script has the same name as the directory),\n                e.g. ``'./metrics/accuracy'`` or ``'./metrics/accuracy/accuracy.py'``\n            - a dataset identifier on the Hugging Face Hub (list all available datasets and ids with ``evaluate.list_evaluation_modules()``)\n                e.g. ``'accuracy'``, ``'bleu'`` or ``'word_length'``\n        local_path (``str``): path to the local folder to copy the datset script to.\n        download_config (Optional ``datasets.DownloadConfig``: specific download configuration parameters.\n        **download_kwargs: optional attributes for DownloadConfig() which will override the attributes in download_config if supplied.\n    \"\"\"\n    evaluation_module = evaluation_module_factory(\n        path, download_config=download_config, force_local_path=local_path, **download_kwargs\n    )\n    print(\n        f\"The processing scripts for metric {path} can be inspected at {local_path}. \"\n        f\"The main class is in {evaluation_module.module_path}. \"\n        f\"You can modify this processing scripts and use it with `evaluate.load({local_path})`.\"\n    )", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "inspect.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 129, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.18473895582329317}, {"context": "        WARNING:evaluate.evaluator.base:Dataset split not defined! Automatically evaluating with split: TEST\n        'test'\n        ```\n        \"\"\"\n        if split is None:\n            split = choose_split(data, subset)\n            logger.warning(f\"Dataset split not defined! Automatically evaluating with split: {split.upper()}\")\n        return split\n\n    def load_data(self, data: Union[str, Dataset], subset: str = None, split: str = None):\n        \"\"\"\n        Load dataset with given subset and split.\n        Args:\n            data ([`Dataset`] or `str`, defaults to `None`):\n                Specifies the dataset we will run evaluation on. If it is of\n                type `str`, we treat it as the dataset name, and load it. Otherwise we assume it represents a pre-loaded dataset.\n            subset (`str`, defaults to `None`):\n                Specifies dataset subset to be passed to `name` in `load_dataset`. To be\n                used with datasets with several configurations (e.g. glue/sst2).\n            split (`str`, defaults to `None`):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluator", "base.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.18454935622317598}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n# \n#     @_check_start\n#     def state_dict(self) -> OrderedDict:\n#         state_dict = OrderedDict()\n#         for channel in self.parent_channels:\n#             channel.send((\"state_dict\", None))\n#         for idx, channel in enumerate(self.parent_channels):\n#             msg, _state_dict = channel.recv()\n#             if msg != \"state_dict\":\n#                 raise RuntimeError(f\"Expected 'state_dict' but received {msg}\")\n#             state_dict[f\"worker{idx}\"] = _state_dict\n# \n#         return state_dict\n# \n#     @_check_start\n#     def load_state_dict(self, state_dict: OrderedDict) -> None:\n#         if \"worker0\" not in state_dict:\n#             state_dict = OrderedDict(\n#                 **{f\"worker{idx}\": state_dict for idx in range(self.num_workers)}\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#                 for td in self.shared_tensordicts:\n#                     td.share_memory_()\n#             elif self._memmap:\n#                 for td in self.shared_tensordicts:\n#                     td.memmap_()\n#         else:\n#             if self._share_memory:\n#                 self.shared_tensordict_parent.share_memory_()\n#                 if not self.shared_tensordict_parent.is_shared():\n#                     raise RuntimeError(\"share_memory_() failed\")\n#             elif self._memmap:\n#                 self.shared_tensordict_parent.memmap_()\n#                 if not self.shared_tensordict_parent.is_memmap():\n#                     raise RuntimeError(\"memmap_() failed\")\n# \n#             self.shared_tensordicts = self.shared_tensordict_parent.unbind(0)\n#         if self.pin_memory:\n#             self.shared_tensordict_parent.pin_memory()\n# \n#         if raise_no_selected_keys:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#         keys = set()\n#         for i in range(self.num_workers):\n#             msg, data = self.parent_channels[i].recv()\n#             if msg != \"step_result\":\n#                 raise RuntimeError(\n#                     f\"Expected 'step_result' but received {msg} from worker {i}\"\n#                 )\n#             # data is the set of updated keys\n#             keys = keys.union(data)\n#         # We must pass a clone of the tensordict, as the values of this tensordict\n#         # will be modified in-place at further steps\n#         return self.shared_tensordict_parent.select(\n#             *keys,\n#             strict=False,\n#         ).clone()\n# \n#     @_check_start\n#     def _shutdown_workers(self) -> None:\n#         if self.is_closed:\n#             raise RuntimeError(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n#             )\n#         if shared_td is not None:\n#             for key in in_keys:\n#                 if (\n#                     (key + \"_sum\" not in shared_td.keys())\n#                     or (key + \"_ssq\" not in shared_td.keys())\n#                     or (key + \"_count\" not in shared_td.keys())\n#                 ):\n#                     raise KeyError(\n#                         f\"key {key} not present in the shared tensordict \"\n#                         f\"with keys {shared_td.keys()}\"\n#                     )\n# \n#         self.lock = lock\n#         self.decay = decay\n#         self.eps = eps\n# \n#     def _call(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         if self.lock is not None:\n#             self.lock.acquire()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/collectors/collectors.py\n# --------------------------------------------------\n#         elif msg == \"seed\":\n#             data_in, static_seed = data_in\n#             new_seed = dc.set_seed(data_in, static_seed=static_seed)\n#             torch.manual_seed(data_in)\n#             np.random.seed(data_in)\n#             pipe_child.send((new_seed, \"seeded\"))\n#             has_timed_out = False\n#             continue\n# \n#         elif msg == \"reset\":\n#             dc.reset()\n#             pipe_child.send((j, \"reset\"))\n#             continue\n# \n#         elif msg == \"state_dict\":\n#             state_dict = dc.state_dict()\n#             # send state_dict to cpu first\n#             state_dict = recursive_map_to_cpu(state_dict)\n#             pipe_child.send((state_dict, \"state_dict\"))\n#             has_timed_out = False\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#             elif self._memmap:\n#                 self.shared_tensordict_parent.memmap_()\n#                 if not self.shared_tensordict_parent.is_memmap():\n#                     raise RuntimeError(\"memmap_() failed\")\n# \n#             self.shared_tensordicts = self.shared_tensordict_parent.unbind(0)\n#         if self.pin_memory:\n#             self.shared_tensordict_parent.pin_memory()\n# \n#         if raise_no_selected_keys:\n#             if self._verbose:\n#                 print(\n#                     f\"\\n {self.__class__.__name__}.shared_tensordict_parent is \\n{self.shared_tensordict_parent}. \\n\"\n#                     f\"You can select keys to be synchronised by setting the selected_keys and/or excluded_keys \"\n#                     f\"arguments when creating the batched environment.\"\n#                 )\n# \n#     def _start_workers(self) -> None:\n#         \"\"\"Starts the various envs.\"\"\"\n#         raise NotImplementedError\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n#         elif tensordict is None:\n#             raise RuntimeError(\"tensordict must be provided when auto_reset is False\")\n# \n#         if policy is None:\n# \n#             def policy(td):\n#                 return td.set(\"action\", self.action_spec.rand())\n# \n#         tensordicts = []\n#         for i in range(max_steps):\n#             if auto_cast_to_device:\n#                 tensordict = tensordict.to(policy_device)\n#             tensordict = policy(tensordict)\n#             if auto_cast_to_device:\n#                 tensordict = tensordict.to(env_device)\n#             tensordict = self.step(tensordict)\n#             tensordicts.append(tensordict.clone())\n#             if (\n#                 break_when_any_done and tensordict.get(\"done\").any()\n#             ) or i == max_steps - 1:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n(self) -> None:\n        if self.is_closed:\n            raise RuntimeError(\n                \"calling {self.__class__.__name__}._shutdown_workers only allowed when env.is_closed = False\"\n            )\n        for i, channel in enumerate(self.parent_channels):\n            if self._verbose:\n                print(f\"closing {i}\")\n            # try:\n            channel.send((\"close\", None))\n            # except:\n            #     raise RuntimeError(f\"closing {channel} number {i} failed\")\n            msg, _ = channel.recv()\n            if msg != \"closing\":\n                raise RuntimeError(\n                    f\"Expected 'closing' but received {msg} from worker {i}\"\n                )\n\n        del self.shared_tensordicts, self.shared_tensordict_parent\n\n        for channel in self.parent_channels:\n            channel.close()\n        for proc in self._workers:\n            proc.join()\n        del self._workers\n        del self.parent_channels\n\n    @_check_start\n    def set_seed(\n        self, seed: Optional[int] = None, static_seed: bool = False\n    ) -> Optional[int]:\n        self._seeds = []\n        for channel in self.parent_channels:\n            channel.send((\"seed\", (seed, static_seed)))\n            self._seeds.append(seed)\n            msg, new_seed = channel.recv()\n            if msg != \"seeded\":\n                raise RuntimeError(f\"Expected 'seeded' but received {msg}\")\n            seed = new_seed\n        return seed\n\n    @_check_start\n    def _reset(self, tensordict: TensorDictBase, **kwargs) -> TensorDictBase:\n        cmd_out = \"reset\"\n        if tensordict is not None and \"_reset\" in tensordict.keys():\n            self._assert_tensordict_shape(tensordict)\n            _reset = tensordict.get(\"_reset\")\n        else:\n            _reset = torch.ones(self.batch_size, dtype=torch.bool)\n\n        for i, channel in enumerate(self.parent_channels):\n            if not _reset[i].any():\n                continue\n            kwargs[\"tensordict\"] = tensordict[i] if tensordict is not None else None\n            channel.send((cmd_out, kwargs))\n\n        keys = set()\n        for i, channel in enumerate(self.parent_channels):\n            if not _reset[i].any():\n                continue\n            cmd_in, new_keys = channel.recv()\n            keys = keys.union(new_keys)\n            if cmd_in != \"reset_obs\":\n                raise RuntimeError(f\"received cmd {cmd_in} instead of reset_obs\")\n        check_count = 0\n        while self.shared_tensordict_parent.get(\"done\")[_reset].any():\n            if check_count == 4:\n                raise RuntimeError(\n                    \"Envs have just been reset bur env is done on specified '_reset' dimensions.\"\n                )\n            else:\n                check_count += 1\n                # there might be some delay between writing the shared tensordict\n                # and reading the updated value on the main process\n                sleep(0.01)\n        return self.shared_tensordict_parent.select(\n            *keys,\n            strict=False,\n        ).clone()\n\n    def __reduce__(self):\n        if not self.is_closed:\n            # ParallelEnv contains non-instantiated envs, thus it can be\n            # closed and serialized if the environment building functions\n            # permit it\n            self.close()\n        return super().__reduce__()\n\n    def __getattr__(self, attr: str) -> Any:\n        if attr in self.__dir__():\n            return super().__getattr__(\n                attr\n            )  # make sure that appropriate exceptions are raised\n        elif attr.startswith(\"__\"):\n            raise AttributeError(\n                \"dispatching built-in private methods is not permitted.\"\n            )\n        else:\n            if attr in self._excluded_wrapped_keys:\n                raise AttributeError(f\"Getting {attr} resulted in an exception\")\n            try:\n                # _ = getattr(self._dummy_env, attr)\n                if self.is_closed:\n                    raise RuntimeError(\n                        \"Trying to access attributes of closed/non started \"\n                        \"environments. Check that the batched environment \"\n                        \"has been started (e.g. by calling env.reset)\"\n                    )\n                # dispatch to workers\n                return _dispatch_caller_parallel(attr, self)\n            except AttributeError:\n                raise AttributeError(\n                    f\"attribute {attr} not found in \" f\"{self._dummy_env_str}\"\n                )\n\n    def to(self, device: DEVICE_TYPING):\n        device = torch.device(device)\n        if device == self.device:\n            return self\n        super().to(device)\n        if self._seeds is not None:\n            warn(\n                \"Sending a seeded ParallelEnv to another device requires \"\n                f\"re-seeding it. Re-seeding envs to {self._seeds}.\"\n            )\n            self.set_seed(self._seeds[0])\n        return self\n\n\ndef _recursively_strip_locks_from_state_dict(state_dict: OrderedDict) -> OrderedDict:\n    return OrderedDict(\n        **{\n            k: _recursively_strip_locks_from_state_dict(item)\n            if isinstance(item, OrderedDict)\n            else None\n            if isinstance(item, MpLock)\n            else item\n            for k, item in state_dict.items()\n        }\n    )\n\n\ndef _run_worker_pipe_shared_mem(\n    idx: int,\n    parent_pipe: connection.Connection,\n    child_pipe: connection.Connection,\n    env_fun: Union[EnvBase, Callable],\n    env_fun_kwargs: Dict[str, Any],\n    pin_memory: bool,\n    env_input_keys: Dict[str, Any],\n    device: DEVICE_TYPING = \"cpu\",\n    allow_step_when_done: bool = False,\n    verbose: bool = False,\n) -> None:\n    parent_pipe.close()\n    pid = os.getpid()\n    if not isinstance(env_fun, EnvBase):\n        env = env_fun(**env_fun_kwargs)\n    else:\n        if env_fun_kwargs:\n            raise RuntimeError(\n                \"env_fun_kwargs must be empty if an environment is passed to a process.\"\n            )\n        env = env_fun\n    env = env.to(device)\n    i = -1\n    initialized = False\n\n    # make sure that process can be closed\n    tensordict = None\n    _td = None\n    data = None\n\n    reset_keys = None\n    step_keys = None\n\n    while True:\n        try:\n            cmd, data = child_pipe.recv()\n        except EOFError as err:\n            raise EOFError(f\"proc {pid} failed, last command: {cmd}.\") from err\n        if cmd == \"seed\":\n            if not initialized:\n                raise RuntimeError(\"call 'init' before closing\")\n            # torch.manual_seed(data)\n            # np.random.seed(data)\n            new_seed = env.set_seed(data[0], static_seed=data[1])\n            child_pipe.send((\"seeded\", new_seed))\n\n        elif cmd == \"init\":\n            if verbose:\n                print(f\"initializing {pid}\")\n            if initialized:\n                raise RuntimeError(\"worker already initialized\")\n            i = 0\n            tensordict = data\n            if not (tensordict.is_shared() or tensordict.is_memmap()):\n                raise RuntimeError(\n                    \"tensordict must be placed in shared memory (share_memory_() or memmap_())\"\n                )\n            initialized = True\n\n        elif cmd == \"reset\":", "choices": [{"text": "if not initialized:"}], "metadata": {"task_id": "pytorch_rl/132", "ground_truth": "            reset_kwargs = data", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "context_start_lineno": 787, "line_no": 990, "query_window": {"context": "                raise RuntimeError(\"call 'init' before closing\")\n            # torch.manual_seed(data)\n            # np.random.seed(data)\n            new_seed = env.set_seed(data[0], static_seed=data[1])\n            child_pipe.send((\"seeded\", new_seed))\n\n        elif cmd == \"init\":\n            if verbose:\n                print(f\"initializing {pid}\")\n            if initialized:\n                raise RuntimeError(\"worker already initialized\")\n            i = 0\n            tensordict = data\n            if not (tensordict.is_shared() or tensordict.is_memmap()):\n                raise RuntimeError(\n                    \"tensordict must be placed in shared memory (share_memory_() or memmap_())\"\n                )\n            initialized = True\n\n        elif cmd == \"reset\":", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 990, "task_id": "pytorch_rl/132", "start_line_no": 970, "end_line_no": 990, "window_size": 20, "context_start_lineno": 787, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            policy_device = \"cpu\"\n\n        env_device = self.device\n\n        if auto_reset:\n            if tensordict is not None:\n                raise RuntimeError(\n                    \"tensordict cannot be provided when auto_reset is True\"\n                )\n            tensordict = self.reset()\n        elif tensordict is None:\n            raise RuntimeError(\"tensordict must be provided when auto_reset is False\")\n\n        if policy is None:\n\n            def policy(td):\n                return td.set(\"action\", self.action_spec.rand())\n\n        tensordicts = []\n        for i in range(max_steps):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 650, "start_line_no": 640, "end_line_no": 660, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3170731707317073}, {"context": "                for td in self.shared_tensordicts:\n                    td.share_memory_()\n            elif self._memmap:\n                for td in self.shared_tensordicts:\n                    td.memmap_()\n        else:\n            if self._share_memory:\n                self.shared_tensordict_parent.share_memory_()\n                if not self.shared_tensordict_parent.is_shared():\n                    raise RuntimeError(\"share_memory_() failed\")\n            elif self._memmap:\n                self.shared_tensordict_parent.memmap_()\n                if not self.shared_tensordict_parent.is_memmap():\n                    raise RuntimeError(\"memmap_() failed\")\n\n            self.shared_tensordicts = self.shared_tensordict_parent.unbind(0)\n        if self.pin_memory:\n            self.shared_tensordict_parent.pin_memory()\n\n        if raise_no_selected_keys:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3008849557522124}, {"context": "                has_timed_out = True\n                continue\n            # pipe_child.send(\"done\")\n\n        elif msg == \"update\":\n            dc.update_policy_weights_()\n            pipe_child.send((j, \"updated\"))\n            has_timed_out = False\n            continue\n\n        elif msg == \"seed\":\n            data_in, static_seed = data_in\n            new_seed = dc.set_seed(data_in, static_seed=static_seed)\n            torch.manual_seed(data_in)\n            np.random.seed(data_in)\n            pipe_child.send((new_seed, \"seeded\"))\n            has_timed_out = False\n            continue\n\n        elif msg == \"reset\":", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "collectors", "collectors.py"], "line_no": 1730, "start_line_no": 1720, "end_line_no": 1740, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3}, {"context": "            lock = mp.Lock()\n        if in_keys is None:\n            in_keys = [\"observation\", \"reward\"]\n        super().__init__(in_keys)\n        self._td = shared_td\n        if shared_td is not None and not (\n            shared_td.is_shared() or shared_td.is_memmap()\n        ):\n            raise RuntimeError(\n                \"shared_td must be either in shared memory or a memmap \" \"tensordict.\"\n            )\n        if shared_td is not None:\n            for key in in_keys:\n                if (\n                    (key + \"_sum\" not in shared_td.keys())\n                    or (key + \"_ssq\" not in shared_td.keys())\n                    or (key + \"_count\" not in shared_td.keys())\n                ):\n                    raise KeyError(\n                        f\"key {key} not present in the shared tensordict \"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 2330, "start_line_no": 2320, "end_line_no": 2340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2971014492753623}, {"context": "\n        self.shared_tensordict_parent.update_(\n            tensordict.select(\n                *self.env_input_keys,\n                strict=False,\n            )\n        )\n        for i in range(self.num_workers):\n            self.parent_channels[i].send((\"step\", None))\n\n        keys = set()\n        for i in range(self.num_workers):\n            msg, data = self.parent_channels[i].recv()\n            if msg != \"step_result\":\n                raise RuntimeError(\n                    f\"Expected 'step_result' but received {msg} from worker {i}\"\n                )\n            # data is the set of updated keys\n            keys = keys.union(data)\n        # We must pass a clone of the tensordict, as the values of this tensordict", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 770, "start_line_no": 760, "end_line_no": 780, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28859060402684567}, {"context": "\n        if self.share_individual_td:\n            if not isinstance(self.shared_tensordict_parent, LazyStackedTensorDict):\n                self.shared_tensordicts = [\n                    td.clone() for td in self.shared_tensordict_parent.unbind(0)\n                ]\n                self.shared_tensordict_parent = torch.stack(self.shared_tensordicts, 0)\n            else:\n                self.shared_tensordicts = self.shared_tensordict_parent\n            if self._share_memory:\n                for td in self.shared_tensordicts:\n                    td.share_memory_()\n            elif self._memmap:\n                for td in self.shared_tensordicts:\n                    td.memmap_()\n        else:\n            if self._share_memory:\n                self.shared_tensordict_parent.share_memory_()\n                if not self.shared_tensordict_parent.is_shared():\n                    raise RuntimeError(\"share_memory_() failed\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2857142857142857}, {"context": "            channel2.close()\n            self.parent_channels.append(channel1)\n            self._workers.append(w)\n\n        # send shared tensordict to workers\n        for channel, shared_tensordict in zip(\n            self.parent_channels, self.shared_tensordicts\n        ):\n            channel.send((\"init\", shared_tensordict))\n        self.is_closed = False\n\n    @_check_start\n    def state_dict(self) -> OrderedDict:\n        state_dict = OrderedDict()\n        for channel in self.parent_channels:\n            channel.send((\"state_dict\", None))\n        for idx, channel in enumerate(self.parent_channels):\n            msg, _state_dict = channel.recv()\n            if msg != \"state_dict\":\n                raise RuntimeError(f\"Expected 'state_dict' but received {msg}\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 730, "start_line_no": 720, "end_line_no": 740, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28378378378378377}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n# \n#     @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n#     @pytest.mark.parametrize(\"env_name\", [PONG_VERSIONED, PENDULUM_VERSIONED])\n#     @pytest.mark.parametrize(\"frame_skip\", [4, 1])\n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     def test_parallel_env_transform_consistency(self, env_name, frame_skip, device):\n#         env_parallel_in, env_serial_in, env0_in = _make_envs(\n#             env_name,\n#             frame_skip,\n#             transformed_in=True,\n#             transformed_out=False,\n#             device=device,\n#             N=3,\n#         )\n#         env_parallel_out, env_serial_out, env0_out = _make_envs(\n#             env_name,\n#             frame_skip,\n#             transformed_in=False,\n#             transformed_out=True,\n#             device=device,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#         self, env_name, frame_skip, transformed_in, transformed_out, device\n#     ):\n#         # tests creation on device\n#         torch.manual_seed(0)\n#         N = 3\n# \n#         env_parallel, env_serial, env0 = _make_envs(\n#             env_name,\n#             frame_skip,\n#             transformed_in=transformed_in,\n#             transformed_out=transformed_out,\n#             device=device,\n#             N=N,\n#         )\n# \n#         assert env0.device == torch.device(device)\n#         out = env0.rollout(max_steps=20)\n#         assert out.device == torch.device(device)\n# \n#         assert env_serial.device == torch.device(device)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#         env0.close()\n# \n#     @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n#     @pytest.mark.skipif(not torch.cuda.device_count(), reason=\"no cuda device detected\")\n#     @pytest.mark.parametrize(\"frame_skip\", [4])\n#     @pytest.mark.parametrize(\"device\", [0])\n#     @pytest.mark.parametrize(\"env_name\", [PONG_VERSIONED, PENDULUM_VERSIONED])\n#     @pytest.mark.parametrize(\"transformed_in\", [True, False])\n#     @pytest.mark.parametrize(\"transformed_out\", [True, False])\n#     def test_parallel_env_device(\n#         self, env_name, frame_skip, transformed_in, transformed_out, device\n#     ):\n#         # tests creation on device\n#         torch.manual_seed(0)\n#         N = 3\n# \n#         env_parallel, env_serial, env0 = _make_envs(\n#             env_name,\n#             frame_skip,\n#             transformed_in=transformed_in,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#         env1 = DMControlEnv(\"humanoid\", \"stand\")\n#         env1_obs_keys = list(env1.observation_spec.keys())\n#         env2 = DMControlEnv(\"humanoid\", \"walk\")\n#         env2_obs_keys = list(env2.observation_spec.keys())\n# \n#         assert len(env1_obs_keys)\n#         assert len(env2_obs_keys)\n# \n#         def env1_maker():\n#             return TransformedEnv(\n#                 DMControlEnv(\"humanoid\", \"stand\"),\n#                 Compose(\n#                     CatTensors(env1_obs_keys, \"observation_stand\", del_keys=False),\n#                     CatTensors(env1_obs_keys, \"observation\"),\n#                     DoubleToFloat(\n#                         in_keys=[\"observation_stand\", \"observation\"],\n#                         in_keys_inv=[\"action\"],\n#                     ),\n#                 ),\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_collector.py\n# --------------------------------------------------\n#     ccollector.shutdown()\n# \n# \n# @pytest.mark.skipif(not _has_gym, reason=\"gym library is not installed\")\n# def test_collector_env_reset():\n#     torch.manual_seed(0)\n# \n#     def make_env():\n#         return GymEnv(PONG_VERSIONED, frame_skip=4)\n# \n#     env = SerialEnv(2, make_env)\n#     # env = SerialEnv(3, lambda: GymEnv(\"CartPole-v1\", frame_skip=4))\n#     env.set_seed(0)\n#     collector = SyncDataCollector(\n#         env, total_frames=10000, frames_per_batch=10000, split_trajs=False\n#     )\n#     for _data in collector:\n#         continue\n#     steps = _data[\"collector\", \"step_count\"][..., 1:]\n#     done = _data[\"done\"][..., :-1, :].squeeze(-1)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#     with pytest.raises(AssertionError):\n#         assert_allclose_td(td1a, td1c)\n#     env.close()\n# \n# \n# @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n# @pytest.mark.parametrize(\"env_name\", [PENDULUM_VERSIONED, PONG_VERSIONED])\n# @pytest.mark.parametrize(\"frame_skip\", [1, 4])\n# def test_rollout(env_name, frame_skip, seed=0):\n#     env = GymEnv(env_name, frame_skip=frame_skip)\n# \n#     torch.manual_seed(seed)\n#     np.random.seed(seed)\n#     env.set_seed(seed)\n#     env.reset()\n#     rollout1 = env.rollout(max_steps=100)\n# \n#     torch.manual_seed(seed)\n#     np.random.seed(seed)\n#     env.set_seed(seed)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n# \n#     torch.manual_seed(seed)\n#     np.random.seed(seed)\n#     env.set_seed(seed)\n#     env.reset()\n#     rollout1 = env.rollout(max_steps=100)\n# \n#     torch.manual_seed(seed)\n#     np.random.seed(seed)\n#     env.set_seed(seed)\n#     env.reset()\n#     rollout2 = env.rollout(max_steps=100)\n# \n#     assert_allclose_td(rollout1, rollout2)\n# \n#     torch.manual_seed(seed)\n#     env.set_seed(seed + 10)\n#     env.reset()\n#     rollout3 = env.rollout(max_steps=100)\n#     with pytest.raises(AssertionError):\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n(\"already pixel\")\n        elif (\n            env_name != PONG_VERSIONED\n            and from_pixels\n            and (not torch.has_cuda or not torch.cuda.device_count())\n        ):\n            raise pytest.skip(\"no cuda device\")\n\n        tdreset = []\n        tdrollout = []\n        final_seed = []\n        for _ in range(2):\n            env0 = GymEnv(\n                env_name,\n                frame_skip=frame_skip,\n                from_pixels=from_pixels,\n                pixels_only=pixels_only,\n            )\n            torch.manual_seed(0)\n            np.random.seed(0)\n            final_seed.append(env0.set_seed(0))\n            tdreset.append(env0.reset())\n            tdrollout.append(env0.rollout(max_steps=50))\n            assert env0.from_pixels is from_pixels\n            env0.close()\n            env_type = type(env0._env)\n            del env0\n\n        assert_allclose_td(*tdreset)\n        assert_allclose_td(*tdrollout)\n        final_seed0, final_seed1 = final_seed\n        assert final_seed0 == final_seed1\n\n        if env_name == PONG_VERSIONED:\n            base_env = gym.make(env_name, frameskip=frame_skip)\n            frame_skip = 1\n        else:\n            base_env = _make_gym_environment(env_name)\n\n        if from_pixels and not _is_from_pixels(base_env):\n            base_env = PixelObservationWrapper(base_env, pixels_only=pixels_only)\n        assert type(base_env) is env_type\n        env1 = GymWrapper(base_env, frame_skip=frame_skip)\n        torch.manual_seed(0)\n        np.random.seed(0)\n        final_seed2 = env1.set_seed(0)\n        tdreset2 = env1.reset()\n        rollout2 = env1.rollout(max_steps=50)\n        assert env1.from_pixels is from_pixels\n        env1.close()\n        del env1, base_env\n\n        assert_allclose_td(tdreset[0], tdreset2, rtol=1e-4, atol=1e-4)\n        assert final_seed0 == final_seed2\n        assert_allclose_td(tdrollout[0], rollout2, rtol=1e-4, atol=1e-4)\n\n    def test_gym_fake_td(self, env_name, frame_skip, from_pixels, pixels_only):\n        if env_name == PONG_VERSIONED and not from_pixels:\n            raise pytest.skip(\"already pixel\")\n        elif (\n            env_name != PONG_VERSIONED\n            and from_pixels\n            and (not torch.has_cuda or not torch.cuda.device_count())\n        ):\n            raise pytest.skip(\"no cuda device\")\n\n        env = GymEnv(\n            env_name,\n            frame_skip=frame_skip,\n            from_pixels=from_pixels,\n            pixels_only=pixels_only,\n        )\n        check_env_specs(env)\n\n\n@implement_for(\"gym\", None, \"0.26\")\ndef _make_gym_environment(env_name):  # noqa: F811\n    return gym.make(env_name)\n\n\n@implement_for(\"gym\", \"0.26\", None)\ndef _make_gym_environment(env_name):  # noqa: F811\n    return gym.make(env_name, render_mode=\"rgb_array\")\n\n\n@pytest.mark.skipif(not _has_dmc, reason=\"no dm_control library found\")\n@pytest.mark.parametrize(\"env_name,task\", [[\"cheetah\", \"run\"]])\n@pytest.mark.parametrize(\"frame_skip\", [1, 3])\n@pytest.mark.parametrize(\n    \"from_pixels,pixels_only\",\n    [\n        [True, True],\n        [True, False],\n        [False, False],\n    ],\n)\nclass TestDMControl:\n    def test_dmcontrol(self, env_name, task, frame_skip, from_pixels, pixels_only):\n        if from_pixels and (not torch.has_cuda or not torch.cuda.device_count()):\n            raise pytest.skip(\"no cuda device\")\n\n        tds = []\n        tds_reset = []\n        final_seed = []\n        for _ in range(2):\n            env0 = DMControlEnv(\n                env_name,\n                task,\n                frame_skip=frame_skip,\n                from_pixels=from_pixels,\n                pixels_only=pixels_only,\n            )\n            torch.manual_seed(0)\n            np.random.seed(0)\n            final_seed0 = env0.set_seed(0)\n            tdreset0 = env0.reset()\n            rollout0 = env0.rollout(max_steps=50)\n            env0.close()\n            del env0\n            tds_reset.append(tdreset0)\n            tds.append(rollout0)\n            final_seed.append(final_seed0)\n\n        tdreset1, tdreset0 = tds_reset\n        rollout0, rollout1 = tds\n        final_seed0, final_seed1 = final_seed\n\n        assert_allclose_td(tdreset1, tdreset0)\n        assert final_seed0 == final_seed1\n        assert_allclose_td(rollout0, rollout1)\n\n        env1 = DMControlEnv(\n            env_name,\n            task,\n            frame_skip=frame_skip,\n            from_pixels=from_pixels,\n            pixels_only=pixels_only,\n        )\n        torch.manual_seed(1)\n        np.random.seed(1)\n        final_seed1 = env1.set_seed(1)\n        tdreset1 = env1.reset()\n        rollout1 = env1.rollout(max_steps=50)\n        env1.close()\n        del env1\n\n        with pytest.raises(AssertionError):\n            assert_allclose_td(tdreset1, tdreset0)\n            assert final_seed0 == final_seed1\n            assert_allclose_td(rollout0, rollout1)\n\n        base_env = suite.load(env_name, task)\n        if from_pixels:\n            render_kwargs = {\"camera_id\": 0}\n            base_env = pixels.Wrapper(\n                base_env, pixels_only=pixels_only, render_kwargs=render_kwargs\n            )\n        env2 = DMControlWrapper(base_env, frame_skip=frame_skip)\n        torch.manual_seed(0)\n        np.random.seed(0)\n        final_seed2 = env2.set_seed(0)\n        tdreset2 = env2.reset()\n        rollout2 = env2.rollout(max_steps=50)\n\n        assert_allclose_td(tdreset0, tdreset2)\n        assert final_seed0 == final_seed2\n        assert_allclose_td(rollout0, rollout2)\n\n    def test_faketd(self, env_name, task, frame_skip, from_pixels, pixels_only):\n        if from_pixels and (not torch.has_cuda or not torch.cuda.device_count()):\n            raise pytest.skip(\"no cuda device\")\n\n        env = DMControlEnv(\n            env_name,\n            task,\n            frame_skip=frame_skip,\n            from_pixels=from_pixels,\n            pixels_only=pixels_only,\n        )\n        check_env_specs(env)\n\n\n@pytest.mark.skipif(\n    IS_OSX,\n    reason=\"rendering unstable on osx, skipping (mujoco.FatalError: gladLoadGL error)\",\n)", "choices": [{"text": "test/test_gym.py"}], "metadata": {"task_id": "pytorch_rl/106", "ground_truth": "@pytest.mark.skipif(not (_has_dmc and _has_gym), reason=\"gym or dm_control not present\")", "fpath_tuple": ["pytorch_rl", "test", "test_libs.py"], "context_start_lineno": 71, "line_no": 257, "query_window": {"context": "        assert_allclose_td(rollout0, rollout2)\n\n    def test_faketd(self, env_name, task, frame_skip, from_pixels, pixels_only):\n        if from_pixels and (not torch.has_cuda or not torch.cuda.device_count()):\n            raise pytest.skip(\"no cuda device\")\n\n        env = DMControlEnv(\n            env_name,\n            task,\n            frame_skip=frame_skip,\n            from_pixels=from_pixels,\n            pixels_only=pixels_only,\n        )\n        check_env_specs(env)\n\n\n@pytest.mark.skipif(\n    IS_OSX,\n    reason=\"rendering unstable on osx, skipping (mujoco.FatalError: gladLoadGL error)\",\n)", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_libs.py"], "line_no": 257, "task_id": "pytorch_rl/106", "start_line_no": 237, "end_line_no": 257, "window_size": 20, "context_start_lineno": 71, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    with pytest.raises(AssertionError):\n        assert_allclose_td(td1a, td1c)\n    env.close()\n\n\n@pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n@pytest.mark.parametrize(\"env_name\", [PENDULUM_VERSIONED, PONG_VERSIONED])\n@pytest.mark.parametrize(\"frame_skip\", [1, 4])\ndef test_rollout(env_name, frame_skip, seed=0):\n    env = GymEnv(env_name, frame_skip=frame_skip)\n\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    env.set_seed(seed)\n    env.reset()\n    rollout1 = env.rollout(max_steps=100)\n\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    env.set_seed(seed)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.34532374100719426}, {"context": "    assert_allclose_td(td1a, td1b)\n\n    env.set_seed(\n        seed=seed + 10,\n    )\n    td0c = env.reset()\n    td1c = env.step(td0c.clone().set(\"action\", action))\n\n    with pytest.raises(AssertionError):\n        assert_allclose_td(td0a, td0c.select(*td0a.keys()))\n    with pytest.raises(AssertionError):\n        assert_allclose_td(td1a, td1c)\n    env.close()\n\n\n@pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n@pytest.mark.parametrize(\"env_name\", [PENDULUM_VERSIONED, PONG_VERSIONED])\n@pytest.mark.parametrize(\"frame_skip\", [1, 4])\ndef test_rollout(env_name, frame_skip, seed=0):\n    env = GymEnv(env_name, frame_skip=frame_skip)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3263888888888889}, {"context": "        elif i == 1:\n            b2c = d\n        else:\n            break\n    with pytest.raises(AssertionError):\n        assert_allclose_td(b1c, b2c)\n\n    assert_allclose_td(b1c, b1)\n    assert_allclose_td(b2c, b2)\n\n    ccollector.shutdown()\n\n\n@pytest.mark.skipif(not _has_gym, reason=\"gym library is not installed\")\ndef test_collector_env_reset():\n    torch.manual_seed(0)\n\n    def make_env():\n        return GymEnv(PONG_VERSIONED, frame_skip=4)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_collector.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.32608695652173914}, {"context": "        td_serial = env_serial.rollout(max_steps=50)\n\n        env_parallel.set_seed(0)\n        torch.manual_seed(0)\n        td_parallel = env_parallel.rollout(max_steps=50)\n\n        assert_allclose_td(td_serial, td_parallel)\n\n    @pytest.mark.skipif(not _has_dmc, reason=\"no dm_control\")\n    def test_multitask(self):\n        env1 = DMControlEnv(\"humanoid\", \"stand\")\n        env1_obs_keys = list(env1.observation_spec.keys())\n        env2 = DMControlEnv(\"humanoid\", \"walk\")\n        env2_obs_keys = list(env2.observation_spec.keys())\n\n        assert len(env1_obs_keys)\n        assert len(env2_obs_keys)\n\n        def env1_maker():\n            return TransformedEnv(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3237410071942446}, {"context": "        assert env_parallel.device == torch.device(device)\n        td_device = env_parallel.reset()\n        assert td_device.device == torch.device(device), env_parallel\n        td_device = env_parallel.rand_step()\n        assert td_device.device == torch.device(device), env_parallel\n        td_device = env_parallel.rollout(max_steps=10)\n        assert td_device.device == torch.device(device), env_parallel\n\n        env_parallel.close()\n        env_serial.close()\n        env0.close()\n\n    @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n    @pytest.mark.skipif(not torch.cuda.device_count(), reason=\"no cuda device detected\")\n    @pytest.mark.parametrize(\"frame_skip\", [4])\n    @pytest.mark.parametrize(\"device\", [0])\n    @pytest.mark.parametrize(\"env_name\", [PONG_VERSIONED, PENDULUM_VERSIONED])\n    @pytest.mark.parametrize(\"transformed_in\", [True, False])\n    @pytest.mark.parametrize(\"transformed_out\", [True, False])\n    def test_parallel_env_device(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 770, "start_line_no": 760, "end_line_no": 780, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.32116788321167883}, {"context": "        env0.close()\n\n    @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n    @pytest.mark.skipif(not torch.cuda.device_count(), reason=\"no cuda device detected\")\n    @pytest.mark.parametrize(\"frame_skip\", [4])\n    @pytest.mark.parametrize(\"device\", [0])\n    @pytest.mark.parametrize(\"env_name\", [PONG_VERSIONED, PENDULUM_VERSIONED])\n    @pytest.mark.parametrize(\"transformed_in\", [True, False])\n    @pytest.mark.parametrize(\"transformed_out\", [True, False])\n    def test_parallel_env_device(\n        self, env_name, frame_skip, transformed_in, transformed_out, device\n    ):\n        # tests creation on device\n        torch.manual_seed(0)\n        N = 3\n\n        env_parallel, env_serial, env0 = _make_envs(\n            env_name,\n            frame_skip,\n            transformed_in=transformed_in,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 780, "start_line_no": 770, "end_line_no": 790, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.31690140845070425}, {"context": "        out = env_serial.rollout(max_steps=20)\n        assert out.device == torch.device(device)\n\n        assert env_parallel.device == torch.device(device)\n        out = env_parallel.rollout(max_steps=20)\n        assert out.device == torch.device(device)\n\n        env_parallel.close()\n        env_serial.close()\n        env0.close()\n\n    @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n    @pytest.mark.parametrize(\"env_name\", [PONG_VERSIONED, PENDULUM_VERSIONED])\n    @pytest.mark.parametrize(\"frame_skip\", [4, 1])\n    @pytest.mark.parametrize(\"device\", get_available_devices())\n    def test_parallel_env_transform_consistency(self, env_name, frame_skip, device):\n        env_parallel_in, env_serial_in, env0_in = _make_envs(\n            env_name,\n            frame_skip,\n            transformed_in=True,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 810, "start_line_no": 800, "end_line_no": 820, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3120567375886525}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"accuracy\",\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"accuracy\"], 1.0)\n# \n#     def test_bootstrap(self):\n#         data = Dataset.from_dict({\"label\": [1, 0, 0], \"text\": [\"great movie\", \"great movie\", \"horrible movie\"]})\n# \n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=data,\n#             metric=\"accuracy\",\n#             label_mapping=self.label_mapping,\n#             strategy=\"bootstrap\",\n#             n_resamples=10,\n#             random_state=0,\n#         )\n#         self.assertAlmostEqual(results[\"accuracy\"][\"score\"], 0.666666, 5)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/evaluator/token_classification.py\n# --------------------------------------------------\n#                 if prediction[token_index][\"start\"] > word_offset[0]:  # bad indexing\n#                     pred_processed.append(\"O\")\n#                 elif prediction[token_index][\"start\"] == word_offset[0]:\n#                     pred_processed.append(prediction[token_index][\"entity\"])\n# \n#             preds.append(pred_processed)\n# \n#         return {\"predictions\": preds}\n# \n#     def words_to_offsets(self, words: List[str], join_by: str):\n#         \"\"\"\n#         Convert a list of words to a list of offsets, where word are joined by `join_by`.\n# \n#         Args:\n#             words (`List[str]`):\n#                 List of words to get offsets from.\n#             join_by (`str`):\n#                 String to insert between words.\n# \n#         Returns:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#             data=self.data,\n#         )\n#         self.assertEqual(results[\"exact_match\"], 100.0)\n#         self.assertEqual(results[\"f1\"], 100.0)\n# \n#         # squad_v2-like dataset\n#         results = self.evaluator.compute(\n#             data=self.data_v2,\n#             metric=\"squad_v2\",\n#         )\n#         self.assertDictEqual(\n#             {key: results[key] for key in [\"HasAns_f1\", \"NoAns_f1\"]}, {\"HasAns_f1\": 100.0, \"NoAns_f1\": 0.0}\n#         )\n# \n#     def test_data_loading(self):\n#         # Test passing in dataset by name with data_split\n#         data = self.evaluator.load_data(\"evaluate/squad-ci\", split=\"validation[:1]\")\n#         self.evaluator.prepare_data(\n#             data=data, question_column=\"question\", context_column=\"context\", id_column=\"id\", label_column=\"answers\"\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=data,\n#             metric=\"accuracy\",\n#             label_mapping=self.label_mapping,\n#             strategy=\"bootstrap\",\n#             n_resamples=10,\n#             random_state=0,\n#         )\n#         self.assertAlmostEqual(results[\"accuracy\"][\"score\"], 0.666666, 5)\n#         self.assertAlmostEqual(results[\"accuracy\"][\"confidence_interval\"][0], 0.33333, 5)\n#         self.assertAlmostEqual(results[\"accuracy\"][\"confidence_interval\"][1], 0.666666, 5)\n#         self.assertAlmostEqual(results[\"accuracy\"][\"standard_error\"], 0.22498, 5)\n# \n#     def test_perf(self):\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.perf_pipe,\n#             data=self.data,\n#             metric=\"accuracy\",\n#             input_column=self.input_column,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#             {\"start\": 2, \"entity\": \"I-LOC\"},\n#             {\"start\": 4, \"entity\": \"I-LOC\"},\n#             {\"start\": 9, \"entity\": \"O\"},\n#             {\"start\": 11, \"entity\": \"O\"},\n#             {\"start\": 16, \"entity\": \"B-LOC\"},\n#             {\"start\": 21, \"entity\": \"O\"},\n#         ]\n# \n#         return [result]\n# \n# \n# class DummyAutomaticSpeechRecognitionPipeline:\n#     def __init__(self) -> None:\n#         self.task = \"automatic-speech-recognition\"\n# \n#     def __call__(self, inputs, **kwargs):\n#         return [{\"text\": \"Lorem ipsum\"} for _ in inputs]\n# \n# \n# class TestEvaluator(TestCase):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n# \n# class DummyAutomaticSpeechRecognitionPipeline:\n#     def __init__(self) -> None:\n#         self.task = \"automatic-speech-recognition\"\n# \n#     def __call__(self, inputs, **kwargs):\n#         return [{\"text\": \"Lorem ipsum\"} for _ in inputs]\n# \n# \n# class TestEvaluator(TestCase):\n#     def setUp(self):\n#         self.data = Dataset.from_dict({\"label\": [1, 0], \"text\": [\"great movie\", \"horrible movie\"]})\n#         self.default_ckpt = \"hf-internal-testing/tiny-random-bert\"\n#         self.default_model = AutoModelForSequenceClassification.from_pretrained(self.default_ckpt, num_labels=2)\n#         self.default_tokenizer = AutoTokenizer.from_pretrained(self.default_ckpt)\n#         self.pipe = pipeline(\"text-classification\", model=self.default_model, tokenizer=self.default_tokenizer)\n#         self.evaluator = evaluator(\"text-classification\")\n#         self.data = Dataset.from_dict({\"label\": [1, 0], \"text\": [\"great movie\", \"horrible movie\"]})\n#         self.label_mapping = {\"LABEL_0\": 0.0, \"LABEL_1\": 1.0}\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n        )\n        self.assertEqual(results[\"exact_match\"], 100.0)\n        self.assertEqual(results[\"f1\"], 100.0)\n\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"squad\",\n        )\n        self.assertEqual(results[\"exact_match\"], 100.0)\n        self.assertEqual(results[\"f1\"], 100.0)\n\n\nclass TestTokenClassificationEvaluator(TestCase):\n    def setUp(self):\n        features = Features(\n            {\n                \"tokens\": Sequence(feature=Value(dtype=\"string\")),\n                \"ner_tags\": Sequence(feature=ClassLabel(names=[\"O\", \"B-LOC\", \"I-LOC\"])),\n            }\n        )\n\n        self.data = Dataset.from_dict(\n            {\n                \"tokens\": [[\"New\", \"York\", \"a\", \"nice\", \"City\", \".\"]],\n                \"ner_tags\": [[1, 2, 0, 0, 1, 0]],\n            },\n            features=features,\n        )\n        self.default_model = \"hf-internal-testing/tiny-bert-for-token-classification\"\n        self.pipe = DummyTokenClassificationPipeline()\n        self.evaluator = evaluator(\"token-classification\")\n\n    @slow\n    def test_model_init(self):\n        results = self.evaluator.compute(\n            model_or_pipeline=self.default_model,\n            data=self.data,\n            metric=\"seqeval\",\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 0.5)\n\n        model = AutoModelForTokenClassification.from_pretrained(self.default_model)\n        tokenizer = AutoTokenizer.from_pretrained(self.default_model)\n        results = self.evaluator.compute(\n            model_or_pipeline=model,\n            data=self.data,\n            metric=\"seqeval\",\n            tokenizer=tokenizer,\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 0.5)\n\n    def test_class_init(self):\n        evaluator = TokenClassificationEvaluator()\n        self.assertEqual(evaluator.task, \"token-classification\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"seqeval\",\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 1.0)\n\n    @slow\n    def test_default_pipe_init(self):\n        results = self.evaluator.compute(\n            data=self.data,\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 2 / 3)\n\n    def test_overwrite_default_metric(self):\n        accuracy = load(\"seqeval\")\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=accuracy,\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 1.0)\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"seqeval\",\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 1.0)\n\n    def test_data_loading(self):\n        # Test passing in dataset by name with data_split\n        data = self.evaluator.load_data(\"evaluate/conll2003-ci\", split=\"validation[:1]\")\n        self.evaluator.prepare_data(\n            data=data,\n            input_column=\"tokens\",\n            label_column=\"ner_tags\",\n            join_by=\" \",\n        )\n\n        # Test passing in dataset by name without data_split and inferring the optimal split\n        data = self.evaluator.load_data(\"evaluate/conll2003-ci\")\n        self.evaluator.prepare_data(\n            data=data,\n            input_column=\"tokens\",\n            label_column=\"ner_tags\",\n            join_by=\" \",\n        )\n\n        # Test that it chooses the correct one (e.g. conll2003 has train, validation, test but should select test)\n        self.assertEqual(data.split, \"test\")\n\n        # Test that the data point returned is correct; this maps to the first example in the dataset\n        self.assertEqual(data[0][\"id\"], \"0\")\n\n    def test_wrong_task(self):\n        self.assertRaises(KeyError, evaluator, \"bad_task\")\n\n    def test_words_to_offsets(self):\n        task_evaluator = evaluator(\"token-classification\")\n\n        words = [\"This\", \"is\", \"a\", \"test\", \".\"]\n        join_by = \" \"\n\n        offsets = task_evaluator.words_to_offsets(words, join_by)\n\n        self.assertListEqual([(0, 3), (5, 6), (8, 8), (10, 13), (15, 15)], offsets)\n\n        words = [\"\u65e5\", \"\u672c\", \"\u8a9e\", \"\u306f\u306a\u305b\u308b\u306e?\"]\n        join_by = \"\"\n\n        offsets = task_evaluator.words_to_offsets(words, join_by)\n\n        self.assertListEqual([(0, 0), (1, 1), (2, 2), (3, 8)], offsets)\n\n    def test_predictions_processor(self):\n        task_evaluator = evaluator(\"token-classification\")\n        join_by = \" \"\n        words = [[\"New\", \"York\", \"a\", \"nice\", \"City\", \".\"]]\n\n        # aligned start and words\n        predictions = [\n            [\n                {\"start\": 0, \"entity\": \"B-LOC\"},\n                {\"start\": 2, \"entity\": \"I-LOC\"},\n                {\"start\": 4, \"entity\": \"I-LOC\"},\n                {\"start\": 9, \"entity\": \"O\"},\n                {\"start\": 11, \"entity\": \"O\"},\n                {\"start\": 16, \"entity\": \"B-LOC\"},\n                {\"start\": 21, \"entity\": \"O\"},\n            ]\n        ]\n        predictions = task_evaluator.predictions_processor(predictions, words, join_by)\n        self.assertListEqual(predictions[\"predictions\"][0], [\"B-LOC\", \"I-LOC\", \"O\", \"O\", \"B-LOC\", \"O\"])\n\n        # non-aligned start and words\n        predictions = [\n            [\n                {\"start\": 0, \"entity\": \"B-LOC\"},\n                {\"start\": 2, \"entity\": \"I-LOC\"},\n                {\"start\": 9, \"entity\": \"O\"},\n                {\"start\": 11, \"entity\": \"O\"},\n                {\"start\": 16, \"entity\": \"B-LOC\"},\n                {\"start\": 21, \"entity\": \"O\"},\n            ]\n        ]\n        predictions = task_evaluator.predictions_processor(predictions, words, join_by)\n        self.assertListEqual(predictions[\"predictions\"][0], [\"B-LOC\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\"])\n\n        # non-aligned start and words\n        predictions = [\n            [\n                {\"start\": 0, \"entity\": \"B-LOC\"},\n                {\"start\": 6, \"entity\": \"I-LOC\"},\n                {\"start\": 9, \"entity\": \"O\"},\n                {\"start\": 11, \"entity\": \"O\"},\n                {\"start\": 16, \"entity\": \"B-LOC\"},\n                {\"start\": 21, \"entity\": \"O\"},\n            ]\n        ]\n        predictions = task_evaluator.predictions_processor(predictions, words, join_by)\n        self.assertListEqual(predictions[\"predictions\"][0], [\"B-LOC\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\"])\n\n        # non-aligned start and words\n        predictions = [\n            [", "choices": [{"text": "{\"start\": 0, \"entity\": \"B-LOC\"},"}], "metadata": {"task_id": "huggingface_evaluate/148", "ground_truth": "                {\"start\": 0, \"entity\": \"B-LOC\"},", "fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "context_start_lineno": 660, "line_no": 842, "query_window": {"context": "        predictions = task_evaluator.predictions_processor(predictions, words, join_by)\n        self.assertListEqual(predictions[\"predictions\"][0], [\"B-LOC\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\"])\n\n        # non-aligned start and words\n        predictions = [\n            [\n                {\"start\": 0, \"entity\": \"B-LOC\"},\n                {\"start\": 6, \"entity\": \"I-LOC\"},\n                {\"start\": 9, \"entity\": \"O\"},\n                {\"start\": 11, \"entity\": \"O\"},\n                {\"start\": 16, \"entity\": \"B-LOC\"},\n                {\"start\": 21, \"entity\": \"O\"},\n            ]\n        ]\n        predictions = task_evaluator.predictions_processor(predictions, words, join_by)\n        self.assertListEqual(predictions[\"predictions\"][0], [\"B-LOC\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\"])\n\n        # non-aligned start and words\n        predictions = [\n            [", "metadata": {"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 842, "task_id": "huggingface_evaluate/148", "start_line_no": 822, "end_line_no": 842, "window_size": 20, "context_start_lineno": 660, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "            {\"start\": 2, \"entity\": \"I-LOC\"},\n            {\"start\": 4, \"entity\": \"I-LOC\"},\n            {\"start\": 9, \"entity\": \"O\"},\n            {\"start\": 11, \"entity\": \"O\"},\n            {\"start\": 16, \"entity\": \"B-LOC\"},\n            {\"start\": 21, \"entity\": \"O\"},\n        ]\n\n        return [result]\n\n\nclass DummyAutomaticSpeechRecognitionPipeline:\n    def __init__(self) -> None:\n        self.task = \"automatic-speech-recognition\"\n\n    def __call__(self, inputs, **kwargs):\n        return [{\"text\": \"Lorem ipsum\"} for _ in inputs]\n\n\nclass TestEvaluator(TestCase):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.27927927927927926}, {"context": "            return [{\"score\": 0.95, \"start\": 31, \"end\": 39, \"answer\": \"Felix\"} for _ in question]\n\n\nclass DummyTokenClassificationPipeline:\n    def __init__(self):\n        self.task = \"token-classification\"\n\n    def __call__(self, inputs, **kwargs):\n        result = [\n            {\"start\": 0, \"entity\": \"B-LOC\"},\n            {\"start\": 2, \"entity\": \"I-LOC\"},\n            {\"start\": 4, \"entity\": \"I-LOC\"},\n            {\"start\": 9, \"entity\": \"O\"},\n            {\"start\": 11, \"entity\": \"O\"},\n            {\"start\": 16, \"entity\": \"B-LOC\"},\n            {\"start\": 21, \"entity\": \"O\"},\n        ]\n\n        return [result]\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.27184466019417475}, {"context": "            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"accuracy\",\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    def test_bootstrap(self):\n        data = Dataset.from_dict({\"label\": [1, 0, 0], \"text\": [\"great movie\", \"great movie\", \"horrible movie\"]})\n\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=data,\n            metric=\"accuracy\",\n            label_mapping=self.label_mapping,\n            strategy=\"bootstrap\",\n            n_resamples=10,\n            random_state=0,\n        )\n        self.assertAlmostEqual(results[\"accuracy\"][\"score\"], 0.666666, 5)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.25217391304347825}, {"context": "            metric=\"squad_v2\",\n        )\n        self.assertDictEqual(\n            {key: results[key] for key in [\"HasAns_f1\", \"NoAns_f1\"]}, {\"HasAns_f1\": 100.0, \"NoAns_f1\": 100.0}\n        )\n\n    @slow\n    def test_default_pipe_init(self):\n        # squad_v1-like dataset\n        results = self.evaluator.compute(\n            data=self.data,\n        )\n        self.assertEqual(results[\"exact_match\"], 100.0)\n        self.assertEqual(results[\"f1\"], 100.0)\n\n        # squad_v2-like dataset\n        results = self.evaluator.compute(\n            data=self.data_v2,\n            metric=\"squad_v2\",\n        )", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 620, "start_line_no": 610, "end_line_no": 630, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.24770642201834864}, {"context": "\n            # get a list of tuples giving the indexes of the start and end character of each word\n            words_offsets = self.words_to_offsets(words[i], join_by)\n\n            token_index = 0\n            for word_offset in words_offsets:\n                # for each word, we may keep only the predicted label for the first token, discard the others\n                while prediction[token_index][\"start\"] < word_offset[0]:\n                    token_index += 1\n\n                if prediction[token_index][\"start\"] > word_offset[0]:  # bad indexing\n                    pred_processed.append(\"O\")\n                elif prediction[token_index][\"start\"] == word_offset[0]:\n                    pred_processed.append(prediction[token_index][\"entity\"])\n\n            preds.append(pred_processed)\n\n        return {\"predictions\": preds}\n\n    def words_to_offsets(self, words: List[str], join_by: str):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluator", "token_classification.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2440944881889764}, {"context": "    def test_overwrite_default_metric(self):\n        accuracy = load(\"accuracy\")\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=accuracy,\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"accuracy\",\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    def test_bootstrap(self):\n        data = Dataset.from_dict({\"label\": [1, 0, 0], \"text\": [\"great movie\", \"great movie\", \"horrible movie\"]})\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.24107142857142858}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/contrib/metrics/example.py\n# --------------------------------------------------\n# from federatedscope.register import register_metric\n# \n# METRIC_NAME = 'example'\n# \n# \n# def MyMetric(ctx, **kwargs):\n#     return ctx.num_train_data\n# \n# \n# def call_my_metric(types):\n#     if METRIC_NAME in types:\n#         the_larger_the_better = True\n#         metric_builder = MyMetric\n#         return METRIC_NAME, metric_builder, the_larger_the_better\n# \n# \n# register_metric(METRIC_NAME, call_my_metric)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/dataloader/dataloader.py\n# --------------------------------------------------\n# \n#     # create the temp dir for output\n#     tmp_dir = os.path.join(cfg.outdir, 'temp')\n#     os.makedirs(tmp_dir, exist_ok=True)\n# \n#     if cfg.federate.save_to:\n#         cfg.federate.save_to = os.path.join(cfg.outdir, cfg.federate.save_to)\n#         os.makedirs(cfg.federate.save_to, exist_ok=True)\n# \n#     # modification for debug (load a small subset from the whole dataset)\n#     if cfg.data.is_debug:\n#         cfg.federate.client_num = 6\n#         cfg.data.hetero_data_name = [\n#             'imdb', 'agnews', 'squad', 'newsqa', 'cnndm', 'msqg'\n#         ]\n#         cfg.data.num_of_client_for_data = [1, 1, 1, 1, 1, 1]\n#         cfg.federate.total_round_num = 2\n#         cfg.train.local_update_steps = 2\n#         # TODO\n#         cfg.federate.atc_load_from = ''\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/metric/newsqa.py\n# --------------------------------------------------\n#     examples = ctx.get('{}_examples'.format(ctx.cur_split))\n#     encoded_inputs = ctx.get('{}_encoded'.format(ctx.cur_split))\n#     results = ctx.newsqa_results\n#     n_best_size = ctx.cfg.model.n_best_size\n#     max_answer_len = ctx.cfg.model.max_answer_len\n#     null_score_diff_threshold = ctx.cfg.model.null_score_diff_threshold\n# \n#     metrics = compute_squad_metrics(examples, encoded_inputs, results,\n#                                     n_best_size, max_answer_len,\n#                                     null_score_diff_threshold)\n#     return metrics\n# \n# \n# def call_newsqa_metric(types):\n#     if 'newsqa' in types:\n#         the_larger_the_better = True\n#         return 'newsqa', load_newsqa_metrics, the_larger_the_better\n# \n# \n# register_metric('newsqa', call_newsqa_metric)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/dataset/msqg.py\n# --------------------------------------------------\n# \n# def get_msqg_examples(data, is_debug=False):\n#     if is_debug:\n#         data = data[:NUM_DEBUG]\n#     src_examples, tgt_examples = [], []\n#     for ex in data:\n#         src_examples.append(ex['src'])\n#         tgt_examples.append(ex['tgt'])\n#     return src_examples, tgt_examples\n# \n# \n# def process_msqg_dataset(data,\n#                          split,\n#                          tokenizer,\n#                          max_src_len,\n#                          max_tgt_len,\n#                          raw_cache_dir='',\n#                          client_id=None,\n#                          pretrain=False,\n#                          is_debug=False,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/metric/cnndm.py\n# --------------------------------------------------\n# \n# \n# def load_cnndm_metrics(ctx, **kwargs):\n#     tmp_dir = os.path.join(ctx.cfg.outdir, 'temp')\n#     rouges = test_rouge(tmp_dir, ctx.pred_path, ctx.tgt_path)\n#     results = {\n#         k: v\n#         for k, v in rouges.items()\n#         if k in {'rouge_1_f_score', 'rouge_2_f_score', 'rouge_l_f_score'}\n#     }\n#     return results\n# \n# \n# def call_cnndm_metric(types):\n#     if 'cnndm' in types:\n#         the_larger_the_better = True\n#         return 'cnndm', load_cnndm_metrics, the_larger_the_better\n# \n# \n# register_metric('cnndm', call_cnndm_metric)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/metric/cnndm.py\n# --------------------------------------------------\n# import logging\n# import os\n# from federatedscope.register import register_metric\n# from federatedscope.nlp.metric.rouge.utils import test_rouge\n# \n# logger = logging.getLogger(__name__)\n# \n# \n# def load_cnndm_metrics(ctx, **kwargs):\n#     tmp_dir = os.path.join(ctx.cfg.outdir, 'temp')\n#     rouges = test_rouge(tmp_dir, ctx.pred_path, ctx.tgt_path)\n#     results = {\n#         k: v\n#         for k, v in rouges.items()\n#         if k in {'rouge_1_f_score', 'rouge_2_f_score', 'rouge_l_f_score'}\n#     }\n#     return results\n# \n# \n# def call_cnndm_metric(types):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/metric/cnndm.py\n# --------------------------------------------------\n# \n# \n# def load_cnndm_metrics(ctx, **kwargs):\n#     tmp_dir = os.path.join(ctx.cfg.outdir, 'temp')\n#     rouges = test_rouge(tmp_dir, ctx.pred_path, ctx.tgt_path)\n#     results = {\n#         k: v\n#         for k, v in rouges.items()\n#         if k in {'rouge_1_f_score', 'rouge_2_f_score', 'rouge_l_f_score'}\n#     }\n#     return results\n# \n# \n# def call_cnndm_metric(types):\n#     if 'cnndm' in types:\n#         the_larger_the_better = True\n#         return 'cnndm', load_cnndm_metrics, the_larger_the_better\n# \n# \n# register_metric('cnndm', call_cnndm_metric)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport logging\nimport os\nfrom federatedscope.register import register_metric\nfrom federatedscope.nlp.metric.rouge.utils import test_rouge\nfrom federatedscope.nlp.metric.eval import eval\n\nlogger = logging.getLogger(__name__)\n\n\ndef load_msqg_metrics(ctx, **kwargs):\n    tmp_dir = os.path.join(ctx.cfg.outdir, 'temp')\n    rouges = test_rouge(tmp_dir, ctx.pred_path, ctx.tgt_path)\n    qg_res = eval(ctx.pred_path, ctx.src_path, ctx.tgt_path)  # bleu & meteor\n\n    results = rouges\n    results.update(qg_res)\n    results = {\n        k: v\n        for k, v in results.items()\n        if k in {'rouge_l_f_score', 'Bleu_4', 'METEOR'}\n    }", "choices": [{"text": "return results"}], "metadata": {"task_id": "alibaba_FederatedScope/7", "ground_truth": "    return results", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "metric", "msqg.py"], "context_start_lineno": 0, "line_no": 21, "query_window": {"context": "import os\nfrom federatedscope.register import register_metric\nfrom federatedscope.nlp.metric.rouge.utils import test_rouge\nfrom federatedscope.nlp.metric.eval import eval\n\nlogger = logging.getLogger(__name__)\n\n\ndef load_msqg_metrics(ctx, **kwargs):\n    tmp_dir = os.path.join(ctx.cfg.outdir, 'temp')\n    rouges = test_rouge(tmp_dir, ctx.pred_path, ctx.tgt_path)\n    qg_res = eval(ctx.pred_path, ctx.src_path, ctx.tgt_path)  # bleu & meteor\n\n    results = rouges\n    results.update(qg_res)\n    results = {\n        k: v\n        for k, v in results.items()\n        if k in {'rouge_l_f_score', 'Bleu_4', 'METEOR'}\n    }", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "metric", "msqg.py"], "line_no": 21, "task_id": "alibaba_FederatedScope/7", "start_line_no": 1, "end_line_no": 21, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "import logging\nimport os\nfrom federatedscope.register import register_metric\nfrom federatedscope.nlp.metric.rouge.utils import test_rouge\n\nlogger = logging.getLogger(__name__)\n\n\ndef load_cnndm_metrics(ctx, **kwargs):\n    tmp_dir = os.path.join(ctx.cfg.outdir, 'temp')\n    rouges = test_rouge(tmp_dir, ctx.pred_path, ctx.tgt_path)\n    results = {\n        k: v\n        for k, v in rouges.items()\n        if k in {'rouge_1_f_score', 'rouge_2_f_score', 'rouge_l_f_score'}\n    }\n    return results\n\n\ndef call_cnndm_metric(types):", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "metric", "cnndm.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.7307692307692307}, {"context": "import logging\nimport os\nfrom federatedscope.register import register_metric\nfrom federatedscope.nlp.metric.rouge.utils import test_rouge\n\nlogger = logging.getLogger(__name__)\n\n\ndef load_cnndm_metrics(ctx, **kwargs):\n    tmp_dir = os.path.join(ctx.cfg.outdir, 'temp')", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "metric", "cnndm.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.5050505050505051}, {"context": "    rouges = test_rouge(tmp_dir, ctx.pred_path, ctx.tgt_path)\n    results = {\n        k: v\n        for k, v in rouges.items()\n        if k in {'rouge_1_f_score', 'rouge_2_f_score', 'rouge_l_f_score'}\n    }\n    return results\n\n\ndef call_cnndm_metric(types):\n    if 'cnndm' in types:\n        the_larger_the_better = True\n        return 'cnndm', load_cnndm_metrics, the_larger_the_better\n\n\nregister_metric('cnndm', call_cnndm_metric)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "metric", "cnndm.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 26, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.42857142857142855}, {"context": "import os\nimport os.path as osp\nimport logging\nimport torch\nimport numpy as np\nfrom federatedscope.nlp.hetero_tasks.dataset.utils import split_sent, \\\n    DatasetDict, NUM_DEBUG\n\nlogger = logging.getLogger(__name__)\n\n\ndef get_msqg_examples(data, is_debug=False):\n    if is_debug:\n        data = data[:NUM_DEBUG]\n    src_examples, tgt_examples = [], []\n    for ex in data:\n        src_examples.append(ex['src'])\n        tgt_examples.append(ex['tgt'])\n    return src_examples, tgt_examples\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "msqg.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2949640287769784}, {"context": "from federatedscope.register import register_metric\nfrom federatedscope.nlp.hetero_tasks.metric.squad import compute_squad_metrics\n\n\ndef load_newsqa_metrics(ctx, **kwargs):\n    examples = ctx.get('{}_examples'.format(ctx.cur_split))\n    encoded_inputs = ctx.get('{}_encoded'.format(ctx.cur_split))\n    results = ctx.newsqa_results\n    n_best_size = ctx.cfg.model.n_best_size\n    max_answer_len = ctx.cfg.model.max_answer_len\n    null_score_diff_threshold = ctx.cfg.model.null_score_diff_threshold\n\n    metrics = compute_squad_metrics(examples, encoded_inputs, results,\n                                    n_best_size, max_answer_len,\n                                    null_score_diff_threshold)\n    return metrics\n\n\ndef call_newsqa_metric(types):\n    if 'newsqa' in types:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "metric", "newsqa.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2907801418439716}, {"context": "import os\nimport logging\nimport copy\nfrom tqdm import tqdm\n\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nlogger = logging.getLogger(__name__)\n\n\ndef modified_cfg(cfg, cfg_client):\n\n    # create the temp dir for output\n    tmp_dir = os.path.join(cfg.outdir, 'temp')\n    os.makedirs(tmp_dir, exist_ok=True)\n\n    if cfg.federate.save_to:\n        cfg.federate.save_to = os.path.join(cfg.outdir, cfg.federate.save_to)\n        os.makedirs(cfg.federate.save_to, exist_ok=True)\n\n    # modification for debug (load a small subset from the whole dataset)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataloader", "dataloader.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2867132867132867}, {"context": "from federatedscope.register import register_metric\n\nMETRIC_NAME = 'example'\n\n\ndef MyMetric(ctx, **kwargs):\n    return ctx.num_train_data\n\n\ndef call_my_metric(types):\n    if METRIC_NAME in types:\n        the_larger_the_better = True\n        metric_builder = MyMetric\n        return METRIC_NAME, metric_builder, the_larger_the_better\n\n\nregister_metric(METRIC_NAME, call_my_metric)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "contrib", "metrics", "example.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 17, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2796610169491525}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/schedulers/scheduling_ddpm.py\n# --------------------------------------------------\n#         beta_prod_t = 1 - alpha_prod_t\n#         beta_prod_t_prev = 1 - alpha_prod_t_prev\n# \n#         # 2. compute predicted original sample from predicted noise also called\n#         # \"predicted x_0\" of formula (15) from https://arxiv.org/pdf/2006.11239.pdf\n#         if self.config.prediction_type == \"epsilon\":\n#             pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)\n#         elif self.config.prediction_type == \"sample\":\n#             pred_original_sample = model_output\n#         elif self.config.prediction_type == \"v_prediction\":\n#             pred_original_sample = (alpha_prod_t**0.5) * sample - (beta_prod_t**0.5) * model_output\n#         else:\n#             raise ValueError(\n#                 f\"prediction_type given as {self.config.prediction_type} must be one of `epsilon`, `sample` or\"\n#                 \" `v_prediction`  for the DDPMScheduler.\"\n#             )\n# \n#         # 3. Clip \"predicted x_0\"\n#         if self.config.clip_sample:\n#             pred_original_sample = torch.clamp(pred_original_sample, -1, 1)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/schedulers/scheduling_ddpm.py\n# --------------------------------------------------\n# \n#         # 4. Compute coefficients for pred_original_sample x_0 and current sample x_t\n#         # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n#         pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * self.betas[t]) / beta_prod_t\n#         current_sample_coeff = self.alphas[t] ** (0.5) * beta_prod_t_prev / beta_prod_t\n# \n#         # 5. Compute predicted previous sample \u00b5_t\n#         # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n#         pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n# \n#         # 6. Add noise\n#         variance = 0\n#         if t > 0:\n#             device = model_output.device\n#             variance_noise = randn_tensor(\n#                 model_output.shape, generator=generator, device=device, dtype=model_output.dtype\n#             )\n#             if self.variance_type == \"fixed_small_log\":\n#                 variance = self._get_variance(t, predicted_variance=predicted_variance) * variance_noise\n#             else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/bit_diffusion.py\n# --------------------------------------------------\n#     current_sample_coeff = self.alphas[t] ** (0.5) * beta_prod_t_prev / beta_prod_t\n# \n#     # 5. Compute predicted previous sample \u00b5_t\n#     # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n#     pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n# \n#     # 6. Add noise\n#     variance = 0\n#     if t > 0:\n#         noise = torch.randn(\n#             model_output.size(), dtype=model_output.dtype, layout=model_output.layout, generator=generator\n#         ).to(model_output.device)\n#         variance = (self._get_variance(t, predicted_variance=predicted_variance) ** 0.5) * noise\n# \n#     pred_prev_sample = pred_prev_sample + variance\n# \n#     if not return_dict:\n#         return (pred_prev_sample,)\n# \n#     return DDPMSchedulerOutput(prev_sample=pred_prev_sample, pred_original_sample=pred_original_sample)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/bit_diffusion.py\n# --------------------------------------------------\n#             model_output.size(), dtype=model_output.dtype, layout=model_output.layout, generator=generator\n#         ).to(model_output.device)\n#         variance = (self._get_variance(t, predicted_variance=predicted_variance) ** 0.5) * noise\n# \n#     pred_prev_sample = pred_prev_sample + variance\n# \n#     if not return_dict:\n#         return (pred_prev_sample,)\n# \n#     return DDPMSchedulerOutput(prev_sample=pred_prev_sample, pred_original_sample=pred_original_sample)\n# \n# \n# class BitDiffusion(DiffusionPipeline):\n#     def __init__(\n#         self,\n#         unet: UNet2DConditionModel,\n#         scheduler: Union[DDIMScheduler, DDPMScheduler],\n#         bit_scale: Optional[float] = 1.0,\n#     ):\n#         super().__init__()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/schedulers/scheduling_unclip.py\n# --------------------------------------------------\n# \n#         # 6. Add noise\n#         variance = 0\n#         if t > 0:\n#             variance_noise = randn_tensor(\n#                 model_output.shape, dtype=model_output.dtype, generator=generator, device=model_output.device\n#             )\n# \n#             variance = self._get_variance(\n#                 t,\n#                 predicted_variance=predicted_variance,\n#                 prev_timestep=prev_timestep,\n#             )\n# \n#             if self.variance_type == \"fixed_small_log\":\n#                 variance = variance\n#             elif self.variance_type == \"learned_range\":\n#                 variance = (0.5 * variance).exp()\n#             else:\n#                 raise ValueError(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/schedulers/scheduling_ddpm.py\n# --------------------------------------------------\n#         # 6. Add noise\n#         variance = 0\n#         if t > 0:\n#             device = model_output.device\n#             variance_noise = randn_tensor(\n#                 model_output.shape, generator=generator, device=device, dtype=model_output.dtype\n#             )\n#             if self.variance_type == \"fixed_small_log\":\n#                 variance = self._get_variance(t, predicted_variance=predicted_variance) * variance_noise\n#             else:\n#                 variance = (self._get_variance(t, predicted_variance=predicted_variance) ** 0.5) * variance_noise\n# \n#         pred_prev_sample = pred_prev_sample + variance\n# \n#         if not return_dict:\n#             return (pred_prev_sample,)\n# \n#         return DDPMSchedulerOutput(prev_sample=pred_prev_sample, pred_original_sample=pred_original_sample)\n# \n#     def add_noise(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\n\n    def set_timesteps(\n        self, state: DDPMSchedulerState, num_inference_steps: int, shape: Tuple = ()\n    ) -> DDPMSchedulerState:\n        \"\"\"\n        Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference.\n\n        Args:\n            state (`DDIMSchedulerState`):\n                the `FlaxDDPMScheduler` state data class instance.\n            num_inference_steps (`int`):\n                the number of diffusion steps used when generating samples with a pre-trained model.\n        \"\"\"\n\n        step_ratio = self.config.num_train_timesteps // num_inference_steps\n        # creates integer timesteps by multiplying by ratio\n        # rounding to avoid issues when num_inference_step is power of 3\n        timesteps = (jnp.arange(0, num_inference_steps) * step_ratio).round()[::-1]\n\n        return state.replace(\n            num_inference_steps=num_inference_steps,\n            timesteps=timesteps,\n        )\n\n    def _get_variance(self, state: DDPMSchedulerState, t, predicted_variance=None, variance_type=None):\n        alpha_prod_t = state.common.alphas_cumprod[t]\n        alpha_prod_t_prev = jnp.where(t > 0, state.common.alphas_cumprod[t - 1], jnp.array(1.0, dtype=self.dtype))\n\n        # For t > 0, compute predicted variance \u03b2t (see formula (6) and (7) from https://arxiv.org/pdf/2006.11239.pdf)\n        # and sample from it to get previous sample\n        # x_{t-1} ~ N(pred_prev_sample, variance) == add variance to pred_sample\n        variance = (1 - alpha_prod_t_prev) / (1 - alpha_prod_t) * state.common.betas[t]\n\n        if variance_type is None:\n            variance_type = self.config.variance_type\n\n        # hacks - were probably added for training stability\n        if variance_type == \"fixed_small\":\n            variance = jnp.clip(variance, a_min=1e-20)\n        # for rl-diffuser https://arxiv.org/abs/2205.09991\n        elif variance_type == \"fixed_small_log\":\n            variance = jnp.log(jnp.clip(variance, a_min=1e-20))\n        elif variance_type == \"fixed_large\":\n            variance = state.common.betas[t]\n        elif variance_type == \"fixed_large_log\":\n            # Glide max_log\n            variance = jnp.log(state.common.betas[t])\n        elif variance_type == \"learned\":\n            return predicted_variance\n        elif variance_type == \"learned_range\":\n            min_log = variance\n            max_log = state.common.betas[t]\n            frac = (predicted_variance + 1) / 2\n            variance = frac * max_log + (1 - frac) * min_log\n\n        return variance\n\n    def step(\n        self,\n        state: DDPMSchedulerState,\n        model_output: jnp.ndarray,\n        timestep: int,\n        sample: jnp.ndarray,\n        key: jax.random.KeyArray,\n        return_dict: bool = True,\n    ) -> Union[FlaxDDPMSchedulerOutput, Tuple]:\n        \"\"\"\n        Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion\n        process from the learned model outputs (most often the predicted noise).\n\n        Args:\n            state (`DDPMSchedulerState`): the `FlaxDDPMScheduler` state data class instance.\n            model_output (`jnp.ndarray`): direct output from learned diffusion model.\n            timestep (`int`): current discrete timestep in the diffusion chain.\n            sample (`jnp.ndarray`):\n                current instance of sample being created by diffusion process.\n            key (`jax.random.KeyArray`): a PRNG key.\n            return_dict (`bool`): option for returning tuple rather than FlaxDDPMSchedulerOutput class\n\n        Returns:\n            [`FlaxDDPMSchedulerOutput`] or `tuple`: [`FlaxDDPMSchedulerOutput`] if `return_dict` is True, otherwise a\n            `tuple`. When returning a tuple, the first element is the sample tensor.\n\n        \"\"\"\n        t = timestep\n\n        if model_output.shape[1] == sample.shape[1] * 2 and self.config.variance_type in [\"learned\", \"learned_range\"]:\n            model_output, predicted_variance = jnp.split(model_output, sample.shape[1], axis=1)\n        else:\n            predicted_variance = None\n\n        # 1. compute alphas, betas\n        alpha_prod_t = state.common.alphas_cumprod[t]\n        alpha_prod_t_prev = jnp.where(t > 0, state.common.alphas_cumprod[t - 1], jnp.array(1.0, dtype=self.dtype))\n        beta_prod_t = 1 - alpha_prod_t\n        beta_prod_t_prev = 1 - alpha_prod_t_prev\n\n        # 2. compute predicted original sample from predicted noise also called\n        # \"predicted x_0\" of formula (15) from https://arxiv.org/pdf/2006.11239.pdf\n        if self.config.prediction_type == \"epsilon\":\n            pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)\n        elif self.config.prediction_type == \"sample\":\n            pred_original_sample = model_output\n        elif self.config.prediction_type == \"v_prediction\":\n            pred_original_sample = (alpha_prod_t**0.5) * sample - (beta_prod_t**0.5) * model_output\n        else:\n            raise ValueError(\n                f\"prediction_type given as {self.config.prediction_type} must be one of `epsilon`, `sample` \"\n                \" for the FlaxDDPMScheduler.\"\n            )\n\n        # 3. Clip \"predicted x_0\"\n        if self.config.clip_sample:\n            pred_original_sample = jnp.clip(pred_original_sample, -1, 1)\n\n        # 4. Compute coefficients for pred_original_sample x_0 and current sample x_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * state.common.betas[t]) / beta_prod_t\n        current_sample_coeff = state.common.alphas[t] ** (0.5) * beta_prod_t_prev / beta_prod_t\n\n        # 5. Compute predicted previous sample \u00b5_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n\n        # 6. Add noise\n        def random_variance():\n            split_key = jax.random.split(key, num=1)\n            noise = jax.random.normal(split_key, shape=model_output.shape, dtype=self.dtype)\n            return (self._get_variance(state, t, predicted_variance=predicted_variance) ** 0.5) * noise\n\n        variance = jnp.where(t > 0, random_variance(), jnp.zeros(model_output.shape, dtype=self.dtype))\n\n        pred_prev_sample = pred_prev_sample + variance\n\n        if not return_dict:", "choices": [{"text": "return (pred_prev_sample,)"}], "metadata": {"task_id": "huggingface_diffusers/40", "ground_truth": "            return (pred_prev_sample, state)", "fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "schedulers", "scheduling_ddpm_flax.py"], "context_start_lineno": 136, "line_no": 272, "query_window": {"context": "        # 4. Compute coefficients for pred_original_sample x_0 and current sample x_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * state.common.betas[t]) / beta_prod_t\n        current_sample_coeff = state.common.alphas[t] ** (0.5) * beta_prod_t_prev / beta_prod_t\n\n        # 5. Compute predicted previous sample \u00b5_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n\n        # 6. Add noise\n        def random_variance():\n            split_key = jax.random.split(key, num=1)\n            noise = jax.random.normal(split_key, shape=model_output.shape, dtype=self.dtype)\n            return (self._get_variance(state, t, predicted_variance=predicted_variance) ** 0.5) * noise\n\n        variance = jnp.where(t > 0, random_variance(), jnp.zeros(model_output.shape, dtype=self.dtype))\n\n        pred_prev_sample = pred_prev_sample + variance\n\n        if not return_dict:", "metadata": {"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "schedulers", "scheduling_ddpm_flax.py"], "line_no": 272, "task_id": "huggingface_diffusers/40", "start_line_no": 252, "end_line_no": 272, "window_size": 20, "context_start_lineno": 136, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "\n        # 4. Compute coefficients for pred_original_sample x_0 and current sample x_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * self.betas[t]) / beta_prod_t\n        current_sample_coeff = self.alphas[t] ** (0.5) * beta_prod_t_prev / beta_prod_t\n\n        # 5. Compute predicted previous sample \u00b5_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n\n        # 6. Add noise\n        variance = 0\n        if t > 0:\n            device = model_output.device\n            variance_noise = randn_tensor(\n                model_output.shape, generator=generator, device=device, dtype=model_output.dtype\n            )\n            if self.variance_type == \"fixed_small_log\":\n                variance = self._get_variance(t, predicted_variance=predicted_variance) * variance_noise\n            else:", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "schedulers", "scheduling_ddpm.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6439393939393939}, {"context": "            )\n\n        # 4. Compute coefficients for pred_original_sample x_0 and current sample x_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * beta) / beta_prod_t\n        current_sample_coeff = alpha ** (0.5) * beta_prod_t_prev / beta_prod_t\n\n        # 5. Compute predicted previous sample \u00b5_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n\n        # 6. Add noise\n        variance = 0\n        if t > 0:\n            variance_noise = randn_tensor(\n                model_output.shape, dtype=model_output.dtype, generator=generator, device=model_output.device\n            )\n\n            variance = self._get_variance(\n                t,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "schedulers", "scheduling_unclip.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6031746031746031}, {"context": "    current_sample_coeff = self.alphas[t] ** (0.5) * beta_prod_t_prev / beta_prod_t\n\n    # 5. Compute predicted previous sample \u00b5_t\n    # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n    pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n\n    # 6. Add noise\n    variance = 0\n    if t > 0:\n        noise = torch.randn(\n            model_output.size(), dtype=model_output.dtype, layout=model_output.layout, generator=generator\n        ).to(model_output.device)\n        variance = (self._get_variance(t, predicted_variance=predicted_variance) ** 0.5) * noise\n\n    pred_prev_sample = pred_prev_sample + variance\n\n    if not return_dict:\n        return (pred_prev_sample,)\n\n    return DDPMSchedulerOutput(prev_sample=pred_prev_sample, pred_original_sample=pred_original_sample)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "bit_diffusion.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6015037593984962}, {"context": "        raise ValueError(f\"Unsupported prediction_type {prediction_type}.\")\n\n    # 3. Clip \"predicted x_0\"\n    scale = self.bit_scale\n    if self.config.clip_sample:\n        pred_original_sample = torch.clamp(pred_original_sample, -scale, scale)\n\n    # 4. Compute coefficients for pred_original_sample x_0 and current sample x_t\n    # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n    pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * self.betas[t]) / beta_prod_t\n    current_sample_coeff = self.alphas[t] ** (0.5) * beta_prod_t_prev / beta_prod_t\n\n    # 5. Compute predicted previous sample \u00b5_t\n    # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n    pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n\n    # 6. Add noise\n    variance = 0\n    if t > 0:\n        noise = torch.randn(", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "bit_diffusion.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.539568345323741}, {"context": "            pred_original_sample = (alpha_prod_t**0.5) * sample - (beta_prod_t**0.5) * model_output\n        else:\n            raise ValueError(\n                f\"prediction_type given as {self.config.prediction_type} must be one of `epsilon`, `sample` or\"\n                \" `v_prediction`  for the DDPMScheduler.\"\n            )\n\n        # 3. Clip \"predicted x_0\"\n        if self.config.clip_sample:\n            pred_original_sample = torch.clamp(pred_original_sample, -1, 1)\n\n        # 4. Compute coefficients for pred_original_sample x_0 and current sample x_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_original_sample_coeff = (alpha_prod_t_prev ** (0.5) * self.betas[t]) / beta_prod_t\n        current_sample_coeff = self.alphas[t] ** (0.5) * beta_prod_t_prev / beta_prod_t\n\n        # 5. Compute predicted previous sample \u00b5_t\n        # See formula (7) from https://arxiv.org/pdf/2006.11239.pdf\n        pred_prev_sample = pred_original_sample_coeff * pred_original_sample + current_sample_coeff * sample\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "schedulers", "scheduling_ddpm.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.45569620253164556}, {"context": "        t = timestep\n\n        if model_output.shape[1] == sample.shape[1] * 2 and self.variance_type in [\"learned\", \"learned_range\"]:\n            model_output, predicted_variance = torch.split(model_output, sample.shape[1], dim=1)\n        else:\n            predicted_variance = None\n\n        # 1. compute alphas, betas\n        alpha_prod_t = self.alphas_cumprod[t]\n        alpha_prod_t_prev = self.alphas_cumprod[t - 1] if t > 0 else self.one\n        beta_prod_t = 1 - alpha_prod_t\n        beta_prod_t_prev = 1 - alpha_prod_t_prev\n\n        # 2. compute predicted original sample from predicted noise also called\n        # \"predicted x_0\" of formula (15) from https://arxiv.org/pdf/2006.11239.pdf\n        if self.config.prediction_type == \"epsilon\":\n            pred_original_sample = (sample - beta_prod_t ** (0.5) * model_output) / alpha_prod_t ** (0.5)\n        elif self.config.prediction_type == \"sample\":\n            pred_original_sample = model_output\n        elif self.config.prediction_type == \"v_prediction\":", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "schedulers", "scheduling_ddpm.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4129032258064516}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/replay_buffer/base_buffer.py\n# --------------------------------------------------\n#     Overview:\n#         Buffer interface\n#     Interfaces:\n#         default_config, push, update, sample, clear, count, state_dict, load_state_dict\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls) -> EasyDict:\n#         r\"\"\"\n#         Overview:\n#             Default config of this buffer class.\n#         Returns:\n#             - default_config (:obj:`EasyDict`)\n#         \"\"\"\n#         cfg = EasyDict(copy.deepcopy(cls.config))\n#         cfg.cfg_type = cls.__name__ + 'Dict'\n#         return cfg\n# \n#     @abstractmethod\n#     def push(self, data: Union[List[Any], Any], cur_collector_envstep: int) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/learner/base_learner.py\n# --------------------------------------------------\n# from ding.utils.autolog import LoggedValue, LoggedModel, TickTime\n# from ding.utils.data import AsyncDataLoader\n# from .learner_hook import build_learner_hook_by_cfg, add_learner_hook, merge_hooks, LearnerHook\n# logging.info('')  # necessary\n# \n# \n# @LEARNER_REGISTRY.register('base')\n# class BaseLearner(object):\n#     r\"\"\"\n#     Overview:\n#         Base class for policy learning.\n#     Interface:\n#         train, call_hook, register_hook, save_checkpoint, start, setup_dataloader, close\n#     Property:\n#         learn_info, priority_info, last_iter, train_iter, rank, world_size, policy\n#         monitor, log_buffer, logger, tb_logger, ckpt_name, exp_name, instance_name\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls: type) -> EasyDict:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/replay_buffer/base_buffer.py\n# --------------------------------------------------\n# from typing import Union, Dict, Any, List\n# from abc import ABC, abstractmethod\n# import copy\n# from easydict import EasyDict\n# \n# from ding.utils import import_module, BUFFER_REGISTRY\n# \n# \n# class IBuffer(ABC):\n#     r\"\"\"\n#     Overview:\n#         Buffer interface\n#     Interfaces:\n#         default_config, push, update, sample, clear, count, state_dict, load_state_dict\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls) -> EasyDict:\n#         r\"\"\"\n#         Overview:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/log_helper.py\n# --------------------------------------------------\n# def build_logger(\n#     path: str,\n#     name: Optional[str] = None,\n#     need_tb: bool = True,\n#     need_text: bool = True,\n#     text_level: Union[int, str] = logging.INFO\n# ) -> Tuple[Optional[logging.Logger], Optional['SummaryWriter']]:  # noqa\n#     r'''\n#     Overview:\n#         Build text logger and tensorboard logger.\n#     Arguments:\n#         - path (:obj:`str`): Logger(``Textlogger`` & ``SummaryWriter``)'s saved dir\n#         - name (:obj:`str`): The logger file name\n#         - need_tb (:obj:`bool`): Whether ``SummaryWriter`` instance would be created and returned\n#         - need_text (:obj:`bool`): Whether ``loggingLogger`` instance would be created and returned\n#         - text_level (:obj:`int`` or :obj:`str`): Logging level of ``logging.Logger``, default set to ``logging.INFO``\n#     Returns:\n#         - logger (:obj:`Optional[logging.Logger]`): Logger that displays terminal output\n#         - tb_logger (:obj:`Optional['SummaryWriter']`): Saves output to tfboard, only return when ``need_tb``.\n#     '''\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/replay_buffer/utils.py\n# --------------------------------------------------\n# \n# def generate_id(name, data_id: int) -> str:\n#     \"\"\"\n#     Overview:\n#         Use ``self.name`` and input ``id`` to generate a unique id for next data to be inserted.\n#     Arguments:\n#         - data_id (:obj:`int`): Current unique id.\n#     Returns:\n#         - id (:obj:`str`): Id in format \"BufferName_DataId\".\n#     \"\"\"\n#     return \"{}_{}\".format(name, str(data_id))\n# \n# \n# class UsedDataRemover:\n#     \"\"\"\n#     Overview:\n#         UsedDataRemover is a tool to remove file datas that will no longer be used anymore.\n#     Interface:\n#         start, close, add_used_data\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/replay_buffer/naive_buffer.py\n# --------------------------------------------------\n# @BUFFER_REGISTRY.register('naive')\n# class NaiveReplayBuffer(IBuffer):\n#     r\"\"\"\n#     Overview:\n#         Naive replay buffer, can store and sample data.\n#         An naive implementation of replay buffer with no priority or any other advanced features.\n#         This buffer refers to multi-thread/multi-process and guarantees thread-safe, which means that methods like\n#         ``sample``, ``push``, ``clear`` are all mutual to each other.\n#     Interface:\n#         start, close, push, update, sample, clear, count, state_dict, load_state_dict, default_config\n#     Property:\n#         replay_buffer_size, push_count\n#     \"\"\"\n# \n#     config = dict(\n#         type='naive',\n#         replay_buffer_size=10000,\n#         deepcopy=False,\n#         # default `False` for serial pipeline\n#         enable_track_used_data=False,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/replay_buffer/naive_buffer.py\n# --------------------------------------------------\n# import copy\n# from typing import Union, Any, Optional, List\n# import numpy as np\n# from easydict import EasyDict\n# \n# from ding.worker.replay_buffer import IBuffer\n# from ding.utils import LockContext, LockContextType, BUFFER_REGISTRY, build_logger\n# from .utils import UsedDataRemover, PeriodicThruputMonitor\n# \n# \n# @BUFFER_REGISTRY.register('naive')\n# class NaiveReplayBuffer(IBuffer):\n#     r\"\"\"\n#     Overview:\n#         Naive replay buffer, can store and sample data.\n#         An naive implementation of replay buffer with no priority or any other advanced features.\n#         This buffer refers to multi-thread/multi-process and guarantees thread-safe, which means that methods like\n#         ``sample``, ``push``, ``clear`` are all mutual to each other.\n#     Interface:\n#         start, close, push, update, sample, clear, count, state_dict, load_state_dict, default_config\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport copy\nimport time\nfrom typing import Union, NoReturn, Any, Optional, List, Dict, Tuple\nimport numpy as np\n\nfrom ding.worker.replay_buffer import IBuffer\nfrom ding.utils import SumSegmentTree, MinSegmentTree, BUFFER_REGISTRY\nfrom ding.utils import LockContext, LockContextType, build_logger\nfrom ding.utils.autolog import TickTime\nfrom .utils import UsedDataRemover, generate_id, SampledDataAttrMonitor, PeriodicThruputMonitor, ThruputController\n\n\ndef to_positive_index(idx: Union[int, None], size: int) -> int:\n    if idx is None or idx >= 0:\n        return idx\n    else:", "choices": [{"text": "return size + idx"}], "metadata": {"task_id": "opendilab_ACE/89", "ground_truth": "        return size + idx", "fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "advanced_buffer.py"], "context_start_lineno": 0, "line_no": 16, "query_window": {"context": "import copy\nimport time\nfrom typing import Union, NoReturn, Any, Optional, List, Dict, Tuple\nimport numpy as np\n\nfrom ding.worker.replay_buffer import IBuffer\nfrom ding.utils import SumSegmentTree, MinSegmentTree, BUFFER_REGISTRY\nfrom ding.utils import LockContext, LockContextType, build_logger\nfrom ding.utils.autolog import TickTime\nfrom .utils import UsedDataRemover, generate_id, SampledDataAttrMonitor, PeriodicThruputMonitor, ThruputController\n\n\ndef to_positive_index(idx: Union[int, None], size: int) -> int:\n    if idx is None or idx >= 0:\n        return idx\n    else:", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "advanced_buffer.py"], "line_no": 16, "task_id": "opendilab_ACE/89", "start_line_no": 0, "end_line_no": 16, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "import copy\nfrom typing import Union, Any, Optional, List\nimport numpy as np\nfrom easydict import EasyDict\n\nfrom ding.worker.replay_buffer import IBuffer\nfrom ding.utils import LockContext, LockContextType, BUFFER_REGISTRY, build_logger\nfrom .utils import UsedDataRemover, PeriodicThruputMonitor\n\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "naive_buffer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.48514851485148514}, {"context": "import copy\nfrom typing import Union, Any, Optional, List\nimport numpy as np\nfrom easydict import EasyDict\n\nfrom ding.worker.replay_buffer import IBuffer\nfrom ding.utils import LockContext, LockContextType, BUFFER_REGISTRY, build_logger\nfrom .utils import UsedDataRemover, PeriodicThruputMonitor\n\n\n@BUFFER_REGISTRY.register('naive')\nclass NaiveReplayBuffer(IBuffer):\n    r\"\"\"\n    Overview:\n        Naive replay buffer, can store and sample data.\n        An naive implementation of replay buffer with no priority or any other advanced features.\n        This buffer refers to multi-thread/multi-process and guarantees thread-safe, which means that methods like\n        ``sample``, ``push``, ``clear`` are all mutual to each other.\n    Interface:\n        start, close, push, update, sample, clear, count, state_dict, load_state_dict, default_config", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "naive_buffer.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.31976744186046513}, {"context": "from typing import Any\nimport time\nfrom queue import Queue\nfrom typing import Union, Tuple\nfrom threading import Thread\nfrom functools import partial\n\nfrom ding.utils.autolog import LoggedValue, LoggedModel\nfrom ding.utils import LockContext, LockContextType, remove_file\n\n\ndef generate_id(name, data_id: int) -> str:\n    \"\"\"\n    Overview:\n        Use ``self.name`` and input ``id`` to generate a unique id for next data to be inserted.\n    Arguments:\n        - data_id (:obj:`int`): Current unique id.\n    Returns:\n        - id (:obj:`str`): Id in format \"BufferName_DataId\".\n    \"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "utils.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2465753424657534}, {"context": "import json\nimport logging\nimport os\nimport numpy as np\nimport yaml\nfrom tabulate import tabulate\nfrom tensorboardX import SummaryWriter\nfrom typing import Optional, Tuple, Union, Dict, Any\n\n\ndef build_logger(\n    path: str,\n    name: Optional[str] = None,\n    need_tb: bool = True,\n    need_text: bool = True,\n    text_level: Union[int, str] = logging.INFO\n) -> Tuple[Optional[logging.Logger], Optional['SummaryWriter']]:  # noqa\n    r'''\n    Overview:\n        Build text logger and tensorboard logger.", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "log_helper.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.23776223776223776}, {"context": "from typing import Union, Dict, Any, List\nfrom abc import ABC, abstractmethod\nimport copy\nfrom easydict import EasyDict\n\nfrom ding.utils import import_module, BUFFER_REGISTRY\n\n\nclass IBuffer(ABC):\n    r\"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "base_buffer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.23214285714285715}, {"context": "from typing import Any, Union, Callable, List, Dict, Optional, Tuple\nimport time\nimport copy\nimport logging\nfrom functools import partial\nfrom easydict import EasyDict\nfrom collections import namedtuple\n\nfrom ding.torch_utils import CountVar, auto_checkpoint, build_log_buffer\nfrom ding.utils import build_logger, EasyTimer, import_module, LEARNER_REGISTRY, get_rank, get_world_size\nfrom ding.utils.autolog import LoggedValue, LoggedModel, TickTime\nfrom ding.utils.data import AsyncDataLoader\nfrom .learner_hook import build_learner_hook_by_cfg, add_learner_hook, merge_hooks, LearnerHook\nlogging.info('')  # necessary\n\n\n@LEARNER_REGISTRY.register('base')\nclass BaseLearner(object):\n    r\"\"\"\n    Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "learner", "base_learner.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.23030303030303031}, {"context": "from typing import Union, Dict, Any, List\nfrom abc import ABC, abstractmethod\nimport copy\nfrom easydict import EasyDict\n\nfrom ding.utils import import_module, BUFFER_REGISTRY\n\n\nclass IBuffer(ABC):\n    r\"\"\"\n    Overview:\n        Buffer interface\n    Interfaces:\n        default_config, push, update, sample, clear, count, state_dict, load_state_dict\n    \"\"\"\n\n    @classmethod\n    def default_config(cls) -> EasyDict:\n        r\"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "base_buffer.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.22727272727272727}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n# ###############################################################################\n# \n# # save results\n# torch.save(\n#     {\n#         \"frames\": frames,\n#         \"evals\": evals,\n#         \"mavgs\": mavgs,\n#         \"losses\": losses,\n#         \"values\": values,\n#         \"grad_vals\": grad_vals,\n#         \"traj_lengths_training\": traj_lengths,\n#         \"traj_count\": traj_count,\n#         \"weights\": (params,),\n#     },\n#     \"saved_results_td0.pt\",\n# )\n# \n# ###############################################################################\n# # TD-lambda\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb.py\n# --------------------------------------------------\n#     rb = TensorDictPrioritizedReplayBuffer(\n#         alpha=0.7,\n#         beta=0.9,\n#         priority_key=\"td_error\",\n#         storage=ListStorage(5),\n#     )\n#     rb.extend(traj_td)\n#     sampled_td = rb.sample(3)\n#     sampled_td.set(\"td_error\", torch.rand(3))\n#     rb.update_tensordict_priority(sampled_td)\n#     sampled_td = rb.sample(3, include_info=True)\n#     assert (sampled_td.get(\"_weight\") > 0).all()\n#     assert sampled_td.batch_size == torch.Size([3])\n# \n#     # set back the trajectory length\n#     sampled_td_filtered = sampled_td.to_tensordict().exclude(\n#         \"_weight\", \"index\", \"td_error\"\n#     )\n#     sampled_td_filtered.batch_size = [3, 4]\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#         \"grad_vals\": grad_vals,\n#         \"traj_lengths_training\": traj_lengths,\n#         \"traj_count\": traj_count,\n#         \"weights\": (params,),\n#     },\n#     \"saved_results_td0.pt\",\n# )\n# \n# ###############################################################################\n# # TD-lambda\n# # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n# # We can improve the above algorithm by getting a better estimate of the\n# # return, using not only the next state value but the whole sequence of rewards\n# # and values that follow a particular step.\n# #\n# # TorchRL provides a vectorized version of TD(lambda) named\n# # ``vec_td_lambda_advantage_estimate``. We'll use this to obtain a target\n# # value that the value network will be trained to match.\n# #\n# # The big difference in this implementation is that we'll store entire\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#         if is_notebook():\n#             plt.show()\n# \n#     # update policy weights\n#     data_collector.update_policy_weights_()\n# \n# if is_notebook():\n#     display.clear_output(wait=True)\n#     display.display(plt.gcf())\n# \n# ###############################################################################\n# # **Note**: As already mentioned above, to get a more reasonable performance,\n# # use a greater value for ``total_frames`` e.g. 500000.\n# \n# \n# plt.figure(figsize=(15, 15))\n# plt.imshow(plt.imread(\"dqn_td0.png\"))\n# plt.tight_layout()\n# plt.axis(\"off\")\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#                 plt.clf()\n#             plt.figure(figsize=(15, 15))\n#             plt.subplot(3, 2, 1)\n#             plt.plot(frames[-len(evals) :], evals, label=\"return\")\n#             plt.plot(frames[-len(mavgs) :], mavgs, label=\"mavg\")\n#             plt.xlabel(\"frames collected\")\n#             plt.ylabel(\"trajectory length (= return)\")\n#             plt.subplot(3, 2, 2)\n#             plt.plot(traj_count[-len(evals) :], evals, label=\"return\")\n#             plt.plot(traj_count[-len(mavgs) :], mavgs, label=\"mavg\")\n#             plt.xlabel(\"trajectories collected\")\n#             plt.legend()\n#             plt.subplot(3, 2, 3)\n#             plt.plot(frames[-len(losses) :], losses)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"loss\")\n#             plt.subplot(3, 2, 4)\n#             plt.plot(frames[-len(values) :], values)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"value\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#             plt.subplot(3, 2, 5)\n#             plt.plot(frames[-len(grad_vals) :], grad_vals)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"grad norm\")\n#             if len(traj_lengths):\n#                 plt.subplot(3, 2, 6)\n#                 plt.plot(traj_lengths)\n#                 plt.xlabel(\"batches\")\n#                 plt.title(\"traj length (training)\")\n#         plt.savefig(\"dqn_td0.png\")\n#         if is_notebook():\n#             plt.show()\n# \n#     # update policy weights\n#     data_collector.update_policy_weights_()\n# \n# if is_notebook():\n#     display.clear_output(wait=True)\n#     display.display(plt.gcf())\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#             plt.xlabel(\"trajectories collected\")\n#             plt.legend()\n#             plt.subplot(3, 2, 3)\n#             plt.plot(frames[-len(losses) :], losses)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"loss\")\n#             plt.subplot(3, 2, 4)\n#             plt.plot(frames[-len(values) :], values)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"value\")\n#             plt.subplot(3, 2, 5)\n#             plt.plot(frames[-len(grad_vals) :], grad_vals)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"grad norm\")\n#             if len(traj_lengths):\n#                 plt.subplot(3, 2, 6)\n#                 plt.plot(traj_lengths)\n#                 plt.xlabel(\"batches\")\n#                 plt.title(\"traj length (training)\")\n#         plt.savefig(\"dqn_td0.png\")\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n(gv))\n        traj_lengths_eval.append(eval_rollout.shape[-1])\n        evals.append(eval_rollout[\"reward\"].squeeze(-1).sum(-1).item())\n        if len(mavgs):\n            mavgs.append(evals[-1] * 0.05 + mavgs[-1] * 0.95)\n        else:\n            mavgs.append(evals[-1])\n        losses.append(error.item())\n        values.append(action_value[mask].mean().item())\n        traj_count.append(prev_traj_count + data[\"done\"].sum().item())\n        prev_traj_count = traj_count[-1]\n        # plots\n        if j % 10 == 0:\n            if is_notebook():\n                display.clear_output(wait=True)\n                display.display(plt.gcf())\n            else:\n                plt.clf()\n            plt.figure(figsize=(15, 15))\n            plt.subplot(3, 2, 1)\n            plt.plot(frames[-len(evals) :], evals, label=\"return\")\n            plt.plot(frames[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"frames collected\")\n            plt.ylabel(\"trajectory length (= return)\")\n            plt.subplot(3, 2, 2)\n            plt.plot(traj_count[-len(evals) :], evals, label=\"return\")\n            plt.plot(traj_count[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"trajectories collected\")\n            plt.legend()\n            plt.subplot(3, 2, 3)\n            plt.plot(frames[-len(losses) :], losses)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"loss\")\n            plt.subplot(3, 2, 4)\n            plt.plot(frames[-len(values) :], values)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"value\")\n            plt.subplot(3, 2, 5)\n            plt.plot(frames[-len(grad_vals) :], grad_vals)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"grad norm\")\n            if len(traj_lengths):\n                plt.subplot(3, 2, 6)\n                plt.plot(traj_lengths)\n                plt.xlabel(\"batches\")\n                plt.title(\"traj length (training)\")\n        plt.savefig(\"dqn_tdlambda.png\")\n        if is_notebook():\n            plt.show()\n\n    # update policy weights\n    data_collector.update_policy_weights_()\n\nif is_notebook():\n    display.clear_output(wait=True)\n    display.display(plt.gcf())\n\n###############################################################################\n# **Note**: As already mentioned above, to get a more reasonable performance,\n# use a greater value for ``total_frames`` e.g. 500000.\n\nplt.figure(figsize=(15, 15))\nplt.imshow(plt.imread(\"dqn_tdlambda.png\"))\nplt.tight_layout()\nplt.axis(\"off\")\n\n###############################################################################\n\n# save results\ntorch.save(\n    {\n        \"frames\": frames,\n        \"evals\": evals,\n        \"mavgs\": mavgs,\n        \"losses\": losses,\n        \"values\": values,\n        \"grad_vals\": grad_vals,\n        \"traj_lengths_training\": traj_lengths,\n        \"traj_count\": traj_count,\n        \"weights\": (params,),\n    },\n    \"saved_results_tdlambda.pt\",\n)\n\n###############################################################################\n# Let's compare the results on a single plot. Because the TD(lambda) version\n# works better, we'll have fewer episodes collected for a given number of\n# frames (as there are more frames per episode).\n#\n# **Note**: As already mentioned above, to get a more reasonable performance,\n# use a greater value for ``total_frames`` e.g. 500000.\n\nload_td0 = torch.load(\"saved_results_td0.pt\")\nload_tdlambda = torch.load(\"saved_results_tdlambda.pt\")\nframes_td0 = load_td0[\"frames\"]\nframes_tdlambda = load_tdlambda[\"frames\"]\nevals_td0 = load_td0[\"evals\"]\nevals_tdlambda = load_tdlambda[\"evals\"]\nmavgs_td0 = load_td0[\"mavgs\"]\nmavgs_tdlambda = load_tdlambda[\"mavgs\"]\nlosses_td0 = load_td0[\"losses\"]\nlosses_tdlambda = load_tdlambda[\"losses\"]\nvalues_td0 = load_td0[\"values\"]\nvalues_tdlambda = load_tdlambda[\"values\"]\ngrad_vals_td0 = load_td0[\"grad_vals\"]\ngrad_vals_tdlambda = load_tdlambda[\"grad_vals\"]\ntraj_lengths_td0 = load_td0[\"traj_lengths_training\"]\ntraj_lengths_tdlambda = load_tdlambda[\"traj_lengths_training\"]\ntraj_count_td0 = load_td0[\"traj_count\"]\ntraj_count_tdlambda = load_tdlambda[\"traj_count\"]\n\nplt.figure(figsize=(15, 15))\nplt.subplot(3, 2, 1)\nplt.plot(frames[-len(evals_td0) :], evals_td0, label=\"return (td0)\", alpha=0.5)\nplt.plot(\n    frames[-len(evals_tdlambda) :],\n    evals_tdlambda,\n    label=\"return (td(lambda))\",\n    alpha=0.5,\n)\nplt.plot(frames[-len(mavgs_td0) :], mavgs_td0, label=\"mavg (td0)\")\nplt.plot(frames[-len(mavgs_tdlambda) :], mavgs_tdlambda, label=\"mavg (td(lambda))\")\nplt.xlabel(\"frames collected\")\nplt.ylabel(\"trajectory length (= return)\")\nplt.subplot(3, 2, 2)\nplt.plot(traj_count_td0[-len(evals_td0) :], evals_td0, label=\"return (td0)\", alpha=0.5)\nplt.plot(\n    traj_count_tdlambda[-len(evals_tdlambda) :],\n    evals_tdlambda,\n    label=\"return (td(lambda))\",\n    alpha=0.5,\n)\nplt.plot(traj_count_td0[-len(mavgs_td0) :], mavgs_td0, label=\"mavg (td0)\")\nplt.plot(\n    traj_count_tdlambda[-len(mavgs_tdlambda) :],\n    mavgs_tdlambda,\n    label=\"mavg (td(lambda))\",\n)\nplt.xlabel(\"trajectories collected\")\nplt.legend()\nplt.subplot(3, 2, 3)\nplt.plot(frames[-len(losses_td0) :], losses_td0, label=\"loss (td0)\")\nplt.plot(frames[-len(losses_tdlambda) :], losses_tdlambda, label=\"loss (td(lambda))\")\nplt.xlabel(\"frames collected\")\nplt.title(\"loss\")\nplt.legend()\nplt.subplot(3, 2, 4)\nplt.plot(frames[-len(values_td0) :], values_td0, label=\"values (td0)\")\nplt.plot(frames[-len(values_tdlambda) :], values_tdlambda, label=\"values (td(lambda))\")\nplt.xlabel(\"frames collected\")", "choices": [{"text": "plt.title(\"value\")"}], "metadata": {"task_id": "pytorch_rl/189", "ground_truth": "plt.title(\"value\")", "fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "context_start_lineno": 675, "line_no": 825, "query_window": {"context": "    alpha=0.5,\n)\nplt.plot(traj_count_td0[-len(mavgs_td0) :], mavgs_td0, label=\"mavg (td0)\")\nplt.plot(\n    traj_count_tdlambda[-len(mavgs_tdlambda) :],\n    mavgs_tdlambda,\n    label=\"mavg (td(lambda))\",\n)\nplt.xlabel(\"trajectories collected\")\nplt.legend()\nplt.subplot(3, 2, 3)\nplt.plot(frames[-len(losses_td0) :], losses_td0, label=\"loss (td0)\")\nplt.plot(frames[-len(losses_tdlambda) :], losses_tdlambda, label=\"loss (td(lambda))\")\nplt.xlabel(\"frames collected\")\nplt.title(\"loss\")\nplt.legend()\nplt.subplot(3, 2, 4)\nplt.plot(frames[-len(values_td0) :], values_td0, label=\"values (td0)\")\nplt.plot(frames[-len(values_tdlambda) :], values_tdlambda, label=\"values (td(lambda))\")\nplt.xlabel(\"frames collected\")", "metadata": {"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 825, "task_id": "pytorch_rl/189", "start_line_no": 805, "end_line_no": 825, "window_size": 20, "context_start_lineno": 675, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "                plt.clf()\n            plt.figure(figsize=(15, 15))\n            plt.subplot(3, 2, 1)\n            plt.plot(frames[-len(evals) :], evals, label=\"return\")\n            plt.plot(frames[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"frames collected\")\n            plt.ylabel(\"trajectory length (= return)\")\n            plt.subplot(3, 2, 2)\n            plt.plot(traj_count[-len(evals) :], evals, label=\"return\")\n            plt.plot(traj_count[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"trajectories collected\")\n            plt.legend()\n            plt.subplot(3, 2, 3)\n            plt.plot(frames[-len(losses) :], losses)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"loss\")\n            plt.subplot(3, 2, 4)\n            plt.plot(frames[-len(values) :], values)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"value\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.575}, {"context": "            plt.xlabel(\"trajectories collected\")\n            plt.legend()\n            plt.subplot(3, 2, 3)\n            plt.plot(frames[-len(losses) :], losses)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"loss\")\n            plt.subplot(3, 2, 4)\n            plt.plot(frames[-len(values) :], values)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"value\")\n            plt.subplot(3, 2, 5)\n            plt.plot(frames[-len(grad_vals) :], grad_vals)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"grad norm\")\n            if len(traj_lengths):\n                plt.subplot(3, 2, 6)\n                plt.plot(traj_lengths)\n                plt.xlabel(\"batches\")\n                plt.title(\"traj length (training)\")\n        plt.savefig(\"dqn_td0.png\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4878048780487805}, {"context": "        losses.append(error.item())\n        values.append(action_value.mean().item())\n        traj_count.append(prev_traj_count + data[\"done\"].sum().item())\n        prev_traj_count = traj_count[-1]\n        # plots\n        if j % 10 == 0:\n            if is_notebook():\n                display.clear_output(wait=True)\n                display.display(plt.gcf())\n            else:\n                plt.clf()\n            plt.figure(figsize=(15, 15))\n            plt.subplot(3, 2, 1)\n            plt.plot(frames[-len(evals) :], evals, label=\"return\")\n            plt.plot(frames[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"frames collected\")\n            plt.ylabel(\"trajectory length (= return)\")\n            plt.subplot(3, 2, 2)\n            plt.plot(traj_count[-len(evals) :], evals, label=\"return\")\n            plt.plot(traj_count[-len(mavgs) :], mavgs, label=\"mavg\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3305785123966942}, {"context": "            plt.subplot(3, 2, 5)\n            plt.plot(frames[-len(grad_vals) :], grad_vals)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"grad norm\")\n            if len(traj_lengths):\n                plt.subplot(3, 2, 6)\n                plt.plot(traj_lengths)\n                plt.xlabel(\"batches\")\n                plt.title(\"traj length (training)\")\n        plt.savefig(\"dqn_td0.png\")\n        if is_notebook():\n            plt.show()\n\n    # update policy weights\n    data_collector.update_policy_weights_()\n\nif is_notebook():\n    display.clear_output(wait=True)\n    display.display(plt.gcf())\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 480, "start_line_no": 470, "end_line_no": 490, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3113207547169811}, {"context": "###############################################################################\n\n# save results\ntorch.save(\n    {\n        \"frames\": frames,\n        \"evals\": evals,\n        \"mavgs\": mavgs,\n        \"losses\": losses,\n        \"values\": values,\n        \"grad_vals\": grad_vals,\n        \"traj_lengths_training\": traj_lengths,\n        \"traj_count\": traj_count,\n        \"weights\": (params,),\n    },\n    \"saved_results_td0.pt\",\n)\n\n###############################################################################\n# TD-lambda", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30337078651685395}, {"context": "\n@pytest.mark.parametrize(\"stack\", [False, True])\ndef test_rb_trajectories(stack):\n    traj_td = TensorDict(\n        {\"obs\": torch.randn(3, 4, 5), \"actions\": torch.randn(3, 4, 2)},\n        batch_size=[3, 4],\n    )\n    if stack:\n        traj_td = torch.stack([td.to_tensordict() for td in traj_td], 0)\n\n    rb = TensorDictPrioritizedReplayBuffer(\n        alpha=0.7,\n        beta=0.9,\n        priority_key=\"td_error\",\n        storage=ListStorage(5),\n    )\n    rb.extend(traj_td)\n    sampled_td = rb.sample(3)\n    sampled_td.set(\"td_error\", torch.rand(3))\n    rb.update_tensordict_priority(sampled_td)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb.py"], "line_no": 670, "start_line_no": 660, "end_line_no": 680, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21374045801526717}, {"context": "###############################################################################\n# **Note**: As already mentioned above, to get a more reasonable performance,\n# use a greater value for ``total_frames`` e.g. 500000.\n\n\nplt.figure(figsize=(15, 15))\nplt.imshow(plt.imread(\"dqn_td0.png\"))\nplt.tight_layout()\nplt.axis(\"off\")\n\n###############################################################################\n\n# save results\ntorch.save(\n    {\n        \"frames\": frames,\n        \"evals\": evals,\n        \"mavgs\": mavgs,\n        \"losses\": losses,\n        \"values\": values,", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21367521367521367}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_helpers.py\n# --------------------------------------------------\n#         if from_pixels:\n#             expected_keys += [\"pixels\", \"pixels_orig\", \"_reset\"]\n#         else:\n#             expected_keys += [\"observation_orig\", \"observation_vector\"]\n# \n#         if not distributional:\n#             expected_keys += [\"chosen_action_value\"]\n#         try:\n#             assert set(td.keys()) == set(expected_keys)\n#         except AssertionError:\n#             proof_environment.close()\n#             raise\n#         proof_environment.close()\n# \n# \n# @pytest.mark.skipif(not _has_hydra, reason=\"No hydra library found\")\n# @pytest.mark.skipif(not _has_gym, reason=\"No gym library found\")\n# @pytest.mark.parametrize(\"device\", get_available_devices())\n# @pytest.mark.parametrize(\"from_pixels\", [(\"from_pixels=True\", \"catframes=4\"), ()])\n# @pytest.mark.parametrize(\"gsde\", [(), (\"gSDE=True\",)])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_helpers.py\n# --------------------------------------------------\n# \n#         try:\n#             assert set(td.keys()) == set(expected_keys)\n#         except AssertionError:\n#             proof_environment.close()\n#             raise\n# \n#         if cfg.gSDE:\n#             tsf_loc = actor.module[0].module[-1].module.transform(td.get(\"loc\"))\n#             if exploration == \"random\":\n#                 with pytest.raises(AssertionError):\n#                     torch.testing.assert_close(td.get(\"action\"), tsf_loc)\n#             else:\n#                 torch.testing.assert_close(td.get(\"action\"), tsf_loc)\n# \n#         if UNSQUEEZE_SINGLETON and not td.ndimension():\n#             # Linear and conv used to break for non-batched data\n#             value(td.unsqueeze(0))\n#         else:\n#             value(td)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_helpers.py\n# --------------------------------------------------\n#             custom_env_maker=env_maker,\n#             stats={\"loc\": 0.0, \"scale\": 1.0},\n#         )\n#         proof_environment = env_maker()\n#         actor, value = make_ddpg_actor(proof_environment, device=device, cfg=cfg)\n#         td = proof_environment.reset().to(device)\n#         with set_exploration_mode(exploration):\n#             if UNSQUEEZE_SINGLETON and not td.ndimension():\n#                 # Linear and conv used to break for non-batched data\n#                 actor(td.unsqueeze(0))\n#             else:\n#                 actor(td)\n#         expected_keys = [\"done\", \"action\", \"param\"]\n#         if from_pixels:\n#             expected_keys += [\"pixels\", \"hidden\", \"pixels_orig\", \"_reset\"]\n#         else:\n#             expected_keys += [\"observation_vector\", \"observation_orig\"]\n# \n#         if cfg.gSDE:\n#             expected_keys += [\"scale\", \"loc\", \"_eps_gSDE\"]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_helpers.py\n# --------------------------------------------------\n#             # Linear and conv used to break for non-batched data\n#             actor(td.unsqueeze(0))\n#         else:\n#             actor(td)\n# \n#         expected_keys = [\n#             \"done\",\n#             \"action\",\n#             \"action_value\",\n#         ]\n#         if from_pixels:\n#             expected_keys += [\"pixels\", \"pixels_orig\", \"_reset\"]\n#         else:\n#             expected_keys += [\"observation_orig\", \"observation_vector\"]\n# \n#         if not distributional:\n#             expected_keys += [\"chosen_action_value\"]\n#         try:\n#             assert set(td.keys()) == set(expected_keys)\n#         except AssertionError:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_helpers.py\n# --------------------------------------------------\n#             else:\n#                 actor(td)\n#         expected_keys = [\"done\", \"action\", \"param\"]\n#         if from_pixels:\n#             expected_keys += [\"pixels\", \"hidden\", \"pixels_orig\", \"_reset\"]\n#         else:\n#             expected_keys += [\"observation_vector\", \"observation_orig\"]\n# \n#         if cfg.gSDE:\n#             expected_keys += [\"scale\", \"loc\", \"_eps_gSDE\"]\n# \n#         try:\n#             assert set(td.keys()) == set(expected_keys)\n#         except AssertionError:\n#             proof_environment.close()\n#             raise\n# \n#         if cfg.gSDE:\n#             tsf_loc = actor.module[0].module[-1].module.transform(td.get(\"loc\"))\n#             if exploration == \"random\":\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_helpers.py\n# --------------------------------------------------\n#         expected_keys += [\"state_action_value\"]\n#         try:\n#             assert set(td.keys()) == set(expected_keys)\n#         except AssertionError:\n#             proof_environment.close()\n#             raise\n# \n#         proof_environment.close()\n#         del proof_environment\n# \n# \n# @pytest.mark.skipif(not _has_hydra, reason=\"No hydra library found\")\n# @pytest.mark.skipif(not _has_gym, reason=\"No gym library found\")\n# @pytest.mark.parametrize(\"device\", get_available_devices())\n# @pytest.mark.parametrize(\"from_pixels\", [(), (\"from_pixels=True\", \"catframes=4\")])\n# @pytest.mark.parametrize(\"gsde\", [(), (\"gSDE=True\",)])\n# @pytest.mark.parametrize(\"shared_mapping\", [(), (\"shared_mapping=True\",)])\n# @pytest.mark.parametrize(\"exploration\", [\"random\", \"mode\"])\n# @pytest.mark.parametrize(\"action_space\", [\"discrete\", \"continuous\"])\n# def test_ppo_maker(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_helpers.py\n# --------------------------------------------------\n#                 with pytest.raises(AssertionError):\n#                     torch.testing.assert_close(td.get(\"action\"), tsf_loc)\n#             else:\n#                 torch.testing.assert_close(td.get(\"action\"), tsf_loc)\n# \n#         if UNSQUEEZE_SINGLETON and not td.ndimension():\n#             # Linear and conv used to break for non-batched data\n#             value(td.unsqueeze(0))\n#         else:\n#             value(td)\n#         expected_keys += [\"state_action_value\"]\n#         try:\n#             assert set(td.keys()) == set(expected_keys)\n#         except AssertionError:\n#             proof_environment.close()\n#             raise\n# \n#         proof_environment.close()\n#         del proof_environment\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n else \"observation_vector\",\n            \"pixels_orig\" if len(from_pixels) else \"observation_orig\",\n            \"action\",\n            \"sample_log_prob\",\n        ]\n        if action_space == \"continuous\":\n            expected_keys += [\"loc\", \"scale\"]\n        else:\n            expected_keys += [\"logits\"]\n        if shared_mapping:\n            expected_keys += [\"hidden\"]\n        if len(gsde):\n            expected_keys += [\"_eps_gSDE\"]\n\n        td = proof_environment.reset().to(device)\n        td_clone = td.clone()\n        with set_exploration_mode(exploration):\n            if UNSQUEEZE_SINGLETON and not td_clone.ndimension():\n                # Linear and conv used to break for non-batched data\n                actor(td_clone.unsqueeze(0))\n            else:\n                actor(td_clone)\n\n        if from_pixels:\n            # for CatFrames\n            expected_keys += [\"_reset\"]\n\n        try:\n            assert set(td_clone.keys()) == set(expected_keys)\n        except AssertionError:\n            proof_environment.close()\n            raise\n\n        if cfg.gSDE:\n            if cfg.shared_mapping:\n                tsf_loc = actor[-2].module[-1].module.transform(td_clone.get(\"loc\"))\n            else:\n                tsf_loc = (\n                    actor.module[0].module[-1].module.transform(td_clone.get(\"loc\"))\n                )\n\n            if exploration == \"random\":\n                with pytest.raises(AssertionError):\n                    torch.testing.assert_close(td_clone.get(\"action\"), tsf_loc)\n            else:\n                torch.testing.assert_close(td_clone.get(\"action\"), tsf_loc)\n\n        value = actor_value.get_value_operator()\n        expected_keys = [\n            \"done\",\n            \"pixels\" if len(from_pixels) else \"observation_vector\",\n            \"pixels_orig\" if len(from_pixels) else \"observation_orig\",\n            \"state_value\",\n        ]\n        if from_pixels:\n            # for CatFrames\n            expected_keys += [\"_reset\"]\n        if shared_mapping:\n            expected_keys += [\"hidden\"]\n        if len(gsde):\n            expected_keys += [\"_eps_gSDE\"]\n\n        td_clone = td.clone()\n        if UNSQUEEZE_SINGLETON and not td_clone.ndimension():\n            # Linear and conv used to break for non-batched data\n            value(td_clone.unsqueeze(0))\n        else:\n            value(td_clone)\n        try:\n            assert set(td_clone.keys()) == set(expected_keys)\n        except AssertionError:\n            proof_environment.close()\n            raise\n        proof_environment.close()\n        del proof_environment\n\n\n@pytest.mark.skipif(not _has_hydra, reason=\"No hydra library found\")\n@pytest.mark.skipif(not _has_gym, reason=\"No gym library found\")\n@pytest.mark.parametrize(\"device\", get_available_devices())\n@pytest.mark.parametrize(\"from_pixels\", [(), (\"from_pixels=True\", \"catframes=4\")])\n@pytest.mark.parametrize(\"gsde\", [(), (\"gSDE=True\",)])\n@pytest.mark.parametrize(\"shared_mapping\", [(), (\"shared_mapping=True\",)])\n@pytest.mark.parametrize(\"exploration\", [\"random\", \"mode\"])\n@pytest.mark.parametrize(\"action_space\", [\"discrete\", \"continuous\"])\ndef test_a2c_maker(\n    device, from_pixels, shared_mapping, gsde, exploration, action_space\n):\n    if not gsde and exploration != \"random\":\n        pytest.skip(\"no need to test this setting\")\n    flags = list(from_pixels + shared_mapping + gsde)\n    config_fields = [\n        (config_field.name, config_field.type, config_field)\n        for config_cls in (\n            EnvConfig,\n            A2CLossConfig,\n            A2CModelConfig,\n        )\n        for config_field in dataclasses.fields(config_cls)\n    ]\n\n    Config = dataclasses.make_dataclass(cls_name=\"Config\", fields=config_fields)\n    cs = ConfigStore.instance()\n    cs.store(name=\"config\", node=Config)\n\n    with initialize(version_base=None, config_path=None):\n        cfg = compose(config_name=\"config\", overrides=flags)\n        # if gsde and from_pixels:\n        #     pytest.skip(\"gsde and from_pixels are incompatible\")\n\n        if from_pixels:\n            if action_space == \"continuous\":\n                env_maker = ContinuousActionConvMockEnvNumpy\n            else:\n                env_maker = DiscreteActionConvMockEnvNumpy\n        else:\n            if action_space == \"continuous\":\n                env_maker = ContinuousActionVecMockEnv\n            else:\n                env_maker = DiscreteActionVecMockEnv\n\n        env_maker = transformed_env_constructor(\n            cfg,\n            use_env_creator=False,\n            custom_env_maker=env_maker,\n            stats={\"loc\": 0.0, \"scale\": 1.0},\n        )\n        proof_environment = env_maker()\n\n        if cfg.from_pixels and not cfg.shared_mapping:\n            with pytest.raises(\n                RuntimeError,\n                match=\"A2C learnt from pixels require the shared_mapping to be set to True\",\n            ):\n                actor_value = make_a2c_model(\n                    proof_environment,\n                    device=device,\n                    cfg=cfg,\n                )\n            return\n\n        if action_space == \"discrete\" and cfg.gSDE:\n            with pytest.raises(\n                RuntimeError,\n                match=\"cannot use gSDE with discrete actions\",\n            ):\n                actor_value = make_a2c_model(\n                    proof_environment,\n                    device=device,\n                    cfg=cfg,\n                )\n            return\n\n        actor_value = make_a2c_model(\n            proof_environment,\n            device=device,\n            cfg=cfg,\n        )\n        actor = actor_value.get_policy_operator()\n        expected_keys = [\n            \"done\",\n            \"pixels\" if len(from_pixels) else \"observation_vector\",\n            \"pixels_orig\" if len(from_pixels) else \"observation_orig\",\n            \"action\",\n            \"sample_log_prob\",\n        ]\n        if from_pixels:\n            # for CatFrames\n            expected_keys += [\"_reset\"]\n        if action_space == \"continuous\":\n            expected_keys += [\"loc\", \"scale\"]\n        else:\n            expected_keys += [\"logits\"]\n        if shared_mapping:\n            expected_keys += [\"hidden\"]\n        if len(gsde):\n            expected_keys += [\"_eps_gSDE\"]\n\n        td = proof_environment.reset().to(device)\n        td_clone = td.clone()\n        with set_exploration_mode(exploration):\n            if UNSQUEEZE_SINGLETON and not td_clone.ndimension():\n                # Linear and conv used to break for non-batched data\n                actor(td_clone.unsqueeze(0))\n            else:\n                actor(td_clone)\n\n        try:\n            assert set(td_clone.keys()) == set(expected_keys)\n        except AssertionError:\n            proof_environment.close()\n            raise\n\n        if cfg.gSDE:\n            if cfg.shared_mapping:\n                tsf_loc = actor[-2].module[-1].module.transform(td_clone.get(\"loc\"))\n            else:", "choices": [{"text": "tsf_loc = actor.module[0].module[-1].module.transform(td_clone.get(\"loc\"))"}], "metadata": {"task_id": "pytorch_rl/140", "ground_truth": "                tsf_loc = (", "fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "context_start_lineno": 333, "line_no": 530, "query_window": {"context": "\n        td = proof_environment.reset().to(device)\n        td_clone = td.clone()\n        with set_exploration_mode(exploration):\n            if UNSQUEEZE_SINGLETON and not td_clone.ndimension():\n                # Linear and conv used to break for non-batched data\n                actor(td_clone.unsqueeze(0))\n            else:\n                actor(td_clone)\n\n        try:\n            assert set(td_clone.keys()) == set(expected_keys)\n        except AssertionError:\n            proof_environment.close()\n            raise\n\n        if cfg.gSDE:\n            if cfg.shared_mapping:\n                tsf_loc = actor[-2].module[-1].module.transform(td_clone.get(\"loc\"))\n            else:", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "line_no": 530, "task_id": "pytorch_rl/140", "start_line_no": 510, "end_line_no": 530, "window_size": 20, "context_start_lineno": 333, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "\n        try:\n            assert set(td.keys()) == set(expected_keys)\n        except AssertionError:\n            proof_environment.close()\n            raise\n\n        if cfg.gSDE:\n            tsf_loc = actor.module[0].module[-1].module.transform(td.get(\"loc\"))\n            if exploration == \"random\":\n                with pytest.raises(AssertionError):\n                    torch.testing.assert_close(td.get(\"action\"), tsf_loc)\n            else:\n                torch.testing.assert_close(td.get(\"action\"), tsf_loc)\n\n        if UNSQUEEZE_SINGLETON and not td.ndimension():\n            # Linear and conv used to break for non-batched data\n            value(td.unsqueeze(0))\n        else:\n            value(td)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7431192660550459}, {"context": "                with pytest.raises(AssertionError):\n                    torch.testing.assert_close(td.get(\"action\"), tsf_loc)\n            else:\n                torch.testing.assert_close(td.get(\"action\"), tsf_loc)\n\n        if UNSQUEEZE_SINGLETON and not td.ndimension():\n            # Linear and conv used to break for non-batched data\n            value(td.unsqueeze(0))\n        else:\n            value(td)\n        expected_keys += [\"state_action_value\"]\n        try:\n            assert set(td.keys()) == set(expected_keys)\n        except AssertionError:\n            proof_environment.close()\n            raise\n\n        proof_environment.close()\n        del proof_environment\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.625}, {"context": "            custom_env_maker=env_maker,\n            stats={\"loc\": 0.0, \"scale\": 1.0},\n        )\n        proof_environment = env_maker()\n        actor, value = make_ddpg_actor(proof_environment, device=device, cfg=cfg)\n        td = proof_environment.reset().to(device)\n        with set_exploration_mode(exploration):\n            if UNSQUEEZE_SINGLETON and not td.ndimension():\n                # Linear and conv used to break for non-batched data\n                actor(td.unsqueeze(0))\n            else:\n                actor(td)\n        expected_keys = [\"done\", \"action\", \"param\"]\n        if from_pixels:\n            expected_keys += [\"pixels\", \"hidden\", \"pixels_orig\", \"_reset\"]\n        else:\n            expected_keys += [\"observation_vector\", \"observation_orig\"]\n\n        if cfg.gSDE:\n            expected_keys += [\"scale\", \"loc\", \"_eps_gSDE\"]", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4888888888888889}, {"context": "            custom_env_maker=env_maker,\n            stats={\"loc\": 0.0, \"scale\": 1.0},\n        )\n        proof_environment = env_maker(\n            categorical_action_encoding=cfg.categorical_action_encoding,\n        )\n\n        actor = make_dqn_actor(proof_environment, cfg, device)\n        td = proof_environment.reset().to(device)\n        if UNSQUEEZE_SINGLETON and not td.ndimension():\n            # Linear and conv used to break for non-batched data\n            actor(td.unsqueeze(0))\n        else:\n            actor(td)\n\n        expected_keys = [\n            \"done\",\n            \"action\",\n            \"action_value\",\n        ]", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4453125}, {"context": "        cfg = compose(config_name=\"config\", overrides=flags)\n\n        env_maker = (\n            ContinuousActionConvMockEnvNumpy\n            if from_pixels\n            else ContinuousActionVecMockEnv\n        )\n        env_maker = transformed_env_constructor(\n            cfg,\n            use_env_creator=False,\n            custom_env_maker=env_maker,\n            stats={\"loc\": 0.0, \"scale\": 1.0},\n        )\n        proof_environment = env_maker()\n        actor, value = make_ddpg_actor(proof_environment, device=device, cfg=cfg)\n        td = proof_environment.reset().to(device)\n        with set_exploration_mode(exploration):\n            if UNSQUEEZE_SINGLETON and not td.ndimension():\n                # Linear and conv used to break for non-batched data\n                actor(td.unsqueeze(0))", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.43448275862068964}, {"context": "            else:\n                actor(td)\n        expected_keys = [\"done\", \"action\", \"param\"]\n        if from_pixels:\n            expected_keys += [\"pixels\", \"hidden\", \"pixels_orig\", \"_reset\"]\n        else:\n            expected_keys += [\"observation_vector\", \"observation_orig\"]\n\n        if cfg.gSDE:\n            expected_keys += [\"scale\", \"loc\", \"_eps_gSDE\"]\n\n        try:\n            assert set(td.keys()) == set(expected_keys)\n        except AssertionError:\n            proof_environment.close()\n            raise\n\n        if cfg.gSDE:\n            tsf_loc = actor.module[0].module[-1].module.transform(td.get(\"loc\"))\n            if exploration == \"random\":", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.42735042735042733}, {"context": "            # Linear and conv used to break for non-batched data\n            actor(td.unsqueeze(0))\n        else:\n            actor(td)\n\n        expected_keys = [\n            \"done\",\n            \"action\",\n            \"action_value\",\n        ]\n        if from_pixels:\n            expected_keys += [\"pixels\", \"pixels_orig\", \"_reset\"]\n        else:\n            expected_keys += [\"observation_orig\", \"observation_vector\"]\n\n        if not distributional:\n            expected_keys += [\"chosen_action_value\"]\n        try:\n            assert set(td.keys()) == set(expected_keys)\n        except AssertionError:", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_helpers.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4017094017094017}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/ppo/ppo.py\n# --------------------------------------------------\n#         cfg=cfg,\n#         obs_norm_state_dict=obs_norm_state_dict,\n#         action_dim_gsde=action_dim_gsde,\n#         state_dim_gsde=state_dim_gsde,\n#     )\n# \n#     collector = make_collector_onpolicy(\n#         make_env=create_env_fn,\n#         actor_model_explore=actor_model,\n#         cfg=cfg,\n#         # make_env_kwargs=[\n#         #     {\"device\": device} if device >= 0 else {}\n#         #     for device in cfg.env_rendering_devices\n#         # ],\n#     )\n# \n#     recorder = transformed_env_constructor(\n#         cfg,\n#         video_tag=video_tag,\n#         norm_obs_only=True,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/a2c/a2c.py\n# --------------------------------------------------\n#         action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n#         del proof_td\n#     else:\n#         action_dim_gsde, state_dim_gsde = None, None\n# \n#     proof_env.close()\n#     create_env_fn = parallel_env_constructor(\n#         cfg=cfg,\n#         obs_norm_state_dict=obs_norm_state_dict,\n#         action_dim_gsde=action_dim_gsde,\n#         state_dim_gsde=state_dim_gsde,\n#     )\n# \n#     collector = make_collector_onpolicy(\n#         make_env=create_env_fn,\n#         actor_model_explore=actor_model,\n#         cfg=cfg,\n#     )\n# \n#     recorder = transformed_env_constructor(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/ppo/ppo.py\n# --------------------------------------------------\n#         with torch.no_grad(), set_exploration_mode(\"random\"):\n#             # get dimensions to build the parallel env\n#             proof_td = model(proof_env.reset().to(device))\n#         action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n#         del proof_td\n#     else:\n#         action_dim_gsde, state_dim_gsde = None, None\n# \n#     proof_env.close()\n#     create_env_fn = parallel_env_constructor(\n#         cfg=cfg,\n#         obs_norm_state_dict=obs_norm_state_dict,\n#         action_dim_gsde=action_dim_gsde,\n#         state_dim_gsde=state_dim_gsde,\n#     )\n# \n#     collector = make_collector_onpolicy(\n#         make_env=create_env_fn,\n#         actor_model_explore=actor_model,\n#         cfg=cfg,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/ddpg/ddpg.py\n# --------------------------------------------------\n#         action_dim_gsde, state_dim_gsde = None, None\n# \n#     proof_env.close()\n# \n#     create_env_fn = parallel_env_constructor(\n#         cfg=cfg,\n#         obs_norm_state_dict=obs_norm_state_dict,\n#         action_dim_gsde=action_dim_gsde,\n#         state_dim_gsde=state_dim_gsde,\n#     )\n# \n#     collector = make_collector_offpolicy(\n#         make_env=create_env_fn,\n#         actor_model_explore=actor_model_explore,\n#         cfg=cfg,\n#         # make_env_kwargs=[\n#         #     {\"device\": device} if device >= 0 else {}\n#         #     for device in args.env_rendering_devices\n#         # ],\n#     )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/redq/redq.py\n# --------------------------------------------------\n#         del proof_td\n#     else:\n#         action_dim_gsde, state_dim_gsde = None, None\n# \n#     proof_env.close()\n#     create_env_fn = parallel_env_constructor(\n#         cfg=cfg,\n#         obs_norm_state_dict=obs_norm_state_dict,\n#         action_dim_gsde=action_dim_gsde,\n#         state_dim_gsde=state_dim_gsde,\n#     )\n# \n#     collector = make_collector_offpolicy(\n#         make_env=create_env_fn,\n#         actor_model_explore=actor_model_explore,\n#         cfg=cfg,\n#         # make_env_kwargs=[\n#         #     {\"device\": device} if device >= 0 else {}\n#         #     for device in args.env_rendering_devices\n#         # ],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/ddpg/ddpg.py\n# --------------------------------------------------\n#         # mostly for debugging\n#         actor_model_explore.share_memory()\n# \n#     if cfg.gSDE:\n#         with torch.no_grad(), set_exploration_mode(\"random\"):\n#             # get dimensions to build the parallel env\n#             proof_td = actor_model_explore(proof_env.reset().to(device))\n#         action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n#         del proof_td\n#     else:\n#         action_dim_gsde, state_dim_gsde = None, None\n# \n#     proof_env.close()\n# \n#     create_env_fn = parallel_env_constructor(\n#         cfg=cfg,\n#         obs_norm_state_dict=obs_norm_state_dict,\n#         action_dim_gsde=action_dim_gsde,\n#         state_dim_gsde=state_dim_gsde,\n#     )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/redq/redq.py\n# --------------------------------------------------\n#         ).to(device)\n#     if device == torch.device(\"cpu\"):\n#         # mostly for debugging\n#         actor_model_explore.share_memory()\n# \n#     if cfg.gSDE:\n#         with torch.no_grad(), set_exploration_mode(\"random\"):\n#             # get dimensions to build the parallel env\n#             proof_td = actor_model_explore(proof_env.reset().to(device))\n#         action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n#         del proof_td\n#     else:\n#         action_dim_gsde, state_dim_gsde = None, None\n# \n#     proof_env.close()\n#     create_env_fn = parallel_env_constructor(\n#         cfg=cfg,\n#         obs_norm_state_dict=obs_norm_state_dict,\n#         action_dim_gsde=action_dim_gsde,\n#         state_dim_gsde=state_dim_gsde,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport dataclasses\nimport uuid\nfrom datetime import datetime\n\nimport hydra\nimport torch.cuda\nfrom hydra.core.config_store import ConfigStore\nfrom torchrl.envs import EnvCreator, ParallelEnv\nfrom torchrl.envs.transforms import RewardScaling, TransformedEnv\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import OrnsteinUhlenbeckProcessWrapper\nfrom torchrl.record import VideoRecorder\nfrom torchrl.record.loggers import generate_exp_name, get_logger\nfrom torchrl.trainers.helpers.collectors import (\n    make_collector_offpolicy,\n    OffPolicyCollectorConfig,\n)\nfrom torchrl.trainers.helpers.envs import (\n    correct_for_frame_skip,\n    EnvConfig,\n    initialize_observation_norm_transforms,\n    parallel_env_constructor,\n    retrieve_observation_norms_state_dict,\n    transformed_env_constructor,\n)\nfrom torchrl.trainers.helpers.logger import LoggerConfig\nfrom torchrl.trainers.helpers.losses import LossConfig, make_sac_loss\nfrom torchrl.trainers.helpers.models import make_sac_model, SACModelConfig\nfrom torchrl.trainers.helpers.replay_buffer import make_replay_buffer, ReplayArgsConfig\nfrom torchrl.trainers.helpers.trainers import make_trainer, TrainerConfig\n\nconfig_fields = [\n    (config_field.name, config_field.type, config_field)\n    for config_cls in (\n        TrainerConfig,\n        OffPolicyCollectorConfig,\n        EnvConfig,\n        LossConfig,\n        SACModelConfig,\n        LoggerConfig,\n        ReplayArgsConfig,\n    )\n    for config_field in dataclasses.fields(config_cls)\n]\n\nConfig = dataclasses.make_dataclass(cls_name=\"Config\", fields=config_fields)\ncs = ConfigStore.instance()\ncs.store(name=\"config\", node=Config)\n\nDEFAULT_REWARD_SCALING = {\n    \"Hopper-v1\": 5,\n    \"Walker2d-v1\": 5,\n    \"HalfCheetah-v1\": 5,\n    \"cheetah\": 5,\n    \"Ant-v2\": 5,\n    \"Humanoid-v2\": 20,\n    \"humanoid\": 100,\n}\n\n\n@hydra.main(version_base=None, config_path=\".\", config_name=\"config\")\ndef main(cfg: \"DictConfig\"):  # noqa: F821\n\n    cfg = correct_for_frame_skip(cfg)\n\n    if not isinstance(cfg.reward_scaling, float):\n        cfg.reward_scaling = DEFAULT_REWARD_SCALING.get(cfg.env_name, 5.0)\n\n    device = (\n        torch.device(\"cpu\")\n        if torch.cuda.device_count() == 0\n        else torch.device(\"cuda:0\")\n    )\n\n    exp_name = \"_\".join(\n        [\n            \"SAC\",\n            cfg.exp_name,\n            str(uuid.uuid4())[:8],\n            datetime.now().strftime(\"%y_%m_%d-%H_%M_%S\"),\n        ]\n    )\n\n    exp_name = generate_exp_name(\"SAC\", cfg.exp_name)\n    logger = get_logger(\n        logger_type=cfg.logger, logger_name=\"sac_logging\", experiment_name=exp_name\n    )\n    video_tag = exp_name if cfg.record_video else \"\"\n\n    key, init_env_steps, stats = None, None, None\n    if not cfg.vecnorm and cfg.norm_stats:\n        if not hasattr(cfg, \"init_env_steps\"):\n            raise AttributeError(\"init_env_steps missing from arguments.\")\n        key = (\"next\", \"pixels\") if cfg.from_pixels else (\"next\", \"observation_vector\")\n        init_env_steps = cfg.init_env_steps\n        stats = {\"loc\": None, \"scale\": None}\n    elif cfg.from_pixels:\n        stats = {\"loc\": 0.5, \"scale\": 0.5}\n\n    proof_env = transformed_env_constructor(\n        cfg=cfg,\n        use_env_creator=False,\n        stats=stats,\n    )()\n    initialize_observation_norm_transforms(\n        proof_environment=proof_env, num_iter=init_env_steps, key=key\n    )\n    _, obs_norm_state_dict = retrieve_observation_norms_state_dict(proof_env)[0]\n\n    model = make_sac_model(\n        proof_env,\n        cfg=cfg,\n        device=device,\n    )\n    loss_module, target_net_updater = make_sac_loss(model, cfg)\n\n    actor_model_explore = model[0]\n    if cfg.ou_exploration:\n        actor_model_explore = OrnsteinUhlenbeckProcessWrapper(\n            actor_model_explore,\n            annealing_num_steps=cfg.annealing_frames,\n            sigma=cfg.ou_sigma,\n            theta=cfg.ou_theta,\n        ).to(device)\n    if device == torch.device(\"cpu\"):\n        # mostly for debugging\n        actor_model_explore.share_memory()\n\n    if cfg.gSDE:\n        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = actor_model_explore(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n        del proof_td\n    else:", "choices": [{"text": "action_dim_gsde, state_dim_gsde = None, None"}], "metadata": {"task_id": "pytorch_rl/6", "ground_truth": "        action_dim_gsde, state_dim_gsde = None, None", "fpath_tuple": ["pytorch_rl", "examples", "sac", "sac.py"], "context_start_lineno": 0, "line_no": 140, "query_window": {"context": "\n    actor_model_explore = model[0]\n    if cfg.ou_exploration:\n        actor_model_explore = OrnsteinUhlenbeckProcessWrapper(\n            actor_model_explore,\n            annealing_num_steps=cfg.annealing_frames,\n            sigma=cfg.ou_sigma,\n            theta=cfg.ou_theta,\n        ).to(device)\n    if device == torch.device(\"cpu\"):\n        # mostly for debugging\n        actor_model_explore.share_memory()\n\n    if cfg.gSDE:\n        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = actor_model_explore(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n        del proof_td\n    else:", "metadata": {"fpath_tuple": ["pytorch_rl", "examples", "sac", "sac.py"], "line_no": 140, "task_id": "pytorch_rl/6", "start_line_no": 120, "end_line_no": 140, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "\n    actor_model_explore = model[0]\n    if cfg.ou_exploration:\n        if cfg.gSDE:\n            raise RuntimeError(\"gSDE and ou_exploration are incompatible\")\n        actor_model_explore = OrnsteinUhlenbeckProcessWrapper(\n            actor_model_explore,\n            annealing_num_steps=cfg.annealing_frames,\n            sigma=cfg.ou_sigma,\n            theta=cfg.ou_theta,\n        ).to(device)\n    if device == torch.device(\"cpu\"):\n        # mostly for debugging\n        actor_model_explore.share_memory()\n\n    if cfg.gSDE:\n        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = actor_model_explore(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "redq", "redq.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.9}, {"context": "    if cfg.ou_exploration:\n        if cfg.gSDE:\n            raise RuntimeError(\"gSDE and ou_exploration are incompatible\")\n        actor_model_explore = OrnsteinUhlenbeckProcessWrapper(\n            actor_model_explore,\n            annealing_num_steps=cfg.annealing_frames,\n            sigma=cfg.ou_sigma,\n            theta=cfg.ou_theta,\n        ).to(device)\n    if device == torch.device(\"cpu\"):\n        # mostly for debugging\n        actor_model_explore.share_memory()\n\n    if cfg.gSDE:\n        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = actor_model_explore(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n        del proof_td\n    else:", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "ddpg", "ddpg.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.8909090909090909}, {"context": "        ).to(device)\n    if device == torch.device(\"cpu\"):\n        # mostly for debugging\n        actor_model_explore.share_memory()\n\n    if cfg.gSDE:\n        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = actor_model_explore(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n        del proof_td\n    else:\n        action_dim_gsde, state_dim_gsde = None, None\n\n    proof_env.close()\n    create_env_fn = parallel_env_constructor(\n        cfg=cfg,\n        obs_norm_state_dict=obs_norm_state_dict,\n        action_dim_gsde=action_dim_gsde,\n        state_dim_gsde=state_dim_gsde,", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "redq", "redq.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6814159292035398}, {"context": "        # mostly for debugging\n        actor_model_explore.share_memory()\n\n    if cfg.gSDE:\n        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = actor_model_explore(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n        del proof_td\n    else:\n        action_dim_gsde, state_dim_gsde = None, None\n\n    proof_env.close()\n\n    create_env_fn = parallel_env_constructor(\n        cfg=cfg,\n        obs_norm_state_dict=obs_norm_state_dict,\n        action_dim_gsde=action_dim_gsde,\n        state_dim_gsde=state_dim_gsde,\n    )", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "ddpg", "ddpg.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.631578947368421}, {"context": "\n    model = make_ppo_model(\n        proof_env,\n        cfg=cfg,\n        device=device,\n    )\n    actor_model = model.get_policy_operator()\n\n    loss_module = make_ppo_loss(model, cfg)\n    if cfg.gSDE:\n        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = model(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n        del proof_td\n    else:\n        action_dim_gsde, state_dim_gsde = None, None\n\n    proof_env.close()\n    create_env_fn = parallel_env_constructor(", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "ppo", "ppo.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6}, {"context": "        cfg=cfg,\n        device=device,\n    )\n    actor_model = model.get_policy_operator()\n\n    loss_module = make_a2c_loss(model, cfg)\n    if cfg.gSDE:\n        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = model(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n        del proof_td\n    else:\n        action_dim_gsde, state_dim_gsde = None, None\n\n    proof_env.close()\n    create_env_fn = parallel_env_constructor(\n        cfg=cfg,\n        obs_norm_state_dict=obs_norm_state_dict,\n        action_dim_gsde=action_dim_gsde,", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "a2c", "a2c.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5655737704918032}, {"context": "        with torch.no_grad(), set_exploration_mode(\"random\"):\n            # get dimensions to build the parallel env\n            proof_td = model(proof_env.reset().to(device))\n        action_dim_gsde, state_dim_gsde = proof_td.get(\"_eps_gSDE\").shape[-2:]\n        del proof_td\n    else:\n        action_dim_gsde, state_dim_gsde = None, None\n\n    proof_env.close()\n    create_env_fn = parallel_env_constructor(\n        cfg=cfg,\n        obs_norm_state_dict=obs_norm_state_dict,\n        action_dim_gsde=action_dim_gsde,\n        state_dim_gsde=state_dim_gsde,\n    )\n\n    collector = make_collector_onpolicy(\n        make_env=create_env_fn,\n        actor_model_explore=actor_model,\n        cfg=cfg,", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "ppo", "ppo.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5537190082644629}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n# \n#         return self.activation(residual + y)\n# \n# \n# class BottleneckResNetBlock(nn.Module):\n#     \"\"\"\n#     Bottleneck residual network block.\n# \n#     Attributes\n#     ----------\n#     filters: int\n#         Number of filters.\n#     conv: ModuleDef\n#         Convolution module.\n#     norm: ModuleDef\n#         Normalization module.\n#     activation: Callable\n#         Activation function.\n#     strides: Tuple[int, int]\n#         Strides.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         -------\n#         jnp.ndarray\n#             Output of the subnetwork.\n#         \"\"\"\n#         x = nn.Dense(self.output_dim, dtype=self.dtype)(x)\n#         x = jnp.asarray(x, self.dtype)\n#         return x\n# \n# \n# class ResNet(nn.Module):\n#     \"\"\"\n#      Deep feature extractor subnetwork.\n# \n#     Attributes\n#     ----------\n#     stage_sizes: Sequence[int]\n#         Sizes for each stage.\n#     block_cls: ModuleDef\n#         Block class.\n#     output_dim: int\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Deep feature extractor representation.\n#         \"\"\"\n#         conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n#         norm = partial(\n#             nn.BatchNorm,\n#             use_running_average=not train,\n#             momentum=0.9,\n#             epsilon=1e-5,\n#             dtype=self.dtype,\n#         )\n#         x = conv(\n#             self.num_filters, (7, 7), (2, 2), padding=[(3, 3), (3, 3)], name=\"conv_init\"\n#         )(x)\n#         x = norm(name=\"bn_init\")(x)\n#         x = nn.relu(x)\n#         x = nn.max_pool(x, (3, 3), strides=(2, 2), padding=\"SAME\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         x: jnp.ndarray\n#             Block inputs.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Block outputs.\n#         \"\"\"\n#         residual = x\n#         y = self.conv(self.filters, (3, 3), self.strides)(x)\n#         y = self.norm()(y)\n#         y = self.activation(y)\n#         y = self.conv(self.filters, (3, 3))(y)\n#         y = self.norm(scale_init=nn.initializers.zeros)(y)\n# \n#         if residual.shape != y.shape:\n#             residual = self.conv(self.filters, (1, 1), self.strides, name=\"conv_proj\")(\n#                 residual\n#             )\n#             residual = self.norm(name=\"norm_proj\")(residual)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Outputs.\n#         \"\"\"\n#         x = self.dfe_subnet(x, train)\n#         x = self.output_subnet(x, train)\n#         return x\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         y = self.norm()(y)\n#         y = self.activation(y)\n#         y = self.conv(self.filters, (3, 3))(y)\n#         y = self.norm(scale_init=nn.initializers.zeros)(y)\n# \n#         if residual.shape != y.shape:\n#             residual = self.conv(self.filters, (1, 1), self.strides, name=\"conv_proj\")(\n#                 residual\n#             )\n#             residual = self.norm(name=\"norm_proj\")(residual)\n# \n#         return self.activation(residual + y)\n# \n# \n# class BottleneckResNetBlock(nn.Module):\n#     \"\"\"\n#     Bottleneck residual network block.\n# \n#     Attributes\n#     ----------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         Forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Outputs.\n#         \"\"\"\n#         x = self.dfe_subnet(x, train)\n#         x = self.output_subnet(x, train)\n#         return x\n# \n# \n# WideResNet28_10 = partial(WideResNet, depth=28, widen_factor=10)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         x = jnp.mean(x, axis=(1, 2))\n#         return x\n# \n# \n# class OutputSubNet(nn.Module):\n#     \"\"\"\n#     Output subnetwork.\n# \n#     Attributes\n#     ----------\n#     output_dim: int\n#         Output dimension.\n#     \"\"\"\n# \n#     output_dim: int\n#     dtype: Any = jnp.float32\n# \n#     @nn.compact\n#     def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         jnp.ndarray\n#             Block outputs.\n#         \"\"\"\n#         residual = x\n#         y = self.conv(self.filters, (1, 1))(x)\n#         y = self.norm()(y)\n#         y = self.activation(y)\n#         y = self.conv(self.filters, (3, 3), self.strides)(y)\n#         y = self.norm()(y)\n#         y = self.activation(y)\n#         y = self.conv(self.filters * 4, (1, 1))(y)\n#         y = self.norm(scale_init=nn.initializers.zeros)(y)\n# \n#         if residual.shape != y.shape:\n#             residual = self.conv(\n#                 self.filters * 4, (1, 1), self.strides, name=\"conv_proj\"\n#             )(residual)\n#             residual = self.norm(name=\"norm_proj\")(residual)\n# \n#         return self.activation(residual + y)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\"\"\"\nWide ResNet model\n(adapted from https://github.com/google/flax/blob/v0.2/examples/cifar10/models/wideresnet.py)\n\"\"\"\nfrom functools import partial\nfrom typing import Any, Callable, Tuple\n\nimport flax.linen as nn\nimport jax.numpy as jnp\n\nfrom fortuna.typing import Array\n\nModuleDef = Any\n\n\nclass WideResnetBlock(nn.Module):\n    \"\"\"\n    A wide residual network block.\n\n    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    filters: int\n        Number of filters.\n    strides: Tuple[int, int]\n        Strides.\n    :param dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Block forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Block inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Block outputs.\n        \"\"\"\n        dropout = nn.Dropout(rate=self.dropout_rate)\n\n        y = self.norm(name=\"bn1\")(x)\n        y = nn.relu(y)\n        y = self.conv(self.filters, (3, 3), self.strides, name=\"conv1\")(y)\n        y = self.norm(name=\"bn2\")(y)\n        y = nn.relu(y)\n        if self.dropout_rate > 0.0:\n            y = dropout(y, deterministic=not train)\n        y = self.conv(self.filters, (3, 3), name=\"conv2\")(y)\n\n        # Apply an up projection in case of channel mismatch\n        if (x.shape[-1] != self.filters) or self.strides != (1, 1):\n            x = self.conv(self.filters, (3, 3), self.strides)(x)\n        return x + y\n\n\nclass WideResnetGroup(nn.Module):\n    \"\"\"\n    A wide residual network group.\n\n    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    blocks_per_group: int\n        Number of blocks per group.\n    strides: Tuple[int, int]\n        Strides.\n    dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    blocks_per_group: int\n    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Group forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Group inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Group outputs.\n        \"\"\"\n        for i in range(self.blocks_per_group):\n            x = WideResnetBlock(\n                conv=self.conv,\n                norm=self.norm,\n                activation=self.activation,\n                filters=self.filters,\n                strides=self.strides if i == 0 else (1, 1),", "choices": [{"text": "dropout_rate=self.dropout_rate,"}], "metadata": {"task_id": "awslabs_fortuna/113", "ground_truth": "                dropout_rate=self.dropout_rate,", "fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "context_start_lineno": 0, "line_no": 128, "query_window": {"context": "\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Group inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Group outputs.\n        \"\"\"\n        for i in range(self.blocks_per_group):\n            x = WideResnetBlock(\n                conv=self.conv,\n                norm=self.norm,\n                activation=self.activation,\n                filters=self.filters,\n                strides=self.strides if i == 0 else (1, 1),", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 128, "task_id": "awslabs_fortuna/113", "start_line_no": 108, "end_line_no": 128, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        \"\"\"\n        Bottleneck block forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Block inputs.\n\n        Returns\n        -------\n        jnp.ndarray\n            Block outputs.\n        \"\"\"\n        residual = x\n        y = self.conv(self.filters, (1, 1))(x)\n        y = self.norm()(y)\n        y = self.activation(y)\n        y = self.conv(self.filters, (3, 3), self.strides)(y)\n        y = self.norm()(y)\n        y = self.activation(y)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4}, {"context": "        for i, block_size in enumerate(self.stage_sizes):\n            for j in range(block_size):\n                strides = (2, 2) if i > 0 and j == 0 else (1, 1)\n                x = self.block_cls(\n                    self.num_filters * 2 ** i,\n                    strides=strides,\n                    conv=conv,\n                    norm=norm,\n                    activation=self.activation,\n                )(x)\n        x = jnp.mean(x, axis=(1, 2))\n        return x\n\n\nclass OutputSubNet(nn.Module):\n    \"\"\"\n    Output subnetwork.\n\n    Attributes\n    ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3942307692307692}, {"context": "    def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x: Array\n            Input data.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Outputs.\n        \"\"\"\n        x = self.dfe_subnet(x, train)\n        x = self.output_subnet(x, train)\n        return x\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}, {"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.35555555555555557}, {"context": "        x: jnp.ndarray\n            Block inputs.\n\n        Returns\n        -------\n        jnp.ndarray\n            Block outputs.\n        \"\"\"\n        residual = x\n        y = self.conv(self.filters, (3, 3), self.strides)(x)\n        y = self.norm()(y)\n        y = self.activation(y)\n        y = self.conv(self.filters, (3, 3))(y)\n        y = self.norm(scale_init=nn.initializers.zeros)(y)\n\n        if residual.shape != y.shape:\n            residual = self.conv(self.filters, (1, 1), self.strides, name=\"conv_proj\")(\n                residual\n            )\n            residual = self.norm(name=\"norm_proj\")(residual)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.35353535353535354}, {"context": "        self.dfe_subnet = DeepFeatureExtractorSubNet(\n            stage_sizes=self.stage_sizes,\n            block_cls=self.block_cls,\n            num_filters=self.num_filters,\n            dtype=self.dtype,\n            activation=self.activation,\n            conv=self.conv,\n        )\n        self.output_subnet = OutputSubNet(output_dim=self.output_dim, dtype=self.dtype)\n\n    def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x: Array\n            Input data.\n        train: bool\n            Whether the call is performed during training.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3490566037735849}, {"context": "    activation: Callable\n    strides: Tuple[int, int] = (1, 1)\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray,) -> jnp.ndarray:\n        \"\"\"\n        Block forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Block inputs.\n\n        Returns\n        -------\n        jnp.ndarray\n            Block outputs.\n        \"\"\"\n        residual = x\n        y = self.conv(self.filters, (3, 3), self.strides)(x)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3469387755102041}, {"context": "    def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Deep feature extractor subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: Array\n            Input data.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Deep feature extractor representation.\n        \"\"\"\n        conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n        norm = partial(\n            nn.BatchNorm,\n            use_running_average=not train,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.33653846153846156}, {"context": "        Output subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Deep feature extractor representation.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Output of the subnetwork.\n        \"\"\"\n        x = nn.Dense(self.output_dim, dtype=self.dtype)(x)\n        x = jnp.asarray(x, self.dtype)\n        return x\n\n\nclass ResNet(nn.Module):", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "        y = self.norm()(y)\n        y = self.activation(y)\n        y = self.conv(self.filters, (3, 3))(y)\n        y = self.norm(scale_init=nn.initializers.zeros)(y)\n\n        if residual.shape != y.shape:\n            residual = self.conv(self.filters, (1, 1), self.strides, name=\"conv_proj\")(\n                residual\n            )\n            residual = self.norm(name=\"norm_proj\")(residual)\n\n        return self.activation(residual + y)\n\n\nclass BottleneckResNetBlock(nn.Module):\n    \"\"\"\n    Bottleneck residual network block.\n\n    Attributes\n    ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.28703703703703703}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/cql.py\n# --------------------------------------------------\n#            6  | ``model.value_``    int         256            | Linear layer size for value     | Defalut to None when\n#               | ``embedding_size``                             | network.                        | model.value_network\n#               |                                                |                                 | is False.\n#            7  | ``learn.learning``  float       3e-4           | Learning rate for soft q        | Defalut to 1e-3, when\n#               | ``_rate_q``                                    | network.                        | model.value_network\n#               |                                                |                                 | is True.\n#            8  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to 1e-3, when\n#               | ``_rate_policy``                               | network.                        | model.value_network\n#               |                                                |                                 | is True.\n#            9  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to None when\n#               | ``_rate_value``                                | network.                        | model.value_network\n#               |                                                |                                 | is False.\n#            10 | ``learn.alpha``     float       0.2            | Entropy regularization          | alpha is initiali-\n#               |                                                | coefficient.                    | zation for auto\n#               |                                                |                                 | `\\alpha`, when\n#               |                                                |                                 | auto_alpha is True\n#            11 | ``learn.repara_``   bool        True           | Determine whether to use        |\n#               | ``meterization``                               | reparameterization trick.       |\n#            12 | ``learn.``          bool        False          | Determine whether to use        | Temperature parameter\n#               | ``auto_alpha``                                 | auto temperature parameter      | determines the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/masac.py\n# ding/policy/sac.py\n# --------------------------------------------------\n#            7  | ``learn.learning``  float       3e-4           | Learning rate for soft q        | Defalut to 1e-3, when\n#               | ``_rate_q``                                    | network.                        | model.value_network\n#               |                                                |                                 | is True.\n#            8  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to 1e-3, when\n#               | ``_rate_policy``                               | network.                        | model.value_network\n#               |                                                |                                 | is True.\n#            9  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to None when\n#               | ``_rate_value``                                | network.                        | model.value_network\n#               |                                                |                                 | is False.\n#            10 | ``learn.alpha``     float       0.2            | Entropy regularization          | alpha is initiali-\n#               |                                                | coefficient.                    | zation for auto\n#               |                                                |                                 | `\\alpha`, when\n#               |                                                |                                 | auto_alpha is True\n#            11 | ``learn.repara_``   bool        True           | Determine whether to use        |\n#               | ``meterization``                               | reparameterization trick.       |\n#            12 | ``learn.``          bool        False          | Determine whether to use        | Temperature parameter\n#               | ``auto_alpha``                                 | auto temperature parameter      | determines the\n#               |                                                | `\\alpha`.                       | relative importance\n#               |                                                |                                 | of the entropy term\n#               |                                                |                                 | against the reward.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/masac.py\n# ding/policy/sac.py\n# --------------------------------------------------\n#               |                                                | coefficient.                    | zation for auto\n#               |                                                |                                 | `\\alpha`, when\n#               |                                                |                                 | auto_alpha is True\n#            11 | ``learn.repara_``   bool        True           | Determine whether to use        |\n#               | ``meterization``                               | reparameterization trick.       |\n#            12 | ``learn.``          bool        False          | Determine whether to use        | Temperature parameter\n#               | ``auto_alpha``                                 | auto temperature parameter      | determines the\n#               |                                                | `\\alpha`.                       | relative importance\n#               |                                                |                                 | of the entropy term\n#               |                                                |                                 | against the reward.\n#            13 | ``learn.-``         bool        False          | Determine whether to ignore     | Use ignore_done only\n#               | ``ignore_done``                                | done flag.                      | in halfcheetah env.\n#            14 | ``learn.-``         float       0.005          | Used for soft update of the     | aka. Interpolation\n#               | ``target_theta``                               | target network.                 | factor in polyak aver\n#               |                                                |                                 | aging for target\n#               |                                                |                                 | networks.\n#            == ====================  ========    =============  ================================= =======================\n#        \"\"\"\n# \n#     config = dict(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/cql.py\n# --------------------------------------------------\n#               | ``_rate_value``                                | network.                        | model.value_network\n#               |                                                |                                 | is False.\n#            10 | ``learn.alpha``     float       0.2            | Entropy regularization          | alpha is initiali-\n#               |                                                | coefficient.                    | zation for auto\n#               |                                                |                                 | `\\alpha`, when\n#               |                                                |                                 | auto_alpha is True\n#            11 | ``learn.repara_``   bool        True           | Determine whether to use        |\n#               | ``meterization``                               | reparameterization trick.       |\n#            12 | ``learn.``          bool        False          | Determine whether to use        | Temperature parameter\n#               | ``auto_alpha``                                 | auto temperature parameter      | determines the\n#               |                                                | `\\alpha`.                       | relative importance\n#               |                                                |                                 | of the entropy term\n#               |                                                |                                 | against the reward.\n#            13 | ``learn.-``         bool        False          | Determine whether to ignore     | Use ignore_done only\n#               | ``ignore_done``                                | done flag.                      | in halfcheetah env.\n#            14 | ``learn.-``         float       0.005          | Used for soft update of the     | aka. Interpolation\n#               | ``target_theta``                               | target network.                 | factor in polyak aver\n#               |                                                |                                 | aging for target\n#               |                                                |                                 | networks.\n#            == ====================  ========    =============  ================================= =======================\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import List, Dict, Any, Tuple, Union\nfrom collections import namedtuple\nimport copy\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.distributions import Normal, Independent\n\nfrom ding.torch_utils import Adam, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import default_collate, default_decollate\nfrom .base_policy import Policy\nfrom .common_utils import default_preprocess_learn\n\n\n@POLICY_REGISTRY.register('sac')\nclass SACPolicy(Policy):\n    r\"\"\"\n       Overview:\n           Policy class of SAC algorithm.\n\n       Config:\n           == ====================  ========    =============  ================================= =======================\n           ID Symbol                Type        Default Value  Description                       Other(Shape)\n           == ====================  ========    =============  ================================= =======================\n           1  ``type``              str         td3            | RL policy register name, refer  | this arg is optional,\n                                                               | to registry ``POLICY_REGISTRY`` | a placeholder\n           2  ``cuda``              bool        True           | Whether to use cuda for network |\n           3  | ``random_``         int         10000          | Number of randomly collected    | Default to 10000 for\n              | ``collect_size``                               | training samples in replay      | SAC, 25000 for DDPG/\n              |                                                | buffer when training starts.    | TD3.\n           4  | ``model.policy_``   int         256            | Linear layer size for policy    |\n              | ``embedding_size``                             | network.                        |\n           5  | ``model.soft_q_``   int         256            | Linear layer size for soft q    |\n              | ``embedding_size``                             | network.                        |\n           6  | ``model.value_``    int         256            | Linear layer size for value     | Defalut to None when\n              | ``embedding_size``                             | network.                        | model.value_network\n              |                                                |                                 | is False.\n           7  | ``learn.learning``  float       3e-4           | Learning rate for soft q        | Defalut to 1e-3, when\n              | ``_rate_q``                                    | network.                        | model.value_network\n              |                                                |                                 | is True.\n           8  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to 1e-3, when\n              | ``_rate_policy``                               | network.                        | model.value_network\n              |                                                |                                 | is True.\n           9  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to None when\n              | ``_rate_value``                                | network.                        | model.value_network\n              |                                                |                                 | is False.\n           10 | ``learn.alpha``     float       0.2            | Entropy regularization          | alpha is initiali-\n              |                                                | coefficient.                    | zation for auto\n              |                                                |                                 | `\\alpha`, when\n              |                                                |                                 | auto_alpha is True\n           11 | ``learn.repara_``   bool        True           | Determine whether to use        |\n              | ``meterization``                               | reparameterization trick.       |", "choices": [{"text": "`learn.auto_alpha`` | bool | False | Determine whether to use auto temperature parameter"}], "metadata": {"task_id": "opendilab_ACE/13", "ground_truth": "           12 | ``learn.``          bool        False          | Determine whether to use        | Temperature parameter", "fpath_tuple": ["opendilab_ACE", "ding", "policy", "sac.py"], "context_start_lineno": 0, "line_no": 55, "query_window": {"context": "           5  | ``model.soft_q_``   int         256            | Linear layer size for soft q    |\n              | ``embedding_size``                             | network.                        |\n           6  | ``model.value_``    int         256            | Linear layer size for value     | Defalut to None when\n              | ``embedding_size``                             | network.                        | model.value_network\n              |                                                |                                 | is False.\n           7  | ``learn.learning``  float       3e-4           | Learning rate for soft q        | Defalut to 1e-3, when\n              | ``_rate_q``                                    | network.                        | model.value_network\n              |                                                |                                 | is True.\n           8  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to 1e-3, when\n              | ``_rate_policy``                               | network.                        | model.value_network\n              |                                                |                                 | is True.\n           9  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to None when\n              | ``_rate_value``                                | network.                        | model.value_network\n              |                                                |                                 | is False.\n           10 | ``learn.alpha``     float       0.2            | Entropy regularization          | alpha is initiali-\n              |                                                | coefficient.                    | zation for auto\n              |                                                |                                 | `\\alpha`, when\n              |                                                |                                 | auto_alpha is True\n           11 | ``learn.repara_``   bool        True           | Determine whether to use        |\n              | ``meterization``                               | reparameterization trick.       |", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "sac.py"], "line_no": 55, "task_id": "opendilab_ACE/13", "start_line_no": 35, "end_line_no": 55, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "           6  | ``model.value_``    int         256            | Linear layer size for value     | Defalut to None when\n              | ``embedding_size``                             | network.                        | model.value_network\n              |                                                |                                 | is False.\n           7  | ``learn.learning``  float       3e-4           | Learning rate for soft q        | Defalut to 1e-3, when\n              | ``_rate_q``                                    | network.                        | model.value_network\n              |                                                |                                 | is True.\n           8  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to 1e-3, when\n              | ``_rate_policy``                               | network.                        | model.value_network\n              |                                                |                                 | is True.\n           9  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to None when\n              | ``_rate_value``                                | network.                        | model.value_network\n              |                                                |                                 | is False.\n           10 | ``learn.alpha``     float       0.2            | Entropy regularization          | alpha is initiali-\n              |                                                | coefficient.                    | zation for auto\n              |                                                |                                 | `\\alpha`, when\n              |                                                |                                 | auto_alpha is True\n           11 | ``learn.repara_``   bool        True           | Determine whether to use        |\n              | ``meterization``                               | reparameterization trick.       |\n           12 | ``learn.``          bool        False          | Determine whether to use        | Temperature parameter\n              | ``auto_alpha``                                 | auto temperature parameter      | determines the", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "cql.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.9099099099099099}, {"context": "           7  | ``learn.learning``  float       3e-4           | Learning rate for soft q        | Defalut to 1e-3, when\n              | ``_rate_q``                                    | network.                        | model.value_network\n              |                                                |                                 | is True.\n           8  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to 1e-3, when\n              | ``_rate_policy``                               | network.                        | model.value_network\n              |                                                |                                 | is True.\n           9  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to None when\n              | ``_rate_value``                                | network.                        | model.value_network\n              |                                                |                                 | is False.\n           10 | ``learn.alpha``     float       0.2            | Entropy regularization          | alpha is initiali-\n              |                                                | coefficient.                    | zation for auto\n              |                                                |                                 | `\\alpha`, when\n              |                                                |                                 | auto_alpha is True\n           11 | ``learn.repara_``   bool        True           | Determine whether to use        |\n              | ``meterization``                               | reparameterization trick.       |\n           12 | ``learn.``          bool        False          | Determine whether to use        | Temperature parameter\n              | ``auto_alpha``                                 | auto temperature parameter      | determines the\n              |                                                | `\\alpha`.                       | relative importance\n              |                                                |                                 | of the entropy term\n              |                                                |                                 | against the reward.", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "masac.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}, {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "sac.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.725}, {"context": "           3  | ``random_``         int         10000          | Number of randomly collected    | Default to 10000 for\n              | ``collect_size``                               | training samples in replay      | SAC, 25000 for DDPG/\n              |                                                | buffer when training starts.    | TD3.\n           4  | ``model.policy_``   int         256            | Linear layer size for policy    |\n              | ``embedding_size``                             | network.                        |\n           5  | ``model.soft_q_``   int         256            | Linear layer size for soft q    |\n              | ``embedding_size``                             | network.                        |\n           6  | ``model.value_``    int         256            | Linear layer size for value     | Defalut to None when\n              | ``embedding_size``                             | network.                        | model.value_network\n              |                                                |                                 | is False.\n           7  | ``learn.learning``  float       3e-4           | Learning rate for soft q        | Defalut to 1e-3, when\n              | ``_rate_q``                                    | network.                        | model.value_network\n              |                                                |                                 | is True.\n           8  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to 1e-3, when\n              | ``_rate_policy``                               | network.                        | model.value_network\n              |                                                |                                 | is True.\n           9  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to None when\n              | ``_rate_value``                                | network.                        | model.value_network\n              |                                                |                                 | is False.\n           10 | ``learn.alpha``     float       0.2            | Entropy regularization          | alpha is initiali-", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "masac.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}, {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "sac.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.640625}, {"context": "           1  ``type``              str         td3            | RL policy register name, refer  | this arg is optional,\n                                                               | to registry ``POLICY_REGISTRY`` | a placeholder\n           2  ``cuda``              bool        True           | Whether to use cuda for network |\n           3  | ``random_``         int         10000          | Number of randomly collected    | Default to 10000 for\n              | ``collect_size``                               | training samples in replay      | SAC, 25000 for DDPG/\n              |                                                | buffer when training starts.    | TD3.\n           4  | ``model.policy_``   int         256            | Linear layer size for policy    |\n              | ``embedding_size``                             | network.                        |\n           5  | ``model.soft_q_``   int         256            | Linear layer size for soft q    |\n              | ``embedding_size``                             | network.                        |\n           6  | ``model.value_``    int         256            | Linear layer size for value     | Defalut to None when\n              | ``embedding_size``                             | network.                        | model.value_network\n              |                                                |                                 | is False.\n           7  | ``learn.learning``  float       3e-4           | Learning rate for soft q        | Defalut to 1e-3, when\n              | ``_rate_q``                                    | network.                        | model.value_network\n              |                                                |                                 | is True.\n           8  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to 1e-3, when\n              | ``_rate_policy``                               | network.                        | model.value_network\n              |                                                |                                 | is True.\n           9  | ``learn.learning``  float       3e-4           | Learning rate for policy        | Defalut to None when", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "cql.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.48026315789473684}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_restore(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n# \n#             # load state\n#             prob_reg.load_state(checkpoint_path=tmp_dir)\n# \n#             # save state\n#             prob_reg.save_state(checkpoint_path=tmp_dir)\n# \n#     def test_dryrun_class_map(self):\n#         with tempfile.TemporaryDirectory() as tmp_dir:\n#             prob_class = ProbClassifier(\n#                 model=MyModel(self.class_output_dim),\n#                 posterior_approximator=MAPPosteriorApproximator(),\n#                 output_calibrator=ClassificationTemperatureScaler(),\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_nodir_nodump,\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n# \n#             # no save dir but dump\n#             with self.assertRaises(ValueError):\n#                 status = prob_reg.train(\n#                     train_data_loader=self.reg_train_data_loader,\n#                     calib_data_loader=self.reg_val_data_loader,\n#                     val_data_loader=self.reg_val_data_loader,\n#                     fit_config=self.reg_fit_config_nodir_dump,\n#                     calib_config=self.reg_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n#             prob_reg.posterior.load_state(tmp_dir)\n# \n#             # restore\n#             prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_restore(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n# \n#             # load state\n#             prob_reg.load_state(checkpoint_path=tmp_dir)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n#             prob_reg.posterior.load_state(tmp_dir)\n# \n#             # save dir and dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n#             prob_reg.posterior.load_state(tmp_dir)\n# \n#             # restore\n#             prob_reg.train(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                     calib_data_loader=self.reg_val_data_loader,\n#                     val_data_loader=self.reg_val_data_loader,\n#                     fit_config=self.reg_fit_config_nodir_dump,\n#                     calib_config=self.reg_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n#             prob_reg.posterior.load_state(tmp_dir)\n# \n#             # save dir and dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#             # no save dir but dump\n#             with self.assertRaises(ValueError):\n#                 status = prob_class.train(\n#                     train_data_loader=self.class_train_data_loader,\n#                     calib_data_loader=self.class_val_data_loader,\n#                     val_data_loader=self.class_val_data_loader,\n#                     fit_config=self.class_fit_config_nodir_dump,\n#                     calib_config=self.class_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_nodump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n#             sample = prob_class.posterior.sample()\n#             prob_class.posterior.load_state(tmp_dir)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nclass_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_dump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # restore\n            prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_restore(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_class.load_state(checkpoint_path=tmp_dir)\n\n            # save state\n            prob_class.save_state(checkpoint_path=tmp_dir)\n\n    def test_dryrun_reg_advi(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            prob_reg = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=ADVIPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    fit_config=self.reg_fit_config_nodir_dump,\n                    calib_config=self.reg_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # restore from advi\n            prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # restore from map\n            prob_reg_map = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_reg.load_state(checkpoint_path=tmp_dir)\n\n            # save state\n            prob_reg.save_state(checkpoint_path=tmp_dir)\n\n    def test_dryrun_class_advi(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            prob_class = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=ADVIPosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_nodir_nodump,\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_nodump(tmp_dir),", "choices": [{"text": "calib_config=self.class_calib_config_nodir_nodump,"}], "metadata": {"task_id": "awslabs_fortuna/40", "ground_truth": "                calib_config=self.class_calib_config_nodir_nodump,", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "context_start_lineno": 245, "line_no": 397, "query_window": {"context": "                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_nodump(tmp_dir),", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 397, "task_id": "awslabs_fortuna/40", "start_line_no": 377, "end_line_no": 397, "window_size": 20, "context_start_lineno": 245, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            # no save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_nodir_nodump,\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9464285714285714}, {"context": "                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    fit_config=self.reg_fit_config_nodir_dump,\n                    calib_config=self.reg_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9122807017543859}, {"context": "                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    fit_config=self.reg_fit_config_nodir_dump,\n                    calib_config=self.reg_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7540983606557377}, {"context": "                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # restore\n            prob_reg.train(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7096774193548387}, {"context": "            prob_reg = ProbRegressor(\n                model=MLP(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5977011494252874}, {"context": "                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # restore\n            prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_reg.load_state(checkpoint_path=tmp_dir)\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5882352941176471}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#                 item.is_in(val.get(key))\n#                 for (key, item) in self._specs.items()\n#                 if item is not None\n#             ]\n#         )\n# \n#     def project(self, val: TensorDictBase) -> TensorDictBase:\n#         for key, item in self.items():\n#             if item is None:\n#                 continue\n#             _val = val.get(key)\n#             if not self._specs[key].is_in(_val):\n#                 val.set(key, self._specs[key].project(_val))\n#         return val\n# \n#     def rand(self, shape=None) -> TensorDictBase:\n#         if shape is None:\n#             shape = torch.Size([])\n#         _dict = {\n#             key: self[key].rand(shape)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#         else:\n#             n_tasks = len(create_env_fn)\n#             self.meta_data = []\n#             for i in range(n_tasks):\n#                 self.meta_data.append(\n#                     get_env_metadata(create_env_fn[i], create_env_kwargs[i])\n#                 )\n#         self._set_properties()\n# \n#     def update_kwargs(self, kwargs: Union[dict, List[dict]]) -> None:\n#         \"\"\"Updates the kwargs of each environment given a dictionary or a list of dictionaries.\n# \n#         Args:\n#             kwargs (dict or list of dict): new kwargs to use with the environments\n# \n#         \"\"\"\n#         if isinstance(kwargs, dict):\n#             for _kwargs in self.create_env_kwargs:\n#                 _kwargs.update(kwargs)\n#         else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/gym_like.py\n# --------------------------------------------------\n#         self, info_dict: Dict[str, Any], tensordict: TensorDictBase\n#     ) -> TensorDictBase:\n#         if not isinstance(info_dict, dict) and len(self.keys):\n#             warnings.warn(\n#                 f\"Found an info_dict of type {type(info_dict)} \"\n#                 f\"but expected type or subtype `dict`.\"\n#             )\n#         for key in self.keys:\n#             if key in info_dict:\n#                 tensordict[key] = info_dict[key]\n#         return tensordict\n# \n#     @property\n#     def info_spec(self) -> Dict[str, TensorSpec]:\n#         return self._info_spec\n# \n# \n# class GymLikeEnv(_EnvWrapper):\n#     \"\"\"A gym-like env is an environment.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#         return f\"CompositeSpec(\\n{sub_str}, device={self._device}, shape={self.shape})\"\n# \n#     def type_check(\n#         self,\n#         value: Union[torch.Tensor, TensorDictBase],\n#         selected_keys: Union[str, Optional[Sequence[str]]] = None,\n#     ):\n#         if isinstance(value, torch.Tensor) and isinstance(selected_keys, str):\n#             value = {selected_keys: value}\n#             selected_keys = [selected_keys]\n# \n#         for _key in self:\n#             if self[_key] is not None and (\n#                 selected_keys is None or _key in selected_keys\n#             ):\n#                 self._specs[_key].type_check(value[_key], _key)\n# \n#     def is_in(self, val: Union[dict, TensorDictBase]) -> bool:\n#         return all(\n#             [\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n# \n#         for _key in self:\n#             if self[_key] is not None and (\n#                 selected_keys is None or _key in selected_keys\n#             ):\n#                 self._specs[_key].type_check(value[_key], _key)\n# \n#     def is_in(self, val: Union[dict, TensorDictBase]) -> bool:\n#         return all(\n#             [\n#                 item.is_in(val.get(key))\n#                 for (key, item) in self._specs.items()\n#                 if item is not None\n#             ]\n#         )\n# \n#     def project(self, val: TensorDictBase) -> TensorDictBase:\n#         for key, item in self.items():\n#             if item is None:\n#                 continue\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/collectors/collectors.py\n# --------------------------------------------------\n#         \"\"\"\n#         # if create_env_fn is not None:\n#         #     if create_env_kwargs is None:\n#         #         create_env_kwargs = {}\n#         #     self.create_env_fn = create_env_fn\n#         #     if isinstance(create_env_fn, EnvBase):\n#         #         env = create_env_fn\n#         #     else:\n#         #         env = self.create_env_fn(**create_env_kwargs)\n#         # else:\n#         #     env = None\n# \n#         if policy is None:\n#             if not hasattr(self, \"env\") or self.env is None:\n#                 raise ValueError(\n#                     \"env must be provided to _get_policy_and_device if policy is None\"\n#                 )\n#             policy = RandomPolicy(self.env.action_spec)\n#         elif isinstance(policy, nn.Module):\n#             # TODO: revisit these checks when we have determined whether arbitrary\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/gym_like.py\n# --------------------------------------------------\n#         return tensordict\n# \n#     @property\n#     def info_spec(self) -> Dict[str, TensorSpec]:\n#         return self._info_spec\n# \n# \n# class GymLikeEnv(_EnvWrapper):\n#     \"\"\"A gym-like env is an environment.\n# \n#     Its behaviour is similar to gym environments in what common methods (specifically reset and step) are expected to do.\n# \n#     A :obj:`GymLikeEnv` has a :obj:`.step()` method with the following signature:\n# \n#         ``env.step(action: np.ndarray) -> Tuple[Union[np.ndarray, dict], double, bool, *info]``\n# \n#     where the outputs are the observation, reward and done state respectively.\n#     In this implementation, the info output is discarded (but specific keys can be read\n#     by updating info_dict_reader, see :obj:`set_info_dict_reader` class method).\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom __future__ import annotations\n\nfrom collections import OrderedDict\nfrom typing import Callable, Dict, Optional, Union\n\nimport torch\nfrom tensordict.tensordict import TensorDictBase\n\nfrom torchrl.data.utils import CloudpickleWrapper\nfrom torchrl.envs.common import EnvBase, EnvMetaData\n\n\nclass EnvCreator:\n    \"\"\"Environment creator class.\n\n    EnvCreator is a generic environment creator class that can substitute\n    lambda functions when creating environments in multiprocessing contexts.\n    If the environment created on a subprocess must share information with the\n    main process (e.g. for the VecNorm transform), EnvCreator will pass the\n    pointers to the tensordicts in shared memory to each process such that\n    all of them are synchronised.\n\n    Args:\n        create_env_fn (callable): a callable that returns an EnvBase\n            instance.\n        create_env_kwargs (dict, optional): the kwargs of the env creator.\n        share_memory (bool, optional): if False, the resulting tensordict\n            from the environment won't be placed in shared memory.\n\n    Examples:\n        >>> # We create the same environment on 2 processes using VecNorm\n        >>> # and check that the discounted count of observations match on\n        >>> # both workers, even if one has not executed any step\n        >>> import time\n        >>> from torchrl.envs.libs.gym import GymEnv\n        >>> from torchrl.envs.transforms import VecNorm, TransformedEnv\n        >>> from torchrl.envs import EnvCreator\n        >>> from torch import multiprocessing as mp\n        >>> env_fn = lambda: TransformedEnv(GymEnv(\"Pendulum-v1\"), VecNorm())\n        >>> env_creator = EnvCreator(env_fn)\n        >>>\n        >>> def test_env1(env_creator):\n        ...     env = env_creator()\n        ...     tensordict = env.reset()\n        ...     for _ in range(10):\n        ...         env.rand_step(tensordict)\n        ...         if tensordict.get(\"done\"):\n        ...             tensordict = env.reset(tensordict)\n        ...     print(\"env 1: \", env.transform._td.get((\"next\", \"observation_count\")))\n        >>>\n        >>> def test_env2(env_creator):\n        ...     env = env_creator()\n        ...     time.sleep(5)\n        ...     print(\"env 2: \", env.transform._td.get((\"next\", \"observation_count\")))\n        >>>\n        >>> if __name__ == \"__main__\":\n        ...     ps = []\n        ...     p1 = mp.Process(target=test_env1, args=(env_creator,))\n        ...     p1.start()\n        ...     ps.append(p1)\n        ...     p2 = mp.Process(target=test_env2, args=(env_creator,))\n        ...     p2.start()\n        ...     ps.append(p1)\n        ...     for p in ps:\n        ...         p.join()\n        env 1:  tensor([11.9934])\n        env 2:  tensor([11.9934])\n    \"\"\"\n\n    def __init__(\n        self,\n        create_env_fn: Callable[..., EnvBase],\n        create_env_kwargs: Optional[Dict] = None,\n        share_memory: bool = True,\n    ) -> None:\n        if not isinstance(create_env_fn, EnvCreator):\n            self.create_env_fn = CloudpickleWrapper(create_env_fn)\n        else:\n            self.create_env_fn = create_env_fn\n\n        self.create_env_kwargs = (\n            create_env_kwargs if isinstance(create_env_kwargs, dict) else {}\n        )\n        self.initialized = False\n        self._meta_data = None\n        self._share_memory = share_memory\n        self.init_()\n\n    def share_memory(self, state_dict: OrderedDict) -> None:\n        for key, item in list(state_dict.items()):\n            if isinstance(item, (TensorDictBase,)):\n                if not item.is_shared():\n                    item.share_memory_()\n                else:\n                    print(\n                        f\"{self.env_type}: {item} is already shared\"\n                    )  # , deleting key')\n                    del state_dict[key]\n            elif isinstance(item, OrderedDict):\n                self.share_memory(item)\n            elif isinstance(item, torch.Tensor):\n                del state_dict[key]\n\n    @property\n    def meta_data(self):\n        if self._meta_data is None:\n            raise RuntimeError(\n                \"meta_data is None in EnvCreator. \" \"Make sure init_() has been called.\"\n            )\n        return self._meta_data\n\n    @meta_data.setter\n    def meta_data(self, value: EnvMetaData):\n        self._meta_data = value\n\n    def init_(self) -> EnvCreator:\n        shadow_env = self.create_env_fn(**self.create_env_kwargs)\n        tensordict = shadow_env.reset()\n        shadow_env.rand_step(tensordict)\n        self.env_type = type(shadow_env)\n        self._transform_state_dict = shadow_env.state_dict()\n        if self._share_memory:\n            self.share_memory(self._transform_state_dict)\n        self.initialized = True\n        self.meta_data = EnvMetaData.build_metadata_from_env(shadow_env)\n        shadow_env.close()\n        del shadow_env\n        return self\n\n    def __call__(self, **kwargs) -> EnvBase:\n        if not self.initialized:\n            raise RuntimeError(\"EnvCreator must be initialized before being called.\")\n        kwargs.update(self.create_env_kwargs)  # create_env_kwargs precedes\n        env = self.create_env_fn(**kwargs)\n        env.load_state_dict(self._transform_state_dict, strict=False)\n        return env\n\n    def state_dict(self) -> OrderedDict:\n        if self._transform_state_dict is None:\n            return OrderedDict()\n        return self._transform_state_dict\n\n    def load_state_dict(self, state_dict: OrderedDict) -> None:\n        if self._transform_state_dict is not None:\n            for key, item in state_dict.items():\n                item_to_update = self._transform_state_dict[key]\n                item_to_update.copy_(item)\n\n    def __repr__(self) -> str:\n        substr = \", \".join(\n            [f\"{key}: {type(item)}\" for key, item in self.create_env_kwargs]\n        )\n        return f\"EnvCreator({self.create_env_fn}({substr}))\"\n\n\ndef env_creator(fun: Callable) -> EnvCreator:\n    \"\"\"Helper function to call `EnvCreator`.\"\"\"\n    return EnvCreator(fun)\n\n\ndef get_env_metadata(\n    env_or_creator: Union[EnvBase, Callable], kwargs: Optional[Dict] = None\n):\n    \"\"\"Retrieves a EnvMetaData object from an env.\"\"\"\n    if isinstance(env_or_creator, (EnvBase,)):\n        return EnvMetaData.build_metadata_from_env(env_or_creator)\n    elif not isinstance(env_or_creator, EnvBase) and not isinstance(\n        env_or_creator, EnvCreator\n    ):\n        # then env is a creator", "choices": [{"text": "\"return EnvMetaData.build_metadata_from_env(env_or_creator(**kwargs))\""}], "metadata": {"task_id": "pytorch_rl/8", "ground_truth": "        if kwargs is None:", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "env_creator.py"], "context_start_lineno": 0, "line_no": 175, "query_window": {"context": "            [f\"{key}: {type(item)}\" for key, item in self.create_env_kwargs]\n        )\n        return f\"EnvCreator({self.create_env_fn}({substr}))\"\n\n\ndef env_creator(fun: Callable) -> EnvCreator:\n    \"\"\"Helper function to call `EnvCreator`.\"\"\"\n    return EnvCreator(fun)\n\n\ndef get_env_metadata(\n    env_or_creator: Union[EnvBase, Callable], kwargs: Optional[Dict] = None\n):\n    \"\"\"Retrieves a EnvMetaData object from an env.\"\"\"\n    if isinstance(env_or_creator, (EnvBase,)):\n        return EnvMetaData.build_metadata_from_env(env_or_creator)\n    elif not isinstance(env_or_creator, EnvBase) and not isinstance(\n        env_or_creator, EnvCreator\n    ):\n        # then env is a creator", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "env_creator.py"], "line_no": 175, "task_id": "pytorch_rl/8", "start_line_no": 155, "end_line_no": 175, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        self, info_dict: Dict[str, Any], tensordict: TensorDictBase\n    ) -> TensorDictBase:\n        if not isinstance(info_dict, dict) and len(self.keys):\n            warnings.warn(\n                f\"Found an info_dict of type {type(info_dict)} \"\n                f\"but expected type or subtype `dict`.\"\n            )\n        for key in self.keys:\n            if key in info_dict:\n                tensordict[key] = info_dict[key]\n        return tensordict\n\n    @property\n    def info_spec(self) -> Dict[str, TensorSpec]:\n        return self._info_spec\n\n\nclass GymLikeEnv(_EnvWrapper):\n    \"\"\"A gym-like env is an environment.\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.323943661971831}, {"context": "\n        Args:\n            create_env_fn (Callable or list of callables): an env creator\n                function (or a list of creators)\n            create_env_kwargs (dictionary): kwargs for the env creator\n            policy (TensorDictModule, optional): a policy to be used\n            device (int, str or torch.device, optional): device where to place\n                the policy\n            observation_spec (TensorSpec, optional): spec of the observations\n\n        \"\"\"\n        # if create_env_fn is not None:\n        #     if create_env_kwargs is None:\n        #         create_env_kwargs = {}\n        #     self.create_env_fn = create_env_fn\n        #     if isinstance(create_env_fn, EnvBase):\n        #         env = create_env_fn\n        #     else:\n        #         env = self.create_env_fn(**create_env_kwargs)\n        # else:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "collectors", "collectors.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.31386861313868614}, {"context": "        return f\"CompositeSpec(\\n{sub_str}, device={self._device}, shape={self.shape})\"\n\n    def type_check(\n        self,\n        value: Union[torch.Tensor, TensorDictBase],\n        selected_keys: Union[str, Optional[Sequence[str]]] = None,\n    ):\n        if isinstance(value, torch.Tensor) and isinstance(selected_keys, str):\n            value = {selected_keys: value}\n            selected_keys = [selected_keys]\n\n        for _key in self:\n            if self[_key] is not None and (\n                selected_keys is None or _key in selected_keys\n            ):\n                self._specs[_key].type_check(value[_key], _key)\n\n    def is_in(self, val: Union[dict, TensorDictBase]) -> bool:\n        return all(\n            [", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 1780, "start_line_no": 1770, "end_line_no": 1790, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3103448275862069}, {"context": "                raise KeyError(\n                    f\"The CompositeSpec instance with keys {self.keys()} does not have a '{key}' key.\"\n                )\n        return out\n\n    def __repr__(self) -> str:\n        sub_str = [\n            indent(f\"{k}: {str(item)}\", 4 * \" \") for k, item in self._specs.items()\n        ]\n        sub_str = \",\\n\".join(sub_str)\n        return f\"CompositeSpec(\\n{sub_str}, device={self._device}, shape={self.shape})\"\n\n    def type_check(\n        self,\n        value: Union[torch.Tensor, TensorDictBase],\n        selected_keys: Union[str, Optional[Sequence[str]]] = None,\n    ):\n        if isinstance(value, torch.Tensor) and isinstance(selected_keys, str):\n            value = {selected_keys: value}\n            selected_keys = [selected_keys]", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 1770, "start_line_no": 1760, "end_line_no": 1780, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30952380952380953}, {"context": "            self._info_spec = dict(zip(self.keys, spec))\n        else:\n            if spec is None:\n                spec = {}\n\n            self._info_spec = {\n                key: spec.get(key, UnboundedContinuousTensorSpec()) for key in self.keys\n            }\n\n    def __call__(\n        self, info_dict: Dict[str, Any], tensordict: TensorDictBase\n    ) -> TensorDictBase:\n        if not isinstance(info_dict, dict) and len(self.keys):\n            warnings.warn(\n                f\"Found an info_dict of type {type(info_dict)} \"\n                f\"but expected type or subtype `dict`.\"\n            )\n        for key in self.keys:\n            if key in info_dict:\n                tensordict[key] = info_dict[key]", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2986111111111111}, {"context": "\n    def _get_metadata(\n        self, create_env_fn: List[Callable], create_env_kwargs: List[Dict]\n    ):\n        if self._single_task:\n            # if EnvCreator, the metadata are already there\n            meta_data = get_env_metadata(create_env_fn[0], create_env_kwargs[0])\n            self.meta_data = meta_data.expand(\n                *(self.num_workers, *meta_data.batch_size)\n            )\n        else:\n            n_tasks = len(create_env_fn)\n            self.meta_data = []\n            for i in range(n_tasks):\n                self.meta_data.append(\n                    get_env_metadata(create_env_fn[i], create_env_kwargs[i])\n                )\n        self._set_properties()\n\n    def update_kwargs(self, kwargs: Union[dict, List[dict]]) -> None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.296551724137931}, {"context": "\n        for _key in self:\n            if self[_key] is not None and (\n                selected_keys is None or _key in selected_keys\n            ):\n                self._specs[_key].type_check(value[_key], _key)\n\n    def is_in(self, val: Union[dict, TensorDictBase]) -> bool:\n        return all(\n            [\n                item.is_in(val.get(key))\n                for (key, item) in self._specs.items()\n                if item is not None\n            ]\n        )\n\n    def project(self, val: TensorDictBase) -> TensorDictBase:\n        for key, item in self.items():\n            if item is None:\n                continue", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 1790, "start_line_no": 1780, "end_line_no": 1800, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2923076923076923}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler_flax.py\n# --------------------------------------------------\n#         num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n# \n#         for scheduler_class in self.scheduler_classes:\n#             scheduler_config = self.get_scheduler_config()\n#             scheduler = scheduler_class(**scheduler_config)\n#             state = scheduler.create_state()\n# \n#             sample, _ = self.dummy_sample\n#             residual = 0.1 * sample\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 state = scheduler.set_timesteps(state, num_inference_steps, shape=sample.shape)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             # copy over dummy past residuals (must be done after set_timesteps)\n#             dummy_past_residuals = jnp.array([residual + 0.2, residual + 0.15, residual + 0.1, residual + 0.05])\n#             state = state.replace(ets=dummy_past_residuals[:])\n# \n#             output_0, state = scheduler.step_prk(state, residual, 0, sample, **kwargs)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler_flax.py\n# --------------------------------------------------\n#             sample, _ = self.dummy_sample\n#             residual = 0.1 * sample\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 state = scheduler.set_timesteps(state, num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             outputs_dict = scheduler.step(state, residual, 0, sample, **kwargs)\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 state = scheduler.set_timesteps(state, num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             outputs_tuple = scheduler.step(state, residual, 0, sample, return_dict=False, **kwargs)\n# \n#             recursive_check(outputs_tuple[0], outputs_dict.prev_sample)\n# \n#     def test_step_shape(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n#         return sample\n# \n#     def test_step_shape(self):\n#         kwargs = dict(self.forward_default_kwargs)\n# \n#         num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n# \n#         for scheduler_class in self.scheduler_classes:\n#             scheduler_config = self.get_scheduler_config()\n#             scheduler = scheduler_class(**scheduler_config)\n# \n#             sample = self.dummy_sample\n#             residual = 0.1 * sample\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 scheduler.set_timesteps(num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             # copy over dummy past residuals (must be done after set_timesteps)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n# \n#             sample = self.dummy_sample\n#             residual = 0.1 * sample\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 scheduler.set_timesteps(num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             # copy over dummy past residuals (must be done after set_timesteps)\n#             dummy_past_residuals = [residual + 0.2, residual + 0.15, residual + 0.10]\n#             scheduler.model_outputs = dummy_past_residuals[: scheduler.config.solver_order]\n# \n#             time_step_0 = scheduler.timesteps[5]\n#             time_step_1 = scheduler.timesteps[6]\n# \n#             output_0 = scheduler.step(residual, time_step_0, sample, **kwargs).prev_sample\n#             output_1 = scheduler.step(residual, time_step_1, sample, **kwargs).prev_sample\n# \n#             self.assertEqual(output_0.shape, sample.shape)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler_flax.py\n# --------------------------------------------------\n#             residual = 0.1 * sample\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 state = scheduler.set_timesteps(state, num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             output_0 = scheduler.step(state, residual, 0, sample, **kwargs).prev_sample\n#             output_1 = scheduler.step(state, residual, 1, sample, **kwargs).prev_sample\n# \n#             self.assertEqual(output_0.shape, sample.shape)\n#             self.assertEqual(output_0.shape, output_1.shape)\n# \n#     def test_timesteps(self):\n#         for timesteps in [100, 500, 1000]:\n#             self.check_over_configs(num_train_timesteps=timesteps)\n# \n#     def test_steps_offset(self):\n#         for steps_offset in [0, 1]:\n#             self.check_over_configs(steps_offset=steps_offset)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n 5, 10, 50, 100, 999, 1000]:\n            self.check_over_forward(num_inference_steps=num_inference_steps, time_step=0)\n\n    def test_full_loop_no_noise(self):\n        sample = self.full_loop()\n        result_mean = torch.mean(torch.abs(sample))\n\n        assert abs(result_mean.item() - 0.3301) < 1e-3\n\n    def test_full_loop_with_v_prediction(self):\n        sample = self.full_loop(prediction_type=\"v_prediction\")\n        result_mean = torch.mean(torch.abs(sample))\n\n        assert abs(result_mean.item() - 0.2251) < 1e-3\n\n    def test_fp16_support(self):\n        scheduler_class = self.scheduler_classes[0]\n        scheduler_config = self.get_scheduler_config(thresholding=True, dynamic_thresholding_ratio=0)\n        scheduler = scheduler_class(**scheduler_config)\n\n        num_inference_steps = 10\n        model = self.dummy_model()\n        sample = self.dummy_sample_deter.half()\n        scheduler.set_timesteps(num_inference_steps)\n\n        for i, t in enumerate(scheduler.timesteps):\n            residual = model(sample, t)\n            sample = scheduler.step(residual, t, sample).prev_sample\n\n        assert sample.dtype == torch.float16\n\n\nclass PNDMSchedulerTest(SchedulerCommonTest):\n    scheduler_classes = (PNDMScheduler,)\n    forward_default_kwargs = ((\"num_inference_steps\", 50),)\n\n    def get_scheduler_config(self, **kwargs):\n        config = {\n            \"num_train_timesteps\": 1000,\n            \"beta_start\": 0.0001,\n            \"beta_end\": 0.02,\n            \"beta_schedule\": \"linear\",\n        }\n\n        config.update(**kwargs)\n        return config\n\n    def check_over_configs(self, time_step=0, **config):\n        kwargs = dict(self.forward_default_kwargs)\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n        sample = self.dummy_sample\n        residual = 0.1 * sample\n        dummy_past_residuals = [residual + 0.2, residual + 0.15, residual + 0.1, residual + 0.05]\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config(**config)\n            scheduler = scheduler_class(**scheduler_config)\n            scheduler.set_timesteps(num_inference_steps)\n            # copy over dummy past residuals\n            scheduler.ets = dummy_past_residuals[:]\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n                new_scheduler.set_timesteps(num_inference_steps)\n                # copy over dummy past residuals\n                new_scheduler.ets = dummy_past_residuals[:]\n\n            output = scheduler.step_prk(residual, time_step, sample, **kwargs).prev_sample\n            new_output = new_scheduler.step_prk(residual, time_step, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n            output = scheduler.step_plms(residual, time_step, sample, **kwargs).prev_sample\n            new_output = new_scheduler.step_plms(residual, time_step, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def test_from_save_pretrained(self):\n        pass\n\n    def check_over_forward(self, time_step=0, **forward_kwargs):\n        kwargs = dict(self.forward_default_kwargs)\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n        sample = self.dummy_sample\n        residual = 0.1 * sample\n        dummy_past_residuals = [residual + 0.2, residual + 0.15, residual + 0.1, residual + 0.05]\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            scheduler.set_timesteps(num_inference_steps)\n\n            # copy over dummy past residuals (must be after setting timesteps)\n            scheduler.ets = dummy_past_residuals[:]\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n                # copy over dummy past residuals\n                new_scheduler.set_timesteps(num_inference_steps)\n\n                # copy over dummy past residual (must be after setting timesteps)\n                new_scheduler.ets = dummy_past_residuals[:]\n\n            output = scheduler.step_prk(residual, time_step, sample, **kwargs).prev_sample\n            new_output = new_scheduler.step_prk(residual, time_step, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n            output = scheduler.step_plms(residual, time_step, sample, **kwargs).prev_sample\n            new_output = new_scheduler.step_plms(residual, time_step, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def full_loop(self, **config):\n        scheduler_class = self.scheduler_classes[0]\n        scheduler_config = self.get_scheduler_config(**config)\n        scheduler = scheduler_class(**scheduler_config)\n\n        num_inference_steps = 10\n        model = self.dummy_model()\n        sample = self.dummy_sample_deter\n        scheduler.set_timesteps(num_inference_steps)\n\n        for i, t in enumerate(scheduler.prk_timesteps):\n            residual = model(sample, t)\n            sample = scheduler.step_prk(residual, t, sample).prev_sample\n\n        for i, t in enumerate(scheduler.plms_timesteps):\n            residual = model(sample, t)\n            sample = scheduler.step_plms(residual, t, sample).prev_sample\n\n        return sample\n\n    def test_step_shape(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):", "choices": [{"text": "kwargs[\"num_inference_steps\"] = num_inference_steps"}], "metadata": {"task_id": "huggingface_diffusers/53", "ground_truth": "                kwargs[\"num_inference_steps\"] = num_inference_steps", "fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "context_start_lineno": 1199, "line_no": 1349, "query_window": {"context": "            residual = model(sample, t)\n            sample = scheduler.step_plms(residual, t, sample).prev_sample\n\n        return sample\n\n    def test_step_shape(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 1349, "task_id": "huggingface_diffusers/53", "start_line_no": 1329, "end_line_no": 1349, "window_size": 20, "context_start_lineno": 1199, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()\n\n            sample, _ = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                state = scheduler.set_timesteps(state, num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output_0 = scheduler.step(state, residual, 0, sample, **kwargs).prev_sample\n            output_1 = scheduler.step(state, residual, 1, sample, **kwargs).prev_sample\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7555555555555555}, {"context": "        return sample\n\n    def test_step_shape(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            # copy over dummy past residuals (must be done after set_timesteps)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 1130, "start_line_no": 1120, "end_line_no": 1140, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7553191489361702}, {"context": "\n        num_inference_steps = 10\n        model = self.dummy_model()\n        sample = self.dummy_sample_deter\n        scheduler.set_timesteps(num_inference_steps)\n\n        for i, t in enumerate(scheduler.timesteps):\n            residual = model(sample, t)\n            sample = scheduler.step(residual, t, sample).prev_sample\n\n        return sample\n\n    def test_step_shape(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 1120, "start_line_no": 1110, "end_line_no": 1130, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7441860465116279}, {"context": "                )\n\n        kwargs = dict(self.forward_default_kwargs)\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()\n\n            sample, _ = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                state = scheduler.set_timesteps(state, num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            outputs_dict = scheduler.step(state, residual, 0, sample, **kwargs)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7333333333333333}, {"context": "\n        for i, t in enumerate(state.plms_timesteps):\n            residual = model(sample, t)\n            sample, state = scheduler.step_plms(state, residual, t, sample)\n\n        return sample\n\n    def test_step_shape(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()\n\n            sample, _ = self.dummy_sample\n            residual = 0.1 * sample\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "line_no": 790, "start_line_no": 780, "end_line_no": 800, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7241379310344828}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/algorithms/designers/grid.py\n# --------------------------------------------------\n#     grid_values[parameter_config.name] = _grid_points_from_parameter_config(\n#         parameter_config)\n#   return grid_values\n# \n# \n# def _make_grid_search_parameters(\n#     indices: Sequence[int],\n#     search_space: pyvizier.SearchSpace) -> List[pyvizier.ParameterDict]:\n#   \"\"\"Selects the specific parameters from an index and study_spec based on the natural ordering over a Cartesian Product.\n# \n#   This is looped over a sequence of indices. For a given `index`, this is\n#   effectively equivalent to itertools.product(list_of_lists)[index].\n# \n#   Args:\n#     indices: Index over Cartesian Product.\n#     search_space: SearchSpace to produce the Cartesian Product. Ordering decided\n#       alphabetically over the parameter names.\n# \n#   Returns:\n#     ParameterDict for a trial suggestion.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config.py\n# --------------------------------------------------\n#     return external_values\n# \n#   def trial_parameters(\n#       self, proto: study_pb2.Trial) -> Dict[str, ParameterValueSequence]:\n#     \"\"\"Returns the trial values, cast to external types, if they exist.\n# \n#     Args:\n#       proto:\n# \n#     Returns:\n#       Parameter values dict: cast to each parameter's external_type, if exists.\n#       NOTE that the values in the dict may be a Sequence as opposed to a single\n#       element.\n# \n#     Raises:\n#       ValueError: If the trial parameters do not exist in this search space.\n#       ValueError: If the trial contains duplicate parameters.\n#     \"\"\"\n#     pytrial = proto_converters.TrialConverter.from_proto(proto)\n#     return self._pytrial_parameters(pytrial)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_iterators.py\n# --------------------------------------------------\n# \n#   def __next__(self) -> ParameterConfig:\n#     if self._stop_iteration is not None:\n#       raise self._stop_iteration\n#     return self._next\n# \n#   def choose_value(self, value: ParameterValueTypes) -> None:\n#     \"\"\"Choose the value for the last ParameterConfig.\"\"\"\n#     try:\n#       self._next = self._gen.send(value)\n#     except StopIteration as e:\n#       self._stop_iteration = e\n# \n#   @property\n#   def parameters(self) -> ParameterDict:\n#     \"\"\"Parameters chosen so far.\n# \n#     WARNING: Do not mutate the dict until this Iterator is exhausted.\n#     \"\"\"\n#     return self._parameters\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config.py\n# --------------------------------------------------\n#       parent_name, pc = parameter_configs.pop(0)\n#       parameter_configs.extend(\n#           (pc.name, child) for child in pc.child_parameter_configs)\n#       if pc.name not in remaining_parameters:\n#         continue\n#       if parent_name is not None:\n#         # This is a child parameter. If the parent was not seen,\n#         # skip this parameter config.\n#         if parent_name not in parameter_values:\n#           continue\n#         parent_value = parameter_values[parent_name]\n#         if parent_value not in pc.matching_parent_values:\n#           continue\n#       parameter_values[pc.name] = remaining_parameters[pc.name].value\n#       if pc.external_type is None:\n#         external_value = remaining_parameters[pc.name].value\n#       else:\n#         external_value = remaining_parameters[pc.name].cast(pc.external_type)  # pytype: disable=wrong-arg-types\n#       external_values[pc.name] = external_value\n#       remaining_parameters.pop(pc.name)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/proto_converters.py\n# --------------------------------------------------\n#     parent_proto.ClearField('conditional_parameter_specs')\n#     for child_pair in children:\n#       if len(child_pair) != 2:\n#         raise ValueError(\n#             \"\"\"Each element in children must be a tuple of\n#             (Sequence of valid parent values,  ParameterConfig)\"\"\"\n#         )\n# \n#     logging.debug(\n#         '_set_child_parameter_configs: parent_proto=%s, children=%s',\n#         parent_proto,\n#         children,\n#     )\n#     for unsorted_parent_values, child in children:\n#       parent_values = sorted(unsorted_parent_values)\n#       child_proto = cls.to_proto(child.clone_without_children)\n#       conditional_parameter_spec = (\n#           study_pb2.StudySpec.ParameterSpec.ConditionalParameterSpec(\n#               parameter_spec=child_proto\n#           )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/pyvizier/converters/core.py\n# --------------------------------------------------\n#   # TODO: Deprecate or update so that it returns SearchSpace.\n#   @property\n#   def parameter_configs(self) -> Dict[str, pyvizier.ParameterConfig]:\n#     \"\"\"Returns a dict of the original Parameter configs.\"\"\"\n#     return {\n#         converter.parameter_config.name: converter.parameter_config\n#         for converter in self.parameter_converters\n#     }\n# \n#   @classmethod\n#   def from_study_configs(\n#       cls,\n#       study_configs: Sequence[pyvizier.ProblemStatement],\n#       metric_information: Collection[pyvizier.MetricInformation],\n#       *,\n#       use_study_id_feature: bool = True,\n#   ) -> 'DefaultTrialConverter':\n#     \"\"\"Creates a converter from a list of study configs.\n# \n#     Args:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/proto_converters.py\n# --------------------------------------------------\n# \n#     Raises:\n#       ValueError: If the child configs are invalid\n#     \"\"\"\n#     children: List[Tuple[MonotypeParameterSequence, vz.ParameterConfig]] = []\n#     for child in pc.child_parameter_configs:\n#       children.append((child.matching_parent_values, child))\n#     if not children:\n#       return\n# \n#     parent_proto.ClearField('conditional_parameter_specs')\n#     for child_pair in children:\n#       if len(child_pair) != 2:\n#         raise ValueError(\n#             \"\"\"Each element in children must be a tuple of\n#             (Sequence of valid parent values,  ParameterConfig)\"\"\"\n#         )\n# \n#     logging.debug(\n#         '_set_child_parameter_configs: parent_proto=%s, children=%s',\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n int, str]] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.instance_of((float, int, str))),\n      kw_only=True)\n  _external_type: ExternalType = attr.ib(\n      init=True,\n      converter=lambda v: v or ExternalType.INTERNAL,\n      validator=attr.validators.optional(\n          attr.validators.instance_of(ExternalType)),\n      repr=lambda v: v.name if v is not None else 'None',\n      kw_only=True)\n\n  # TODO: Make this a defaultdict and public.\n  _children: dict[Union[float, int, str, bool], 'SearchSpace'] = attr.ib(\n      init=True,\n      factory=dict,\n      # For equality checks, drop any empty search spaces.\n      eq=lambda d: {k: v for k, v in d.items() if v.parameters},\n      repr=lambda d: json.dumps(d, indent=2, default=repr))\n\n  # TODO: Deprecate this field.\n  _matching_parent_values: MonotypeParameterSequence = attr.ib(\n      init=True, default=tuple(), kw_only=True, eq=False)\n\n  # Experimental feature.\n  fidelity_config: Optional[FidelityConfig] = attr.ib(\n      init=True,\n      default=None,\n      kw_only=True,\n  )\n\n  # Pytype treats instances of EnumTypeWrapper as types, but they can't be\n  # evaluated at runtime, so a Union[] of proto enums has to be a forward\n  # reference below.\n  @classmethod\n  def factory(\n      cls,\n      name: str,\n      *,\n      bounds: Optional[Union[Tuple[int, int], Tuple[float, float]]] = None,\n      feasible_values: Optional[MonotypeParameterSequence] = None,\n      children: Optional[Sequence[Tuple[MonotypeParameterSequence,\n                                        'ParameterConfig']]] = None,\n      fidelity_config: Optional[FidelityConfig] = None,\n      scale_type: Optional[ScaleType] = None,\n      default_value: Optional[Union[float, int, str]] = None,\n      external_type: Optional[ExternalType] = ExternalType.INTERNAL\n  ) -> 'ParameterConfig':\n    \"\"\"Factory method.\n\n    Args:\n      name: The parameter's name. Cannot be empty.\n      bounds: REQUIRED for INTEGER or DOUBLE type. Specifies (min, max). The\n        type of (min, max) determines the created ParameterConfig's type.\n      feasible_values: REQUIRED for DISCRETE or CATEGORICAL type. The elements'\n        type determines the created ParameterConfig's type.\n      children: sequence of tuples formatted as: (matching_parent_values,\n        ParameterConfig). ONLY THE TYPES ARE VALIDATED. If the child\n        ParameterConfig protos already have parent values set, they will be\n        overridden by the provided matching_parent_values.\n      fidelity_config: Fidelity config.  NOT VALIDATED.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      default_value: A default value for the Parameter.\n      external_type: An annotation indicating the type this parameter should be\n        cast to.\n\n    Returns:\n      A ParameterConfig object which wraps a partially validated proto.\n\n    Raises:\n      ValueError: Exactly one of feasible_values and bounds must be convertible\n        to Boolean true. Bounds and numeric feasible_values must be finite.\n        Bounds and feasible_values, if provided, must consist of\n        elements of the same type.\n      TypeError: If children's matching_parent_values are not compatible with\n        the ParameterConfig being created.\n    \"\"\"\n    if not name:\n      raise ValueError('Parameter name cannot be empty.')\n\n    if bool(feasible_values) == bool(bounds):\n      raise ValueError(\n          'While creating Parameter with name={}: exactly one of '\n          '\"feasible_values\" or \"bounds\" must be provided, but given '\n          'feasible_values={} and bounds={}.'.format(name, feasible_values,\n                                                     bounds))\n    if feasible_values:\n      if len(set(feasible_values)) != len(feasible_values):\n        counter = collections.Counter(feasible_values)\n        duplicate_dict = {k: v for k, v in counter.items() if v > 1}\n        raise ValueError(\n            'Feasible values cannot have duplicates: {}'.format(duplicate_dict))\n      if all(isinstance(v, (float, int)) for v in feasible_values):\n        inferred_type = ParameterType.DISCRETE\n        feasible_values, bounds = _get_feasible_points_and_bounds(\n            feasible_values)\n      elif all(isinstance(v, str) for v in feasible_values):\n        inferred_type = ParameterType.CATEGORICAL\n        feasible_values = _get_categories(feasible_values)\n      else:\n        raise ValueError(\n            'Feasible values must all be numeric or strings. Given {}'.format(\n                feasible_values))\n    else:  # bounds were specified.\n      if isinstance(bounds[0], int) and isinstance(bounds[1], int):\n        inferred_type = ParameterType.INTEGER\n        _validate_bounds(bounds)\n      elif isinstance(bounds[0], float) and isinstance(bounds[1], float):\n        inferred_type = ParameterType.DOUBLE\n        _validate_bounds(bounds)\n      else:\n        raise ValueError(\n            'Bounds must both be integers or doubles. Given: {}'.format(bounds))\n\n    if default_value is not None:\n      default_value = _get_default_value(inferred_type, default_value)\n\n    pc = cls(\n        name=name,\n        type=inferred_type,\n        bounds=bounds,\n        feasible_values=feasible_values,\n        scale_type=scale_type,\n        default_value=default_value,\n        fidelity_config=fidelity_config,\n        external_type=external_type)\n    if children:\n      pc = pc._add_children(children)\n    return pc\n\n  @property\n  def name(self) -> str:\n    return self._name\n\n  @property\n  def type(self) -> ParameterType:\n    return self._type\n\n  @property\n  def external_type(self) -> ExternalType:\n    return self._external_type\n\n  @property\n  def scale_type(self) -> Optional[ScaleType]:\n    return self._scale_type\n\n  @property\n  def bounds(self) -> Union[Tuple[float, float], Tuple[int, int]]:\n    \"\"\"Returns the bounds, if set, or raises a ValueError.\"\"\"\n    if self.type == ParameterType.CATEGORICAL:\n      raise ValueError('Accessing bounds of a categorical parameter: %s' %\n                       self.name)\n    return self._bounds\n\n  @property\n  def _child_parameter_configs(self) -> Iterator['ParameterConfig']:\n    for subspace in self._children.values():\n      for param in subspace.parameters:\n        yield param\n\n  # TODO: TO BE DEPRECATED. If we want to continue supporting multiple\n  # matching parent values, expose \"def compact_subspaces(self)\" that returns\n  # Iterator[tuple[MonotypeValueSequence, ParameterConfig]]\n  @property\n  def matching_parent_values(self) -> MonotypeParameterList:\n    \"\"\"Returns the matching parent values, if this is a child parameter.\"\"\"\n    if not self._matching_parent_values:\n      return []\n    return list(self._matching_parent_values)\n\n  # TODO: TO BE DEPRECATED. Replace with\n  # def subspaces() -> Iterator[Value, 'SearchSpace'] which lets users\n  # iterate over all search spaces.\n  @property\n  def child_parameter_configs(self) -> List['ParameterConfig']:", "choices": [{"text": "return list(self._child_parameter_configs)"}], "metadata": {"task_id": "google_vizier/175", "ground_truth": "    return copy.deepcopy(list(self._child_parameter_configs))", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "context_start_lineno": 187, "line_no": 363, "query_window": {"context": "  def _child_parameter_configs(self) -> Iterator['ParameterConfig']:\n    for subspace in self._children.values():\n      for param in subspace.parameters:\n        yield param\n\n  # TODO: TO BE DEPRECATED. If we want to continue supporting multiple\n  # matching parent values, expose \"def compact_subspaces(self)\" that returns\n  # Iterator[tuple[MonotypeValueSequence, ParameterConfig]]\n  @property\n  def matching_parent_values(self) -> MonotypeParameterList:\n    \"\"\"Returns the matching parent values, if this is a child parameter.\"\"\"\n    if not self._matching_parent_values:\n      return []\n    return list(self._matching_parent_values)\n\n  # TODO: TO BE DEPRECATED. Replace with\n  # def subspaces() -> Iterator[Value, 'SearchSpace'] which lets users\n  # iterate over all search spaces.\n  @property\n  def child_parameter_configs(self) -> List['ParameterConfig']:", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 363, "task_id": "google_vizier/175", "start_line_no": 343, "end_line_no": 363, "window_size": 20, "context_start_lineno": 187, "repo": "google_vizier"}}, "top_k_context": [{"context": "  def _set_child_parameter_configs(\n      cls,\n      parent_proto: study_pb2.StudySpec.ParameterSpec,\n      pc: vz.ParameterConfig,\n  ):\n    \"\"\"Sets the parent_proto's conditional_parameter_specs field.\n\n    Args:\n      parent_proto: Modified in place.\n      pc: Parent ParameterConfig to copy children from.\n\n    Raises:\n      ValueError: If the child configs are invalid\n    \"\"\"\n    children: List[Tuple[MonotypeParameterSequence, vz.ParameterConfig]] = []\n    for child in pc.child_parameter_configs:\n      children.append((child.matching_parent_values, child))\n    if not children:\n      return\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "proto_converters.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.27848101265822783}, {"context": "    }\n\n  @property\n  def metric_information(self) -> Dict[str, pyvizier.MetricInformation]:\n    \"\"\"See base class.\"\"\"\n    return {\n        mc.metric_information.name: mc.metric_information\n        for mc in self.metric_converters\n    }\n\n  # TODO: Deprecate or update so that it returns SearchSpace.\n  @property\n  def parameter_configs(self) -> Dict[str, pyvizier.ParameterConfig]:\n    \"\"\"Returns a dict of the original Parameter configs.\"\"\"\n    return {\n        converter.parameter_config.name: converter.parameter_config\n        for converter in self.parameter_converters\n    }\n\n  @classmethod", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "pyvizier", "converters", "core.py"], "line_no": 1050, "start_line_no": 1040, "end_line_no": 1060, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.27741935483870966}, {"context": "\n    Raises:\n      ValueError: If the child configs are invalid\n    \"\"\"\n    children: List[Tuple[MonotypeParameterSequence, vz.ParameterConfig]] = []\n    for child in pc.child_parameter_configs:\n      children.append((child.matching_parent_values, child))\n    if not children:\n      return\n\n    parent_proto.ClearField('conditional_parameter_specs')\n    for child_pair in children:\n      if len(child_pair) != 2:\n        raise ValueError(\n            \"\"\"Each element in children must be a tuple of\n            (Sequence of valid parent values,  ParameterConfig)\"\"\"\n        )\n\n    logging.debug(\n        '_set_child_parameter_configs: parent_proto=%s, children=%s',", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "proto_converters.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.27710843373493976}, {"context": "    \"\"\"Returns the trial paremeter values cast to external types.\"\"\"\n    parameter_values: Dict[str, Union[float, int, str]] = {}\n    external_values: Dict[str, Union[float, int, str, bool]] = {}\n    # parameter_configs is a list of Tuple[parent_name, ParameterConfig].\n    parameter_configs: List[Tuple[Optional[str], vz.ParameterConfig]] = [\n        (None, p) for p in self.search_space.parameters\n    ]\n    remaining_parameters = copy.deepcopy(pytrial.parameters)\n    # Traverse the conditional tree using a BFS.\n    while parameter_configs and remaining_parameters:\n      parent_name, pc = parameter_configs.pop(0)\n      parameter_configs.extend(\n          (pc.name, child) for child in pc.child_parameter_configs)\n      if pc.name not in remaining_parameters:\n        continue\n      if parent_name is not None:\n        # This is a child parameter. If the parent was not seen,\n        # skip this parameter config.\n        if parent_name not in parameter_values:\n          continue", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2711864406779661}, {"context": "        for parameter in search_space.parameters:\n          subspace.add(parameter)\n        search_space = subspace\n      self._parameters[parameter_config.name] = value\n\n  def __next__(self) -> ParameterConfig:\n    if self._stop_iteration is not None:\n      raise self._stop_iteration\n    return self._next\n\n  def choose_value(self, value: ParameterValueTypes) -> None:\n    \"\"\"Choose the value for the last ParameterConfig.\"\"\"\n    try:\n      self._next = self._gen.send(value)\n    except StopIteration as e:\n      self._stop_iteration = e\n\n  @property\n  def parameters(self) -> ParameterDict:\n    \"\"\"Parameters chosen so far.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_iterators.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.26973684210526316}, {"context": "        parent_value = parameter_values[parent_name]\n        if parent_value not in pc.matching_parent_values:\n          continue\n      parameter_values[pc.name] = remaining_parameters[pc.name].value\n      if pc.external_type is None:\n        external_value = remaining_parameters[pc.name].value\n      else:\n        external_value = remaining_parameters[pc.name].cast(pc.external_type)  # pytype: disable=wrong-arg-types\n      external_values[pc.name] = external_value\n      remaining_parameters.pop(pc.name)\n    return external_values\n\n  def trial_parameters(\n      self, proto: study_pb2.Trial) -> Dict[str, ParameterValueSequence]:\n    \"\"\"Returns the trial values, cast to external types, if they exist.\n\n    Args:\n      proto:\n\n    Returns:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.26582278481012656}, {"context": "        f'ParameterConfig type is not one of the supported primitives for ParameterConfig: {parameter_config}'\n    )\n\n\ndef _make_grid_values(\n    search_space: pyvizier.SearchSpace\n) -> Mapping[str, List[pyvizier.ParameterValue]]:\n  \"\"\"Makes the grid values for every parameter.\"\"\"\n  grid_values = {}\n  for parameter_config in search_space.parameters:\n    grid_values[parameter_config.name] = _grid_points_from_parameter_config(\n        parameter_config)\n  return grid_values\n\n\ndef _make_grid_search_parameters(\n    indices: Sequence[int],\n    search_space: pyvizier.SearchSpace) -> List[pyvizier.ParameterDict]:\n  \"\"\"Selects the specific parameters from an index and study_spec based on the natural ordering over a Cartesian Product.\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "algorithms", "designers", "grid.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2631578947368421}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/td3.py\n# --------------------------------------------------\n#                 _next_val_td,\n#                 _qval_td,\n#             ],\n#             0,\n#         )\n# \n#         # cat params\n#         q_params_detach = self.qvalue_network_params.detach()\n#         qvalue_params = torch.cat(\n#             [\n#                 q_params_detach,\n#                 self.target_qvalue_network_params,\n#                 self.qvalue_network_params,\n#             ],\n#             0,\n#         )\n#         tensordict_qval = vmap(self.qvalue_network)(\n#             tensordict_qval,\n#             qvalue_params,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/redq.py\n# --------------------------------------------------\n#         )  # for next value estimation\n#         tensordict_qval = torch.cat(\n#             [\n#                 _actor_loss_td,\n#                 _next_val_td,\n#                 _qval_td,\n#             ],\n#             0,\n#         )\n# \n#         # cat params\n#         q_params_detach = self.qvalue_network_params.detach()\n#         qvalue_params = torch.cat(\n#             [q_params_detach, selected_q_params, self.qvalue_network_params], 0\n#         )\n#         tensordict_qval = vmap(self.qvalue_network)(\n#             tensordict_qval,\n#             qvalue_params,\n#         )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/planners/mppi.py\n# --------------------------------------------------\n#             },\n#             batch_size,\n#         )\n# \n#         for _ in range(self.optim_steps):\n#             actions_means = container.get((\"stats\", \"_action_means\"))\n#             actions_stds = container.get((\"stats\", \"_action_stds\"))\n#             actions = actions_means + actions_stds * torch.randn(\n#                 *action_shape,\n#                 device=actions_means.device,\n#                 dtype=actions_means.dtype,\n#             )\n#             actions = self.env.action_spec.project(actions)\n#             optim_tensordict = container.get(\"tensordict\").clone()\n#             policy = _PrecomputedActionsSequentialSetter(actions)\n#             optim_tensordict = self.env.rollout(\n#                 max_steps=self.planning_horizon,\n#                 policy=policy,\n#                 auto_reset=False,\n#                 tensordict=optim_tensordict,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/planners/mppi.py\n# --------------------------------------------------\n#         self.register_buffer(\"temperature\", torch.tensor(temperature))\n# \n#     def planning(self, tensordict: TensorDictBase) -> torch.Tensor:\n#         batch_size = tensordict.batch_size\n#         action_shape = (\n#             *batch_size,\n#             self.num_candidates,\n#             self.planning_horizon,\n#             *self.action_spec.shape,\n#         )\n#         action_stats_shape = (\n#             *batch_size,\n#             1,\n#             self.planning_horizon,\n#             *self.action_spec.shape,\n#         )\n#         action_topk_shape = (\n#             *batch_size,\n#             self.top_k,\n#             self.planning_horizon,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/planners/mppi.py\n# --------------------------------------------------\n#         action_stats_shape = (\n#             *batch_size,\n#             1,\n#             self.planning_horizon,\n#             *self.action_spec.shape,\n#         )\n#         action_topk_shape = (\n#             *batch_size,\n#             self.top_k,\n#             self.planning_horizon,\n#             *self.action_spec.shape,\n#         )\n#         adv_topk_shape = (\n#             *batch_size,\n#             self.top_k,\n#             1,\n#             1,\n#         )\n#         K_DIM = len(self.action_spec.shape) - 4\n#         expanded_original_tensordict = (\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/planners/mppi.py\n# --------------------------------------------------\n#         container = TensorDict(\n#             {\n#                 \"tensordict\": expanded_original_tensordict,\n#                 \"stats\": TensorDict(\n#                     {\n#                         \"_action_means\": _action_means,\n#                         \"_action_stds\": _action_stds,\n#                     },\n#                     [*batch_size, 1, self.planning_horizon],\n#                 ),\n#             },\n#             batch_size,\n#         )\n# \n#         for _ in range(self.optim_steps):\n#             actions_means = container.get((\"stats\", \"_action_means\"))\n#             actions_stds = container.get((\"stats\", \"_action_stds\"))\n#             actions = actions_means + actions_stds * torch.randn(\n#                 *action_shape,\n#                 device=actions_means.device,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/planners/mppi.py\n# --------------------------------------------------\n#             tensordict.unsqueeze(-1)\n#             .expand(*batch_size, self.num_candidates)\n#             .to_tensordict()\n#         )\n#         _action_means = torch.zeros(\n#             *action_stats_shape,\n#             device=tensordict.device,\n#             dtype=self.env.action_spec.dtype,\n#         )\n#         _action_stds = torch.ones_like(_action_means)\n#         container = TensorDict(\n#             {\n#                 \"tensordict\": expanded_original_tensordict,\n#                 \"stats\": TensorDict(\n#                     {\n#                         \"_action_means\": _action_means,\n#                         \"_action_stds\": _action_stds,\n#                     },\n#                     [*batch_size, 1, self.planning_horizon],\n#                 ),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/planners/mppi.py\n# --------------------------------------------------\n#             *self.action_spec.shape,\n#         )\n#         adv_topk_shape = (\n#             *batch_size,\n#             self.top_k,\n#             1,\n#             1,\n#         )\n#         K_DIM = len(self.action_spec.shape) - 4\n#         expanded_original_tensordict = (\n#             tensordict.unsqueeze(-1)\n#             .expand(*batch_size, self.num_candidates)\n#             .to_tensordict()\n#         )\n#         _action_means = torch.zeros(\n#             *action_stats_shape,\n#             device=tensordict.device,\n#             dtype=self.env.action_spec.dtype,\n#         )\n#         _action_stds = torch.ones_like(_action_means)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport torch\nfrom tensordict.tensordict import TensorDict, TensorDictBase\n\nfrom torchrl.envs import EnvBase\nfrom torchrl.modules.planners.common import MPCPlannerBase\n\n\nclass CEMPlanner(MPCPlannerBase):\n    \"\"\"CEMPlanner Module.\n\n    Reference: The cross-entropy method for optimization, Botev et al. 2013\n\n    This module will perform a CEM planning step when given a TensorDict\n    containing initial states.\n    The CEM planning step is performed by sampling actions from a Gaussian\n    distribution with zero mean and unit variance.\n    The sampled actions are then used to perform a rollout in the environment.\n    The cumulative rewards obtained with the rollout is then\n    ranked. We select the top-k episodes and use their actions to update the\n    mean and standard deviation of the actions distribution.\n    The CEM planning step is repeated for a specified number of steps.\n\n    A call to the module returns the actions that empirically maximised the\n    returns given a planning horizon\n\n    Args:\n        env (EnvBase): The environment to perform the planning step on (can be\n            `ModelBasedEnv` or :obj:`EnvBase`).\n        planning_horizon (int): The length of the simulated trajectories\n        optim_steps (int): The number of optimization steps used by the MPC\n            planner\n        num_candidates (int): The number of candidates to sample from the\n            Gaussian distributions.\n        top_k (int): The number of top candidates to use to\n            update the mean and standard deviation of the Gaussian distribution.\n        reward_key (str, optional): The key in the TensorDict to use to\n            retrieve the reward. Defaults to \"reward\".\n        action_key (str, optional): The key in the TensorDict to use to store\n            the action. Defaults to \"action\"\n\n    Examples:\n        >>> from tensordict import TensorDict\n        >>> from torchrl.data import CompositeSpec, UnboundedContinuousTensorSpec\n        >>> from torchrl.envs.model_based import ModelBasedEnvBase\n        >>> from torchrl.modules import SafeModule\n        >>> class MyMBEnv(ModelBasedEnvBase):\n        ...     def __init__(self, world_model, device=\"cpu\", dtype=None, batch_size=None):\n        ...         super().__init__(world_model, device=device, dtype=dtype, batch_size=batch_size)\n        ...         self.observation_spec = CompositeSpec(\n        ...             next_hidden_observation=UnboundedContinuousTensorSpec((4,))\n        ...         )\n        ...         self.input_spec = CompositeSpec(\n        ...             hidden_observation=UnboundedContinuousTensorSpec((4,)),\n        ...             action=UnboundedContinuousTensorSpec((1,)),\n        ...         )\n        ...         self.reward_spec = UnboundedContinuousTensorSpec((1,))\n        ...\n        ...     def _reset(self, tensordict: TensorDict) -> TensorDict:\n        ...         tensordict = TensorDict(\n        ...             {},\n        ...             batch_size=self.batch_size,\n        ...             device=self.device,\n        ...         )\n        ...         tensordict = tensordict.update(\n        ...             self.input_spec.rand())\n        ...         tensordict = tensordict.update(\n        ...             self.observation_spec.rand())\n        ...         return tensordict\n        ...\n        >>> from torchrl.modules import MLP, WorldModelWrapper\n        >>> import torch.nn as nn\n        >>> world_model = WorldModelWrapper(\n        ...     SafeModule(\n        ...         MLP(out_features=4, activation_class=nn.ReLU, activate_last_layer=True, depth=0),\n        ...         in_keys=[\"hidden_observation\", \"action\"],\n        ...         out_keys=[\"hidden_observation\"],\n        ...     ),\n        ...     SafeModule(\n        ...         nn.Linear(4, 1),\n        ...         in_keys=[\"hidden_observation\"],\n        ...         out_keys=[\"reward\"],\n        ...     ),\n        ... )\n        >>> env = MyMBEnv(world_model)\n        >>> # Build a planner and use it as actor\n        >>> planner = CEMPlanner(env, 10, 11, 7, 3)\n        >>> env.rollout(5, planner)\n        TensorDict(\n            fields={\n                action: Tensor(torch.Size([5, 1]), dtype=torch.float32),\n                done: Tensor(torch.Size([5, 1]), dtype=torch.bool),\n                hidden_observation: Tensor(torch.Size([5, 4]), dtype=torch.float32),\n                next: LazyStackedTensorDict(\n                    fields={\n                        hidden_observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},\n                    batch_size=torch.Size([5]),\n                    device=cpu,\n                    is_shared=False),\n                reward: Tensor(torch.Size([5, 1]), dtype=torch.float32)},\n            batch_size=torch.Size([5]),\n            device=cpu,\n            is_shared=False)\n    \"\"\"\n\n    def __init__(\n        self,\n        env: EnvBase,\n        planning_horizon: int,\n        optim_steps: int,\n        num_candidates: int,\n        top_k: int,\n        reward_key: str = \"reward\",\n        action_key: str = \"action\",\n    ):\n        super().__init__(env=env, action_key=action_key)\n        self.planning_horizon = planning_horizon\n        self.optim_steps = optim_steps\n        self.num_candidates = num_candidates\n        self.top_k = top_k\n        self.reward_key = reward_key\n\n    def planning(self, tensordict: TensorDictBase) -> torch.Tensor:\n        batch_size = tensordict.batch_size\n        action_shape = (\n            *batch_size,\n            self.num_candidates,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        action_stats_shape = (\n            *batch_size,\n            1,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        action_topk_shape = (\n            *batch_size,\n            self.top_k,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        TIME_DIM = len(self.action_spec.shape) - 3\n        K_DIM = len(self.action_spec.shape) - 4\n        expanded_original_tensordict = (\n            tensordict.unsqueeze(-1)\n            .expand(*batch_size, self.num_candidates)", "choices": [{"text": ".expand(*action_shape)"}], "metadata": {"task_id": "pytorch_rl/141", "ground_truth": "            .to_tensordict()", "fpath_tuple": ["pytorch_rl", "torchrl", "modules", "planners", "cem.py"], "context_start_lineno": 0, "line_no": 151, "query_window": {"context": "            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        action_stats_shape = (\n            *batch_size,\n            1,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        action_topk_shape = (\n            *batch_size,\n            self.top_k,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        TIME_DIM = len(self.action_spec.shape) - 3\n        K_DIM = len(self.action_spec.shape) - 4\n        expanded_original_tensordict = (\n            tensordict.unsqueeze(-1)\n            .expand(*batch_size, self.num_candidates)", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "planners", "cem.py"], "line_no": 151, "task_id": "pytorch_rl/141", "start_line_no": 131, "end_line_no": 151, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        action_stats_shape = (\n            *batch_size,\n            1,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        action_topk_shape = (\n            *batch_size,\n            self.top_k,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        adv_topk_shape = (\n            *batch_size,\n            self.top_k,\n            1,\n            1,\n        )\n        K_DIM = len(self.action_spec.shape) - 4\n        expanded_original_tensordict = (", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "planners", "mppi.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7017543859649122}, {"context": "            *self.action_spec.shape,\n        )\n        adv_topk_shape = (\n            *batch_size,\n            self.top_k,\n            1,\n            1,\n        )\n        K_DIM = len(self.action_spec.shape) - 4\n        expanded_original_tensordict = (\n            tensordict.unsqueeze(-1)\n            .expand(*batch_size, self.num_candidates)\n            .to_tensordict()\n        )\n        _action_means = torch.zeros(\n            *action_stats_shape,\n            device=tensordict.device,\n            dtype=self.env.action_spec.dtype,\n        )\n        _action_stds = torch.ones_like(_action_means)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "planners", "mppi.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6363636363636364}, {"context": "            tensordict.unsqueeze(-1)\n            .expand(*batch_size, self.num_candidates)\n            .to_tensordict()\n        )\n        _action_means = torch.zeros(\n            *action_stats_shape,\n            device=tensordict.device,\n            dtype=self.env.action_spec.dtype,\n        )\n        _action_stds = torch.ones_like(_action_means)\n        container = TensorDict(\n            {\n                \"tensordict\": expanded_original_tensordict,\n                \"stats\": TensorDict(\n                    {\n                        \"_action_means\": _action_means,\n                        \"_action_stds\": _action_stds,\n                    },\n                    [*batch_size, 1, self.planning_horizon],\n                ),", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "planners", "mppi.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5}, {"context": "        self.register_buffer(\"temperature\", torch.tensor(temperature))\n\n    def planning(self, tensordict: TensorDictBase) -> torch.Tensor:\n        batch_size = tensordict.batch_size\n        action_shape = (\n            *batch_size,\n            self.num_candidates,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        action_stats_shape = (\n            *batch_size,\n            1,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )\n        action_topk_shape = (\n            *batch_size,\n            self.top_k,\n            self.planning_horizon,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "planners", "mppi.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.48}, {"context": "        reward_key: str = \"reward\",\n        action_key: str = \"action\",\n    ):\n        super().__init__(env=env, action_key=action_key)\n        self.advantage_module = advantage_module\n        self.planning_horizon = planning_horizon\n        self.optim_steps = optim_steps\n        self.num_candidates = num_candidates\n        self.top_k = top_k\n        self.reward_key = reward_key\n        self.register_buffer(\"temperature\", torch.tensor(temperature))\n\n    def planning(self, tensordict: TensorDictBase) -> torch.Tensor:\n        batch_size = tensordict.batch_size\n        action_shape = (\n            *batch_size,\n            self.num_candidates,\n            self.planning_horizon,\n            *self.action_spec.shape,\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "planners", "mppi.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.35051546391752575}, {"context": "        container = TensorDict(\n            {\n                \"tensordict\": expanded_original_tensordict,\n                \"stats\": TensorDict(\n                    {\n                        \"_action_means\": _action_means,\n                        \"_action_stds\": _action_stds,\n                    },\n                    [*batch_size, 1, self.planning_horizon],\n                ),\n            },\n            batch_size,\n        )\n\n        for _ in range(self.optim_steps):\n            actions_means = container.get((\"stats\", \"_action_means\"))\n            actions_stds = container.get((\"stats\", \"_action_stds\"))\n            actions = actions_means + actions_stds * torch.randn(\n                *action_shape,\n                device=actions_means.device,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "planners", "mppi.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3020833333333333}, {"context": "            .expand(self.num_qvalue_nets, *tensordict_actor[0].batch_size)\n        )  # for actor loss\n        _qval_td = tensordict_select.select(*self.qvalue_network.in_keys).expand(\n            self.num_qvalue_nets,\n            *tensordict_select.select(*self.qvalue_network.in_keys).batch_size,\n        )  # for qvalue loss\n        _next_val_td = (\n            tensordict_actor[1]\n            .select(*self.qvalue_network.in_keys)\n            .expand(self.sub_sample_len, *tensordict_actor[1].batch_size)\n        )  # for next value estimation\n        tensordict_qval = torch.cat(\n            [\n                _actor_loss_td,\n                _next_val_td,\n                _qval_td,\n            ],\n            0,\n        )\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "redq.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.29347826086956524}, {"context": "            *tensordict_select.select(*self.qvalue_network.in_keys).batch_size,\n        )  # for qvalue loss\n        _next_val_td = (\n            tensordict_actor[1]\n            .select(*self.qvalue_network.in_keys)\n            .expand(self.num_qvalue_nets, *tensordict_actor[1].batch_size)\n        )  # for next value estimation\n        tensordict_qval = torch.cat(\n            [\n                _actor_loss_td,\n                _next_val_td,\n                _qval_td,\n            ],\n            0,\n        )\n\n        # cat params\n        q_params_detach = self.qvalue_network_params.detach()\n        qvalue_params = torch.cat(\n            [", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "td3.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2872340425531915}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/module.py\n# --------------------------------------------------\n# \n# logger = get_logger(__name__)\n# \n# \n# class FileFreeLock(BaseFileLock):\n#     \"\"\"Thread lock until a file **cannot** be locked\"\"\"\n# \n#     def __init__(self, lock_file, *args, **kwargs):\n#         self.filelock = FileLock(lock_file)\n#         super().__init__(lock_file, *args, **kwargs)\n# \n#     def _acquire(self):\n#         try:\n#             self.filelock.acquire(timeout=0.01, poll_intervall=0.02)  # Try to lock once\n#         except Timeout:\n#             # We couldn't acquire the lock, the file is locked!\n#             self._lock_file_fd = self.filelock.lock_file\n#         else:\n#             # We were able to acquire the lock, the file is not yet locked!\n#             self.filelock.release()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/logging.py\n# --------------------------------------------------\n#     def __getattr__(self, _):\n#         \"\"\"Return empty function.\"\"\"\n# \n#         def empty_fn(*args, **kwargs):  # pylint: disable=unused-argument\n#             return\n# \n#         return empty_fn\n# \n#     def __enter__(self):\n#         return self\n# \n#     def __exit__(self, type_, value, traceback):\n#         return\n# \n# \n# _tqdm_active = True\n# \n# \n# class _tqdm_cls:\n#     def __call__(self, *args, **kwargs):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/module.py\n# --------------------------------------------------\n# \n#     def _acquire(self):\n#         try:\n#             self.filelock.acquire(timeout=0.01, poll_intervall=0.02)  # Try to lock once\n#         except Timeout:\n#             # We couldn't acquire the lock, the file is locked!\n#             self._lock_file_fd = self.filelock.lock_file\n#         else:\n#             # We were able to acquire the lock, the file is not yet locked!\n#             self.filelock.release()\n#             self._lock_file_fd = None\n# \n#     def _release(self):\n#         self._lock_file_fd = None\n# \n# \n# # lists - summarize long lists similarly to NumPy\n# # arrays/tensors - let the frameworks control formatting\n# def summarize_if_long_list(obj):\n#     if not type(obj) == list or len(obj) <= 6:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/logging.py\n# --------------------------------------------------\n#     def get_lock(self):\n#         if _tqdm_active:\n#             return tqdm_lib.tqdm.get_lock()\n# \n# \n# tqdm = _tqdm_cls()\n# \n# \n# def is_progress_bar_enabled() -> bool:\n#     \"\"\"Return a boolean indicating whether tqdm progress bars are enabled.\"\"\"\n#     global _tqdm_active\n#     return bool(_tqdm_active)\n# \n# \n# def enable_progress_bar():\n#     \"\"\"Enable tqdm progress bar.\"\"\"\n#     global _tqdm_active\n#     _tqdm_active = True\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/evaluator/utils.py\n# --------------------------------------------------\n# from datasets import Dataset, get_dataset_split_names\n# \n# \n# class DatasetColumn(list):\n#     \"\"\"Helper class to avoid loading a dataset column into memory when accessing it.\"\"\"\n# \n#     def __init__(self, dataset: Dataset, key: str):\n#         self.dataset = dataset\n#         self.key = key\n# \n#     def __len__(self):\n#         return len(self.dataset)\n# \n#     def __getitem__(self, i):\n#         return self.dataset[i][self.key]\n# \n#     def __iter__(self):\n#         return (self.dataset[i][self.key] for i in range(len(self)))\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/google_bleu/tokenizer_13a.py\n# metrics/bleu/tokenizer_13a.py\n# --------------------------------------------------\n#         \"\"\"\n#         Tokenizes an input line with the tokenizer.\n#         :param line: a segment to tokenize\n#         :return: the tokenized line\n#         \"\"\"\n#         return line\n# \n# \n# class TokenizerRegexp(BaseTokenizer):\n#     def signature(self):\n#         return \"re\"\n# \n#     def __init__(self):\n#         self._re = [\n#             # language-dependent part (assuming Western languages)\n#             (re.compile(r\"([\\{-\\~\\[-\\` -\\&\\(-\\+\\:-\\@\\/])\"), r\" \\1 \"),\n#             # tokenize period and comma unless preceded by a digit\n#             (re.compile(r\"([^0-9])([\\.,])\"), r\"\\1 \\2 \"),\n#             # tokenize period and comma unless followed by a digit\n#             (re.compile(r\"([\\.,])([^0-9])\"), r\" \\1 \\2\"),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/logging.py\n# --------------------------------------------------\n# \n#     def __exit__(self, type_, value, traceback):\n#         return\n# \n# \n# _tqdm_active = True\n# \n# \n# class _tqdm_cls:\n#     def __call__(self, *args, **kwargs):\n#         if _tqdm_active:\n#             return tqdm_lib.tqdm(*args, **kwargs)\n#         else:\n#             return EmptyTqdm(*args, **kwargs)\n# \n#     def set_lock(self, *args, **kwargs):\n#         self._lock = None\n#         if _tqdm_active:\n#             return tqdm_lib.tqdm.set_lock(*args, **kwargs)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/logging.py\n# --------------------------------------------------\n#         if _tqdm_active:\n#             return tqdm_lib.tqdm(*args, **kwargs)\n#         else:\n#             return EmptyTqdm(*args, **kwargs)\n# \n#     def set_lock(self, *args, **kwargs):\n#         self._lock = None\n#         if _tqdm_active:\n#             return tqdm_lib.tqdm.set_lock(*args, **kwargs)\n# \n#     def get_lock(self):\n#         if _tqdm_active:\n#             return tqdm_lib.tqdm.get_lock()\n# \n# \n# tqdm = _tqdm_cls()\n# \n# \n# def is_progress_bar_enabled() -> bool:\n#     \"\"\"Return a boolean indicating whether tqdm progress bars are enabled.\"\"\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2020 The HuggingFace Datasets Authors and the current dataset script contributor.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This code is adapted from OpenAI's release\n# https://github.com/openai/human-eval/blob/master/human_eval/execution.py\n\nimport contextlib\nimport faulthandler\nimport io\nimport multiprocessing\nimport os\nimport platform\nimport signal\nimport tempfile\n\n\ndef check_correctness(check_program, timeout, task_id, completion_id):\n    \"\"\"\n    Evaluates the functional correctness of a completion by running the test\n    suite provided in the problem.\n\n    :param completion_id: an optional completion ID so we can match\n        the results later even if execution finishes asynchronously.\n    \"\"\"\n    manager = multiprocessing.Manager()\n    result = manager.list()\n\n    p = multiprocessing.Process(target=unsafe_execute, args=(check_program, result, timeout))\n    p.start()\n    p.join(timeout=timeout + 1)\n    if p.is_alive():\n        p.kill()\n\n    if not result:\n        result.append(\"timed out\")\n\n    return dict(\n        task_id=task_id,\n        passed=result[0] == \"passed\",\n        result=result[0],\n        completion_id=completion_id,\n    )\n\n\ndef unsafe_execute(check_program, result, timeout):\n\n    with create_tempdir():\n\n        # These system calls are needed when cleaning up tempdir.\n        import os\n        import shutil\n\n        rmtree = shutil.rmtree\n        rmdir = os.rmdir\n        chdir = os.chdir\n\n        # Disable functionalities that can make destructive changes to the test.\n        reliability_guard()\n\n        # Run program.\n        try:\n            exec_globals = {}\n            with swallow_io():\n                with time_limit(timeout):\n                    exec(check_program, exec_globals)\n            result.append(\"passed\")\n        except TimeoutException:\n            result.append(\"timed out\")\n        except BaseException as e:\n            result.append(f\"failed: {e}\")\n\n        # Needed for cleaning up.\n        shutil.rmtree = rmtree\n        os.rmdir = rmdir\n        os.chdir = chdir\n\n\n@contextlib.contextmanager\ndef time_limit(seconds):\n    def signal_handler(signum, frame):\n        raise TimeoutException(\"Timed out!\")\n\n    signal.setitimer(signal.ITIMER_REAL, seconds)\n    signal.signal(signal.SIGALRM, signal_handler)\n    try:\n        yield\n    finally:\n        signal.setitimer(signal.ITIMER_REAL, 0)\n\n\n@contextlib.contextmanager\ndef swallow_io():\n    stream = WriteOnlyStringIO()\n    with contextlib.redirect_stdout(stream):\n        with contextlib.redirect_stderr(stream):\n            with redirect_stdin(stream):\n                yield\n\n\n@contextlib.contextmanager\ndef create_tempdir():\n    with tempfile.TemporaryDirectory() as dirname:\n        with chdir(dirname):\n            yield dirname\n\n\nclass TimeoutException(Exception):\n    pass\n\n\nclass WriteOnlyStringIO(io.StringIO):\n    \"\"\"StringIO that throws an exception when it's read from\"\"\"\n\n    def read(self, *args, **kwargs):\n        raise OSError\n\n    def readline(self, *args, **kwargs):\n        raise OSError\n\n    def readlines(self, *args, **kwargs):\n        raise OSError\n\n    def readable(self, *args, **kwargs):\n        \"\"\"Returns True if the IO object can be read.\"\"\"", "choices": [{"text": "def reliability_guard():"}], "metadata": {"task_id": "huggingface_evaluate/172", "ground_truth": "        return False", "fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "execute.py"], "context_start_lineno": 0, "line_no": 135, "query_window": {"context": "\n\nclass TimeoutException(Exception):\n    pass\n\n\nclass WriteOnlyStringIO(io.StringIO):\n    \"\"\"StringIO that throws an exception when it's read from\"\"\"\n\n    def read(self, *args, **kwargs):\n        raise OSError\n\n    def readline(self, *args, **kwargs):\n        raise OSError\n\n    def readlines(self, *args, **kwargs):\n        raise OSError\n\n    def readable(self, *args, **kwargs):\n        \"\"\"Returns True if the IO object can be read.\"\"\"", "metadata": {"fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "execute.py"], "line_no": 135, "task_id": "huggingface_evaluate/172", "start_line_no": 115, "end_line_no": 135, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "\n    def __exit__(self, type_, value, traceback):\n        return\n\n\n_tqdm_active = True\n\n\nclass _tqdm_cls:\n    def __call__(self, *args, **kwargs):\n        if _tqdm_active:\n            return tqdm_lib.tqdm(*args, **kwargs)\n        else:\n            return EmptyTqdm(*args, **kwargs)\n\n    def set_lock(self, *args, **kwargs):\n        self._lock = None\n        if _tqdm_active:\n            return tqdm_lib.tqdm.set_lock(*args, **kwargs)\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "logging.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.19767441860465115}, {"context": "    def __getattr__(self, _):\n        \"\"\"Return empty function.\"\"\"\n\n        def empty_fn(*args, **kwargs):  # pylint: disable=unused-argument\n            return\n\n        return empty_fn\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, type_, value, traceback):\n        return\n\n\n_tqdm_active = True\n\n\nclass _tqdm_cls:\n    def __call__(self, *args, **kwargs):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "logging.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1935483870967742}, {"context": "    \"\"\"A base dummy tokenizer to derive from.\"\"\"\n\n    def signature(self):\n        \"\"\"\n        Returns a signature for the tokenizer.\n        :return: signature string\n        \"\"\"\n        return \"none\"\n\n    def __call__(self, line):\n        \"\"\"\n        Tokenizes an input line with the tokenizer.\n        :param line: a segment to tokenize\n        :return: the tokenized line\n        \"\"\"\n        return line\n\n\nclass TokenizerRegexp(BaseTokenizer):\n    def signature(self):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "google_bleu", "tokenizer_13a.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}, {"fpath_tuple": ["huggingface_evaluate", "metrics", "bleu", "tokenizer_13a.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.19101123595505617}, {"context": "from datasets import Dataset, get_dataset_split_names\n\n\nclass DatasetColumn(list):\n    \"\"\"Helper class to avoid loading a dataset column into memory when accessing it.\"\"\"\n\n    def __init__(self, dataset: Dataset, key: str):\n        self.dataset = dataset\n        self.key = key\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluator", "utils.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.18604651162790697}, {"context": "        if _tqdm_active:\n            return tqdm_lib.tqdm(*args, **kwargs)\n        else:\n            return EmptyTqdm(*args, **kwargs)\n\n    def set_lock(self, *args, **kwargs):\n        self._lock = None\n        if _tqdm_active:\n            return tqdm_lib.tqdm.set_lock(*args, **kwargs)\n\n    def get_lock(self):\n        if _tqdm_active:\n            return tqdm_lib.tqdm.get_lock()\n\n\ntqdm = _tqdm_cls()\n\n\ndef is_progress_bar_enabled() -> bool:\n    \"\"\"Return a boolean indicating whether tqdm progress bars are enabled.\"\"\"", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "logging.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.18556701030927836}, {"context": "\nlogger = get_logger(__name__)\n\n\nclass FileFreeLock(BaseFileLock):\n    \"\"\"Thread lock until a file **cannot** be locked\"\"\"\n\n    def __init__(self, lock_file, *args, **kwargs):\n        self.filelock = FileLock(lock_file)\n        super().__init__(lock_file, *args, **kwargs)\n\n    def _acquire(self):\n        try:\n            self.filelock.acquire(timeout=0.01, poll_intervall=0.02)  # Try to lock once\n        except Timeout:\n            # We couldn't acquire the lock, the file is locked!\n            self._lock_file_fd = self.filelock.lock_file\n        else:\n            # We were able to acquire the lock, the file is not yet locked!\n            self.filelock.release()", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.17796610169491525}, {"context": "\nclass EmptyTqdm:\n    \"\"\"Dummy tqdm which doesn't do anything.\"\"\"\n\n    def __init__(self, *args, **kwargs):  # pylint: disable=unused-argument\n        self._iterator = args[0] if args else None\n\n    def __iter__(self):\n        return iter(self._iterator)\n\n    def __getattr__(self, _):\n        \"\"\"Return empty function.\"\"\"\n\n        def empty_fn(*args, **kwargs):  # pylint: disable=unused-argument\n            return\n\n        return empty_fn\n\n    def __enter__(self):\n        return self", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "logging.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.17142857142857143}, {"context": "from datasets.features.features import _check_non_null_non_empty_recursive\nfrom datasets.utils.filelock import BaseFileLock, FileLock, Timeout\nfrom datasets.utils.py_utils import copyfunc, temp_seed, zip_dict\n\nfrom . import config\nfrom .info import EvaluationModuleInfo\nfrom .naming import camelcase_to_snakecase\nfrom .utils.file_utils import DownloadConfig\nfrom .utils.logging import get_logger\n\n\nlogger = get_logger(__name__)\n\n\nclass FileFreeLock(BaseFileLock):\n    \"\"\"Thread lock until a file **cannot** be locked\"\"\"\n\n    def __init__(self, lock_file, *args, **kwargs):\n        self.filelock = FileLock(lock_file)\n        super().__init__(lock_file, *args, **kwargs)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1694915254237288}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_2d_blocks_flax.py\n# --------------------------------------------------\n#             Parameters `dtype`\n#     \"\"\"\n#     in_channels: int\n#     out_channels: int\n#     dropout: float = 0.0\n#     num_layers: int = 1\n#     attn_num_head_channels: int = 1\n#     add_downsample: bool = True\n#     use_linear_projection: bool = False\n#     only_cross_attention: bool = False\n#     dtype: jnp.dtype = jnp.float32\n# \n#     def setup(self):\n#         resnets = []\n#         attentions = []\n# \n#         for i in range(self.num_layers):\n#             in_channels = self.in_channels if i == 0 else self.out_channels\n# \n#             res_block = FlaxResnetBlock2D(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/attention_flax.py\n# --------------------------------------------------\n#         n_heads (:obj:`int`):\n#             Number of heads\n#         d_head (:obj:`int`):\n#             Hidden states dimension inside each head\n#         dropout (:obj:`float`, *optional*, defaults to 0.0):\n#             Dropout rate\n#         only_cross_attention (`bool`, defaults to `False`):\n#             Whether to only apply cross attention.\n#         dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n#             Parameters `dtype`\n#     \"\"\"\n#     dim: int\n#     n_heads: int\n#     d_head: int\n#     dropout: float = 0.0\n#     only_cross_attention: bool = False\n#     dtype: jnp.dtype = jnp.float32\n# \n#     def setup(self):\n#         # self attention (or cross_attention if only_cross_attention is True)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/vae_flax.py\n# --------------------------------------------------\n#     r\"\"\"\n#     Flax Resnet blocks-based Decoder block for diffusion-based VAE.\n# \n#     Parameters:\n#         in_channels (:obj:`int`):\n#             Input channels\n#         out_channels (:obj:`int`):\n#             Output channels\n#         dropout (:obj:`float`, *optional*, defaults to 0.0):\n#             Dropout rate\n#         num_layers (:obj:`int`, *optional*, defaults to 1):\n#             Number of Resnet layer block\n#         resnet_groups (:obj:`int`, *optional*, defaults to `32`):\n#             The number of groups to use for the Resnet block group norm\n#         add_upsample (:obj:`bool`, *optional*, defaults to `True`):\n#             Whether to add upsample layer\n#         dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n#             Parameters `dtype`\n#     \"\"\"\n#     in_channels: int\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_2d_blocks_flax.py\n# --------------------------------------------------\n#         num_layers (:obj:`int`, *optional*, defaults to 1):\n#             Number of attention blocks layers\n#         add_downsample (:obj:`bool`, *optional*, defaults to `True`):\n#             Whether to add downsampling layer before each final output\n#         dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n#             Parameters `dtype`\n#     \"\"\"\n#     in_channels: int\n#     out_channels: int\n#     dropout: float = 0.0\n#     num_layers: int = 1\n#     add_downsample: bool = True\n#     dtype: jnp.dtype = jnp.float32\n# \n#     def setup(self):\n#         resnets = []\n# \n#         for i in range(self.num_layers):\n#             in_channels = self.in_channels if i == 0 else self.out_channels\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_2d_blocks_flax.py\n# --------------------------------------------------\n#     r\"\"\"\n#     Flax 2D downsizing block\n# \n#     Parameters:\n#         in_channels (:obj:`int`):\n#             Input channels\n#         out_channels (:obj:`int`):\n#             Output channels\n#         dropout (:obj:`float`, *optional*, defaults to 0.0):\n#             Dropout rate\n#         num_layers (:obj:`int`, *optional*, defaults to 1):\n#             Number of attention blocks layers\n#         add_downsample (:obj:`bool`, *optional*, defaults to `True`):\n#             Whether to add downsampling layer before each final output\n#         dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n#             Parameters `dtype`\n#     \"\"\"\n#     in_channels: int\n#     out_channels: int\n#     dropout: float = 0.0\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/vae_flax.py\n# --------------------------------------------------\n#         in_channels (:obj:`int`):\n#             Input channels\n#         dropout (:obj:`float`, *optional*, defaults to 0.0):\n#             Dropout rate\n#         num_layers (:obj:`int`, *optional*, defaults to 1):\n#             Number of Resnet layer block\n#         resnet_groups (:obj:`int`, *optional*, defaults to `32`):\n#             The number of groups to use for the Resnet and Attention block group norm\n#         attn_num_head_channels (:obj:`int`, *optional*, defaults to `1`):\n#             Number of attention heads for each attention block\n#         dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n#             Parameters `dtype`\n#     \"\"\"\n#     in_channels: int\n#     dropout: float = 0.0\n#     num_layers: int = 1\n#     resnet_groups: int = 32\n#     attn_num_head_channels: int = 1\n#     dtype: jnp.dtype = jnp.float32\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_2d_blocks_flax.py\n# --------------------------------------------------\n#             Output channels\n#         dropout (:obj:`float`, *optional*, defaults to 0.0):\n#             Dropout rate\n#         num_layers (:obj:`int`, *optional*, defaults to 1):\n#             Number of attention blocks layers\n#         attn_num_head_channels (:obj:`int`, *optional*, defaults to 1):\n#             Number of attention heads of each spatial transformer block\n#         add_downsample (:obj:`bool`, *optional*, defaults to `True`):\n#             Whether to add downsampling layer before each final output\n#         dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n#             Parameters `dtype`\n#     \"\"\"\n#     in_channels: int\n#     out_channels: int\n#     dropout: float = 0.0\n#     num_layers: int = 1\n#     attn_num_head_channels: int = 1\n#     add_downsample: bool = True\n#     use_linear_projection: bool = False\n#     only_cross_attention: bool = False\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nsample2D(self.out_channels, dtype=self.dtype)\n\n    def __call__(self, hidden_states, temb, deterministic=True):\n        output_states = ()\n\n        for resnet in self.resnets:\n            hidden_states = resnet(hidden_states, temb, deterministic=deterministic)\n            output_states += (hidden_states,)\n\n        if self.add_downsample:\n            hidden_states = self.downsamplers_0(hidden_states)\n            output_states += (hidden_states,)\n\n        return hidden_states, output_states\n\n\nclass FlaxCrossAttnUpBlock2D(nn.Module):\n    r\"\"\"\n    Cross Attention 2D Upsampling block - original architecture from Unet transformers:\n    https://arxiv.org/abs/2103.06104\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        out_channels (:obj:`int`):\n            Output channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        num_layers (:obj:`int`, *optional*, defaults to 1):\n            Number of attention blocks layers\n        attn_num_head_channels (:obj:`int`, *optional*, defaults to 1):\n            Number of attention heads of each spatial transformer block\n        add_upsample (:obj:`bool`, *optional*, defaults to `True`):\n            Whether to add upsampling layer before each final output\n        dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n            Parameters `dtype`\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    prev_output_channel: int\n    dropout: float = 0.0\n    num_layers: int = 1\n    attn_num_head_channels: int = 1\n    add_upsample: bool = True\n    use_linear_projection: bool = False\n    only_cross_attention: bool = False\n    dtype: jnp.dtype = jnp.float32\n\n    def setup(self):\n        resnets = []\n        attentions = []\n\n        for i in range(self.num_layers):\n            res_skip_channels = self.in_channels if (i == self.num_layers - 1) else self.out_channels\n            resnet_in_channels = self.prev_output_channel if i == 0 else self.out_channels\n\n            res_block = FlaxResnetBlock2D(\n                in_channels=resnet_in_channels + res_skip_channels,\n                out_channels=self.out_channels,\n                dropout_prob=self.dropout,\n                dtype=self.dtype,\n            )\n            resnets.append(res_block)\n\n            attn_block = FlaxTransformer2DModel(\n                in_channels=self.out_channels,\n                n_heads=self.attn_num_head_channels,\n                d_head=self.out_channels // self.attn_num_head_channels,\n                depth=1,\n                use_linear_projection=self.use_linear_projection,\n                only_cross_attention=self.only_cross_attention,\n                dtype=self.dtype,\n            )\n            attentions.append(attn_block)\n\n        self.resnets = resnets\n        self.attentions = attentions\n\n        if self.add_upsample:\n            self.upsamplers_0 = FlaxUpsample2D(self.out_channels, dtype=self.dtype)\n\n    def __call__(self, hidden_states, res_hidden_states_tuple, temb, encoder_hidden_states, deterministic=True):\n        for resnet, attn in zip(self.resnets, self.attentions):\n            # pop res hidden states\n            res_hidden_states = res_hidden_states_tuple[-1]\n            res_hidden_states_tuple = res_hidden_states_tuple[:-1]\n            hidden_states = jnp.concatenate((hidden_states, res_hidden_states), axis=-1)\n\n            hidden_states = resnet(hidden_states, temb, deterministic=deterministic)\n            hidden_states = attn(hidden_states, encoder_hidden_states, deterministic=deterministic)\n\n        if self.add_upsample:\n            hidden_states = self.upsamplers_0(hidden_states)\n\n        return hidden_states\n\n\nclass FlaxUpBlock2D(nn.Module):\n    r\"\"\"\n    Flax 2D upsampling block\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        out_channels (:obj:`int`):\n            Output channels\n        prev_output_channel (:obj:`int`):\n            Output channels from the previous block\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        num_layers (:obj:`int`, *optional*, defaults to 1):\n            Number of attention blocks layers\n        add_downsample (:obj:`bool`, *optional*, defaults to `True`):\n            Whether to add downsampling layer before each final output\n        dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n            Parameters `dtype`\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    prev_output_channel: int\n    dropout: float = 0.0\n    num_layers: int = 1\n    add_upsample: bool = True\n    dtype: jnp.dtype = jnp.float32\n\n    def setup(self):\n        resnets = []\n\n        for i in range(self.num_layers):\n            res_skip_channels = self.in_channels if (i == self.num_layers - 1) else self.out_channels\n            resnet_in_channels = self.prev_output_channel if i == 0 else self.out_channels\n\n            res_block = FlaxResnetBlock2D(\n                in_channels=resnet_in_channels + res_skip_channels,\n                out_channels=self.out_channels,\n                dropout_prob=self.dropout,\n                dtype=self.dtype,\n            )\n            resnets.append(res_block)\n\n        self.resnets = resnets\n\n        if self.add_upsample:\n            self.upsamplers_0 = FlaxUpsample2D(self.out_channels, dtype=self.dtype)\n\n    def __call__(self, hidden_states, res_hidden_states_tuple, temb, deterministic=True):\n        for resnet in self.resnets:\n            # pop res hidden states\n            res_hidden_states = res_hidden_states_tuple[-1]\n            res_hidden_states_tuple = res_hidden_states_tuple[:-1]\n            hidden_states = jnp.concatenate((hidden_states, res_hidden_states), axis=-1)\n\n            hidden_states = resnet(hidden_states, temb, deterministic=deterministic)\n\n        if self.add_upsample:\n            hidden_states = self.upsamplers_0(hidden_states)\n\n        return hidden_states\n\n\nclass FlaxUNetMidBlock2DCrossAttn(nn.Module):\n    r\"\"\"\n    Cross Attention 2D Mid-level block - original architecture from Unet transformers: https://arxiv.org/abs/2103.06104\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        num_layers (:obj:`int`, *optional*, defaults to 1):\n            Number of attention blocks layers\n        attn_num_head_channels (:obj:`int`, *optional*, defaults to 1):\n            Number of attention heads of each spatial transformer block\n        dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):", "choices": [{"text": "jnp.float32"}], "metadata": {"task_id": "huggingface_diffusers/180", "ground_truth": "            Parameters `dtype`", "fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_2d_blocks_flax.py"], "context_start_lineno": 140, "line_no": 314, "query_window": {"context": "        if self.add_upsample:\n            hidden_states = self.upsamplers_0(hidden_states)\n\n        return hidden_states\n\n\nclass FlaxUNetMidBlock2DCrossAttn(nn.Module):\n    r\"\"\"\n    Cross Attention 2D Mid-level block - original architecture from Unet transformers: https://arxiv.org/abs/2103.06104\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        num_layers (:obj:`int`, *optional*, defaults to 1):\n            Number of attention blocks layers\n        attn_num_head_channels (:obj:`int`, *optional*, defaults to 1):\n            Number of attention heads of each spatial transformer block\n        dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):", "metadata": {"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_2d_blocks_flax.py"], "line_no": 314, "task_id": "huggingface_diffusers/180", "start_line_no": 294, "end_line_no": 314, "window_size": 20, "context_start_lineno": 140, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "\nclass FlaxCrossAttnDownBlock2D(nn.Module):\n    r\"\"\"\n    Cross Attention 2D Downsizing block - original architecture from Unet transformers:\n    https://arxiv.org/abs/2103.06104\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        out_channels (:obj:`int`):\n            Output channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        num_layers (:obj:`int`, *optional*, defaults to 1):\n            Number of attention blocks layers\n        attn_num_head_channels (:obj:`int`, *optional*, defaults to 1):\n            Number of attention heads of each spatial transformer block\n        add_downsample (:obj:`bool`, *optional*, defaults to `True`):\n            Whether to add downsampling layer before each final output\n        dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_2d_blocks_flax.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7209302325581395}, {"context": "            hidden_states = self.upsamplers_0(hidden_states)\n\n        return hidden_states\n\n\nclass FlaxUNetMidBlock2D(nn.Module):\n    r\"\"\"\n    Flax Unet Mid-Block module.\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        num_layers (:obj:`int`, *optional*, defaults to 1):\n            Number of Resnet layer block\n        resnet_groups (:obj:`int`, *optional*, defaults to `32`):\n            The number of groups to use for the Resnet and Attention block group norm\n        attn_num_head_channels (:obj:`int`, *optional*, defaults to `1`):\n            Number of attention heads for each attention block", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "vae_flax.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.59375}, {"context": "            output_states += (hidden_states,)\n\n        if self.add_downsample:\n            hidden_states = self.downsamplers_0(hidden_states)\n            output_states += (hidden_states,)\n\n        return hidden_states, output_states\n\n\nclass FlaxDownBlock2D(nn.Module):\n    r\"\"\"\n    Flax 2D downsizing block\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        out_channels (:obj:`int`):\n            Output channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_2d_blocks_flax.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4793388429752066}, {"context": "    r\"\"\"\n    Flax 2D downsizing block\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        out_channels (:obj:`int`):\n            Output channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        num_layers (:obj:`int`, *optional*, defaults to 1):\n            Number of attention blocks layers\n        add_downsample (:obj:`bool`, *optional*, defaults to `True`):\n            Whether to add downsampling layer before each final output\n        dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n            Parameters `dtype`\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    dropout: float = 0.0", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_2d_blocks_flax.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4573643410852713}, {"context": "        for resnet in self.resnets:\n            hidden_states = resnet(hidden_states, deterministic=deterministic)\n\n        if self.add_downsample:\n            hidden_states = self.downsamplers_0(hidden_states)\n\n        return hidden_states\n\n\nclass FlaxUpDecoderBlock2D(nn.Module):\n    r\"\"\"\n    Flax Resnet blocks-based Decoder block for diffusion-based VAE.\n\n    Parameters:\n        in_channels (:obj:`int`):\n            Input channels\n        out_channels (:obj:`int`):\n            Output channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "vae_flax.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.45112781954887216}, {"context": "\nclass FlaxBasicTransformerBlock(nn.Module):\n    r\"\"\"\n    A Flax transformer block layer with `GLU` (Gated Linear Unit) activation function as described in:\n    https://arxiv.org/abs/1706.03762\n\n\n    Parameters:\n        dim (:obj:`int`):\n            Inner hidden states dimension\n        n_heads (:obj:`int`):\n            Number of heads\n        d_head (:obj:`int`):\n            Hidden states dimension inside each head\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        only_cross_attention (`bool`, defaults to `False`):\n            Whether to only apply cross attention.\n        dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n            Parameters `dtype`", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "attention_flax.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4228187919463087}, {"context": "            Output channels\n        dropout (:obj:`float`, *optional*, defaults to 0.0):\n            Dropout rate\n        num_layers (:obj:`int`, *optional*, defaults to 1):\n            Number of attention blocks layers\n        attn_num_head_channels (:obj:`int`, *optional*, defaults to 1):\n            Number of attention heads of each spatial transformer block\n        add_downsample (:obj:`bool`, *optional*, defaults to `True`):\n            Whether to add downsampling layer before each final output\n        dtype (:obj:`jnp.dtype`, *optional*, defaults to jnp.float32):\n            Parameters `dtype`\n    \"\"\"\n    in_channels: int\n    out_channels: int\n    dropout: float = 0.0\n    num_layers: int = 1\n    attn_num_head_channels: int = 1\n    add_downsample: bool = True\n    use_linear_projection: bool = False\n    only_cross_attention: bool = False", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_2d_blocks_flax.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4172661870503597}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/conftest.py\n# --------------------------------------------------\n# def jsonl2_path(tmp_path_factory):\n#     path = str(tmp_path_factory.mktemp(\"data\") / \"dataset2.jsonl\")\n#     with open(path, \"w\") as f:\n#         for item in DATA:\n#             f.write(json.dumps(item) + \"\\n\")\n#     return path\n# \n# \n# @pytest.fixture(scope=\"session\")\n# def jsonl_312_path(tmp_path_factory):\n#     path = str(tmp_path_factory.mktemp(\"data\") / \"dataset_312.jsonl\")\n#     with open(path, \"w\") as f:\n#         for item in DATA_312:\n#             f.write(json.dumps(item) + \"\\n\")\n#     return path\n# \n# \n# @pytest.fixture(scope=\"session\")\n# def jsonl_str_path(tmp_path_factory):\n#     path = str(tmp_path_factory.mktemp(\"data\") / \"dataset-str.jsonl\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/conftest.py\n# --------------------------------------------------\n#         data = bytes(FILE_CONTENT, \"utf-8\")\n#         with zstd.open(path, \"wb\") as f:\n#             f.write(data)\n#         return path\n# \n# \n# @pytest.fixture(scope=\"session\")\n# def lz4_file(tmp_path_factory):\n#     if config.LZ4_AVAILABLE:\n#         import lz4.frame\n# \n#         path = tmp_path_factory.mktemp(\"data\") / \"file.txt.lz4\"\n#         data = bytes(FILE_CONTENT, \"utf-8\")\n#         with lz4.frame.open(path, \"wb\") as f:\n#             f.write(data)\n#         return path\n# \n# \n# @pytest.fixture(scope=\"session\")\n# def xml_file(tmp_path_factory):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#         else:\n#             temp_file_manager = partial(tempfile.NamedTemporaryFile, dir=cache_dir, delete=False)\n#             resume_size = 0\n# \n#         # Download to temporary file, then copy to cache dir once finished.\n#         # Otherwise you get corrupt cache entries if the download gets interrupted.\n#         with temp_file_manager() as temp_file:\n#             logger.info(f\"{url} not found in cache or force_download set to True, downloading to {temp_file.name}\")\n# \n#             # GET file object\n#             if url.startswith(\"ftp://\"):\n#                 ftp_get(url, temp_file)\n#             else:\n#                 http_get(\n#                     url,\n#                     temp_file,\n#                     proxies=proxies,\n#                     resume_size=resume_size,\n#                     headers=headers,\n#                     cookies=cookies,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_metric_common.py\n# --------------------------------------------------\n#             mock_load.side_effect = load_local_metric\n#             yield\n# \n#     @classmethod\n#     def register_intensive_calls_patcher(cls, evaluation_module_name):\n#         def wrapper(patcher):\n#             patcher = contextmanager(patcher)\n#             cls.INTENSIVE_CALLS_PATCHER[evaluation_module_name] = patcher\n#             return patcher\n# \n#         return wrapper\n# \n# \n# # Metrics intensive calls patchers\n# # --------------------------------\n# \n# \n# @LocalModuleTest.register_intensive_calls_patcher(\"bleurt\")\n# def patch_bleurt(module_name):\n#     import tensorflow.compat.v1 as tf\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#             @contextmanager\n#             def _resumable_file_manager():\n#                 with open(incomplete_path, \"a+b\") as f:\n#                     yield f\n# \n#             temp_file_manager = _resumable_file_manager\n#             if os.path.exists(incomplete_path):\n#                 resume_size = os.stat(incomplete_path).st_size\n#             else:\n#                 resume_size = 0\n#         else:\n#             temp_file_manager = partial(tempfile.NamedTemporaryFile, dir=cache_dir, delete=False)\n#             resume_size = 0\n# \n#         # Download to temporary file, then copy to cache dir once finished.\n#         # Otherwise you get corrupt cache entries if the download gets interrupted.\n#         with temp_file_manager() as temp_file:\n#             logger.info(f\"{url} not found in cache or force_download set to True, downloading to {temp_file.name}\")\n# \n#             # GET file object\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/utils.py\n# --------------------------------------------------\n#     elif mode is OfflineSimulationMode.HF_EVALUATE_OFFLINE_SET_TO_1:\n#         with patch(\"evaluate.config.HF_EVALUATE_OFFLINE\", True):\n#             yield\n#     else:\n#         raise ValueError(\"Please use a value from the OfflineSimulationMode enum.\")\n# \n# \n# @contextmanager\n# def set_current_working_directory_to_temp_dir(*args, **kwargs):\n#     original_working_dir = str(Path().resolve())\n#     with tempfile.TemporaryDirectory(*args, **kwargs) as tmp_dir:\n#         try:\n#             os.chdir(tmp_dir)\n#             yield\n#         finally:\n#             os.chdir(original_working_dir)\n# \n# \n# def is_rng_equal(rng1, rng2):\n#     return deepcopy(rng1).integers(0, 100, 10).tolist() == deepcopy(rng2).integers(0, 100, 10).tolist()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/bertscore/bertscore.py\n# --------------------------------------------------\n#     logger = datasets.utils.logging.get_logger(\"transformers.modeling_utils\")\n#     logger.addFilter(filter_log)\n#     try:\n#         yield\n#     finally:\n#         logger.removeFilter(filter_log)\n# \n# \n# _CITATION = \"\"\"\\\n# @inproceedings{bert-score,\n#   title={BERTScore: Evaluating Text Generation with BERT},\n#   author={Tianyi Zhang* and Varsha Kishore* and Felix Wu* and Kilian Q. Weinberger and Yoav Artzi},\n#   booktitle={International Conference on Learning Representations},\n#   year={2020},\n#   url={https://openreview.net/forum?id=SkeHuCVFDr}\n# }\n# \"\"\"\n# \n# _DESCRIPTION = \"\"\"\\\n# BERTScore leverages the pre-trained contextual embeddings from BERT and matches words in candidate and reference\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2020 The HuggingFace Datasets Authors and the current dataset script contributor.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This code is adapted from OpenAI's release\n# https://github.com/openai/human-eval/blob/master/human_eval/execution.py\n\nimport contextlib\nimport faulthandler\nimport io\nimport multiprocessing\nimport os\nimport platform\nimport signal\nimport tempfile\n\n\ndef check_correctness(check_program, timeout, task_id, completion_id):\n    \"\"\"\n    Evaluates the functional correctness of a completion by running the test\n    suite provided in the problem.\n\n    :param completion_id: an optional completion ID so we can match\n        the results later even if execution finishes asynchronously.\n    \"\"\"\n    manager = multiprocessing.Manager()\n    result = manager.list()\n\n    p = multiprocessing.Process(target=unsafe_execute, args=(check_program, result, timeout))\n    p.start()\n    p.join(timeout=timeout + 1)\n    if p.is_alive():\n        p.kill()\n\n    if not result:\n        result.append(\"timed out\")\n\n    return dict(\n        task_id=task_id,\n        passed=result[0] == \"passed\",\n        result=result[0],\n        completion_id=completion_id,\n    )\n\n\ndef unsafe_execute(check_program, result, timeout):\n\n    with create_tempdir():\n\n        # These system calls are needed when cleaning up tempdir.\n        import os\n        import shutil\n\n        rmtree = shutil.rmtree\n        rmdir = os.rmdir\n        chdir = os.chdir\n\n        # Disable functionalities that can make destructive changes to the test.\n        reliability_guard()\n\n        # Run program.\n        try:\n            exec_globals = {}\n            with swallow_io():\n                with time_limit(timeout):\n                    exec(check_program, exec_globals)\n            result.append(\"passed\")\n        except TimeoutException:\n            result.append(\"timed out\")\n        except BaseException as e:\n            result.append(f\"failed: {e}\")\n\n        # Needed for cleaning up.\n        shutil.rmtree = rmtree\n        os.rmdir = rmdir\n        os.chdir = chdir\n\n\n@contextlib.contextmanager\ndef time_limit(seconds):\n    def signal_handler(signum, frame):\n        raise TimeoutException(\"Timed out!\")\n\n    signal.setitimer(signal.ITIMER_REAL, seconds)\n    signal.signal(signal.SIGALRM, signal_handler)\n    try:\n        yield\n    finally:\n        signal.setitimer(signal.ITIMER_REAL, 0)\n\n\n@contextlib.contextmanager\ndef swallow_io():\n    stream = WriteOnlyStringIO()\n    with contextlib.redirect_stdout(stream):\n        with contextlib.redirect_stderr(stream):\n            with redirect_stdin(stream):\n                yield\n\n\n@contextlib.contextmanager\ndef create_tempdir():", "choices": [{"text": "\"\"\"A basic implementation for context manager to create and automatically delete a temporary directory\"\"\""}], "metadata": {"task_id": "huggingface_evaluate/2", "ground_truth": "    with tempfile.TemporaryDirectory() as dirname:", "fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "execute.py"], "context_start_lineno": 0, "line_no": 112, "query_window": {"context": "\n    signal.setitimer(signal.ITIMER_REAL, seconds)\n    signal.signal(signal.SIGALRM, signal_handler)\n    try:\n        yield\n    finally:\n        signal.setitimer(signal.ITIMER_REAL, 0)\n\n\n@contextlib.contextmanager\ndef swallow_io():\n    stream = WriteOnlyStringIO()\n    with contextlib.redirect_stdout(stream):\n        with contextlib.redirect_stderr(stream):\n            with redirect_stdin(stream):\n                yield\n\n\n@contextlib.contextmanager\ndef create_tempdir():", "metadata": {"fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "execute.py"], "line_no": 112, "task_id": "huggingface_evaluate/2", "start_line_no": 92, "end_line_no": 112, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "from packaging import version\n\nimport evaluate\n\n\n@contextmanager\ndef filter_logging_context():\n    def filter_log(record):\n        return False if \"This IS expected if you are initializing\" in record.msg else True\n\n    logger = datasets.utils.logging.get_logger(\"transformers.modeling_utils\")\n    logger.addFilter(filter_log)\n    try:\n        yield\n    finally:\n        logger.removeFilter(filter_log)\n\n\n_CITATION = \"\"\"\\\n@inproceedings{bert-score,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "bertscore", "bertscore.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.18803418803418803}, {"context": "    elif mode is OfflineSimulationMode.HF_EVALUATE_OFFLINE_SET_TO_1:\n        with patch(\"evaluate.config.HF_EVALUATE_OFFLINE\", True):\n            yield\n    else:\n        raise ValueError(\"Please use a value from the OfflineSimulationMode enum.\")\n\n\n@contextmanager\ndef set_current_working_directory_to_temp_dir(*args, **kwargs):\n    original_working_dir = str(Path().resolve())\n    with tempfile.TemporaryDirectory(*args, **kwargs) as tmp_dir:\n        try:\n            os.chdir(tmp_dir)\n            yield\n        finally:\n            os.chdir(original_working_dir)\n\n\ndef is_rng_equal(rng1, rng2):\n    return deepcopy(rng1).integers(0, 100, 10).tolist() == deepcopy(rng2).integers(0, 100, 10).tolist()", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "utils.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.18181818181818182}, {"context": "        return cache_path\n\n    # From now on, connected is True.\n    # Prevent parallel downloads of the same file with a lock.\n    lock_path = cache_path + \".lock\"\n    with FileLock(lock_path):\n\n        if resume_download:\n            incomplete_path = cache_path + \".incomplete\"\n\n            @contextmanager\n            def _resumable_file_manager():\n                with open(incomplete_path, \"a+b\") as f:\n                    yield f\n\n            temp_file_manager = _resumable_file_manager\n            if os.path.exists(incomplete_path):\n                resume_size = os.stat(incomplete_path).st_size\n            else:\n                resume_size = 0", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1794871794871795}, {"context": "                yield\n        else:\n            yield\n\n    @contextmanager\n    def use_local_metrics(self, evaluation_module_type):\n        def load_local_metric(evaluation_module_name, *args, **kwargs):\n            return load(os.path.join(evaluation_module_type + \"s\", evaluation_module_name), *args, **kwargs)\n\n        with patch(\"evaluate.load\") as mock_load:\n            mock_load.side_effect = load_local_metric\n            yield\n\n    @classmethod\n    def register_intensive_calls_patcher(cls, evaluation_module_name):\n        def wrapper(patcher):\n            patcher = contextmanager(patcher)\n            cls.INTENSIVE_CALLS_PATCHER[evaluation_module_name] = patcher\n            return patcher\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_metric_common.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1721311475409836}, {"context": "            @contextmanager\n            def _resumable_file_manager():\n                with open(incomplete_path, \"a+b\") as f:\n                    yield f\n\n            temp_file_manager = _resumable_file_manager\n            if os.path.exists(incomplete_path):\n                resume_size = os.stat(incomplete_path).st_size\n            else:\n                resume_size = 0\n        else:\n            temp_file_manager = partial(tempfile.NamedTemporaryFile, dir=cache_dir, delete=False)\n            resume_size = 0\n\n        # Download to temporary file, then copy to cache dir once finished.\n        # Otherwise you get corrupt cache entries if the download gets interrupted.\n        with temp_file_manager() as temp_file:\n            logger.info(f\"{url} not found in cache or force_download set to True, downloading to {temp_file.name}\")\n\n            # GET file object", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 600, "start_line_no": 590, "end_line_no": 610, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1702127659574468}, {"context": "        f.write(data)\n    return path\n\n\n@pytest.fixture(scope=\"session\")\ndef zstd_file(tmp_path_factory):\n    if config.ZSTANDARD_AVAILABLE:\n        import zstandard as zstd\n\n        path = tmp_path_factory.mktemp(\"data\") / \"file.txt.zst\"\n        data = bytes(FILE_CONTENT, \"utf-8\")\n        with zstd.open(path, \"wb\") as f:\n            f.write(data)\n        return path\n\n\n@pytest.fixture(scope=\"session\")\ndef lz4_file(tmp_path_factory):\n    if config.LZ4_AVAILABLE:\n        import lz4.frame", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "conftest.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.16379310344827586}, {"context": "@pytest.fixture(scope=\"session\")\ndef jsonl_path(tmp_path_factory):\n    path = str(tmp_path_factory.mktemp(\"data\") / \"dataset.jsonl\")\n    with open(path, \"w\") as f:\n        for item in DATA:\n            f.write(json.dumps(item) + \"\\n\")\n    return path\n\n\n@pytest.fixture(scope=\"session\")\ndef jsonl2_path(tmp_path_factory):\n    path = str(tmp_path_factory.mktemp(\"data\") / \"dataset2.jsonl\")\n    with open(path, \"w\") as f:\n        for item in DATA:\n            f.write(json.dumps(item) + \"\\n\")\n    return path\n\n\n@pytest.fixture(scope=\"session\")\ndef jsonl_312_path(tmp_path_factory):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "conftest.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1619047619047619}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#         results = evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"f1\",\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"f1\"], 1.0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(\n#             data=self.data,\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"accuracy\"], 1.0)\n# \n#     def test_data_loading(self):\n# \n#         # Test passing in dataset by name with split\n#         data = self.evaluator.load_data(\"evaluate/imdb-ci\", split=\"test[:1]\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/__init__.py\n# --------------------------------------------------\n#     AutomaticSpeechRecognitionEvaluator,\n#     Evaluator,\n#     ImageClassificationEvaluator,\n#     QuestionAnsweringEvaluator,\n#     SummarizationEvaluator,\n#     Text2TextGenerationEvaluator,\n#     TextClassificationEvaluator,\n#     TextGenerationEvaluator,\n#     TokenClassificationEvaluator,\n#     TranslationEvaluator,\n#     evaluator,\n# )\n# from .hub import push_to_hub\n# from .info import ComparisonInfo, EvaluationModuleInfo, MeasurementInfo, MetricInfo\n# from .inspect import inspect_evaluation_module, list_evaluation_modules\n# from .loading import load\n# from .module import CombinedEvaluations, Comparison, EvaluationModule, Measurement, Metric, combine\n# from .saving import save\n# from .utils import *\n# from .utils import gradio, logging\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#             metric=\"seqeval\",\n#         )\n#         self.assertEqual(results[\"overall_accuracy\"], 1.0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(\n#             data=self.data,\n#         )\n#         self.assertEqual(results[\"overall_accuracy\"], 2 / 3)\n# \n#     def test_overwrite_default_metric(self):\n#         accuracy = load(\"seqeval\")\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=accuracy,\n#         )\n#         self.assertEqual(results[\"overall_accuracy\"], 1.0)\n#         results = self.evaluator.compute(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/__init__.py\n# --------------------------------------------------\n#     AutomaticSpeechRecognitionEvaluator,\n#     Evaluator,\n#     ImageClassificationEvaluator,\n#     QuestionAnsweringEvaluator,\n#     SummarizationEvaluator,\n#     Text2TextGenerationEvaluator,\n#     TextClassificationEvaluator,\n#     TextGenerationEvaluator,\n#     TokenClassificationEvaluator,\n#     TranslationEvaluator,\n#     evaluator,\n# )\n# from .hub import push_to_hub\n# from .info import ComparisonInfo, EvaluationModuleInfo, MeasurementInfo, MetricInfo\n# from .inspect import inspect_evaluation_module, list_evaluation_modules\n# from .loading import load\n# from .module import CombinedEvaluations, Comparison, EvaluationModule, Measurement, Metric, combine\n# from .saving import save\n# from .utils import *\n# from .utils import gradio, logging\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(data=self.data)\n#         self.assertIsInstance(results[\"unique_words\"], int)\n# \n#     def test_overwrite_default_metric(self):\n#         word_length = load(\"word_length\")\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=word_length,\n#         )\n#         self.assertIsInstance(results[\"average_word_length\"], int)\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"word_length\",\n#         )\n#         self.assertIsInstance(results[\"average_word_length\"], int)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(data=self.data)\n#         self.assertEqual(results[\"bleu\"], 0)\n# \n#     def test_overwrite_default_metric(self):\n#         rouge = load(\"rouge\")\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=rouge,\n#         )\n#         self.assertEqual(results[\"rouge1\"], 1.0)\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"rouge\",\n#         )\n#         self.assertEqual(results[\"rouge1\"], 1.0)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#         evaluator = Text2TextGenerationEvaluator()\n#         self.assertEqual(evaluator.task, \"text2text-generation\")\n#         self.assertIsNone(evaluator.default_metric_name)\n# \n#         results = evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"bleu\",\n#         )\n#         self.assertEqual(results[\"bleu\"], 0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(data=self.data)\n#         self.assertEqual(results[\"bleu\"], 0)\n# \n#     def test_overwrite_default_metric(self):\n#         rouge = load(\"rouge\")\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2022 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\ntry:\n    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n    from transformers.pipelines import TASK_ALIASES\n    from transformers.pipelines import check_task as check_pipeline_task\n\n    TRANSFORMERS_AVAILABLE = True\nexcept ImportError:\n    TRANSFORMERS_AVAILABLE = False\n\nfrom typing import Dict, List\n\nfrom .automatic_speech_recognition import AutomaticSpeechRecognitionEvaluator\nfrom .base import Evaluator\nfrom .image_classification import ImageClassificationEvaluator\nfrom .question_answering import QuestionAnsweringEvaluator\nfrom .text2text_generation import SummarizationEvaluator, Text2TextGenerationEvaluator, TranslationEvaluator\nfrom .text_classification import TextClassificationEvaluator\nfrom .text_generation import TextGenerationEvaluator\nfrom .token_classification import TokenClassificationEvaluator\n\n\nSUPPORTED_EVALUATOR_TASKS = {\n    \"text-classification\": {\n        \"implementation\": TextClassificationEvaluator,\n        \"default_metric_name\": \"accuracy\",\n    },\n    \"image-classification\": {\n        \"implementation\": ImageClassificationEvaluator,\n        \"default_metric_name\": \"accuracy\",\n    },\n    \"question-answering\": {\n        \"implementation\": QuestionAnsweringEvaluator,\n        \"default_metric_name\": \"squad\",\n    },\n    \"token-classification\": {\n        \"implementation\": TokenClassificationEvaluator,\n        \"default_metric_name\": \"seqeval\",\n    },\n    \"text-generation\": {\n        \"implementation\": TextGenerationEvaluator,\n        \"default_metric_name\": \"word_count\",\n    },\n    \"text2text-generation\": {\n        \"implementation\": Text2TextGenerationEvaluator,\n        \"default_metric_name\": \"bleu\",\n    },\n    \"summarization\": {\n        \"implementation\": SummarizationEvaluator,\n        \"default_metric_name\": \"rouge\",\n    },\n    \"translation\": {\n        \"implementation\": TranslationEvaluator,\n        \"default_metric_name\": \"bleu\",", "choices": [{"text": "}"}], "metadata": {"task_id": "huggingface_evaluate/151", "ground_truth": "    },", "fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluator", "__init__.py"], "context_start_lineno": 0, "line_no": 68, "query_window": {"context": "    },\n    \"token-classification\": {\n        \"implementation\": TokenClassificationEvaluator,\n        \"default_metric_name\": \"seqeval\",\n    },\n    \"text-generation\": {\n        \"implementation\": TextGenerationEvaluator,\n        \"default_metric_name\": \"word_count\",\n    },\n    \"text2text-generation\": {\n        \"implementation\": Text2TextGenerationEvaluator,\n        \"default_metric_name\": \"bleu\",\n    },\n    \"summarization\": {\n        \"implementation\": SummarizationEvaluator,\n        \"default_metric_name\": \"rouge\",\n    },\n    \"translation\": {\n        \"implementation\": TranslationEvaluator,\n        \"default_metric_name\": \"bleu\",", "metadata": {"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "evaluator", "__init__.py"], "line_no": 68, "task_id": "huggingface_evaluate/151", "start_line_no": 48, "end_line_no": 68, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "        self.evaluator = evaluator(\"text2text-generation\")\n\n    def test_pipe_init(self):\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n        )\n        self.assertEqual(results[\"bleu\"], 0)\n\n    def test_class_init(self):\n        evaluator = Text2TextGenerationEvaluator()\n        self.assertEqual(evaluator.task, \"text2text-generation\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"bleu\",\n        )\n        self.assertEqual(results[\"bleu\"], 0)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 920, "start_line_no": 910, "end_line_no": 930, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3023255813953488}, {"context": "        evaluator = Text2TextGenerationEvaluator()\n        self.assertEqual(evaluator.task, \"text2text-generation\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"bleu\",\n        )\n        self.assertEqual(results[\"bleu\"], 0)\n\n    @slow\n    def test_default_pipe_init(self):\n        results = self.evaluator.compute(data=self.data)\n        self.assertEqual(results[\"bleu\"], 0)\n\n    def test_overwrite_default_metric(self):\n        rouge = load(\"rouge\")\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 930, "start_line_no": 920, "end_line_no": 940, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.29347826086956524}, {"context": "        evaluator = TextGenerationEvaluator()\n        self.assertEqual(evaluator.task, \"text-generation\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"word_count\",\n        )\n        self.assertIsInstance(results[\"unique_words\"], int)\n\n    @slow\n    def test_default_pipe_init(self):\n        results = self.evaluator.compute(data=self.data)\n        self.assertIsInstance(results[\"unique_words\"], int)\n\n    def test_overwrite_default_metric(self):\n        word_length = load(\"word_length\")\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 870, "start_line_no": 860, "end_line_no": 880, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.25}, {"context": "\nfrom packaging import version\n\n\nSCRIPTS_VERSION = \"main\" if version.parse(__version__).is_devrelease else __version__\n\ndel version\n\nfrom .evaluation_suite import EvaluationSuite\nfrom .evaluator import (\n    AutomaticSpeechRecognitionEvaluator,\n    Evaluator,\n    ImageClassificationEvaluator,\n    QuestionAnsweringEvaluator,\n    SummarizationEvaluator,\n    Text2TextGenerationEvaluator,\n    TextClassificationEvaluator,\n    TextGenerationEvaluator,\n    TokenClassificationEvaluator,\n    TranslationEvaluator,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "__init__.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.24444444444444444}, {"context": "        self.assertEqual(results[\"overall_accuracy\"], 0.5)\n\n    def test_class_init(self):\n        evaluator = TokenClassificationEvaluator()\n        self.assertEqual(evaluator.task, \"token-classification\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"seqeval\",\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 1.0)\n\n    @slow\n    def test_default_pipe_init(self):\n        results = self.evaluator.compute(\n            data=self.data,\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 2 / 3)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 720, "start_line_no": 710, "end_line_no": 730, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.23711340206185566}, {"context": "    AutomaticSpeechRecognitionEvaluator,\n    Evaluator,\n    ImageClassificationEvaluator,\n    QuestionAnsweringEvaluator,\n    SummarizationEvaluator,\n    Text2TextGenerationEvaluator,\n    TextClassificationEvaluator,\n    TextGenerationEvaluator,\n    TokenClassificationEvaluator,\n    TranslationEvaluator,\n    evaluator,\n)\nfrom .hub import push_to_hub\nfrom .info import ComparisonInfo, EvaluationModuleInfo, MeasurementInfo, MetricInfo\nfrom .inspect import inspect_evaluation_module, list_evaluation_modules\nfrom .loading import load\nfrom .module import CombinedEvaluations, Comparison, EvaluationModule, Measurement, Metric, combine\nfrom .saving import save\nfrom .utils import *\nfrom .utils import gradio, logging", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "__init__.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.23655913978494625}, {"context": "            tokenizer=tokenizer,\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    def test_class_init(self):\n        evaluator = TextClassificationEvaluator()\n        self.assertEqual(evaluator.task, \"text-classification\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"f1\",\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"f1\"], 1.0)\n\n    @slow\n    def test_default_pipe_init(self):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.23469387755102042}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n# \n#             # save dir, no dump\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_nodump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n#             sample = prob_class.posterior.sample()\n#             prob_class.posterior.load_state(tmp_dir)\n# \n#             # save dir and dump\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#             # no save dir but dump\n#             with self.assertRaises(ValueError):\n#                 status = prob_class.train(\n#                     train_data_loader=self.class_train_data_loader,\n#                     calib_data_loader=self.class_val_data_loader,\n#                     val_data_loader=self.class_val_data_loader,\n#                     fit_config=self.class_fit_config_nodir_dump,\n#                     calib_config=self.class_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_nodump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n#             sample = prob_class.posterior.sample()\n#             prob_class.posterior.load_state(tmp_dir)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n# \n#             # no save dir but dump\n#             with self.assertRaises(ValueError):\n#                 status = prob_class.train(\n#                     train_data_loader=self.class_train_data_loader,\n#                     calib_data_loader=self.class_val_data_loader,\n#                     val_data_loader=self.class_val_data_loader,\n#                     fit_config=self.class_fit_config_nodir_dump,\n#                     calib_config=self.class_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_nodump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n#             sample = prob_class.posterior.sample()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                     calib_data_loader=self.reg_val_data_loader,\n#                     val_data_loader=self.reg_val_data_loader,\n#                     fit_config=self.reg_fit_config_nodir_dump,\n#                     calib_config=self.reg_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n#             prob_reg.posterior.load_state(tmp_dir)\n# \n#             # save dir and dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                     val_data_loader=self.reg_val_data_loader,\n#                     fit_config=self.reg_fit_config_nodir_dump,\n#                     calib_config=self.reg_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n#             prob_reg.posterior.load_state(tmp_dir)\n# \n#             # save dir and dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n),\n                posterior_approximator=DeepEnsemblePosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    fit_config=self.reg_fit_config_nodir_dump,\n                    calib_config=self.reg_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # restore\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_reg.load_state(checkpoint_path=tmp_dir)\n\n            # save state\n            prob_reg.save_state(checkpoint_path=tmp_dir)\n\n    def test_dryrun_class_deep_ensemble(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            prob_class = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=DeepEnsemblePosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_nodir_nodump,\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_dump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # restore\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_restore(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_class.load_state(checkpoint_path=tmp_dir)\n\n            # save state\n            prob_class.save_state(checkpoint_path=tmp_dir)\n\n    def test_dryrun_reg_laplace(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            prob_reg = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=LaplacePosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    map_fit_config=self.reg_fit_config_nodir_nodump,\n                    fit_config=self.reg_fit_config_nodir_dump,", "choices": [{"text": "calib_config=self.reg_calib_config_nodir_nodump,"}], "metadata": {"task_id": "awslabs_fortuna/76", "ground_truth": "                    calib_config=self.reg_calib_config_nodir_nodump,", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "context_start_lineno": 453, "line_no": 605, "query_window": {"context": "            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    map_fit_config=self.reg_fit_config_nodir_nodump,\n                    fit_config=self.reg_fit_config_nodir_dump,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 605, "task_id": "awslabs_fortuna/76", "start_line_no": 585, "end_line_no": 605, "window_size": 20, "context_start_lineno": 453, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    fit_config=self.reg_fit_config_nodir_dump,\n                    calib_config=self.reg_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9814814814814815}, {"context": "                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    fit_config=self.reg_fit_config_nodir_dump,\n                    calib_config=self.reg_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9814814814814815}, {"context": "            )\n            # no save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_nodir_nodump,\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}, {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9454545454545454}, {"context": "            # no save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_nodir_nodump,\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9454545454545454}, {"context": "\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}, {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 540, "start_line_no": 530, "end_line_no": 550, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.896551724137931}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/deprecated.py\n# --------------------------------------------------\n#     next_state_value as get_next_state_value,\n# )\n# from torchrl.objectives.common import LossModule\n# \n# try:\n#     from functorch import vmap\n# \n#     FUNCTORCH_ERR = \"\"\n#     _has_functorch = True\n# except ImportError as err:\n#     FUNCTORCH_ERR = str(err)\n#     _has_functorch = False\n# \n# \n# class REDQLoss_deprecated(LossModule):\n#     \"\"\"REDQ Loss module.\n# \n#     REDQ (RANDOMIZED ENSEMBLED DOUBLE Q-LEARNING: LEARNING FAST WITHOUT A MODEL\n#     https://openreview.net/pdf?id=AY8zfZm0tDd) generalizes the idea of using an ensemble of Q-value functions to\n#     train a SAC-like algorithm.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/redq.py\n# --------------------------------------------------\n#     distance_loss,\n#     next_state_value as get_next_state_value,\n# )\n# \n# try:\n#     from functorch import vmap\n# \n#     FUNCTORCH_ERR = \"\"\n#     _has_functorch = True\n# except ImportError as err:\n#     FUNCTORCH_ERR = str(err)\n#     _has_functorch = False\n# \n# \n# class REDQLoss(LossModule):\n#     \"\"\"REDQ Loss module.\n# \n#     REDQ (RANDOMIZED ENSEMBLED DOUBLE Q-LEARNING: LEARNING FAST WITHOUT A MODEL\n#     https://openreview.net/pdf?id=AY8zfZm0tDd) generalizes the idea of using an ensemble of Q-value functions to\n#     train a SAC-like algorithm.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n#     TensorDictReplayBuffer,\n# )\n# from torchrl.envs.libs.gym import _has_gym\n# from torchrl.trainers import Recorder, Trainer\n# from torchrl.trainers.helpers import transformed_env_constructor\n# from torchrl.trainers.trainers import (\n#     _has_tqdm,\n#     _has_ts,\n#     BatchSubSampler,\n#     CountFramesLog,\n#     LogReward,\n#     mask_batch,\n#     OptimizerHook,\n#     ReplayBufferTrainer,\n#     RewardNormalizer,\n#     SelectKeys,\n#     UpdateWeights,\n# )\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/trainers.py\n# --------------------------------------------------\n# \n# from torchrl._utils import _CKPT_BACKEND, KeyDependentDefaultDict\n# from torchrl.collectors.collectors import _DataCollector\n# from torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\n# from torchrl.data.utils import DEVICE_TYPING\n# from torchrl.envs.common import EnvBase\n# from torchrl.envs.utils import set_exploration_mode\n# from torchrl.modules import SafeModule\n# from torchrl.objectives.common import LossModule\n# from torchrl.record.loggers import Logger\n# \n# try:\n#     from tqdm import tqdm\n# \n#     _has_tqdm = True\n# except ImportError:\n#     _has_tqdm = False\n# \n# try:\n#     from torchsnapshot import Snapshot, StateDict\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb.py\n# --------------------------------------------------\n#     ReplayBuffer,\n#     TensorDictPrioritizedReplayBuffer,\n#     TensorDictReplayBuffer,\n# )\n# from torchrl.data.replay_buffers import samplers, writers\n# from torchrl.data.replay_buffers.samplers import (\n#     PrioritizedSampler,\n#     RandomSampler,\n#     SamplerWithoutReplacement,\n# )\n# \n# from torchrl.data.replay_buffers.storages import (\n#     LazyMemmapStorage,\n#     LazyTensorStorage,\n#     ListStorage,\n# )\n# from torchrl.data.replay_buffers.writers import RoundRobinWriter\n# from torchrl.envs.transforms.transforms import (\n#     BinarizeReward,\n#     CatFrames,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/trainers.py\n# --------------------------------------------------\n# \n#     _has_ts = True\n# except ImportError:\n#     _has_ts = False\n# \n# REPLAY_BUFFER_CLASS = {\n#     \"prioritized\": TensorDictPrioritizedReplayBuffer,\n#     \"circular\": TensorDictReplayBuffer,\n# }\n# \n# LOGGER_METHODS = {\n#     \"grad_norm\": \"log_scalar\",\n#     \"loss\": \"log_scalar\",\n# }\n# \n# TYPE_DESCR = {float: \"4.4f\", int: \"\"}\n# \n# \n# class TrainerHookBase:\n#     \"\"\"An abstract hooking class for torchrl Trainer class.\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n#     _has_tb = True\n# except ImportError:\n#     _has_tb = False\n# \n# from tensordict import TensorDict\n# from torchrl.data import (\n#     LazyMemmapStorage,\n#     LazyTensorStorage,\n#     ListStorage,\n#     TensorDictPrioritizedReplayBuffer,\n#     TensorDictReplayBuffer,\n# )\n# from torchrl.envs.libs.gym import _has_gym\n# from torchrl.trainers import Recorder, Trainer\n# from torchrl.trainers.helpers import transformed_env_constructor\n# from torchrl.trainers.trainers import (\n#     _has_tqdm,\n#     _has_ts,\n#     BatchSubSampler,\n#     CountFramesLog,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/trainers.py\n# --------------------------------------------------\n# \n# try:\n#     from tqdm import tqdm\n# \n#     _has_tqdm = True\n# except ImportError:\n#     _has_tqdm = False\n# \n# try:\n#     from torchsnapshot import Snapshot, StateDict\n# \n#     _has_ts = True\n# except ImportError:\n#     _has_ts = False\n# \n# REPLAY_BUFFER_CLASS = {\n#     \"prioritized\": TensorDictPrioritizedReplayBuffer,\n#     \"circular\": TensorDictReplayBuffer,\n# }\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport abc\nimport os\nfrom collections import OrderedDict\nfrom copy import copy\nfrom typing import Any, Dict, Sequence, Union\n\nimport torch\nfrom tensordict.memmap import MemmapTensor\nfrom tensordict.prototype import is_tensorclass\nfrom tensordict.tensordict import TensorDict, TensorDictBase\n\nfrom torchrl._utils import _CKPT_BACKEND\nfrom torchrl.data.replay_buffers.utils import INT_CLASSES\n\ntry:\n    from torchsnapshot.serialization import tensor_from_memoryview\n\n    _has_ts = True\nexcept ImportError:", "choices": [{"text": "_has_ts = False"}], "metadata": {"task_id": "pytorch_rl/19", "ground_truth": "    _has_ts = False", "fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "context_start_lineno": 0, "line_no": 24, "query_window": {"context": "\nimport abc\nimport os\nfrom collections import OrderedDict\nfrom copy import copy\nfrom typing import Any, Dict, Sequence, Union\n\nimport torch\nfrom tensordict.memmap import MemmapTensor\nfrom tensordict.prototype import is_tensorclass\nfrom tensordict.tensordict import TensorDict, TensorDictBase\n\nfrom torchrl._utils import _CKPT_BACKEND\nfrom torchrl.data.replay_buffers.utils import INT_CLASSES\n\ntry:\n    from torchsnapshot.serialization import tensor_from_memoryview\n\n    _has_ts = True\nexcept ImportError:", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 24, "task_id": "pytorch_rl/19", "start_line_no": 4, "end_line_no": 24, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "\nfrom torchrl._utils import _CKPT_BACKEND, KeyDependentDefaultDict\nfrom torchrl.collectors.collectors import _DataCollector\nfrom torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\nfrom torchrl.data.utils import DEVICE_TYPING\nfrom torchrl.envs.common import EnvBase\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.record.loggers import Logger\n\ntry:\n    from tqdm import tqdm\n\n    _has_tqdm = True\nexcept ImportError:\n    _has_tqdm = False\n\ntry:\n    from torchsnapshot import Snapshot, StateDict", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "from time import sleep\n\nimport pytest\nimport torch\nfrom torch import nn\n\ntry:\n    from tensorboard.backend.event_processing import event_accumulator\n    from torchrl.record.loggers import TensorboardLogger\n\n    _has_tb = True\nexcept ImportError:\n    _has_tb = False\n\nfrom tensordict import TensorDict\nfrom torchrl.data import (\n    LazyMemmapStorage,\n    LazyTensorStorage,\n    ListStorage,\n    TensorDictPrioritizedReplayBuffer,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3173076923076923}, {"context": "\ntry:\n    from tqdm import tqdm\n\n    _has_tqdm = True\nexcept ImportError:\n    _has_tqdm = False\n\ntry:\n    from torchsnapshot import Snapshot, StateDict\n\n    _has_ts = True\nexcept ImportError:\n    _has_ts = False\n\nREPLAY_BUFFER_CLASS = {\n    \"prioritized\": TensorDictPrioritizedReplayBuffer,\n    \"circular\": TensorDictReplayBuffer,\n}\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3010752688172043}, {"context": "\nimport numpy as np\nimport pytest\nimport torch\nfrom _utils_internal import get_available_devices\nfrom tensordict.prototype import is_tensorclass, tensorclass\nfrom tensordict.tensordict import assert_allclose_td, TensorDict, TensorDictBase\nfrom torchrl.data import (\n    PrioritizedReplayBuffer,\n    RemoteTensorDictReplayBuffer,\n    ReplayBuffer,\n    TensorDictPrioritizedReplayBuffer,\n    TensorDictReplayBuffer,\n)\nfrom torchrl.data.replay_buffers import samplers, writers\nfrom torchrl.data.replay_buffers.samplers import (\n    PrioritizedSampler,\n    RandomSampler,\n    SamplerWithoutReplacement,\n)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.29245283018867924}, {"context": "from collections import defaultdict, OrderedDict\nfrom copy import deepcopy\nfrom textwrap import indent\nfrom typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Type, Union\n\nimport numpy as np\nimport torch.nn\nfrom tensordict.tensordict import pad, TensorDictBase\nfrom tensordict.utils import expand_right\nfrom torch import nn, optim\n\nfrom torchrl._utils import _CKPT_BACKEND, KeyDependentDefaultDict\nfrom torchrl.collectors.collectors import _DataCollector\nfrom torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\nfrom torchrl.data.utils import DEVICE_TYPING\nfrom torchrl.envs.common import EnvBase\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.record.loggers import Logger", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2900763358778626}, {"context": "    _has_tb = True\nexcept ImportError:\n    _has_tb = False\n\nfrom tensordict import TensorDict\nfrom torchrl.data import (\n    LazyMemmapStorage,\n    LazyTensorStorage,\n    ListStorage,\n    TensorDictPrioritizedReplayBuffer,\n    TensorDictReplayBuffer,\n)\nfrom torchrl.envs.libs.gym import _has_gym\nfrom torchrl.trainers import Recorder, Trainer\nfrom torchrl.trainers.helpers import transformed_env_constructor\nfrom torchrl.trainers.trainers import (\n    _has_tqdm,\n    _has_ts,\n    BatchSubSampler,\n    CountFramesLog,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28440366972477066}, {"context": "import torch\n\nfrom tensordict.nn import TensorDictSequential\nfrom tensordict.tensordict import TensorDict, TensorDictBase\nfrom torch import Tensor\n\nfrom torchrl.envs.utils import set_exploration_mode, step_mdp\nfrom torchrl.modules import SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.objectives.utils import (\n    distance_loss,\n    next_state_value as get_next_state_value,\n)\n\ntry:\n    from functorch import vmap\n\n    FUNCTORCH_ERR = \"\"\n    _has_functorch = True\nexcept ImportError as err:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "redq.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2807017543859649}, {"context": "import torch\n\nfrom tensordict import TensorDict\nfrom tensordict.tensordict import TensorDictBase\nfrom torch import Tensor\nfrom torchrl.envs.utils import set_exploration_mode, step_mdp\nfrom torchrl.modules import SafeModule\nfrom torchrl.objectives import (\n    distance_loss,\n    hold_out_params,\n    next_state_value as get_next_state_value,\n)\nfrom torchrl.objectives.common import LossModule\n\ntry:\n    from functorch import vmap\n\n    FUNCTORCH_ERR = \"\"\n    _has_functorch = True\nexcept ImportError as err:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "deprecated.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2807017543859649}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/training/train_state.py\n# --------------------------------------------------\n# from __future__ import annotations\n# \n# from typing import Any\n# \n# import jax.numpy as jnp\n# from flax.training import train_state\n# \n# from fortuna.utils.strings import convert_string_to_jnp_array\n# \n# \n# class TrainState(train_state.TrainState):\n#     encoded_name: jnp.ndarray = convert_string_to_jnp_array(\"TrainState\")\n# \n#     @classmethod\n#     def init(cls, *args, **kwargs) -> Any:\n#         pass\n# \n#     @classmethod\n#     def init_from_dict(cls, *args, **kwargs) -> TrainState:\n#         pass\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/conformal/classification/adaptive_prediction.py\n# --------------------------------------------------\n# from typing import List, Optional\n# \n# import jax.numpy as jnp\n# import numpy as np\n# from jax import vmap\n# \n# from fortuna.typing import Array\n# \n# \n# class AdaptivePredictionConformalClassifier:\n#     def score(self, val_probs: Array, val_targets: Array,) -> jnp.ndarray:\n#         \"\"\"\n#         Compute score function.\n# \n#         Parameters\n#         ----------\n#         val_probs: Array\n#             A two-dimensional array of class probabilities for each validation data point.\n#         val_targets: Array\n#             A one-dimensional array of validation target variables.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/normalizing_flow/advi/advi_architecture.py\n# --------------------------------------------------\n# from __future__ import annotations\n# \n# from typing import Optional, Tuple\n# \n# import jax.numpy as jnp\n# from jax import random\n# from jax._src.prng import PRNGKeyArray\n# \n# from fortuna.utils.builtins import HashableMixin\n# \n# \n# class ADVIArchitecture(HashableMixin):\n#     def __init__(self, dim: int, std_init_params: float = 0.1):\n#         \"\"\"\n#         ADVI architecture. This consists of a simple component-wise linear transformation of the input. The\n#         transformation includes a mean and a log-scale parameters. With this architecture, when the base distribution\n#         is a diagonal Gaussian, the resulting push-forward will also be. See\n#          [Dinh et al., 2017](https://arxiv.org/abs/1605.08803) for reference.\n# \n#         :param dim: int\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/normalizing_flow/advi/advi_posterior.py\n# --------------------------------------------------\n# from __future__ import annotations\n# \n# import logging\n# from typing import Optional, Tuple\n# \n# import jax.numpy as jnp\n# from flax.core import FrozenDict\n# from jax._src.prng import PRNGKeyArray\n# from jax.flatten_util import ravel_pytree\n# \n# from fortuna.data.loader import DataLoader, InputsLoader\n# from fortuna.distribution.gaussian import DiagGaussian\n# from fortuna.prob_model.fit_config import FitConfig\n# from fortuna.prob_model.joint.base import Joint\n# from fortuna.prob_model.joint.state import JointState\n# from fortuna.prob_model.posterior.base import Posterior\n# from fortuna.prob_model.posterior.normalizing_flow.advi import ADVI_NAME\n# from fortuna.prob_model.posterior.normalizing_flow.advi.advi_approximator import \\\n#     ADVIPosteriorApproximator\n# from fortuna.prob_model.posterior.normalizing_flow.advi.advi_architecture import \\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/normalizing_flow/normalizing_flow_trainer.py\n# --------------------------------------------------\n# from __future__ import annotations\n# \n# import abc\n# from typing import Any, Callable, Dict, Optional, Tuple, Union\n# \n# import jax.numpy as jnp\n# import numpy as np\n# from flax.core import FrozenDict\n# from jax import random, vmap\n# from jax._src.prng import PRNGKeyArray\n# from jax.tree_util import tree_map\n# from optax._src.base import PyTree\n# \n# from fortuna.distribution.base import Distribution\n# from fortuna.prob_model.posterior.posterior_trainer import PosteriorTrainerABC\n# from fortuna.prob_model.posterior.state import PosteriorState\n# from fortuna.typing import Array, Batch, CalibMutable, CalibParams, Params\n# \n# \n# class NormalizingFlowTrainer(PosteriorTrainerABC):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/swag/swag_posterior.py\n# --------------------------------------------------\n# from __future__ import annotations\n# \n# import logging\n# from typing import Optional\n# \n# import jax.numpy as jnp\n# from jax import random\n# from jax._src.prng import PRNGKeyArray\n# from jax.flatten_util import ravel_pytree\n# \n# from fortuna.data.loader import DataLoader, InputsLoader\n# from fortuna.prob_model.fit_config import FitConfig\n# from fortuna.prob_model.joint.base import Joint\n# from fortuna.prob_model.joint.state import JointState\n# from fortuna.prob_model.posterior.base import Posterior\n# from fortuna.prob_model.posterior.map.map_approximator import \\\n#     MAPPosteriorApproximator\n# from fortuna.prob_model.posterior.map.map_posterior import MAPPosterior\n# from fortuna.prob_model.posterior.map.map_state import MAPState\n# from fortuna.prob_model.posterior.posterior_state_repository import \\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n# from __future__ import annotations\n# \n# from typing import Callable, Iterable, Optional, Union\n# \n# import jax\n# import numpy as np\n# from flax import jax_utils\n# from jax.tree_util import tree_map\n# \n# from fortuna.typing import Array, Batch\n# \n# \n# class DataLoader:\n#     def __init__(\n#         self,\n#         data_loader: Union[\n#             FromIterableToDataLoader,\n#             FromCallableIterableToDataLoader,\n#             FromArrayDataToDataLoader,\n#             FromTensorFlowDataLoaderToDataLoader,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport os\nimport pathlib\nfrom typing import List, Optional\n\nimport numpy as np", "choices": [{"text": "output_dir: Optional[pathlib.Path] = None"}], "metadata": {"task_id": "awslabs_fortuna/193", "ground_truth": "from jax._src.prng import PRNGKeyArray", "fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "deep_ensemble", "deep_ensemble_posterior.py"], "context_start_lineno": 0, "line_no": 8, "query_window": {"context": "from __future__ import annotations\n\nimport logging\nimport os\nimport pathlib\nfrom typing import List, Optional\n\nimport numpy as np", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "deep_ensemble", "deep_ensemble_posterior.py"], "line_no": 8, "task_id": "awslabs_fortuna/193", "start_line_no": 0, "end_line_no": 8, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "from __future__ import annotations\n\nfrom typing import Callable, Iterable, Optional, Union\n\nimport jax\nimport numpy as np\nfrom flax import jax_utils\nfrom jax.tree_util import tree_map\n\nfrom fortuna.typing import Array, Batch", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.36585365853658536}, {"context": "from __future__ import annotations\n\nimport logging\nfrom typing import Optional\n\nimport jax.numpy as jnp\nfrom jax import random\nfrom jax._src.prng import PRNGKeyArray\nfrom jax.flatten_util import ravel_pytree\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "swag", "swag_posterior.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.30952380952380953}, {"context": "from __future__ import annotations\n\nimport abc\nfrom typing import Any, Callable, Dict, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom flax.core import FrozenDict\nfrom jax import random, vmap\nfrom jax._src.prng import PRNGKeyArray", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "normalizing_flow", "normalizing_flow_trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3}, {"context": "from __future__ import annotations\n\nimport logging\nfrom typing import Optional, Tuple\n\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom jax._src.prng import PRNGKeyArray\nfrom jax.flatten_util import ravel_pytree\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "normalizing_flow", "advi", "advi_posterior.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2916666666666667}, {"context": "from __future__ import annotations\n\nfrom typing import Optional, Tuple\n\nimport jax.numpy as jnp\nfrom jax import random\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.utils.builtins import HashableMixin\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "normalizing_flow", "advi", "advi_architecture.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.28888888888888886}, {"context": "from typing import List, Optional\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom jax import vmap\n\nfrom fortuna.typing import Array\n\n\nclass AdaptivePredictionConformalClassifier:", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "classification", "adaptive_prediction.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2727272727272727}, {"context": "from __future__ import annotations\n\nfrom typing import Any\n\nimport jax.numpy as jnp\nfrom flax.training import train_state\n\nfrom fortuna.utils.strings import convert_string_to_jnp_array\n\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "training", "train_state.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2682926829268293}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_ppo():\n#     config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         ppo_main(config[0], seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_sac():\n#     config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#     config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n#     config[0].policy.cuda = False\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     finally:\n#         os.popen('rm -rf log ckpt*')\n# \n# \n# @pytest.mark.unittest\n# def test_coma():\n#     config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\n#     config[0].policy.cuda = False\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n# def test_her_dqn():\n#     bitflip_her_dqn_config.policy.cuda = False\n#     try:\n#         bitflip_dqn_main(bitflip_her_dqn_config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_collaq():\n#     config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n#     config[0].policy.cuda = False\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     finally:\n#         os.popen('rm -rf log ckpt*')\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_sac_auto_alpha():\n#     config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     config[0].policy.learn.is_auto_alpha = True\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_r2d2():\n#     config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n# \n# @pytest.mark.unittest\n# def test_coma():\n#     config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\n#     config[0].policy.cuda = False\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     finally:\n#         os.popen('rm -rf log ckpt*')\n# \n# \n# @pytest.mark.unittest\n# def test_qmix():\n#     config = [deepcopy(cooperative_navigation_qmix_config), deepcopy(cooperative_navigation_qmix_create_config)]\n#     config[0].policy.cuda = False\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         ppo_main(config[0], seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_sac():\n#     config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_sac_auto_alpha():\n#     config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     config[0].policy.learn.is_auto_alpha = True\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\ncreate_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_rainbow_config import cartpole_rainbow_config, cartpole_rainbow_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_iqn_config import cartpole_iqn_config, cartpole_iqn_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_c51_config import cartpole_c51_config, cartpole_c51_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_qrdqn_config import cartpole_qrdqn_config, cartpole_qrdqn_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_sqn_config import cartpole_sqn_config, cartpole_sqn_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_ppg_config import cartpole_ppg_config, cartpole_ppg_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_acer_config import cartpole_acer_config, cartpole_acer_create_config  # noqa\nfrom dizoo.classic_control.cartpole.entry.cartpole_ppg_main import main as ppg_main\nfrom dizoo.classic_control.cartpole.entry.cartpole_ppo_main import main as ppo_main\nfrom dizoo.classic_control.cartpole.config.cartpole_r2d2_config import cartpole_r2d2_config, cartpole_r2d2_create_config  # noqa\nfrom dizoo.classic_control.pendulum.config import pendulum_ddpg_config, pendulum_ddpg_create_config\nfrom dizoo.classic_control.pendulum.config import pendulum_td3_config, pendulum_td3_create_config\nfrom dizoo.classic_control.pendulum.config import pendulum_sac_config, pendulum_sac_create_config\nfrom dizoo.classic_control.bitflip.config import bitflip_her_dqn_config, bitflip_her_dqn_create_config\nfrom dizoo.classic_control.bitflip.entry.bitflip_dqn_main import main as bitflip_dqn_main\nfrom dizoo.multiagent_particle.config import cooperative_navigation_qmix_config, cooperative_navigation_qmix_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_wqmix_config, cooperative_navigation_wqmix_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_vdn_config, cooperative_navigation_vdn_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_coma_config, cooperative_navigation_coma_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_collaq_config, cooperative_navigation_collaq_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_atoc_config, cooperative_navigation_atoc_create_config  # noqa\nfrom dizoo.league_demo.league_demo_ppo_config import league_demo_ppo_config\nfrom dizoo.league_demo.selfplay_demo_ppo_main import main as selfplay_main\nfrom dizoo.league_demo.league_demo_ppo_main import main as league_main\nfrom dizoo.classic_control.pendulum.config.pendulum_sac_data_generation_default_config import pendulum_sac_data_genearation_default_config, pendulum_sac_data_genearation_default_create_config  # noqa\nfrom dizoo.classic_control.pendulum.config.pendulum_cql_config import pendulum_cql_default_config, pendulum_cql_default_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_qrdqn_generation_data_config import cartpole_qrdqn_generation_data_config, cartpole_qrdqn_generation_data_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_cql_config import cartpole_discrete_cql_config, cartpole_discrete_cql_create_config  # noqa\n\nwith open(\"./algo_record.log\", \"w+\") as f:\n    f.write(\"ALGO TEST STARTS\\n\")\n\n\n@pytest.mark.algotest\ndef test_dqn():\n    config = [deepcopy(cartpole_dqn_config), deepcopy(cartpole_dqn_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"1. dqn\\n\")\n\n\n@pytest.mark.algotest\ndef test_ddpg():\n    config = [deepcopy(pendulum_ddpg_config), deepcopy(pendulum_ddpg_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"2. ddpg\\n\")\n\n\n@pytest.mark.algotest\ndef test_td3():\n    config = [deepcopy(pendulum_td3_config), deepcopy(pendulum_td3_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"3. td3\\n\")\n\n\n@pytest.mark.algotest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"4. a2c\\n\")\n\n\n@pytest.mark.algotest\ndef test_rainbow():\n    config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"5. rainbow\\n\")\n\n\n@pytest.mark.algotest\ndef test_ppo():\n    config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n    try:\n        ppo_main(config[0], seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"6. ppo\\n\")\n\n\n# @pytest.mark.algotest\ndef test_collaq():\n    config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"7. collaq\\n\")\n\n\n# @pytest.mark.algotest\ndef test_coma():", "choices": [{"text": "config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]"}], "metadata": {"task_id": "opendilab_ACE/84", "ground_truth": "    config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]", "fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "context_start_lineno": 15, "line_no": 128, "query_window": {"context": "        ppo_main(config[0], seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"6. ppo\\n\")\n\n\n# @pytest.mark.algotest\ndef test_collaq():\n    config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"7. collaq\\n\")\n\n\n# @pytest.mark.algotest\ndef test_coma():", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 128, "task_id": "opendilab_ACE/84", "start_line_no": 108, "end_line_no": 128, "window_size": 20, "context_start_lineno": 15, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_ppo():\n    config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        ppo_main(config[0], seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sac():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.47474747474747475}, {"context": "    config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n    config[0].policy.cuda = False\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_coma():\n    config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\n    config[0].policy.cuda = False\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4722222222222222}, {"context": "        ppo_main(config[0], seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sac():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sac_auto_alpha():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    config[0].policy.learn.is_auto_alpha = True", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.47}, {"context": "def test_impala():\n    config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_her_dqn():\n    bitflip_her_dqn_config.policy.cuda = False\n    try:\n        bitflip_dqn_main(bitflip_her_dqn_config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_collaq():", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4519230769230769}, {"context": "def test_her_dqn():\n    bitflip_her_dqn_config.policy.cuda = False\n    try:\n        bitflip_dqn_main(bitflip_her_dqn_config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_collaq():\n    config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n    config[0].policy.cuda = False\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.45132743362831856}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_qrdqn():\n    config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_ppo():\n    config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4489795918367347}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/tensordict_module/exploration.py\n# --------------------------------------------------\n#         Args:\n#             frames (int): number of frames since last step.\n# \n#         \"\"\"\n#         for _ in range(frames):\n#             self.sigma.data[0] = max(\n#                 self.sigma_end.item(),\n#                 (\n#                     self.sigma\n#                     - (self.sigma_init - self.sigma_end) / self.annealing_num_steps\n#                 ).item(),\n#             )\n# \n#     def _add_noise(self, action: torch.Tensor) -> torch.Tensor:\n#         sigma = self.sigma.item()\n#         noise = torch.normal(\n#             mean=torch.ones(action.shape) * self.mean.item(),\n#             std=torch.ones(action.shape) * self.std.item(),\n#         ).to(action.device)\n#         action = action + noise * sigma\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_collector.py\n# --------------------------------------------------\n# \n#     if collector_class is not SyncDataCollector:\n#         collector_kwargs[\"create_env_fn\"] = [\n#             collector_kwargs[\"create_env_fn\"] for _ in range(num_envs)\n#         ]\n# \n#     collector = collector_class(**collector_kwargs)\n# \n#     keys = {\n#         \"action\",\n#         \"done\",\n#         \"collector\",\n#         \"hidden1\",\n#         \"hidden2\",\n#         (\"collector\", \"mask\"),\n#         (\"next\", \"hidden1\"),\n#         (\"next\", \"hidden2\"),\n#         (\"next\", \"observation\"),\n#         \"next\",\n#         \"observation\",\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/collectors.py\n# --------------------------------------------------\n#         else cfg.collector_devices[0]\n#     )\n#     collector_helper_kwargs = {\n#         \"env_fns\": make_env,\n#         \"env_kwargs\": env_kwargs,\n#         \"policy\": actor_model_explore,\n#         \"max_frames_per_traj\": cfg.max_frames_per_traj,\n#         \"frames_per_batch\": cfg.frames_per_batch,\n#         \"total_frames\": cfg.total_frames,\n#         \"postproc\": ms,\n#         \"num_env_per_collector\": 1,\n#         # we already took care of building the make_parallel_env function\n#         \"num_collectors\": -cfg.num_workers // -cfg.env_per_collector,\n#         \"devices\": cfg.collector_devices,\n#         \"passing_devices\": cfg.collector_devices,\n#         \"pin_memory\": cfg.pin_memory,\n#         \"split_trajs\": True,\n#         # trajectories must be separated in online settings\n#         \"init_with_lag\": cfg.init_with_lag,\n#         \"exploration_mode\": cfg.exploration_mode,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/collectors.py\n# --------------------------------------------------\n#         \"init_random_frames\": cfg.init_random_frames,\n#         \"pin_memory\": cfg.pin_memory,\n#         \"split_trajs\": True,\n#         # trajectories must be separated if multi-step is used\n#         \"init_with_lag\": cfg.init_with_lag,\n#         \"exploration_mode\": cfg.exploration_mode,\n#     }\n# \n#     collector = collector_helper(**collector_helper_kwargs)\n#     collector.set_seed(cfg.seed)\n#     return collector\n# \n# \n# def make_collector_onpolicy(\n#     make_env: Callable[[], EnvBase],\n#     actor_model_explore: Union[TensorDictModuleWrapper, SafeProbabilisticSequential],\n#     cfg: \"DictConfig\",  # noqa: F821\n#     make_env_kwargs: Optional[Dict] = None,\n# ) -> _DataCollector:\n#     \"\"\"Makes a collector in on-policy settings.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/dreamer/dreamer.py\n# --------------------------------------------------\n#         if (i % cfg.record_interval) == 0:\n#             do_log = True\n#         else:\n#             do_log = False\n# \n#         if collected_frames >= cfg.init_random_frames:\n#             if i % cfg.record_interval == 0:\n#                 logger.log_scalar(\"cmpt\", cmpt)\n#             for j in range(cfg.optim_steps_per_batch):\n#                 cmpt += 1\n#                 # sample from replay buffer\n#                 sampled_tensordict = replay_buffer.sample(cfg.batch_size).to(\n#                     device, non_blocking=True\n#                 )\n#                 if reward_normalizer is not None:\n#                     sampled_tensordict = reward_normalizer.normalize_reward(\n#                         sampled_tensordict\n#                     )\n#                 # update world model\n#                 with autocast(dtype=torch.float16):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/collectors/collectors.py\n# --------------------------------------------------\n#             for j in range(self.frames_per_batch):\n#                 if self._frames < self.init_random_frames:\n#                     self.env.rand_step(self._tensordict)\n#                 else:\n#                     td_cast = self._cast_to_policy(self._tensordict)\n#                     td_cast = self.policy(td_cast)\n#                     self._cast_to_env(td_cast, self._tensordict)\n#                     self._tensordict = self.env.step(self._tensordict)\n# \n#                 step_count = self._tensordict.get((\"collector\", \"step_count\"))\n#                 self._tensordict.set_((\"collector\", \"step_count\"), step_count + 1)\n#                 # we must clone all the values, since the step / traj_id updates are done in-place\n#                 try:\n#                     self._tensordict_out[..., j] = self._tensordict\n#                 except RuntimeError:\n#                     # unlock the output tensordict to allow for new keys to be written\n#                     # these will be missed during the sync but at least we won't get an error during the update\n#                     is_shared = self._tensordict_out.is_shared()\n#                     self._tensordict_out.unlock()\n#                     self._tensordict_out[..., j] = self._tensordict\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom dataclasses import dataclass, field as dataclass_field\nfrom typing import Any, Callable, Optional, Sequence, Tuple, Union\n\nimport torch\n\nfrom torchrl.envs import ParallelEnv\nfrom torchrl.envs.common import EnvBase\nfrom torchrl.envs.env_creator import env_creator, EnvCreator\nfrom torchrl.envs.libs.dm_control import DMControlEnv\nfrom torchrl.envs.libs.gym import GymEnv\nfrom torchrl.envs.transforms import (\n    CatFrames,\n    CatTensors,\n    CenterCrop,\n    Compose,\n    DoubleToFloat,\n    FiniteTensorDictCheck,\n    GrayScale,\n    NoopResetEnv,\n    ObservationNorm,\n    Resize,\n    RewardScaling,\n    ToTensorImage,\n    TransformedEnv,\n    VecNorm,\n)\nfrom torchrl.envs.transforms.transforms import FlattenObservation, gSDENoise\nfrom torchrl.record.loggers import Logger\nfrom torchrl.record.recorder import VideoRecorder\n\nLIBS = {\n    \"gym\": GymEnv,\n    \"dm_control\": DMControlEnv,\n}\n\n\ndef correct_for_frame_skip(cfg: \"DictConfig\") -> \"DictConfig\":  # noqa: F821\n    \"\"\"Correct the arguments for the input frame_skip, by dividing all the arguments that reflect a count of frames by the frame_skip.\n\n    This is aimed at avoiding unknowingly over-sampling from the environment, i.e. targetting a total number of frames\n    of 1M but actually collecting frame_skip * 1M frames.\n\n    Args:\n        cfg (DictConfig): DictConfig containing some frame-counting argument, including:\n            \"max_frames_per_traj\", \"total_frames\", \"frames_per_batch\", \"record_frames\", \"annealing_frames\",\n            \"init_random_frames\", \"init_env_steps\"\n\n    Returns:\n         the input DictConfig, modified in-place.\n\n    \"\"\"\n    # Adapt all frame counts wrt frame_skip\n    if cfg.frame_skip != 1:\n        fields = [\n            \"max_frames_per_traj\",\n            \"total_frames\",\n            \"frames_per_batch\",\n            \"record_frames\",\n            \"annealing_frames\",\n            \"init_random_frames\",\n            \"init_env_steps\",\n            \"noops\",\n        ]\n        for field in fields:\n            if hasattr(cfg, field):\n                setattr(cfg, field, getattr(cfg, field) // cfg.frame_skip)", "choices": [{"text": "cfg`."}], "metadata": {"task_id": "pytorch_rl/20", "ground_truth": "    return cfg", "fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "envs.py"], "context_start_lineno": 0, "line_no": 71, "query_window": {"context": "\n    Returns:\n         the input DictConfig, modified in-place.\n\n    \"\"\"\n    # Adapt all frame counts wrt frame_skip\n    if cfg.frame_skip != 1:\n        fields = [\n            \"max_frames_per_traj\",\n            \"total_frames\",\n            \"frames_per_batch\",\n            \"record_frames\",\n            \"annealing_frames\",\n            \"init_random_frames\",\n            \"init_env_steps\",\n            \"noops\",\n        ]\n        for field in fields:\n            if hasattr(cfg, field):\n                setattr(cfg, field, getattr(cfg, field) // cfg.frame_skip)", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "envs.py"], "line_no": 71, "task_id": "pytorch_rl/20", "start_line_no": 51, "end_line_no": 71, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            self._tensordict.update(self.env.reset(), inplace=True)\n            self._tensordict.fill_((\"collector\", \"step_count\"), 0)\n\n        n = self.env.batch_size[0] if len(self.env.batch_size) else 1\n        self._tensordict.set(\n            (\"collector\", \"traj_ids\"),\n            torch.arange(n).view(self.env.batch_size[:1]),\n        )\n\n        with set_exploration_mode(self.exploration_mode):\n            for j in range(self.frames_per_batch):\n                if self._frames < self.init_random_frames:\n                    self.env.rand_step(self._tensordict)\n                else:\n                    td_cast = self._cast_to_policy(self._tensordict)\n                    td_cast = self.policy(td_cast)\n                    self._cast_to_env(td_cast, self._tensordict)\n                    self._tensordict = self.env.step(self._tensordict)\n\n                step_count = self._tensordict.get((\"collector\", \"step_count\"))", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "collectors", "collectors.py"], "line_no": 660, "start_line_no": 650, "end_line_no": 670, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.25}, {"context": "\n        # tensordict = tensordict.reshape(-1, cfg.batch_length)\n        print(tensordict.shape)\n        replay_buffer.extend(tensordict.cpu())\n        logger.log_scalar(\n            \"r_training\",\n            tensordict[\"reward\"].mean().detach().item(),\n            step=collected_frames,\n        )\n\n        if (i % cfg.record_interval) == 0:\n            do_log = True\n        else:\n            do_log = False\n\n        if collected_frames >= cfg.init_random_frames:\n            if i % cfg.record_interval == 0:\n                logger.log_scalar(\"cmpt\", cmpt)\n            for j in range(cfg.optim_steps_per_batch):\n                cmpt += 1", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "dreamer", "dreamer.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.24615384615384617}, {"context": "        \"policy\": actor_model_explore,\n        \"max_frames_per_traj\": cfg.max_frames_per_traj,\n        \"frames_per_batch\": cfg.frames_per_batch,\n        \"total_frames\": cfg.total_frames,\n        \"postproc\": ms,\n        \"num_env_per_collector\": 1,\n        # we already took care of building the make_parallel_env function\n        \"num_collectors\": -cfg.num_workers // -cfg.env_per_collector,\n        \"devices\": cfg.collector_devices,\n        \"passing_devices\": cfg.collector_devices,\n        \"init_random_frames\": cfg.init_random_frames,\n        \"pin_memory\": cfg.pin_memory,\n        \"split_trajs\": True,\n        # trajectories must be separated if multi-step is used\n        \"init_with_lag\": cfg.init_with_lag,\n        \"exploration_mode\": cfg.exploration_mode,\n    }\n\n    collector = collector_helper(**collector_helper_kwargs)\n    collector.set_seed(cfg.seed)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "collectors.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.24390243902439024}, {"context": "    ms = None\n\n    env_kwargs = {}\n    if make_env_kwargs is not None and isinstance(make_env_kwargs, dict):\n        env_kwargs.update(make_env_kwargs)\n    elif make_env_kwargs is not None:\n        env_kwargs = make_env_kwargs\n    cfg.collector_devices = (\n        cfg.collector_devices\n        if len(cfg.collector_devices) > 1\n        else cfg.collector_devices[0]\n    )\n    collector_helper_kwargs = {\n        \"env_fns\": make_env,\n        \"env_kwargs\": env_kwargs,\n        \"policy\": actor_model_explore,\n        \"max_frames_per_traj\": cfg.max_frames_per_traj,\n        \"frames_per_batch\": cfg.frames_per_batch,\n        \"total_frames\": cfg.total_frames,\n        \"postproc\": ms,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "collectors.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.23853211009174313}, {"context": "\n    policy(env_maker().reset())\n\n    collector_kwargs = {\n        \"create_env_fn\": env_maker,\n        \"policy\": policy,\n        \"total_frames\": total_frames,\n        \"frames_per_batch\": frames_per_batch,\n        \"init_random_frames\": init_random_frames,\n    }\n\n    if collector_class is not SyncDataCollector:\n        collector_kwargs[\"create_env_fn\"] = [\n            collector_kwargs[\"create_env_fn\"] for _ in range(num_envs)\n        ]\n\n    collector = collector_class(**collector_kwargs)\n\n    keys = {\n        \"action\",", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_collector.py"], "line_no": 980, "start_line_no": 970, "end_line_no": 990, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.23809523809523808}, {"context": "            if hasattr(policy, \"spec\")\n            else None\n        )\n        self.safe = safe\n\n    def step(self, frames: int = 1) -> None:\n        \"\"\"A step of sigma decay.\n\n        After self.annealing_num_steps, this function is a no-op.\n\n        Args:\n            frames (int): number of frames since last step.\n\n        \"\"\"\n        for _ in range(frames):\n            self.sigma.data[0] = max(\n                self.sigma_end.item(),\n                (\n                    self.sigma\n                    - (self.sigma_init - self.sigma_end) / self.annealing_num_steps", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "exploration.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.23728813559322035}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/pretrained_models.py\n# --------------------------------------------------\n# \n# ##############################################################################\n# # We collect a rollout of 32 steps and print its output:\n# #\n# rollout = env_transformed.rollout(32, policy)\n# print(\"rollout with transform:\", rollout)\n# \n# ##############################################################################\n# # For fine tuning, we integrate the transform in the policy after making the parameters\n# # trainable. In practice, it may be wiser to restrict this to a subset of the parameters (say the last layer\n# # of the MLP).\n# #\n# r3m.train()\n# policy = TensorDictSequential(r3m, policy)\n# print(\"number of params after r3m is integrated:\", len(list(policy.parameters())))\n# \n# ##############################################################################\n# # Again, we collect a rollout with R3M. The structure of the output has changed slightly, as now\n# # the environment returns pixels (and not an embedding). The embedding \"r3m_vec\" is an intermediate\n# # result of our policy.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n# \n#         If True, the env needs to be used with a tensordict having the same batch size as the env.\n#         batch_locked is an immutable property.\n#         \"\"\"\n#         return self._batch_locked\n# \n#     @batch_locked.setter\n#     def batch_locked(self, value: bool) -> None:\n#         raise RuntimeError(\"batch_locked is a read-only property\")\n# \n#     @property\n#     def run_type_checks(self) -> bool:\n#         return self._run_type_checks\n# \n#     @run_type_checks.setter\n#     def run_type_checks(self, run_type_checks: bool) -> None:\n#         self._run_type_checks = run_type_checks\n# \n#     @property\n#     def batch_size(self) -> TensorSpec:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_transforms.py\n# --------------------------------------------------\n# \n#         assert env._input_spec is not None\n#         assert \"action\" in env._input_spec\n#         assert env._input_spec[\"action\"] is not None\n#         assert env._observation_spec is not None\n#         assert env._reward_spec is not None\n# \n#         env.insert_transform(0, CatFrames(N=4, dim=-1, in_keys=[key]))\n# \n#         # transformed envs do not have spec after insert -- they need to be computed\n#         assert env._input_spec is None\n#         assert env._observation_spec is None\n#         assert env._reward_spec is None\n# \n#         assert isinstance(env.transform, Compose)\n#         assert len(env.transform) == 1\n#         obs_spec = env.observation_spec\n#         obs_spec = obs_spec[key]\n#         assert obs_spec.shape[-1] == 4 * env.base_env.observation_spec[key].shape[-1]\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/tensordict_tutorial.py\n# --------------------------------------------------\n# tensordict.set(\"d\", torch.ones(tensordict.shape))\n# assert (tensordict[\"c\"] == 0).all()\n# assert (tensordict[\"d\"] == 1).all()\n# \n# ###############################################################################\n# # ``values()``\n# # ------------------------------\n# # The values of a ``TensorDict`` can be retrieved with the ``values()`` function.\n# # Note that, unlike python ``dicts``, the ``values()`` method returns a\n# # generator and not a list.\n# \n# for value in tensordict.values():\n#     print(value.shape)\n# \n# ###############################################################################\n# # ``update(tensordict_or_dict)``\n# # ------------------------------\n# # The ``update`` method can be used to update a TensorDict with another one\n# # (or with a dict):\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/tensordict_tutorial.py\n# --------------------------------------------------\n# \n# for value in tensordict.values():\n#     print(value.shape)\n# \n# ###############################################################################\n# # ``update(tensordict_or_dict)``\n# # ------------------------------\n# # The ``update`` method can be used to update a TensorDict with another one\n# # (or with a dict):\n# \n# tensordict.update({\"a\": torch.ones((3, 4, 5)), \"d\": 2 * torch.ones((3, 4, 2))})\n# # Also works with tensordict.update(TensorDict({\"a\":torch.ones((3, 4, 5)),\n# # \"c\":torch.ones((3, 4, 2))}, batch_size=[3,4]))\n# print(f\"a is now equal to 1: {(tensordict['a'] == 1).all()}\")\n# print(f\"d is now equal to 2: {(tensordict['d'] == 2).all()}\")\n# \n# ###############################################################################\n# # ``del``\n# # ------------------------------\n# # TensorDict also support keys deletion with the ``del`` operator:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/torchrl_demo.py\n# --------------------------------------------------\n# \n# from torchrl.envs.utils import step_mdp\n# \n# env = GymEnv(\"Pendulum-v1\")\n# \n# action_spec = env.action_spec\n# actor_module = nn.Linear(3, 1)\n# actor = SafeModule(\n#     actor_module, spec=action_spec, in_keys=[\"observation\"], out_keys=[\"action\"]\n# )\n# \n# torch.manual_seed(0)\n# env.set_seed(0)\n# \n# max_steps = 100\n# tensordict = env.reset()\n# tensordicts = TensorDict({}, [max_steps])\n# for i in range(max_steps):\n#     actor(tensordict)\n#     tensordicts[i] = env.step(tensordict)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n# \n#     _keys = {\n#         \"action_spec\",\n#         \"observation_spec\",\n#         \"reward_spec\",\n#         \"input_spec\",\n#         \"from_pixels\",\n#     }\n# \n#     def __init__(self, env: EnvBase):\n#         self.env = env\n# \n#     def __getitem__(self, item: str) -> Any:\n#         if item not in self._keys:\n#             raise KeyError(f\"item must be one of {self._keys}\")\n#         return getattr(self.env, item)\n# \n#     def keys(self) -> Sequence[str]:\n#         return self._keys\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# -*- coding: utf-8 -*-\n\"\"\"\nTorchRL envs\n============================\n\"\"\"\n##############################################################################\n# Environments play a crucial role in RL settings, often somewhat similar to\n# datasets in supervised and unsupervised settings. The RL community has\n# become quite familiar with OpenAI gym API which offers a flexible way of\n# building environments, initializing them and interacting with them. However,\n# many other libraries exist, and the way one interacts with them can be quite\n# different from what is expected with *gym*.\n#\n# Let us start by describing how TorchRL interacts with gym, which will serve\n# as an introduction to other frameworks.\n#\n# Gym environments\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n# To run this part of the tutorial, you will need to have a recent version of\n# the gym library installed, as well as the atari suite. You can get this\n# installed by installing the following packages:\n#   $ pip install gym atari-py ale-py gym[accept-rom-license] pygame\n# To unify all frameworks, torchrl environments are built inside the\n# ``__init__`` method with a private method called ``_build_env`` that\n# will pass the arguments and keyword arguments to the root library builder.\n#\n# With gym, it means that building an environment is as easy as:\n# sphinx_gallery_start_ignore\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n# sphinx_gallery_end_ignore\n\nimport torch\nfrom matplotlib import pyplot as plt\nfrom tensordict import TensorDict\n\n##############################################################################\n\nfrom torchrl.envs.libs.gym import GymEnv\n\nenv = GymEnv(\"Pendulum-v1\")\n\n###############################################################################\n# The list of available environment can be accessed through this command:\n\nGymEnv.available_envs[:10]\n\n###############################################################################\n# Env Specs\n# ------------------------------\n# Like other frameworks, TorchRL envs have attributes that indicate what\n# space is for the observations, action and reward. Because it often happens\n# that more than one observation is retrieved, we expect the observation spec\n# to be of type ``CompositeSpec``. Reward and action do not have this restriction:\n\nprint(\"Env observation_spec: \\n\", env.observation_spec)\nprint(\"Env action_spec: \\n\", env.action_spec)\nprint(\"Env reward_spec: \\n\", env.reward_spec)\n\n###############################################################################\n# Those spec come with a series of useful tools: one can assert whether a\n# sample is in the defined space. We can also use some heuristic to project\n# a sample in the space if it is out of space, and generate random (possibly\n# uniformly distributed) numbers in that space:\n\naction = torch.ones(1) * 3\nprint(\"action is in bounds?\\n\", bool(env.action_spec.is_in(action)))", "choices": [{"text": "action is in bounds?"}], "metadata": {"task_id": "pytorch_rl/174", "ground_truth": "print(\"projected action: \\n\", env.action_spec.project(action))", "fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "torch_envs.py"], "context_start_lineno": 0, "line_no": 68, "query_window": {"context": "###############################################################################\n# Env Specs\n# ------------------------------\n# Like other frameworks, TorchRL envs have attributes that indicate what\n# space is for the observations, action and reward. Because it often happens\n# that more than one observation is retrieved, we expect the observation spec\n# to be of type ``CompositeSpec``. Reward and action do not have this restriction:\n\nprint(\"Env observation_spec: \\n\", env.observation_spec)\nprint(\"Env action_spec: \\n\", env.action_spec)\nprint(\"Env reward_spec: \\n\", env.reward_spec)\n\n###############################################################################\n# Those spec come with a series of useful tools: one can assert whether a\n# sample is in the defined space. We can also use some heuristic to project\n# a sample in the space if it is out of space, and generate random (possibly\n# uniformly distributed) numbers in that space:\n\naction = torch.ones(1) * 3\nprint(\"action is in bounds?\\n\", bool(env.action_spec.is_in(action)))", "metadata": {"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "torch_envs.py"], "line_no": 68, "task_id": "pytorch_rl/174", "start_line_no": 48, "end_line_no": 68, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    \"\"\"Container for action, observation and reward specs.\n\n    This class allows one to create an environment, retrieve all of the specs\n    in a single data container (and access them in one place) before erasing\n    the environment from the workspace.\n\n    Args:\n        env (EnvBase): environment from which the specs have to be read.\n\n    \"\"\"\n\n    _keys = {\n        \"action_spec\",\n        \"observation_spec\",\n        \"reward_spec\",\n        \"input_spec\",\n        \"from_pixels\",\n    }\n\n    def __init__(self, env: EnvBase):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20238095238095238}, {"context": "    td_module(td)\n    print(\"mode:\", td[\"action\"])\n\nwith set_exploration_mode(\"mean\"):\n    td_module(td)\n    print(\"mean:\", td[\"action\"])\n\n###############################################################################\n# Using Environments and Modules\n# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nfrom torchrl.envs.utils import step_mdp\n\nenv = GymEnv(\"Pendulum-v1\")\n\naction_spec = env.action_spec\nactor_module = nn.Linear(3, 1)\nactor = SafeModule(\n    actor_module, spec=action_spec, in_keys=[\"observation\"], out_keys=[\"action\"]\n)", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "torchrl_demo.py"], "line_no": 570, "start_line_no": 560, "end_line_no": 580, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.1952662721893491}, {"context": "tensordict.set(\"d\", torch.ones(tensordict.shape))\nassert (tensordict[\"c\"] == 0).all()\nassert (tensordict[\"d\"] == 1).all()\n\n###############################################################################\n# ``values()``\n# ------------------------------\n# The values of a ``TensorDict`` can be retrieved with the ``values()`` function.\n# Note that, unlike python ``dicts``, the ``values()`` method returns a\n# generator and not a list.\n\nfor value in tensordict.values():\n    print(value.shape)\n\n###############################################################################\n# ``update(tensordict_or_dict)``\n# ------------------------------\n# The ``update`` method can be used to update a TensorDict with another one\n# (or with a dict):\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "tensordict_tutorial.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.19298245614035087}, {"context": "d = torch.zeros((3, 4, 2, 2))\ntensordict[\"d\"] = d\nprint(f\"td[\\\"d\\\"] is d: {d is tensordict['d']}\")\n\n###############################################################################\n# ``keys()``\n# ------------------------------\n# We can access the keys of a tensordict:\n\ntensordict[\"c\"] = torch.zeros(tensordict.shape)\ntensordict.set(\"d\", torch.ones(tensordict.shape))\nassert (tensordict[\"c\"] == 0).all()\nassert (tensordict[\"d\"] == 1).all()\n\n###############################################################################\n# ``values()``\n# ------------------------------\n# The values of a ``TensorDict`` can be retrieved with the ``values()`` function.\n# Note that, unlike python ``dicts``, the ``values()`` method returns a\n# generator and not a list.", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "tensordict_tutorial.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.19101123595505617}, {"context": "    def test_insert(self):\n        env = ContinuousActionVecMockEnv()\n        obs_spec = env.observation_spec\n        (key,) = itertools.islice(obs_spec.keys(), 1)\n        env = TransformedEnv(env)\n\n        # we start by asking the spec. That will create the private attributes\n        _ = env.action_spec\n        _ = env.observation_spec\n        _ = env.reward_spec\n\n        assert env._input_spec is not None\n        assert \"action\" in env._input_spec\n        assert env._input_spec[\"action\"] is not None\n        assert env._observation_spec is not None\n        assert env._reward_spec is not None\n\n        env.insert_transform(0, CatFrames(N=4, dim=-1, in_keys=[key]))\n\n        # transformed envs do not have spec after insert -- they need to be computed", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_transforms.py"], "line_no": 1710, "start_line_no": 1700, "end_line_no": 1720, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.1891891891891892}, {"context": "        if key in (\"_input_spec\", \"_observation_spec\", \"_action_spec\", \"_reward_spec\"):\n            raise AttributeError(\n                \"To set an environment spec, please use `env.observation_spec = obs_spec` (without the leading\"\n                \" underscore).\"\n            )\n        return super().__setattr__(key, value)\n\n    @property\n    def batch_locked(self) -> bool:\n        \"\"\"Whether the environnement can be used with a batch size different from the one it was initialized with or not.\n\n        If True, the env needs to be used with a tensordict having the same batch size as the env.\n        batch_locked is an immutable property.\n        \"\"\"\n        return self._batch_locked\n\n    @batch_locked.setter\n    def batch_locked(self, value: bool) -> None:\n        raise RuntimeError(\"batch_locked is a read-only property\")\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.18686868686868688}, {"context": "env_transformed = TransformedEnv(base_env, r3m)\nnet = nn.Sequential(\n    nn.LazyLinear(128), nn.Tanh(), nn.Linear(128, base_env.action_spec.shape[-1])\n)\npolicy = Actor(net, in_keys=[\"r3m_vec\"])\n\n##############################################################################\n# Let's check the number of parameters of the policy:\n#\nprint(\"number of params:\", len(list(policy.parameters())))\n\n##############################################################################\n# We collect a rollout of 32 steps and print its output:\n#\nrollout = env_transformed.rollout(32, policy)\nprint(\"rollout with transform:\", rollout)\n\n##############################################################################\n# For fine tuning, we integrate the transform in the policy after making the parameters\n# trainable. In practice, it may be wiser to restrict this to a subset of the parameters (say the last layer", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "pretrained_models.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.18686868686868688}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#             elif self._memmap:\n#                 self.shared_tensordict_parent.memmap_()\n#                 if not self.shared_tensordict_parent.is_memmap():\n#                     raise RuntimeError(\"memmap_() failed\")\n# \n#             self.shared_tensordicts = self.shared_tensordict_parent.unbind(0)\n#         if self.pin_memory:\n#             self.shared_tensordict_parent.pin_memory()\n# \n#         if raise_no_selected_keys:\n#             if self._verbose:\n#                 print(\n#                     f\"\\n {self.__class__.__name__}.shared_tensordict_parent is \\n{self.shared_tensordict_parent}. \\n\"\n#                     f\"You can select keys to be synchronised by setting the selected_keys and/or excluded_keys \"\n#                     f\"arguments when creating the batched environment.\"\n#                 )\n# \n#     def _start_workers(self) -> None:\n#         \"\"\"Starts the various envs.\"\"\"\n#         raise NotImplementedError\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#         counter = 0\n#         for key, p in loss_fn.qvalue_network_params.items(True, True):\n#             if not isinstance(key, tuple):\n#                 key = (key,)\n#             if not isinstance(p, nn.Parameter):\n#                 counter += 1\n#                 key = \"_sep_\".join([\"qvalue_network\", *key])\n#                 mapped_param = next(\n#                     (k for k, val in loss_fn._param_maps.items() if val == key)\n#                 )\n#                 assert (p == getattr(loss_fn, mapped_param)).all()\n#                 assert (p == 0).all()\n#         assert counter == len(loss_fn._actor_network_params.keys(True, True))\n#         assert counter == len(loss_fn.actor_network_params.keys(True, True))\n# \n#         # check that params of the original actor are those of the loss_fn\n#         for p in actor.parameters():\n#             assert p in set(loss_fn.parameters())\n# \n#         if delay_qvalue:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n#             buffer_name = f\"_cat_buffers_{in_key}\"\n#             buffer = getattr(self, buffer_name)\n#             if isinstance(buffer, torch.nn.parameter.UninitializedBuffer):\n#                 continue\n#             buffer[_reset] = 0\n# \n#         return tensordict\n# \n#     def _make_missing_buffer(self, data, buffer_name):\n#         shape = list(data.shape)\n#         d = shape[self.dim]\n#         shape[self.dim] = d * self.N\n#         shape = torch.Size(shape)\n#         getattr(self, buffer_name).materialize(shape)\n#         buffer = getattr(self, buffer_name).to(data.dtype).to(data.device).zero_()\n#         setattr(self, buffer_name, buffer)\n#         return buffer\n# \n#     def _call(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         \"\"\"Update the episode tensordict with max pooled keys.\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n#             \"_reset\",\n#             torch.ones(\n#                 tensordict.batch_size,\n#                 dtype=torch.bool,\n#                 device=tensordict.device\n#                 if tensordict.device is not None\n#                 else torch.device(\"cpu\"),\n#             ),\n#         )\n#         for in_key in self.in_keys:\n#             buffer_name = f\"_cat_buffers_{in_key}\"\n#             buffer = getattr(self, buffer_name)\n#             if isinstance(buffer, torch.nn.parameter.UninitializedBuffer):\n#                 continue\n#             buffer[_reset] = 0\n# \n#         return tensordict\n# \n#     def _make_missing_buffer(self, data, buffer_name):\n#         shape = list(data.shape)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/utils.py\n# --------------------------------------------------\n#                     f\"Incongruent target and source parameter lists: \"\n#                     f\"{_source} is not an attribute of the loss_module\"\n#                 )\n# \n#         self._target_names = _target_names\n#         self._source_names = _source_names\n#         self.loss_module = loss_module\n#         self.initialized = False\n# \n#     @property\n#     def _targets(self):\n#         return TensorDict(\n#             {name: getattr(self.loss_module, name) for name in self._target_names},\n#             [],\n#         )\n# \n#     @property\n#     def _sources(self):\n#         return TensorDict(\n#             {name: getattr(self.loss_module, name) for name in self._source_names},\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/dqn.py\n# --------------------------------------------------\n#         td_copy = tensordict.clone()\n#         if td_copy.device != tensordict.device:\n#             raise RuntimeError(f\"{tensordict} and {td_copy} have different devices\")\n#         assert hasattr(self.value_network, \"_is_stateless\")\n#         self.value_network(\n#             td_copy,\n#             params=self.value_network_params,\n#         )\n# \n#         action = tensordict.get(\"action\")\n#         pred_val = td_copy.get(\"action_value\")\n# \n#         if self.action_space == \"categorical\":\n#             pred_val_index = torch.gather(pred_val, -1, index=action).squeeze(-1)\n#         else:\n#             action = action.to(torch.float)\n#             pred_val_index = (pred_val * action).sum(-1)\n# \n#         with torch.no_grad():\n#             target_value = next_state_value(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/dqn.py\n# --------------------------------------------------\n#                 f\"{tensordict.__class__.__name__} but {tensordict.device} was found\"\n#             )\n# \n#         for k, t in tensordict.items():\n#             if t.device != device:\n#                 raise RuntimeError(\n#                     f\"found key value pair {k}-{t.shape} \"\n#                     f\"with device {t.device} when {device} was required\"\n#                 )\n# \n#         td_copy = tensordict.clone()\n#         if td_copy.device != tensordict.device:\n#             raise RuntimeError(f\"{tensordict} and {td_copy} have different devices\")\n#         assert hasattr(self.value_network, \"_is_stateless\")\n#         self.value_network(\n#             td_copy,\n#             params=self.value_network_params,\n#         )\n# \n#         action = tensordict.get(\"action\")\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom __future__ import annotations\n\nimport itertools\nfrom copy import deepcopy\nfrom typing import Iterator, List, Optional, Tuple, Union\n\nimport torch\n\nfrom tensordict.nn import make_functional, repopulate_module\n\nfrom tensordict.tensordict import TensorDictBase\nfrom torch import nn, Tensor\nfrom torch.nn import Parameter\n\nfrom torchrl.modules import SafeModule\nfrom torchrl.modules.utils import Buffer\n\n_has_functorch = False\ntry:\n    import functorch as ft  # noqa\n\n    _has_functorch = True\n    FUNCTORCH_ERR = \"\"\nexcept ImportError:\n    print(\n        \"failed to import functorch. TorchRL's features that do not require \"\n        \"functional programming should work, but functionality and performance \"\n        \"may be affected. Consider installing functorch and/or upgrating pytorch.\"\n    )\n    FUNCTORCH_ERROR = \"functorch not installed. Consider installing functorch to use this functionality.\"\n\n\nclass LossModule(nn.Module):\n    \"\"\"A parent class for RL losses.\n\n    LossModule inherits from nn.Module. It is designed to read an input TensorDict and return another tensordict\n    with loss keys named \"loss_*\".\n    Splitting the loss in its component can then be used by the trainer to log the various loss values throughout\n    training. Other scalars present in the output tensordict will be logged too.\n\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self._param_maps = {}\n        # self.register_forward_pre_hook(_parameters_to_tensordict)\n\n    def forward(self, tensordict: TensorDictBase) -> TensorDictBase:\n        \"\"\"It is designed to read an input TensorDict and return another tensordict with loss keys named \"loss*\".\n\n        Splitting the loss in its component can then be used by the trainer to log the various loss values throughout\n        training. Other scalars present in the output tensordict will be logged too.\n\n        Args:\n            tensordict: an input tensordict with the values required to compute the loss.\n\n        Returns:\n            A new tensordict with no batch dimension containing various loss scalars which will be named \"loss*\". It\n            is essential that the losses are returned with this name as they will be read by the trainer before\n            backpropagation.\n\n        \"\"\"\n        raise NotImplementedError\n\n    def convert_to_functional(\n        self,\n        module: SafeModule,\n        module_name: str,\n        expand_dim: Optional[int] = None,\n        create_target_params: bool = False,\n        compare_against: Optional[List[Parameter]] = None,\n        funs_to_decorate=None,\n    ) -> None:\n        if funs_to_decorate is None:\n            funs_to_decorate = [\"forward\"]\n        # To make it robust to device casting, we must register list of\n        # tensors as lazy calls to `getattr(self, name_of_tensor)`.\n        # Otherwise, casting the module to a device will keep old references\n        # to uncast tensors\n        try:\n            buffer_names = next(itertools.islice(zip(*module.named_buffers()), 1))\n        except StopIteration:\n            buffer_names = ()\n        params = make_functional(module, funs_to_decorate=funs_to_decorate)\n        functional_module = deepcopy(module)\n        repopulate_module(module, params)\n\n        params_and_buffers = params\n        # we transform the buffers in params to make sure they follow the device\n        # as tensor = nn.Parameter(tensor) keeps its identity when moved to another device\n\n        def create_buffers(tensor):\n\n            if isinstance(tensor, torch.Tensor) and not isinstance(\n                tensor, (Buffer, nn.Parameter)\n            ):\n                return Buffer(tensor, requires_grad=tensor.requires_grad)\n            return tensor\n\n        # separate params and buffers\n        params_and_buffers = params_and_buffers.apply(create_buffers)\n        for key in params_and_buffers.keys(True):\n            if \"_sep_\" in key:\n                raise KeyError(\n                    f\"The key {key} contains the '_sep_' pattern which is prohibited. Consider renaming the parameter / buffer.\"\n                )\n        params_and_buffers_flat = params_and_buffers.flatten_keys(\"_sep_\")\n        buffers = params_and_buffers_flat.select(*buffer_names)\n        params = params_and_buffers_flat.exclude(*buffer_names)\n\n        if expand_dim and not _has_functorch:\n            raise ImportError(\n                \"expanding params is only possible when functorch is installed,\"\n                \"as this feature requires calls to the vmap operator.\"\n            )\n        if expand_dim:\n            # Expands the dims of params and buffers.\n            # If the param already exist in the module, we return a simple expansion of the\n            # original one. Otherwise, we expand and resample it.\n            # For buffers, a cloned expansion (or equivalently a repeat) is returned.\n            if compare_against is not None:\n                compare_against = set(compare_against)\n            else:\n                compare_against = set()\n\n            def _compare_and_expand(param):\n\n                if param in compare_against:\n                    expanded_param = param.data.expand(expand_dim, *param.shape)\n                    # the expanded parameter must be sent to device when to()\n                    # is called:\n                    return expanded_param\n                else:\n                    p_out = param.repeat(expand_dim, *[1 for _ in param.shape])\n                    p_out = nn.Parameter(\n                        p_out.uniform_(\n                            p_out.min().item(), p_out.max().item()\n                        ).requires_grad_()\n                    )\n                    return p_out\n\n            params_udpated = params.apply(\n                _compare_and_expand, batch_size=[expand_dim, *params.shape]\n            )\n\n            params = params_udpated\n            buffers = buffers.apply(\n                lambda buffer: Buffer(buffer.expand(expand_dim, *buffer.shape).clone()),\n                batch_size=[expand_dim, *buffers.shape],\n            )\n\n            params_and_buffers.update(params.unflatten_keys(\"_sep_\"))\n            params_and_buffers.update(buffers.unflatten_keys(\"_sep_\"))\n            params_and_buffers.batch_size = params.batch_size\n\n            # self.params_to_map = params_to_map\n\n        param_name = module_name + \"_params\"\n\n        prev_set_params = set(self.parameters())\n\n        # register parameters and buffers\n        for key, parameter in params.items():\n            if parameter not in prev_set_params:\n                setattr(self, \"_sep_\".join([module_name, key]), parameter)\n            else:\n                for _param_name, p in self.named_parameters():\n                    if parameter is p:\n                        break\n                else:\n                    raise RuntimeError(\"parameter not found\")\n                setattr(self, \"_sep_\".join([module_name, key]), _param_name)\n        prev_set_buffers = set(self.buffers())\n        for key, buffer in buffers.items():\n            if buffer not in prev_set_buffers:\n                self.register_buffer(\"_sep_\".join([module_name, key]), buffer)\n            else:\n                for _buffer_name, b in self.named_buffers():\n                    if buffer is b:\n                        break\n                else:\n                    raise RuntimeError(\"buffer not found\")\n                setattr(self, \"_sep_\".join([module_name, key]), _buffer_name)\n\n        setattr(self, \"_\" + param_name, params_and_buffers)\n        setattr(\n            self.__class__,", "choices": [{"text": "\"\"\""}], "metadata": {"task_id": "pytorch_rl/193", "ground_truth": "            param_name,", "fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "common.py"], "context_start_lineno": 0, "line_no": 192, "query_window": {"context": "                    if parameter is p:\n                        break\n                else:\n                    raise RuntimeError(\"parameter not found\")\n                setattr(self, \"_sep_\".join([module_name, key]), _param_name)\n        prev_set_buffers = set(self.buffers())\n        for key, buffer in buffers.items():\n            if buffer not in prev_set_buffers:\n                self.register_buffer(\"_sep_\".join([module_name, key]), buffer)\n            else:\n                for _buffer_name, b in self.named_buffers():\n                    if buffer is b:\n                        break\n                else:\n                    raise RuntimeError(\"buffer not found\")\n                setattr(self, \"_sep_\".join([module_name, key]), _buffer_name)\n\n        setattr(self, \"_\" + param_name, params_and_buffers)\n        setattr(\n            self.__class__,", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "common.py"], "line_no": 192, "task_id": "pytorch_rl/193", "start_line_no": 172, "end_line_no": 192, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "\n        Returns:\n            a tensor containing the DQN loss.\n\n        \"\"\"\n        device = self.device if self.device is not None else input_tensordict.device\n        tensordict = input_tensordict.to(device)\n        if tensordict.device != device:\n            raise RuntimeError(\n                f\"device {device} was expected for \"\n                f\"{tensordict.__class__.__name__} but {tensordict.device} was found\"\n            )\n\n        for k, t in tensordict.items():\n            if t.device != device:\n                raise RuntimeError(\n                    f\"found key value pair {k}-{t.shape} \"\n                    f\"with device {t.device} when {device} was required\"\n                )\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "dqn.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2897196261682243}, {"context": "                f\"{tensordict.__class__.__name__} but {tensordict.device} was found\"\n            )\n\n        for k, t in tensordict.items():\n            if t.device != device:\n                raise RuntimeError(\n                    f\"found key value pair {k}-{t.shape} \"\n                    f\"with device {t.device} when {device} was required\"\n                )\n\n        td_copy = tensordict.clone()\n        if td_copy.device != tensordict.device:\n            raise RuntimeError(f\"{tensordict} and {td_copy} have different devices\")\n        assert hasattr(self.value_network, \"_is_stateless\")\n        self.value_network(\n            td_copy,\n            params=self.value_network_params,\n        )\n\n        action = tensordict.get(\"action\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "dqn.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28695652173913044}, {"context": "                \"Did not find any target parameters or buffers in the loss module.\"\n            )\n\n        _source_names = [\"\".join(name.split(\"target_\")) for name in _target_names]\n\n        for _source in _source_names:\n            try:\n                getattr(loss_module, _source)\n            except AttributeError:\n                raise RuntimeError(\n                    f\"Incongruent target and source parameter lists: \"\n                    f\"{_source} is not an attribute of the loss_module\"\n                )\n\n        self._target_names = _target_names\n        self._source_names = _source_names\n        self.loss_module = loss_module\n        self.initialized = False\n\n    @property", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "utils.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.27927927927927926}, {"context": "                self,\n                buffer_name,\n                torch.nn.parameter.UninitializedBuffer(\n                    device=torch.device(\"cpu\"), dtype=torch.get_default_dtype()\n                ),\n            )\n\n    def reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n        \"\"\"Resets _buffers.\"\"\"\n        _reset = tensordict.set_default(\n            \"_reset\",\n            torch.ones(\n                tensordict.batch_size,\n                dtype=torch.bool,\n                device=tensordict.device\n                if tensordict.device is not None\n                else torch.device(\"cpu\"),\n            ),\n        )\n        for in_key in self.in_keys:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 1540, "start_line_no": 1530, "end_line_no": 1550, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2719298245614035}, {"context": "            \"_reset\",\n            torch.ones(\n                tensordict.batch_size,\n                dtype=torch.bool,\n                device=tensordict.device\n                if tensordict.device is not None\n                else torch.device(\"cpu\"),\n            ),\n        )\n        for in_key in self.in_keys:\n            buffer_name = f\"_cat_buffers_{in_key}\"\n            buffer = getattr(self, buffer_name)\n            if isinstance(buffer, torch.nn.parameter.UninitializedBuffer):\n                continue\n            buffer[_reset] = 0\n\n        return tensordict\n\n    def _make_missing_buffer(self, data, buffer_name):\n        shape = list(data.shape)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 1550, "start_line_no": 1540, "end_line_no": 1560, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2711864406779661}, {"context": "        assert len({p for n, p in named_parameters}) == len(list(named_parameters))\n        assert len({p for n, p in named_buffers}) == len(list(named_buffers))\n\n        for name, p in named_parameters:\n            assert p.grad.norm() > 0.0, f\"parameter {name} has a null gradient\"\n\n        # modify params and check that expanded values are updated\n        for p in loss_fn.parameters():\n            p.data *= 0\n\n        counter = 0\n        for key, p in loss_fn.qvalue_network_params.items(True, True):\n            if not isinstance(key, tuple):\n                key = (key,)\n            if not isinstance(p, nn.Parameter):\n                counter += 1\n                key = \"_sep_\".join([\"qvalue_network\", *key])\n                mapped_param = next(\n                    (k for k, val in loss_fn._param_maps.items() if val == key)\n                )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 1620, "start_line_no": 1610, "end_line_no": 1630, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26515151515151514}, {"context": "                for td in self.shared_tensordicts:\n                    td.share_memory_()\n            elif self._memmap:\n                for td in self.shared_tensordicts:\n                    td.memmap_()\n        else:\n            if self._share_memory:\n                self.shared_tensordict_parent.share_memory_()\n                if not self.shared_tensordict_parent.is_shared():\n                    raise RuntimeError(\"share_memory_() failed\")\n            elif self._memmap:\n                self.shared_tensordict_parent.memmap_()\n                if not self.shared_tensordict_parent.is_memmap():\n                    raise RuntimeError(\"memmap_() failed\")\n\n            self.shared_tensordicts = self.shared_tensordict_parent.unbind(0)\n        if self.pin_memory:\n            self.shared_tensordict_parent.pin_memory()\n\n        if raise_no_selected_keys:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26373626373626374}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#                 out_keys=[\"out\"],\n#                 spec=spec,\n#                 safe=safe,\n#                 **kwargs,\n#             )\n# \n#         tdmodule = SafeProbabilisticSequential(tdnet, prob_module)\n#         params = make_functional(tdmodule)\n# \n#         # vmap = True\n#         params = params.expand(10)\n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n#         if safe and spec_type == \"bounded\":\n#             with pytest.raises(\n#                 RuntimeError, match=\"vmap cannot be used with safe=True\"\n#             ):\n#                 td_out = vmap(tdmodule, (None, 0))(td, params)\n#             return\n#         else:\n#             td_out = vmap(tdmodule, (None, 0))(td, params)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#             prob_module = SafeProbabilisticModule(\n#                 in_keys=[\"loc\", \"scale\"],\n#                 out_keys=[\"out\"],\n#                 spec=spec,\n#                 safe=safe,\n#                 **kwargs,\n#             )\n# \n#         tdmodule = SafeProbabilisticSequential(tdnet, prob_module)\n#         params = make_functional(tdmodule)\n# \n#         td = TensorDict({\"in\": torch.randn(3, 32 * param_multiplier)}, [3])\n#         tdmodule(td, params=params)\n#         assert td.shape == torch.Size([3])\n#         assert td.get(\"out\").shape == torch.Size([3, 32])\n# \n#         # test bounds\n#         if not safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n#         elif safe and spec_type == \"bounded\":\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#         assert hasattr(tdmodule, \"__delitem__\")\n#         assert len(tdmodule) == 3\n#         del tdmodule[2]\n#         assert len(tdmodule) == 2\n# \n#         assert hasattr(tdmodule, \"__getitem__\")\n#         assert tdmodule[0] is tdmodule1\n#         assert tdmodule[1] is tdmodule2\n# \n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n#         tdmodule(td)\n#         assert td.shape == torch.Size([3])\n#         assert td.get(\"out\").shape == torch.Size([3, 4])\n# \n#         # test bounds\n#         if not safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n#         elif safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#                 safe=False,\n#                 **kwargs,\n#             )\n#             tdmodule = SafeSequential(tdmodule1, dummy_tdmodule, tdmodule2)\n# \n#         assert hasattr(tdmodule, \"__setitem__\")\n#         assert len(tdmodule) == 3\n#         tdmodule[1] = tdmodule2\n#         assert len(tdmodule) == 3\n# \n#         assert hasattr(tdmodule, \"__delitem__\")\n#         assert len(tdmodule) == 3\n#         del tdmodule[2]\n#         assert len(tdmodule) == 2\n# \n#         assert hasattr(tdmodule, \"__getitem__\")\n#         assert tdmodule[0] is tdmodule1\n#         assert tdmodule[1] is tdmodule2\n# \n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#         assert hasattr(tdmodule, \"__delitem__\")\n#         assert len(tdmodule) == 3\n#         del tdmodule[2]\n#         del params[\"module\", \"2\"]\n#         assert len(tdmodule) == 2\n# \n#         assert hasattr(tdmodule, \"__getitem__\")\n#         assert tdmodule[0] is tdmodule1\n#         assert tdmodule[1] is tdmodule2\n# \n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n#         tdmodule(td, params)\n#         assert td.shape == torch.Size([3])\n#         assert td.get(\"out\").shape == torch.Size([3, 4])\n# \n#         # test bounds\n#         if not safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n#         elif safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#             tdmodule = SafeSequential(tdmodule1, dummy_tdmodule, tdmodule2)\n# \n#         params = make_functional(tdmodule)\n# \n#         assert hasattr(tdmodule, \"__setitem__\")\n#         assert len(tdmodule) == 3\n#         tdmodule[1] = tdmodule2\n#         params[\"module\", \"1\"] = params[\"module\", \"2\"]\n#         assert len(tdmodule) == 3\n# \n#         assert hasattr(tdmodule, \"__delitem__\")\n#         assert len(tdmodule) == 3\n#         del tdmodule[2]\n#         del params[\"module\", \"2\"]\n#         assert len(tdmodule) == 2\n# \n#         assert hasattr(tdmodule, \"__getitem__\")\n#         assert tdmodule[0] is tdmodule1\n#         assert tdmodule[1] is tdmodule2\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#                 tdmodule1, dummy_tdmodule, tdmodule2, prob_module\n#             )\n# \n#         assert hasattr(tdmodule, \"__setitem__\")\n#         assert len(tdmodule) == 4\n#         tdmodule[1] = tdmodule2\n#         tdmodule[2] = prob_module\n#         assert len(tdmodule) == 4\n# \n#         assert hasattr(tdmodule, \"__delitem__\")\n#         assert len(tdmodule) == 4\n#         del tdmodule[3]\n#         assert len(tdmodule) == 3\n# \n#         assert hasattr(tdmodule, \"__getitem__\")\n#         assert tdmodule[0] is tdmodule1\n#         assert tdmodule[1] is tdmodule2\n#         assert tdmodule[2] is prob_module\n# \n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=safe,\n                **kwargs,\n            )\n            tdmodule = SafeProbabilisticSequential(\n                tdmodule1, dummy_tdmodule, tdmodule2, prob_module\n            )\n\n        params = make_functional(tdmodule, funs_to_decorate=[\"forward\", \"get_dist\"])\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 4\n        tdmodule[1] = tdmodule2\n        tdmodule[2] = prob_module\n        params[\"module\", \"1\"] = params[\"module\", \"2\"]\n        params[\"module\", \"2\"] = params[\"module\", \"3\"]\n        assert len(tdmodule) == 4\n\n        assert hasattr(tdmodule, \"__delitem__\")\n        assert len(tdmodule) == 4\n        del tdmodule[3]\n        del params[\"module\", \"3\"]\n        assert len(tdmodule) == 3\n\n        assert hasattr(tdmodule, \"__getitem__\")\n        assert tdmodule[0] is tdmodule1\n        assert tdmodule[1] is tdmodule2\n        assert tdmodule[2] is prob_module\n\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        tdmodule(td, params=params)\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 4])\n\n        dist = tdmodule.get_dist(td, params=params)\n        assert dist.rsample().shape[: td.ndimension()] == td.shape\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    def test_functional_with_buffer(self, safe, spec_type):\n        torch.manual_seed(0)\n        param_multiplier = 1\n\n        net1 = nn.Sequential(nn.Linear(7, 7), nn.BatchNorm1d(7))\n        dummy_net = nn.Sequential(nn.Linear(7, 7), nn.BatchNorm1d(7))\n        net2 = nn.Sequential(\n            nn.Linear(7, 7 * param_multiplier), nn.BatchNorm1d(7 * param_multiplier)\n        )\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 7)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(7)\n\n        if safe and spec is None:\n            pytest.skip(\"safe and spec is None is checked elsewhere\")\n        else:\n            tdmodule1 = SafeModule(\n                net1, spec=None, in_keys=[\"in\"], out_keys=[\"hidden\"], safe=False\n            )\n            dummy_tdmodule = SafeModule(\n                dummy_net,\n                spec=None,\n                in_keys=[\"hidden\"],\n                out_keys=[\"hidden\"],\n                safe=False,\n            )\n            tdmodule2 = SafeModule(\n                net2,\n                spec=spec,\n                in_keys=[\"hidden\"],\n                out_keys=[\"out\"],\n                safe=safe,\n            )\n            tdmodule = SafeSequential(tdmodule1, dummy_tdmodule, tdmodule2)\n\n        params = make_functional(tdmodule)\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 3\n        tdmodule[1] = tdmodule2\n        params[\"module\", \"1\"] = params[\"module\", \"2\"]\n        assert len(tdmodule) == 3\n\n        assert hasattr(tdmodule, \"__delitem__\")\n        assert len(tdmodule) == 3\n        del tdmodule[2]\n        del params[\"module\", \"2\"]\n        assert len(tdmodule) == 2\n\n        assert hasattr(tdmodule, \"__getitem__\")\n        assert tdmodule[0] is tdmodule1\n        assert tdmodule[1] is tdmodule2\n\n        td = TensorDict({\"in\": torch.randn(3, 7)}, [3])\n        tdmodule(td, params=params)\n\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 7])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    def test_functional_with_buffer_probabilistic(self, safe, spec_type):\n        torch.manual_seed(0)\n        param_multiplier = 2\n\n        net1 = nn.Sequential(nn.Linear(7, 7), nn.BatchNorm1d(7))\n        dummy_net = nn.Sequential(nn.Linear(7, 7), nn.BatchNorm1d(7))\n        net2 = nn.Sequential(\n            nn.Linear(7, 7 * param_multiplier), nn.BatchNorm1d(7 * param_multiplier)\n        )\n        net2 = NormalParamWrapper(net2)\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 7)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(7)\n        else:\n            raise NotImplementedError\n\n        kwargs = {\"distribution_class\": TanhNormal}\n\n        if safe and spec is None:\n            pytest.skip(\"safe and spec is None is checked elsewhere\")\n        else:\n            tdmodule1 = SafeModule(\n                net1, in_keys=[\"in\"], out_keys=[\"hidden\"], spec=None, safe=False\n            )\n            dummy_tdmodule = SafeModule(\n                dummy_net,\n                in_keys=[\"hidden\"],\n                out_keys=[\"hidden\"],\n                spec=None,\n                safe=False,\n            )\n            tdmodule2 = SafeModule(\n                net2,\n                in_keys=[\"hidden\"],\n                out_keys=[\"loc\", \"scale\"],\n                spec=None,\n                safe=False,\n            )\n\n            prob_module = SafeProbabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=safe,\n                **kwargs,\n            )\n            tdmodule = SafeProbabilisticSequential(\n                tdmodule1, dummy_tdmodule, tdmodule2, prob_module\n            )\n\n        params = make_functional(tdmodule, [\"forward\", \"get_dist\"])\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 4\n        tdmodule[1] = tdmodule2\n        tdmodule[2] = prob_module\n        params[\"module\", \"1\"] = params[\"module\", \"2\"]\n        params[\"module\", \"2\"] = params[\"module\", \"3\"]\n        assert len(tdmodule) == 4\n\n        assert hasattr(tdmodule, \"__delitem__\")\n        assert len(tdmodule) == 4", "choices": [{"text": "del tdmodule[3]"}], "metadata": {"task_id": "pytorch_rl/94", "ground_truth": "        del tdmodule[3]", "fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "context_start_lineno": 900, "line_no": 1085, "query_window": {"context": "                spec=spec,\n                safe=safe,\n                **kwargs,\n            )\n            tdmodule = SafeProbabilisticSequential(\n                tdmodule1, dummy_tdmodule, tdmodule2, prob_module\n            )\n\n        params = make_functional(tdmodule, [\"forward\", \"get_dist\"])\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 4\n        tdmodule[1] = tdmodule2\n        tdmodule[2] = prob_module\n        params[\"module\", \"1\"] = params[\"module\", \"2\"]\n        params[\"module\", \"2\"] = params[\"module\", \"3\"]\n        assert len(tdmodule) == 4\n\n        assert hasattr(tdmodule, \"__delitem__\")\n        assert len(tdmodule) == 4", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 1085, "task_id": "pytorch_rl/94", "start_line_no": 1065, "end_line_no": 1085, "window_size": 20, "context_start_lineno": 900, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            )\n\n            prob_module = SafeProbabilisticModule(\n                spec=spec,\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                safe=False,\n                **kwargs,\n            )\n            tdmodule = SafeProbabilisticSequential(\n                tdmodule1, dummy_tdmodule, tdmodule2, prob_module\n            )\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 4\n        tdmodule[1] = tdmodule2\n        tdmodule[2] = prob_module\n        assert len(tdmodule) == 4\n\n        assert hasattr(tdmodule, \"__delitem__\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 760, "start_line_no": 750, "end_line_no": 770, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7164179104477612}, {"context": "                out_keys=[\"hidden\"],\n                safe=False,\n            )\n            tdmodule2 = SafeModule(\n                net2,\n                spec=spec,\n                in_keys=[\"hidden\"],\n                out_keys=[\"out\"],\n                safe=safe,\n            )\n            tdmodule = SafeSequential(tdmodule1, dummy_tdmodule, tdmodule2)\n\n        params = make_functional(tdmodule)\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 3\n        tdmodule[1] = tdmodule2\n        params[\"module\", \"1\"] = params[\"module\", \"2\"]\n        assert len(tdmodule) == 3\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 830, "start_line_no": 820, "end_line_no": 840, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6323529411764706}, {"context": "            tdmodule = SafeSequential(tdmodule1, dummy_tdmodule, tdmodule2)\n\n        params = make_functional(tdmodule)\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 3\n        tdmodule[1] = tdmodule2\n        params[\"module\", \"1\"] = params[\"module\", \"2\"]\n        assert len(tdmodule) == 3\n\n        assert hasattr(tdmodule, \"__delitem__\")\n        assert len(tdmodule) == 3\n        del tdmodule[2]\n        del params[\"module\", \"2\"]\n        assert len(tdmodule) == 2\n\n        assert hasattr(tdmodule, \"__getitem__\")\n        assert tdmodule[0] is tdmodule1\n        assert tdmodule[1] is tdmodule2\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 840, "start_line_no": 830, "end_line_no": 850, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6031746031746031}, {"context": "                spec=None,\n                in_keys=[\"hidden\"],\n                out_keys=[\"hidden\"],\n                safe=False,\n            )\n            tdmodule2 = SafeModule(\n                spec=spec,\n                module=net2,\n                in_keys=[\"hidden\"],\n                out_keys=[\"out\"],\n                safe=False,\n                **kwargs,\n            )\n            tdmodule = SafeSequential(tdmodule1, dummy_tdmodule, tdmodule2)\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 3\n        tdmodule[1] = tdmodule2\n        assert len(tdmodule) == 3\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 670, "start_line_no": 660, "end_line_no": 680, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5714285714285714}, {"context": "                safe=False,\n                **kwargs,\n            )\n            tdmodule = SafeSequential(tdmodule1, dummy_tdmodule, tdmodule2)\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 3\n        tdmodule[1] = tdmodule2\n        assert len(tdmodule) == 3\n\n        assert hasattr(tdmodule, \"__delitem__\")\n        assert len(tdmodule) == 3\n        del tdmodule[2]\n        assert len(tdmodule) == 2\n\n        assert hasattr(tdmodule, \"__getitem__\")\n        assert tdmodule[0] is tdmodule1\n        assert tdmodule[1] is tdmodule2\n\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 680, "start_line_no": 670, "end_line_no": 690, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5128205128205128}, {"context": "                prob_module = SafeProbabilisticModule(\n                    in_keys=[\"loc\", \"scale\"],\n                    out_keys=[\"out\"],\n                    spec=spec,\n                    safe=safe,\n                    **kwargs,\n                )\n\n            return\n        else:\n            prob_module = SafeProbabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=safe,\n                **kwargs,\n            )\n\n        tdmodule = SafeProbabilisticSequential(tdnet, prob_module)\n        params = make_functional(tdmodule)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5070422535211268}, {"context": "                    in_keys=[\"loc\", \"scale\"],\n                    out_keys=[\"out\"],\n                    spec=spec,\n                    safe=safe,\n                    **kwargs,\n                )\n            return\n        else:\n            prob_module = SafeProbabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=safe,\n                **kwargs,\n            )\n\n        tdmodule = SafeProbabilisticSequential(tdnet, prob_module)\n        params = make_functional(tdmodule)\n\n        # vmap = True", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 570, "start_line_no": 560, "end_line_no": 580, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.48}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#         cls._reward_spec = cls._reward_spec.to(torch.get_default_dtype())\n#         return super().__new__(*args, **kwargs)\n# \n#     def __init__(\n#         self,\n#         *args,\n#         seed: int = 100,\n#         **kwargs,\n#     ):\n#         super().__init__(\n#             device=\"cpu\",\n#             dtype=torch.get_default_dtype(),\n#         )\n#         self.set_seed(seed)\n#         self.is_closed = False\n# \n#     @property\n#     def maxstep(self):\n#         return 100\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#         )\n# \n#     def __init__(self, device, batch_size=None):\n#         super(MockBatchedLockedEnv, self).__init__(device=device, batch_size=batch_size)\n#         self.counter = 0\n# \n#     rand_step = MockSerialEnv.rand_step\n# \n#     def _set_seed(self, seed: Optional[int]):\n#         assert seed >= 1\n#         self.seed = seed\n#         self.counter = seed % 17  # make counter a small number\n#         self.max_val = max(self.counter + 100, self.counter * 2)\n# \n#     def _step(self, tensordict):\n#         if len(self.batch_size):\n#             leading_batch_size = (\n#                 tensordict.shape[: -len(self.batch_size)]\n#                 if tensordict is not None\n#                 else []\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n# \n# \n# class ContinuousActionVecMockEnv(_MockEnv):\n#     @classmethod\n#     def __new__(\n#         cls,\n#         *args,\n#         observation_spec=None,\n#         action_spec=None,\n#         input_spec=None,\n#         reward_spec=None,\n#         from_pixels=False,\n#         **kwargs,\n#     ):\n#         batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n#         size = cls.size = 7\n#         if observation_spec is None:\n#             cls.out_key = \"observation\"\n#             observation_spec = CompositeSpec(\n#                 observation=UnboundedContinuousTensorSpec(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n# \n#     def _get_in_obs(self, obs):\n#         return obs\n# \n#     def _get_out_obs(self, obs):\n#         return obs\n# \n#     def _reset(self, tensordict: TensorDictBase = None) -> TensorDictBase:\n#         self.counter += 1\n#         state = torch.zeros(self.size) + self.counter\n#         if tensordict is None:\n#             tensordict = TensorDict({}, self.batch_size, device=self.device)\n#         tensordict = tensordict.select().set(self.out_key, self._get_out_obs(state))\n#         tensordict = tensordict.set(self._out_key, self._get_out_obs(state))\n#         tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n#         return tensordict\n# \n#     def _step(\n#         self,\n#         tensordict: TensorDictBase,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#         reward_spec=None,\n#         from_pixels=False,\n#         **kwargs,\n#     ):\n#         batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n#         size = cls.size = 7\n#         if observation_spec is None:\n#             cls.out_key = \"observation\"\n#             observation_spec = CompositeSpec(\n#                 observation=UnboundedContinuousTensorSpec(\n#                     shape=torch.Size([*batch_size, size])\n#                 ),\n#                 observation_orig=UnboundedContinuousTensorSpec(\n#                     shape=torch.Size([*batch_size, size])\n#                 ),\n#                 shape=batch_size,\n#             )\n#         if action_spec is None:\n#             action_spec = BoundedTensorSpec(\n#                 -1,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n# class DiscreteActionVecMockEnv(_MockEnv):\n#     @classmethod\n#     def __new__(\n#         cls,\n#         *args,\n#         observation_spec=None,\n#         action_spec=None,\n#         input_spec=None,\n#         reward_spec=None,\n#         from_pixels=False,\n#         categorical_action_encoding=False,\n#         **kwargs,\n#     ):\n#         batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n#         size = cls.size = 7\n#         if observation_spec is None:\n#             cls.out_key = \"observation\"\n#             observation_spec = CompositeSpec(\n#                 observation=UnboundedContinuousTensorSpec(\n#                     shape=torch.Size([*batch_size, size])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#         cls._input_spec = input_spec\n#         cls.from_pixels = from_pixels\n#         return super().__new__(*args, **kwargs)\n# \n#     def _get_in_obs(self, obs):\n#         return obs\n# \n#     def _get_out_obs(self, obs):\n#         return obs\n# \n#     def _reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         self.counter += 1\n#         self.step_count = 0\n#         # state = torch.zeros(self.size) + self.counter\n#         if tensordict is None:\n#             tensordict = TensorDict({}, self.batch_size, device=self.device)\n#         tensordict = tensordict.select()\n#         tensordict.update(self.observation_spec.rand())\n#         # tensordict.set(\"next_\" + self.out_key, self._get_out_obs(state))\n#         # tensordict.set(\"next_\" + self._out_key, self._get_out_obs(state))\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nset(\"done\", done)\n        return tensordict\n\n    def _obs_step(self, obs, a):\n        return obs + a / self.maxstep\n\n\nclass DiscreteActionVecPolicy:\n    in_keys = [\"observation\"]\n    out_keys = [\"action\"]\n\n    def _get_in_obs(self, tensordict):\n        obs = tensordict.get(*self.in_keys)\n        return obs\n\n    def __call__(self, tensordict):\n        obs = self._get_in_obs(tensordict)\n        max_obs = (obs == obs.max(dim=-1, keepdim=True)[0]).cumsum(-1).argmax(-1)\n        k = tensordict.get(*self.in_keys).shape[-1]\n        max_obs = (max_obs + 1) % k\n        action = torch.nn.functional.one_hot(max_obs, k)\n        tensordict.set(*self.out_keys, action)\n        return tensordict\n\n\nclass DiscreteActionConvMockEnv(DiscreteActionVecMockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=True,\n        **kwargs,\n    ):\n        batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n        if observation_spec is None:\n            cls.out_key = \"pixels\"\n            observation_spec = CompositeSpec(\n                pixels=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, 1, 7, 7])\n                ),\n                pixels_orig=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, 1, 7, 7])\n                ),\n                shape=batch_size,\n            )\n        if action_spec is None:\n            action_spec = OneHotDiscreteTensorSpec(7, shape=(*batch_size, 7))\n        if reward_spec is None:\n            reward_spec = UnboundedContinuousTensorSpec(shape=(*batch_size, 1))\n\n        if input_spec is None:\n            cls._out_key = \"pixels_orig\"\n            input_spec = CompositeSpec(\n                **{\n                    cls._out_key: observation_spec[\"pixels_orig\"],\n                    \"action\": action_spec,\n                },\n                shape=batch_size,\n            )\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1).unsqueeze(0)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -1, -2).squeeze()\n\n\nclass DiscreteActionConvMockEnvNumpy(DiscreteActionConvMockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=True,\n        categorical_action_encoding=False,\n        **kwargs,\n    ):\n        batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n        if observation_spec is None:\n            cls.out_key = \"pixels\"\n            observation_spec = CompositeSpec(\n                pixels=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, 7, 7, 3])\n                ),\n                pixels_orig=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, 7, 7, 3])\n                ),\n                shape=batch_size,\n            )\n        if action_spec is None:\n            action_spec_cls = (\n                DiscreteTensorSpec\n                if categorical_action_encoding\n                else OneHotDiscreteTensorSpec\n            )\n            action_spec = action_spec_cls(7, shape=(*batch_size, 7))\n        if input_spec is None:\n            cls._out_key = \"pixels_orig\"\n            input_spec = CompositeSpec(\n                **{\n                    cls._out_key: observation_spec[\"pixels_orig\"],\n                    \"action\": action_spec,\n                },\n                shape=batch_size,\n            )\n\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            categorical_action_encoding=categorical_action_encoding,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1).unsqueeze(-1)\n        obs = obs.expand(*obs.shape[:-1], 3)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -2, -3)[..., 0, :]\n\n    def _obs_step(self, obs, a):\n        return obs + a.unsqueeze(-1) / self.maxstep\n\n\nclass ContinuousActionConvMockEnv(ContinuousActionVecMockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=True,\n        pixel_shape=None,\n        **kwargs,\n    ):\n        batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n        if pixel_shape is None:\n            pixel_shape = [1, 7, 7]\n        if observation_spec is None:\n            cls.out_key = \"pixels\"\n            observation_spec = CompositeSpec(\n                pixels=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, *pixel_shape])\n                ),\n                pixels_orig=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, *pixel_shape])\n                ),\n                shape=batch_size,\n            )\n\n        if action_spec is None:\n            action_spec = BoundedTensorSpec(-1, 1, [*batch_size, pixel_shape[-1]])\n\n        if reward_spec is None:\n            reward_spec = UnboundedContinuousTensorSpec(shape=(*batch_size, 1))\n        if input_spec is None:\n            cls._out_key = \"pixels_orig\"\n            input_spec = CompositeSpec(\n                **{cls._out_key: observation_spec[\"pixels\"], \"action\": action_spec},\n                shape=batch_size,\n            )\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -1, -2).squeeze()\n\n\nclass ContinuousActionConvMockEnvNumpy(ContinuousActionConvMockEnv):\n    @classmethod\n    def __new__(", "choices": [{"text": "cls,"}], "metadata": {"task_id": "pytorch_rl/147", "ground_truth": "        cls,", "fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "context_start_lineno": 512, "line_no": 718, "query_window": {"context": "            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -1, -2).squeeze()\n\n\nclass ContinuousActionConvMockEnvNumpy(ContinuousActionConvMockEnv):\n    @classmethod\n    def __new__(", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 718, "task_id": "pytorch_rl/147", "start_line_no": 698, "end_line_no": 718, "window_size": 20, "context_start_lineno": 512, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            cls._out_key = \"observation_orig\"\n            input_spec = CompositeSpec(\n                **{\n                    cls._out_key: observation_spec[\"observation\"],\n                    \"action\": action_spec,\n                },\n                shape=batch_size,\n            )\n        cls._reward_spec = reward_spec\n        cls._observation_spec = observation_spec\n        cls._input_spec = input_spec\n        cls.from_pixels = from_pixels\n        return super().__new__(*args, **kwargs)\n\n    def _get_in_obs(self, obs):\n        return obs\n\n    def _get_out_obs(self, obs):\n        return obs\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4489795918367347}, {"context": "    def __init__(self, device, batch_size=None):\n        super(MockBatchedUnLockedEnv, self).__init__(\n            batch_size=batch_size, device=device\n        )\n\n    @classmethod\n    def __new__(cls, *args, **kwargs):\n        return super().__new__(cls, *args, _batch_locked=False, **kwargs)\n\n\nclass DiscreteActionVecMockEnv(_MockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=False,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4}, {"context": "\n\nclass ContinuousActionVecMockEnv(_MockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=False,\n        **kwargs,\n    ):\n        batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n        size = cls.size = 7\n        if observation_spec is None:\n            cls.out_key = \"observation\"\n            observation_spec = CompositeSpec(\n                observation=UnboundedContinuousTensorSpec(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38392857142857145}, {"context": "                    cls._out_key: observation_spec[\"observation\"],\n                    \"action\": action_spec,\n                }\n            )\n        cls._reward_spec = reward_spec\n        cls._observation_spec = observation_spec\n        cls._input_spec = input_spec\n        cls.from_pixels = from_pixels\n        cls.categorical_action_encoding = categorical_action_encoding\n        return super().__new__(*args, **kwargs)\n\n    def _get_in_obs(self, obs):\n        return obs\n\n    def _get_out_obs(self, obs):\n        return obs\n\n    def _reset(self, tensordict: TensorDictBase = None) -> TensorDictBase:\n        self.counter += 1\n        state = torch.zeros(self.size) + self.counter", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3826086956521739}, {"context": "        tensordict.set(self.out_key, self._get_out_obs(obs))\n        tensordict.set(self._out_key, self._get_out_obs(obs))\n\n        done = torch.isclose(obs, torch.ones_like(obs) * (self.counter + 1))\n        reward = done.any(-1).unsqueeze(-1)\n        # set done to False\n        done = torch.zeros_like(done).all(-1).unsqueeze(-1)\n        tensordict.set(\"reward\", reward.to(torch.get_default_dtype()))\n        tensordict.set(\"done\", done)\n        return tensordict\n\n\nclass ContinuousActionVecMockEnv(_MockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3813559322033898}, {"context": "                    1,\n                )\n            )\n        cls._reward_spec = reward_spec\n        cls._observation_spec = observation_spec\n        cls._input_spec = input_spec\n        return super().__new__(\n            cls,\n            *args,\n            **kwargs,\n        )\n\n    def __init__(self, device, batch_size=None):\n        super(MockBatchedLockedEnv, self).__init__(device=device, batch_size=batch_size)\n        self.counter = 0\n\n    rand_step = MockSerialEnv.rand_step\n\n    def _set_seed(self, seed: Optional[int]):\n        assert seed >= 1", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.36936936936936937}, {"context": "\nclass _MockEnv(EnvBase):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        **kwargs,\n    ):\n        for key, item in list(cls._observation_spec.items()):\n            cls._observation_spec[key] = item.to(torch.get_default_dtype())\n        cls._reward_spec = cls._reward_spec.to(torch.get_default_dtype())\n        return super().__new__(*args, **kwargs)\n\n    def __init__(\n        self,\n        *args,\n        seed: int = 100,\n        **kwargs,\n    ):\n        super().__init__(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3490566037735849}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion_2/test_stable_diffusion_depth.py\n# --------------------------------------------------\n# \n#     def get_inputs(self, device=\"cpu\", dtype=torch.float32, seed=0):\n#         generator = torch.Generator(device=device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/depth2img/two_cats.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"two tigers\",\n#             \"image\": init_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 3,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n#         }\n#         return inputs\n# \n#     def test_stable_diffusion_depth2img_pipeline_default(self):\n#         pipe = StableDiffusionDepth2ImgPipeline.from_pretrained(\n#             \"stabilityai/stable-diffusion-2-depth\", safety_checker=None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_img2img.py\n# --------------------------------------------------\n#         super().tearDown()\n#         gc.collect()\n#         torch.cuda.empty_cache()\n# \n#     def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n#         generator = torch.Generator(device=generator_device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_img2img/sketch-mountains-input.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"a fantasy landscape, concept art, high resolution\",\n#             \"image\": init_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 3,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n#         }\n#         return inputs\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion_2/test_stable_diffusion_depth.py\n# --------------------------------------------------\n#         generator = torch.Generator(device=device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/depth2img/two_cats.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"two tigers\",\n#             \"image\": init_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 3,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n#         }\n#         return inputs\n# \n#     def test_depth2img_pndm(self):\n#         pipe = StableDiffusionDepth2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-depth\")\n#         pipe.to(torch_device)\n#         pipe.set_progress_bar_config(disable=None)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_img2img.py\n# --------------------------------------------------\n#     def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n#         generator = torch.Generator(device=generator_device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_img2img/sketch-mountains-input.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"a fantasy landscape, concept art, high resolution\",\n#             \"image\": init_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 50,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n#         }\n#         return inputs\n# \n#     def test_img2img_pndm(self):\n#         sd_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n#         sd_pipe.to(torch_device)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_inpaint_legacy.py\n# --------------------------------------------------\n# \n#     def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n#         generator = torch.Generator(device=generator_device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_image.png\"\n#         )\n#         mask_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_mask.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"A red cat sitting on a park bench\",\n#             \"image\": init_image,\n#             \"mask_image\": mask_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 3,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_inpaint_legacy.py\n# --------------------------------------------------\n#         gc.collect()\n#         torch.cuda.empty_cache()\n# \n#     def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n#         generator = torch.Generator(device=generator_device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_image.png\"\n#         )\n#         mask_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_mask.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"A red cat sitting on a park bench\",\n#             \"image\": init_image,\n#             \"mask_image\": mask_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 50,\n#             \"strength\": 0.75,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\ndummy_components()\n        sd_pipe = StableDiffusionInpaintPipeline(**components)\n        sd_pipe = sd_pipe.to(device)\n        sd_pipe.set_progress_bar_config(disable=None)\n\n        inputs = self.get_dummy_inputs(device)\n        images = sd_pipe(**inputs, num_images_per_prompt=2).images\n\n        # check if the output is a list of 2 images\n        assert len(images) == 2\n\n\n@slow\n@require_torch_gpu\nclass StableDiffusionInpaintPipelineSlowTests(unittest.TestCase):\n    def setUp(self):\n        super().setUp()\n\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_mask.png\"\n        )\n        inputs = {\n            \"prompt\": \"Face of a yellow cat, high resolution, sitting on a park bench\",\n            \"image\": init_image,\n            \"mask_image\": mask_image,\n            \"generator\": generator,\n            \"num_inference_steps\": 3,\n            \"guidance_scale\": 7.5,\n            \"output_type\": \"numpy\",\n        }\n        return inputs\n\n    def test_stable_diffusion_inpaint_ddim(self):\n        pipe = StableDiffusionInpaintPipeline.from_pretrained(\n            \"runwayml/stable-diffusion-inpainting\", safety_checker=None\n        )\n        pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n        pipe.enable_attention_slicing()\n\n        inputs = self.get_inputs(torch_device)\n        image = pipe(**inputs).images\n        image_slice = image[0, 253:256, 253:256, -1].flatten()\n\n        assert image.shape == (1, 512, 512, 3)\n        expected_slice = np.array([0.0427, 0.0460, 0.0483, 0.0460, 0.0584, 0.0521, 0.1549, 0.1695, 0.1794])\n\n        assert np.abs(expected_slice - image_slice).max() < 1e-4\n\n    def test_stable_diffusion_inpaint_fp16(self):\n        pipe = StableDiffusionInpaintPipeline.from_pretrained(\n            \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16, safety_checker=None\n        )\n        pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n        pipe.enable_attention_slicing()\n\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        image = pipe(**inputs).images\n        image_slice = image[0, 253:256, 253:256, -1].flatten()\n\n        assert image.shape == (1, 512, 512, 3)\n        expected_slice = np.array([0.1443, 0.1218, 0.1587, 0.1594, 0.1411, 0.1284, 0.1370, 0.1506, 0.2339])\n\n        assert np.abs(expected_slice - image_slice).max() < 5e-2\n\n    def test_stable_diffusion_inpaint_pndm(self):\n        pipe = StableDiffusionInpaintPipeline.from_pretrained(\n            \"runwayml/stable-diffusion-inpainting\", safety_checker=None\n        )\n        pipe.scheduler = PNDMScheduler.from_config(pipe.scheduler.config)\n        pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n        pipe.enable_attention_slicing()\n\n        inputs = self.get_inputs(torch_device)\n        image = pipe(**inputs).images\n        image_slice = image[0, 253:256, 253:256, -1].flatten()\n\n        assert image.shape == (1, 512, 512, 3)\n        expected_slice = np.array([0.0425, 0.0273, 0.0344, 0.1694, 0.1727, 0.1812, 0.3256, 0.3311, 0.3272])\n\n        assert np.abs(expected_slice - image_slice).max() < 1e-4\n\n    def test_stable_diffusion_inpaint_k_lms(self):\n        pipe = StableDiffusionInpaintPipeline.from_pretrained(\n            \"runwayml/stable-diffusion-inpainting\", safety_checker=None\n        )\n        pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n        pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n        pipe.enable_attention_slicing()\n\n        inputs = self.get_inputs(torch_device)\n        image = pipe(**inputs).images\n        image_slice = image[0, 253:256, 253:256, -1].flatten()\n\n        assert image.shape == (1, 512, 512, 3)\n        expected_slice = np.array([0.9314, 0.7575, 0.9432, 0.8885, 0.9028, 0.7298, 0.9811, 0.9667, 0.7633])\n\n        assert np.abs(expected_slice - image_slice).max() < 1e-4\n\n    def test_stable_diffusion_inpaint_with_sequential_cpu_offloading(self):\n        torch.cuda.empty_cache()\n        torch.cuda.reset_max_memory_allocated()\n        torch.cuda.reset_peak_memory_stats()\n\n        pipe = StableDiffusionInpaintPipeline.from_pretrained(\n            \"runwayml/stable-diffusion-inpainting\", safety_checker=None, torch_dtype=torch.float16\n        )\n        pipe = pipe.to(torch_device)\n        pipe.set_progress_bar_config(disable=None)\n        pipe.enable_attention_slicing(1)\n        pipe.enable_sequential_cpu_offload()\n\n        inputs = self.get_inputs(torch_device, dtype=torch.float16)\n        _ = pipe(**inputs)\n\n        mem_bytes = torch.cuda.max_memory_allocated()\n        # make sure that less than 2.2 GB is allocated\n        assert mem_bytes < 2.2 * 10**9\n\n\n@nightly\n@require_torch_gpu\nclass StableDiffusionInpaintPipelineNightlyTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )", "choices": [{"text": "mask_image = load_image("}], "metadata": {"task_id": "huggingface_diffusers/197", "ground_truth": "        mask_image = load_image(", "fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint.py"], "context_start_lineno": 152, "line_no": 301, "query_window": {"context": "\n        mem_bytes = torch.cuda.max_memory_allocated()\n        # make sure that less than 2.2 GB is allocated\n        assert mem_bytes < 2.2 * 10**9\n\n\n@nightly\n@require_torch_gpu\nclass StableDiffusionInpaintPipelineNightlyTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint.py"], "line_no": 301, "task_id": "huggingface_diffusers/197", "start_line_no": 281, "end_line_no": 301, "window_size": 20, "context_start_lineno": 152, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        pipe(**inputs, callback=callback_fn, callback_steps=1)\n        assert callback_fn.has_been_called\n        assert number_of_steps == 2\n\n\n@nightly\n@require_torch_gpu\nclass StableDiffusionInpaintLegacyPipelineNightlyTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint_legacy.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7602739726027398}, {"context": "        assert images.shape == (batch_size * num_images_per_prompt, 32, 32, 3)\n\n\n@slow\n@require_torch_gpu\nclass StableDiffusionInpaintLegacyPipelineSlowTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_mask.png\"", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint_legacy.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7133333333333334}, {"context": "\n\n@nightly\n@require_torch_gpu\nclass StableDiffusionImg2ImgPipelineNightlyTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_img2img/sketch-mountains-input.png\"\n        )\n        inputs = {\n            \"prompt\": \"a fantasy landscape, concept art, high resolution\",\n            \"image\": init_image,\n            \"generator\": generator,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_img2img.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.697986577181208}, {"context": "\n@nightly\n@require_torch_gpu\nclass StableDiffusionImg2ImgPipelineNightlyTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/depth2img/two_cats.png\"\n        )\n        inputs = {\n            \"prompt\": \"two tigers\",\n            \"image\": init_image,\n            \"generator\": generator,\n            \"num_inference_steps\": 3,\n            \"strength\": 0.75,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion_2", "test_stable_diffusion_depth.py"], "line_no": 540, "start_line_no": 530, "end_line_no": 550, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6493506493506493}, {"context": "        inputs[\"prompt\"] = [inputs[\"prompt\"]] * batch_size\n        images = sd_pipe(**inputs, num_images_per_prompt=num_images_per_prompt).images\n\n        assert images.shape == (batch_size * num_images_per_prompt, 32, 32, 3)\n\n\n@slow\n@require_torch_gpu\nclass StableDiffusionImg2ImgPipelineSlowTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_img2img/sketch-mountains-input.png\"\n        )", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_img2img.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6459627329192547}, {"context": "        assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-3\n\n\n@slow\n@require_torch_gpu\nclass StableDiffusionDepth2ImgPipelineSlowTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/depth2img/two_cats.png\"\n        )\n        inputs = {\n            \"prompt\": \"two tigers\",\n            \"image\": init_image,\n            \"generator\": generator,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion_2", "test_stable_diffusion_depth.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.61875}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/splitters/graph/analyzer.py\n# --------------------------------------------------\n# \n#         \"\"\"\n#         edge_index, x = data.edge_index, data.x\n#         cnt = 0\n#         for row, col in edge_index.T:\n#             row, col = row.item(), col.item()\n#             cnt += torch.sum(x[row] != x[col]).item()\n# \n#         return cnt / edge_index.shape[1]\n# \n#     def hamming(self):\n#         r\"\"\"\n# \n#         Returns:\n#             the average hamming distance of feature for the raw G, split G\n#             and missing edge G\n# \n#         \"\"\"\n#         return self.hamming_distance_graph(\n#             self.raw_data), self.hamming_distance_graph(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/model/gpr.py\n# --------------------------------------------------\n#         for k in range(self.K):\n#             x = self.propagate(edge_index, x=x, norm=norm)\n#             gamma = self.temp[k + 1]\n#             hidden = hidden + gamma * x\n#         return hidden\n# \n#     def message(self, x_j, norm):\n#         return norm.view(-1, 1) * x_j\n# \n#     def __repr__(self):\n#         return '{}(K={}, temp={})'.format(self.__class__.__name__, self.K,\n#                                           self.temp)\n# \n# \n# class GPR_Net(torch.nn.Module):\n#     r\"\"\"GPR-GNN model from the \"Adaptive Universal Generalized PageRank\n#     Graph Neural Network\" paper, in ICLR'21\n# \n#     Arguments:\n#         in_channels (int): dimension of input.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/splitters/graph/analyzer.py\n# --------------------------------------------------\n#         edge_index, x = data.edge_index, data.x\n#         cnt = 0\n#         for row, col in edge_index.T:\n#             row, col = row.item(), col.item()\n#             cnt += torch.sum(x[row] != x[col]).item()\n# \n#         return cnt / edge_index.shape[1]\n# \n#     def hamming(self):\n#         r\"\"\"\n# \n#         Returns:\n#             the average hamming distance of feature for the raw G, split G\n#             and missing edge G\n# \n#         \"\"\"\n#         return self.hamming_distance_graph(\n#             self.raw_data), self.hamming_distance_graph(\n#                 self.fl_data()), self.hamming_distance_graph(\n#                     self.missing_data())\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/contrib/model/fedsam_convnet.py\n# --------------------------------------------------\n#         x = self.layer1(x)\n#         x = self.layer2(x)\n#         x = torch.reshape(x, (x.shape[0], -1))\n#         x = self.classifier(x)\n#         return x\n# \n#     def model_size(self):\n#         tot_size = 0\n#         for param in self.parameters():\n#             tot_size += param.size()[0]\n#         return tot_size\n# \n# \n# def call_fedsam_conv2(model_config, local_data):\n#     if model_config.type == 'fedsam_conv2':\n#         model = Conv2Model(10)\n#         return model\n# \n# \n# register_model('fedsam_conv2', call_fedsam_conv2)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/splitters/graph/analyzer.py\n# --------------------------------------------------\n#                                             dtype=torch.int64).T\n#             else:\n#                 ms_data[key] = item\n# \n#         return ms_data\n# \n#     def portion_ms_node(self):\n#         r\"\"\"\n# \n#         Returns:\n#             the proportion of nodes who miss egde.\n# \n#         \"\"\"\n#         cnt_list = []\n#         ms_set = {x.item() for x in set(self.missing_data().edge_index[0])}\n#         for sub_data in self.split_data:\n#             cnt = 0\n#             for idx in sub_data.index_orig:\n#                 if idx.item() in ms_set:\n#                     cnt += 1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/splitters/graph/analyzer.py\n# --------------------------------------------------\n# \n#         return fl_data\n# \n#     def missing_data(self):\n#         r\"\"\"\n# \n#         Returns:\n#             the graph data built by missing edge index.\n# \n#         \"\"\"\n#         ms_data = Data()\n#         raw_edge_set = {tuple(x) for x in self.raw_data.edge_index.T.numpy()}\n#         split_edge_set = {\n#             tuple(x)\n#             for x in self.fl_data().edge_index.T.numpy()\n#         }\n#         ms_set = raw_edge_set - split_edge_set\n#         for key, item in self.raw_data:\n#             if key == 'edge_index':\n#                 ms_data[key] = torch.tensor([list(x) for x in ms_set],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/splitters/graph/analyzer.py\n# --------------------------------------------------\n#         ms_data = Data()\n#         raw_edge_set = {tuple(x) for x in self.raw_data.edge_index.T.numpy()}\n#         split_edge_set = {\n#             tuple(x)\n#             for x in self.fl_data().edge_index.T.numpy()\n#         }\n#         ms_set = raw_edge_set - split_edge_set\n#         for key, item in self.raw_data:\n#             if key == 'edge_index':\n#                 ms_data[key] = torch.tensor([list(x) for x in ms_set],\n#                                             dtype=torch.int64).T\n#             else:\n#                 ms_data[key] = item\n# \n#         return ms_data\n# \n#     def portion_ms_node(self):\n#         r\"\"\"\n# \n#         Returns:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/model/link_level.py\n# --------------------------------------------------\n# \n#         dim_list = [hidden for _ in range(layers)]\n#         self.output = MLP([hidden] + dim_list + [out_channels],\n#                           batch_norm=True)\n# \n#     def forward(self, data):\n#         if isinstance(data, Data):\n#             x, edge_index = data.x, data.edge_index\n#         elif isinstance(data, tuple):\n#             x, edge_index = data\n#         else:\n#             raise TypeError('Unsupported data type!')\n# \n#         x = self.gnn((x, edge_index))\n#         return x\n# \n#     def link_predictor(self, x, edge_index):\n#         x = x[edge_index[0]] * x[edge_index[1]]\n#         x = self.output(x)\n#         return x\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import division\n\nimport torch\nimport numpy as np\nimport scipy.sparse as sp\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data\n\nfrom federatedscope.gfl.model import SAGE_Net\n\"\"\"\nhttps://proceedings.neurips.cc//paper/2021/file/ \\\n34adeb8e3242824038aa65460a47c29e-Paper.pdf\nFedsageplus models from the \"Subgraph Federated Learning with Missing\nNeighbor Generation\" (FedSage+) paper, in NeurIPS'21\nSource: https://github.com/zkhku/fedsage\n\"\"\"\n\n\nclass Sampling(nn.Module):\n    def __init__(self):\n        super(Sampling, self).__init__()\n\n    def forward(self, inputs):\n        rand = torch.normal(0, 1, size=inputs.shape)\n\n        return inputs + rand.to(inputs.device)\n\n\nclass FeatGenerator(nn.Module):\n    def __init__(self, latent_dim, dropout, num_pred, feat_shape):\n        super(FeatGenerator, self).__init__()\n        self.num_pred = num_pred\n        self.feat_shape = feat_shape\n        self.dropout = dropout\n        self.sample = Sampling()\n        self.fc1 = nn.Linear(latent_dim, 256)\n        self.fc2 = nn.Linear(256, 2048)\n        self.fc_flat = nn.Linear(2048, self.num_pred * self.feat_shape)\n\n    def forward(self, x):\n        x = self.sample(x)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.dropout(x, self.dropout, training=self.training)\n        x = torch.tanh(self.fc_flat(x))\n\n        return x\n\n\nclass NumPredictor(nn.Module):\n    def __init__(self, latent_dim):\n        self.latent_dim = latent_dim\n        super(NumPredictor, self).__init__()\n        self.reg_1 = nn.Linear(self.latent_dim, 1)\n\n    def forward(self, x):\n        x = F.relu(self.reg_1(x))\n        return x\n\n\n# Mend the graph via NeighGen\nclass MendGraph(nn.Module):\n    def __init__(self, num_pred):\n        super(MendGraph, self).__init__()\n        self.num_pred = num_pred\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def mend_graph(self, x, edge_index, pred_degree, gen_feats):\n        device = gen_feats.device\n        num_node, num_feature = x.shape\n        new_edges = []\n        gen_feats = gen_feats.view(-1, self.num_pred, num_feature)\n\n        if pred_degree.device.type != 'cpu':\n            pred_degree = pred_degree.cpu()\n        pred_degree = torch._cast_Int(torch.round(pred_degree)).detach()\n        x = x.detach()\n        fill_feats = torch.vstack((x, gen_feats.view(-1, num_feature)))\n\n        for i in range(num_node):\n            for j in range(min(self.num_pred, max(0, pred_degree[i]))):\n                new_edges.append(\n                    np.asarray([i, num_node + i * self.num_pred + j]))\n\n        new_edges = torch.tensor(np.asarray(new_edges).reshape((-1, 2)),\n                                 dtype=torch.int64).T\n        new_edges = new_edges.to(device)\n        if len(new_edges) > 0:\n            fill_edges = torch.hstack((edge_index, new_edges))\n        else:\n            fill_edges = torch.clone(edge_index)\n        return fill_feats, fill_edges\n\n    def forward(self, x, edge_index, pred_missing, gen_feats):\n        fill_feats, fill_edges = self.mend_graph(x, edge_index, pred_missing,\n                                                 gen_feats)\n\n        return fill_feats, fill_edges\n\n\nclass LocalSage_Plus(nn.Module):\n    def __init__(self,\n                 in_channels,\n                 out_channels,\n                 hidden,\n                 gen_hidden,\n                 dropout=0.5,\n                 num_pred=5):\n        super(LocalSage_Plus, self).__init__()\n\n        self.encoder_model = SAGE_Net(in_channels=in_channels,\n                                      out_channels=gen_hidden,\n                                      hidden=hidden,\n                                      max_depth=2,\n                                      dropout=dropout)\n        self.reg_model = NumPredictor(latent_dim=gen_hidden)\n        self.gen = FeatGenerator(latent_dim=gen_hidden,\n                                 dropout=dropout,\n                                 num_pred=num_pred,\n                                 feat_shape=in_channels)\n        self.mend_graph = MendGraph(num_pred)\n\n        self.classifier = SAGE_Net(in_channels=in_channels,\n                                   out_channels=out_channels,\n                                   hidden=hidden,\n                                   max_depth=2,\n                                   dropout=dropout)\n\n    def forward(self, data):\n        x = self.encoder_model(data)\n        degree = self.reg_model(x)\n        gen_feat = self.gen(x)\n        mend_feats, mend_edge_index = self.mend_graph(data.x, data.edge_index,\n                                                      degree, gen_feat)\n        nc_pred = self.classifier(\n            Data(x=mend_feats, edge_index=mend_edge_index))\n        return degree, gen_feat, nc_pred[:data.num_nodes]\n\n    def inference(self, impared_data, raw_data):\n        x = self.encoder_model(impared_data)\n        degree = self.reg_model(x)\n        gen_feat = self.gen(x)\n        mend_feats, mend_edge_index = self.mend_graph(raw_data.x,\n                                                      raw_data.edge_index,\n                                                      degree, gen_feat)\n        nc_pred = self.classifier(\n            Data(x=mend_feats, edge_index=mend_edge_index))", "choices": [{"text": "nc_pred[:raw_data.num_nodes]"}], "metadata": {"task_id": "alibaba_FederatedScope/140", "ground_truth": "        return degree, gen_feat, nc_pred[:raw_data.num_nodes]", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "model", "fedsageplus.py"], "context_start_lineno": 0, "line_no": 152, "query_window": {"context": "\n    def forward(self, data):\n        x = self.encoder_model(data)\n        degree = self.reg_model(x)\n        gen_feat = self.gen(x)\n        mend_feats, mend_edge_index = self.mend_graph(data.x, data.edge_index,\n                                                      degree, gen_feat)\n        nc_pred = self.classifier(\n            Data(x=mend_feats, edge_index=mend_edge_index))\n        return degree, gen_feat, nc_pred[:data.num_nodes]\n\n    def inference(self, impared_data, raw_data):\n        x = self.encoder_model(impared_data)\n        degree = self.reg_model(x)\n        gen_feat = self.gen(x)\n        mend_feats, mend_edge_index = self.mend_graph(raw_data.x,\n                                                      raw_data.edge_index,\n                                                      degree, gen_feat)\n        nc_pred = self.classifier(\n            Data(x=mend_feats, edge_index=mend_edge_index))", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "model", "fedsageplus.py"], "line_no": 152, "task_id": "alibaba_FederatedScope/140", "start_line_no": 132, "end_line_no": 152, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "        self.output = MLP([hidden] + dim_list + [out_channels],\n                          batch_norm=True)\n\n    def forward(self, data):\n        if isinstance(data, Data):\n            x, edge_index = data.x, data.edge_index\n        elif isinstance(data, tuple):\n            x, edge_index = data\n        else:\n            raise TypeError('Unsupported data type!')\n\n        x = self.gnn((x, edge_index))\n        return x\n\n    def link_predictor(self, x, edge_index):\n        x = x[edge_index[0]] * x[edge_index[1]]\n        x = self.output(x)\n        return x", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "model", "link_level.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 88, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.30097087378640774}, {"context": "\n        return fl_data\n\n    def missing_data(self):\n        r\"\"\"\n\n        Returns:\n            the graph data built by missing edge index.\n\n        \"\"\"\n        ms_data = Data()\n        raw_edge_set = {tuple(x) for x in self.raw_data.edge_index.T.numpy()}\n        split_edge_set = {\n            tuple(x)\n            for x in self.fl_data().edge_index.T.numpy()\n        }\n        ms_set = raw_edge_set - split_edge_set\n        for key, item in self.raw_data:\n            if key == 'edge_index':\n                ms_data[key] = torch.tensor([list(x) for x in ms_set],", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "splitters", "graph", "analyzer.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.297029702970297}, {"context": "        Returns:\n            the split edge index.\n\n        \"\"\"\n        fl_data = Data()\n        for key, item in self.raw_data:\n            if key == 'edge_index':\n                fl_data[key] = self.fl_adj()\n            else:\n                fl_data[key] = item\n\n        return fl_data\n\n    def missing_data(self):\n        r\"\"\"\n\n        Returns:\n            the graph data built by missing edge index.\n\n        \"\"\"", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "splitters", "graph", "analyzer.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.29069767441860467}, {"context": "        ms_data = Data()\n        raw_edge_set = {tuple(x) for x in self.raw_data.edge_index.T.numpy()}\n        split_edge_set = {\n            tuple(x)\n            for x in self.fl_data().edge_index.T.numpy()\n        }\n        ms_set = raw_edge_set - split_edge_set\n        for key, item in self.raw_data:\n            if key == 'edge_index':\n                ms_data[key] = torch.tensor([list(x) for x in ms_set],\n                                            dtype=torch.int64).T\n            else:\n                ms_data[key] = item\n\n        return ms_data\n\n    def portion_ms_node(self):\n        r\"\"\"\n\n        Returns:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "splitters", "graph", "analyzer.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.28846153846153844}, {"context": "\n        self.classifier = nn.Sequential(nn.Linear(64 * 5 * 5, 384), nn.ReLU(),\n                                        nn.Linear(384, 192), nn.ReLU(),\n                                        nn.Linear(192, self.num_classes))\n\n        self.size = self.model_size()\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = torch.reshape(x, (x.shape[0], -1))\n        x = self.classifier(x)\n        return x\n\n    def model_size(self):\n        tot_size = 0\n        for param in self.parameters():\n            tot_size += param.size()[0]\n        return tot_size\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "contrib", "model", "fedsam_convnet.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2871287128712871}, {"context": "\n        \"\"\"\n        edge_index, x = data.edge_index, data.x\n        cnt = 0\n        for row, col in edge_index.T:\n            row, col = row.item(), col.item()\n            cnt += torch.sum(x[row] != x[col]).item()\n\n        return cnt / edge_index.shape[1]\n\n    def hamming(self):\n        r\"\"\"\n\n        Returns:\n            the average hamming distance of feature for the raw G, split G\n            and missing edge G\n\n        \"\"\"\n        return self.hamming_distance_graph(\n            self.raw_data), self.hamming_distance_graph(", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "splitters", "graph", "analyzer.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2828282828282828}, {"context": "            self.temp.data[k] = self.alpha * (1 - self.alpha)**k\n        self.temp.data[-1] = (1 - self.alpha)**self.K\n\n    def forward(self, x, edge_index, edge_weight=None):\n        edge_index, norm = gcn_norm(edge_index,\n                                    edge_weight,\n                                    num_nodes=x.size(0),\n                                    dtype=x.dtype)\n\n        hidden = x * (self.temp[0])\n        for k in range(self.K):\n            x = self.propagate(edge_index, x=x, norm=norm)\n            gamma = self.temp[k + 1]\n            hidden = hidden + gamma * x\n        return hidden\n\n    def message(self, x_j, norm):\n        return norm.view(-1, 1) * x_j\n\n    def __repr__(self):", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "model", "gpr.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2815533980582524}, {"context": "        return self.homophily_value(self.raw_data.edge_index,\n                                    self.raw_data.y), self.homophily_value(\n                                        self.fl_data().edge_index,\n                                        self.fl_data().y)\n\n    def hamming_distance_graph(self, data):\n        r\"\"\"\n\n        Returns:\n            calculate the hamming distance of graph data\n\n        \"\"\"\n        edge_index, x = data.edge_index, data.x\n        cnt = 0\n        for row, col in edge_index.T:\n            row, col = row.item(), col.item()\n            cnt += torch.sum(x[row] != x[col]).item()\n\n        return cnt / edge_index.shape[1]\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "splitters", "graph", "analyzer.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2815533980582524}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_c51():\n#     config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_qrdqn():\n#     config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_sac_auto_alpha():\n#     config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     config[0].policy.learn.is_auto_alpha = True\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_r2d2():\n#     config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         ppo_main(config[0], seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_sac():\n#     config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_sac_auto_alpha():\n#     config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     config[0].policy.learn.is_auto_alpha = True\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_a2c():\n#     config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_rainbow():\n#     config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry_algo.py\n# --------------------------------------------------\n#         )\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n#     # train cql\n#     config = [deepcopy(pendulum_cql_default_config), deepcopy(pendulum_cql_default_create_config)]\n#     try:\n#         serial_pipeline_offline(config, seed=0)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     with open(\"./algo_record.log\", \"a+\") as f:\n#         f.write(\"26. cql\\n\")\n# \n# \n# @pytest.mark.algotest\n# def test_discrete_cql():\n#     # train expert\n#     config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n#     config[0].exp_name = 'cartpole'\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry_algo.py\n# --------------------------------------------------\n#     config = [\n#         deepcopy(pendulum_sac_data_genearation_default_config),\n#         deepcopy(pendulum_sac_data_genearation_default_create_config)\n#     ]\n#     collect_count = config[0].policy.other.replay_buffer.replay_buffer_size\n#     expert_data_path = config[0].policy.collect.save_path\n#     state_dict = torch.load(config[0].policy.learn.learner.load_path, map_location='cpu')\n#     try:\n#         collect_demo_data(\n#             config, seed=0, collect_count=collect_count, expert_data_path=expert_data_path, state_dict=state_dict\n#         )\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n#     # train cql\n#     config = [deepcopy(pendulum_cql_default_config), deepcopy(pendulum_cql_default_create_config)]\n#     try:\n#         serial_pipeline_offline(config, seed=0)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nest\ndef test_r2d2():\n    config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_impala():\n    config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_her_dqn():\n    bitflip_her_dqn_config.policy.cuda = False\n    try:\n        bitflip_dqn_main(bitflip_her_dqn_config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_collaq():\n    config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n    config[0].policy.cuda = False\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_coma():\n    config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\n    config[0].policy.cuda = False\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_qmix():\n    config = [deepcopy(cooperative_navigation_qmix_config), deepcopy(cooperative_navigation_qmix_create_config)]\n    config[0].policy.cuda = False\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_wqmix():\n    config = [deepcopy(cooperative_navigation_wqmix_config), deepcopy(cooperative_navigation_wqmix_create_config)]\n    config[0].policy.cuda = False\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_qtran():\n    config = [deepcopy(cooperative_navigation_qtran_config), deepcopy(cooperative_navigation_qtran_create_config)]\n    config[0].policy.cuda = False\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_atoc():\n    config = [deepcopy(cooperative_navigation_atoc_config), deepcopy(cooperative_navigation_atoc_create_config)]\n    config[0].policy.cuda = False\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_ppg():\n    cartpole_ppg_config.policy.use_cuda = False\n    try:\n        ppg_main(cartpole_ppg_config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sqn():\n    config = [deepcopy(cartpole_sqn_config), deepcopy(cartpole_sqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_selfplay():\n    try:\n        selfplay_main(deepcopy(league_demo_ppo_config), seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_league():\n    try:\n        league_main(deepcopy(league_demo_ppo_config), seed=0, max_iterations=1)\n    except Exception as e:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_acer():\n    config = [deepcopy(cartpole_acer_config), deepcopy(cartpole_acer_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_cql():\n    # train expert\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n    # collect expert data\n    import torch\n    config = [\n        deepcopy(pendulum_sac_data_genearation_default_config),\n        deepcopy(pendulum_sac_data_genearation_default_create_config)\n    ]\n    collect_count = 1000\n    expert_data_path = config[0].policy.collect.save_path\n    state_dict = torch.load('./default_experiment/ckpt/iteration_0.pth.tar', map_location='cpu')\n    try:", "choices": [{"text": "collect_demo_data("}], "metadata": {"task_id": "opendilab_ACE/140", "ground_truth": "        collect_demo_data(", "fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "context_start_lineno": 156, "line_no": 342, "query_window": {"context": "@pytest.mark.unittest\ndef test_cql():\n    # train expert\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n    # collect expert data\n    import torch\n    config = [\n        deepcopy(pendulum_sac_data_genearation_default_config),\n        deepcopy(pendulum_sac_data_genearation_default_create_config)\n    ]\n    collect_count = 1000\n    expert_data_path = config[0].policy.collect.save_path\n    state_dict = torch.load('./default_experiment/ckpt/iteration_0.pth.tar', map_location='cpu')\n    try:", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 342, "task_id": "opendilab_ACE/140", "start_line_no": 322, "end_line_no": 342, "window_size": 20, "context_start_lineno": 156, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "def test_cql():\n    # train expert\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n    # collect expert data\n    import torch\n    config = [\n        deepcopy(pendulum_sac_data_genearation_default_config),\n        deepcopy(pendulum_sac_data_genearation_default_create_config)\n    ]\n    collect_count = config[0].policy.other.replay_buffer.replay_buffer_size\n    expert_data_path = config[0].policy.collect.save_path\n    state_dict = torch.load(config[0].policy.learn.learner.load_path, map_location='cpu')\n    try:\n        collect_demo_data(\n            config, seed=0, collect_count=collect_count, expert_data_path=expert_data_path, state_dict=state_dict", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6605504587155964}, {"context": "    config = [\n        deepcopy(pendulum_sac_data_genearation_default_config),\n        deepcopy(pendulum_sac_data_genearation_default_create_config)\n    ]\n    collect_count = config[0].policy.other.replay_buffer.replay_buffer_size\n    expert_data_path = config[0].policy.collect.save_path\n    state_dict = torch.load(config[0].policy.learn.learner.load_path, map_location='cpu')\n    try:\n        collect_demo_data(\n            config, seed=0, collect_count=collect_count, expert_data_path=expert_data_path, state_dict=state_dict\n        )\n    except Exception:\n        assert False, \"pipeline fail\"\n\n    # train cql\n    config = [deepcopy(pendulum_cql_default_config), deepcopy(pendulum_cql_default_create_config)]\n    try:\n        serial_pipeline_offline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5929203539823009}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_td3():\n    config = [deepcopy(pendulum_td3_config), deepcopy(pendulum_td3_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5882352941176471}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_ppo():\n    config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        ppo_main(config[0], seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sac():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5825242718446602}, {"context": "        ppo_main(config[0], seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sac():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sac_auto_alpha():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    config[0].policy.learn.is_auto_alpha = True", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5769230769230769}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_iqn():\n    config = [deepcopy(cartpole_iqn_config), deepcopy(cartpole_iqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_c51():\n    config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5742574257425742}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/stable_diffusion/pipeline_onnx_stable_diffusion.py\n# --------------------------------------------------\n# logger = logging.get_logger(__name__)\n# \n# \n# class OnnxStableDiffusionPipeline(DiffusionPipeline):\n#     vae_encoder: OnnxRuntimeModel\n#     vae_decoder: OnnxRuntimeModel\n#     text_encoder: OnnxRuntimeModel\n#     tokenizer: CLIPTokenizer\n#     unet: OnnxRuntimeModel\n#     scheduler: Union[DDIMScheduler, PNDMScheduler, LMSDiscreteScheduler]\n#     safety_checker: OnnxRuntimeModel\n#     feature_extractor: CLIPFeatureExtractor\n# \n#     _optional_components = [\"safety_checker\", \"feature_extractor\"]\n# \n#     def __init__(\n#         self,\n#         vae_encoder: OnnxRuntimeModel,\n#         vae_decoder: OnnxRuntimeModel,\n#         text_encoder: OnnxRuntimeModel,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/latent_diffusion/pipeline_latent_diffusion_superresolution.py\n# --------------------------------------------------\n# \n# \n# def preprocess(image):\n#     w, h = image.size\n#     w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n#     image = image.resize((w, h), resample=PIL_INTERPOLATION[\"lanczos\"])\n#     image = np.array(image).astype(np.float32) / 255.0\n#     image = image[None].transpose(0, 3, 1, 2)\n#     image = torch.from_numpy(image)\n#     return 2.0 * image - 1.0\n# \n# \n# class LDMSuperResolutionPipeline(DiffusionPipeline):\n#     r\"\"\"\n#     A pipeline for image super-resolution using Latent\n# \n#     This class inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods the\n#     library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)\n# \n#     Parameters:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/stable_diffusion/pipeline_onnx_stable_diffusion_inpaint_legacy.py\n# --------------------------------------------------\n# from ...schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\n# from ...utils import deprecate, logging\n# from ..onnx_utils import OnnxRuntimeModel\n# from ..pipeline_utils import DiffusionPipeline\n# from . import StableDiffusionPipelineOutput\n# \n# \n# logger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n# \n# \n# def preprocess(image):\n#     w, h = image.size\n#     w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n#     image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n#     image = np.array(image).astype(np.float32) / 255.0\n#     image = image[None].transpose(0, 3, 1, 2)\n#     return 2.0 * image - 1.0\n# \n# \n# def preprocess_mask(mask, scale_factor=8):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/stable_diffusion/pipeline_onnx_stable_diffusion_img2img.py\n# --------------------------------------------------\n# \n# logger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n# \n# \n# # Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.preprocess with 8->64\n# def preprocess(image):\n#     if isinstance(image, torch.Tensor):\n#         return image\n#     elif isinstance(image, PIL.Image.Image):\n#         image = [image]\n# \n#     if isinstance(image[0], PIL.Image.Image):\n#         w, h = image[0].size\n#         w, h = map(lambda x: x - x % 64, (w, h))  # resize to integer multiple of 64\n# \n#         image = [np.array(i.resize((w, h), resample=PIL_INTERPOLATION[\"lanczos\"]))[None, :] for i in image]\n#         image = np.concatenate(image, axis=0)\n#         image = np.array(image).astype(np.float32) / 255.0\n#         image = image.transpose(0, 3, 1, 2)\n#         image = 2.0 * image - 1.0\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/img2img_inpainting.py\n# --------------------------------------------------\n# def prepare_mask_and_masked_image(image, mask):\n#     image = np.array(image.convert(\"RGB\"))\n#     image = image[None].transpose(0, 3, 1, 2)\n#     image = torch.from_numpy(image).to(dtype=torch.float32) / 127.5 - 1.0\n# \n#     mask = np.array(mask.convert(\"L\"))\n#     mask = mask.astype(np.float32) / 255.0\n#     mask = mask[None, None]\n#     mask[mask < 0.5] = 0\n#     mask[mask >= 0.5] = 1\n#     mask = torch.from_numpy(mask)\n# \n#     masked_image = image * (mask < 0.5)\n# \n#     return mask, masked_image\n# \n# \n# def check_size(image, height, width):\n#     if isinstance(image, PIL.Image.Image):\n#         w, h = image.size\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/stable_diffusion/pipeline_onnx_stable_diffusion_inpaint_legacy.py\n# --------------------------------------------------\n# def preprocess(image):\n#     w, h = image.size\n#     w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n#     image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n#     image = np.array(image).astype(np.float32) / 255.0\n#     image = image[None].transpose(0, 3, 1, 2)\n#     return 2.0 * image - 1.0\n# \n# \n# def preprocess_mask(mask, scale_factor=8):\n#     mask = mask.convert(\"L\")\n#     w, h = mask.size\n#     w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n#     mask = mask.resize((w // scale_factor, h // scale_factor), resample=PIL.Image.NEAREST)\n#     mask = np.array(mask).astype(np.float32) / 255.0\n#     mask = np.tile(mask, (4, 1, 1))\n#     mask = mask[None].transpose(0, 1, 2, 3)  # what does this step do?\n#     mask = 1 - mask  # repaint white, keep black\n#     return mask\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2022 The HuggingFace Team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport inspect\nfrom typing import Callable, List, Optional, Union\n\nimport numpy as np\nimport torch\n\nimport PIL\nfrom transformers import CLIPFeatureExtractor, CLIPTokenizer\n\nfrom ...configuration_utils import FrozenDict\nfrom ...schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\nfrom ...utils import PIL_INTERPOLATION, deprecate, logging\nfrom ..onnx_utils import ORT_TO_NP_TYPE, OnnxRuntimeModel\nfrom ..pipeline_utils import DiffusionPipeline\nfrom . import StableDiffusionPipelineOutput\n\n\nlogger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n\n\nNUM_UNET_INPUT_CHANNELS = 9\nNUM_LATENT_CHANNELS = 4\n\n\ndef prepare_mask_and_masked_image(image, mask, latents_shape):\n    image = np.array(image.convert(\"RGB\").resize((latents_shape[1] * 8, latents_shape[0] * 8)))\n    image = image[None].transpose(0, 3, 1, 2)\n    image = image.astype(np.float32) / 127.5 - 1.0\n\n    image_mask = np.array(mask.convert(\"L\").resize((latents_shape[1] * 8, latents_shape[0] * 8)))", "choices": [{"text": "image_mask = image_mask.astype(np.float32) / 255.0"}], "metadata": {"task_id": "huggingface_diffusers/181", "ground_truth": "    masked_image = image * (image_mask < 127.5)", "fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_onnx_stable_diffusion_inpaint.py"], "context_start_lineno": 0, "line_no": 44, "query_window": {"context": "from ...schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\nfrom ...utils import PIL_INTERPOLATION, deprecate, logging\nfrom ..onnx_utils import ORT_TO_NP_TYPE, OnnxRuntimeModel\nfrom ..pipeline_utils import DiffusionPipeline\nfrom . import StableDiffusionPipelineOutput\n\n\nlogger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n\n\nNUM_UNET_INPUT_CHANNELS = 9\nNUM_LATENT_CHANNELS = 4\n\n\ndef prepare_mask_and_masked_image(image, mask, latents_shape):\n    image = np.array(image.convert(\"RGB\").resize((latents_shape[1] * 8, latents_shape[0] * 8)))\n    image = image[None].transpose(0, 3, 1, 2)\n    image = image.astype(np.float32) / 127.5 - 1.0\n\n    image_mask = np.array(mask.convert(\"L\").resize((latents_shape[1] * 8, latents_shape[0] * 8)))", "metadata": {"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_onnx_stable_diffusion_inpaint.py"], "line_no": 44, "task_id": "huggingface_diffusers/181", "start_line_no": 24, "end_line_no": 44, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "from ...schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\nfrom ...utils import deprecate, logging\nfrom ..onnx_utils import OnnxRuntimeModel\nfrom ..pipeline_utils import DiffusionPipeline\nfrom . import StableDiffusionPipelineOutput\n\n\nlogger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n\n\ndef preprocess(image):\n    w, h = image.size\n    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n    image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n    image = np.array(image).astype(np.float32) / 255.0\n    image = image[None].transpose(0, 3, 1, 2)\n    return 2.0 * image - 1.0\n\n\ndef preprocess_mask(mask, scale_factor=8):", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_onnx_stable_diffusion_inpaint_legacy.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5757575757575758}, {"context": "from diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\nfrom diffusers.pipelines.stable_diffusion.safety_checker import StableDiffusionSafetyChecker\nfrom diffusers.schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\nfrom diffusers.utils import deprecate, logging\nfrom transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n\n\nlogger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n\n\ndef prepare_mask_and_masked_image(image, mask):\n    image = np.array(image.convert(\"RGB\"))\n    image = image[None].transpose(0, 3, 1, 2)\n    image = torch.from_numpy(image).to(dtype=torch.float32) / 127.5 - 1.0\n\n    mask = np.array(mask.convert(\"L\"))\n    mask = mask.astype(np.float32) / 255.0\n    mask = mask[None, None]\n    mask[mask < 0.5] = 0\n    mask[mask >= 0.5] = 1", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "img2img_inpainting.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5568862275449101}, {"context": "import PIL\nfrom transformers import CLIPFeatureExtractor, CLIPTokenizer\n\nfrom ...configuration_utils import FrozenDict\nfrom ...schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\nfrom ...utils import PIL_INTERPOLATION, deprecate, logging\nfrom ..onnx_utils import ORT_TO_NP_TYPE, OnnxRuntimeModel\nfrom ..pipeline_utils import DiffusionPipeline\nfrom . import StableDiffusionPipelineOutput\n\n\nlogger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n\n\n# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.preprocess with 8->64\ndef preprocess(image):\n    if isinstance(image, torch.Tensor):\n        return image\n    elif isinstance(image, PIL.Image.Image):\n        image = [image]", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_onnx_stable_diffusion_img2img.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4602272727272727}, {"context": "import inspect\nfrom typing import Callable, List, Optional, Union\n\nimport numpy as np\nimport torch\n\nimport PIL\nfrom transformers import CLIPFeatureExtractor, CLIPTokenizer\n\nfrom ...configuration_utils import FrozenDict\nfrom ...schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\nfrom ...utils import deprecate, logging\nfrom ..onnx_utils import OnnxRuntimeModel\nfrom ..pipeline_utils import DiffusionPipeline\nfrom . import StableDiffusionPipelineOutput\n\n\nlogger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_onnx_stable_diffusion_inpaint_legacy.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4240506329113924}, {"context": "from ...schedulers import (\n    DDIMScheduler,\n    DPMSolverMultistepScheduler,\n    EulerAncestralDiscreteScheduler,\n    EulerDiscreteScheduler,\n    LMSDiscreteScheduler,\n    PNDMScheduler,\n)\nfrom ...utils import PIL_INTERPOLATION, deprecate, randn_tensor\nfrom ..pipeline_utils import DiffusionPipeline, ImagePipelineOutput\n\n\ndef preprocess(image):\n    w, h = image.size\n    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n    image = image.resize((w, h), resample=PIL_INTERPOLATION[\"lanczos\"])\n    image = np.array(image).astype(np.float32) / 255.0\n    image = image[None].transpose(0, 3, 1, 2)\n    image = torch.from_numpy(image)\n    return 2.0 * image - 1.0", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "latent_diffusion", "pipeline_latent_diffusion_superresolution.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4157303370786517}, {"context": "from transformers import CLIPFeatureExtractor, CLIPTokenizer\n\nfrom ...configuration_utils import FrozenDict\nfrom ...schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\nfrom ...utils import deprecate, logging\nfrom ..onnx_utils import ORT_TO_NP_TYPE, OnnxRuntimeModel\nfrom ..pipeline_utils import DiffusionPipeline\nfrom . import StableDiffusionPipelineOutput\n\n\nlogger = logging.get_logger(__name__)\n\n\nclass OnnxStableDiffusionPipeline(DiffusionPipeline):\n    vae_encoder: OnnxRuntimeModel\n    vae_decoder: OnnxRuntimeModel\n    text_encoder: OnnxRuntimeModel\n    tokenizer: CLIPTokenizer\n    unet: OnnxRuntimeModel\n    scheduler: Union[DDIMScheduler, PNDMScheduler, LMSDiscreteScheduler]", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_onnx_stable_diffusion.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.39751552795031053}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#     return self._parameter_configs[name]\n# \n#   def pop(self, name: str) -> ParameterConfig:\n#     return self._parameter_configs.pop(name)\n# \n#   def add(self,\n#           parameter_config: ParameterConfig,\n#          \n#           *,\n#           replace: bool = False) -> ParameterConfig:\n#     \"\"\"Adds the ParameterConfig.\n# \n#     For advanced users only. Takes a reference to Parameterconfig.\n#     Future edits will change the search space.\n# \n#     Args:\n#       parameter_config:\n#       replace: Determines the behavior when there already exists a\n#         ParameterConfig with the same name. If set to True, replaces it. If set\n#         to False, raises ValueError.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/automated_stopping.py\n# --------------------------------------------------\n# \n# @attr.s(frozen=True, init=True, slots=True, kw_only=True)\n# class AutomatedStoppingConfig:\n#   \"\"\"A wrapper for study_pb2.automated_stopping_spec.\"\"\"\n#   _proto: AutomatedStoppingConfigProto = attr.ib(init=True, kw_only=True)\n# \n#   @classmethod\n#   def default_stopping_spec(cls) -> 'AutomatedStoppingConfig':\n#     \"\"\"Use Vizier's default early stopping.\"\"\"\n#     config = study_pb2.StudySpec.DefaultEarlyStoppingSpec()\n#     return cls(proto=config)\n# \n#   @classmethod\n#   def from_proto(\n#       cls, proto: AutomatedStoppingConfigProto) -> 'AutomatedStoppingConfig':\n#     return cls(proto=proto)\n# \n#   def to_proto(self) -> AutomatedStoppingConfigProto:\n#     \"\"\"Returns this object as a proto.\"\"\"\n#     return copy.deepcopy(self._proto)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#   Vizier search space can be *conditional*.\n#   Parameter names are guaranteed to be unique in any subspace.\n# \n#   Attribute:\n#     _parameter_configs: Maps parameter names to configs.\n#   \"\"\"\n#   _parameter_configs: dict[str, ParameterConfig] = attr.field(\n#       init=False, factory=dict)\n# \n#   # TODO: To be deprecated.\n#   _parent_values: MonotypeParameterSequence = attr.field(\n#       default=tuple(), converter=tuple, kw_only=True)\n# \n#   @property\n#   def parameter_names(self) -> AbstractSet[str]:\n#     return self._parameter_configs.keys()\n# \n#   def get(self, name: str) -> ParameterConfig:\n#     if name not in self._parameter_configs:\n#       raise KeyError(f'{name} is not in the search space.')\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/algorithms/designers/quasi_random.py\n# --------------------------------------------------\n#                skip_points: int,\n#                num_points_generated: int = 0,\n#                primes_override: Optional[List[int]] = None,\n#                scramble: bool = False):\n#     \"\"\"Create a Halton sequence generator.\n# \n#     Args:\n#       num_dimensions: Number of dimensions for each point in the seqeunce. This\n#         corresponds to the number of parameters in the Vizier search space.\n#       skip_points: The number of initial points that should be skipped before\n#         the first point is returned.\n#       num_points_generated: Number of points that have already been generated.\n#       primes_override: If supplied, use these primes to seed each dimension of\n#         the Halton sequence. This is useful for testing. NOTE: These values are\n#         not validated, so it is the responsibility of the user to supply\n#         legitimate primes.\n#       scramble: If True, will scramble the resulting Halton sequence. This is\n#         intended to be used for testing.\n# \n#     Returns:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/base_study_config.py\n# --------------------------------------------------\n# \n#   @property\n#   def debug_info(self) -> str:\n#     return ''\n# \n#   @classmethod\n#   def from_problem(cls: Type[_T], problem: 'ProblemStatement') -> _T:\n#     \"\"\"Converts a ProblemStatement to a subclass instance.\n# \n#     Note that this method is useful in subclasses but not so much in\n#     `ProblemStatement` itself. `ProblemStatement.from_problem` simply generates\n#     a (shallow) copy of `problem`.\n# \n#     Args:\n#       problem:\n# \n#     Returns:\n#       A subclass instance filled with shallow copies of `ProblemStatement`\n#       fields.\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/optimizers/optimizers.py\n# --------------------------------------------------\n#       loss_fn: LossFunction,\n#       rng: chex.PRNGKey,\n#       *,\n#       constraints: Optional[sp.Constraint] = None,\n#   ) -> tuple[Params, dict[str, Array]]:\n#     # L-BFGS-B may be used on unconstrained problems (in which case it is\n#     # slightly different from L-BFGS, in that it uses the Cauchy point/subspace\n#     # minimization to choose the line search direction). Bounds must be None or\n#     # a tuple of size 2. The tuple must contain lower/upper bounds, which may be\n#     # None or a pytree with the same structure as the model parameters returned\n#     # by setup (otherwise Jaxopt will raise an error).\n#     p = setup(jax.random.PRNGKey(0))\n#     bounds = None if constraints is None else constraints.bounds\n#     is_leaf = lambda x: jax.tree_util.treedef_is_leaf(  # pylint: disable=g-long-lambda\n#         jax.tree_util.tree_structure(x)\n#     )\n# \n#     def _none_to_inf(b, inf):\n#       \"\"\"Converts None bounds to inf or -inf to pass to the optimizer.\"\"\"\n#       if b is None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/stochastic_process_model.py\n# --------------------------------------------------\n# \n#   @classmethod\n#   def from_prior(cls,\n#                  prior: tfd.Distribution,\n#                  constraint: Optional[Constraint] = None) -> 'ModelParameter':\n#     \"\"\"Builds a `ModelParameter` from a `tfd.Distribution`.\n# \n#     If `constraint` or `constraint.bijector` is None, then the constraint\n#     bijector is assumed to be the prior distribution's default event space\n#     bijector. See\n#     https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution#experimental_default_event_space_bijector\n# \n#     Args:\n#       prior: Parameter prior distribution.\n#       constraint: The parameter constraint.\n# \n#     Returns:\n#       model_parameter: The parameter specification with the given prior.\n#     \"\"\"\n#     if constraint is None or constraint.bounds is None:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"Collection of well-tuned GP models.\"\"\"\n\n# TODO: Add Ax/BoTorch GP.\n\nimport functools\nfrom typing import Any, Generator\n\nimport attr\nimport chex\nimport jax\nfrom jax import numpy as jnp\nfrom jax.config import config\nimport numpy as np\nfrom tensorflow_probability.substrates import jax as tfp\nfrom vizier._src.jax import stochastic_process_model as sp\nfrom vizier._src.jax.optimizers import optimizers\n\n# Jax disables float64 computations by default and will silently convert\n# float64s to float32s. We must explicitly enable float64.\nconfig.update('jax_enable_x64', True)\n\ntfb = tfp.bijectors\ntfd = tfp.distributions\nArray = Any\ntfpk = tfp.math.psd_kernels\n\n\n@attr.define\nclass VizierGaussianProcess(sp.ModelCoroutine[chex.Array, tfd.GaussianProcess]):\n  \"\"\"Vizier's tuned GP.\n\n  See __call__ method documentation.\n\n  Attributes:\n    _boundary_epsilon: We expand the constraints by this number so that the\n      values exactly at the boundary can be mapped to unconstrained space. i.e.\n      we are trying to avoid SoftClip(low=1e-2, high=1.).inverse(1e-2) giving\n      NaN.\n  \"\"\"\n\n  _feature_dim: int\n  _use_retrying_cholesky: bool = attr.field(default=True, kw_only=True)\n  _boundary_epsilon: float = attr.field(default=1e-12, kw_only=True)\n\n  @classmethod\n  def model_and_loss_fn(\n      cls,\n      features: chex.Array,\n      labels: chex.Array,\n      *,", "choices": [{"text": "ModelParameter` from a `tfd.Distribution`."}], "metadata": {"task_id": "google_vizier/193", "ground_truth": "      use_retrying_cholesky: bool = True,", "fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "models", "tuned_gp_models.py"], "context_start_lineno": 0, "line_no": 66, "query_window": {"context": "\n  See __call__ method documentation.\n\n  Attributes:\n    _boundary_epsilon: We expand the constraints by this number so that the\n      values exactly at the boundary can be mapped to unconstrained space. i.e.\n      we are trying to avoid SoftClip(low=1e-2, high=1.).inverse(1e-2) giving\n      NaN.\n  \"\"\"\n\n  _feature_dim: int\n  _use_retrying_cholesky: bool = attr.field(default=True, kw_only=True)\n  _boundary_epsilon: float = attr.field(default=1e-12, kw_only=True)\n\n  @classmethod\n  def model_and_loss_fn(\n      cls,\n      features: chex.Array,\n      labels: chex.Array,\n      *,", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "models", "tuned_gp_models.py"], "line_no": 66, "task_id": "google_vizier/193", "start_line_no": 46, "end_line_no": 66, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "    init_fn: Initializes parameter values.\n    constraint: Parameter constraint.\n    regularizer: Regularizes the parameter.\n  \"\"\"\n\n  name: str = attr.field()\n  init_fn: InitFn = attr.field()\n  constraint: Optional[Constraint] = attr.field(default=None)\n  regularizer: Callable[[Array], Array] = attr.field(\n      kw_only=True, default=lambda x: jnp.zeros([], dtype=x.dtype))\n\n  @classmethod\n  def from_prior(cls,\n                 prior: tfd.Distribution,\n                 constraint: Optional[Constraint] = None) -> 'ModelParameter':\n    \"\"\"Builds a `ModelParameter` from a `tfd.Distribution`.\n\n    If `constraint` or `constraint.bijector` is None, then the constraint\n    bijector is assumed to be the prior distribution's default event space\n    bijector. See", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.20903954802259886}, {"context": "  \"\"\"\n\n  num_line_search_steps: int = attr.field(kw_only=True, default=20)\n  random_restarts: int = attr.field(kw_only=True, default=64)\n  best_n: Optional[int] = attr.field(kw_only=True, default=None)\n  _speed_test: bool = attr.field(kw_only=True, default=False)\n\n  def __call__(\n      self,\n      setup: Setup,\n      loss_fn: LossFunction,\n      rng: chex.PRNGKey,\n      *,\n      constraints: Optional[sp.Constraint] = None,\n  ) -> tuple[Params, dict[str, Array]]:\n    # L-BFGS-B may be used on unconstrained problems (in which case it is\n    # slightly different from L-BFGS, in that it uses the Cauchy point/subspace\n    # minimization to choose the line search direction). Bounds must be None or\n    # a tuple of size 2. The tuple must contain lower/upper bounds, which may be\n    # None or a pytree with the same structure as the model parameters returned", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "optimizers", "optimizers.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.20297029702970298}, {"context": "      factory=MetricsConfig,\n      converter=MetricsConfig,\n      validator=attr.validators.instance_of(MetricsConfig),\n      kw_only=True)\n\n  metadata: common.Metadata = attr.field(\n      init=True,\n      kw_only=True,\n      factory=common.Metadata,\n      validator=attr.validators.instance_of(common.Metadata))\n\n  @property\n  def debug_info(self) -> str:\n    return ''\n\n  @classmethod\n  def from_problem(cls: Type[_T], problem: 'ProblemStatement') -> _T:\n    \"\"\"Converts a ProblemStatement to a subclass instance.\n\n    Note that this method is useful in subclasses but not so much in", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "base_study_config.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.20253164556962025}, {"context": "      validator=attr.validators.deep_iterable(\n          member_validator=attr.validators.instance_of(int),\n          iterable_validator=attr.validators.instance_of(Iterable)))\n\n  _scramble: bool = attr.field(\n      default=False, validator=attr.validators.instance_of(bool), kw_only=True)\n\n  def __init__(self,\n               num_dimensions: int,\n               *,\n               skip_points: int,\n               num_points_generated: int = 0,\n               primes_override: Optional[List[int]] = None,\n               scramble: bool = False):\n    \"\"\"Create a Halton sequence generator.\n\n    Args:\n      num_dimensions: Number of dimensions for each point in the seqeunce. This\n        corresponds to the number of parameters in the Vizier search space.\n      skip_points: The number of initial points that should be skipped before", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "algorithms", "designers", "quasi_random.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2011173184357542}, {"context": "        # Adds a deepcopy so that every ParameterConfig object is unique.\n        added.append(selected.add(copy.deepcopy(parameter)))\n\n    return ParameterConfigSelector(added)\n\n\n@attr.define(frozen=False, init=True, slots=True, kw_only=True)\nclass SearchSpace:\n  \"\"\"[Cross-platform] Collection of ParameterConfigs.\n\n  Vizier search space can be *conditional*.\n  Parameter names are guaranteed to be unique in any subspace.\n\n  Attribute:\n    _parameter_configs: Maps parameter names to configs.\n  \"\"\"\n  _parameter_configs: dict[str, ParameterConfig] = attr.field(\n      init=False, factory=dict)\n\n  # TODO: To be deprecated.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 1110, "start_line_no": 1100, "end_line_no": 1120, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.19883040935672514}, {"context": "  _proto: AutomatedStoppingConfigProto = attr.ib(init=True, kw_only=True)\n\n  @classmethod\n  def default_stopping_spec(cls) -> 'AutomatedStoppingConfig':\n    \"\"\"Use Vizier's default early stopping.\"\"\"\n    config = study_pb2.StudySpec.DefaultEarlyStoppingSpec()\n    return cls(proto=config)\n\n  @classmethod\n  def from_proto(\n      cls, proto: AutomatedStoppingConfigProto) -> 'AutomatedStoppingConfig':\n    return cls(proto=proto)\n\n  def to_proto(self) -> AutomatedStoppingConfigProto:\n    \"\"\"Returns this object as a proto.\"\"\"\n    return copy.deepcopy(self._proto)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "automated_stopping.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 46, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.1986754966887417}, {"context": "  _parent_values: MonotypeParameterSequence = attr.field(\n      default=tuple(), converter=tuple, kw_only=True)\n\n  @property\n  def parameter_names(self) -> AbstractSet[str]:\n    return self._parameter_configs.keys()\n\n  def get(self, name: str) -> ParameterConfig:\n    if name not in self._parameter_configs:\n      raise KeyError(f'{name} is not in the search space.')\n    return self._parameter_configs[name]\n\n  def pop(self, name: str) -> ParameterConfig:\n    return self._parameter_configs.pop(name)\n\n  def add(self,\n          parameter_config: ParameterConfig,\n         \n          *,\n          replace: bool = False) -> ParameterConfig:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 1130, "start_line_no": 1120, "end_line_no": 1140, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.18238993710691823}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/brier_score/brier_score.py\n# --------------------------------------------------\n#  pages={2825--2830},\n#  year={2011}\n# }\n# \"\"\"\n# \n# _DESCRIPTION = \"\"\"\\\n# Brier score is a type of evaluation metric for classification tasks, where you predict outcomes such as win/lose, spam/ham, click/no-click etc.\n# `BrierScore = 1/N * sum( (p_i - o_i)^2 )`\n# \"\"\"\n# \n# \n# _KWARGS_DESCRIPTION = \"\"\"\n# Args:\n#     y_true : array of shape (n_samples,)\n#         True targets.\n# \n#     y_prob : array of shape (n_samples,)\n#         Probabilities of the positive class.\n# \n#     sample_weight : array-like of shape (n_samples,), default=None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/matthews_correlation/matthews_correlation.py\n# --------------------------------------------------\n#          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n#          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n#   journal={Journal of Machine Learning Research},\n#   volume={12},\n#   pages={2825--2830},\n#   year={2011}\n# }\n# \"\"\"\n# \n# \n# @evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n# class MatthewsCorrelation(evaluate.Metric):\n#     def _info(self):\n#         return evaluate.MetricInfo(\n#             description=_DESCRIPTION,\n#             citation=_CITATION,\n#             inputs_description=_KWARGS_DESCRIPTION,\n#             features=datasets.Features(\n#                 {\n#                     \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/f1/f1.py\n# --------------------------------------------------\n# }\n# \"\"\"\n# \n# \n# @evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n# class F1(evaluate.Metric):\n#     def _info(self):\n#         return evaluate.MetricInfo(\n#             description=_DESCRIPTION,\n#             citation=_CITATION,\n#             inputs_description=_KWARGS_DESCRIPTION,\n#             features=datasets.Features(\n#                 {\n#                     \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n#                     \"references\": datasets.Sequence(datasets.Value(\"int32\")),\n#                 }\n#                 if self.config_name == \"multilabel\"\n#                 else {\n#                     \"predictions\": datasets.Value(\"int32\"),\n#                     \"references\": datasets.Value(\"int32\"),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/precision/precision.py\n# --------------------------------------------------\n# }\n# \"\"\"\n# \n# \n# @evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n# class Precision(evaluate.Metric):\n#     def _info(self):\n#         return evaluate.MetricInfo(\n#             description=_DESCRIPTION,\n#             citation=_CITATION,\n#             inputs_description=_KWARGS_DESCRIPTION,\n#             features=datasets.Features(\n#                 {\n#                     \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n#                     \"references\": datasets.Sequence(datasets.Value(\"int32\")),\n#                 }\n#                 if self.config_name == \"multilabel\"\n#                 else {\n#                     \"predictions\": datasets.Value(\"int32\"),\n#                     \"references\": datasets.Value(\"int32\"),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/accuracy/accuracy.py\n# --------------------------------------------------\n#          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n#   journal={Journal of Machine Learning Research},\n#   volume={12},\n#   pages={2825--2830},\n#   year={2011}\n# }\n# \"\"\"\n# \n# \n# @evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n# class Accuracy(evaluate.Metric):\n#     def _info(self):\n#         return evaluate.MetricInfo(\n#             description=_DESCRIPTION,\n#             citation=_CITATION,\n#             inputs_description=_KWARGS_DESCRIPTION,\n#             features=datasets.Features(\n#                 {\n#                     \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n#                     \"references\": datasets.Sequence(datasets.Value(\"int32\")),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/mse/mse.py\n# --------------------------------------------------\n#  pages={2825--2830},\n#  year={2011}\n# }\n# \"\"\"\n# \n# _DESCRIPTION = \"\"\"\\\n# Mean Squared Error(MSE) is the average of the square of difference between the predicted\n# and actual values.\n# \"\"\"\n# \n# \n# _KWARGS_DESCRIPTION = \"\"\"\n# Args:\n#     predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)\n#         Estimated target values.\n#     references: array-like of shape (n_samples,) or (n_samples, n_outputs)\n#         Ground truth (correct) target values.\n#     sample_weight: array-like of shape (n_samples,), default=None\n#         Sample weights.\n#     multioutput: {\"raw_values\", \"uniform_average\"} or array-like of shape (n_outputs,), default=\"uniform_average\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/mae/mae.py\n# --------------------------------------------------\n#  pages={2825--2830},\n#  year={2011}\n# }\n# \"\"\"\n# \n# _DESCRIPTION = \"\"\"\\\n# Mean Absolute Error (MAE) is the mean of the magnitude of difference between the predicted and actual\n# values.\n# \"\"\"\n# \n# \n# _KWARGS_DESCRIPTION = \"\"\"\n# Args:\n#     predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)\n#         Estimated target values.\n#     references: array-like of shape (n_samples,) or (n_samples, n_outputs)\n#         Ground truth (correct) target values.\n#     sample_weight: array-like of shape (n_samples,), default=None\n#         Sample weights.\n#     multioutput: {\"raw_values\", \"uniform_average\"} or array-like of shape (n_outputs,), default=\"uniform_average\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2022 The HuggingFace Datasets Authors and the current dataset script contributor.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"MAPE - Mean Absolute Percentage Error Metric\"\"\"\n\nimport datasets\nfrom sklearn.metrics import mean_absolute_percentage_error\n\nimport evaluate\n\n\n_CITATION = \"\"\"\\\n@article{scikit-learn,\n title={Scikit-learn: Machine Learning in {P}ython},\n author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n journal={Journal of Machine Learning Research},\n volume={12},\n pages={2825--2830},\n year={2011}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nMean Absolute Percentage Error (MAPE) is the mean percentage error difference between the predicted and actual\nvalues.\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nArgs:", "choices": [{"text": "predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)"}], "metadata": {"task_id": "huggingface_evaluate/10", "ground_truth": "    predictions: array-like of shape (n_samples,) or (n_samples, n_outputs)", "fpath_tuple": ["huggingface_evaluate", "metrics", "mape", "mape.py"], "context_start_lineno": 0, "line_no": 43, "query_window": {"context": " title={Scikit-learn: Machine Learning in {P}ython},\n author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n journal={Journal of Machine Learning Research},\n volume={12},\n pages={2825--2830},\n year={2011}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nMean Absolute Percentage Error (MAPE) is the mean percentage error difference between the predicted and actual\nvalues.\n\"\"\"\n\n\n_KWARGS_DESCRIPTION = \"\"\"\nArgs:", "metadata": {"fpath_tuple": ["huggingface_evaluate", "metrics", "mape", "mape.py"], "line_no": 43, "task_id": "huggingface_evaluate/10", "start_line_no": 23, "end_line_no": 43, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "\n_CITATION = \"\"\"\\\n@article{scikit-learn,\n title={Scikit-learn: Machine Learning in {P}ython},\n author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n journal={Journal of Machine Learning Research},\n volume={12},\n pages={2825--2830},\n year={2011}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nMean Absolute Error (MAE) is the mean of the magnitude of difference between the predicted and actual\nvalues.\n\"\"\"\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "mae", "mae.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.8604651162790697}, {"context": "\n_CITATION = \"\"\"\\\n@article{scikit-learn,\n title={Scikit-learn: Machine Learning in {P}ython},\n author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n journal={Journal of Machine Learning Research},\n volume={12},\n pages={2825--2830},\n year={2011}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nMean Squared Error(MSE) is the average of the square of difference between the predicted\nand actual values.\n\"\"\"\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "mse", "mse.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.7794117647058824}, {"context": "        {'accuracy': 0.8778625954198473}\n\"\"\"\n\n\n_CITATION = \"\"\"\n@article{scikit-learn,\n  title={Scikit-learn: Machine Learning in {P}ython},\n  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n  journal={Journal of Machine Learning Research},\n  volume={12},\n  pages={2825--2830},\n  year={2011}\n}\n\"\"\"\n\n\n@evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "accuracy", "accuracy.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.6756756756756757}, {"context": "@article{scikit-learn,\n    title={Scikit-learn: Machine Learning in {P}ython},\n    author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n    and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n    and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n    Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n    journal={Journal of Machine Learning Research},\n    volume={12},\n    pages={2825--2830},\n    year={2011}\n}\n\"\"\"\n\n\n@evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\nclass Precision(evaluate.Metric):\n    def _info(self):\n        return evaluate.MetricInfo(\n            description=_DESCRIPTION,\n            citation=_CITATION,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "precision", "precision.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.6298701298701299}, {"context": "@article{scikit-learn,\n    title={Scikit-learn: Machine Learning in {P}ython},\n    author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n           and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n           and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n           Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n    journal={Journal of Machine Learning Research},\n    volume={12},\n    pages={2825--2830},\n    year={2011}\n}\n\"\"\"\n\n\n@evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\nclass F1(evaluate.Metric):\n    def _info(self):\n        return evaluate.MetricInfo(\n            description=_DESCRIPTION,\n            citation=_CITATION,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "f1", "f1.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.6258064516129033}, {"context": "        ...                                     average='macro')\n        >>> print(round(results['matthews_correlation'], 2))\n        0.25\n\"\"\"\n\n_CITATION = \"\"\"\\\n@article{scikit-learn,\n  title={Scikit-learn: Machine Learning in {P}ython},\n  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n  journal={Journal of Machine Learning Research},\n  volume={12},\n  pages={2825--2830},\n  year={2011}\n}\n\"\"\"\n\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "matthews_correlation", "matthews_correlation.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.6209150326797386}, {"context": "\n_CITATION = \"\"\"\\\n@article{scikit-learn,\n title={Scikit-learn: Machine Learning in {P}ython},\n author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n journal={Journal of Machine Learning Research},\n volume={12},\n pages={2825--2830},\n year={2011}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nBrier score is a type of evaluation metric for classification tasks, where you predict outcomes such as win/lose, spam/ham, click/no-click etc.\n`BrierScore = 1/N * sum( (p_i - o_i)^2 )`\n\"\"\"\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "brier_score", "brier_score.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.592814371257485}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/predictive/base.py\n# --------------------------------------------------\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             An estimate of the predictive mean for each input.\n#         \"\"\"\n#         if rng is None:\n#             rng = self.rng.get()\n# \n#         return self._loop_fun_through_inputs_loader(\n#             self._batched_mean, inputs_loader, n_posterior_samples, rng, distribute\n#         )\n# \n#     def _batched_mean(\n#         self,\n#         inputs: Array,\n#         n_posterior_samples: int = 30,\n#         rng: Optional[PRNGKeyArray] = None,\n#     ) -> jnp.ndarray:\n#         if rng is None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/likelihood/base.py\n# --------------------------------------------------\n#         Compute the outputs and their calibrated version.\n# \n#         Parameters\n#         ----------\n#         params : Params\n#             The random parameters of the probabilistic model.\n#         inputs_loader : InputsLoader\n#             A loader of input data points.\n#         mutable : Optional[Mutable]\n#             The mutable objects used to evaluate the models.\n#         distribute: bool\n#             Whether to distribute computation over multiple devices, if available.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The calibrated outputs.\n#         \"\"\"\n#         if distribute and jax.local_device_count() <= 1:\n#             distribute = False\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/output_calibrator/output_calib_manager/state.py\n# --------------------------------------------------\n#             The random parameters of the probabilistic model.\n#         mutable : Optional[Mutable]\n#             The mutable objects used to evaluate the models.\n#         \"\"\"\n#         self.params = params\n#         self.mutable = mutable\n# \n#     @classmethod\n#     def init_from_dict(cls, d: Union[Dict, FrozenDict]) -> OutputCalibManagerState:\n#         \"\"\"\n#         Initialize an output calibration manager state from a dictionary.\n# \n#         Parameters\n#         ----------\n#         d : Union[Dict, FrozenDict]\n#             A dictionary with as keys the calibrators and as values their initializations.\n# \n#         Returns\n#         -------\n#         OutputCalibManagerState\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/classification.py\n# --------------------------------------------------\n#     ) -> Status:\n#         \"\"\"\n#         Calibrate the probabilistic classifier.\n# \n#         Parameters\n#         ----------\n#         calib_data_loader : DataLoader\n#             A calibration data loader.\n#         val_data_loader : DataLoader\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/predictive/classification.py\n# --------------------------------------------------\n#              A posterior distribution object.\n#         \"\"\"\n#         super().__init__(posterior)\n# \n#     def mean(\n#         self,\n#         inputs_loader: InputsLoader,\n#         n_posterior_samples: int = 30,\n#         rng: Optional[PRNGKeyArray] = None,\n#         distribute: bool = True,\n#     ) -> jnp.ndarray:\n#         r\"\"\"\n#         Estimate the predictive mean of the one-hot encoded target variable, that is\n# \n#         .. math::\n#             \\mathbb{E}_{\\tilde{Y}|x, \\mathcal{D}}[\\tilde{Y}],\n# \n#         where:\n#          - :math:`x` is an observed input variable;\n#          - :math:`\\tilde{Y}` is a one-hot encoded random target variable;\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/model_manager/state.py\n# fortuna/prob_model/state.py\n# --------------------------------------------------\n#             The random parameters of the probabilistic model.\n#         mutable : Optional[Mutable]\n#             The mutable objects used to evaluate the models.\n#         \"\"\"\n#         self.params = params\n#         self.mutable = mutable\n# \n#     @classmethod\n#     def init_from_dict(cls, d: Union[Dict, FrozenDict]) -> ModelManagerState:\n#         \"\"\"\n#         Initialize the model manager state from a dictionary. This dictionary should be like the output of\n#         :func:`~fortuna.model.model_manager.base.ModelManager.init`.\n# \n#         Parameters\n#         ----------\n#         d : Union[Dict, FrozenDict]\n#             A dictionary like the output of :func:`~fortuna.model.model_manager.base.ModelManager.init`.\n# \n#         Returns\n#         -------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/swag/swag_posterior.py\n# --------------------------------------------------\n#         ----------\n#         rng : Optional[PRNGKeyArray]\n#             A random number generator. If not passed, this will be taken from the attributes of this class.\n#         inputs_loader: Optional[InputsLoader]\n#             Input data loader. This or `inputs` is required if the posterior state includes mutable objects.\n#         inputs: Optional[Array]\n#             Input variables. This or `inputs_loader` is required if the posterior state includes mutable objects.\n# \n#         Returns\n#         -------\n#         JointState\n#             A sample from the posterior distribution.\n#         \"\"\"\n#         if rng is None:\n#             rng = self.rng.get()\n#         state = self.state.get()\n#         if state.mutable is not None and inputs_loader is None and inputs is None:\n#             raise ValueError(\n#                 \"The posterior state contains mutable objects. Please pass `inputs_loader` or `inputs`.\"\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/regression.py\n# --------------------------------------------------\n#         Parameters\n#         ----------\n#         calib_data_loader : DataLoader\n#             A calibration data loader.\n#         val_data_loader : DataLoader\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n#             self._check_output_dim(val_data_loader)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Callable, Iterable, Optional, Union\n\nimport jax\nimport numpy as np\nfrom flax import jax_utils\nfrom jax.tree_util import tree_map\n\nfrom fortuna.typing import Array, Batch\n\n\nclass DataLoader:\n    def __init__(\n        self,\n        data_loader: Union[\n            FromIterableToDataLoader,\n            FromCallableIterableToDataLoader,\n            FromArrayDataToDataLoader,\n            FromTensorFlowDataLoaderToDataLoader,\n            FromTorchDataLoaderToDataLoader,\n            ChoppedDataLoader\n        ],\n    ):\n        \"\"\"\n        A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n        are arrays, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n        FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n            A data loader.\n        \"\"\"\n        self._data_loader = data_loader\n\n    def __iter__(self):\n        yield from self._data_loader()\n\n    @classmethod\n    def from_array_data(\n        cls,\n        data: Batch,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ) -> DataLoader:\n        \"\"\"\n        Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n        respectively.\n\n        Parameters\n        ----------\n        data: Batch\n            Input and target arrays of data.\n        batch_size: Optional[int]\n            The batch size. If not given, the data will not be batched.\n        shuffle: bool\n            Whether the data loader should shuffle at every call.\n        prefetch: bool\n            Whether to prefetch the next batch.\n\n        Returns\n        -------\n        DataLoader\n            A data loader built out of the tuple of arrays.\n        \"\"\"\n        return cls(\n            data_loader=FromArrayDataToDataLoader(\n                data, batch_size=batch_size, shuffle=shuffle, prefetch=prefetch\n            )\n        )\n\n    @classmethod\n    def from_callable_iterable(cls, fun: Callable[[], Iterable[Batch],],) -> DataLoader:\n        \"\"\"\n        Transform a callable iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        fun: Callable[[], Iterable[Batch]]\n            A callable iterable of tuples of input and target arrays.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromCallableIterableToDataLoader(fun))\n\n    @classmethod\n    def from_iterable(cls, iterable: Iterable[Batch],) -> DataLoader:\n        \"\"\"\n        Transform an iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        iterable: Iterable[Batch]\n            An iterable of tuples of input and target arrays.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromIterableToDataLoader(iterable))\n\n    @classmethod\n    def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n        \"\"\"\n        Transform a TensorFlow data loader into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        tf_data_loader\n            A TensorFlow data loader where each batch is a tuple of input and target Tensors.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(\n            data_loader=FromTensorFlowDataLoaderToDataLoader(\n                tf_data_loader=tf_data_loader\n            )\n        )\n\n    @classmethod\n    def from_torch_data_loader(cls, torch_data_loader) -> DataLoader:\n        \"\"\"\n        Transform a PyTorch data loader into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        torch_data_loader\n            A PyTorch data loader where each batch is a tuple of input and target Tensors.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(\n            data_loader=FromTorchDataLoaderToDataLoader(\n                torch_data_loader=torch_data_loader\n            )\n        )\n\n    def to_array_data(self) -> Batch:\n        \"\"\"\n        Reduce a data loader to a tuple of input and target arrays.\n\n        Returns\n        -------\n        Batch\n            Tuple of input and target arrays.\n        \"\"\"\n        inputs, targets = [], []\n        for batch_inputs, batch_targets in self._data_loader():\n            inputs.append(batch_inputs)\n            targets.append(batch_targets)\n        return np.concatenate(inputs, 0), np.concatenate(targets, 0)\n\n    def to_array_inputs(self) -> Array:\n        \"\"\"\n        Reduce a data loader to an array of target data.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        inputs = []\n        for batch_inputs, batch_targets in self._data_loader():\n            inputs.append(batch_inputs)\n        return np.concatenate(inputs, 0)\n\n    def to_array_targets(self) -> Array:\n        \"\"\"\n        Reduce a data loader to an array of target data.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        targets = []\n        for batch_inputs, batch_targets in self._data_loader():\n            targets.append(batch_targets)\n        return np.concatenate(targets, 0)\n\n    def to_inputs_loader(self) -> InputsLoader:\n        \"\"\"\n        Reduce a data loader to an inputs loader.\n\n        Returns\n        -------\n        InputsLoader\n            The inputs loader derived from the data loader.\n        \"\"\"\n        return InputsLoader.from_data_loader(DataLoader(data_loader=self._data_loader))\n\n    def to_targets_loader(self) -> TargetsLoader:\n        \"\"\"\n        Reduce a data loader to a targets loader.\n\n        Returns\n        -------\n        TargetsLoader\n            The targets loader derived from the data loader.\n        \"\"\"\n        return TargetsLoader.from_data_loader(DataLoader(data_loader=self._data_loader))\n\n    @classmethod\n    def chop(cls, data_loader: DataLoader, divisor: int) -> DataLoader:\n        \"\"\"\n        Chop the last part of each batch of the data loader, to make sure the number od data points per batch divides\n        `divisor`.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader\n        divisor : int\n            Number of data points that each batched must divide.\n\n        Returns\n        -------\n        DataLoader\n            A data loader with chopped batches.\n        \"\"\"\n        return cls(data_loader=ChoppedDataLoader(data_loader=data_loader, divisor=divisor))\n\n\nclass InputsLoader:\n    def __init__(\n        self,\n        inputs_loader: Union[\n            FromArrayInputsToInputsLoader,\n            FromDataLoaderToInputsLoader,\n            FromCallableIterableToInputsLoader,\n            FromIterableToInputsLoader,\n            ChoppedInputsLoader\n        ],\n    ):\n        \"\"\"\n        An inputs loader class. Each batch is an array of inputs, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        inputs_loader : Union[FromArrayInputsToInputsLoader, FromDataLoaderToInputsLoader]\n            An inputs loader.\n        \"\"\"\n        self._inputs_loader = inputs_loader\n\n    def __iter__(self):", "choices": [{"text": "yield from self._inputs_loader()"}], "metadata": {"task_id": "awslabs_fortuna/199", "ground_truth": "        yield from self._inputs_loader()", "fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "context_start_lineno": 0, "line_no": 257, "query_window": {"context": "        self,\n        inputs_loader: Union[\n            FromArrayInputsToInputsLoader,\n            FromDataLoaderToInputsLoader,\n            FromCallableIterableToInputsLoader,\n            FromIterableToInputsLoader,\n            ChoppedInputsLoader\n        ],\n    ):\n        \"\"\"\n        An inputs loader class. Each batch is an array of inputs, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        inputs_loader : Union[FromArrayInputsToInputsLoader, FromDataLoaderToInputsLoader]\n            An inputs loader.\n        \"\"\"\n        self._inputs_loader = inputs_loader\n\n    def __iter__(self):", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 257, "task_id": "awslabs_fortuna/199", "start_line_no": 237, "end_line_no": 257, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "\n    def calibrate(\n        self,\n        calib_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_config: CalibConfig = CalibConfig(),\n    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "regression.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3111111111111111}, {"context": "        self,\n        rng: Optional[PRNGKeyArray] = None,\n        inputs_loader: Optional[InputsLoader] = None,\n        inputs: Optional[Array] = None,\n        **kwargs,\n    ) -> JointState:\n        \"\"\"\n        Sample from the posterior distribution.\n\n        Parameters\n        ----------\n        rng : Optional[PRNGKeyArray]\n            A random number generator. If not passed, this will be taken from the attributes of this class.\n        inputs_loader: Optional[InputsLoader]\n            Input data loader. This or `inputs` is required if the posterior state includes mutable objects.\n        inputs: Optional[Array]\n            Input variables. This or `inputs_loader` is required if the posterior state includes mutable objects.\n\n        Returns\n        -------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "swag", "swag_posterior.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3018867924528302}, {"context": "    params: Params\n    mutable: Optional[Mutable] = None\n\n    def __init__(self, params: Params, mutable: Optional[Mutable] = None):\n        \"\"\"\n        An model manager state class.\n\n        Parameters\n        ----------\n        params : Params\n            The random parameters of the probabilistic model.\n        mutable : Optional[Mutable]\n            The mutable objects used to evaluate the models.\n        \"\"\"\n        self.params = params\n        self.mutable = mutable\n\n    @classmethod\n    def init_from_dict(cls, d: Union[Dict, FrozenDict]) -> ModelManagerState:\n        \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "model_manager", "state.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}, {"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "state.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.30097087378640774}, {"context": "\n\nclass ClassificationPredictive(Predictive):\n    def __init__(self, posterior: Posterior):\n        \"\"\"\n        Classification predictive distribution class.\n\n        Parameters\n        ----------\n        posterior : Posterior\n             A posterior distribution object.\n        \"\"\"\n        super().__init__(posterior)\n\n    def mean(\n        self,\n        inputs_loader: InputsLoader,\n        n_posterior_samples: int = 30,\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "classification.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.29896907216494845}, {"context": "            fit_config,\n            calib_config,\n            **fit_kwargs,\n        )\n\n    def calibrate(\n        self,\n        calib_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_config: CalibConfig = CalibConfig(),\n    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "classification.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2967032967032967}, {"context": "    params: CalibParams\n    mutable: Optional[CalibMutable] = None\n\n    def __init__(self, params: CalibParams, mutable: Optional[CalibMutable] = None):\n        \"\"\"\n        An model manager state class.\n\n        Parameters\n        ----------\n        params : Params\n            The random parameters of the probabilistic model.\n        mutable : Optional[Mutable]\n            The mutable objects used to evaluate the models.\n        \"\"\"\n        self.params = params\n        self.mutable = mutable\n\n    @classmethod\n    def init_from_dict(cls, d: Union[Dict, FrozenDict]) -> OutputCalibManagerState:\n        \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "output_calibrator", "output_calib_manager", "state.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2897196261682243}, {"context": "\n    def get_outputs(\n        self,\n        params: Params,\n        inputs_loader: InputsLoader,\n        mutable: Optional[Mutable] = None,\n        distribute: bool = True,\n        **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Compute the outputs and their calibrated version.\n\n        Parameters\n        ----------\n        params : Params\n            The random parameters of the probabilistic model.\n        inputs_loader : InputsLoader\n            A loader of input data points.\n        mutable : Optional[Mutable]\n            The mutable objects used to evaluate the models.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "base.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2830188679245283}, {"context": "        Parameters\n        ----------\n        inputs_loader : InputsLoader\n            A loader of input data points.\n        n_posterior_samples : int\n            Number of samples to draw from the posterior distribution for each input.\n        rng: Optional[PRNGKeyArray]\n            A random number generator. If not passed, this will be taken from the attributes of this class.\n        distribute: bool\n            Whether to distribute computation over multiple devices, if available.\n\n        Returns\n        -------\n        jnp.ndarray\n            An estimate of the predictive mean for each input.\n        \"\"\"\n        if rng is None:\n            rng = self.rng.get()\n\n        return self._loop_fun_through_inputs_loader(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "base.py"], "line_no": 480, "start_line_no": 470, "end_line_no": 490, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2786885245901639}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/ddpg/ddpg.py\n# --------------------------------------------------\n# from torchrl.trainers.helpers.envs import (\n#     correct_for_frame_skip,\n#     EnvConfig,\n#     initialize_observation_norm_transforms,\n#     parallel_env_constructor,\n#     retrieve_observation_norms_state_dict,\n#     transformed_env_constructor,\n# )\n# from torchrl.trainers.helpers.logger import LoggerConfig\n# from torchrl.trainers.helpers.losses import LossConfig, make_ddpg_loss\n# from torchrl.trainers.helpers.models import DDPGModelConfig, make_ddpg_actor\n# from torchrl.trainers.helpers.replay_buffer import make_replay_buffer, ReplayArgsConfig\n# from torchrl.trainers.helpers.trainers import make_trainer, TrainerConfig\n# \n# config_fields = [\n#     (config_field.name, config_field.type, config_field)\n#     for config_cls in (\n#         TrainerConfig,\n#         OffPolicyCollectorConfig,\n#         EnvConfig,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_ddpg.py\n# --------------------------------------------------\n# from torchrl.collectors import MultiaSyncDataCollector\n# from torchrl.data import CompositeSpec, TensorDictReplayBuffer\n# from torchrl.data.postprocs import MultiStep\n# from torchrl.data.replay_buffers.samplers import PrioritizedSampler, RandomSampler\n# from torchrl.data.replay_buffers.storages import LazyMemmapStorage\n# from torchrl.envs import (\n#     CatTensors,\n#     DoubleToFloat,\n#     EnvCreator,\n#     ObservationNorm,\n#     ParallelEnv,\n# )\n# from torchrl.envs.libs.dm_control import DMControlEnv\n# from torchrl.envs.libs.gym import GymEnv\n# from torchrl.envs.transforms import RewardScaling, TransformedEnv\n# from torchrl.envs.utils import set_exploration_mode, step_mdp\n# from torchrl.modules import (\n#     MLP,\n#     OrnsteinUhlenbeckProcessWrapper,\n#     ProbabilisticActor,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/td3/td3.py\n# --------------------------------------------------\n#     DoubleToFloat,\n#     EnvCreator,\n#     ObservationNorm,\n#     ParallelEnv,\n#     TransformedEnv,\n# )\n# from torchrl.envs.libs.gym import GymEnv\n# from torchrl.envs.transforms import RewardScaling\n# from torchrl.envs.utils import set_exploration_mode\n# from torchrl.modules import (\n#     AdditiveGaussianWrapper,\n#     MLP,\n#     ProbabilisticActor,\n#     SafeModule,\n#     ValueOperator,\n# )\n# from torchrl.modules.distributions import TanhDelta\n# \n# from torchrl.objectives import SoftUpdate\n# from torchrl.objectives.td3 import TD3Loss\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/__init__.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# from .trainers import (\n#     BatchSubSampler,\n#     ClearCudaCache,\n#     CountFramesLog,\n#     LogReward,\n#     mask_batch,\n#     OptimizerHook,\n#     Recorder,\n#     ReplayBufferTrainer,\n#     RewardNormalizer,\n#     SelectKeys,\n#     Trainer,\n#     UpdateWeights,\n# )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n#     TensorDictReplayBuffer,\n# )\n# from torchrl.envs.libs.gym import _has_gym\n# from torchrl.trainers import Recorder, Trainer\n# from torchrl.trainers.helpers import transformed_env_constructor\n# from torchrl.trainers.trainers import (\n#     _has_tqdm,\n#     _has_ts,\n#     BatchSubSampler,\n#     CountFramesLog,\n#     LogReward,\n#     mask_batch,\n#     OptimizerHook,\n#     ReplayBufferTrainer,\n#     RewardNormalizer,\n#     SelectKeys,\n#     UpdateWeights,\n# )\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/trainers.py\n# --------------------------------------------------\n# \n# from torchrl._utils import _CKPT_BACKEND, KeyDependentDefaultDict\n# from torchrl.collectors.collectors import _DataCollector\n# from torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\n# from torchrl.data.utils import DEVICE_TYPING\n# from torchrl.envs.common import EnvBase\n# from torchrl.envs.utils import set_exploration_mode\n# from torchrl.modules import SafeModule\n# from torchrl.objectives.common import LossModule\n# from torchrl.record.loggers import Logger\n# \n# try:\n#     from tqdm import tqdm\n# \n#     _has_tqdm = True\n# except ImportError:\n#     _has_tqdm = False\n# \n# try:\n#     from torchsnapshot import Snapshot, StateDict\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/trainers.py\n# --------------------------------------------------\n# \n# try:\n#     from tqdm import tqdm\n# \n#     _has_tqdm = True\n# except ImportError:\n#     _has_tqdm = False\n# \n# try:\n#     from torchsnapshot import Snapshot, StateDict\n# \n#     _has_ts = True\n# except ImportError:\n#     _has_ts = False\n# \n# REPLAY_BUFFER_CLASS = {\n#     \"prioritized\": TensorDictPrioritizedReplayBuffer,\n#     \"circular\": TensorDictReplayBuffer,\n# }\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n#     LogReward,\n#     mask_batch,\n#     OptimizerHook,\n#     ReplayBufferTrainer,\n#     RewardNormalizer,\n#     SelectKeys,\n#     UpdateWeights,\n# )\n# \n# \n# def _fun_checker(fun, checker):\n#     def new_fun(*args, **kwargs):\n#         checker[0] = True\n#         return fun(*args, **kwargs)\n# \n#     return new_fun, fun\n# \n# \n# class MockingOptim:\n#     param_groups = [{\"params\": []}]\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Union\nfrom warnings import warn\n\nimport torch\nfrom tensordict.nn import TensorDictModuleWrapper\nfrom torch import optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom torchrl.collectors.collectors import _DataCollector\nfrom torchrl.data import ReplayBuffer\nfrom torchrl.envs.common import EnvBase\nfrom torchrl.modules import reset_noise, SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.objectives.utils import TargetNetUpdater\nfrom torchrl.record.loggers import Logger\nfrom torchrl.trainers.trainers import (\n    BatchSubSampler,\n    ClearCudaCache,\n    CountFramesLog,\n    LogReward,\n    Recorder,\n    ReplayBufferTrainer,\n    RewardNormalizer,\n    SelectKeys,", "choices": [{"text": "UpdateWeights"}], "metadata": {"task_id": "pytorch_rl/157", "ground_truth": "    Trainer,", "fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "trainers.py"], "context_start_lineno": 0, "line_no": 30, "query_window": {"context": "from tensordict.nn import TensorDictModuleWrapper\nfrom torch import optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom torchrl.collectors.collectors import _DataCollector\nfrom torchrl.data import ReplayBuffer\nfrom torchrl.envs.common import EnvBase\nfrom torchrl.modules import reset_noise, SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.objectives.utils import TargetNetUpdater\nfrom torchrl.record.loggers import Logger\nfrom torchrl.trainers.trainers import (\n    BatchSubSampler,\n    ClearCudaCache,\n    CountFramesLog,\n    LogReward,\n    Recorder,\n    ReplayBufferTrainer,\n    RewardNormalizer,\n    SelectKeys,", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "trainers.py"], "line_no": 30, "task_id": "pytorch_rl/157", "start_line_no": 10, "end_line_no": 30, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    TensorDictReplayBuffer,\n)\nfrom torchrl.envs.libs.gym import _has_gym\nfrom torchrl.trainers import Recorder, Trainer\nfrom torchrl.trainers.helpers import transformed_env_constructor\nfrom torchrl.trainers.trainers import (\n    _has_tqdm,\n    _has_ts,\n    BatchSubSampler,\n    CountFramesLog,\n    LogReward,\n    mask_batch,\n    OptimizerHook,\n    ReplayBufferTrainer,\n    RewardNormalizer,\n    SelectKeys,\n    UpdateWeights,\n)\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3565217391304348}, {"context": "\nfrom torchrl._utils import _CKPT_BACKEND, KeyDependentDefaultDict\nfrom torchrl.collectors.collectors import _DataCollector\nfrom torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\nfrom torchrl.data.utils import DEVICE_TYPING\nfrom torchrl.envs.common import EnvBase\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.record.loggers import Logger\n\ntry:\n    from tqdm import tqdm\n\n    _has_tqdm = True\nexcept ImportError:\n    _has_tqdm = False\n\ntry:\n    from torchsnapshot import Snapshot, StateDict", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.31007751937984496}, {"context": "from collections import defaultdict, OrderedDict\nfrom copy import deepcopy\nfrom textwrap import indent\nfrom typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Type, Union\n\nimport numpy as np\nimport torch.nn\nfrom tensordict.tensordict import pad, TensorDictBase\nfrom tensordict.utils import expand_right\nfrom torch import nn, optim\n\nfrom torchrl._utils import _CKPT_BACKEND, KeyDependentDefaultDict\nfrom torchrl.collectors.collectors import _DataCollector\nfrom torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\nfrom torchrl.data.utils import DEVICE_TYPING\nfrom torchrl.envs.common import EnvBase\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.record.loggers import Logger", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3006993006993007}, {"context": "    _has_tb = True\nexcept ImportError:\n    _has_tb = False\n\nfrom tensordict import TensorDict\nfrom torchrl.data import (\n    LazyMemmapStorage,\n    LazyTensorStorage,\n    ListStorage,\n    TensorDictPrioritizedReplayBuffer,\n    TensorDictReplayBuffer,\n)\nfrom torchrl.envs.libs.gym import _has_gym\nfrom torchrl.trainers import Recorder, Trainer\nfrom torchrl.trainers.helpers import transformed_env_constructor\nfrom torchrl.trainers.trainers import (\n    _has_tqdm,\n    _has_ts,\n    BatchSubSampler,\n    CountFramesLog,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2764227642276423}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom .trainers import (\n    BatchSubSampler,\n    ClearCudaCache,\n    CountFramesLog,\n    LogReward,\n    mask_batch,\n    OptimizerHook,\n    Recorder,\n    ReplayBufferTrainer,\n    RewardNormalizer,\n    SelectKeys,\n    Trainer,\n    UpdateWeights,\n)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "__init__.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 19, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2734375}, {"context": "import torch.cuda\nimport tqdm\n\nfrom torch import nn, optim\nfrom torchrl.collectors import MultiSyncDataCollector\nfrom torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\n\nfrom torchrl.data.replay_buffers.storages import LazyMemmapStorage\nfrom torchrl.envs import (\n    Compose,\n    DoubleToFloat,\n    EnvCreator,\n    ObservationNorm,\n    ParallelEnv,\n    TransformedEnv,\n)\nfrom torchrl.envs.libs.gym import GymEnv\nfrom torchrl.envs.transforms import RewardScaling\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import (", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "td3", "td3.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.23357664233576642}, {"context": "from copy import deepcopy\nfrom typing import Optional\n\nimport numpy as np\nimport torch\nimport torch.cuda\nimport tqdm\nfrom matplotlib import pyplot as plt\nfrom tensordict.nn import TensorDictModule\nfrom torch import nn, optim\nfrom torchrl.collectors import MultiaSyncDataCollector\nfrom torchrl.data import CompositeSpec, TensorDictReplayBuffer\nfrom torchrl.data.postprocs import MultiStep\nfrom torchrl.data.replay_buffers.samplers import PrioritizedSampler, RandomSampler\nfrom torchrl.data.replay_buffers.storages import LazyMemmapStorage\nfrom torchrl.envs import (\n    CatTensors,\n    DoubleToFloat,\n    EnvCreator,\n    ObservationNorm,", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_ddpg.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2328767123287671}, {"context": "from torchrl.envs import EnvCreator, ParallelEnv\nfrom torchrl.envs.transforms import RewardScaling, TransformedEnv\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import OrnsteinUhlenbeckProcessWrapper\nfrom torchrl.record import VideoRecorder\nfrom torchrl.record.loggers import generate_exp_name, get_logger\nfrom torchrl.trainers.helpers.collectors import (\n    make_collector_offpolicy,\n    OffPolicyCollectorConfig,\n)\nfrom torchrl.trainers.helpers.envs import (\n    correct_for_frame_skip,\n    EnvConfig,\n    initialize_observation_norm_transforms,\n    parallel_env_constructor,\n    retrieve_observation_norms_state_dict,\n    transformed_env_constructor,\n)\nfrom torchrl.trainers.helpers.logger import LoggerConfig\nfrom torchrl.trainers.helpers.losses import LossConfig, make_ddpg_loss", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "ddpg", "ddpg.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2323943661971831}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/data_helper.py\n# --------------------------------------------------\n# \n# def to_ndarray(item: Any, dtype: np.dtype = None) -> np.ndarray:\n#     r\"\"\"\n#     Overview:\n#         Change `torch.Tensor`, sequence of scalars to ndarray, and keep other data types unchanged.\n#     Arguments:\n#         - item (:obj:`object`): the item to be changed\n#         - dtype (:obj:`type`): the type of wanted ndarray\n#     Returns:\n#         - item (:obj:`object`): the changed ndarray\n#     .. note:\n# \n#         Now supports item type: :obj:`torch.Tensor`,  :obj:`dict`, :obj:`list`, :obj:`tuple` and :obj:`None`\n#     \"\"\"\n# \n#     def transform(d):\n#         if dtype is None:\n#             return np.array(d)\n#         else:\n#             return np.array(d, dtype=dtype)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/network/rnn.py\n# --------------------------------------------------\n#         - masks (:obj:`torch.BoolTensor`): mask has the same device as lengths\n#     \"\"\"\n#     if len(lengths.shape) == 1:\n#         lengths = lengths.unsqueeze(dim=1)\n#     bz = lengths.numel()\n#     if max_len is None:\n#         max_len = lengths.max()\n#     else:\n#         max_len = min(max_len, lengths.max())\n#     return torch.arange(0, max_len).type_as(lengths).repeat(bz, 1).lt(lengths).to(lengths.device)\n# \n# \n# class LSTMForwardWrapper(object):\n#     r\"\"\"\n#     Overview:\n#         A class which provides methods to use before and after `forward`, in order to wrap the LSTM `forward` method.\n#     Interfaces:\n#         _before_forward, _after_forward\n#     \"\"\"\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/data_helper.py\n# --------------------------------------------------\n#                 new_data.append(to_tensor(t, dtype, ignore_keys, transform_scalar))\n#             return new_data\n#     elif isinstance(item, np.ndarray):\n#         if dtype is None:\n#             if item.dtype == np.float64:\n#                 return torch.FloatTensor(item)\n#             else:\n#                 return torch.from_numpy(item)\n#         else:\n#             return torch.from_numpy(item).to(dtype)\n#     elif isinstance(item, bool) or isinstance(item, str):\n#         return item\n#     elif np.isscalar(item):\n#         if transform_scalar:\n#             if dtype is None:\n#                 return torch.as_tensor(item)\n#             else:\n#                 return torch.as_tensor(item).to(dtype)\n#         else:\n#             return item\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/network/rnn.py\n# --------------------------------------------------\n#                 zeros = torch.zeros(\n#                     num_directions * self.num_layers, 1, self.hidden_size, dtype=inputs.dtype, device=inputs.device\n#                 )\n#                 state = []\n#                 for prev in prev_state:\n#                     if prev is None:\n#                         state.append([zeros, zeros])\n#                     else:\n#                         state.append(prev)\n#                 state = list(zip(*state))\n#                 prev_state = [torch.cat(t, dim=1) for t in state]\n#         else:\n#             raise TypeError(\"not support prev_state type: {}\".format(type(prev_state)))\n#         return prev_state\n# \n#     def forward(self, inputs, prev_state, list_next_state=True):\n#         r\"\"\"\n#         Overview:\n#             wrapped nn.GRU.forward\n#         Arguments:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/data_helper.py\n# --------------------------------------------------\n#         ignore_keys: list = [],\n#         transform_scalar: bool = True\n# ) -> torch.Tensor:\n#     r\"\"\"\n#     Overview:\n#         Change `numpy.ndarray`, sequence of scalars to torch.Tensor, and keep other data types unchanged.\n#     Arguments:\n#         - item (:obj:`Any`): the item to be changed\n#         - dtype (:obj:`type`): the type of wanted tensor\n#     Returns:\n#         - item (:obj:`torch.Tensor`): the change tensor\n#     .. note:\n# \n#         Now supports item type: :obj:`dict`, :obj:`list`, :obj:`tuple` and :obj:`None`\n#     \"\"\"\n# \n#     def transform(d):\n#         if dtype is None:\n#             return torch.as_tensor(d)\n#         else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/distribution.py\n# --------------------------------------------------\n#         elif reduction == 'mean':\n#             return entropy.mean()\n# \n#     def noise_mode(self, viz: bool = False) -> Tuple[torch.Tensor, Dict[str, np.ndarray]]:\n#         r\"\"\"\n#         Overview:\n#             add noise to logits\n#         Arguments:\n#             - viz (:obj:`bool`): Whether to return numpy from of logits, noise and noise_logits; \\\n#                 Short for \"visualize\". (Because tensor type cannot visualize in tb or text log)\n#         Returns:\n#             - result (:obj:`torch.Tensor`): noised logits\n#             - viz_feature (:obj:`Dict[str, np.ndarray]`): ndarray type data for visualization.\n#         \"\"\"\n#         u = torch.rand_like(self.logits)\n#         u = -torch.log(-torch.log(u))\n#         noise_logits = self.logits + u\n#         result = noise_logits.argmax(dim=-1)\n#         if viz:\n#             viz_feature = {}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/data_helper.py\n# --------------------------------------------------\n#             return item.numpy()\n#         else:\n#             return item.numpy().astype(dtype)\n#     elif isinstance(item, np.ndarray):\n#         if dtype is None:\n#             return item\n#         else:\n#             return item.astype(dtype)\n#     elif isinstance(item, bool) or isinstance(item, str):\n#         return item\n#     elif np.isscalar(item):\n#         return np.array(item)\n#     elif item is None:\n#         return None\n#     else:\n#         raise TypeError(\"not support item type: {}\".format(type(item)))\n# \n# \n# def to_list(item: Any) -> list:\n#     r\"\"\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom collections.abc import Sequence, Mapping\nfrom typing import List, Dict, Union, Any\n\nimport torch\nimport re\nfrom torch._six import string_classes\nimport collections.abc as container_abcs\n\nint_classes = int\nnp_str_obj_array_pattern = re.compile(r'[SaUO]')\n\ndefault_collate_err_msg_format = (\n    \"default_collate: batch must contain tensors, numpy arrays, numbers, \"\n    \"dicts or lists; found {}\"\n)\n\n\ndef default_collate(batch: Sequence, cat_1dim: bool = True) -> Union[torch.Tensor, Mapping, Sequence]:\n    \"\"\"\n    Overview:\n        Put each data field into a tensor with outer dimension batch size.\n    Example:\n        >>> # a list with B tensors shaped (m, n) -->> a tensor shaped (B, m, n)\n        >>> a = [torch.zeros(2,3) for _ in range(4)]\n        >>> default_collate(a).shape\n        torch.Size([4, 2, 3])\n        >>>\n        >>> # a list with B lists, each list contains m elements -->> a list of m tensors, each with shape (B, )\n        >>> a = [[0 for __ in range(3)] for _ in range(4)]\n        >>> default_collate(a)\n        [tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0])]\n        >>>\n        >>> # a list with B dicts, whose values are tensors shaped :math:`(m, n)` -->>\n        >>> # a dict whose values are tensors with shape :math:`(B, m, n)`\n        >>> a = [{i: torch.zeros(i,i+1) for i in range(2, 4)} for _ in range(4)]\n        >>> print(a[0][2].shape, a[0][3].shape)\n        torch.Size([2, 3]) torch.Size([3, 4])\n        >>> b = default_collate(a)\n        >>> print(b[2].shape, b[3].shape)\n        torch.Size([4, 2, 3]) torch.Size([4, 3, 4])\n    Arguments:\n        - batch (:obj:`Sequence`): a data sequence, whose length is batch size, whose element is one piece of data\n    Returns:\n        - ret (:obj:`Union[torch.Tensor, Mapping, Sequence]`): the collated data, with batch size into each data field.\\\n            the return dtype depends on the original element dtype, can be [torch.Tensor, Mapping, Sequence].\n    \"\"\"\n    elem = batch[0]\n    elem_type = type(elem)\n    if isinstance(elem, torch.Tensor):\n        out = None\n        if torch.utils.data.get_worker_info() is not None:\n            # If we're in a background process, directly concatenate into a\n            # shared memory tensor to avoid an extra copy\n            numel = sum([x.numel() for x in batch])\n            storage = elem.storage()._new_shared(numel)\n            out = elem.new(storage)\n        if elem.shape == (1, ) and cat_1dim:\n            # reshape (B, 1) -> (B)\n            return torch.cat(batch, 0, out=out)\n            # return torch.stack(batch, 0, out=out)\n        else:\n            return torch.stack(batch, 0, out=out)\n    elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n            and elem_type.__name__ != 'string_':\n        if elem_type.__name__ == 'ndarray':\n            # array of string classes and object\n            if np_str_obj_array_pattern.search(elem.dtype.str) is not None:\n                raise TypeError(default_collate_err_msg_format.format(elem.dtype))\n            return default_collate([torch.as_tensor(b) for b in batch], cat_1dim=cat_1dim)\n        elif elem.shape == ():  # scalars\n            return torch.as_tensor(batch)", "choices": [{"text": ""}], "metadata": {"task_id": "opendilab_ACE/56", "ground_truth": "    elif isinstance(elem, float):", "fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "collate_fn.py"], "context_start_lineno": 0, "line_no": 71, "query_window": {"context": "            # If we're in a background process, directly concatenate into a\n            # shared memory tensor to avoid an extra copy\n            numel = sum([x.numel() for x in batch])\n            storage = elem.storage()._new_shared(numel)\n            out = elem.new(storage)\n        if elem.shape == (1, ) and cat_1dim:\n            # reshape (B, 1) -> (B)\n            return torch.cat(batch, 0, out=out)\n            # return torch.stack(batch, 0, out=out)\n        else:\n            return torch.stack(batch, 0, out=out)\n    elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n            and elem_type.__name__ != 'string_':\n        if elem_type.__name__ == 'ndarray':\n            # array of string classes and object\n            if np_str_obj_array_pattern.search(elem.dtype.str) is not None:\n                raise TypeError(default_collate_err_msg_format.format(elem.dtype))\n            return default_collate([torch.as_tensor(b) for b in batch], cat_1dim=cat_1dim)\n        elif elem.shape == ():  # scalars\n            return torch.as_tensor(batch)", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "collate_fn.py"], "line_no": 71, "task_id": "opendilab_ACE/56", "start_line_no": 51, "end_line_no": 71, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "            return transform(item)\n        elif hasattr(item, '_fields'):  # namedtuple\n            return type(item)(*[to_ndarray(t, dtype) for t in item])\n        else:\n            new_data = []\n            for t in item:\n                new_data.append(to_ndarray(t, dtype))\n            return new_data\n    elif isinstance(item, torch.Tensor):\n        if dtype is None:\n            return item.numpy()\n        else:\n            return item.numpy().astype(dtype)\n    elif isinstance(item, np.ndarray):\n        if dtype is None:\n            return item\n        else:\n            return item.astype(dtype)\n    elif isinstance(item, bool) or isinstance(item, str):\n        return item", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "data_helper.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2564102564102564}, {"context": "            - entropy (:obj:`torch.Tensor`): the calculated entropy\n        \"\"\"\n        a = self.logits - self.logits.max(dim=-1, keepdim=True)[0]\n        ea = torch.exp(a)\n        z = ea.sum(dim=-1, keepdim=True)\n        p = ea / z\n        entropy = (p * (torch.log(z) - a)).sum(dim=-1)\n        assert (reduction in [None, 'mean'])\n        if reduction is None:\n            return entropy\n        elif reduction == 'mean':\n            return entropy.mean()\n\n    def noise_mode(self, viz: bool = False) -> Tuple[torch.Tensor, Dict[str, np.ndarray]]:\n        r\"\"\"\n        Overview:\n            add noise to logits\n        Arguments:\n            - viz (:obj:`bool`): Whether to return numpy from of logits, noise and noise_logits; \\\n                Short for \"visualize\". (Because tensor type cannot visualize in tb or text log)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "distribution.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.24630541871921183}, {"context": "        return [to_dtype(t, dtype) for t in item]\n    elif isinstance(item, dict):\n        return {k: to_dtype(item[k], dtype) for k in item.keys()}\n    else:\n        raise TypeError(\"not support item type: {}\".format(type(item)))\n\n\ndef to_tensor(\n        item: Any,\n        dtype: Optional[torch.dtype] = None,\n        ignore_keys: list = [],\n        transform_scalar: bool = True\n) -> torch.Tensor:\n    r\"\"\"\n    Overview:\n        Change `numpy.ndarray`, sequence of scalars to torch.Tensor, and keep other data types unchanged.\n    Arguments:\n        - item (:obj:`Any`): the item to be changed\n        - dtype (:obj:`type`): the type of wanted tensor\n    Returns:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "data_helper.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.24598930481283424}, {"context": "            prev_state = (zeros, zeros)\n        elif is_sequence(prev_state):\n            if len(prev_state) == 2 and isinstance(prev_state[0], torch.Tensor):\n                pass\n            else:\n                if len(prev_state) != batch_size:\n                    raise RuntimeError(\n                        \"prev_state number is not equal to batch_size: {}/{}\".format(len(prev_state), batch_size)\n                    )\n                num_directions = 1\n                zeros = torch.zeros(\n                    num_directions * self.num_layers, 1, self.hidden_size, dtype=inputs.dtype, device=inputs.device\n                )\n                state = []\n                for prev in prev_state:\n                    if prev is None:\n                        state.append([zeros, zeros])\n                    else:\n                        state.append(prev)\n                state = list(zip(*state))", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "network", "rnn.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.24293785310734464}, {"context": "    elif isinstance(item, list) or isinstance(item, tuple):\n        if len(item) == 0:\n            return None\n        elif isinstance(item[0], numbers.Integral) or isinstance(item[0], numbers.Real):\n            return transform(item)\n        elif hasattr(item, '_fields'):  # namedtuple\n            return type(item)(*[to_tensor(t, dtype) for t in item])\n        else:\n            new_data = []\n            for t in item:\n                new_data.append(to_tensor(t, dtype, ignore_keys, transform_scalar))\n            return new_data\n    elif isinstance(item, np.ndarray):\n        if dtype is None:\n            if item.dtype == np.float64:\n                return torch.FloatTensor(item)\n            else:\n                return torch.from_numpy(item)\n        else:\n            return torch.from_numpy(item).to(dtype)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "data_helper.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2411764705882353}, {"context": "\ndef sequence_mask(lengths: torch.Tensor, max_len: Optional[int] = None) -> torch.BoolTensor:\n    r\"\"\"\n    Overview:\n        create a mask for a batch sequences with different lengths\n    Arguments:\n        - lengths (:obj:`torch.Tensor`): lengths in each different sequences, shape could be (n, 1) or (n)\n        - max_len (:obj:`int`): the padding size, if max_len is None, the padding size is the \\\n            max length of sequences\n    Returns:\n        - masks (:obj:`torch.BoolTensor`): mask has the same device as lengths\n    \"\"\"\n    if len(lengths.shape) == 1:\n        lengths = lengths.unsqueeze(dim=1)\n    bz = lengths.numel()\n    if max_len is None:\n        max_len = lengths.max()\n    else:\n        max_len = min(max_len, lengths.max())\n    return torch.arange(0, max_len).type_as(lengths).repeat(bz, 1).lt(lengths).to(lengths.device)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "network", "rnn.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.23809523809523808}, {"context": "    elif item is None:\n        return None\n    elif isinstance(item, torch.Tensor):\n        if dtype is None:\n            return item\n        else:\n            return item.to(dtype)\n    else:\n        raise TypeError(\"not support item type: {}\".format(type(item)))\n\n\ndef to_ndarray(item: Any, dtype: np.dtype = None) -> np.ndarray:\n    r\"\"\"\n    Overview:\n        Change `torch.Tensor`, sequence of scalars to ndarray, and keep other data types unchanged.\n    Arguments:\n        - item (:obj:`object`): the item to be changed\n        - dtype (:obj:`type`): the type of wanted ndarray\n    Returns:\n        - item (:obj:`object`): the changed ndarray", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "data_helper.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.23668639053254437}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/cl/fedgc/client.py\n# --------------------------------------------------\n# import torch\n# import logging\n# import copy\n# import numpy as np\n# \n# from federatedscope.core.message import Message\n# from federatedscope.core.workers.client import Client\n# from federatedscope.core.auxiliaries.utils import merge_dict\n# \n# logger = logging.getLogger(__name__)\n# \n# \n# class GlobalContrastFLClient(Client):\n#     r\"\"\"\n#     GlobalContrastFL(Fedgc) Client receive aggregated model weight from\n#     server then update local weight; it also receive global loss from server\n#     to train model and update weight locally.\n#     \"\"\"\n#     def _register_default_handlers(self):\n#         self.register_handlers('assign_client_id',\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/gcflplus/worker.py\n# --------------------------------------------------\n#                  data=None,\n#                  model=None,\n#                  client_num=5,\n#                  total_round_num=10,\n#                  device='cpu',\n#                  strategy=None,\n#                  **kwargs):\n#         super(GCFLPlusServer,\n#               self).__init__(ID, state, config, data, model, client_num,\n#                              total_round_num, device, strategy, **kwargs)\n#         # Initial cluster\n#         self.cluster_indices = [\n#             np.arange(1, self._cfg.federate.client_num + 1).astype(\"int\")\n#         ]\n#         self.client_clusters = [[ID for ID in cluster_id]\n#                                 for cluster_id in self.cluster_indices]\n#         # Maintain a grad sequence\n#         self.seqs_grads = {\n#             idx: []\n#             for idx in range(1, self._cfg.federate.client_num + 1)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/fedsageplus/worker.py\n# --------------------------------------------------\n# \n# class FedSagePlusServer(Server):\n#     def __init__(self,\n#                  ID=-1,\n#                  state=0,\n#                  config=None,\n#                  data=None,\n#                  model=None,\n#                  client_num=5,\n#                  total_round_num=10,\n#                  device='cpu',\n#                  strategy=None,\n#                  **kwargs):\n#         r\"\"\"\n#         FedSage+ consists of three of training stages.\n#         Stage1: 0, local pre-train for generator.\n#         Stage2: -> 2 * fedgen_epoch, federated training for generator.\n#         Stage3: -> 2 * fedgen_epoch + total_round_num: federated training\n#         for GraphSAGE Classifier\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/worker/server.py\n# --------------------------------------------------\n#                  model=None,\n#                  client_num=5,\n#                  total_round_num=10,\n#                  device='cpu',\n#                  strategy=None,\n#                  unseen_clients_id=None,\n#                  **kwargs):\n# \n#         super().__init__(ID=ID,\n#                          state=state,\n#                          config=config,\n#                          data=data,\n#                          model=model,\n#                          client_num=client_num,\n#                          total_round_num=total_round_num,\n#                          device=device,\n#                          strategy=strategy,\n#                          unseen_clients_id=unseen_clients_id,\n#                          **kwargs)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/gcflplus/worker.py\n# --------------------------------------------------\n#     min_cut, norm\n# \n# logger = logging.getLogger(__name__)\n# \n# \n# class GCFLPlusServer(Server):\n#     def __init__(self,\n#                  ID=-1,\n#                  state=0,\n#                  config=None,\n#                  data=None,\n#                  model=None,\n#                  client_num=5,\n#                  total_round_num=10,\n#                  device='cpu',\n#                  strategy=None,\n#                  **kwargs):\n#         super(GCFLPlusServer,\n#               self).__init__(ID, state, config, data, model, client_num,\n#                              total_round_num, device, strategy, **kwargs)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/xgb_base/worker/XGBServer.py\n# --------------------------------------------------\n# class XGBServer(Server):\n#     def __init__(self,\n#                  ID=-1,\n#                  state=0,\n#                  config=None,\n#                  data=None,\n#                  model=None,\n#                  client_num=2,\n#                  total_round_num=10,\n#                  device='cpu',\n#                  strategy=None,\n#                  **kwargs):\n#         super(XGBServer,\n#               self).__init__(ID, state, config, data, model, client_num,\n#                              total_round_num, device, strategy, **kwargs)\n# \n#         self.batch_size = self._cfg.dataloader.batch_size\n#         self.feature_partition = np.diff(self._cfg.vertical.dims, prepend=0)\n#         self.total_num_of_feature = self._cfg.vertical.dims[-1]\n#         self._init_data_related_var()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/worker/server.py\n# --------------------------------------------------\n# \n# logger = logging.getLogger(__name__)\n# \n# \n# class ATCServer(Server):\n#     def __init__(self,\n#                  ID=-1,\n#                  state=0,\n#                  config=None,\n#                  data=None,\n#                  model=None,\n#                  client_num=5,\n#                  total_round_num=10,\n#                  device='cpu',\n#                  strategy=None,\n#                  unseen_clients_id=None,\n#                  **kwargs):\n# \n#         super().__init__(ID=ID,\n#                          state=state,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/xgb_base/worker/XGBClient.py\n# --------------------------------------------------\n#     def __init__(self,\n#                  ID=-1,\n#                  server_id=None,\n#                  state=0,\n#                  config=None,\n#                  data=None,\n#                  model=None,\n#                  device='cpu',\n#                  strategy=None,\n#                  *args,\n#                  **kwargs):\n# \n#         super(XGBClient,\n#               self).__init__(ID, server_id, state, config, data, model, device,\n#                              strategy, *args, **kwargs)\n# \n#         self.data = data\n#         self.own_label = ('y' in data['train'])\n#         self.msg_buffer = dict()\n#         self.client_num = self._cfg.federate.client_num\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport logging\nfrom federatedscope.core.message import Message\nfrom federatedscope.core.auxiliaries.utils import merge_dict_of_results\nfrom federatedscope.core.workers import Client\nfrom federatedscope.nlp.hetero_tasks.trainer.utils import ContrastiveMonitor\n\nlogger = logging.getLogger(__name__)\n\n\nclass ATCClient(Client):\n    def __init__(self,\n                 ID=-1,\n                 server_id=None,\n                 state=-1,\n                 config=None,\n                 data=None,\n                 model=None,\n                 device='cpu',\n                 strategy=None,", "choices": [{"text": "**kwargs):"}], "metadata": {"task_id": "alibaba_FederatedScope/187", "ground_truth": "                 *args,", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "worker", "client.py"], "context_start_lineno": 0, "line_no": 19, "query_window": {"context": "import logging\nfrom federatedscope.core.message import Message\nfrom federatedscope.core.auxiliaries.utils import merge_dict_of_results\nfrom federatedscope.core.workers import Client\nfrom federatedscope.nlp.hetero_tasks.trainer.utils import ContrastiveMonitor\n\nlogger = logging.getLogger(__name__)\n\n\nclass ATCClient(Client):\n    def __init__(self,\n                 ID=-1,\n                 server_id=None,\n                 state=-1,\n                 config=None,\n                 data=None,\n                 model=None,\n                 device='cpu',\n                 strategy=None,", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "worker", "client.py"], "line_no": 19, "task_id": "alibaba_FederatedScope/187", "start_line_no": 0, "end_line_no": 19, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "import numpy as np\nimport logging\n\nfrom federatedscope.core.workers import Client\nfrom federatedscope.core.message import Message\n\nlogger = logging.getLogger(__name__)\n\n\nclass XGBClient(Client):\n    def __init__(self,\n                 ID=-1,\n                 server_id=None,\n                 state=0,\n                 config=None,\n                 data=None,\n                 model=None,\n                 device='cpu',\n                 strategy=None,\n                 *args,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "XGBClient.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.6296296296296297}, {"context": "import os\nimport json\nimport logging\nimport copy\nimport torch\nimport numpy as np\nfrom federatedscope.core.message import Message\nfrom federatedscope.core.workers import Server\nfrom federatedscope.nlp.hetero_tasks.trainer.utils import ContrastiveMonitor\nfrom federatedscope.nlp.hetero_tasks.dataset.utils import load_synth_data\n\nlogger = logging.getLogger(__name__)\n\n\nclass ATCServer(Server):\n    def __init__(self,\n                 ID=-1,\n                 state=0,\n                 config=None,\n                 data=None,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "worker", "server.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.6111111111111112}, {"context": "import numpy as np\n\nfrom federatedscope.core.workers import Server\nfrom federatedscope.core.message import Message\n\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass XGBServer(Server):\n    def __init__(self,\n                 ID=-1,\n                 state=0,\n                 config=None,\n                 data=None,\n                 model=None,\n                 client_num=2,\n                 total_round_num=10,\n                 device='cpu',", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "XGBServer.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.5168539325842697}, {"context": "import torch\nimport logging\nimport copy\nimport numpy as np\n\nfrom federatedscope.core.message import Message\nfrom federatedscope.core.workers.server import Server\nfrom federatedscope.core.workers.client import Client\nfrom federatedscope.core.auxiliaries.utils import merge_dict_of_results\nfrom federatedscope.gfl.gcflplus.utils import compute_pairwise_distances, \\\n    min_cut, norm\n\nlogger = logging.getLogger(__name__)\n\n\nclass GCFLPlusServer(Server):\n    def __init__(self,\n                 ID=-1,\n                 state=0,\n                 config=None,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "gcflplus", "worker.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.494949494949495}, {"context": "\nlogger = logging.getLogger(__name__)\n\n\nclass ATCServer(Server):\n    def __init__(self,\n                 ID=-1,\n                 state=0,\n                 config=None,\n                 data=None,\n                 model=None,\n                 client_num=5,\n                 total_round_num=10,\n                 device='cpu',\n                 strategy=None,\n                 unseen_clients_id=None,\n                 **kwargs):\n\n        super().__init__(ID=ID,\n                         state=state,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "worker", "server.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.43478260869565216}, {"context": "from federatedscope.core.data import ClientData\n\nfrom federatedscope.gfl.trainer.nodetrainer import NodeMiniBatchTrainer\nfrom federatedscope.gfl.model.fedsageplus import LocalSage_Plus, FedSage_Plus\nfrom federatedscope.gfl.fedsageplus.utils import GraphMender, HideGraph\nfrom federatedscope.gfl.fedsageplus.trainer import LocalGenTrainer, \\\n    FedGenTrainer\n\nlogger = logging.getLogger(__name__)\n\n\nclass FedSagePlusServer(Server):\n    def __init__(self,\n                 ID=-1,\n                 state=0,\n                 config=None,\n                 data=None,\n                 model=None,\n                 client_num=5,\n                 total_round_num=10,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "fedsageplus", "worker.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.38181818181818183}, {"context": "    min_cut, norm\n\nlogger = logging.getLogger(__name__)\n\n\nclass GCFLPlusServer(Server):\n    def __init__(self,\n                 ID=-1,\n                 state=0,\n                 config=None,\n                 data=None,\n                 model=None,\n                 client_num=5,\n                 total_round_num=10,\n                 device='cpu',\n                 strategy=None,\n                 **kwargs):\n        super(GCFLPlusServer,\n              self).__init__(ID, state, config, data, model, client_num,\n                             total_round_num, device, strategy, **kwargs)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "gcflplus", "worker.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.38144329896907214}, {"context": "import torch\nimport logging\nimport copy\nimport numpy as np\n\nfrom federatedscope.core.message import Message\nfrom federatedscope.core.workers.client import Client\nfrom federatedscope.core.auxiliaries.utils import merge_dict\n\nlogger = logging.getLogger(__name__)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "cl", "fedgc", "client.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.379746835443038}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n#         n_target_samples: Optional[int]\n#             Number of target samples to draw when computing quantiles.\n#         rng: Optional[PRNGKeyArray]\n#             A random number generator.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated quantiles for each output.\n#         \"\"\"\n#         if calibrated:\n#             self._check_calibrated()\n#             state = self.state.get()\n#             outputs = self.output_calib_manager.apply(\n#                 params=state.params[\"output_calibrator\"],\n#                 outputs=outputs,\n#                 mutable=state.mutable[\"output_calibrator\"],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         \"\"\"\n#         Estimate the standard deviation of the one-hot encoded target variable given the output, with respect to the\n#         predictive distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         variances: Optional[jnp.ndarray]\n#             Variance for each output.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated standard deviation for each output.\n#         \"\"\"\n#         return super().std(outputs, variances, calibrated)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         jnp.ndarray\n#             The estimated variance for each output.\n#         \"\"\"\n#         return super().variance(outputs, calibrated, **kwargs)\n# \n#     def std(\n#         self,\n#         outputs: jnp.ndarray,\n#         variances: Optional[jnp.ndarray] = None,\n#         calibrated: bool = True,\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the standard deviation of the one-hot encoded target variable given the output, with respect to the\n#         predictive distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         variances: Optional[jnp.ndarray]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_output_layer/base.py\n# --------------------------------------------------\n#         Returns\n#         -------\n#         jnp.ndarray\n#             An evaluation of the log-pdf for each output.\n#         \"\"\"\n#         pass\n# \n#     @abc.abstractmethod\n#     def predict(self, outputs: Array, **kwargs) -> jnp.ndarray:\n#         \"\"\"\n#         Predict target variables starting from the calibrated outputs.\n# \n#         Parameters\n#         ----------\n#         outputs : Array\n#             Calibrated outputs.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         \"\"\"\n#         return super().mode(outputs, calibrated, **kwargs)\n# \n#     def variance(\n#         self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         \"\"\"\n#         return super().mean(outputs, calibrated, **kwargs)\n# \n#     def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mode for each output.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mode for each output.\n#         \"\"\"\n#         return super().mode(outputs, calibrated, **kwargs)\n# \n#     def variance(\n#         self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated variance for each output.\n#         \"\"\"\n#         return super().variance(outputs, calibrated, **kwargs)\n# \n#     def std(\n#         self,\n#         outputs: jnp.ndarray,\n#         variances: Optional[jnp.ndarray] = None,\n#         calibrated: bool = True,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mean for each output.\n#         \"\"\"\n#         return super().mean(outputs, calibrated, **kwargs)\n# \n#     def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport abc\nfrom typing import Any, List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG, abc.ABC):\n    def __init__(\n        self,\n        output_calib_manager: OutputCalibManager,\n        prob_output_layer: ProbOutputLayer,\n    ):\n        r\"\"\"\n        Abstract predictive distribution. It characterizes the distribution of the target variable given the\n        calibrated outputs. It can be see as :math:`p(y|\\omega)`, where :math:`y` is a target variable and\n        :math:`\\omega` a calibrated output.\n        \"\"\"\n        self.output_calib_manager = output_calib_manager\n        self.prob_output_layer = prob_output_layer\n        self.state = None\n\n    def log_prob(\n        self, outputs: Array, targets: Array, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Evaluate the log-probability density function (a.k.a. log-pdf) given the outputs and target data.\n\n        Parameters\n        ----------\n        outputs : Array\n            Calibrated outputs.\n        targets : Array\n            Target data points.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray", "choices": [{"text": "The estimated log-pdf for each output."}], "metadata": {"task_id": "awslabs_fortuna/96", "ground_truth": "            An evaluation of the log-pdf for each data point.", "fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "base.py"], "context_start_lineno": 0, "line_no": 47, "query_window": {"context": "\n    def log_prob(\n        self, outputs: Array, targets: Array, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Evaluate the log-probability density function (a.k.a. log-pdf) given the outputs and target data.\n\n        Parameters\n        ----------\n        outputs : Array\n            Calibrated outputs.\n        targets : Array\n            Target data points.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "base.py"], "line_no": 47, "task_id": "awslabs_fortuna/96", "start_line_no": 27, "end_line_no": 47, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            prob_output_layer=prob_output_layer,\n        )\n\n    def mean(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mean of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mean for each output.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6039603960396039}, {"context": "        \"\"\"\n        return super().mode(outputs, calibrated, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5918367346938775}, {"context": "        \"\"\"\n        return super().mean(outputs, calibrated, **kwargs)\n\n    def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mode for each output.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5533980582524272}, {"context": "        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mean for each output.\n        \"\"\"\n        return super().mean(outputs, calibrated, **kwargs)\n\n    def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5480769230769231}, {"context": "        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mode for each output.\n        \"\"\"\n        return super().mode(outputs, calibrated, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5436893203883495}, {"context": "        \"\"\"\n        Evaluate the log-probability density function (a.k.a. log-pdf) of target variables for each of the outputs.\n\n        Parameters\n        ----------\n        outputs : Array\n            Calibrated outputs.\n        targets : Array\n            Target data points.\n\n        Returns\n        -------\n        jnp.ndarray\n            An evaluation of the log-pdf for each output.\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def predict(self, outputs: Array, **kwargs) -> jnp.ndarray:\n        \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_output_layer", "base.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5376344086021505}, {"context": "        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated variance for each output.\n        \"\"\"\n        return super().variance(outputs, calibrated, **kwargs)\n\n    def std(\n        self,\n        outputs: jnp.ndarray,\n        variances: Optional[jnp.ndarray] = None,\n        calibrated: bool = True,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.53}, {"context": "    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the standard deviation of the one-hot encoded target variable given the output, with respect to the\n        predictive distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        variances: Optional[jnp.ndarray]\n            Variance for each output.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated standard deviation for each output.\n        \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.47619047619047616}, {"context": "    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the quantile of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        q: Union[float, Array, List]\n            Quantile(s) to estimate.\n        outputs : jnp.ndarray\n            Model outputs.\n        n_target_samples: Optional[int]\n            Number of target samples to draw when computing quantiles.\n        rng: Optional[PRNGKeyArray]\n            A random number generator.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4491525423728814}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/marine_parallel_collector.py\n# --------------------------------------------------\n#             self._update_policy_thread.start()\n# \n#     def _join_thread(self) -> None:\n#         if not self._eval_flag:\n#             self._update_policy_thread.join()\n#             del self._update_policy_thread\n# \n#     # override\n#     def close(self) -> None:\n#         if self._end_flag:\n#             return\n#         self._end_flag = True\n#         time.sleep(1)\n#         if hasattr(self, '_env_manager'):\n#             self._env_manager.close()\n#         self._join_thread()\n# \n#     # override\n#     def _policy_inference(self, obs: Dict[int, Any]) -> Dict[int, Any]:\n#         env_ids = list(obs.keys())\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/marine_parallel_collector.py\n# --------------------------------------------------\n# \n#     # override\n#     @policy.setter\n#     def policy(self, _policy: List[Policy]) -> None:\n#         self._policy = _policy\n#         self._n_episode = _policy[0].get_attribute('cfg').collect.get('n_episode', None)\n#         self._n_sample = _policy[0].get_attribute('cfg').collect.get('n_sample', None)\n#         assert any(\n#             [t is None for t in [self._n_sample, self._n_episode]]\n#         ), \"n_episode/n_sample in policy cfg can't be not None at the same time\"\n#         # TODO(nyz) the same definition of traj_len in serial and parallel\n#         if self._n_episode is not None:\n#             self._traj_len = INF\n#         elif self._n_sample is not None:\n#             self._traj_len = self._n_sample\n# \n#     @property\n#     def env_manager(self, _env_manager) -> None:\n#         self._env_manager = _env_manager\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/marine_parallel_collector.py\n# --------------------------------------------------\n#             self.policy = policy\n#             self._policy_is_active = [None for _ in range(2)]\n#             self._policy_iter = [None for _ in range(2)]\n#             self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n#             self._traj_buffer = {\n#                 env_id: [TrajBuffer(self._traj_buffer_length) for _ in range(len(policy))]\n#                 for env_id in range(self._env_num)\n#             }\n#         # self._first_update_policy = True\n# \n#         self._episode_result = [[] for k in range(self._env_num)]\n#         self._obs_pool = CachePool('obs', self._env_num)\n#         self._policy_output_pool = CachePool('policy_output', self._env_num)\n#         self._total_step = 0\n#         self._total_sample = 0\n#         self._total_episode = 0\n# \n#     @property\n#     def policy(self) -> List[Policy]:\n#         return self._policy\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/marine_parallel_collector.py\n# --------------------------------------------------\n#         self._episode_result = [[] for k in range(self._env_num)]\n#         self._obs_pool = CachePool('obs', self._env_num)\n#         self._policy_output_pool = CachePool('policy_output', self._env_num)\n#         self._total_step = 0\n#         self._total_sample = 0\n#         self._total_episode = 0\n# \n#     @property\n#     def policy(self) -> List[Policy]:\n#         return self._policy\n# \n#     # override\n#     @policy.setter\n#     def policy(self, _policy: List[Policy]) -> None:\n#         self._policy = _policy\n#         self._n_episode = _policy[0].get_attribute('cfg').collect.get('n_episode', None)\n#         self._n_sample = _policy[0].get_attribute('cfg').collect.get('n_sample', None)\n#         assert any(\n#             [t is None for t in [self._n_sample, self._n_episode]]\n#         ), \"n_episode/n_sample in policy cfg can't be not None at the same time\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/marine_parallel_collector.py\n# --------------------------------------------------\n#             assert len(self._cfg.policy) == 1\n#             policy = [create_policy(self._cfg.policy[0], enable_field=['eval']).eval_mode]\n#             self.policy = policy\n#             self._policy_is_active = [None]\n#             self._policy_iter = [None]\n#             self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n#             self._traj_buffer = {env_id: [TrajBuffer(self._traj_len)] for env_id in range(self._env_num)}\n#         else:\n#             assert len(self._cfg.policy) == 2\n#             policy = [create_policy(self._cfg.policy[i], enable_field=['collect']).collect_mode for i in range(2)]\n#             self.policy = policy\n#             self._policy_is_active = [None for _ in range(2)]\n#             self._policy_iter = [None for _ in range(2)]\n#             self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n#             self._traj_buffer = {\n#                 env_id: [TrajBuffer(self._traj_buffer_length) for _ in range(len(policy))]\n#                 for env_id in range(self._env_num)\n#             }\n#         # self._first_update_policy = True\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/marine_parallel_collector.py\n# --------------------------------------------------\n#         self._start_time = time.time()\n#         self._compressor = get_data_compressor(self._cfg.compressor)\n# \n#         # create env\n#         self._env_cfg = self._cfg.env\n#         env_manager = self._setup_env_manager(self._env_cfg)\n#         self.env_manager = env_manager\n# \n#         # create policy\n#         if self._eval_flag:\n#             assert len(self._cfg.policy) == 1\n#             policy = [create_policy(self._cfg.policy[0], enable_field=['eval']).eval_mode]\n#             self.policy = policy\n#             self._policy_is_active = [None]\n#             self._policy_iter = [None]\n#             self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n#             self._traj_buffer = {env_id: [TrajBuffer(self._traj_len)] for env_id in range(self._env_num)}\n#         else:\n#             assert len(self._cfg.policy) == 2\n#             policy = [create_policy(self._cfg.policy[i], enable_field=['collect']).collect_mode for i in range(2)]\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import Dict, Any, List\nimport time\nimport uuid\nfrom collections import namedtuple\nfrom threading import Thread\nfrom functools import partial\n\nimport numpy as np\nimport torch\nfrom easydict import EasyDict\n\nfrom ding.policy import create_policy, Policy\nfrom ding.envs import get_vec_env_setting, create_env_manager, BaseEnvManager\nfrom ding.utils import get_data_compressor, pretty_print, PARALLEL_COLLECTOR_REGISTRY\nfrom .base_parallel_collector import BaseParallelCollector\nfrom .base_serial_collector import CachePool, TrajBuffer\n\nINF = float(\"inf\")\n\n\n@PARALLEL_COLLECTOR_REGISTRY.register('zergling')\nclass ZerglingParallelCollector(BaseParallelCollector):\n    \"\"\"\n    Feature:\n      - one policy, many envs\n      - async envs(step + reset)\n      - batch network eval\n      - different episode length env\n      - periodic policy update\n      - metadata + stepdata\n    \"\"\"\n    config = dict(\n        print_freq=5,\n        compressor='lz4',\n        update_policy_second=3,\n        # The following keys is set by the commander\n        # env\n        # policy\n        # collect_setting\n        # eval_flag\n        # policy_update_path\n    )\n\n    # override\n    def __init__(self, cfg: dict) -> None:\n        super().__init__(cfg)\n        self._update_policy_thread = Thread(\n            target=self._update_policy_periodically, args=(), name='update_policy', daemon=True\n        )\n        self._start_time = time.time()\n        self._compressor = get_data_compressor(self._cfg.compressor)\n\n        # create env\n        self._env_cfg = self._cfg.env\n        env_manager = self._setup_env_manager(self._env_cfg)\n        self.env_manager = env_manager\n\n        # create policy\n        if self._eval_flag:\n            policy = create_policy(self._cfg.policy, enable_field=['eval']).eval_mode\n        else:\n            policy = create_policy(self._cfg.policy, enable_field=['collect']).collect_mode\n        self.policy = policy\n\n        self._episode_result = [[] for k in range(self._env_num)]\n        self._obs_pool = CachePool('obs', self._env_num)\n        self._policy_output_pool = CachePool('policy_output', self._env_num)", "choices": [{"text": "self._total_step = 0"}], "metadata": {"task_id": "opendilab_ACE/49", "ground_truth": "        self._traj_buffer = {env_id: TrajBuffer(self._traj_len) for env_id in range(self._env_num)}", "fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "zergling_parallel_collector.py"], "context_start_lineno": 0, "line_no": 67, "query_window": {"context": "            target=self._update_policy_periodically, args=(), name='update_policy', daemon=True\n        )\n        self._start_time = time.time()\n        self._compressor = get_data_compressor(self._cfg.compressor)\n\n        # create env\n        self._env_cfg = self._cfg.env\n        env_manager = self._setup_env_manager(self._env_cfg)\n        self.env_manager = env_manager\n\n        # create policy\n        if self._eval_flag:\n            policy = create_policy(self._cfg.policy, enable_field=['eval']).eval_mode\n        else:\n            policy = create_policy(self._cfg.policy, enable_field=['collect']).collect_mode\n        self.policy = policy\n\n        self._episode_result = [[] for k in range(self._env_num)]\n        self._obs_pool = CachePool('obs', self._env_num)\n        self._policy_output_pool = CachePool('policy_output', self._env_num)", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "zergling_parallel_collector.py"], "line_no": 67, "task_id": "opendilab_ACE/49", "start_line_no": 47, "end_line_no": 67, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "        # eval_flag\n        # policy_update_path\n    )\n\n    # override\n    def __init__(self, cfg: dict) -> None:\n        super().__init__(cfg)\n        self._update_policy_thread = Thread(\n            target=self._update_policy_periodically, args=(), name='update_policy', daemon=True\n        )\n        self._start_time = time.time()\n        self._compressor = get_data_compressor(self._cfg.compressor)\n\n        # create env\n        self._env_cfg = self._cfg.env\n        env_manager = self._setup_env_manager(self._env_cfg)\n        self.env_manager = env_manager\n\n        # create policy\n        if self._eval_flag:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "marine_parallel_collector.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5393258426966292}, {"context": "        self._start_time = time.time()\n        self._compressor = get_data_compressor(self._cfg.compressor)\n\n        # create env\n        self._env_cfg = self._cfg.env\n        env_manager = self._setup_env_manager(self._env_cfg)\n        self.env_manager = env_manager\n\n        # create policy\n        if self._eval_flag:\n            assert len(self._cfg.policy) == 1\n            policy = [create_policy(self._cfg.policy[0], enable_field=['eval']).eval_mode]\n            self.policy = policy\n            self._policy_is_active = [None]\n            self._policy_iter = [None]\n            self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n            self._traj_buffer = {env_id: [TrajBuffer(self._traj_len)] for env_id in range(self._env_num)}\n        else:\n            assert len(self._cfg.policy) == 2\n            policy = [create_policy(self._cfg.policy[i], enable_field=['collect']).collect_mode for i in range(2)]", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "marine_parallel_collector.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.47058823529411764}, {"context": "            self.policy = policy\n            self._policy_is_active = [None for _ in range(2)]\n            self._policy_iter = [None for _ in range(2)]\n            self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n            self._traj_buffer = {\n                env_id: [TrajBuffer(self._traj_buffer_length) for _ in range(len(policy))]\n                for env_id in range(self._env_num)\n            }\n        # self._first_update_policy = True\n\n        self._episode_result = [[] for k in range(self._env_num)]\n        self._obs_pool = CachePool('obs', self._env_num)\n        self._policy_output_pool = CachePool('policy_output', self._env_num)\n        self._total_step = 0\n        self._total_sample = 0\n        self._total_episode = 0\n\n    @property\n    def policy(self) -> List[Policy]:\n        return self._policy", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "marine_parallel_collector.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.34545454545454546}, {"context": "            assert len(self._cfg.policy) == 1\n            policy = [create_policy(self._cfg.policy[0], enable_field=['eval']).eval_mode]\n            self.policy = policy\n            self._policy_is_active = [None]\n            self._policy_iter = [None]\n            self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n            self._traj_buffer = {env_id: [TrajBuffer(self._traj_len)] for env_id in range(self._env_num)}\n        else:\n            assert len(self._cfg.policy) == 2\n            policy = [create_policy(self._cfg.policy[i], enable_field=['collect']).collect_mode for i in range(2)]\n            self.policy = policy\n            self._policy_is_active = [None for _ in range(2)]\n            self._policy_iter = [None for _ in range(2)]\n            self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n            self._traj_buffer = {\n                env_id: [TrajBuffer(self._traj_buffer_length) for _ in range(len(policy))]\n                for env_id in range(self._env_num)\n            }\n        # self._first_update_policy = True\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "marine_parallel_collector.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "        self._episode_result = [[] for k in range(self._env_num)]\n        self._obs_pool = CachePool('obs', self._env_num)\n        self._policy_output_pool = CachePool('policy_output', self._env_num)\n        self._total_step = 0\n        self._total_sample = 0\n        self._total_episode = 0\n\n    @property\n    def policy(self) -> List[Policy]:\n        return self._policy\n\n    # override\n    @policy.setter\n    def policy(self, _policy: List[Policy]) -> None:\n        self._policy = _policy\n        self._n_episode = _policy[0].get_attribute('cfg').collect.get('n_episode', None)\n        self._n_sample = _policy[0].get_attribute('cfg').collect.get('n_sample', None)\n        assert any(\n            [t is None for t in [self._n_sample, self._n_episode]]\n        ), \"n_episode/n_sample in policy cfg can't be not None at the same time\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "marine_parallel_collector.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3220338983050847}, {"context": "        if self._eval_flag:\n            env_cfg = evaluator_env_cfg\n        else:\n            env_cfg = collector_env_cfg\n        env_manager = create_env_manager(cfg.manager, [partial(env_fn, cfg=c) for c in env_cfg])\n        return env_manager\n\n    def _start_thread(self) -> None:\n        # evaluator doesn't need to update policy periodically, only updating policy when starts\n        if not self._eval_flag:\n            self._update_policy_thread.start()\n\n    def _join_thread(self) -> None:\n        if not self._eval_flag:\n            self._update_policy_thread.join()\n            del self._update_policy_thread\n\n    # override\n    def close(self) -> None:\n        if self._end_flag:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "marine_parallel_collector.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.29906542056074764}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#         ua += \"; \" + user_agent\n#     return ua\n# \n# \n# def get_authentication_headers_for_url(url: str, use_auth_token: Optional[Union[str, bool]] = None) -> dict:\n#     \"\"\"Handle the HF authentication\"\"\"\n#     headers = {}\n#     if url.startswith(config.HF_ENDPOINT):\n#         token = None\n#         if isinstance(use_auth_token, str):\n#             token = use_auth_token\n#         elif bool(use_auth_token):\n#             from huggingface_hub import hf_api\n# \n#             token = hf_api.HfFolder.get_token()\n#         if token:\n#             headers[\"authorization\"] = f\"Bearer {token}\"\n#     return headers\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#     parsed = urlparse(url_or_filename)\n#     return parsed.scheme in (\"http\", \"https\", \"s3\", \"gs\", \"hdfs\", \"ftp\")\n# \n# \n# def is_local_path(url_or_filename: str) -> bool:\n#     # On unix the scheme of a local path is empty (for both absolute and relative),\n#     # while on windows the scheme is the drive name (ex: \"c\") for absolute paths.\n#     # for details on the windows behavior, see https://bugs.python.org/issue42215\n#     return urlparse(url_or_filename).scheme == \"\" or os.path.ismount(urlparse(url_or_filename).scheme + \":/\")\n# \n# \n# def is_relative_path(url_or_filename: str) -> bool:\n#     return urlparse(url_or_filename).scheme == \"\" and not os.path.isabs(url_or_filename)\n# \n# \n# def relative_to_absolute_path(path: T) -> T:\n#     \"\"\"Convert relative path to absolute path.\"\"\"\n#     abs_path_str = os.path.abspath(os.path.expanduser(os.path.expandvars(str(path))))\n#     return Path(abs_path_str) if isinstance(path, Path) else abs_path_str\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n# \n#     if is_remote_url(url_or_filename):\n#         # URL, so get it from the cache (downloading if necessary)\n#         output_path = get_from_cache(\n#             url_or_filename,\n#             cache_dir=cache_dir,\n#             force_download=download_config.force_download,\n#             proxies=download_config.proxies,\n#             resume_download=download_config.resume_download,\n#             user_agent=download_config.user_agent,\n#             local_files_only=download_config.local_files_only,\n#             use_etag=download_config.use_etag,\n#             max_retries=download_config.max_retries,\n#             use_auth_token=download_config.use_auth_token,\n#             ignore_url_params=download_config.ignore_url_params,\n#             download_desc=download_config.download_desc,\n#         )\n#     elif os.path.exists(url_or_filename):\n#         # File, and it exists.\n#         output_path = url_or_filename\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#             token = use_auth_token\n#         elif bool(use_auth_token):\n#             from huggingface_hub import hf_api\n# \n#             token = hf_api.HfFolder.get_token()\n#         if token:\n#             headers[\"authorization\"] = f\"Bearer {token}\"\n#     return headers\n# \n# \n# class OfflineModeIsEnabled(ConnectionError):\n#     pass\n# \n# \n# def _raise_if_offline_mode_is_enabled(msg: Optional[str] = None):\n#     \"\"\"Raise an OfflineModeIsEnabled error (subclass of ConnectionError) if HF_EVALUATE_OFFLINE is True.\"\"\"\n#     if config.HF_EVALUATE_OFFLINE:\n#         raise OfflineModeIsEnabled(\n#             \"Offline mode is enabled.\" if msg is None else \"Offline mode is enabled. \" + str(msg)\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#     elif is_local_path(url_or_filename):\n#         # File, but it doesn't exist.\n#         raise FileNotFoundError(f\"Local file {url_or_filename} doesn't exist\")\n#     else:\n#         # Something unknown\n#         raise ValueError(f\"unable to parse {url_or_filename} as a URL or as a local path\")\n# \n#     if output_path is None:\n#         return output_path\n# \n#     if download_config.extract_compressed_file:\n#         output_path = ExtractManager(cache_dir=download_config.cache_dir).extract(\n#             output_path, force_extract=download_config.force_extract\n#         )\n# \n#     return output_path\n# \n# \n# def get_datasets_user_agent(user_agent: Optional[Union[str, dict]] = None) -> str:\n#     ua = f\"datasets/{__version__}; python/{config.PY_VERSION}\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#             local_files_only=download_config.local_files_only,\n#             use_etag=download_config.use_etag,\n#             max_retries=download_config.max_retries,\n#             use_auth_token=download_config.use_auth_token,\n#             ignore_url_params=download_config.ignore_url_params,\n#             download_desc=download_config.download_desc,\n#         )\n#     elif os.path.exists(url_or_filename):\n#         # File, and it exists.\n#         output_path = url_or_filename\n#     elif is_local_path(url_or_filename):\n#         # File, but it doesn't exist.\n#         raise FileNotFoundError(f\"Local file {url_or_filename} doesn't exist\")\n#     else:\n#         # Something unknown\n#         raise ValueError(f\"unable to parse {url_or_filename} as a URL or as a local path\")\n# \n#     if output_path is None:\n#         return output_path\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nretry/max_retries}]\")\n                time.sleep(sleep_time)\n                retry += 1\n\n\ndef _request_with_retry(\n    method: str,\n    url: str,\n    max_retries: int = 0,\n    base_wait_time: float = 0.5,\n    max_wait_time: float = 2,\n    timeout: float = 10.0,\n    **params,\n) -> requests.Response:\n    \"\"\"Wrapper around requests to retry in case it fails with a ConnectTimeout, with exponential backoff.\n\n    Note that if the environment variable HF_EVALUATE_OFFLINE is set to 1, then a OfflineModeIsEnabled error is raised.\n\n    Args:\n        method (str): HTTP method, such as 'GET' or 'HEAD'.\n        url (str): The URL of the resource to fetch.\n        max_retries (int): Maximum number of retries, defaults to 0 (no retries).\n        base_wait_time (float): Duration (in seconds) to wait before retrying the first time. Wait time between\n            retries then grows exponentially, capped by max_wait_time.\n        max_wait_time (float): Maximum amount of time between two retries, in seconds.\n        **params: Params to pass to :obj:`requests.request`.\n    \"\"\"\n    _raise_if_offline_mode_is_enabled(f\"Tried to reach {url}\")\n    tries, success = 0, False\n    while not success:\n        tries += 1\n        try:\n            response = requests.request(method=method.upper(), url=url, timeout=timeout, **params)\n            success = True\n        except (requests.exceptions.ConnectTimeout, requests.exceptions.ConnectionError) as err:\n            if tries > max_retries:\n                raise err\n            else:\n                logger.info(f\"{method} request to {url} timed out, retrying... [{tries/max_retries}]\")\n                sleep_time = min(max_wait_time, base_wait_time * 2 ** (tries - 1))  # Exponential backoff\n                time.sleep(sleep_time)\n    return response\n\n\ndef ftp_head(url, timeout=10.0):\n    _raise_if_offline_mode_is_enabled(f\"Tried to reach {url}\")\n    try:\n        with closing(urllib.request.urlopen(url, timeout=timeout)) as r:\n            r.read(1)\n    except Exception:\n        return False\n    return True\n\n\ndef ftp_get(url, temp_file, timeout=10.0):\n    _raise_if_offline_mode_is_enabled(f\"Tried to reach {url}\")\n    try:\n        logger.info(f\"Getting through FTP {url} into {temp_file.name}\")\n        with closing(urllib.request.urlopen(url, timeout=timeout)) as r:\n            shutil.copyfileobj(r, temp_file)\n    except urllib.error.URLError as e:\n        raise ConnectionError(e) from None\n\n\ndef http_get(\n    url, temp_file, proxies=None, resume_size=0, headers=None, cookies=None, timeout=100.0, max_retries=0, desc=None\n):\n    headers = copy.deepcopy(headers) or {}\n    headers[\"user-agent\"] = get_datasets_user_agent(user_agent=headers.get(\"user-agent\"))\n    if resume_size > 0:\n        headers[\"Range\"] = f\"bytes={resume_size:d}-\"\n    response = _request_with_retry(\n        method=\"GET\",\n        url=url,\n        stream=True,\n        proxies=proxies,\n        headers=headers,\n        cookies=cookies,\n        max_retries=max_retries,\n        timeout=timeout,\n    )\n    if response.status_code == 416:  # Range not satisfiable\n        return\n    content_length = response.headers.get(\"Content-Length\")\n    total = resume_size + int(content_length) if content_length is not None else None\n    with logging.tqdm(\n        unit=\"B\",\n        unit_scale=True,\n        total=total,\n        initial=resume_size,\n        desc=desc or \"Downloading\",\n        disable=not logging.is_progress_bar_enabled(),\n    ) as progress:\n        for chunk in response.iter_content(chunk_size=1024):\n            progress.update(len(chunk))\n            temp_file.write(chunk)\n\n\ndef http_head(\n    url, proxies=None, headers=None, cookies=None, allow_redirects=True, timeout=10.0, max_retries=0\n) -> requests.Response:\n    headers = copy.deepcopy(headers) or {}\n    headers[\"user-agent\"] = get_datasets_user_agent(user_agent=headers.get(\"user-agent\"))\n    response = _request_with_retry(\n        method=\"HEAD\",\n        url=url,\n        proxies=proxies,\n        headers=headers,\n        cookies=cookies,\n        allow_redirects=allow_redirects,\n        timeout=timeout,\n        max_retries=max_retries,\n    )\n    return response\n\n\ndef request_etag(url: str, use_auth_token: Optional[Union[str, bool]] = None) -> Optional[str]:\n    headers = get_authentication_headers_for_url(url, use_auth_token=use_auth_token)\n    response = http_head(url, headers=headers, max_retries=3)\n    response.raise_for_status()\n    etag = response.headers.get(\"ETag\") if response.ok else None\n    return etag\n\n\ndef get_from_cache(\n    url,\n    cache_dir=None,\n    force_download=False,\n    proxies=None,\n    etag_timeout=100,\n    resume_download=False,\n    user_agent=None,\n    local_files_only=False,\n    use_etag=True,\n    max_retries=0,\n    use_auth_token=None,\n    ignore_url_params=False,\n    download_desc=None,\n) -> str:\n    \"\"\"\n    Given a URL, look for the corresponding file in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n\n    Return:\n        Local path (string)\n\n    Raises:\n        FileNotFoundError: in case of non-recoverable file\n            (non-existent or no cache on disk)\n        ConnectionError: in case of unreachable url\n            and no cache on disk\n    \"\"\"\n    if cache_dir is None:\n        cache_dir = config.HF_EVALUATE_CACHE\n    if isinstance(cache_dir, Path):\n        cache_dir = str(cache_dir)\n\n    os.makedirs(cache_dir, exist_ok=True)\n\n    if ignore_url_params:\n        # strip all query parameters and #fragments from the URL\n        cached_url = urljoin(url, urlparse(url).path)\n    else:\n        cached_url = url  # additional parameters may be added to the given URL\n\n    connected = False\n    response = None\n    cookies = None\n    etag = None\n    head_error = None\n\n    # Try a first time to file the file on the local file system without eTag (None)\n    # if we don't ask for 'force_download' then we spare a request\n    filename = hash_url_to_filename(cached_url, etag=None)\n    cache_path = os.path.join(cache_dir, filename)\n\n    if os.path.exists(cache_path) and not force_download and not use_etag:\n        return cache_path\n\n    # Prepare headers for authentication\n    headers = get_authentication_headers_for_url(url, use_auth_token=use_auth_token)\n    if user_agent is not None:\n        headers[\"user-agent\"] = user_agent\n\n    # We don't have the file locally or we need an eTag\n    if not local_files_only:\n        if url.startswith(\"ftp://\"):", "choices": [{"text": "connected = ftp_head(url)"}], "metadata": {"task_id": "huggingface_evaluate/110", "ground_truth": "            connected = ftp_head(url)", "fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "context_start_lineno": 323, "line_no": 510, "query_window": {"context": "    cookies = None\n    etag = None\n    head_error = None\n\n    # Try a first time to file the file on the local file system without eTag (None)\n    # if we don't ask for 'force_download' then we spare a request\n    filename = hash_url_to_filename(cached_url, etag=None)\n    cache_path = os.path.join(cache_dir, filename)\n\n    if os.path.exists(cache_path) and not force_download and not use_etag:\n        return cache_path\n\n    # Prepare headers for authentication\n    headers = get_authentication_headers_for_url(url, use_auth_token=use_auth_token)\n    if user_agent is not None:\n        headers[\"user-agent\"] = user_agent\n\n    # We don't have the file locally or we need an eTag\n    if not local_files_only:\n        if url.startswith(\"ftp://\"):", "metadata": {"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 510, "task_id": "huggingface_evaluate/110", "start_line_no": 490, "end_line_no": 510, "window_size": 20, "context_start_lineno": 323, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "\n    if is_remote_url(url_or_filename):\n        # URL, so get it from the cache (downloading if necessary)\n        output_path = get_from_cache(\n            url_or_filename,\n            cache_dir=cache_dir,\n            force_download=download_config.force_download,\n            proxies=download_config.proxies,\n            resume_download=download_config.resume_download,\n            user_agent=download_config.user_agent,\n            local_files_only=download_config.local_files_only,\n            use_etag=download_config.use_etag,\n            max_retries=download_config.max_retries,\n            use_auth_token=download_config.use_auth_token,\n            ignore_url_params=download_config.ignore_url_params,\n            download_desc=download_config.download_desc,\n        )\n    elif os.path.exists(url_or_filename):\n        # File, and it exists.\n        output_path = url_or_filename", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3115942028985507}, {"context": "            local_files_only=download_config.local_files_only,\n            use_etag=download_config.use_etag,\n            max_retries=download_config.max_retries,\n            use_auth_token=download_config.use_auth_token,\n            ignore_url_params=download_config.ignore_url_params,\n            download_desc=download_config.download_desc,\n        )\n    elif os.path.exists(url_or_filename):\n        # File, and it exists.\n        output_path = url_or_filename\n    elif is_local_path(url_or_filename):\n        # File, but it doesn't exist.\n        raise FileNotFoundError(f\"Local file {url_or_filename} doesn't exist\")\n    else:\n        # Something unknown\n        raise ValueError(f\"unable to parse {url_or_filename} as a URL or as a local path\")\n\n    if output_path is None:\n        return output_path\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2808219178082192}, {"context": "        ua += \"; \" + user_agent\n    return ua\n\n\ndef get_authentication_headers_for_url(url: str, use_auth_token: Optional[Union[str, bool]] = None) -> dict:\n    \"\"\"Handle the HF authentication\"\"\"\n    headers = {}\n    if url.startswith(config.HF_ENDPOINT):\n        token = None\n        if isinstance(use_auth_token, str):\n            token = use_auth_token\n        elif bool(use_auth_token):\n            from huggingface_hub import hf_api\n\n            token = hf_api.HfFolder.get_token()\n        if token:\n            headers[\"authorization\"] = f\"Bearer {token}\"\n    return headers\n\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.24516129032258063}, {"context": "        requests.exceptions.ConnectionError: in case of internet connection issue\n    \"\"\"\n    if download_config is None:\n        download_config = DownloadConfig(**download_kwargs)\n\n    cache_dir = download_config.cache_dir or config.DOWNLOADED_EVALUATE_PATH\n    if isinstance(cache_dir, Path):\n        cache_dir = str(cache_dir)\n    if isinstance(url_or_filename, Path):\n        url_or_filename = str(url_or_filename)\n\n    if is_remote_url(url_or_filename):\n        # URL, so get it from the cache (downloading if necessary)\n        output_path = get_from_cache(\n            url_or_filename,\n            cache_dir=cache_dir,\n            force_download=download_config.force_download,\n            proxies=download_config.proxies,\n            resume_download=download_config.resume_download,\n            user_agent=download_config.user_agent,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.23026315789473684}, {"context": "        sys.path.append(hf_modules_cache)\n\n        os.makedirs(hf_modules_cache, exist_ok=True)\n        if not os.path.exists(os.path.join(hf_modules_cache, \"__init__.py\")):\n            with open(os.path.join(hf_modules_cache, \"__init__.py\"), \"w\"):\n                pass\n    return hf_modules_cache\n\n\ndef is_remote_url(url_or_filename: str) -> bool:\n    parsed = urlparse(url_or_filename)\n    return parsed.scheme in (\"http\", \"https\", \"s3\", \"gs\", \"hdfs\", \"ftp\")\n\n\ndef is_local_path(url_or_filename: str) -> bool:\n    # On unix the scheme of a local path is empty (for both absolute and relative),\n    # while on windows the scheme is the drive name (ex: \"c\") for absolute paths.\n    # for details on the windows behavior, see https://bugs.python.org/issue42215\n    return urlparse(url_or_filename).scheme == \"\" or os.path.ismount(urlparse(url_or_filename).scheme + \":/\")\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.22404371584699453}, {"context": "    ua += f\"; pyarrow/{config.PYARROW_VERSION}\"\n    if config.TORCH_AVAILABLE:\n        ua += f\"; torch/{config.TORCH_VERSION}\"\n    if config.TF_AVAILABLE:\n        ua += f\"; tensorflow/{config.TF_VERSION}\"\n    if config.JAX_AVAILABLE:\n        ua += f\"; jax/{config.JAX_VERSION}\"\n    if isinstance(user_agent, dict):\n        ua += f\"; {'; '.join(f'{k}/{v}' for k, v in user_agent.items())}\"\n    elif isinstance(user_agent, str):\n        ua += \"; \" + user_agent\n    return ua\n\n\ndef get_authentication_headers_for_url(url: str, use_auth_token: Optional[Union[str, bool]] = None) -> dict:\n    \"\"\"Handle the HF authentication\"\"\"\n    headers = {}\n    if url.startswith(config.HF_ENDPOINT):\n        token = None\n        if isinstance(use_auth_token, str):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.22285714285714286}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/config/config.py\n# --------------------------------------------------\n#             Init method. Create config including dict type config and text type config.\n#         Arguments:\n#             - cfg_dict (:obj:`Optional[dict]`): dict type config\n#             - cfg_text (:obj:`Optional[str]`): text type config\n#             - filename (:obj:`Optional[str]`): config file name\n#         \"\"\"\n#         if cfg_dict is None:\n#             cfg_dict = {}\n#         if not isinstance(cfg_dict, dict):\n#             raise TypeError(\"invalid type for cfg_dict: {}\".format(type(cfg_dict)))\n#         self._cfg_dict = cfg_dict\n#         if cfg_text:\n#             text = cfg_text\n#         elif filename:\n#             with open(filename, 'r') as f:\n#                 text = f.read()\n#         else:\n#             text = '.'\n#         self._text = text\n#         self._filename = filename\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env_manager/subprocess_env_manager.py\n# --------------------------------------------------\n#         for _, p in self._pipe_parents.items():\n#             p.send(['getattr', [key], {}])\n#         data = {i: p.recv() for i, p in self._pipe_parents.items()}\n#         self._check_data(data)\n#         ret = [data[i] for i in self._pipe_parents.keys()]\n#         return ret\n# \n#     # override\n#     def enable_save_replay(self, replay_path: Union[List[str], str]) -> None:\n#         \"\"\"\n#         Overview:\n#             Set each env's replay save path.\n#         Arguments:\n#             - replay_path (:obj:`Union[List[str], str]`): List of paths for each environment; \\\n#                 Or one path for all environments.\n#         \"\"\"\n#         if isinstance(replay_path, str):\n#             replay_path = [replay_path] * self.env_num\n#         self._env_replay_path = replay_path\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env_manager/subprocess_env_manager.py\n# --------------------------------------------------\n#         self._create_state()\n#         self.reset(reset_param)\n# \n#     def reset(self, reset_param: Optional[Dict] = None) -> None:\n#         \"\"\"\n#         Overview:\n#             Reset the environments their parameters.\n#         Arguments:\n#             - reset_param (:obj:`List`): Dict of reset parameters for each environment, key is the env_id, \\\n#                 value is the cooresponding reset parameters.\n#         \"\"\"\n#         self._check_closed()\n#         # clear previous info\n#         for env_id in self._waiting_env['step']:\n#             self._pipe_parents[env_id].recv()\n#         self._waiting_env['step'].clear()\n# \n#         if reset_param is None:\n#             reset_env_list = [env_id for env_id in range(self._env_num)]\n#         else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env_manager/subprocess_env_manager.py\n# --------------------------------------------------\n#             self._data = {k: ShmBufferContainer(dtype, v) for k, v in shape.items()}\n#         elif isinstance(shape, (tuple, list)):\n#             self._data = ShmBuffer(dtype, shape)\n#         else:\n#             raise RuntimeError(\"not support shape: {}\".format(shape))\n#         self._shape = shape\n# \n#     def fill(self, src_arr: Union[Dict[Any, np.ndarray], np.ndarray]) -> None:\n#         \"\"\"\n#         Overview:\n#             Fill the one or many shared memory buffer.\n#         Arguments:\n#             - src_arr (:obj:`Union[Dict[Any, np.ndarray], np.ndarray]`): array to fill the buffer.\n#         \"\"\"\n#         if isinstance(self._shape, dict):\n#             for k in self._shape.keys():\n#                 self._data[k].fill(src_arr[k])\n#         elif isinstance(self._shape, (tuple, list)):\n#             self._data.fill(src_arr)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env_manager/subprocess_env_manager.py\n# --------------------------------------------------\n#             Fill the one or many shared memory buffer.\n#         Arguments:\n#             - src_arr (:obj:`Union[Dict[Any, np.ndarray], np.ndarray]`): array to fill the buffer.\n#         \"\"\"\n#         if isinstance(self._shape, dict):\n#             for k in self._shape.keys():\n#                 self._data[k].fill(src_arr[k])\n#         elif isinstance(self._shape, (tuple, list)):\n#             self._data.fill(src_arr)\n# \n#     def get(self) -> Union[Dict[Any, np.ndarray], np.ndarray]:\n#         \"\"\"\n#         Overview:\n#             Get the one or many arrays stored in the buffer.\n#         Return:\n#             - data (:obj:`np.ndarray`): The array(s) stored in the buffer.\n#         \"\"\"\n#         if isinstance(self._shape, dict):\n#             return {k: self._data[k].get() for k in self._shape.keys()}\n#         elif isinstance(self._shape, (tuple, list)):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env_manager/subprocess_env_manager.py\n# --------------------------------------------------\n#     # override\n#     def close(self) -> None:\n#         \"\"\"\n#         Overview:\n#             CLose the env manager and release all related resources.\n#         \"\"\"\n#         if self._closed:\n#             return\n#         self._closed = True\n#         self._env_ref.close()\n#         for _, p in self._pipe_parents.items():\n#             p.send(['close', None, None])\n#         for _, p in self._pipe_parents.items():\n#             p.recv()\n#         for i in range(self._env_num):\n#             self._env_states[i] = EnvState.VOID\n#         # disable process join for avoiding hang\n#         # for p in self._subprocesses:\n#         #     p.join()\n#         for _, p in self._subprocesses.items():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env_manager/subprocess_env_manager.py\n# --------------------------------------------------\n#         Overview:\n#             Set each env's replay save path.\n#         Arguments:\n#             - replay_path (:obj:`Union[List[str], str]`): List of paths for each environment; \\\n#                 Or one path for all environments.\n#         \"\"\"\n#         if isinstance(replay_path, str):\n#             replay_path = [replay_path] * self.env_num\n#         self._env_replay_path = replay_path\n# \n#     # override\n#     def close(self) -> None:\n#         \"\"\"\n#         Overview:\n#             CLose the env manager and release all related resources.\n#         \"\"\"\n#         if self._closed:\n#             return\n#         self._closed = True\n#         self._env_ref.close()\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n reset_param is not None:\n            assert len(reset_param) == len(self._env_fn)\n        self._create_state()\n        self.reset(reset_param)\n\n    def _create_state(self) -> None:\n        self._env_episode_count = {i: 0 for i in range(self.env_num)}\n        self._ready_obs = {i: None for i in range(self.env_num)}\n        self._envs = [e() for e in self._env_fn]\n        # env_ref is used to acquire some common attributes of env, like obs_shape and act_shape\n        self._env_ref = self._envs[0]\n        assert len(self._envs) == self._env_num\n        self._reset_param = {i: {} for i in range(self.env_num)}\n        self._env_states = {i: EnvState.INIT for i in range(self.env_num)}\n        if self._env_replay_path is not None:\n            for e, s in zip(self._envs, self._env_replay_path):\n                e.enable_save_replay(s)\n        self._closed = False\n\n    def reset(self, reset_param: Optional[Dict] = None) -> None:\n        \"\"\"\n        Overview:\n            Reset the environments their parameters.\n        Arguments:\n            - reset_param (:obj:`List`): Dict of reset parameters for each environment, key is the env_id, \\\n                value is the cooresponding reset parameters.\n        \"\"\"\n        self._check_closed()\n        # set seed if necessary\n        env_ids = list(range(self._env_num)) if reset_param is None else list(reset_param.keys())\n        for i, env_id in enumerate(env_ids):  # loop-type is necessary\n            if self._env_seed[env_id] is not None:\n                if self._env_dynamic_seed is not None:\n                    self._envs[env_id].seed(self._env_seed[env_id], self._env_dynamic_seed)\n                else:\n                    self._envs[env_id].seed(self._env_seed[env_id])\n                self._env_seed[env_id] = None  # seed only use once\n        # reset env\n        if reset_param is None:\n            env_range = range(self.env_num)\n        else:\n            for env_id in reset_param:\n                self._reset_param[env_id] = reset_param[env_id]\n            env_range = reset_param.keys()\n        for env_id in env_range:\n            if self._env_replay_path is not None and self._env_states[env_id] == EnvState.RUN:\n                logging.warning(\"please don't reset a unfinished env when you enable save replay, we just skip it\")\n                continue\n            self._env_states[env_id] = EnvState.RESET\n            self._reset(env_id)\n\n    def _reset(self, env_id: int) -> None:\n\n        @retry_wrapper(max_retry=self._max_retry, waiting_time=self._retry_waiting_time)\n        @timeout_wrapper(timeout=self._reset_timeout)\n        def reset_fn():\n            # if self._reset_param[env_id] is None, just reset specific env, not pass reset param\n            if self._reset_param[env_id] is not None:\n                assert isinstance(self._reset_param[env_id], dict), type(self._reset_param[env_id])\n                return self._envs[env_id].reset(**self._reset_param[env_id])\n            else:\n                return self._envs[env_id].reset()\n\n        try:\n            obs = reset_fn()\n        except Exception as e:\n            self._env_states[env_id] = EnvState.ERROR\n            self.close()\n            raise e\n        self._ready_obs[env_id] = obs\n        self._env_states[env_id] = EnvState.RUN\n\n    def step(self, actions: Dict[int, Any]) -> Dict[int, namedtuple]:\n        \"\"\"\n        Overview:\n            Step all environments. Reset an env if done.\n        Arguments:\n            - actions (:obj:`Dict[int, Any]`): {env_id: action}\n        Returns:\n            - timesteps (:obj:`Dict[int, namedtuple]`): {env_id: timestep}. Timestep is a \\\n                ``BaseEnvTimestep`` tuple with observation, reward, done, env_info.\n        Example:\n            >>>     actions_dict = {env_id: model.forward(obs) for env_id, obs in obs_dict.items())}\n            >>>     timesteps = env_manager.step(actions_dict):\n            >>>     for env_id, timestep in timesteps.items():\n            >>>         pass\n\n        .. note:\n\n            - The env_id that appears in ``actions`` will also be returned in ``timesteps``.\n            - Once an environment is done, it is reset immediately.\n        \"\"\"\n        self._check_closed()\n        timesteps = {}\n        for env_id, act in actions.items():\n            timesteps[env_id] = self._step(env_id, act)\n            if timesteps[env_id].done:\n                self._env_episode_count[env_id] += 1\n                if self._env_episode_count[env_id] < self._episode_num and self._auto_reset:\n                    self._env_states[env_id] = EnvState.RESET\n                    self._reset(env_id)\n                else:\n                    self._env_states[env_id] = EnvState.DONE\n            else:\n                self._ready_obs[env_id] = timesteps[env_id].obs\n        return timesteps\n\n    def _step(self, env_id: int, act: Any) -> namedtuple:\n\n        @retry_wrapper(max_retry=self._max_retry, waiting_time=self._retry_waiting_time)\n        @timeout_wrapper(timeout=self._step_timeout)\n        def step_fn():\n            return self._envs[env_id].step(act)\n\n        try:\n            return step_fn()\n        except Exception as e:\n            self._env_states[env_id] = EnvState.ERROR\n            raise e\n\n    def seed(self, seed: Union[Dict[int, int], List[int], int], dynamic_seed: bool = None) -> None:\n        \"\"\"\n        Overview:\n            Set the seed for each environment.\n        Arguments:\n            - seed (:obj:`Union[Dict[int, int], List[int], int]`): List of seeds for each environment; \\\n                Or one seed for the first environment and other seeds are generated automatically.\n        \"\"\"\n        if isinstance(seed, numbers.Integral):\n            seed = [seed + i for i in range(self.env_num)]\n            self._env_seed = seed\n        elif isinstance(seed, list):\n            assert len(seed) == self._env_num, \"len(seed) {:d} != env_num {:d}\".format(len(seed), self._env_num)\n            self._env_seed = seed\n        elif isinstance(seed, dict):\n            if not hasattr(self, '_env_seed'):\n                raise RuntimeError(\"please indicate all the seed of each env in the beginning\")\n            for env_id, s in seed.items():\n                self._env_seed[env_id] = s\n        else:\n            raise TypeError(\"invalid seed arguments type: {}\".format(type(seed)))\n        self._env_dynamic_seed = dynamic_seed\n\n    def enable_save_replay(self, replay_path: Union[List[str], str]) -> None:\n        \"\"\"\n        Overview:\n            Set each env's replay save path.\n        Arguments:\n            - replay_path (:obj:`Union[List[str], str]`): List of paths for each environment; \\\n                Or one path for all environments.\n        \"\"\"", "choices": [{"text": "if isinstance(replay_path, str):"}], "metadata": {"task_id": "opendilab_ACE/34", "ground_truth": "        if isinstance(replay_path, str):", "fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "base_env_manager.py"], "context_start_lineno": 205, "line_no": 356, "query_window": {"context": "        elif isinstance(seed, list):\n            assert len(seed) == self._env_num, \"len(seed) {:d} != env_num {:d}\".format(len(seed), self._env_num)\n            self._env_seed = seed\n        elif isinstance(seed, dict):\n            if not hasattr(self, '_env_seed'):\n                raise RuntimeError(\"please indicate all the seed of each env in the beginning\")\n            for env_id, s in seed.items():\n                self._env_seed[env_id] = s\n        else:\n            raise TypeError(\"invalid seed arguments type: {}\".format(type(seed)))\n        self._env_dynamic_seed = dynamic_seed\n\n    def enable_save_replay(self, replay_path: Union[List[str], str]) -> None:\n        \"\"\"\n        Overview:\n            Set each env's replay save path.\n        Arguments:\n            - replay_path (:obj:`Union[List[str], str]`): List of paths for each environment; \\\n                Or one path for all environments.\n        \"\"\"", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "base_env_manager.py"], "line_no": 356, "task_id": "opendilab_ACE/34", "start_line_no": 336, "end_line_no": 356, "window_size": 20, "context_start_lineno": 205, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "        for _, p in self._pipe_parents.items():\n            p.send(['getattr', [key], {}])\n        data = {i: p.recv() for i, p in self._pipe_parents.items()}\n        self._check_data(data)\n        ret = [data[i] for i in self._pipe_parents.keys()]\n        return ret\n\n    # override\n    def enable_save_replay(self, replay_path: Union[List[str], str]) -> None:\n        \"\"\"\n        Overview:\n            Set each env's replay save path.\n        Arguments:\n            - replay_path (:obj:`Union[List[str], str]`): List of paths for each environment; \\\n                Or one path for all environments.\n        \"\"\"\n        if isinstance(replay_path, str):\n            replay_path = [replay_path] * self.env_num\n        self._env_replay_path = replay_path\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "subprocess_env_manager.py"], "line_no": 650, "start_line_no": 640, "end_line_no": 660, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5144927536231884}, {"context": "        Overview:\n            Set each env's replay save path.\n        Arguments:\n            - replay_path (:obj:`Union[List[str], str]`): List of paths for each environment; \\\n                Or one path for all environments.\n        \"\"\"\n        if isinstance(replay_path, str):\n            replay_path = [replay_path] * self.env_num\n        self._env_replay_path = replay_path\n\n    # override\n    def close(self) -> None:\n        \"\"\"\n        Overview:\n            CLose the env manager and release all related resources.\n        \"\"\"\n        if self._closed:\n            return\n        self._closed = True\n        self._env_ref.close()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "subprocess_env_manager.py"], "line_no": 660, "start_line_no": 650, "end_line_no": 670, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4732824427480916}, {"context": "            self._data = {k: ShmBufferContainer(dtype, v) for k, v in shape.items()}\n        elif isinstance(shape, (tuple, list)):\n            self._data = ShmBuffer(dtype, shape)\n        else:\n            raise RuntimeError(\"not support shape: {}\".format(shape))\n        self._shape = shape\n\n    def fill(self, src_arr: Union[Dict[Any, np.ndarray], np.ndarray]) -> None:\n        \"\"\"\n        Overview:\n            Fill the one or many shared memory buffer.\n        Arguments:\n            - src_arr (:obj:`Union[Dict[Any, np.ndarray], np.ndarray]`): array to fill the buffer.\n        \"\"\"\n        if isinstance(self._shape, dict):\n            for k in self._shape.keys():\n                self._data[k].fill(src_arr[k])\n        elif isinstance(self._shape, (tuple, list)):\n            self._data.fill(src_arr)\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "subprocess_env_manager.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3841059602649007}, {"context": "    def __init__(self, dtype: np.generic, shape: Union[Dict[Any, tuple], tuple]) -> None:\n        \"\"\"\n        Overview:\n            Initialize the buffer container.\n        Arguments:\n            - dtype (:obj:`np.generic`): dtype of the data to limit the size of the buffer.\n            - shape (:obj:`Union[Dict[Any, tuple], tuple]`): If `Dict[Any, tuple]`, use a dict to manage \\\n                multiple buffers; If `tuple`, use single buffer.\n        \"\"\"\n        if isinstance(shape, dict):\n            self._data = {k: ShmBufferContainer(dtype, v) for k, v in shape.items()}\n        elif isinstance(shape, (tuple, list)):\n            self._data = ShmBuffer(dtype, shape)\n        else:\n            raise RuntimeError(\"not support shape: {}\".format(shape))\n        self._shape = shape\n\n    def fill(self, src_arr: Union[Dict[Any, np.ndarray], np.ndarray]) -> None:\n        \"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "subprocess_env_manager.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3619631901840491}, {"context": "        \"\"\"\n        Overview:\n            Set up the environments and their parameters.\n        Arguments:\n            - reset_param (:obj:`Optional[Dict]`): Dict of reset parameters for each environment, key is the env_id, \\\n                value is the cooresponding reset parameters.\n        \"\"\"\n        assert self._closed, \"please first close the env manager\"\n        if reset_param is not None:\n            assert len(reset_param) == len(self._env_fn)\n        self._create_state()\n        self.reset(reset_param)\n\n    def reset(self, reset_param: Optional[Dict] = None) -> None:\n        \"\"\"\n        Overview:\n            Reset the environments their parameters.\n        Arguments:\n            - reset_param (:obj:`List`): Dict of reset parameters for each environment, key is the env_id, \\\n                value is the cooresponding reset parameters.", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "subprocess_env_manager.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3546099290780142}, {"context": "\n    # override\n    def __getattr__(self, key: str) -> Any:\n        self._check_closed()\n        # we suppose that all the envs has the same attributes, if you need different envs, please\n        # create different env managers.\n        if not hasattr(self._env_ref, key):\n            raise AttributeError(\"env `{}` doesn't have the attribute `{}`\".format(type(self._env_ref), key))\n        if isinstance(getattr(self._env_ref, key), MethodType) and key not in self.method_name_list:\n            raise RuntimeError(\"env getattr doesn't supports method({}), please override method_name_list\".format(key))\n        for _, p in self._pipe_parents.items():\n            p.send(['getattr', [key], {}])\n        data = {i: p.recv() for i, p in self._pipe_parents.items()}\n        self._check_data(data)\n        ret = [data[i] for i in self._pipe_parents.keys()]\n        return ret\n\n    # override\n    def enable_save_replay(self, replay_path: Union[List[str], str]) -> None:\n        \"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env_manager", "subprocess_env_manager.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.33714285714285713}, {"context": "    \"\"\"\n\n    def __init__(\n            self,\n            cfg_dict: Optional[dict] = None,\n            cfg_text: Optional[str] = None,\n            filename: Optional[str] = None\n    ) -> None:\n        \"\"\"\n        Overview:\n            Init method. Create config including dict type config and text type config.\n        Arguments:\n            - cfg_dict (:obj:`Optional[dict]`): dict type config\n            - cfg_text (:obj:`Optional[str]`): text type config\n            - filename (:obj:`Optional[str]`): config file name\n        \"\"\"\n        if cfg_dict is None:\n            cfg_dict = {}\n        if not isinstance(cfg_dict, dict):\n            raise TypeError(\"invalid type for cfg_dict: {}\".format(type(cfg_dict)))", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "config", "config.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3358208955223881}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/collection.py\n# --------------------------------------------------\n# \n#     def _load(value):\n#         if content not in value:\n#             raise ValueError('{content} not found in value'.format(content=repr(content)))\n# \n#         return value\n# \n#     return method('__contains__') & Loader(_load)\n# \n# \n# def cofilter(checker: Callable[[Any], bool], type_back: bool = True) -> ILoaderClass:\n# \n#     def _load(value):\n#         _result = [item for item in value if checker(item)]\n#         if type_back:\n#             _result = type(value)(_result)\n#         return _result\n# \n#     return method('__iter__') & Loader(_load)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/base.py\n# --------------------------------------------------\n#             try:\n#                 return self.load(value)\n#             except CAPTURE_EXCEPTIONS:\n#                 return Loader(other).load(value)\n# \n#         return Loader(_load)\n# \n#     def __ror__(self, other) -> 'ILoaderClass':\n#         return Loader(other) | self\n# \n#     def __rshift__(self, other) -> 'ILoaderClass':\n# \n#         def _load(value: _ValueType) -> _ValueType:\n#             _return_value = self.load(value)\n#             return _to_loader(other).load(_return_value)\n# \n#         return Loader(_load)\n# \n#     def __rrshift__(self, other) -> 'ILoaderClass':\n#         return Loader(other) >> self\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/mapping.py\n# --------------------------------------------------\n#     value_loader = Loader(value_loader)\n# \n#     def _load(value):\n#         _key_errors = []\n#         _value_errors = []\n#         _result = {}\n#         for key_, value_ in value.items():\n#             key_error, value_error = None, None\n#             key_result, value_result = None, None\n# \n#             try:\n#                 key_result = key_loader(key_)\n#             except CAPTURE_EXCEPTIONS as err:\n#                 key_error = err\n# \n#             try:\n#                 value_result = value_loader(value_)\n#             except CAPTURE_EXCEPTIONS as err:\n#                 value_error = err\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/mapping.py\n# --------------------------------------------------\n# def mpkeys() -> ILoaderClass:\n#     return method('items') & method('keys') & Loader(lambda v: set(v.keys()))\n# \n# \n# def mpvalues() -> ILoaderClass:\n#     return method('items') & method('values') & Loader(lambda v: set(v.values()))\n# \n# \n# def mpitems() -> ILoaderClass:\n#     return method('items') & Loader(lambda v: set([(key, value) for key, value in v.items()]))\n# \n# \n# _INDEX_PRECHECK = method('__getitem__')\n# \n# \n# def item(key) -> ILoaderClass:\n#     return _INDEX_PRECHECK & Loader(\n#         (lambda v: key in v.keys(), lambda v: v[key], KeyError('key {key} not found'.format(key=repr(key))))\n#     )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/norm.py\n# --------------------------------------------------\n# }\n# \n# \n# @normfunc\n# def lcmp(first, *items):\n#     if len(items) % 2 == 1:\n#         raise ValueError('Count of items should be odd number but {number} found.'.format(number=len(items) + 1))\n# \n#     ops, items = items[0::2], items[1::2]\n#     for op in ops:\n#         if op not in _COMPARE_OPERATORS.keys():\n#             raise KeyError('Invalid compare operator - {op}.'.format(op=repr(op)))\n# \n#     _last = first\n#     for op, item in zip(ops, items):\n#         if not _COMPARE_OPERATORS[op](_last, item):\n#             return False\n#         _last = item\n# \n#     return True\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/norm.py\n# --------------------------------------------------\n# }\n# \n# \n# @normfunc\n# def lcmp(first, *items):\n#     if len(items) % 2 == 1:\n#         raise ValueError('Count of items should be odd number but {number} found.'.format(number=len(items) + 1))\n# \n#     ops, items = items[0::2], items[1::2]\n#     for op in ops:\n#         if op not in _COMPARE_OPERATORS.keys():\n#             raise KeyError('Invalid compare operator - {op}.'.format(op=repr(op)))\n# \n#     _last = first\n#     for op, item in zip(ops, items):\n#         if not _COMPARE_OPERATORS[op](_last, item):\n#             return False\n#         _last = item\n# \n#     return True\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/norm.py\n# --------------------------------------------------\n#     '>=': operator.__ge__,\n# }\n# \n# \n# @normfunc\n# def lcmp(first, *items):\n#     if len(items) % 2 == 1:\n#         raise ValueError('Count of items should be odd number but {number} found.'.format(number=len(items) + 1))\n# \n#     ops, items = items[0::2], items[1::2]\n#     for op in ops:\n#         if op not in _COMPARE_OPERATORS.keys():\n#             raise KeyError('Invalid compare operator - {op}.'.format(op=repr(op)))\n# \n#     _last = first\n#     for op, item in zip(ops, items):\n#         if not _COMPARE_OPERATORS[op](_last, item):\n#             return False\n#         _last = item\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/norm.py\n# --------------------------------------------------\n# lisnot = normfunc(operator.is_not)\n# \n# lsum = _binary_reducing(lambda x, y: x + y, 0)\n# \n# _COMPARE_OPERATORS = {\n#     '!=': operator.__ne__,\n#     '==': operator.__eq__,\n#     '<': operator.__lt__,\n#     '<=': operator.__le__,\n#     '>': operator.__gt__,\n#     '>=': operator.__ge__,\n# }\n# \n# \n# @normfunc\n# def lcmp(first, *items):\n#     if len(items) % 2 == 1:\n#         raise ValueError('Count of items should be odd number but {number} found.'.format(number=len(items) + 1))\n# \n#     ops, items = items[0::2], items[1::2]\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport math\nimport operator\nfrom typing import Optional, Union, Callable, Any\n\nfrom .base import Loader, ILoaderClass\nfrom .utils import keep, check_only\n\nNUMBER_TYPES = (int, float)\nNUMBER_TYPING = Union[int, float]\n\n\ndef numeric(int_ok: bool = True, float_ok: bool = True, inf_ok: bool = True) -> ILoaderClass:\n    if not int_ok and not float_ok:\n        raise ValueError('Either int or float should be allowed.')\n\n    def _load(value) -> NUMBER_TYPING:\n        if isinstance(value, NUMBER_TYPES):\n            if math.isnan(value):\n                raise ValueError('nan is not numeric value')\n            if isinstance(value, int) and not int_ok:\n                raise TypeError('int is not allowed but {actual} found'.format(actual=repr(value)))\n            if isinstance(value, float) and not float_ok:\n                raise TypeError('float is not allowed but {actual} found'.format(actual=repr(value)))\n            if math.isinf(value) and not inf_ok:\n                raise ValueError('inf is not allowed but {actual} found'.format(actual=repr(value)))\n\n            return value\n        else:\n            raise TypeError(\n                'numeric value should be either int, float or str, but {actual} found'.format(\n                    actual=repr(type(value).__name__)\n                )\n            )\n\n    return Loader(_load)\n\n\ndef interval(\n        left: Optional[NUMBER_TYPING] = None,\n        right: Optional[NUMBER_TYPING] = None,\n        left_ok: bool = True,\n        right_ok: bool = True,\n        eps=0.0\n) -> ILoaderClass:\n    if left is None:\n        left = -math.inf\n    if right is None:\n        right = +math.inf\n    if left > right:\n        raise ValueError(\n            \"Left bound should no more than right bound, but {left} > {right}.\".format(\n                left=repr(left), right=repr(right)\n            )\n        )\n    eps = math.fabs(eps)\n\n    def _value_compare_with_eps(a, b) -> int:\n        if math.fabs(a - b) <= eps:\n            return 0\n        elif a < b:\n            return -1\n        else:\n            return 1\n\n    def _load(value) -> NUMBER_TYPING:\n        _left_check = _value_compare_with_eps(value, left)\n        if _left_check < 0:\n            raise ValueError(\n                'value should be no less than {left} but {value} found'.format(left=repr(left), value=repr(value))\n            )\n        elif not left_ok and _left_check == 0:\n            raise ValueError(\n                'value should not be equal to left bound {left} but {value} found'.format(\n                    left=repr(left), value=repr(value)\n                )\n            )\n\n        _right_check = _value_compare_with_eps(value, right)\n        if _right_check > 0:\n            raise ValueError(\n                'value should be no more than {right} but {value} found'.format(right=repr(right), value=repr(value))\n            )\n        elif not right_ok and _right_check == 0:\n            raise ValueError(\n                'value should not be equal to right bound {right} but {value} found'.format(\n                    right=repr(right), value=repr(value)\n                )\n            )\n\n        return value\n\n    return Loader(_load)\n\n\ndef is_negative() -> ILoaderClass:\n    return Loader((lambda x: x < 0, lambda x: ValueError('negative required but {value} found'.format(value=repr(x)))))\n\n\ndef is_positive() -> ILoaderClass:\n    return Loader((lambda x: x > 0, lambda x: ValueError('positive required but {value} found'.format(value=repr(x)))))\n\n\ndef non_negative() -> ILoaderClass:\n    return Loader(\n        (lambda x: x >= 0, lambda x: ValueError('non-negative required but {value} found'.format(value=repr(x))))\n    )\n\n\ndef non_positive() -> ILoaderClass:\n    return Loader(\n        (lambda x: x <= 0, lambda x: ValueError('non-positive required but {value} found'.format(value=repr(x))))\n    )\n\n\ndef negative() -> ILoaderClass:\n    return Loader(lambda x: -x)\n\n\ndef positive() -> ILoaderClass:\n    return Loader(lambda x: +x)\n\n\ndef _math_binary(func: Callable[[Any, Any], Any], attachment) -> ILoaderClass:\n    return Loader(lambda x: func(x, Loader(attachment)(x)))\n\n\ndef plus(addend) -> ILoaderClass:\n    return _math_binary(lambda x, y: x + y, addend)\n\n\ndef minus(subtrahend) -> ILoaderClass:\n    return _math_binary(lambda x, y: x - y, subtrahend)\n\n\ndef minus_with(minuend) -> ILoaderClass:\n    return _math_binary(lambda x, y: y - x, minuend)\n\n\ndef multi(multiplier) -> ILoaderClass:\n    return _math_binary(lambda x, y: x * y, multiplier)\n\n\ndef divide(divisor) -> ILoaderClass:\n    return _math_binary(lambda x, y: x / y, divisor)\n\n\ndef divide_with(dividend) -> ILoaderClass:\n    return _math_binary(lambda x, y: y / x, dividend)\n\n\ndef power(index) -> ILoaderClass:\n    return _math_binary(lambda x, y: x ** y, index)\n\n\ndef power_with(base) -> ILoaderClass:\n    return _math_binary(lambda x, y: y ** x, base)\n\n\ndef msum(*items) -> ILoaderClass:\n\n    def _load(value):\n        return sum([item(value) for item in items])\n\n    return Loader(_load)\n\n\ndef mmulti(*items) -> ILoaderClass:\n\n    def _load(value):\n        _result = 1\n        for item in items:\n            _result *= item(value)\n        return _result\n\n    return Loader(_load)\n\n\n_COMPARE_OPERATORS = {\n    '!=': operator.__ne__,\n    '==': operator.__eq__,\n    '<': operator.__lt__,\n    '<=': operator.__le__,\n    '>': operator.__gt__,\n    '>=': operator.__ge__,\n}\n\n\ndef _msinglecmp(first, op, second) -> ILoaderClass:\n    first = Loader(first)\n    second = Loader(second)\n\n    if op in _COMPARE_OPERATORS.keys():", "choices": [{"text": "return first >> ("}], "metadata": {"task_id": "opendilab_ACE/37", "ground_truth": "        return Loader(", "fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "number.py"], "context_start_lineno": 0, "line_no": 192, "query_window": {"context": "        return _result\n\n    return Loader(_load)\n\n\n_COMPARE_OPERATORS = {\n    '!=': operator.__ne__,\n    '==': operator.__eq__,\n    '<': operator.__lt__,\n    '<=': operator.__le__,\n    '>': operator.__gt__,\n    '>=': operator.__ge__,\n}\n\n\ndef _msinglecmp(first, op, second) -> ILoaderClass:\n    first = Loader(first)\n    second = Loader(second)\n\n    if op in _COMPARE_OPERATORS.keys():", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "number.py"], "line_no": 192, "task_id": "opendilab_ACE/37", "start_line_no": 172, "end_line_no": 192, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "    def __ge__(self, other):\n        return _binary(self, norm(other), operator.__ge__)\n\n\nlnot = normfunc(lambda x: not x)\nland = _binary_reducing(lambda x, y: x and y, True)\nlor = _binary_reducing(lambda x, y: x or y, True)\n\nlin = normfunc(operator.__contains__)\nlis = normfunc(operator.is_)\nlisnot = normfunc(operator.is_not)\n\nlsum = _binary_reducing(lambda x, y: x + y, 0)\n\n_COMPARE_OPERATORS = {\n    '!=': operator.__ne__,\n    '==': operator.__eq__,\n    '<': operator.__lt__,\n    '<=': operator.__le__,\n    '>': operator.__gt__,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "norm.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.38461538461538464}, {"context": "lisnot = normfunc(operator.is_not)\n\nlsum = _binary_reducing(lambda x, y: x + y, 0)\n\n_COMPARE_OPERATORS = {\n    '!=': operator.__ne__,\n    '==': operator.__eq__,\n    '<': operator.__lt__,\n    '<=': operator.__le__,\n    '>': operator.__gt__,\n    '>=': operator.__ge__,\n}\n\n\n@normfunc\ndef lcmp(first, *items):\n    if len(items) % 2 == 1:\n        raise ValueError('Count of items should be odd number but {number} found.'.format(number=len(items) + 1))\n\n    ops, items = items[0::2], items[1::2]", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "norm.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.35135135135135137}, {"context": "    for op in ops:\n        if op not in _COMPARE_OPERATORS.keys():\n            raise KeyError('Invalid compare operator - {op}.'.format(op=repr(op)))\n\n    _last = first\n    for op, item in zip(ops, items):\n        if not _COMPARE_OPERATORS[op](_last, item):\n            return False\n        _last = item\n\n    return True", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "norm.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 221, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.32941176470588235}, {"context": "    '>=': operator.__ge__,\n}\n\n\n@normfunc\ndef lcmp(first, *items):\n    if len(items) % 2 == 1:\n        raise ValueError('Count of items should be odd number but {number} found.'.format(number=len(items) + 1))\n\n    ops, items = items[0::2], items[1::2]\n    for op in ops:\n        if op not in _COMPARE_OPERATORS.keys():\n            raise KeyError('Invalid compare operator - {op}.'.format(op=repr(op)))\n\n    _last = first\n    for op, item in zip(ops, items):\n        if not _COMPARE_OPERATORS[op](_last, item):\n            return False\n        _last = item\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "norm.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.32456140350877194}, {"context": "    def _load(value):\n        _result = {key_: value_ for key_, value_ in value.items() if check(key_, value_)}\n\n        if type_back:\n            _result = type(value)(_result)\n        return _result\n\n    return method('items') & Loader(_load)\n\n\ndef mpkeys() -> ILoaderClass:\n    return method('items') & method('keys') & Loader(lambda v: set(v.keys()))\n\n\ndef mpvalues() -> ILoaderClass:\n    return method('items') & method('values') & Loader(lambda v: set(v.values()))\n\n\ndef mpitems() -> ILoaderClass:\n    return method('items') & Loader(lambda v: set([(key, value) for key, value in v.items()]))", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "mapping.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.30337078651685395}, {"context": "\n    def value_errors(self) -> MAPPING_ERRORS:\n        return self.__value_errors\n\n    def errors(self) -> MAPPING_ERRORS:\n        return self.__errors\n\n\ndef mapping(key_loader, value_loader, type_back: bool = True) -> ILoaderClass:\n    key_loader = Loader(key_loader)\n    value_loader = Loader(value_loader)\n\n    def _load(value):\n        _key_errors = []\n        _value_errors = []\n        _result = {}\n        for key_, value_ in value.items():\n            key_error, value_error = None, None\n            key_result, value_result = None, None\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "mapping.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.29069767441860467}, {"context": "\n    def __rshift__(self, other) -> 'ILoaderClass':\n\n        def _load(value: _ValueType) -> _ValueType:\n            _return_value = self.load(value)\n            return _to_loader(other).load(_return_value)\n\n        return Loader(_load)\n\n    def __rrshift__(self, other) -> 'ILoaderClass':\n        return Loader(other) >> self", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "base.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 151, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.28205128205128205}, {"context": "        return value\n\n    return method('__len__') & Loader(_load)\n\n\ndef length_is(length_: int) -> ILoaderClass:\n    return length(min_length=length_, max_length=length_)\n\n\ndef contains(content) -> ILoaderClass:\n\n    def _load(value):\n        if content not in value:\n            raise ValueError('{content} not found in value'.format(content=repr(content)))\n\n        return value\n\n    return method('__contains__') & Loader(_load)\n\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "collection.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2777777777777778}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/gym_like.py\n# --------------------------------------------------\n# \n#             done, do_break = self.read_done(done)\n#             if do_break:\n#                 break\n# \n#         obs_dict = self.read_obs(obs)\n# \n#         if reward is None:\n#             reward = np.nan\n#         reward = self._to_tensor(reward, dtype=self.reward_spec.dtype)\n#         done = self._to_tensor(done, dtype=torch.bool)\n# \n#         tensordict_out = TensorDict(\n#             obs_dict, batch_size=tensordict.batch_size, device=self.device\n#         )\n# \n#         tensordict_out.set(\"reward\", reward)\n#         tensordict_out.set(\"done\", done)\n#         if self.info_dict_reader is not None and info is not None:\n#             self.info_dict_reader(info, tensordict_out)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/jax_utils.py\n# --------------------------------------------------\n#             t[name] = value.reshape(example.shape).view(example.dtype)\n#     return type(object_example)(**t)\n# \n# \n# def _extract_spec(data: Union[torch.Tensor, TensorDictBase]) -> TensorSpec:\n#     if isinstance(data, torch.Tensor):\n#         if data.dtype in (torch.float, torch.double, torch.half):\n#             return UnboundedContinuousTensorSpec(\n#                 shape=data.shape, dtype=data.dtype, device=data.device\n#             )\n#         else:\n#             return UnboundedDiscreteTensorSpec(\n#                 shape=data.shape, dtype=data.dtype, device=data.device\n#             )\n#     elif isinstance(data, TensorDictBase):\n#         return CompositeSpec(\n#             **{key: _extract_spec(value) for key, value in data.items()}\n#         )\n#     else:\n#         raise TypeError(f\"Unsupported data type {type(data)}\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/vip.py\n# --------------------------------------------------\n#         else:\n#             self._device = dest\n#         return super().to(dest)\n# \n#     @property\n#     def device(self):\n#         return self._device\n# \n#     @property\n#     def dtype(self):\n#         return self._dtype\n# \n# \n# class VIPRewardTransform(VIPTransform):\n#     \"\"\"A VIP transform to compute rewards based on embedded similarity.\n# \n#     This class will update the reward computation\n#     \"\"\"\n# \n#     def reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#             else BoundedTensorSpec(\n#                 low,\n#                 high,\n#                 shape,\n#                 dtype=dtype,\n#                 device=device,\n#             )\n#         )\n#     elif isinstance(spec, (Dict,)):\n#         spec_out = {}\n#         for k in spec.keys():\n#             spec_out[k] = _gym_to_torchrl_spec_transform(\n#                 spec[k],\n#                 device=device,\n#                 categorical_action_encoding=categorical_action_encoding,\n#             )\n#         return CompositeSpec(**spec_out)\n#     elif isinstance(spec, gym.spaces.dict.Dict):\n#         return _gym_to_torchrl_spec_transform(\n#             spec.spaces,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/jumanji.py\n# --------------------------------------------------\n#         if dtype in (torch.float, torch.double, torch.half):\n#             return UnboundedContinuousTensorSpec(\n#                 shape=shape, dtype=dtype, device=device\n#             )\n#         else:\n#             return UnboundedDiscreteTensorSpec(shape=shape, dtype=dtype, device=device)\n#     elif isinstance(spec, jumanji.specs.Spec) and hasattr(spec, \"__dict__\"):\n#         new_spec = {}\n#         for key, value in spec.__dict__.items():\n#             if isinstance(value, jumanji.specs.Spec):\n#                 if key.endswith(\"_obs\"):\n#                     key = key[:-4]\n#                 if key.endswith(\"_spec\"):\n#                     key = key[:-5]\n#                 new_spec[key] = _jumanji_to_torchrl_spec_transform(\n#                     value, dtype, device, categorical_action_encoding\n#                 )\n#         return CompositeSpec(**new_spec)\n#     else:\n#         raise TypeError(f\"Unsupported spec type {type(spec)}\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#             minimum = torch.tensor(minimum, dtype=dtype, device=device)\n#         if not isinstance(maximum, torch.Tensor):\n#             maximum = torch.tensor(maximum, dtype=dtype, device=device)\n#         if maximum.device != device:\n#             maximum = maximum.to(device)\n#         if minimum.device != device:\n#             minimum = minimum.to(device)\n#         if dtype is not None and minimum.dtype is not dtype:\n#             minimum = minimum.to(dtype)\n#         if dtype is not None and maximum.dtype is not dtype:\n#             maximum = maximum.to(dtype)\n#         err_msg = (\n#             \"BoundedTensorSpec requires the shape to be explicitely (via \"\n#             \"the shape argument) or implicitely defined (via either the \"\n#             \"minimum or the maximum or both). If the maximum and/or the \"\n#             \"minimum have a non-singleton shape, they must match the \"\n#             \"provided shape if this one is set explicitely.\"\n#         )\n#         if shape is not None and not isinstance(shape, torch.Size):\n#             if isinstance(shape, int):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/distributions/utils.py\n# --------------------------------------------------\n#         return elt.to(device)\n#     return elt\n# \n# \n# def _cast_transform_device(transform, device):\n#     if transform is None:\n#         return transform\n#     elif isinstance(transform, d.ComposeTransform):\n#         for i, t in enumerate(transform.parts):\n#             transform.parts[i] = _cast_transform_device(t, device)\n#     elif isinstance(transform, d.Transform):\n#         for attribute in dir(transform):\n#             value = getattr(transform, attribute)\n#             if isinstance(value, torch.Tensor):\n#                 setattr(transform, attribute, value.to(device))\n#         return transform\n#     else:\n#         raise TypeError(\n#             f\"Cannot perform device casting for transform of type {type(transform)}\"\n#         )\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n} was done after reset on specified '_reset' dimensions. This is (currently) not allowed.\"\n            )\n        if tensordict is not None:\n            tensordict.update(tensordict_reset)\n        else:\n            tensordict = tensordict_reset\n        return tensordict\n\n    def numel(self) -> int:\n        return prod(self.batch_size)\n\n    def set_seed(\n        self, seed: Optional[int] = None, static_seed: bool = False\n    ) -> Optional[int]:\n        \"\"\"Sets the seed of the environment and returns the next seed to be used (which is the input seed if a single environment is present).\n\n        Args:\n            seed (int): seed to be set\n            static_seed (bool, optional): if True, the seed is not incremented.\n                Defaults to False\n\n        Returns:\n            integer representing the \"next seed\": i.e. the seed that should be\n            used for another environment if created concomittently to this environment.\n\n        \"\"\"\n        if seed is not None:\n            torch.manual_seed(seed)\n        self._set_seed(seed)\n        if seed is not None and not static_seed:\n            new_seed = seed_generator(seed)\n            seed = new_seed\n        return seed\n\n    @abc.abstractmethod\n    def _set_seed(self, seed: Optional[int]):\n        raise NotImplementedError\n\n    def set_state(self):\n        raise NotImplementedError\n\n    def _assert_tensordict_shape(self, tensordict: TensorDictBase) -> None:\n        if tensordict.batch_size != self.batch_size and (\n            self.batch_locked or self.batch_size != torch.Size([])\n        ):\n            raise RuntimeError(\n                f\"Expected a tensordict with shape==env.shape, \"\n                f\"got {tensordict.batch_size} and {self.batch_size}\"\n            )\n\n    def rand_step(self, tensordict: Optional[TensorDictBase] = None) -> TensorDictBase:\n        \"\"\"Performs a random step in the environment given the action_spec attribute.\n\n        Args:\n            tensordict (TensorDictBase, optional): tensordict where the resulting info should be written.\n\n        Returns:\n            a tensordict object with the new observation after a random step in the environment. The action will\n            be stored with the \"action\" key.\n\n        \"\"\"\n        if tensordict is None:\n            tensordict = TensorDict(\n                {}, device=self.device, batch_size=self.batch_size, _run_checks=False\n            )\n        action = self.action_spec.rand()\n        tensordict.set(\"action\", action)\n        return self.step(tensordict)\n\n    @property\n    def specs(self) -> Specs:\n        \"\"\"Returns a Specs container where all the environment specs are contained.\n\n        This feature allows one to create an environment, retrieve all of the specs in a single data container and then\n        erase the environment from the workspace.\n\n        \"\"\"\n        return Specs(self)\n\n    def rollout(\n        self,\n        max_steps: int,\n        policy: Optional[Callable[[TensorDictBase], TensorDictBase]] = None,\n        callback: Optional[Callable[[TensorDictBase, ...], TensorDictBase]] = None,\n        auto_reset: bool = True,\n        auto_cast_to_device: bool = False,\n        break_when_any_done: bool = True,\n        return_contiguous: bool = True,\n        tensordict: Optional[TensorDictBase] = None,\n    ) -> TensorDictBase:\n        \"\"\"Executes a rollout in the environment.\n\n        The function will stop as soon as one of the contained environments\n        returns done=True.\n\n        Args:\n            max_steps (int): maximum number of steps to be executed. The actual number of steps can be smaller if\n                the environment reaches a done state before max_steps have been executed.\n            policy (callable, optional): callable to be called to compute the desired action. If no policy is provided,\n                actions will be called using :obj:`env.rand_step()`\n                default = None\n            callback (callable, optional): function to be called at each iteration with the given TensorDict.\n            auto_reset (bool, optional): if True, resets automatically the environment\n                if it is in a done state when the rollout is initiated.\n                Default is :obj:`True`.\n            auto_cast_to_device (bool, optional): if True, the device of the tensordict is automatically cast to the\n                policy device before the policy is used. Default is :obj:`False`.\n            break_when_any_done (bool): breaks if any of the done state is True. Default is True.\n            return_contiguous (bool): if False, a LazyStackedTensorDict will be returned. Default is True.\n            tensordict (TensorDict, optional): if auto_reset is False, an initial\n                tensordict must be provided.\n\n        Returns:\n            TensorDict object containing the resulting trajectory.\n\n        \"\"\"\n        try:\n            policy_device = next(policy.parameters()).device\n        except AttributeError:\n            policy_device = \"cpu\"\n\n        env_device = self.device\n\n        if auto_reset:\n            if tensordict is not None:\n                raise RuntimeError(\n                    \"tensordict cannot be provided when auto_reset is True\"\n                )\n            tensordict = self.reset()\n        elif tensordict is None:\n            raise RuntimeError(\"tensordict must be provided when auto_reset is False\")\n\n        if policy is None:\n\n            def policy(td):\n                return td.set(\"action\", self.action_spec.rand())\n\n        tensordicts = []\n        for i in range(max_steps):\n            if auto_cast_to_device:\n                tensordict = tensordict.to(policy_device)\n            tensordict = policy(tensordict)\n            if auto_cast_to_device:\n                tensordict = tensordict.to(env_device)\n            tensordict = self.step(tensordict)\n            tensordicts.append(tensordict.clone())\n            if (\n                break_when_any_done and tensordict.get(\"done\").any()\n            ) or i == max_steps - 1:\n                break\n            tensordict = step_mdp(\n                tensordict,\n                keep_other=True,\n                exclude_reward=False,\n                exclude_action=False,\n            )\n\n            if callback is not None:\n                callback(self, tensordict)\n\n        batch_size = self.batch_size if tensordict is None else tensordict.batch_size\n\n        out_td = torch.stack(tensordicts, len(batch_size))\n        if return_contiguous:\n            return out_td.contiguous()\n        return out_td\n\n    def _select_observation_keys(self, tensordict: TensorDictBase) -> Iterator[str]:\n        for key in tensordict.keys():\n            if key.rfind(\"observation\") >= 0:\n                yield key\n\n    def _to_tensor(\n        self,\n        value: Union[dict, bool, float, torch.Tensor, np.ndarray],\n        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[torch.dtype] = None,\n    ) -> Union[torch.Tensor, dict]:\n        if device is None:\n            device = self.device\n\n        if isinstance(value, dict):\n            return {\n                _key: self._to_tensor(_value, dtype=dtype, device=device)\n                for _key, _value in value.items()\n            }\n        elif isinstance(value, (bool, Number)):\n            value = np.array(value)\n\n        if dtype is None and self.dtype is not None:\n            dtype = self.dtype\n        elif dtype is not None:\n            dtype = dtype_map.get(dtype, dtype)\n        else:\n            dtype = value.dtype\n\n        if not isinstance(value, torch.Tensor):", "choices": [{"text": "return torch.tensor(value, dtype=dtype, device=device)"}], "metadata": {"task_id": "pytorch_rl/161", "ground_truth": "            if dtype is not None:", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "context_start_lineno": 521, "line_no": 718, "query_window": {"context": "    ) -> Union[torch.Tensor, dict]:\n        if device is None:\n            device = self.device\n\n        if isinstance(value, dict):\n            return {\n                _key: self._to_tensor(_value, dtype=dtype, device=device)\n                for _key, _value in value.items()\n            }\n        elif isinstance(value, (bool, Number)):\n            value = np.array(value)\n\n        if dtype is None and self.dtype is not None:\n            dtype = self.dtype\n        elif dtype is not None:\n            dtype = dtype_map.get(dtype, dtype)\n        else:\n            dtype = value.dtype\n\n        if not isinstance(value, torch.Tensor):", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 718, "task_id": "pytorch_rl/161", "start_line_no": 698, "end_line_no": 718, "window_size": 20, "context_start_lineno": 521, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "\ndef _cast_device(elt: Union[torch.Tensor, float], device) -> Union[torch.Tensor, float]:\n    if isinstance(elt, torch.Tensor):\n        return elt.to(device)\n    return elt\n\n\ndef _cast_transform_device(transform, device):\n    if transform is None:\n        return transform\n    elif isinstance(transform, d.ComposeTransform):\n        for i, t in enumerate(transform.parts):\n            transform.parts[i] = _cast_transform_device(t, device)\n    elif isinstance(transform, d.Transform):\n        for attribute in dir(transform):\n            value = getattr(transform, attribute)\n            if isinstance(value, torch.Tensor):\n                setattr(transform, attribute, value.to(device))\n        return transform\n    else:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "distributions", "utils.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.47674418604651164}, {"context": "        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[torch.dtype, str]] = None,\n    ):\n        dtype, device = _default_dtype_and_device(dtype, device)\n        if dtype is None:\n            dtype = torch.get_default_dtype()\n        if device is None:\n            device = torch._get_default_device()\n\n        if not isinstance(minimum, torch.Tensor):\n            minimum = torch.tensor(minimum, dtype=dtype, device=device)\n        if not isinstance(maximum, torch.Tensor):\n            maximum = torch.tensor(maximum, dtype=dtype, device=device)\n        if maximum.device != device:\n            maximum = maximum.to(device)\n        if minimum.device != device:\n            minimum = minimum.to(device)\n        if dtype is not None and minimum.dtype is not dtype:\n            minimum = minimum.to(dtype)\n        if dtype is not None and maximum.dtype is not dtype:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4567901234567901}, {"context": "            shape=shape,\n            minimum=np.asarray(spec.minimum),\n            maximum=np.asarray(spec.maximum),\n            dtype=dtype,\n            device=device,\n        )\n    elif isinstance(spec, jumanji.specs.Array):\n        shape = spec.shape\n        if dtype is None:\n            dtype = numpy_to_torch_dtype_dict[spec.dtype]\n        if dtype in (torch.float, torch.double, torch.half):\n            return UnboundedContinuousTensorSpec(\n                shape=shape, dtype=dtype, device=device\n            )\n        else:\n            return UnboundedDiscreteTensorSpec(shape=shape, dtype=dtype, device=device)\n    elif isinstance(spec, jumanji.specs.Spec) and hasattr(spec, \"__dict__\"):\n        new_spec = {}\n        for key, value in spec.__dict__.items():\n            if isinstance(value, jumanji.specs.Spec):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "jumanji.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.41346153846153844}, {"context": "        if not len(shape):\n            shape = torch.Size([1])\n        if dtype is None:\n            dtype = numpy_to_torch_dtype_dict[spec.dtype]\n        low = torch.tensor(spec.low, device=device, dtype=dtype)\n        high = torch.tensor(spec.high, device=device, dtype=dtype)\n        is_unbounded = low.isinf().all() and high.isinf().all()\n        return (\n            UnboundedContinuousTensorSpec(shape, device=device, dtype=dtype)\n            if is_unbounded\n            else BoundedTensorSpec(\n                low,\n                high,\n                shape,\n                dtype=dtype,\n                device=device,\n            )\n        )\n    elif isinstance(spec, (Dict,)):\n        spec_out = {}", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.41237113402061853}, {"context": "            )\n\n        if self._device is not None:\n            self.to(self._device)\n        if self._dtype is not None:\n            self.to(self._dtype)\n\n    def to(self, dest: Union[DEVICE_TYPING, torch.dtype]):\n        if isinstance(dest, torch.dtype):\n            self._dtype = dest\n        else:\n            self._device = dest\n        return super().to(dest)\n\n    @property\n    def device(self):\n        return self._device\n\n    @property\n    def dtype(self):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "vip.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.41025641025641024}, {"context": "        if data.dtype in (torch.float, torch.double, torch.half):\n            return UnboundedContinuousTensorSpec(\n                shape=data.shape, dtype=data.dtype, device=data.device\n            )\n        else:\n            return UnboundedDiscreteTensorSpec(\n                shape=data.shape, dtype=data.dtype, device=data.device\n            )\n    elif isinstance(data, TensorDictBase):\n        return CompositeSpec(\n            **{key: _extract_spec(value) for key, value in data.items()}\n        )\n    else:\n        raise TypeError(f\"Unsupported data type {type(data)}\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "jax_utils.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 114, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.41}, {"context": "\n            if _reward is None:\n                _reward = self.reward_spec.zero()\n\n            reward = self.read_reward(reward, _reward)\n\n            if isinstance(done, bool) or (\n                isinstance(done, np.ndarray) and not len(done)\n            ):\n                done = torch.tensor([done], device=self.device)\n\n            done, do_break = self.read_done(done)\n            if do_break:\n                break\n\n        obs_dict = self.read_obs(obs)\n\n        if reward is None:\n            reward = np.nan\n        reward = self._to_tensor(reward, dtype=self.reward_spec.dtype)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4069767441860465}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_data.py\n# --------------------------------------------------\n#             assert type(a) == np.ndarray\n#             assert a.shape == (3, 5)\n# \n#     def test_get_inputs_from_generator_function(self):\n#         data = make_generator_fun_random_data(\n#             n_batches=2,\n#             batch_size=3,\n#             shape_inputs=(5,),\n#             output_dim=4,\n#             output_type=\"continuous\",\n#         )\n#         data = DataLoader.from_callable_iterable(data)\n#         inputs = InputsLoader.from_data_loader(data)\n#         for a in inputs:\n#             assert type(a) == np.ndarray\n#             assert a.shape == (3, 5)\n# \n#     def test_array_data(self):\n#         data_org = make_array_random_data(\n#             n_data=10,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_likelihood.py\n# --------------------------------------------------\n#                 shape_inputs=self.shape_inputs,\n#                 output_dim=self.output_dim,\n#                 output_type=\"discrete\",\n#             )\n#         )\n#         self.class_inputs_arr = InputsLoader.from_data_loader(self.class_data_arr)\n# \n#         self.class_data_gen_fun = DataLoader.from_callable_iterable(\n#             make_generator_fun_random_data(\n#                 n_batches=self.n_batches,\n#                 batch_size=self.batch_size,\n#                 shape_inputs=self.shape_inputs,\n#                 output_dim=self.output_dim,\n#                 output_type=\"discrete\",\n#             )\n#         )\n#         self.class_inputs_gen_fun = InputsLoader.from_data_loader(\n#             self.class_data_gen_fun\n#         )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/calib_model/test_calibrate.py\n# --------------------------------------------------\n#             n_data=100,\n#             shape_inputs=self.reg_input_shape,\n#             output_dim=self.reg_output_dim,\n#             output_type=\"continuous\",\n#         )\n#         reg_train_data = [\n#             (reg_train_data[0][i : i + bs], reg_train_data[1][i : i + bs])\n#             for i in range(0, len(reg_train_data[0]), bs)\n#         ]\n#         reg_val_data = [\n#             (reg_val_data[0][i : i + bs], reg_val_data[1][i : i + bs])\n#             for i in range(0, len(reg_val_data[0]), bs)\n#         ]\n#         self.reg_train_data_loader = DataLoader.from_iterable(reg_train_data)\n#         self.reg_val_data_loader = DataLoader.from_iterable(reg_val_data)\n# \n#         class_train_data = make_array_random_data(\n#             n_data=100,\n#             shape_inputs=self.class_input_shape,\n#             output_dim=self.class_output_dim,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/calib_model/test_calibrate.py\n# --------------------------------------------------\n#             for i in range(0, len(class_train_data[0]), bs)\n#         ]\n#         class_val_data = [\n#             (class_val_data[0][i : i + bs], class_val_data[1][i : i + bs])\n#             for i in range(0, len(class_val_data[0]), bs)\n#         ]\n#         self.class_train_data_loader = DataLoader.from_iterable(class_train_data)\n#         self.class_val_data_loader = DataLoader.from_iterable(class_val_data)\n# \n#         self.class_fit_config_nodir_nodump = FitConfig(\n#             optimizer=FitOptimizer(n_epochs=3), monitor=FitMonitor(metrics=(accuracy,))\n#         )\n#         self.reg_fit_config_nodir_nodump = FitConfig(\n#             optimizer=FitOptimizer(n_epochs=3), monitor=FitMonitor(metrics=(rmse,))\n#         )\n#         self.calib_config_dir_nodump = lambda directory, metric: CalibConfig(\n#             optimizer=CalibOptimizer(n_epochs=3),\n#             monitor=CalibMonitor(metrics=(metric,)),\n#             checkpointer=CalibCheckpointer(save_checkpoint_dir=directory),\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/calib_model/test_calibrate.py\n# --------------------------------------------------\n#             (reg_val_data[0][i : i + bs], reg_val_data[1][i : i + bs])\n#             for i in range(0, len(reg_val_data[0]), bs)\n#         ]\n#         self.reg_train_data_loader = DataLoader.from_iterable(reg_train_data)\n#         self.reg_val_data_loader = DataLoader.from_iterable(reg_val_data)\n# \n#         class_train_data = make_array_random_data(\n#             n_data=100,\n#             shape_inputs=self.class_input_shape,\n#             output_dim=self.class_output_dim,\n#             output_type=\"discrete\",\n#         )\n#         class_val_data = make_array_random_data(\n#             n_data=100,\n#             shape_inputs=self.class_input_shape,\n#             output_dim=self.class_output_dim,\n#             output_type=\"discrete\",\n#         )\n#         class_train_data = [\n#             (class_train_data[0][i : i + bs], class_train_data[1][i : i + bs])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/calib_model/test_calibrate.py\n# --------------------------------------------------\n#             output_type=\"discrete\",\n#         )\n#         class_val_data = make_array_random_data(\n#             n_data=100,\n#             shape_inputs=self.class_input_shape,\n#             output_dim=self.class_output_dim,\n#             output_type=\"discrete\",\n#         )\n#         class_train_data = [\n#             (class_train_data[0][i : i + bs], class_train_data[1][i : i + bs])\n#             for i in range(0, len(class_train_data[0]), bs)\n#         ]\n#         class_val_data = [\n#             (class_val_data[0][i : i + bs], class_val_data[1][i : i + bs])\n#             for i in range(0, len(class_val_data[0]), bs)\n#         ]\n#         self.class_train_data_loader = DataLoader.from_iterable(class_train_data)\n#         self.class_val_data_loader = DataLoader.from_iterable(class_val_data)\n# \n#         self.class_fit_config_nodir_nodump = FitConfig(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport tempfile\nimport unittest\n\nfrom fortuna.data.loader import DataLoader\nfrom fortuna.metric.classification import accuracy, brier_score\nfrom fortuna.metric.regression import rmse\nfrom fortuna.model.mlp import MLP\nfrom fortuna.output_calibrator.classification import \\\n    ClassificationTemperatureScaler\nfrom fortuna.output_calibrator.regression import RegressionTemperatureScaler\nfrom fortuna.prob_model.calib_config import (CalibConfig, CalibMonitor,\n                                             CalibOptimizer)\nfrom fortuna.prob_model.classification import ProbClassifier\nfrom fortuna.prob_model.fit_config import FitConfig, FitMonitor\nfrom fortuna.prob_model.fit_config.checkpointer import FitCheckpointer\nfrom fortuna.prob_model.fit_config.optimizer import FitOptimizer\nfrom fortuna.prob_model.posterior.deep_ensemble.deep_ensemble_posterior import \\\n    DeepEnsemblePosteriorApproximator\nfrom fortuna.prob_model.posterior.laplace.laplace_posterior import \\\n    LaplacePosteriorApproximator\nfrom fortuna.prob_model.posterior.map.map_approximator import \\\n    MAPPosteriorApproximator\nfrom fortuna.prob_model.posterior.normalizing_flow.advi.advi_posterior import \\\n    ADVIPosteriorApproximator\nfrom fortuna.prob_model.posterior.swag.swag_posterior import \\\n    SWAGPosteriorApproximator\nfrom fortuna.prob_model.prior import IsotropicGaussianPrior\nfrom fortuna.prob_model.regression import ProbRegressor\nfrom tests.make_data import make_array_random_data\nfrom tests.make_model import MyModel\n\n\ndef brier(dummy, p, y):\n    return brier_score(p, y)\n\n\nclass TestApproximations(unittest.TestCase):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.prob_class = ProbClassifier(\n            model=MyModel(2), prior=IsotropicGaussianPrior()\n        )\n\n        self.reg_input_shape = (3,)\n        self.reg_output_dim = 2\n        bs = 32\n        x, y = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.reg_input_shape,\n            output_dim=self.reg_output_dim,\n            output_type=\"continuous\",\n        )\n        x /= x.max(0)\n        y /= y.max(0)\n        reg_train_data = x, y\n        reg_val_data = make_array_random_data(\n            n_data=10,\n            shape_inputs=self.reg_input_shape,\n            output_dim=self.reg_output_dim,\n            output_type=\"continuous\",\n        )\n        reg_train_data = [\n            (reg_train_data[0][i : i + bs], reg_train_data[1][i : i + bs])\n            for i in range(0, len(reg_train_data[0]), bs)\n        ]\n        reg_val_data = [\n            (reg_val_data[0][i : i + bs], reg_val_data[1][i : i + bs])\n            for i in range(0, len(reg_val_data[0]), bs)\n        ]\n        self.reg_train_data_loader = DataLoader.from_iterable(reg_train_data)\n        self.reg_val_data_loader = DataLoader.from_iterable(reg_val_data)\n\n        self.class_input_shape = (2,)\n        self.class_output_dim = 2\n        class_train_data = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.class_input_shape,\n            output_dim=self.class_output_dim,\n            output_type=\"discrete\",\n        )\n        class_val_data = make_array_random_data(", "choices": [{"text": "n_data=100,"}], "metadata": {"task_id": "awslabs_fortuna/116", "ground_truth": "            n_data=10,", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "context_start_lineno": 0, "line_no": 81, "query_window": {"context": "        reg_train_data = [\n            (reg_train_data[0][i : i + bs], reg_train_data[1][i : i + bs])\n            for i in range(0, len(reg_train_data[0]), bs)\n        ]\n        reg_val_data = [\n            (reg_val_data[0][i : i + bs], reg_val_data[1][i : i + bs])\n            for i in range(0, len(reg_val_data[0]), bs)\n        ]\n        self.reg_train_data_loader = DataLoader.from_iterable(reg_train_data)\n        self.reg_val_data_loader = DataLoader.from_iterable(reg_val_data)\n\n        self.class_input_shape = (2,)\n        self.class_output_dim = 2\n        class_train_data = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.class_input_shape,\n            output_dim=self.class_output_dim,\n            output_type=\"discrete\",\n        )\n        class_val_data = make_array_random_data(", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 81, "task_id": "awslabs_fortuna/116", "start_line_no": 61, "end_line_no": 81, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            (reg_val_data[0][i : i + bs], reg_val_data[1][i : i + bs])\n            for i in range(0, len(reg_val_data[0]), bs)\n        ]\n        self.reg_train_data_loader = DataLoader.from_iterable(reg_train_data)\n        self.reg_val_data_loader = DataLoader.from_iterable(reg_val_data)\n\n        class_train_data = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.class_input_shape,\n            output_dim=self.class_output_dim,\n            output_type=\"discrete\",\n        )\n        class_val_data = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.class_input_shape,\n            output_dim=self.class_output_dim,\n            output_type=\"discrete\",\n        )\n        class_train_data = [\n            (class_train_data[0][i : i + bs], class_train_data[1][i : i + bs])", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "calib_model", "test_calibrate.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9545454545454546}, {"context": "            n_data=100,\n            shape_inputs=self.reg_input_shape,\n            output_dim=self.reg_output_dim,\n            output_type=\"continuous\",\n        )\n        reg_train_data = [\n            (reg_train_data[0][i : i + bs], reg_train_data[1][i : i + bs])\n            for i in range(0, len(reg_train_data[0]), bs)\n        ]\n        reg_val_data = [\n            (reg_val_data[0][i : i + bs], reg_val_data[1][i : i + bs])\n            for i in range(0, len(reg_val_data[0]), bs)\n        ]\n        self.reg_train_data_loader = DataLoader.from_iterable(reg_train_data)\n        self.reg_val_data_loader = DataLoader.from_iterable(reg_val_data)\n\n        class_train_data = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.class_input_shape,\n            output_dim=self.class_output_dim,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "calib_model", "test_calibrate.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.8970588235294118}, {"context": "            output_type=\"discrete\",\n        )\n        class_val_data = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.class_input_shape,\n            output_dim=self.class_output_dim,\n            output_type=\"discrete\",\n        )\n        class_train_data = [\n            (class_train_data[0][i : i + bs], class_train_data[1][i : i + bs])\n            for i in range(0, len(class_train_data[0]), bs)\n        ]\n        class_val_data = [\n            (class_val_data[0][i : i + bs], class_val_data[1][i : i + bs])\n            for i in range(0, len(class_val_data[0]), bs)\n        ]\n        self.class_train_data_loader = DataLoader.from_iterable(class_train_data)\n        self.class_val_data_loader = DataLoader.from_iterable(class_val_data)\n\n        self.class_fit_config_nodir_nodump = FitConfig(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "calib_model", "test_calibrate.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.8243243243243243}, {"context": "        x, y = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.reg_input_shape,\n            output_dim=self.reg_output_dim,\n            output_type=\"continuous\",\n        )\n        x /= x.max(0)\n        y /= y.max(0)\n        reg_train_data = x, y\n        reg_val_data = make_array_random_data(\n            n_data=100,\n            shape_inputs=self.reg_input_shape,\n            output_dim=self.reg_output_dim,\n            output_type=\"continuous\",\n        )\n        reg_train_data = [\n            (reg_train_data[0][i : i + bs], reg_train_data[1][i : i + bs])\n            for i in range(0, len(reg_train_data[0]), bs)\n        ]\n        reg_val_data = [", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "calib_model", "test_calibrate.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7083333333333334}, {"context": "                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n        self.reg_inputs_gen_fun = InputsLoader.from_data_loader(self.reg_data_gen_fun)\n\n        self.class_data_arr = DataLoader.from_array_data(\n            make_array_random_data(\n                n_data=self.n_inputs,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"discrete\",\n            )\n        )\n        self.class_inputs_arr = InputsLoader.from_data_loader(self.class_data_arr)\n\n        self.class_data_gen_fun = DataLoader.from_callable_iterable(\n            make_generator_fun_random_data(\n                n_batches=self.n_batches,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_likelihood.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4936708860759494}, {"context": "        data = make_generator_random_data(\n            n_batches=2,\n            batch_size=3,\n            shape_inputs=(5,),\n            output_dim=4,\n            output_type=\"continuous\",\n        )\n        data = DataLoader.from_iterable(data)\n        inputs = InputsLoader.from_data_loader(data)\n        for a in inputs:\n            assert type(a) == np.ndarray\n            assert a.shape == (3, 5)\n\n    def test_get_inputs_from_generator_function(self):\n        data = make_generator_fun_random_data(\n            n_batches=2,\n            batch_size=3,\n            shape_inputs=(5,),\n            output_dim=4,\n            output_type=\"continuous\",", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_data.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.37755102040816324}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/module.py\n# --------------------------------------------------\n#         \"\"\"\n#         if dl_manager is None:\n#             if download_config is None:\n#                 download_config = DownloadConfig()\n#                 download_config.cache_dir = os.path.join(self.data_dir, \"downloads\")\n#                 download_config.force_download = False\n# \n#             dl_manager = DownloadManager(\n#                 dataset_name=self.name, download_config=download_config, data_dir=self.data_dir\n#             )\n# \n#         self._download_and_prepare(dl_manager)\n# \n#     def _download_and_prepare(self, dl_manager):\n#         \"\"\"Downloads and prepares resources for the evaluation module.\n# \n#         This is the internal implementation to overwrite called when user calls\n#         `download_and_prepare`. It should download all required resources for the evaluation module.\n# \n#         Args:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n#         local_imports = _download_additional_modules(\n#             name=self.name,\n#             base_path=str(Path(self.path).parent),\n#             imports=imports,\n#             download_config=self.download_config,\n#         )\n#         # copy the script and the files in an importable directory\n#         dynamic_modules_path = self.dynamic_modules_path if self.dynamic_modules_path else init_dynamic_modules()\n#         module_path, hash = _create_importable_file(\n#             local_path=self.path,\n#             local_imports=local_imports,\n#             additional_files=[],\n#             dynamic_modules_path=dynamic_modules_path,\n#             module_namespace=self.module_type,\n#             name=self.name,\n#             download_mode=self.download_mode,\n#         )\n#         # make the new module to be noticed by the import system\n#         importlib.invalidate_caches()\n#         return ImportableModule(module_path, hash)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n# \n#     Metrics codes are cached inside the the dynamic modules cache to allow easy import (avoid ugly sys.path tweaks).\n# \n#     Args:\n# \n#         path (str): Path or name of the metric script.\n# \n#             - if ``path`` is a local metric script or a directory containing a local metric script (if the script has the same name as the directory):\n#               -> load the module from the metric script\n#               e.g. ``'./metrics/accuracy'`` or ``'./metrics/accuracy/accuracy.py'``.\n#             - if ``path`` is a metric on the Hugging Face Hub (ex: `glue`, `squad`)\n#               -> load the module from the metric script in the github repository at huggingface/datasets\n#               e.g. ``'accuracy'`` or ``'rouge'``.\n# \n#         revision (Optional ``Union[str, datasets.Version]``):\n#             If specified, the module will be loaded from the datasets repository at this version.\n#             By default:\n#             - it is set to the local version of the lib.\n#             - it will also try to load it from the master branch if it's not available at the local version of the lib.\n#             Specifying a version that is different from your local version of the lib might cause compatibility issues.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/module.py\n# --------------------------------------------------\n# \n#         self._download_and_prepare(dl_manager)\n# \n#     def _download_and_prepare(self, dl_manager):\n#         \"\"\"Downloads and prepares resources for the evaluation module.\n# \n#         This is the internal implementation to overwrite called when user calls\n#         `download_and_prepare`. It should download all required resources for the evaluation module.\n# \n#         Args:\n#             dl_manager (:class:`DownloadManager`): `DownloadManager` used to download and cache data.\n#         \"\"\"\n#         return None\n# \n#     def _compute(self, *, predictions=None, references=None, **kwargs) -> Dict[str, Any]:\n#         \"\"\"This method defines the common API for all the evaluation module in the library\"\"\"\n#         raise NotImplementedError\n# \n#     def __del__(self):\n#         if hasattr(self, \"filelock\") and self.filelock is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/conftest.py\n# --------------------------------------------------\n#     test_hf_evaluate_cache = test_hf_cache_home / \"datasets\"\n#     test_hf_metrics_cache = test_hf_cache_home / \"metrics\"\n#     test_hf_modules_cache = test_hf_cache_home / \"modules\"\n#     monkeypatch.setattr(\"evaluate.config.HF_EVALUATE_CACHE\", str(test_hf_evaluate_cache))\n#     monkeypatch.setattr(\"evaluate.config.HF_METRICS_CACHE\", str(test_hf_metrics_cache))\n#     monkeypatch.setattr(\"evaluate.config.HF_MODULES_CACHE\", str(test_hf_modules_cache))\n#     test_DOWNLOADED_EVALUATE_PATH = test_hf_evaluate_cache / \"downloads\"\n#     monkeypatch.setattr(\"evaluate.config.DOWNLOADED_EVALUATE_PATH\", str(test_DOWNLOADED_EVALUATE_PATH))\n#     test_EXTRACTED_EVALUATE_PATH = test_hf_evaluate_cache / \"downloads\" / \"extracted\"\n#     monkeypatch.setattr(\"evaluate.config.EXTRACTED_EVALUATE_PATH\", str(test_EXTRACTED_EVALUATE_PATH))\n# \n# \n# @pytest.fixture(autouse=True, scope=\"session\")\n# def disable_tqdm_output():\n#     datasets.disable_progress_bar()\n# \n# \n# @pytest.fixture(autouse=True)\n# def set_update_download_counts_to_false(monkeypatch):\n#     # don't take tests into account when counting downloads\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n#             download_config=download_config,\n#         )\n#         if sub_directory is not None:\n#             local_import_path = os.path.join(local_import_path, sub_directory)\n#         local_imports.append((import_name, local_import_path))\n# \n#     # Check library imports\n#     needs_to_be_installed = set()\n#     for library_import_name, library_import_path in library_imports:\n#         try:\n#             lib = importlib.import_module(library_import_name)  # noqa F841\n#         except ImportError:\n#             needs_to_be_installed.add((library_import_name, library_import_path))\n#     if needs_to_be_installed:\n#         raise ImportError(\n#             f\"To be able to use {name}, you need to install the following dependencies\"\n#             f\"{[lib_name for lib_name, lib_path in needs_to_be_installed]} using 'pip install \"\n#             f\"{' '.join([lib_path for lib_name, lib_path in needs_to_be_installed])}' for instance'\"\n#         )\n#     return local_imports\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n_DATASETS_BUCKET_PREFIX\n    else:\n        endpoint = config.CLOUDFRONT_METRICS_DISTRIB_PREFIX if use_cdn else config.S3_METRICS_BUCKET_PREFIX\n    return \"/\".join((endpoint, identifier, filename))\n\n\ndef head_hf_s3(\n    identifier: str, filename: str, use_cdn=False, dataset=True, max_retries=0\n) -> Union[requests.Response, Exception]:\n    return http_head(\n        hf_bucket_url(identifier=identifier, filename=filename, use_cdn=use_cdn, dataset=dataset),\n        max_retries=max_retries,\n    )\n\n\ndef hf_hub_url(path: str, name: str, revision: Optional[str] = None) -> str:\n    revision = revision or config.HUB_DEFAULT_VERSION\n    return config.HUB_EVALUATE_URL.format(path=path, name=name, revision=revision)\n\n\ndef url_or_path_join(base_name: str, *pathnames: str) -> str:\n    if is_remote_url(base_name):\n        return posixpath.join(base_name, *(str(pathname).replace(os.sep, \"/\").lstrip(\"/\") for pathname in pathnames))\n    else:\n        return Path(base_name, *pathnames).as_posix()\n\n\ndef url_or_path_parent(url_or_path: str) -> str:\n    if is_remote_url(url_or_path):\n        return url_or_path[: url_or_path.rindex(\"/\")]\n    else:\n        return os.path.dirname(url_or_path)\n\n\ndef hash_url_to_filename(url, etag=None):\n    \"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    If the url ends with .h5 (Keras HDF5 weights) adds '.h5' to the name\n    so that TF 2.0 can identify it as a HDF5 file\n    (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n    \"\"\"\n    url_bytes = url.encode(\"utf-8\")\n    url_hash = sha256(url_bytes)\n    filename = url_hash.hexdigest()\n\n    if etag:\n        etag_bytes = etag.encode(\"utf-8\")\n        etag_hash = sha256(etag_bytes)\n        filename += \".\" + etag_hash.hexdigest()\n\n    if url.endswith(\".py\"):\n        filename += \".py\"\n\n    return filename\n\n\n@dataclass\nclass DownloadConfig:\n    \"\"\"Configuration for our cached path manager.\n\n    Attributes:\n        cache_dir (:obj:`str` or :obj:`Path`, optional): Specify a cache directory to save the file to (overwrite the\n            default cache dir).\n        force_download (:obj:`bool`, default ``False``): If True, re-dowload the file even if it's already cached in\n            the cache dir.\n        resume_download (:obj:`bool`, default ``False``): If True, resume the download if incompletly recieved file is\n            found.\n        proxies (:obj:`dict`, optional):\n        user_agent (:obj:`str`, optional): Optional string or dict that will be appended to the user-agent on remote\n            requests.\n        extract_compressed_file (:obj:`bool`, default ``False``): If True and the path point to a zip or tar file,\n            extract the compressed file in a folder along the archive.\n        force_extract (:obj:`bool`, default ``False``): If True when extract_compressed_file is True and the archive\n            was already extracted, re-extract the archive and override the folder where it was extracted.\n        delete_extracted (:obj:`bool`, default ``False``): Whether to delete (or keep) the extracted files.\n        use_etag (:obj:`bool`, default ``True``): Whether to use the ETag HTTP response header to validate the cached files.\n        num_proc (:obj:`int`, optional): The number of processes to launch to download the files in parallel.\n        max_retries (:obj:`int`, default ``1``): The number of times to retry an HTTP request if it fails.\n        use_auth_token (:obj:`str` or :obj:`bool`, optional): Optional string or boolean to use as Bearer token\n            for remote files on the Datasets Hub. If True, will get token from ~/.huggingface.\n        ignore_url_params (:obj:`bool`, default ``False``): Whether to strip all query parameters and #fragments from\n            the download URL before using it for caching the file.\n        download_desc (:obj:`str`, optional): A description to be displayed alongside with the progress bar while downloading the files.\n    \"\"\"\n\n    cache_dir: Optional[Union[str, Path]] = None\n    force_download: bool = False\n    resume_download: bool = False\n    local_files_only: bool = False\n    proxies: Optional[Dict] = None\n    user_agent: Optional[str] = None\n    extract_compressed_file: bool = False\n    force_extract: bool = False\n    delete_extracted: bool = False\n    use_etag: bool = True\n    num_proc: Optional[int] = None\n    max_retries: int = 1\n    use_auth_token: Optional[Union[str, bool]] = None\n    ignore_url_params: bool = False\n    download_desc: Optional[str] = None\n\n    def copy(self) -> \"DownloadConfig\":\n        return self.__class__(**{k: copy.deepcopy(v) for k, v in self.__dict__.items()})\n\n\ndef cached_path(\n    url_or_filename,\n    download_config=None,\n    **download_kwargs,\n) -> str:\n    \"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n\n    Return:\n        Local path (string)\n\n    Raises:\n        FileNotFoundError: in case of non-recoverable file\n            (non-existent or no cache on disk)\n        ConnectionError: in case of unreachable url\n            and no cache on disk\n        ValueError: if it couldn't parse the url or filename correctly\n        requests.exceptions.ConnectionError: in case of internet connection issue\n    \"\"\"\n    if download_config is None:\n        download_config = DownloadConfig(**download_kwargs)\n\n    cache_dir = download_config.cache_dir or config.DOWNLOADED_EVALUATE_PATH\n    if isinstance(cache_dir, Path):\n        cache_dir = str(cache_dir)\n    if isinstance(url_or_filename, Path):\n        url_or_filename = str(url_or_filename)\n\n    if is_remote_url(url_or_filename):\n        # URL, so get it from the cache (downloading if necessary)\n        output_path = get_from_cache(\n            url_or_filename,\n            cache_dir=cache_dir,\n            force_download=download_config.force_download,\n            proxies=download_config.proxies,\n            resume_download=download_config.resume_download,\n            user_agent=download_config.user_agent,\n            local_files_only=download_config.local_files_only,\n            use_etag=download_config.use_etag,\n            max_retries=download_config.max_retries,\n            use_auth_token=download_config.use_auth_token,\n            ignore_url_params=download_config.ignore_url_params,", "choices": [{"text": "download_config=download_config,"}], "metadata": {"task_id": "huggingface_evaluate/92", "ground_truth": "            download_desc=download_config.download_desc,", "fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "context_start_lineno": 83, "line_no": 235, "query_window": {"context": "    cache_dir = download_config.cache_dir or config.DOWNLOADED_EVALUATE_PATH\n    if isinstance(cache_dir, Path):\n        cache_dir = str(cache_dir)\n    if isinstance(url_or_filename, Path):\n        url_or_filename = str(url_or_filename)\n\n    if is_remote_url(url_or_filename):\n        # URL, so get it from the cache (downloading if necessary)\n        output_path = get_from_cache(\n            url_or_filename,\n            cache_dir=cache_dir,\n            force_download=download_config.force_download,\n            proxies=download_config.proxies,\n            resume_download=download_config.resume_download,\n            user_agent=download_config.user_agent,\n            local_files_only=download_config.local_files_only,\n            use_etag=download_config.use_etag,\n            max_retries=download_config.max_retries,\n            use_auth_token=download_config.use_auth_token,\n            ignore_url_params=download_config.ignore_url_params,", "metadata": {"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 235, "task_id": "huggingface_evaluate/92", "start_line_no": 215, "end_line_no": 235, "window_size": 20, "context_start_lineno": 83, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "            )\n        if import_type == \"internal\":\n            url_or_filename = url_or_path_join(base_path, import_path + \".py\")\n        elif import_type == \"external\":\n            url_or_filename = import_path\n        else:\n            raise ValueError(\"Wrong import_type\")\n\n        local_import_path = cached_path(\n            url_or_filename,\n            download_config=download_config,\n        )\n        if sub_directory is not None:\n            local_import_path = os.path.join(local_import_path, sub_directory)\n        local_imports.append((import_name, local_import_path))\n\n    # Check library imports\n    needs_to_be_installed = set()\n    for library_import_name, library_import_path in library_imports:\n        try:", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.18461538461538463}, {"context": "import pytest\nfrom datasets import config\nfrom datasets.arrow_dataset import Dataset\nfrom datasets.features import ClassLabel, Features, Sequence, Value\n\n\n@pytest.fixture(autouse=True)\ndef set_test_cache_config(tmp_path_factory, monkeypatch):\n    # test_hf_cache_home = tmp_path_factory.mktemp(\"cache\")  # TODO: why a cache dir per test function does not work?\n    test_hf_cache_home = tmp_path_factory.getbasetemp() / \"cache\"\n    test_hf_evaluate_cache = test_hf_cache_home / \"datasets\"\n    test_hf_metrics_cache = test_hf_cache_home / \"metrics\"\n    test_hf_modules_cache = test_hf_cache_home / \"modules\"\n    monkeypatch.setattr(\"evaluate.config.HF_EVALUATE_CACHE\", str(test_hf_evaluate_cache))\n    monkeypatch.setattr(\"evaluate.config.HF_METRICS_CACHE\", str(test_hf_metrics_cache))\n    monkeypatch.setattr(\"evaluate.config.HF_MODULES_CACHE\", str(test_hf_modules_cache))\n    test_DOWNLOADED_EVALUATE_PATH = test_hf_evaluate_cache / \"downloads\"\n    monkeypatch.setattr(\"evaluate.config.DOWNLOADED_EVALUATE_PATH\", str(test_DOWNLOADED_EVALUATE_PATH))\n    test_EXTRACTED_EVALUATE_PATH = test_hf_evaluate_cache / \"downloads\" / \"extracted\"\n    monkeypatch.setattr(\"evaluate.config.EXTRACTED_EVALUATE_PATH\", str(test_EXTRACTED_EVALUATE_PATH))", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "conftest.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.17901234567901234}, {"context": "        \"\"\"\n        if dl_manager is None:\n            if download_config is None:\n                download_config = DownloadConfig()\n                download_config.cache_dir = os.path.join(self.data_dir, \"downloads\")\n                download_config.force_download = False\n\n            dl_manager = DownloadManager(\n                dataset_name=self.name, download_config=download_config, data_dir=self.data_dir\n            )\n\n        self._download_and_prepare(dl_manager)\n\n    def _download_and_prepare(self, dl_manager):\n        \"\"\"Downloads and prepares resources for the evaluation module.\n\n        This is the internal implementation to overwrite called when user calls\n        `download_and_prepare`. It should download all required resources for the evaluation module.\n\n        Args:", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "line_no": 700, "start_line_no": 690, "end_line_no": 710, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.17777777777777778}, {"context": "    module_type: Optional[str] = None,\n    revision: Optional[Union[str, Version]] = None,\n    download_config: Optional[DownloadConfig] = None,\n    download_mode: Optional[DownloadMode] = None,\n    force_local_path: Optional[str] = None,\n    dynamic_modules_path: Optional[str] = None,\n    **download_kwargs,\n) -> ImportableModule:\n    \"\"\"\n    Download/extract/cache a metric module.\n\n    Metrics codes are cached inside the the dynamic modules cache to allow easy import (avoid ugly sys.path tweaks).\n\n    Args:\n\n        path (str): Path or name of the metric script.\n\n            - if ``path`` is a local metric script or a directory containing a local metric script (if the script has the same name as the directory):\n              -> load the module from the metric script\n              e.g. ``'./metrics/accuracy'`` or ``'./metrics/accuracy/accuracy.py'``.", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 570, "start_line_no": 560, "end_line_no": 580, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.17532467532467533}, {"context": "        self.path = path\n        self.module_type = module_type\n        self.name = Path(path).stem\n        self.download_config = download_config or DownloadConfig()\n        self.download_mode = download_mode\n        self.dynamic_modules_path = dynamic_modules_path\n\n    def get_module(self) -> ImportableModule:\n        # get script and other files\n        imports = get_imports(self.path)\n        local_imports = _download_additional_modules(\n            name=self.name,\n            base_path=str(Path(self.path).parent),\n            imports=imports,\n            download_config=self.download_config,\n        )\n        # copy the script and the files in an importable directory\n        dynamic_modules_path = self.dynamic_modules_path if self.dynamic_modules_path else init_dynamic_modules()\n        module_path, hash = _create_importable_file(\n            local_path=self.path,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.17424242424242425}, {"context": "            download_config ([`DownloadConfig`], *optional*):\n                Specific download configuration parameters.\n            dl_manager ([`DownloadManager`], *optional*):\n                Specific download manager to use.\n\n        Example:\n\n        ```py\n        >>> import evaluate\n        ```\n        \"\"\"\n        if dl_manager is None:\n            if download_config is None:\n                download_config = DownloadConfig()\n                download_config.cache_dir = os.path.join(self.data_dir, \"downloads\")\n                download_config.force_download = False\n\n            dl_manager = DownloadManager(\n                dataset_name=self.name, download_config=download_config, data_dir=self.data_dir\n            )", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "module.py"], "line_no": 690, "start_line_no": 680, "end_line_no": 700, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1721311475409836}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/common.py\n# --------------------------------------------------\n#   def _copy_core(self, ns: Namespace) -> 'Metadata':\n#     \"\"\"Shallow copy: metadata is shared, default namespace changes.\n# \n#     Args:\n#       ns: the namespace to use for the new object.\n# \n#     Returns:\n#       A copy of the object.\n#     \"\"\"\n#     md = Metadata()\n#     md._namespace = ns  # pylint: disable='protected-access'\n#     md._stores = self._stores  # pylint: disable='protected-access'\n#     md._store = md._stores[md._namespace]  # pylint: disable='protected-access'\n#     return md\n# \n#   def update(self, *args: Union[Dict[str, MetadataValue],\n#                                 Iterable[Tuple[str, MetadataValue]]],\n#              **kwargs: MetadataValue) -> None:\n#     self._store.update(*args, **kwargs)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#     Args:\n#       parameters:\n# \n#     Returns:\n#       Always returns True unless an exception is Raised.\n# \n#     Raises:\n#       InvalidParameterError: If parameters are invalid.\n#       NotImplementedError: If parameter type is unknown\n#     \"\"\"\n#     if self.is_conditional:\n#       raise NotImplementedError('Not implemented for conditional space.')\n#     if len(parameters) != len(self._parameter_configs.values()):\n#       set1 = set(pc.name for pc in self._parameter_configs.values())\n#       set2 = set(parameters)\n#       raise InvalidParameterError(\n#           f'Search space has {len(self._parameter_configs.values())} parameters '\n#           f'but only {len(parameters)} were given. '\n#           f'Missing in search space: {set2 - set1}. '\n#           f'Missing in parameters: {set1 - set2}.')\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n# class Measurement:\n#   \"\"\"Collection of metrics with a timestamp.\"\"\"\n# \n#   def _value_is_finite(self, _, value):\n#     if not (np.isfinite(value) and value >= 0):\n#       raise ValueError('Must be finite and non-negative.')\n# \n#   # Should be used as a regular Dict.\n#   metrics: _MetricDict = attr.ib(\n#       init=True,\n#       converter=lambda d: _MetricDict(**d),\n#       default=_MetricDict(),\n#       validator=attr.validators.instance_of(_MetricDict),\n#       on_setattr=[attr.setters.convert, attr.setters.validate])\n# \n#   elapsed_secs: float = attr.ib(\n#       converter=float,\n#       init=True,\n#       default=0,\n#       validator=[attr.validators.instance_of(float), _value_is_finite],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/common.py\n# --------------------------------------------------\n#   \"\"\"\n# \n#   _as_tuple: Tuple[str, ...] = attr.field(hash=True, eq=True, order=True)\n# \n#   def __init__(self, arg: Iterable[str] = ()):\n#     \"\"\"Generates a Namespace from its component strings.\n# \n#     Args:\n#       arg: a tuple representation of a namespace.\n#     \"\"\"\n#     arg = tuple(arg)\n#     self.__attrs_init__(as_tuple=arg)\n# \n#   _ns_repr_table = str.maketrans({':': r'\\:'})\n# \n#   @classmethod\n#   def decode(cls, s: str) -> 'Namespace':\n#     r\"\"\"Decode a string into a Namespace.\n# \n#     For a Namespace x, Namespace.decode(x.encode()) == x.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/base_study_config.py\n# --------------------------------------------------\n#     which would incorrectly use the default_value when min_value == 0, and\n#     requires default_value to have been computed.\n# \n#     Args:\n#       default_value_fn: Default value if min_value is not finite.\n#     \"\"\"\n#     if np.isfinite(self.min_value):\n#       return self.min_value\n#     else:\n#       return default_value_fn()\n# \n#   def max_value_or(self, default_value_fn: Callable[[], float]) -> float:\n#     \"\"\"Returns the minimum value if finite, or default_value_fn().\n# \n#     Avoids the common pitfalls of using\n#       `metric.max_value or default_value`\n#     which would incorrectly use the default_value when max_value == 0, and\n#     requires default_value to have been computed.\n# \n#     Args:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/gaussian_process_ard.py\n# --------------------------------------------------\n#     # pylint: disable=g-doc-return-or-yield\n#     \"\"\"The coroutine that specifies the GP model.\n# \n#     Args:\n#       inputs: index_points to be provided to the GP.\n# \n#     Yields:\n#       `ModelParameter`s describing the parameters to be declared in the Flax\n#         model.\n# \n#     Returns:\n#       A tfd.GaussianProcess with the given index points.\n#     \"\"\"\n#     amplitude = yield sp_model.ModelParameter.from_prior(\n#         tfd.LogNormal(0.0, 1.0, name='amplitude'),\n#         constraint=sp_model.Constraint(bounds=(jnp.array(0.0), None)),\n#     )\n#     kernel = self._kernel_class(\n#         amplitude=amplitude,\n#         length_scale=1.,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/jax/stochastic_process_model.py\n# --------------------------------------------------\n# \n#   @classmethod\n#   def from_prior(cls,\n#                  prior: tfd.Distribution,\n#                  constraint: Optional[Constraint] = None) -> 'ModelParameter':\n#     \"\"\"Builds a `ModelParameter` from a `tfd.Distribution`.\n# \n#     If `constraint` or `constraint.bijector` is None, then the constraint\n#     bijector is assumed to be the prior distribution's default event space\n#     bijector. See\n#     https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution#experimental_default_event_space_bijector\n# \n#     Args:\n#       prior: Parameter prior distribution.\n#       constraint: The parameter constraint.\n# \n#     Returns:\n#       model_parameter: The parameter specification with the given prior.\n#     \"\"\"\n#     if constraint is None or constraint.bounds is None:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nParameter(\n        init_fn=init_fn,\n        name=prior.name,\n        constraint=Constraint(bounds=bounds, bijector=bijector),\n        regularizer=lambda x: -prior.log_prob(x),\n    )\n\n\nModelParameterGenerator = Generator[ModelParameter, Array, _D]\n\n\nclass ModelCoroutine(Protocol, Generic[_In, _D]):\n  \"\"\"`Protocol` to avoid inheritance.\n\n  The coroutine pattern allows the `ModelParameter` objects, and the assembly of\n  parameters into the kernel and stochastic process, to be specified\n  simultaneously. The `StochasticProcessModel` Flax module runs the coroutine\n  to initialize Flax parameters and build stochastic process objects.\n\n  When a `ModelCoroutine` is called, it returns a generator-iterator, which\n  should be iterated to build the `ModelParameter`s and the stochastic process\n  object. See the full protocol below.\n  \"\"\"\n\n  def __call__(self,\n               inputs: Optional[_In] = None) -> ModelParameterGenerator[_D]:\n    \"\"\"Coroutine function to be called from `StochasticProcessModel`.\n\n    The coroutine is implemented via an enhanced generator\n    (https://peps.python.org/pep-0342/). The generator-iterator returned by this\n    method corresponds to the pytype\n    `Generator[YieldType, SendType, ReturnType]`. (Python also has a newer, more\n    flexible `Coroutine` type declared with `async`/`await` syntax. Here, when\n    we reference \"coroutines,\" we're referring to the simpler, more restrictive\n    generator-based implementation.)\n\n    The expected protocol is to run the coroutine for two different use cases:\n\n    1) To build the Flax model.\n    2) To implement Flax model forward passes.\n\n    During (1), a new Flax model parameter is declared with the `name` and\n    `init_fn` of each `ModelParameter` yielded by the generator. The initial\n    values of each Flax parameter are generated by the `init_fn` and then sent\n    into the generator as the left-hand sides of the yield statements. Once all\n    `ModelParameter`s are yielded, the generator raises a `StopIteration`, and\n    `StopIteration.value` contains a `tfd.Distribution` representing a\n    stochastic process (e.g. `tfd.GaussianProcess` or `tfd.StudentTProcess`).\n    During Flax module initialization, the returned `tfd.Distribution` is\n    ignored.\n\n    During (2), for each `ModelParameter` yielded by the generator, the Flax\n    module accesses the Flax parameter of the same name, regularizes it (if\n    applicable), sends the value into the generator, and stores the value of the\n    regularization loss in a Flax mutable variable collection. Once all\n    `ModelParameter`s are yielded, the generator raises a `StopIteration`, and\n    `StopIteration.value` contains a `tfd.Distribution` on the provided index\n    points. The module's `__call__` method returns this distribution.\n\n    Example:\n\n    ```python\n    # Define a coroutine for a simple Gaussian Process model with trainable\n    # kernel amplitude and observation noise variance.\n    def model_coroutine(inputs=None):\n      amplitude_constraint = Constraint(\n          bounds=(jnp.zeros([]), None), bijector=tfb.Exp())\n      amplitude = yield ModelParameter(\n          init_fn=jax.random.exponential,\n          regularizer=lambda x: 1e-3 * x**2,\n          constraint=amplitude_constraint,\n          name='amplitude')\n      kernel = tfpk.ExponentiatedQuadratic(amplitude=amplitude)\n      observation_noise = yield ModelParameter.from_prior(\n          tfd.LogNormal(0.0, 1.0, name='observation_noise'),\n          constraint=Constraint(bounds=(jnp.zeros([]), None)))\n      return tfd.GaussianProcess(kernel=kernel, index_points=inputs,\n          observation_noise_variance=observation_noise)\n    ```\n\n    Args:\n      inputs: An ArrayTree of index points or None.\n    \"\"\"\n    pass\n\n\nclass StochasticProcessModel(nn.Module, Generic[_In]):\n  \"\"\"Builds a Stochastic Process Flax module.\n\n  The module is instantiated with a coroutine in the pattern of\n  `ModelCoroutine` and represents a trainable stochastic process\n  (typically a `tfd.GaussianProcess` or `tfd.StudentTProcess`.)\n\n  The module may also be passed a `mean_fn`, which is evaluated at the input\n  points and returns the mean of the stochastic process (default is a constant\n  zero mean).\n\n  Examples:\n\n  ```python\n  from jax import random\n\n  # Simulate some observed data.\n  dim = 3\n  x_observed = random.uniform(random.PRNGKey(0), shape=(20, dim))\n  y_observed = x_observed.sum(axis=-1)\n\n  # Build a GP module. `coro` follows the `ModelCoroutine` protocol.\n  coro = GaussianProcessARD(dimension=dim)\n  gp_model = StochasticProcessModel(coroutine=coro)\n\n  # Initialize the Flax parameters.\n  init_params = gp_model.init(random.PRNGKey(1), x_observed)\n\n  # Build a GP with `x_observed` as index points. By default, `apply` invokes\n  # the Flax module's `__call__` method.\n  gp, regularization_losses = gp_model.apply(\n      init_params,\n      x_observed,\n      mutable=('losses',))\n\n  # Run the expensive computation (often a Cholesky decomposition) necessary to\n  # compute the GP posterior predictive, and return the predictive distribution\n  # as mutable state.\n  _, pp_state = gp_model.apply(\n      {'params': init_state['params']},\n      x_observed,\n      y_observed,\n      method=gp_model.precompute_predictive,\n      mutable=('predictive'))\n\n  # Now, posterior predictive GPs over different sets of index points,\n  # conditioned on the observed data `x_observed` and `y_observed`, can be built\n  # without recomputing the Cholesky decomposition.\n  x_predicted = random.uniform(random.PRNGKey(2), shape=(5, dim))\n  pp_dist = gp_model.apply(\n      {'params': init_state['params'], **pp_state},\n      x_predicted,\n      method=gp_model.predict)\n  ```\n  \"\"\"\n\n  coroutine: ModelCoroutine\n  mean_fn: Callable[[_In], Array] = lambda _: 0.0\n\n  def setup(self):\n    \"\"\"Builds module parameters.\"\"\"\n    generator = self.coroutine()\n    try:\n      p: ModelParameter = next(generator)\n      while True:\n        # Declare a Flax variable with the name and initialization function from\n        # the `ModelParameter`.\n        param: Array = self.param(p.name, p.init_fn)\n        p: ModelParameter = generator.send(param)\n    except StopIteration:\n      # Ignore the return value from the generator since this method only builds\n      # the Flax parameters.\n      pass\n\n  def __call__(self, x: _In) -> _D:\n    \"\"\"Returns a stochastic process distribution.\n\n    If the Flax module's `apply` method is called with `mutable=True` or\n    `mutable=('losses,')` regularization losses are additionally returned.\n\n    Args:\n      x: ArrayTree of index points in the constrained space.\n\n    Returns:\n      dist: `tfd.Distribution` instance with x as index points.\n    \"\"\"\n    gen = self.coroutine(inputs=x)\n    if self.is_initializing() and isinstance(self.mean_fn, nn.Module):\n      _ = self.mean_fn(x)  # Call mean_fn so its parameters are initialized.\n    try:\n      p: ModelParameter = next(gen)", "choices": [{"text": "yield ModelParameter("}], "metadata": {"task_id": "google_vizier/68", "ground_truth": "      while True:", "fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model.py"], "context_start_lineno": 192, "line_no": 369, "query_window": {"context": "      # the Flax parameters.\n      pass\n\n  def __call__(self, x: _In) -> _D:\n    \"\"\"Returns a stochastic process distribution.\n\n    If the Flax module's `apply` method is called with `mutable=True` or\n    `mutable=('losses,')` regularization losses are additionally returned.\n\n    Args:\n      x: ArrayTree of index points in the constrained space.\n\n    Returns:\n      dist: `tfd.Distribution` instance with x as index points.\n    \"\"\"\n    gen = self.coroutine(inputs=x)\n    if self.is_initializing() and isinstance(self.mean_fn, nn.Module):\n      _ = self.mean_fn(x)  # Call mean_fn so its parameters are initialized.\n    try:\n      p: ModelParameter = next(gen)", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model.py"], "line_no": 369, "task_id": "google_vizier/68", "start_line_no": 349, "end_line_no": 369, "window_size": 20, "context_start_lineno": 192, "repo": "google_vizier"}}, "top_k_context": [{"context": "    init_fn: Initializes parameter values.\n    constraint: Parameter constraint.\n    regularizer: Regularizes the parameter.\n  \"\"\"\n\n  name: str = attr.field()\n  init_fn: InitFn = attr.field()\n  constraint: Optional[Constraint] = attr.field(default=None)\n  regularizer: Callable[[Array], Array] = attr.field(\n      kw_only=True, default=lambda x: jnp.zeros([], dtype=x.dtype))\n\n  @classmethod\n  def from_prior(cls,\n                 prior: tfd.Distribution,\n                 constraint: Optional[Constraint] = None) -> 'ModelParameter':\n    \"\"\"Builds a `ModelParameter` from a `tfd.Distribution`.\n\n    If `constraint` or `constraint.bijector` is None, then the constraint\n    bijector is assumed to be the prior distribution's default event space\n    bijector. See", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "stochastic_process_model.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.22905027932960895}, {"context": "    \"\"\"\n    self.dimension = dimension\n    self._kernel_class = kernel_class\n    self._use_tfp_runtime_validation = use_tfp_runtime_validation\n\n  def __call__(\n      self, inputs: Optional[Array] = None\n  ) -> Generator[sp_model.ModelParameter, Array, tfd.GaussianProcess]:\n    # TODO: Determine why pylint doesn't allow both Returns and\n    # Yields sections.\n    # pylint: disable=g-doc-return-or-yield\n    \"\"\"The coroutine that specifies the GP model.\n\n    Args:\n      inputs: index_points to be provided to the GP.\n\n    Yields:\n      `ModelParameter`s describing the parameters to be declared in the Flax\n        model.\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "jax", "gaussian_process_ard.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.21965317919075145}, {"context": "      converter=lambda x: float(x) if x is not None else np.inf,\n      validator=[attr.validators.instance_of(float), _max_geq_min],\n      on_setattr=attr.setters.validate,\n      kw_only=True)\n\n  def min_value_or(self, default_value_fn: Callable[[], float]) -> float:\n    \"\"\"Returns the minimum value if finite, or default_value_fn().\n\n    Avoids the common pitfalls of using\n      `metric.min_value or default_value`\n    which would incorrectly use the default_value when min_value == 0, and\n    requires default_value to have been computed.\n\n    Args:\n      default_value_fn: Default value if min_value is not finite.\n    \"\"\"\n    if np.isfinite(self.min_value):\n      return self.min_value\n    else:\n      return default_value_fn()", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "base_study_config.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2138728323699422}, {"context": "    (This is a two-component namespace.)\n  * Colons are encoded as r'\\:':\n    Namespace.decode('a\\\\:b') == Namespace(('a:b')).\n    (This is a single-component namespace.)\n\n  Conversions: For a Namespace x,\n  * Namespace.decode(x.encode()) == x; here, x.encode() will be a string with\n    colons separating the components.\n  * Namespaces act as a Sequence[str], so Namespace(tuple(x)) == x and\n    Namespace(x) == x.\n  \"\"\"\n\n  _as_tuple: Tuple[str, ...] = attr.field(hash=True, eq=True, order=True)\n\n  def __init__(self, arg: Iterable[str] = ()):\n    \"\"\"Generates a Namespace from its component strings.\n\n    Args:\n      arg: a tuple representation of a namespace.\n    \"\"\"", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "common.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2111111111111111}, {"context": "      return default\n\n  def __setitem__(self, key: str, value: Union[float, Metric]):\n    if isinstance(value, Metric):\n      self.data.__setitem__(key, value)\n    else:\n      self.data.__setitem__(key, Metric(value=value))\n\n\n@attr.s(auto_attribs=True, frozen=False, init=True, slots=True)\nclass Measurement:\n  \"\"\"Collection of metrics with a timestamp.\"\"\"\n\n  def _value_is_finite(self, _, value):\n    if not (np.isfinite(value) and value >= 0):\n      raise ValueError('Must be finite and non-negative.')\n\n  # Should be used as a regular Dict.\n  metrics: _MetricDict = attr.ib(\n      init=True,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.21052631578947367}, {"context": "  def contains(self, parameters: trial.ParameterDict) -> bool:\n    try:\n      self.assert_contains(parameters)\n      return True\n    except InvalidParameterError:\n      return False\n\n  def assert_contains(self, parameters: trial.ParameterDict) -> bool:\n    \"\"\"Throws an error if parameters is not a valid point in the space.\n\n    Args:\n      parameters:\n\n    Returns:\n      Always returns True unless an exception is Raised.\n\n    Raises:\n      InvalidParameterError: If parameters are invalid.\n      NotImplementedError: If parameter type is unknown\n    \"\"\"", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 1200, "start_line_no": 1190, "end_line_no": 1210, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.20945945945945946}, {"context": "  def __copy__(self) -> 'Metadata':\n    \"\"\"Shallow copy -- metadata continues to be shared.\n\n    Returns:\n      A copy of the object.\n    \"\"\"\n    return self._copy_core(self._namespace)\n\n  # END OF Abstract methods inherited from `MutableMapping` base class.\n\n  def _copy_core(self, ns: Namespace) -> 'Metadata':\n    \"\"\"Shallow copy: metadata is shared, default namespace changes.\n\n    Args:\n      ns: the namespace to use for the new object.\n\n    Returns:\n      A copy of the object.\n    \"\"\"\n    md = Metadata()", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "common.py"], "line_no": 560, "start_line_no": 550, "end_line_no": 570, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2052980132450331}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/deep_ensemble/deep_ensemble_repositories.py\n# --------------------------------------------------\n#         else:\n#             for i in range(self.ensemble_size):\n#                 _update(i)\n# \n#     def extract(\n#         self,\n#         keys: List[str],\n#         i: int = None,\n#         checkpoint_path: Optional[Path] = None,\n#         prefix: str = \"checkpoint_\",\n#         **kwargs\n#     ) -> Union[Dict, List[Dict]]:\n#         def _extract(_i):\n#             return self.state[_i].extract(\n#                 keys=keys, checkpoint_path=checkpoint_path, prefix=prefix, **kwargs\n#             )\n# \n#         if i is not None:\n#             return _extract(i)\n#         dicts = []\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_plot.py\n# --------------------------------------------------\n# \n# from fortuna.plot import plot_reliability_diagram\n# \n# \n# class TestStates(unittest.TestCase):\n#     def test_reliability_diagram(self):\n#         with tempfile.TemporaryDirectory() as tmp_dir:\n#             accs = [np.random.normal(size=20), np.random.normal(size=20)]\n#             confs = [np.random.normal(size=20), np.random.normal(size=20)]\n#             labels = [\"a\", \"b\"]\n#             plot_reliability_diagram(accs, confs)\n#             plot_reliability_diagram(accs[0], confs[0])\n#             plot_reliability_diagram(accs, confs, labels=labels)\n#             plot_reliability_diagram(\n#                 accs, confs, fname=os.path.join(tmp_dir, \"tmp.png\")\n#             )\n#             plot_reliability_diagram(\n#                 accs, confs, fname=os.path.join(tmp_dir, \"tmp.png\")\n#             )\n#             plot_reliability_diagram(accs, confs, title=\"bla\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/training/mixin.py\n# --------------------------------------------------\n#             prefix=prefix,\n#             parallel=True,\n#         )\n#         if d is None:\n#             raise ValueError(\n#                 f\"No checkpoint was found in `restore_checkpoint_path={restore_checkpoint_path}`.\"\n#             )\n#         name = \"\".join([chr(n) for n in d[\"encoded_name\"].tolist()])\n#         return name_to_train_state[name].value.init_from_dict(d, optimizer, **kwargs)\n# \n#     def get_path_latest_checkpoint(\n#         self, checkpoint_dir: Path, prefix: str = \"checkpoint_\"\n#     ) -> Optional[str]:\n#         return checkpoints.latest_checkpoint(ckpt_dir=checkpoint_dir, prefix=prefix)\n# \n# \n# class WithEarlyStoppingMixin:\n#     def __init__(\n#         self,\n#         *,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/deep_ensemble/deep_ensemble_repositories.py\n# --------------------------------------------------\n#             for i in range(ensemble_size)\n#         ]\n# \n#     def get(\n#         self,\n#         i: int = None,\n#         checkpoint_path: Optional[Path] = None,\n#         optimizer: Optional[OptaxOptimizer] = None,\n#         prefix: str = \"checkpoint_\",\n#         **kwargs\n#     ) -> Union[List[PosteriorState], PosteriorState]:\n#         def _get(_i):\n#             return self.state[_i].get(\n#                 checkpoint_path=checkpoint_path,\n#                 optimizer=optimizer,\n#                 prefix=prefix,\n#                 **kwargs\n#             )\n# \n#         if i is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/deep_ensemble/deep_ensemble_repositories.py\n# --------------------------------------------------\n#     ) -> Union[List[PosteriorState], PosteriorState]:\n#         def _get(_i):\n#             return self.state[_i].get(\n#                 checkpoint_path=checkpoint_path,\n#                 optimizer=optimizer,\n#                 prefix=prefix,\n#                 **kwargs\n#             )\n# \n#         if i is not None:\n#             return _get(i)\n#         state = []\n#         for i in range(self.ensemble_size):\n#             state.append(_get(i))\n#         return state\n# \n#     def put(\n#         self,\n#         state: PosteriorState,\n#         i: int = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/deep_ensemble/deep_ensemble_repositories.py\n# --------------------------------------------------\n#         variables: Dict,\n#         i: int = None,\n#         checkpoint_path: Path = None,\n#         optimizer: Optional[OptaxOptimizer] = None,\n#         keep: int = 1,\n#         prefix: str = \"checkpoint_\",\n#         **kwargs\n#     ):\n#         def _update(_i):\n#             self.state[_i].update(\n#                 variables=variables,\n#                 checkpoint_path=checkpoint_path,\n#                 optimizer=optimizer,\n#                 keep=keep,\n#                 prefix=prefix,\n#                 **kwargs\n#             )\n# \n#         if i is not None:\n#             _update(i)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/deep_ensemble/deep_ensemble_repositories.py\n# --------------------------------------------------\n#             _put(i)\n#         else:\n#             for i in range(self.ensemble_size):\n#                 state.append(_put(i))\n# \n#     def pull(\n#         self,\n#         i: int = None,\n#         checkpoint_path: Path = None,\n#         optimizer: Optional[OptaxOptimizer] = None,\n#         prefix: str = \"checkpoint_\",\n#         **kwargs\n#     ) -> Union[DeepEnsembleState, PosteriorState]:\n#         def _pull(_i):\n#             return self.state[_i].pull(\n#                 checkpoint_path=checkpoint_path,\n#                 optimizer=optimizer,\n#                 prefix=prefix,\n#                 **kwargs\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/deep_ensemble/deep_ensemble_repositories.py\n# --------------------------------------------------\n#         checkpoint_path: Optional[Path] = None,\n#         keep: int = 1,\n#         prefix: str = \"checkpoint_\",\n#     ) -> None:\n#         def _put(_i):\n#             return self.state[_i].put(\n#                 state=state, checkpoint_path=checkpoint_path, keep=keep, prefix=prefix\n#             )\n# \n#         if i is not None:\n#             _put(i)\n#         else:\n#             for i in range(self.ensemble_size):\n#                 state.append(_put(i))\n# \n#     def pull(\n#         self,\n#         i: int = None,\n#         checkpoint_path: Path = None,\n#         optimizer: Optional[OptaxOptimizer] = None,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport json\nimport os\nimport tempfile\nimport unittest\nfrom types import SimpleNamespace\n\nimport flax.linen as nn\nimport requests\nfrom jax import random\nfrom tqdm import tqdm\n\nfrom fortuna.model.cnn import CNN\nfrom fortuna.model.mlp import MLP\nfrom fortuna.model.linear import Linear\nfrom tests.make_data import make_array_random_inputs\n\n\ndef download(ckpt_dir, url):\n    name = url[url.rfind(\"/\") + 1 : url.rfind(\"?\")]\n    if ckpt_dir is None:\n        ckpt_dir = tempfile.gettempdir()\n    ckpt_dir = os.path.join(ckpt_dir, \"flaxmodels\")\n    ckpt_file = os.path.join(ckpt_dir, name)\n    if not os.path.exists(ckpt_file):\n        print(f'Downloading: \"{url[:url.rfind(\"?\")]}\" to {ckpt_file}')\n        if not os.path.exists(ckpt_dir):\n            os.makedirs(ckpt_dir)\n\n        response = requests.get(url, stream=True)\n        total_size_in_bytes = int(response.headers.get(\"content-length\", 0))\n        progress_bar = tqdm(total=total_size_in_bytes, unit=\"iB\", unit_scale=True)\n\n        # first create temp file, in case the download fails\n        ckpt_file_temp = os.path.join(ckpt_dir, name + \".temp\")\n        with open(ckpt_file_temp, \"wb\") as file:\n            for data in response.iter_content(chunk_size=1024):", "choices": [{"text": "file.write(data)"}], "metadata": {"task_id": "awslabs_fortuna/195", "ground_truth": "                progress_bar.update(len(data))", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_model.py"], "context_start_lineno": 0, "line_no": 36, "query_window": {"context": "\ndef download(ckpt_dir, url):\n    name = url[url.rfind(\"/\") + 1 : url.rfind(\"?\")]\n    if ckpt_dir is None:\n        ckpt_dir = tempfile.gettempdir()\n    ckpt_dir = os.path.join(ckpt_dir, \"flaxmodels\")\n    ckpt_file = os.path.join(ckpt_dir, name)\n    if not os.path.exists(ckpt_file):\n        print(f'Downloading: \"{url[:url.rfind(\"?\")]}\" to {ckpt_file}')\n        if not os.path.exists(ckpt_dir):\n            os.makedirs(ckpt_dir)\n\n        response = requests.get(url, stream=True)\n        total_size_in_bytes = int(response.headers.get(\"content-length\", 0))\n        progress_bar = tqdm(total=total_size_in_bytes, unit=\"iB\", unit_scale=True)\n\n        # first create temp file, in case the download fails\n        ckpt_file_temp = os.path.join(ckpt_dir, name + \".temp\")\n        with open(ckpt_file_temp, \"wb\") as file:\n            for data in response.iter_content(chunk_size=1024):", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_model.py"], "line_no": 36, "task_id": "awslabs_fortuna/195", "start_line_no": 16, "end_line_no": 36, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            return _get(i)\n        state = []\n        for i in range(self.ensemble_size):\n            state.append(_get(i))\n        return state\n\n    def put(\n        self,\n        state: PosteriorState,\n        i: int = None,\n        checkpoint_path: Optional[Path] = None,\n        keep: int = 1,\n        prefix: str = \"checkpoint_\",\n    ) -> None:\n        def _put(_i):\n            return self.state[_i].put(\n                state=state, checkpoint_path=checkpoint_path, keep=keep, prefix=prefix\n            )\n\n        if i is not None:", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "deep_ensemble", "deep_ensemble_repositories.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.20134228187919462}, {"context": "        checkpoint_path: Optional[Path] = None,\n        keep: int = 1,\n        prefix: str = \"checkpoint_\",\n    ) -> None:\n        def _put(_i):\n            return self.state[_i].put(\n                state=state, checkpoint_path=checkpoint_path, keep=keep, prefix=prefix\n            )\n\n        if i is not None:\n            _put(i)\n        else:\n            for i in range(self.ensemble_size):\n                state.append(_put(i))\n\n    def pull(\n        self,\n        i: int = None,\n        checkpoint_path: Path = None,\n        optimizer: Optional[OptaxOptimizer] = None,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "deep_ensemble", "deep_ensemble_repositories.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.1986754966887417}, {"context": "\n        if i is not None:\n            return _pull(i)\n        state = []\n        for i in range(self.ensemble_size):\n            state.append(_pull(i))\n        return state\n\n    def update(\n        self,\n        variables: Dict,\n        i: int = None,\n        checkpoint_path: Path = None,\n        optimizer: Optional[OptaxOptimizer] = None,\n        keep: int = 1,\n        prefix: str = \"checkpoint_\",\n        **kwargs\n    ):\n        def _update(_i):\n            self.state[_i].update(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "deep_ensemble", "deep_ensemble_repositories.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.1895424836601307}, {"context": "            for i in range(ensemble_size)\n        ]\n\n    def get(\n        self,\n        i: int = None,\n        checkpoint_path: Optional[Path] = None,\n        optimizer: Optional[OptaxOptimizer] = None,\n        prefix: str = \"checkpoint_\",\n        **kwargs\n    ) -> Union[List[PosteriorState], PosteriorState]:\n        def _get(_i):\n            return self.state[_i].get(\n                checkpoint_path=checkpoint_path,\n                optimizer=optimizer,\n                prefix=prefix,\n                **kwargs\n            )\n\n        if i is not None:", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "deep_ensemble", "deep_ensemble_repositories.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.18471337579617833}, {"context": "\nclass DeepEnsemblePosteriorStateRepository:\n    def __init__(self, ensemble_size: int, checkpoint_dir: Optional[Path] = None):\n        self.ensemble_size = ensemble_size\n        self.state = [\n            PosteriorStateRepository(\n                checkpoint_dir=os.path.join(checkpoint_dir, str(i))\n                if checkpoint_dir\n                else None\n            )\n            for i in range(ensemble_size)\n        ]\n\n    def get(\n        self,\n        i: int = None,\n        checkpoint_path: Optional[Path] = None,\n        optimizer: Optional[OptaxOptimizer] = None,\n        prefix: str = \"checkpoint_\",\n        **kwargs", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "deep_ensemble", "deep_ensemble_repositories.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.18238993710691823}, {"context": "        if not os.path.isdir(restore_checkpoint_path) and not os.path.isfile(\n            restore_checkpoint_path\n        ):\n            raise ValueError(\n                f\"`restore_checkpoint_path={restore_checkpoint_path}` was not found.\"\n            )\n        d = checkpoints.restore_checkpoint(\n            ckpt_dir=str(restore_checkpoint_path),\n            target=None,\n            step=None,\n            prefix=prefix,\n            parallel=True,\n        )\n        if d is None:\n            raise ValueError(\n                f\"No checkpoint was found in `restore_checkpoint_path={restore_checkpoint_path}`.\"\n            )\n        name = \"\".join([chr(n) for n in d[\"encoded_name\"].tolist()])\n        return name_to_train_state[name].value.init_from_dict(d, optimizer, **kwargs)\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "training", "mixin.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.1807909604519774}, {"context": "    def test_reliability_diagram(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            accs = [np.random.normal(size=20), np.random.normal(size=20)]\n            confs = [np.random.normal(size=20), np.random.normal(size=20)]\n            labels = [\"a\", \"b\"]\n            plot_reliability_diagram(accs, confs)\n            plot_reliability_diagram(accs[0], confs[0])\n            plot_reliability_diagram(accs, confs, labels=labels)\n            plot_reliability_diagram(\n                accs, confs, fname=os.path.join(tmp_dir, \"tmp.png\")\n            )\n            plot_reliability_diagram(\n                accs, confs, fname=os.path.join(tmp_dir, \"tmp.png\")\n            )\n            plot_reliability_diagram(accs, confs, title=\"bla\")", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_plot.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 25, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.1794871794871795}, {"context": "                variables=variables,\n                checkpoint_path=checkpoint_path,\n                optimizer=optimizer,\n                keep=keep,\n                prefix=prefix,\n                **kwargs\n            )\n\n        if i is not None:\n            _update(i)\n        else:\n            for i in range(self.ensemble_size):\n                _update(i)\n\n    def extract(\n        self,\n        keys: List[str],\n        i: int = None,\n        checkpoint_path: Optional[Path] = None,\n        prefix: str = \"checkpoint_\",", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "deep_ensemble", "deep_ensemble_repositories.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.17880794701986755}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/common.py\n# --------------------------------------------------\n#                 return target_params\n#             else:\n#                 params = getattr(self, param_name)\n#                 return params.detach()\n# \n#         else:\n#             raise RuntimeError(\n#                 f\"{self.__class__.__name__} does not have the target param {target_name}\"\n#             )\n# \n#     def _networks(self) -> Iterator[nn.Module]:\n#         for item in self.__dir__():\n#             if isinstance(item, nn.Module):\n#                 yield item\n# \n#     @property\n#     def device(self) -> torch.device:\n#         for p in self.parameters():\n#             return p.device\n#         return torch.device(\"cpu\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/gym_like.py\n# --------------------------------------------------\n#             self._info_spec = dict(zip(self.keys, spec))\n#         else:\n#             if spec is None:\n#                 spec = {}\n# \n#             self._info_spec = {\n#                 key: spec.get(key, UnboundedContinuousTensorSpec()) for key in self.keys\n#             }\n# \n#     def __call__(\n#         self, info_dict: Dict[str, Any], tensordict: TensorDictBase\n#     ) -> TensorDictBase:\n#         if not isinstance(info_dict, dict) and len(self.keys):\n#             warnings.warn(\n#                 f\"Found an info_dict of type {type(info_dict)} \"\n#                 f\"but expected type or subtype `dict`.\"\n#             )\n#         for key in self.keys:\n#             if key in info_dict:\n#                 tensordict[key] = info_dict[key]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#     @property\n#     def ndim(self):\n#         return self.ndimension()\n# \n#     def ndimension(self):\n#         return len(self.shape)\n# \n#     def set(self, name, spec):\n#         if spec is not None:\n#             shape = spec.shape\n#             if shape[: self.ndim] != self.shape:\n#                 raise ValueError(\n#                     \"The shape of the spec and the CompositeSpec mismatch: the first \"\n#                     f\"{self.ndim} dimensions should match but got spec.shape={spec.shape} and \"\n#                     f\"CompositeSpec.shape={self.shape}.\"\n#                 )\n#         self._specs[name] = spec\n# \n#     def __init__(self, *args, shape=None, device=None, **kwargs):\n#         if shape is None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/tensordict_module/probabilistic.py\n# --------------------------------------------------\n#         return self._spec\n# \n#     @spec.setter\n#     def spec(self, spec: CompositeSpec) -> None:\n#         if not isinstance(spec, CompositeSpec):\n#             raise RuntimeError(\n#                 f\"Trying to set an object of type {type(spec)} as a tensorspec but expected a CompositeSpec instance.\"\n#             )\n#         self._spec = spec\n# \n#     def random(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         \"\"\"Samples a random element in the target space, irrespective of any input.\n# \n#         If multiple output keys are present, only the first will be written in the input :obj:`tensordict`.\n# \n#         Args:\n#             tensordict (TensorDictBase): tensordict where the output value should be written.\n# \n#         Returns:\n#             the original tensordict with a new/updated value for the output key.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/tensordict_module/probabilistic.py\n# --------------------------------------------------\n#                 warnings.warn('got a spec with key \"_\": it will be ignored')\n#         elif spec is None:\n#             spec = CompositeSpec()\n# \n#         if set(spec.keys()) != set(self.out_keys):\n#             # then assume that all the non indicated specs are None\n#             for key in self.out_keys:\n#                 if key not in spec:\n#                     spec[key] = None\n# \n#         if set(spec.keys()) != set(self.out_keys):\n#             raise RuntimeError(\n#                 f\"spec keys and out_keys do not match, got: {set(spec.keys())} and {set(self.out_keys)} respectively\"\n#             )\n# \n#         self._spec = spec\n#         self.safe = safe\n#         if safe:\n#             if spec is None or (\n#                 isinstance(spec, CompositeSpec)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/tensordict_module/probabilistic.py\n# --------------------------------------------------\n#                 and all(_spec is None for _spec in spec.values())\n#             ):\n#                 raise RuntimeError(\n#                     \"`SafeProbabilisticModule(spec=None, safe=True)` is not a valid configuration as the tensor \"\n#                     \"specs are not specified\"\n#                 )\n#             self.register_forward_hook(_forward_hook_safe_action)\n# \n#     @property\n#     def spec(self) -> CompositeSpec:\n#         return self._spec\n# \n#     @spec.setter\n#     def spec(self, spec: CompositeSpec) -> None:\n#         if not isinstance(spec, CompositeSpec):\n#             raise RuntimeError(\n#                 f\"Trying to set an object of type {type(spec)} as a tensorspec but expected a CompositeSpec instance.\"\n#             )\n#         self._spec = spec\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/tensordict_module/probabilistic.py\n# --------------------------------------------------\n#         if set(spec.keys()) != set(self.out_keys):\n#             raise RuntimeError(\n#                 f\"spec keys and out_keys do not match, got: {set(spec.keys())} and {set(self.out_keys)} respectively\"\n#             )\n# \n#         self._spec = spec\n#         self.safe = safe\n#         if safe:\n#             if spec is None or (\n#                 isinstance(spec, CompositeSpec)\n#                 and all(_spec is None for _spec in spec.values())\n#             ):\n#                 raise RuntimeError(\n#                     \"`SafeProbabilisticModule(spec=None, safe=True)` is not a valid configuration as the tensor \"\n#                     \"specs are not specified\"\n#                 )\n#             self.register_forward_hook(_forward_hook_safe_action)\n# \n#     @property\n#     def spec(self) -> CompositeSpec:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n = [spec]\n        else:\n            keys = list(spec.keys())\n            values = [spec[key] for key in keys]\n        for _spec, _key in zip(values, keys):\n            if _spec is None:\n                continue\n            if not _spec.is_in(tensordict_out.get(_key)):\n                try:\n                    tensordict_out.set_(\n                        _key,\n                        _spec.project(tensordict_out.get(_key)),\n                    )\n                except RuntimeError:\n                    tensordict_out.set(\n                        _key,\n                        _spec.project(tensordict_out.get(_key)),\n                    )\n    except RuntimeError as err:\n        if re.search(\n            \"attempting to use a Tensor in some data-dependent control flow\", str(err)\n        ):\n            # \"_is_stateless\" in module.__dict__ and module._is_stateless:\n            raise RuntimeError(\n                \"vmap cannot be used with safe=True, consider turning the safe mode off.\"\n            ) from err\n        else:\n            raise err\n\n\nclass SafeModule(TensorDictModule):\n    \"\"\"An :obj:``SafeModule`` is a :obj:``tensordict.nn.TensorDictModule`` subclass that accepts a :obj:``TensorSpec`` as argument to control the output domain.\n\n    Args:\n        module (nn.Module): a nn.Module used to map the input to the output parameter space. Can be a functional\n            module (FunctionalModule or FunctionalModuleWithBuffers), in which case the :obj:`forward` method will expect\n            the params (and possibly) buffers keyword arguments.\n        in_keys (iterable of str): keys to be read from input tensordict and passed to the module. If it\n            contains more than one element, the values will be passed in the order given by the in_keys iterable.\n        out_keys (iterable of str): keys to be written to the input tensordict. The length of out_keys must match the\n            number of tensors returned by the embedded module. Using \"_\" as a key avoid writing tensor to output.\n        spec (TensorSpec): specs of the output tensor. If the module outputs multiple output tensors,\n            spec characterize the space of the first output tensor.\n        safe (bool): if True, the value of the output is checked against the input spec. Out-of-domain sampling can\n            occur because of exploration policies or numerical under/overflow issues.\n            If this value is out of bounds, it is projected back onto the desired space using the :obj:`TensorSpec.project`\n            method. Default is :obj:`False`.\n\n    Embedding a neural network in a SafeModule only requires to specify the input and output keys. The domain spec can\n        be passed along if needed. SafeModule support functional and regular :obj:`nn.Module` objects. In the functional\n        case, the 'params' (and 'buffers') keyword argument must be specified:\n\n    Examples:\n        >>> import torch\n        >>> from tensordict import TensorDict\n        >>> from tensordict.nn.functional_modules import make_functional\n        >>> from torchrl.data import UnboundedContinuousTensorSpec\n        >>> from torchrl.modules import SafeModule\n        >>> td = TensorDict({\"input\": torch.randn(3, 4), \"hidden\": torch.randn(3, 8)}, [3,])\n        >>> spec = UnboundedContinuousTensorSpec(8)\n        >>> module = torch.nn.GRUCell(4, 8)\n        >>> td_fmodule = SafeModule(\n        ...    module=module,\n        ...    spec=spec,\n        ...    in_keys=[\"input\", \"hidden\"],\n        ...    out_keys=[\"output\"],\n        ...    )\n        >>> params = make_functional(td_fmodule)\n        >>> td_functional = td_fmodule(td.clone(), params=params)\n        >>> print(td_functional)\n        TensorDict(\n            fields={\n                hidden: Tensor(torch.Size([3, 8]), dtype=torch.float32),\n                input: Tensor(torch.Size([3, 4]), dtype=torch.float32),\n                output: Tensor(torch.Size([3, 8]), dtype=torch.float32)},\n            batch_size=torch.Size([3]),\n            device=None,\n            is_shared=False)\n\n    In the stateful case:\n        >>> td_module = SafeModule(\n        ...    module=torch.nn.GRUCell(4, 8),\n        ...    spec=spec,\n        ...    in_keys=[\"input\", \"hidden\"],\n        ...    out_keys=[\"output\"],\n        ...    )\n        >>> td_stateful = td_module(td.clone())\n        >>> print(td_stateful)\n        TensorDict(\n            fields={\n                hidden: Tensor(torch.Size([3, 8]), dtype=torch.float32),\n                input: Tensor(torch.Size([3, 4]), dtype=torch.float32),\n                output: Tensor(torch.Size([3, 8]), dtype=torch.float32)},\n            batch_size=torch.Size([3]),\n            device=None,\n            is_shared=False)\n\n    One can use a vmap operator to call the functional module. In this case the tensordict is expanded to match the\n    batch size (i.e. the tensordict isn't modified in-place anymore):\n        >>> # Model ensemble using vmap\n        >>> from functorch import vmap\n        >>> params_repeat = params.expand(4, *params.shape)\n        >>> td_vmap = vmap(td_fmodule, (None, 0))(td.clone(), params_repeat)\n        >>> print(td_vmap)\n        TensorDict(\n            fields={\n                hidden: Tensor(torch.Size([4, 3, 8]), dtype=torch.float32),\n                input: Tensor(torch.Size([4, 3, 4]), dtype=torch.float32),\n                output: Tensor(torch.Size([4, 3, 8]), dtype=torch.float32)},\n            batch_size=torch.Size([4, 3]),\n            device=None,\n            is_shared=False)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        module: Union[\n            FunctionalModule, FunctionalModuleWithBuffers, SafeModule, nn.Module\n        ],\n        in_keys: Iterable[str],\n        out_keys: Iterable[str],\n        spec: Optional[TensorSpec] = None,\n        safe: bool = False,\n    ):\n        super().__init__(module, in_keys, out_keys)\n\n        if spec is not None and not isinstance(spec, TensorSpec):\n            raise TypeError(\"spec must be a TensorSpec subclass\")\n        elif spec is not None and not isinstance(spec, CompositeSpec):\n            if len(self.out_keys) > 1:\n                raise RuntimeError(\n                    f\"got more than one out_key for the SafeModule: {self.out_keys},\\nbut only one spec. \"\n                    \"Consider using a CompositeSpec object or no spec at all.\"\n                )\n            spec = CompositeSpec(**{self.out_keys[0]: spec})\n        elif spec is not None and isinstance(spec, CompositeSpec):\n            if \"_\" in spec.keys():\n                warnings.warn('got a spec with key \"_\": it will be ignored')\n        elif spec is None:\n            spec = CompositeSpec()\n\n        if set(spec.keys()) != set(self.out_keys):\n            # then assume that all the non indicated specs are None\n            for key in self.out_keys:\n                if key not in spec:\n                    spec[key] = None\n\n        if set(spec.keys()) != set(self.out_keys):\n            raise RuntimeError(\n                f\"spec keys and out_keys do not match, got: {set(spec.keys())} and {set(self.out_keys)} respectively\"\n            )\n\n        self._spec = spec\n        self.safe = safe\n        if safe:\n            if spec is None or (\n                isinstance(spec, CompositeSpec)\n                and all(_spec is None for _spec in spec.values())\n            ):", "choices": [{"text": "raise RuntimeError("}], "metadata": {"task_id": "pytorch_rl/182", "ground_truth": "                raise RuntimeError(", "fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "common.py"], "context_start_lineno": 67, "line_no": 227, "query_window": {"context": "            spec = CompositeSpec()\n\n        if set(spec.keys()) != set(self.out_keys):\n            # then assume that all the non indicated specs are None\n            for key in self.out_keys:\n                if key not in spec:\n                    spec[key] = None\n\n        if set(spec.keys()) != set(self.out_keys):\n            raise RuntimeError(\n                f\"spec keys and out_keys do not match, got: {set(spec.keys())} and {set(self.out_keys)} respectively\"\n            )\n\n        self._spec = spec\n        self.safe = safe\n        if safe:\n            if spec is None or (\n                isinstance(spec, CompositeSpec)\n                and all(_spec is None for _spec in spec.values())\n            ):", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "common.py"], "line_no": 227, "task_id": "pytorch_rl/182", "start_line_no": 207, "end_line_no": 227, "window_size": 20, "context_start_lineno": 67, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "                warnings.warn('got a spec with key \"_\": it will be ignored')\n        elif spec is None:\n            spec = CompositeSpec()\n\n        if set(spec.keys()) != set(self.out_keys):\n            # then assume that all the non indicated specs are None\n            for key in self.out_keys:\n                if key not in spec:\n                    spec[key] = None\n\n        if set(spec.keys()) != set(self.out_keys):\n            raise RuntimeError(\n                f\"spec keys and out_keys do not match, got: {set(spec.keys())} and {set(self.out_keys)} respectively\"\n            )\n\n        self._spec = spec\n        self.safe = safe\n        if safe:\n            if spec is None or (\n                isinstance(spec, CompositeSpec)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "probabilistic.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7840909090909091}, {"context": "        if set(spec.keys()) != set(self.out_keys):\n            raise RuntimeError(\n                f\"spec keys and out_keys do not match, got: {set(spec.keys())} and {set(self.out_keys)} respectively\"\n            )\n\n        self._spec = spec\n        self.safe = safe\n        if safe:\n            if spec is None or (\n                isinstance(spec, CompositeSpec)\n                and all(_spec is None for _spec in spec.values())\n            ):\n                raise RuntimeError(\n                    \"`SafeProbabilisticModule(spec=None, safe=True)` is not a valid configuration as the tensor \"\n                    \"specs are not specified\"\n                )\n            self.register_forward_hook(_forward_hook_safe_action)\n\n    @property\n    def spec(self) -> CompositeSpec:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "probabilistic.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5980392156862745}, {"context": "            raise TypeError(\"spec must be a TensorSpec subclass\")\n        elif spec is not None and not isinstance(spec, CompositeSpec):\n            if len(self.out_keys) > 1:\n                raise RuntimeError(\n                    f\"got more than one out_key for the SafeModule: {self.out_keys},\\nbut only one spec. \"\n                    \"Consider using a CompositeSpec object or no spec at all.\"\n                )\n            spec = CompositeSpec(**{self.out_keys[0]: spec})\n        elif spec is not None and isinstance(spec, CompositeSpec):\n            if \"_\" in spec.keys():\n                warnings.warn('got a spec with key \"_\": it will be ignored')\n        elif spec is None:\n            spec = CompositeSpec()\n\n        if set(spec.keys()) != set(self.out_keys):\n            # then assume that all the non indicated specs are None\n            for key in self.out_keys:\n                if key not in spec:\n                    spec[key] = None\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "probabilistic.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.47107438016528924}, {"context": "                and all(_spec is None for _spec in spec.values())\n            ):\n                raise RuntimeError(\n                    \"`SafeProbabilisticModule(spec=None, safe=True)` is not a valid configuration as the tensor \"\n                    \"specs are not specified\"\n                )\n            self.register_forward_hook(_forward_hook_safe_action)\n\n    @property\n    def spec(self) -> CompositeSpec:\n        return self._spec\n\n    @spec.setter\n    def spec(self, spec: CompositeSpec) -> None:\n        if not isinstance(spec, CompositeSpec):\n            raise RuntimeError(\n                f\"Trying to set an object of type {type(spec)} as a tensorspec but expected a CompositeSpec instance.\"\n            )\n        self._spec = spec\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "probabilistic.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4152542372881356}, {"context": "    def shape(self, value: torch.Size):\n        for key, spec in self.items():\n            if spec.shape[: self.ndim] != self.shape:\n                raise ValueError(\n                    f\"The shape of the spec and the CompositeSpec mismatch during shape resetting: the \"\n                    f\"{self.ndim} first dimensions should match but got self['{key}'].shape={spec.shape} and \"\n                    f\"CompositeSpec.shape={self.shape}.\"\n                )\n        self._shape = torch.Size(value)\n\n    @property\n    def ndim(self):\n        return self.ndimension()\n\n    def ndimension(self):\n        return len(self.shape)\n\n    def set(self, name, spec):\n        if spec is not None:\n            shape = spec.shape", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 1600, "start_line_no": 1590, "end_line_no": 1610, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3739130434782609}, {"context": "        if keys is None:\n            keys = []\n        self.keys = keys\n\n        if isinstance(spec, Sequence):\n            if len(spec) != len(self.keys):\n                raise ValueError(\n                    \"If specifying specs for info keys with a sequence, the \"\n                    \"length of the sequence must match the number of keys\"\n                )\n            self._info_spec = dict(zip(self.keys, spec))\n        else:\n            if spec is None:\n                spec = {}\n\n            self._info_spec = {\n                key: spec.get(key, UnboundedContinuousTensorSpec()) for key in self.keys\n            }\n\n    def __call__(", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.37037037037037035}, {"context": "            target_params = getattr(self, target_name)\n            if target_params is not None:\n                # get targets and update\n                for key in target_params.keys(True, True):\n                    if not isinstance(key, tuple):\n                        key = (key,)\n                    value_to_set = getattr(\n                        self, \"_sep_\".join([\"_target_\" + network_name, *key])\n                    )\n                    target_params.set(key, value_to_set)\n                return target_params\n            else:\n                params = getattr(self, param_name)\n                return params.detach()\n\n        else:\n            raise RuntimeError(\n                f\"{self.__class__.__name__} does not have the target param {target_name}\"\n            )\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "common.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.36363636363636365}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/joint/base.py\n# --------------------------------------------------\n# from typing import List, Optional, Tuple, Union\n# \n# import jax.numpy as jnp\n# from flax.core import FrozenDict\n# from jax._src.prng import PRNGKeyArray\n# \n# from fortuna.data.loader import DataLoader\n# from fortuna.model.model_manager.state import ModelManagerState\n# from fortuna.output_calibrator.output_calib_manager.state import \\\n#     OutputCalibManagerState\n# from fortuna.prob_model.joint.state import JointState\n# from fortuna.prob_model.likelihood.base import Likelihood\n# from fortuna.prob_model.prior.base import Prior\n# from fortuna.typing import Batch, CalibMutable, CalibParams, Mutable, Params\n# from fortuna.utils.random import WithRNG\n# \n# \n# class Joint(WithRNG):\n#     def __init__(self, prior: Prior, likelihood: Likelihood):\n#         r\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/prob_model_calibrator.py\n# --------------------------------------------------\n# from typing import Any, Callable, Dict, Optional, Tuple, Union\n# \n# import jax\n# import jax.numpy as jnp\n# from flax import jax_utils\n# from jax import lax\n# from jax._src.prng import PRNGKeyArray\n# from jax.tree_util import tree_map\n# \n# from fortuna.calibration.calibrator import (CalibratorABC, JittedMixin,\n#                                             MultiDeviceMixin)\n# from fortuna.calibration.state import CalibState\n# from fortuna.data import DataLoader, TargetsLoader\n# from fortuna.typing import Array, Batch, CalibMutable, CalibParams\n# \n# \n# class ProbModelCalibrator(CalibratorABC):\n#     def training_loss_step(\n#         self,\n#         fun: Callable[[Any], Union[float, Tuple[float, dict]]],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/training/trainer.py\n# --------------------------------------------------\n# import abc\n# import collections\n# import logging\n# from functools import partial\n# from typing import Any, Callable, Dict, List, Optional, Tuple\n# \n# import jax\n# import jax.numpy as jnp\n# from flax import jax_utils\n# from flax.core import FrozenDict\n# from flax.training.common_utils import stack_forest\n# from jax import lax, random, value_and_grad\n# from jax._src.prng import PRNGKeyArray\n# from jax.tree_util import tree_map\n# from optax._src.base import PyTree\n# from tqdm import trange\n# from tqdm.std import tqdm as TqdmDecorator\n# \n# from fortuna.data.loader import DataLoader\n# from fortuna.training.mixin import (InputValidatorMixin,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/base.py\n# --------------------------------------------------\n# from fortuna.prob_model.fit_config import FitConfig\n# from fortuna.prob_model.prob_model_calibrator import (\n#     JittedProbModelCalibrator, MultiDeviceProbModelCalibrator,\n#     ProbModelCalibrator)\n# from fortuna.typing import Array, Path, Status\n# from fortuna.utils.data import check_data_loader_is_not_random\n# from fortuna.utils.device import select_trainer_given_devices\n# from fortuna.utils.random import RandomNumberGenerator\n# \n# \n# class ProbModel(abc.ABC):\n#     \"\"\"\n#     Abstract probabilistic model class.\n#     \"\"\"\n# \n#     def __init__(self, seed: int = 0):\n#         self.rng = RandomNumberGenerator(seed=seed)\n#         self.__set_rng()\n# \n#     def __set_rng(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/classification.py\n# --------------------------------------------------\n# from typing import Optional\n# \n# import flax.linen as nn\n# import jax.numpy as jnp\n# import numpy as np\n# \n# from fortuna.calib_model.base import CalibModel\n# from fortuna.calib_model.calib_config.base import CalibConfig\n# from fortuna.calib_model.predictive.classification import \\\n#     ClassificationPredictive\n# from fortuna.output_calibrator.classification import \\\n#     ClassificationTemperatureScaler\n# from fortuna.output_calibrator.output_calib_manager.base import \\\n#     OutputCalibManager\n# from fortuna.prob_output_layer.classification import \\\n#     ClassificationProbOutputLayer\n# from fortuna.typing import Array, Status\n# \n# \n# class CalibClassifier(CalibModel):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/regression.py\n# --------------------------------------------------\n# from typing import Optional\n# \n# import flax.linen as nn\n# import jax.numpy as jnp\n# \n# from fortuna.calib_model.base import CalibModel\n# from fortuna.calib_model.calib_config.base import CalibConfig\n# from fortuna.calib_model.predictive.regression import RegressionPredictive\n# from fortuna.output_calibrator.output_calib_manager.base import \\\n#     OutputCalibManager\n# from fortuna.output_calibrator.regression import RegressionTemperatureScaler\n# from fortuna.prob_output_layer.regression import RegressionProbOutputLayer\n# from fortuna.typing import Array, Status\n# \n# \n# class CalibRegressor(CalibModel):\n#     def __init__(\n#         self,\n#         output_calibrator: Optional[nn.Module] = RegressionTemperatureScaler(),\n#         seed: int = 0,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/base.py\n# --------------------------------------------------\n# import abc\n# import logging\n# from typing import Callable, Dict, Optional\n# \n# import jax\n# import jax.numpy as jnp\n# \n# from fortuna.calibration.state import CalibState\n# from fortuna.data.loader import DataLoader\n# from fortuna.prob_model.calib_config.base import CalibConfig\n# from fortuna.prob_model.fit_config import FitConfig\n# from fortuna.prob_model.prob_model_calibrator import (\n#     JittedProbModelCalibrator, MultiDeviceProbModelCalibrator,\n#     ProbModelCalibrator)\n# from fortuna.typing import Array, Path, Status\n# from fortuna.utils.data import check_data_loader_is_not_random\n# from fortuna.utils.device import select_trainer_given_devices\n# from fortuna.utils.random import RandomNumberGenerator\n# \n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport abc\nimport logging\nfrom typing import Callable, Optional\n\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\n\nfrom fortuna.calib_model.calib_config.base import CalibConfig\nfrom fortuna.calib_model.calib_model_calibrator import (\n    CalibModelCalibrator, JittedCalibModelCalibrator,", "choices": [{"text": "MultiDeviceCalibModelCalibrator)"}], "metadata": {"task_id": "awslabs_fortuna/79", "ground_truth": "    MultiDeviceCalibModelCalibrator)", "fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "base.py"], "context_start_lineno": 0, "line_no": 10, "query_window": {"context": "import abc\nimport logging\nfrom typing import Callable, Optional\n\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\n\nfrom fortuna.calib_model.calib_config.base import CalibConfig\nfrom fortuna.calib_model.calib_model_calibrator import (\n    CalibModelCalibrator, JittedCalibModelCalibrator,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "base.py"], "line_no": 10, "task_id": "awslabs_fortuna/79", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "import abc\nimport logging\nfrom typing import Callable, Dict, Optional\n\nimport jax\nimport jax.numpy as jnp\n\nfrom fortuna.calibration.state import CalibState\nfrom fortuna.data.loader import DataLoader\nfrom fortuna.prob_model.calib_config.base import CalibConfig", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "base.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5769230769230769}, {"context": "from typing import Optional\n\nimport flax.linen as nn\nimport jax.numpy as jnp\n\nfrom fortuna.calib_model.base import CalibModel\nfrom fortuna.calib_model.calib_config.base import CalibConfig\nfrom fortuna.calib_model.predictive.regression import RegressionPredictive\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "regression.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5087719298245614}, {"context": "from typing import Optional\n\nimport flax.linen as nn\nimport jax.numpy as jnp\nimport numpy as np\n\nfrom fortuna.calib_model.base import CalibModel\nfrom fortuna.calib_model.calib_config.base import CalibConfig\nfrom fortuna.calib_model.predictive.classification import \\\n    ClassificationPredictive", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "classification.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.48148148148148145}, {"context": "import abc\nimport logging\nfrom typing import Callable, Dict, Optional\n\nimport jax\nimport jax.numpy as jnp\n\nfrom fortuna.calibration.state import CalibState\nfrom fortuna.data.loader import DataLoader\nfrom fortuna.prob_model.calib_config.base import CalibConfig\nfrom fortuna.prob_model.fit_config import FitConfig\nfrom fortuna.prob_model.prob_model_calibrator import (\n    JittedProbModelCalibrator, MultiDeviceProbModelCalibrator,\n    ProbModelCalibrator)\nfrom fortuna.typing import Array, Path, Status\nfrom fortuna.utils.data import check_data_loader_is_not_random\nfrom fortuna.utils.device import select_trainer_given_devices\nfrom fortuna.utils.random import RandomNumberGenerator\n\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "base.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4810126582278481}, {"context": "import abc\nimport collections\nimport logging\nfrom functools import partial\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\n\nimport jax\nimport jax.numpy as jnp\nfrom flax import jax_utils\nfrom flax.core import FrozenDict", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "training", "trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4716981132075472}, {"context": "from typing import Any, Callable, Dict, Optional, Tuple, Union\n\nimport jax\nimport jax.numpy as jnp\nfrom flax import jax_utils\nfrom jax import lax\nfrom jax._src.prng import PRNGKeyArray\nfrom jax.tree_util import tree_map\n\nfrom fortuna.calibration.calibrator import (CalibratorABC, JittedMixin,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "prob_model_calibrator.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4461538461538462}, {"context": "from typing import List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import DataLoader\nfrom fortuna.model.model_manager.state import ModelManagerState\nfrom fortuna.output_calibrator.output_calib_manager.state import \\\n    OutputCalibManagerState", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "joint", "base.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4393939393939394}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_xgb.py\n# --------------------------------------------------\n# \n# class XGBTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config(self, cfg):\n#         backup_cfg = cfg.clone()\n# \n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n# \n#         cfg.federate.mode = 'standalone'\n#         cfg.federate.client_num = 2\n# \n#         cfg.model.type = 'xgb_tree'\n#         cfg.model.lambda_ = 1\n#         cfg.model.gamma = 0\n#         cfg.model.num_of_trees = 5\n#         cfg.model.max_tree_depth = 3\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_vertical_fl.py\n# --------------------------------------------------\n# \n# class vFLTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config(self, cfg):\n#         backup_cfg = cfg.clone()\n# \n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n# \n#         cfg.federate.mode = 'standalone'\n#         cfg.federate.total_round_num = 30\n#         cfg.federate.client_num = 2\n# \n#         cfg.model.type = 'lr'\n#         cfg.model.use_bias = False\n# \n#         cfg.train.optimizer.lr = 0.05\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_finetune_lr.py\n# tests/test_toy_lr.py\n# --------------------------------------------------\n# \n# class ToyLRTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config_standalone(self, cfg, make_global_eval=False):\n#         backup_cfg = cfg.clone()\n# \n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n#         cfg.federate.mode = 'standalone'\n#         cfg.federate.total_round_num = 20\n#         cfg.federate.make_global_eval = make_global_eval\n#         cfg.federate.client_num = 5\n#         cfg.eval.freq = 10\n#         cfg.data.type = 'toy'\n#         cfg.trainer.type = 'general'\n#         cfg.model.type = 'lr'\n#         cfg.finetune.before_eval = True\n#         cfg.finetune.local_update_steps = 5\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_local_train_lr.py\n# --------------------------------------------------\n# \n# \n# class ToyLRTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config_standalone(self, cfg, make_global_eval=False):\n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n#         cfg.federate.mode = 'standalone'\n#         cfg.federate.total_round_num = 100\n#         cfg.federate.make_global_eval = make_global_eval\n#         cfg.federate.client_num = 5\n#         cfg.eval.freq = 10\n#         cfg.data.type = 'toy'\n#         cfg.trainer.type = 'general'\n#         cfg.model.type = 'lr'\n# \n#         cfg.early_stop.patience = 5\n#         cfg.federate.method = \"local\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_global_train_lr.py\n# --------------------------------------------------\n# \n# class ToyLRTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config_standalone(self, cfg, make_global_eval=False):\n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n#         cfg.federate.mode = 'standalone'\n#         cfg.federate.total_round_num = 30\n#         cfg.federate.make_global_eval = make_global_eval\n#         cfg.federate.client_num = 5\n#         cfg.eval.freq = 10\n#         cfg.data.type = 'toy'\n#         cfg.trainer.type = 'general'\n#         cfg.model.type = 'lr'\n# \n#         cfg.early_stop.patience = 5\n#         cfg.federate.method = \"global\"\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_unseen_clients_lr.py\n# --------------------------------------------------\n# \n# class ToyLRTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config_standalone(self, cfg, make_global_eval=False):\n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n#         cfg.federate.mode = 'standalone'\n#         cfg.federate.total_round_num = 20\n#         cfg.federate.make_global_eval = make_global_eval\n#         cfg.federate.client_num = 5\n#         cfg.federate.unseen_clients_rate = 0.2  # 20% unseen clients\n#         cfg.eval.freq = 10\n#         cfg.data.type = 'toy'\n#         cfg.trainer.type = 'general'\n#         cfg.model.type = 'lr'\n# \n#     def test_toy_example_standalone(self):\n#         init_cfg = global_cfg.clone()\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n\n\nclass PIA_ToyLRTest(unittest.TestCase):\n    def setUp(self):\n        print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n\n    def set_config_standalone(self, cfg):\n        backup_cfg = cfg.clone()\n\n        cfg.use_gpu = False\n        cfg.federate.mode = 'standalone'\n        cfg.federate.total_round_num = 20\n        cfg.federate.client_num = 5\n        cfg.eval.freq = 10", "choices": [{"text": "cfg.data.type = 'toy'"}], "metadata": {"task_id": "alibaba_FederatedScope/45", "ground_truth": "        cfg.data.type = 'toy'", "fpath_tuple": ["alibaba_FederatedScope", "tests", "test_PIA_toy.py"], "context_start_lineno": 0, "line_no": 23, "query_window": {"context": "from federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n\n\nclass PIA_ToyLRTest(unittest.TestCase):\n    def setUp(self):\n        print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n\n    def set_config_standalone(self, cfg):\n        backup_cfg = cfg.clone()\n\n        cfg.use_gpu = False\n        cfg.federate.mode = 'standalone'\n        cfg.federate.total_round_num = 20\n        cfg.federate.client_num = 5\n        cfg.eval.freq = 10", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_PIA_toy.py"], "line_no": 23, "task_id": "alibaba_FederatedScope/45", "start_line_no": 3, "end_line_no": 23, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n\n\nclass ToyLRTest(unittest.TestCase):\n    def setUp(self):\n        print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n\n    def set_config_standalone(self, cfg, make_global_eval=False):\n        import torch\n        cfg.use_gpu = torch.cuda.is_available()\n        cfg.federate.mode = 'standalone'\n        cfg.federate.total_round_num = 20", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_unseen_clients_lr.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.7368421052631579}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n\n\nclass ToyLRTest(unittest.TestCase):\n    def setUp(self):\n        print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n\n    def set_config_standalone(self, cfg, make_global_eval=False):\n        import torch\n        cfg.use_gpu = torch.cuda.is_available()\n        cfg.federate.mode = 'standalone'\n        cfg.federate.total_round_num = 30", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_global_train_lr.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.7217391304347827}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, \\\n    get_client_cls\n\n\nclass ToyLRTest(unittest.TestCase):\n    def setUp(self):\n        print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n\n    def set_config_standalone(self, cfg, make_global_eval=False):\n        import torch\n        cfg.use_gpu = torch.cuda.is_available()\n        cfg.federate.mode = 'standalone'", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_local_train_lr.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.6956521739130435}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n\n\nclass ToyLRTest(unittest.TestCase):\n    def setUp(self):\n        print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n\n    def set_config_standalone(self, cfg, make_global_eval=False):\n        backup_cfg = cfg.clone()\n\n        import torch\n        cfg.use_gpu = torch.cuda.is_available()", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_finetune_lr.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_toy_lr.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.6754385964912281}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\n\n\nclass vFLTest(unittest.TestCase):\n    def setUp(self):\n        print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n\n    def set_config(self, cfg):\n        backup_cfg = cfg.clone()\n\n        import torch\n        cfg.use_gpu = torch.cuda.is_available()", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_vertical_fl.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.6486486486486487}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\n\n\nclass XGBTest(unittest.TestCase):\n    def setUp(self):\n        print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n\n    def set_config(self, cfg):\n        backup_cfg = cfg.clone()\n\n        import torch\n        cfg.use_gpu = torch.cuda.is_available()", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_xgb.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.6486486486486487}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/template/sqn.py\n# --------------------------------------------------\n# \n# from ding.utils import MODEL_REGISTRY\n# from .q_learning import DQN\n# \n# \n# @MODEL_REGISTRY.register('sqn')\n# class SQN(nn.Module):\n# \n#     def __init__(self, *args, **kwargs) -> None:\n#         super(SQN, self).__init__()\n#         self.q0 = DQN(*args, **kwargs)\n#         self.q1 = DQN(*args, **kwargs)\n# \n#     def forward(self, data: torch.Tensor) -> Dict:\n#         output0 = self.q0(data)\n#         output1 = self.q1(data)\n#         return {\n#             'q_value': [output0['logit'], output1['logit']],\n#             'logit': output0['logit'],\n#         }\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/template/q_learning.py\n# --------------------------------------------------\n#     Overview:\n#         RainbowDQN network (C51 + Dueling + Noisy Block)\n# \n#     .. note::\n#         RainbowDQN contains dueling architecture by default\n#     \"\"\"\n# \n#     def __init__(\n#         self,\n#         obs_shape: Union[int, SequenceType],\n#         action_shape: Union[int, SequenceType],\n#         encoder_hidden_size_list: SequenceType = [128, 128, 64],\n#         head_hidden_size: Optional[int] = None,\n#         head_layer_num: int = 1,\n#         activation: Optional[nn.Module] = nn.ReLU(),\n#         norm_type: Optional[str] = None,\n#         v_min: Optional[float] = -10,\n#         v_max: Optional[float] = 10,\n#         n_atom: Optional[int] = 51,\n#     ) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/template/coma.py\n# --------------------------------------------------\n# \n#     def __init__(\n#             self, agent_num: int, obs_shape: Dict, action_shape: Union[int, SequenceType],\n#             actor_hidden_size_list: SequenceType\n#     ) -> None:\n#         \"\"\"\n#         Overview:\n#             initialize COMA network\n#         Arguments:\n#             - agent_num (:obj:`int`): the number of agent\n#             - obs_shape (:obj:`Dict`): the observation information, including agent_state and \\\n#                 global_state\n#             - action_shape (:obj:`Union[int, SequenceType]`): the dimension of action shape\n#             - actor_hidden_size_list (:obj:`SequenceType`): the list of hidden size\n#         \"\"\"\n#         super(COMA, self).__init__()\n#         action_shape = squeeze(action_shape)\n#         actor_input_size = squeeze(obs_shape['agent_state'])\n#         critic_input_size = squeeze(obs_shape['agent_state']) + squeeze(obs_shape['global_state']) + \\\n#             agent_num * action_shape + (agent_num - 1) * action_shape\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/template/q_learning.py\n# --------------------------------------------------\n# \n# \n# @MODEL_REGISTRY.register('drqn')\n# class DRQN(nn.Module):\n#     \"\"\"\n#     Overview:\n#         DQN + RNN = DRQN\n#     \"\"\"\n# \n#     def __init__(\n#             self,\n#             obs_shape: Union[int, SequenceType],\n#             action_shape: Union[int, SequenceType],\n#             encoder_hidden_size_list: SequenceType = [128, 128, 64],\n#             dueling: bool = True,\n#             head_hidden_size: Optional[int] = None,\n#             head_layer_num: int = 1,\n#             lstm_type: Optional[str] = 'normal',\n#             activation: Optional[nn.Module] = nn.ReLU(),\n#             norm_type: Optional[str] = None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/template/qtran.py\n# --------------------------------------------------\n#     \"\"\"\n# \n#     def __init__(\n#             self,\n#             agent_num: int,\n#             obs_shape: int,\n#             global_obs_shape: int,\n#             action_shape: int,\n#             hidden_size_list: list,\n#             embedding_size: int,\n#             lstm_type: str = 'gru',\n#             dueling: bool = False\n#     ) -> None:\n#         \"\"\"\n#         Overview:\n#             initialize QTRAN network\n#         Arguments:\n#             - agent_num (:obj:`int`): the number of agent\n#             - obs_shape (:obj:`int`): the dimension of each agent's observation state\n#             - global_obs_shape (:obj:`int`): the dimension of global observation state\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/template/qmix.py\n# --------------------------------------------------\n#         return q_tot\n# \n# \n# @MODEL_REGISTRY.register('qmix')\n# class QMix(nn.Module):\n#     \"\"\"\n#     Overview:\n#         QMIX network\n#     Interface:\n#         __init__, forward, _setup_global_encoder\n#     \"\"\"\n# \n#     def __init__(\n#             self,\n#             agent_num: int,\n#             obs_shape: int,\n#             global_obs_shape: int,\n#             action_shape: int,\n#             hidden_size_list: list,\n#             mixer: bool = True,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/template/qmix.py\n# --------------------------------------------------\n#     Interface:\n#         __init__, forward, _setup_global_encoder\n#     \"\"\"\n# \n#     def __init__(\n#             self,\n#             agent_num: int,\n#             obs_shape: int,\n#             alone_obs_shape: int,\n#             global_obs_shape: int,\n#             action_shape: int,\n#             hidden_size_list: list,\n#             attention: bool = False,\n#             self_feature_range: Union[List[int], None] = None,\n#             ally_feature_range: Union[List[int], None] = None,\n#             attention_size: int = 32,\n#             mixer: bool = True,\n#             lstm_type: str = 'gru',\n#             dueling: bool = False,\n#     ) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/template/qmix.py\n# --------------------------------------------------\n#     \"\"\"\n# \n#     def __init__(\n#             self,\n#             agent_num: int,\n#             obs_shape: int,\n#             global_obs_shape: int,\n#             action_shape: int,\n#             hidden_size_list: list,\n#             mixer: bool = True,\n#             lstm_type: str = 'gru',\n#             dueling: bool = False\n#     ) -> None:\n#         \"\"\"\n#         Overview:\n#             initialize Qmix network\n#         Arguments:\n#             - agent_num (:obj:`int`): the number of agent\n#             - obs_shape (:obj:`int`): the dimension of each agent's observation state\n#             - global_obs_shape (:obj:`int`): the dimension of global observation state\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import Union, List\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom functools import reduce\nfrom ding.utils import list_split, MODEL_REGISTRY\nfrom ding.torch_utils.network.nn_module import fc_block, MLP\nfrom ding.torch_utils.network.transformer import ScaledDotProductAttention\nfrom .q_learning import DRQN\nfrom ding.model.template.qmix import Mixer\n\n\nclass MixerStar(nn.Module):\n    \"\"\"\n    Overview:\n        mixer network for Q_star in WQMIX , which mix up the independent q_value of\n        each agent to a total q_value and is diffrent from the Qmix's mixer network,\n        here the mixing network is a feedforward network with 3 hidden layers of 256 dim.\n    Interface:\n        __init__, forward\n    \"\"\"\n\n    def __init__(self, agent_num: int, state_dim: int, mixing_embed_dim: int) -> None:\n        \"\"\"\n        Overview:\n            initialize the mixer network of Q_star in WQMIX.\n        Arguments:\n            - agent_num (:obj:`int`): the number of agent\n            - state_dim(:obj:`int`): the dimension of global observation state\n            - mixing_embed_dim (:obj:`int`): the dimension of mixing state emdedding\n        \"\"\"\n        super(MixerStar, self).__init__()\n        self.agent_num = agent_num\n        self.state_dim = state_dim\n        self.embed_dim = mixing_embed_dim\n        self.input_dim = self.agent_num + self.state_dim  # shape N+A\n        non_lin = nn.ReLU()\n        self.net = nn.Sequential(\n            nn.Linear(self.input_dim, self.embed_dim), non_lin, nn.Linear(self.embed_dim, self.embed_dim), non_lin,\n            nn.Linear(self.embed_dim, self.embed_dim), non_lin, nn.Linear(self.embed_dim, 1)\n        )\n\n        # V(s) instead of a bias for the last layers\n        self.V = nn.Sequential(nn.Linear(self.state_dim, self.embed_dim), non_lin, nn.Linear(self.embed_dim, 1))\n\n    def forward(self, agent_qs: torch.FloatTensor, states: torch.FloatTensor) -> torch.FloatTensor:\n        \"\"\"\n        Overview:\n            forward computation graph of the mixer network for Q_star in WQMIX.\n        Arguments:\n            - agent_qs (:obj:`torch.FloatTensor`): the independent q_value of each agent\n            - states (:obj:`torch.FloatTensor`): the emdedding vector of global state\n        Returns:\n            - q_tot (:obj:`torch.FloatTensor`): the total mixed q_value\n        Shapes:\n            - agent_qs (:obj:`torch.FloatTensor`): :math:`(T,B, N)`, where T is timestep,\n              B is batch size, A is agent_num, N is obs_shape\n            - states (:obj:`torch.FloatTensor`): :math:`(T, B, M)`, where M is global_obs_shape\n            - q_tot (:obj:`torch.FloatTensor`): :math:`(T, B, )`\n        \"\"\"\n        # in below annotations about the shape of the variables, T is timestep,\n        # B is batch_size A is agent_num, N is obs_shape\uff0c for example,\n        # in 3s5z, we can set T=10, B=32, A=8, N=216\n        bs = agent_qs.shape[:-1]  # (T*B, A)\n        states = states.reshape(-1, self.state_dim)  # T*B, N),\n        agent_qs = agent_qs.reshape(-1, self.agent_num)  # (T, B, A) -> (T*B, A)\n        inputs = torch.cat([states, agent_qs], dim=1)  # (T*B, N) (T*B, A)-> (T*B, N+A)\n        advs = self.net(inputs)  # (T*B, 1)\n        vs = self.V(states)  # (T*B, 1)\n        y = advs + vs\n        q_tot = y.view(*bs)  # (T*B, 1) -> (T, B)\n\n        return q_tot\n\n\n@MODEL_REGISTRY.register('wqmix')\nclass WQMix(nn.Module):\n    \"\"\"\n    Overview:\n        WQMIX network, which is same as Qmix network\n    Interface:\n        __init__, forward, _setup_global_encoder\n    \"\"\"\n\n    def __init__(\n            self,\n            agent_num: int,\n            obs_shape: int,", "choices": [{"text": "int`): the number of agent"}], "metadata": {"task_id": "opendilab_ACE/116", "ground_truth": "            global_obs_shape: int,", "fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "wqmix.py"], "context_start_lineno": 0, "line_no": 88, "query_window": {"context": "        vs = self.V(states)  # (T*B, 1)\n        y = advs + vs\n        q_tot = y.view(*bs)  # (T*B, 1) -> (T, B)\n\n        return q_tot\n\n\n@MODEL_REGISTRY.register('wqmix')\nclass WQMix(nn.Module):\n    \"\"\"\n    Overview:\n        WQMIX network, which is same as Qmix network\n    Interface:\n        __init__, forward, _setup_global_encoder\n    \"\"\"\n\n    def __init__(\n            self,\n            agent_num: int,\n            obs_shape: int,", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "wqmix.py"], "line_no": 88, "task_id": "opendilab_ACE/116", "start_line_no": 68, "end_line_no": 88, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "        return q_tot\n\n\n@MODEL_REGISTRY.register('qmix')\nclass QMix(nn.Module):\n    \"\"\"\n    Overview:\n        QMIX network\n    Interface:\n        __init__, forward, _setup_global_encoder\n    \"\"\"\n\n    def __init__(\n            self,\n            agent_num: int,\n            obs_shape: int,\n            global_obs_shape: int,\n            action_shape: int,\n            hidden_size_list: list,\n            mixer: bool = True,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "qmix.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5934065934065934}, {"context": "            dim=-1\n        )\n        return obs\n\n\n@MODEL_REGISTRY.register('collaq')\nclass CollaQ(nn.Module):\n    \"\"\"\n    Overview:\n        CollaQ network\n    Interface:\n        __init__, forward, _setup_global_encoder\n    \"\"\"\n\n    def __init__(\n            self,\n            agent_num: int,\n            obs_shape: int,\n            alone_obs_shape: int,\n            global_obs_shape: int,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "qmix.py"], "line_no": 360, "start_line_no": 350, "end_line_no": 370, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4891304347826087}, {"context": "        hidden = F.elu(torch.bmm(agent_qs, w1) + b1)\n        # Second layer\n        w_final = torch.abs(self.hyper_w_final(states))\n        w_final = w_final.view(-1, self.embed_dim, 1)\n        # State-dependent bias\n        v = self.V(states).view(-1, 1, 1)\n        # Compute final output\n        y = torch.bmm(hidden, w_final) + v\n        # Reshape and return\n        q_tot = y.view(*bs)\n        return q_tot\n\n\n@MODEL_REGISTRY.register('qmix')\nclass QMix(nn.Module):\n    \"\"\"\n    Overview:\n        QMIX network\n    Interface:\n        __init__, forward, _setup_global_encoder", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "qmix.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.48333333333333334}, {"context": "from .q_learning import DRQN\n\n\n@MODEL_REGISTRY.register('qtran')\nclass QTran(nn.Module):\n    \"\"\"\n    Overview:\n        QTRAN network\n    Interface:\n        __init__, forward\n    \"\"\"\n\n    def __init__(\n            self,\n            agent_num: int,\n            obs_shape: int,\n            global_obs_shape: int,\n            action_shape: int,\n            hidden_size_list: list,\n            embedding_size: int,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "qtran.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4158415841584158}, {"context": "            else:\n                d = d.reshape(T, B, *d.shape[1:])\n            return d\n\n        x = x.reshape(T * B, *x.shape[2:])\n        x = forward_fn(x)\n        x = reshape(x)\n        return x\n\n    return wrapper\n\n\n@MODEL_REGISTRY.register('drqn')\nclass DRQN(nn.Module):\n    \"\"\"\n    Overview:\n        DQN + RNN = DRQN\n    \"\"\"\n\n    def __init__(", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "q_learning.py"], "line_no": 560, "start_line_no": 550, "end_line_no": 570, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.375}, {"context": "        return x\n\n\n@MODEL_REGISTRY.register('coma')\nclass COMA(nn.Module):\n    \"\"\"\n    Overview:\n        COMA network is QAC-type actor-critic.\n    \"\"\"\n    mode = ['compute_actor', 'compute_critic']\n\n    def __init__(\n            self, agent_num: int, obs_shape: Dict, action_shape: Union[int, SequenceType],\n            actor_hidden_size_list: SequenceType\n    ) -> None:\n        \"\"\"\n        Overview:\n            initialize COMA network\n        Arguments:\n            - agent_num (:obj:`int`): the number of agent", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "coma.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.34146341463414637}, {"context": "            >>> assert outputs['quantiles'].shape == torch.Size([128, 1])\n        \"\"\"\n        x = self.encoder(x)\n        x = self.head(x)\n        return x\n\n\n@MODEL_REGISTRY.register('rainbowdqn')\nclass RainbowDQN(nn.Module):\n    \"\"\"\n    Overview:\n        RainbowDQN network (C51 + Dueling + Noisy Block)\n\n    .. note::\n        RainbowDQN contains dueling architecture by default\n    \"\"\"\n\n    def __init__(\n        self,\n        obs_shape: Union[int, SequenceType],", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "q_learning.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "from typing import Dict\nimport torch\nimport torch.nn as nn\n\nfrom ding.utils import MODEL_REGISTRY\nfrom .q_learning import DQN\n\n\n@MODEL_REGISTRY.register('sqn')\nclass SQN(nn.Module):\n\n    def __init__(self, *args, **kwargs) -> None:\n        super(SQN, self).__init__()\n        self.q0 = DQN(*args, **kwargs)\n        self.q1 = DQN(*args, **kwargs)\n\n    def forward(self, data: torch.Tensor) -> Dict:\n        output0 = self.q0(data)\n        output1 = self.q1(data)\n        return {", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "template", "sqn.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3217391304347826}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/utils/file_utils.py\n# --------------------------------------------------\n#         return fn\n# \n#     return docstring_decorator\n# \n# \n# def estimate_dataset_size(paths):\n#     return sum(path.stat().st_size for path in paths)\n# \n# \n# def readline(f: io.RawIOBase):\n#     # From: https://github.com/python/cpython/blob/d27e2f4d118e7a9909b6a3e5da06c5ff95806a85/Lib/_pyio.py#L525\n#     res = bytearray()\n#     while True:\n#         b = f.read(1)\n#         if not b:\n#             break\n#         res += b\n#         if res.endswith(b\"\\n\"):\n#             break\n#     return bytes(res)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/nist_mt/nist_mt.py\n# --------------------------------------------------\n# \n#     def _compute(self, predictions, references, n: int = 5, lowercase=False, western_lang=True):\n#         tokenizer = NISTTokenizer()\n# \n#         # Account for single reference cases: references always need to have one more dimension than predictions\n#         if isinstance(references[0], str):\n#             references = [[ref] for ref in references]\n# \n#         predictions = [\n#             tokenizer.tokenize(pred, return_str=False, lowercase=lowercase, western_lang=western_lang)\n#             for pred in predictions\n#         ]\n#         references = [\n#             [\n#                 tokenizer.tokenize(ref, return_str=False, lowercase=lowercase, western_lang=western_lang)\n#                 for ref in ref_sentences\n#             ]\n#             for ref_sentences in references\n#         ]\n#         return {\"nist_mt\": corpus_nist(list_of_references=references, hypotheses=predictions, n=n)}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/evaluate/loading.py\n# --------------------------------------------------\n#         else:\n#             # Parse github url to point to zip\n#             github_path = parsed.path[1:]\n#             repo_info, branch = github_path.split(\"/tree/\") if \"/tree/\" in github_path else (github_path, \"master\")\n#             repo_owner, repo_name = repo_info.split(\"/\")\n#             url_path = f\"https://github.com/{repo_owner}/{repo_name}/archive/{branch}.zip\"\n#             sub_directory = f\"{repo_name}-{branch}\"\n#     return url_path, sub_directory\n# \n# \n# def increase_load_count(name: str, resource_type: str):\n#     \"\"\"Update the download count of a dataset or metric.\"\"\"\n#     if not config.HF_EVALUATE_OFFLINE and config.HF_UPDATE_DOWNLOAD_COUNTS:\n#         try:\n#             head_hf_s3(name, filename=name + \".py\", dataset=(resource_type == \"dataset\"))\n#         except Exception:\n#             pass\n# \n# \n# def get_imports(file_path: str) -> Tuple[str, str, str, str]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/sari/sari.py\n# --------------------------------------------------\n#     else:\n#         normalized_sent = sentence\n# \n#     if not return_str:\n#         normalized_sent = normalized_sent.split()\n# \n#     return normalized_sent\n# \n# \n# @evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n# class Sari(evaluate.Metric):\n#     def _info(self):\n#         return evaluate.MetricInfo(\n#             description=_DESCRIPTION,\n#             citation=_CITATION,\n#             inputs_description=_KWARGS_DESCRIPTION,\n#             features=datasets.Features(\n#                 {\n#                     \"sources\": datasets.Value(\"string\", id=\"sequence\"),\n#                     \"predictions\": datasets.Value(\"string\", id=\"sequence\"),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/sari/sari.py\n# --------------------------------------------------\n# \n#     # Normalization is requried for the ASSET dataset (one of the primary\n#     # datasets in sentence simplification) to allow using space\n#     # to split the sentence. Even though Wiki-Auto and TURK datasets,\n#     # do not require normalization, we do it for consistency.\n#     # Code adapted from the EASSE library [1] written by the authors of the ASSET dataset.\n#     # [1] https://github.com/feralvam/easse/blob/580bba7e1378fc8289c663f864e0487188fe8067/easse/utils/preprocessing.py#L7\n# \n#     if lowercase:\n#         sentence = sentence.lower()\n# \n#     if tokenizer in [\"13a\", \"intl\"]:\n#         if version.parse(sacrebleu.__version__).major >= 2:\n#             normalized_sent = sacrebleu.metrics.bleu._get_tokenizer(tokenizer)()(sentence)\n#         else:\n#             normalized_sent = sacrebleu.TOKENIZERS[tokenizer]()(sentence)\n#     elif tokenizer == \"moses\":\n#         normalized_sent = sacremoses.MosesTokenizer().tokenize(sentence, return_str=True, escape=False)\n#     elif tokenizer == \"penn\":\n#         normalized_sent = sacremoses.MosesTokenizer().penn_tokenize(sentence, return_str=True)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/sari/sari.py\n# --------------------------------------------------\n# \n#     if tokenizer in [\"13a\", \"intl\"]:\n#         if version.parse(sacrebleu.__version__).major >= 2:\n#             normalized_sent = sacrebleu.metrics.bleu._get_tokenizer(tokenizer)()(sentence)\n#         else:\n#             normalized_sent = sacrebleu.TOKENIZERS[tokenizer]()(sentence)\n#     elif tokenizer == \"moses\":\n#         normalized_sent = sacremoses.MosesTokenizer().tokenize(sentence, return_str=True, escape=False)\n#     elif tokenizer == \"penn\":\n#         normalized_sent = sacremoses.MosesTokenizer().penn_tokenize(sentence, return_str=True)\n#     else:\n#         normalized_sent = sentence\n# \n#     if not return_str:\n#         normalized_sent = normalized_sent.split()\n# \n#     return normalized_sent\n# \n# \n# @evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n_precision + keepscore_recall)\n\n    # DELETION\n    delgramcounter_rep = sgramcounter_rep - cgramcounter_rep\n    delgramcountergood_rep = delgramcounter_rep - rgramcounter\n    delgramcounterall_rep = sgramcounter_rep - rgramcounter\n    deltmpscore1 = 0\n    deltmpscore2 = 0\n    for delgram in delgramcountergood_rep:\n        deltmpscore1 += delgramcountergood_rep[delgram] / delgramcounter_rep[delgram]\n        deltmpscore2 += delgramcountergood_rep[delgram] / delgramcounterall_rep[delgram]\n    # Define 0/0=1 instead of 0 to give higher scores for predictions that match\n    # a target exactly.\n    delscore_precision = 1\n    if len(delgramcounter_rep) > 0:\n        delscore_precision = deltmpscore1 / len(delgramcounter_rep)\n\n    # ADDITION\n    addgramcounter = set(cgramcounter) - set(sgramcounter)\n    addgramcountergood = set(addgramcounter) & set(rgramcounter)\n    addgramcounterall = set(rgramcounter) - set(sgramcounter)\n\n    addtmpscore = 0\n    for addgram in addgramcountergood:\n        addtmpscore += 1\n\n    # Define 0/0=1 instead of 0 to give higher scores for predictions that match\n    # a target exactly.\n    addscore_precision = 1\n    addscore_recall = 1\n    if len(addgramcounter) > 0:\n        addscore_precision = addtmpscore / len(addgramcounter)\n    if len(addgramcounterall) > 0:\n        addscore_recall = addtmpscore / len(addgramcounterall)\n    addscore = 0\n    if addscore_precision > 0 or addscore_recall > 0:\n        addscore = 2 * addscore_precision * addscore_recall / (addscore_precision + addscore_recall)\n\n    return (keepscore, delscore_precision, addscore)\n\n\ndef SARIsent(ssent, csent, rsents):\n    numref = len(rsents)\n\n    s1grams = ssent.split(\" \")\n    c1grams = csent.split(\" \")\n    s2grams = []\n    c2grams = []\n    s3grams = []\n    c3grams = []\n    s4grams = []\n    c4grams = []\n\n    r1gramslist = []\n    r2gramslist = []\n    r3gramslist = []\n    r4gramslist = []\n    for rsent in rsents:\n        r1grams = rsent.split(\" \")\n        r2grams = []\n        r3grams = []\n        r4grams = []\n        r1gramslist.append(r1grams)\n        for i in range(0, len(r1grams) - 1):\n            if i < len(r1grams) - 1:\n                r2gram = r1grams[i] + \" \" + r1grams[i + 1]\n                r2grams.append(r2gram)\n            if i < len(r1grams) - 2:\n                r3gram = r1grams[i] + \" \" + r1grams[i + 1] + \" \" + r1grams[i + 2]\n                r3grams.append(r3gram)\n            if i < len(r1grams) - 3:\n                r4gram = r1grams[i] + \" \" + r1grams[i + 1] + \" \" + r1grams[i + 2] + \" \" + r1grams[i + 3]\n                r4grams.append(r4gram)\n        r2gramslist.append(r2grams)\n        r3gramslist.append(r3grams)\n        r4gramslist.append(r4grams)\n\n    for i in range(0, len(s1grams) - 1):\n        if i < len(s1grams) - 1:\n            s2gram = s1grams[i] + \" \" + s1grams[i + 1]\n            s2grams.append(s2gram)\n        if i < len(s1grams) - 2:\n            s3gram = s1grams[i] + \" \" + s1grams[i + 1] + \" \" + s1grams[i + 2]\n            s3grams.append(s3gram)\n        if i < len(s1grams) - 3:\n            s4gram = s1grams[i] + \" \" + s1grams[i + 1] + \" \" + s1grams[i + 2] + \" \" + s1grams[i + 3]\n            s4grams.append(s4gram)\n\n    for i in range(0, len(c1grams) - 1):\n        if i < len(c1grams) - 1:\n            c2gram = c1grams[i] + \" \" + c1grams[i + 1]\n            c2grams.append(c2gram)\n        if i < len(c1grams) - 2:\n            c3gram = c1grams[i] + \" \" + c1grams[i + 1] + \" \" + c1grams[i + 2]\n            c3grams.append(c3gram)\n        if i < len(c1grams) - 3:\n            c4gram = c1grams[i] + \" \" + c1grams[i + 1] + \" \" + c1grams[i + 2] + \" \" + c1grams[i + 3]\n            c4grams.append(c4gram)\n\n    (keep1score, del1score, add1score) = SARIngram(s1grams, c1grams, r1gramslist, numref)\n    (keep2score, del2score, add2score) = SARIngram(s2grams, c2grams, r2gramslist, numref)\n    (keep3score, del3score, add3score) = SARIngram(s3grams, c3grams, r3gramslist, numref)\n    (keep4score, del4score, add4score) = SARIngram(s4grams, c4grams, r4gramslist, numref)\n    avgkeepscore = sum([keep1score, keep2score, keep3score, keep4score]) / 4\n    avgdelscore = sum([del1score, del2score, del3score, del4score]) / 4\n    avgaddscore = sum([add1score, add2score, add3score, add4score]) / 4\n    finalscore = (avgkeepscore + avgdelscore + avgaddscore) / 3\n    return finalscore\n\n\ndef normalize(sentence, lowercase: bool = True, tokenizer: str = \"13a\", return_str: bool = True):\n\n    # Normalization is requried for the ASSET dataset (one of the primary\n    # datasets in sentence simplification) to allow using space\n    # to split the sentence. Even though Wiki-Auto and TURK datasets,\n    # do not require normalization, we do it for consistency.\n    # Code adapted from the EASSE library [1] written by the authors of the ASSET dataset.\n    # [1] https://github.com/feralvam/easse/blob/580bba7e1378fc8289c663f864e0487188fe8067/easse/utils/preprocessing.py#L7\n\n    if lowercase:\n        sentence = sentence.lower()\n\n    if tokenizer in [\"13a\", \"intl\"]:\n        if version.parse(sacrebleu.__version__).major >= 2:\n            normalized_sent = sacrebleu.metrics.bleu._get_tokenizer(tokenizer)()(sentence)\n        else:\n            normalized_sent = sacrebleu.TOKENIZERS[tokenizer]()(sentence)\n    elif tokenizer == \"moses\":\n        normalized_sent = sacremoses.MosesTokenizer().tokenize(sentence, return_str=True, escape=False)", "choices": [{"text": "normalized_sent = sacremoses.MosesTokenizer().tokenize(sentence, return_str=True, escape=False)"}], "metadata": {"task_id": "huggingface_evaluate/89", "ground_truth": "    elif tokenizer == \"penn\":", "fpath_tuple": ["huggingface_evaluate", "metrics", "wiki_split", "wiki_split.py"], "context_start_lineno": 146, "line_no": 275, "query_window": {"context": "\ndef normalize(sentence, lowercase: bool = True, tokenizer: str = \"13a\", return_str: bool = True):\n\n    # Normalization is requried for the ASSET dataset (one of the primary\n    # datasets in sentence simplification) to allow using space\n    # to split the sentence. Even though Wiki-Auto and TURK datasets,\n    # do not require normalization, we do it for consistency.\n    # Code adapted from the EASSE library [1] written by the authors of the ASSET dataset.\n    # [1] https://github.com/feralvam/easse/blob/580bba7e1378fc8289c663f864e0487188fe8067/easse/utils/preprocessing.py#L7\n\n    if lowercase:\n        sentence = sentence.lower()\n\n    if tokenizer in [\"13a\", \"intl\"]:\n        if version.parse(sacrebleu.__version__).major >= 2:\n            normalized_sent = sacrebleu.metrics.bleu._get_tokenizer(tokenizer)()(sentence)\n        else:\n            normalized_sent = sacrebleu.TOKENIZERS[tokenizer]()(sentence)\n    elif tokenizer == \"moses\":\n        normalized_sent = sacremoses.MosesTokenizer().tokenize(sentence, return_str=True, escape=False)", "metadata": {"fpath_tuple": ["huggingface_evaluate", "metrics", "wiki_split", "wiki_split.py"], "line_no": 275, "task_id": "huggingface_evaluate/89", "start_line_no": 255, "end_line_no": 275, "window_size": 20, "context_start_lineno": 146, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "\n    # Normalization is requried for the ASSET dataset (one of the primary\n    # datasets in sentence simplification) to allow using space\n    # to split the sentence. Even though Wiki-Auto and TURK datasets,\n    # do not require normalization, we do it for consistency.\n    # Code adapted from the EASSE library [1] written by the authors of the ASSET dataset.\n    # [1] https://github.com/feralvam/easse/blob/580bba7e1378fc8289c663f864e0487188fe8067/easse/utils/preprocessing.py#L7\n\n    if lowercase:\n        sentence = sentence.lower()\n\n    if tokenizer in [\"13a\", \"intl\"]:\n        if version.parse(sacrebleu.__version__).major >= 2:\n            normalized_sent = sacrebleu.metrics.bleu._get_tokenizer(tokenizer)()(sentence)\n        else:\n            normalized_sent = sacrebleu.TOKENIZERS[tokenizer]()(sentence)\n    elif tokenizer == \"moses\":\n        normalized_sent = sacremoses.MosesTokenizer().tokenize(sentence, return_str=True, escape=False)\n    elif tokenizer == \"penn\":\n        normalized_sent = sacremoses.MosesTokenizer().penn_tokenize(sentence, return_str=True)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "sari", "sari.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.9590643274853801}, {"context": "    (keep3score, del3score, add3score) = SARIngram(s3grams, c3grams, r3gramslist, numref)\n    (keep4score, del4score, add4score) = SARIngram(s4grams, c4grams, r4gramslist, numref)\n    avgkeepscore = sum([keep1score, keep2score, keep3score, keep4score]) / 4\n    avgdelscore = sum([del1score, del2score, del3score, del4score]) / 4\n    avgaddscore = sum([add1score, add2score, add3score, add4score]) / 4\n    finalscore = (avgkeepscore + avgdelscore + avgaddscore) / 3\n    return finalscore\n\n\ndef normalize(sentence, lowercase: bool = True, tokenizer: str = \"13a\", return_str: bool = True):\n\n    # Normalization is requried for the ASSET dataset (one of the primary\n    # datasets in sentence simplification) to allow using space\n    # to split the sentence. Even though Wiki-Auto and TURK datasets,\n    # do not require normalization, we do it for consistency.\n    # Code adapted from the EASSE library [1] written by the authors of the ASSET dataset.\n    # [1] https://github.com/feralvam/easse/blob/580bba7e1378fc8289c663f864e0487188fe8067/easse/utils/preprocessing.py#L7\n\n    if lowercase:\n        sentence = sentence.lower()", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "sari", "sari.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.62}, {"context": "\n    if tokenizer in [\"13a\", \"intl\"]:\n        if version.parse(sacrebleu.__version__).major >= 2:\n            normalized_sent = sacrebleu.metrics.bleu._get_tokenizer(tokenizer)()(sentence)\n        else:\n            normalized_sent = sacrebleu.TOKENIZERS[tokenizer]()(sentence)\n    elif tokenizer == \"moses\":\n        normalized_sent = sacremoses.MosesTokenizer().tokenize(sentence, return_str=True, escape=False)\n    elif tokenizer == \"penn\":\n        normalized_sent = sacremoses.MosesTokenizer().penn_tokenize(sentence, return_str=True)\n    else:\n        normalized_sent = sentence\n\n    if not return_str:\n        normalized_sent = normalized_sent.split()\n\n    return normalized_sent\n\n\n@evaluate.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "sari", "sari.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.41081081081081083}, {"context": "\ndef convert_github_url(url_path: str) -> Tuple[str, Optional[str]]:\n    \"\"\"Convert a link to a file on a github repo in a link to the raw github object.\"\"\"\n    parsed = urlparse(url_path)\n    sub_directory = None\n    if parsed.scheme in (\"http\", \"https\", \"s3\") and parsed.netloc == \"github.com\":\n        if \"blob\" in url_path:\n            if not url_path.endswith(\".py\"):\n                raise ValueError(f\"External import from github at {url_path} should point to a file ending with '.py'\")\n            url_path = url_path.replace(\"blob\", \"raw\")  # Point to the raw file\n        else:\n            # Parse github url to point to zip\n            github_path = parsed.path[1:]\n            repo_info, branch = github_path.split(\"/tree/\") if \"/tree/\" in github_path else (github_path, \"master\")\n            repo_owner, repo_name = repo_info.split(\"/\")\n            url_path = f\"https://github.com/{repo_owner}/{repo_name}/archive/{branch}.zip\"\n            sub_directory = f\"{repo_name}-{branch}\"\n    return url_path, sub_directory\n\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "loading.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1975806451612903}, {"context": "            reference_urls=[\"https://en.wikipedia.org/wiki/NIST_(metric)\"],\n        )\n\n    def _compute(self, predictions, references, n: int = 5, lowercase=False, western_lang=True):\n        tokenizer = NISTTokenizer()\n\n        # Account for single reference cases: references always need to have one more dimension than predictions\n        if isinstance(references[0], str):\n            references = [[ref] for ref in references]\n\n        predictions = [\n            tokenizer.tokenize(pred, return_str=False, lowercase=lowercase, western_lang=western_lang)\n            for pred in predictions\n        ]\n        references = [\n            [\n                tokenizer.tokenize(ref, return_str=False, lowercase=lowercase, western_lang=western_lang)\n                for ref in ref_sentences\n            ]\n            for ref_sentences in references", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "nist_mt", "nist_mt.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.19724770642201836}, {"context": "\n    return docstring_decorator\n\n\ndef add_end_docstrings(*docstr):\n    def docstring_decorator(fn):\n        fn.__doc__ = (fn.__doc__ if fn.__doc__ is not None else \"\") + \"\\n\\n\" + \"\".join(docstr)\n        return fn\n\n    return docstring_decorator\n\n\ndef estimate_dataset_size(paths):\n    return sum(path.stat().st_size for path in paths)\n\n\ndef readline(f: io.RawIOBase):\n    # From: https://github.com/python/cpython/blob/d27e2f4d118e7a9909b6a3e5da06c5ff95806a85/Lib/_pyio.py#L525\n    res = bytearray()\n    while True:", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 650, "start_line_no": 640, "end_line_no": 660, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.19491525423728814}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#         Convolution module.\n#     \"\"\"\n# \n#     depth: int = 28\n#     widen_factor: int = 10\n#     dropout_rate: float = 0.0\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     @nn.compact\n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Deep feature extractor subnetwork forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#     @nn.compact\n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Deep feature extractor subnetwork forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Deep feature extractor representation.\n#         \"\"\"\n#         blocks_per_group = (self.depth - 4) // 6\n# \n#         conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#         Widening factor.\n#     dropout_rate: float\n#         Dropout rate.\n#     dtype: Any\n#         Layers' dtype.\n#     activation: Callable\n#         Activation function.\n#     conv: ModuleDef\n#         Convolution module.\n#     \"\"\"\n# \n#     output_dim: int\n#     depth: int = 28\n#     widen_factor: int = 10\n#     dropout_rate: float = 0.0\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     def setup(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#         ----------\n#         x: jnp.ndarray\n#             Group inputs.\n#         train: bool\n#             Whether the call is performed during training.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Group outputs.\n#         \"\"\"\n#         for i in range(self.blocks_per_group):\n#             x = WideResnetBlock(\n#                 conv=self.conv,\n#                 norm=self.norm,\n#                 activation=self.activation,\n#                 filters=self.filters,\n#                 strides=self.strides if i == 0 else (1, 1),\n#                 dropout_rate=self.dropout_rate,\n#             )(x, train=train)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#     Attributes\n#     ----------\n#     conv: ModuleDef\n#         Convolution module.\n#     norm: ModuleDef\n#         Normalization module.\n#     activation: Callable\n#         Activation function.\n#     blocks_per_group: int\n#         Number of blocks per group.\n#     strides: Tuple[int, int]\n#         Strides.\n#     dropout_rate: float\n#         Dropout rate.\n#     \"\"\"\n# \n#     conv: ModuleDef\n#     norm: ModuleDef\n#     activation: Callable\n#     blocks_per_group: int\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#     filters: int\n#     strides: Tuple[int, int] = (1, 1)\n#     dropout_rate: float = 0.0\n# \n#     @nn.compact\n#     def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Group forward pass.\n# \n#         Parameters\n#         ----------\n#         x: jnp.ndarray\n#             Group inputs.\n#         train: bool\n#             Whether the call is performed during training.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Group outputs.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#     dropout_rate: float = 0.0\n# \n#     @nn.compact\n#     def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Block forward pass.\n# \n#         Parameters\n#         ----------\n#         x: jnp.ndarray\n#             Block inputs.\n#         train: bool\n#             Whether the call is performed during training.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Block outputs.\n#         \"\"\"\n#         dropout = nn.Dropout(rate=self.dropout_rate)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#     ----------\n#     conv: ModuleDef\n#         Convolution module.\n#     norm: ModuleDef\n#         Normalization module.\n#     activation: Callable\n#         Activation function.\n#     filters: int\n#         Number of filters.\n#     strides: Tuple[int, int]\n#         Strides.\n#     :param dropout_rate: float\n#         Dropout rate.\n#     \"\"\"\n# \n#     conv: ModuleDef\n#     norm: ModuleDef\n#     activation: Callable\n#     filters: int\n#     strides: Tuple[int, int] = (1, 1)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#     strides: Tuple[int, int]\n#         Strides.\n#     dropout_rate: float\n#         Dropout rate.\n#     \"\"\"\n# \n#     conv: ModuleDef\n#     norm: ModuleDef\n#     activation: Callable\n#     blocks_per_group: int\n#     filters: int\n#     strides: Tuple[int, int] = (1, 1)\n#     dropout_rate: float = 0.0\n# \n#     @nn.compact\n#     def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Group forward pass.\n# \n#         Parameters\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/wideresnet.py\n# --------------------------------------------------\n#         Strides.\n#     :param dropout_rate: float\n#         Dropout rate.\n#     \"\"\"\n# \n#     conv: ModuleDef\n#     norm: ModuleDef\n#     activation: Callable\n#     filters: int\n#     strides: Tuple[int, int] = (1, 1)\n#     dropout_rate: float = 0.0\n# \n#     @nn.compact\n#     def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Block forward pass.\n# \n#         Parameters\n#         ----------\n#         x: jnp.ndarray\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\"\"\"\nFlax implementation of ResNet V1.\nTaken as is from https://github.com/google/flax/blob/main/examples/imagenet/models.py\n\"\"\"\n\n# See issue #620.\n# pytype: disable=wrong-arg-count\n\nfrom functools import partial\nfrom typing import Any, Callable, Sequence, Tuple\n\nimport flax.linen as nn\nimport jax.numpy as jnp\n\nfrom fortuna.typing import Array\n\nModuleDef = Any\n\n\nclass ResNetBlock(nn.Module):\n    \"\"\"\n    Residual network block.\n\n    Attributes\n    ----------\n    filters: int\n        Number of filters.\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    strides: Tuple[int, int]\n        Strides.\n    \"\"\"\n\n    filters: int\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    strides: Tuple[int, int] = (1, 1)\n\n    @nn.compact", "choices": [{"text": "def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:"}], "metadata": {"task_id": "awslabs_fortuna/82", "ground_truth": "    def __call__(self, x: jnp.ndarray,) -> jnp.ndarray:", "fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "context_start_lineno": 0, "line_no": 44, "query_window": {"context": "    ----------\n    filters: int\n        Number of filters.\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    strides: Tuple[int, int]\n        Strides.\n    \"\"\"\n\n    filters: int\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    strides: Tuple[int, int] = (1, 1)\n\n    @nn.compact", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 44, "task_id": "awslabs_fortuna/82", "start_line_no": 24, "end_line_no": 44, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    filters: int\n        Number of filters.\n    strides: Tuple[int, int]\n        Strides.\n    :param dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    filters: int\n    strides: Tuple[int, int] = (1, 1)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7636363636363637}, {"context": "    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    blocks_per_group: int\n        Number of blocks per group.\n    strides: Tuple[int, int]\n        Strides.\n    dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    blocks_per_group: int", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6101694915254238}, {"context": "from fortuna.typing import Array\n\nModuleDef = Any\n\n\nclass WideResnetBlock(nn.Module):\n    \"\"\"\n    A wide residual network block.\n\n    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    filters: int\n        Number of filters.\n    strides: Tuple[int, int]", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5441176470588235}, {"context": "        Strides.\n    :param dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Block forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.47368421052631576}, {"context": "    strides: Tuple[int, int]\n        Strides.\n    dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    blocks_per_group: int\n    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Group forward pass.\n\n        Parameters", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.44155844155844154}, {"context": "        # Apply an up projection in case of channel mismatch\n        if (x.shape[-1] != self.filters) or self.strides != (1, 1):\n            x = self.conv(self.filters, (3, 3), self.strides)(x)\n        return x + y\n\n\nclass WideResnetGroup(nn.Module):\n    \"\"\"\n    A wide residual network group.\n\n    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    blocks_per_group: int\n        Number of blocks per group.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3894736842105263}, {"context": "    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Group forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Group inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Group outputs.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.32142857142857145}, {"context": "    \"\"\"\n    Wide residual network class.\n\n    Attributes\n    ----------\n    output_dim: int\n        Output dimension.\n    depth: int\n        Depth of the subnetwork.\n    widen_factor: int\n        Widening factor.\n    dropout_rate: float\n        Dropout rate.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2948717948717949}, {"context": "        Convolution module.\n    \"\"\"\n\n    depth: int = 28\n    widen_factor: int = 10\n    dropout_rate: float = 0.0\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    @nn.compact\n    def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Deep feature extractor subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: Array\n            Input data.\n        train: bool", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.26804123711340205}, {"context": "        Depth of the subnetwork.\n    widen_factor: int\n        Widening factor.\n    dropout_rate: float\n        Dropout rate.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    depth: int = 28\n    widen_factor: int = 10\n    dropout_rate: float = 0.0\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.26506024096385544}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n# ###############################################################################\n# \n# # save results\n# torch.save(\n#     {\n#         \"frames\": frames,\n#         \"evals\": evals,\n#         \"mavgs\": mavgs,\n#         \"losses\": losses,\n#         \"values\": values,\n#         \"grad_vals\": grad_vals,\n#         \"traj_lengths_training\": traj_lengths,\n#         \"traj_count\": traj_count,\n#         \"weights\": (params,),\n#     },\n#     \"saved_results_td0.pt\",\n# )\n# \n# ###############################################################################\n# # TD-lambda\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb.py\n# --------------------------------------------------\n#     rb = TensorDictPrioritizedReplayBuffer(\n#         alpha=0.7,\n#         beta=0.9,\n#         priority_key=\"td_error\",\n#         storage=ListStorage(5),\n#     )\n#     rb.extend(traj_td)\n#     sampled_td = rb.sample(3)\n#     sampled_td.set(\"td_error\", torch.rand(3))\n#     rb.update_tensordict_priority(sampled_td)\n#     sampled_td = rb.sample(3, include_info=True)\n#     assert (sampled_td.get(\"_weight\") > 0).all()\n#     assert sampled_td.batch_size == torch.Size([3])\n# \n#     # set back the trajectory length\n#     sampled_td_filtered = sampled_td.to_tensordict().exclude(\n#         \"_weight\", \"index\", \"td_error\"\n#     )\n#     sampled_td_filtered.batch_size = [3, 4]\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#         \"grad_vals\": grad_vals,\n#         \"traj_lengths_training\": traj_lengths,\n#         \"traj_count\": traj_count,\n#         \"weights\": (params,),\n#     },\n#     \"saved_results_td0.pt\",\n# )\n# \n# ###############################################################################\n# # TD-lambda\n# # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n# # We can improve the above algorithm by getting a better estimate of the\n# # return, using not only the next state value but the whole sequence of rewards\n# # and values that follow a particular step.\n# #\n# # TorchRL provides a vectorized version of TD(lambda) named\n# # ``vec_td_lambda_advantage_estimate``. We'll use this to obtain a target\n# # value that the value network will be trained to match.\n# #\n# # The big difference in this implementation is that we'll store entire\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#         if is_notebook():\n#             plt.show()\n# \n#     # update policy weights\n#     data_collector.update_policy_weights_()\n# \n# if is_notebook():\n#     display.clear_output(wait=True)\n#     display.display(plt.gcf())\n# \n# ###############################################################################\n# # **Note**: As already mentioned above, to get a more reasonable performance,\n# # use a greater value for ``total_frames`` e.g. 500000.\n# \n# \n# plt.figure(figsize=(15, 15))\n# plt.imshow(plt.imread(\"dqn_td0.png\"))\n# plt.tight_layout()\n# plt.axis(\"off\")\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#                 plt.clf()\n#             plt.figure(figsize=(15, 15))\n#             plt.subplot(3, 2, 1)\n#             plt.plot(frames[-len(evals) :], evals, label=\"return\")\n#             plt.plot(frames[-len(mavgs) :], mavgs, label=\"mavg\")\n#             plt.xlabel(\"frames collected\")\n#             plt.ylabel(\"trajectory length (= return)\")\n#             plt.subplot(3, 2, 2)\n#             plt.plot(traj_count[-len(evals) :], evals, label=\"return\")\n#             plt.plot(traj_count[-len(mavgs) :], mavgs, label=\"mavg\")\n#             plt.xlabel(\"trajectories collected\")\n#             plt.legend()\n#             plt.subplot(3, 2, 3)\n#             plt.plot(frames[-len(losses) :], losses)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"loss\")\n#             plt.subplot(3, 2, 4)\n#             plt.plot(frames[-len(values) :], values)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"value\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#             plt.subplot(3, 2, 5)\n#             plt.plot(frames[-len(grad_vals) :], grad_vals)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"grad norm\")\n#             if len(traj_lengths):\n#                 plt.subplot(3, 2, 6)\n#                 plt.plot(traj_lengths)\n#                 plt.xlabel(\"batches\")\n#                 plt.title(\"traj length (training)\")\n#         plt.savefig(\"dqn_td0.png\")\n#         if is_notebook():\n#             plt.show()\n# \n#     # update policy weights\n#     data_collector.update_policy_weights_()\n# \n# if is_notebook():\n#     display.clear_output(wait=True)\n#     display.display(plt.gcf())\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_dqn.py\n# --------------------------------------------------\n#             plt.xlabel(\"trajectories collected\")\n#             plt.legend()\n#             plt.subplot(3, 2, 3)\n#             plt.plot(frames[-len(losses) :], losses)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"loss\")\n#             plt.subplot(3, 2, 4)\n#             plt.plot(frames[-len(values) :], values)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"value\")\n#             plt.subplot(3, 2, 5)\n#             plt.plot(frames[-len(grad_vals) :], grad_vals)\n#             plt.xlabel(\"frames collected\")\n#             plt.title(\"grad norm\")\n#             if len(traj_lengths):\n#                 plt.subplot(3, 2, 6)\n#                 plt.plot(traj_lengths)\n#                 plt.xlabel(\"batches\")\n#                 plt.title(\"traj length (training)\")\n#         plt.savefig(\"dqn_td0.png\")\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n(gv))\n        traj_lengths_eval.append(eval_rollout.shape[-1])\n        evals.append(eval_rollout[\"reward\"].squeeze(-1).sum(-1).item())\n        if len(mavgs):\n            mavgs.append(evals[-1] * 0.05 + mavgs[-1] * 0.95)\n        else:\n            mavgs.append(evals[-1])\n        losses.append(error.item())\n        values.append(action_value[mask].mean().item())\n        traj_count.append(prev_traj_count + data[\"done\"].sum().item())\n        prev_traj_count = traj_count[-1]\n        # plots\n        if j % 10 == 0:\n            if is_notebook():\n                display.clear_output(wait=True)\n                display.display(plt.gcf())\n            else:\n                plt.clf()\n            plt.figure(figsize=(15, 15))\n            plt.subplot(3, 2, 1)\n            plt.plot(frames[-len(evals) :], evals, label=\"return\")\n            plt.plot(frames[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"frames collected\")\n            plt.ylabel(\"trajectory length (= return)\")\n            plt.subplot(3, 2, 2)\n            plt.plot(traj_count[-len(evals) :], evals, label=\"return\")\n            plt.plot(traj_count[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"trajectories collected\")\n            plt.legend()\n            plt.subplot(3, 2, 3)\n            plt.plot(frames[-len(losses) :], losses)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"loss\")\n            plt.subplot(3, 2, 4)\n            plt.plot(frames[-len(values) :], values)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"value\")\n            plt.subplot(3, 2, 5)\n            plt.plot(frames[-len(grad_vals) :], grad_vals)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"grad norm\")\n            if len(traj_lengths):\n                plt.subplot(3, 2, 6)\n                plt.plot(traj_lengths)\n                plt.xlabel(\"batches\")\n                plt.title(\"traj length (training)\")\n        plt.savefig(\"dqn_tdlambda.png\")\n        if is_notebook():\n            plt.show()\n\n    # update policy weights\n    data_collector.update_policy_weights_()\n\nif is_notebook():\n    display.clear_output(wait=True)\n    display.display(plt.gcf())\n\n###############################################################################\n# **Note**: As already mentioned above, to get a more reasonable performance,\n# use a greater value for ``total_frames`` e.g. 500000.\n\nplt.figure(figsize=(15, 15))\nplt.imshow(plt.imread(\"dqn_tdlambda.png\"))\nplt.tight_layout()\nplt.axis(\"off\")\n\n###############################################################################\n\n# save results\ntorch.save(\n    {\n        \"frames\": frames,\n        \"evals\": evals,\n        \"mavgs\": mavgs,\n        \"losses\": losses,\n        \"values\": values,\n        \"grad_vals\": grad_vals,\n        \"traj_lengths_training\": traj_lengths,\n        \"traj_count\": traj_count,\n        \"weights\": (params,),\n    },\n    \"saved_results_tdlambda.pt\",\n)\n\n###############################################################################\n# Let's compare the results on a single plot. Because the TD(lambda) version\n# works better, we'll have fewer episodes collected for a given number of\n# frames (as there are more frames per episode).\n#\n# **Note**: As already mentioned above, to get a more reasonable performance,\n# use a greater value for ``total_frames`` e.g. 500000.\n\nload_td0 = torch.load(\"saved_results_td0.pt\")\nload_tdlambda = torch.load(\"saved_results_tdlambda.pt\")\nframes_td0 = load_td0[\"frames\"]\nframes_tdlambda = load_tdlambda[\"frames\"]\nevals_td0 = load_td0[\"evals\"]\nevals_tdlambda = load_tdlambda[\"evals\"]\nmavgs_td0 = load_td0[\"mavgs\"]\nmavgs_tdlambda = load_tdlambda[\"mavgs\"]\nlosses_td0 = load_td0[\"losses\"]\nlosses_tdlambda = load_tdlambda[\"losses\"]\nvalues_td0 = load_td0[\"values\"]\nvalues_tdlambda = load_tdlambda[\"values\"]\ngrad_vals_td0 = load_td0[\"grad_vals\"]\ngrad_vals_tdlambda = load_tdlambda[\"grad_vals\"]\ntraj_lengths_td0 = load_td0[\"traj_lengths_training\"]\ntraj_lengths_tdlambda = load_tdlambda[\"traj_lengths_training\"]\ntraj_count_td0 = load_td0[\"traj_count\"]\ntraj_count_tdlambda = load_tdlambda[\"traj_count\"]\n\nplt.figure(figsize=(15, 15))\nplt.subplot(3, 2, 1)\nplt.plot(frames[-len(evals_td0) :], evals_td0, label=\"return (td0)\", alpha=0.5)\nplt.plot(\n    frames[-len(evals_tdlambda) :],\n    evals_tdlambda,\n    label=\"return (td(lambda))\",\n    alpha=0.5,\n)\nplt.plot(frames[-len(mavgs_td0) :], mavgs_td0, label=\"mavg (td0)\")\nplt.plot(frames[-len(mavgs_tdlambda) :], mavgs_tdlambda, label=\"mavg (td(lambda))\")\nplt.xlabel(\"frames collected\")\nplt.ylabel(\"trajectory length (= return)\")\nplt.subplot(3, 2, 2)\nplt.plot(traj_count_td0[-len(evals_td0) :], evals_td0, label=\"return (td0)\", alpha=0.5)\nplt.plot(\n    traj_count_tdlambda[-len(evals_tdlambda) :],\n    evals_tdlambda,\n    label=\"return (td(lambda))\",\n    alpha=0.5,\n)\nplt.plot(traj_count_td0[-len(mavgs_td0) :], mavgs_td0, label=\"mavg (td0)\")\nplt.plot(\n    traj_count_tdlambda[-len(mavgs_tdlambda) :],\n    mavgs_tdlambda,\n    label=\"mavg (td(lambda))\",\n)\nplt.xlabel(\"trajectories collected\")\nplt.legend()\nplt.subplot(3, 2, 3)\nplt.plot(frames[-len(losses_td0) :], losses_td0, label=\"loss (td0)\")\nplt.plot(frames[-len(losses_tdlambda) :], losses_tdlambda, label=\"loss (td(lambda))\")\nplt.xlabel(\"frames collected\")\nplt.title(\"loss\")\nplt.legend()\nplt.subplot(3, 2, 4)\nplt.plot(frames[-len(values_td0) :], values_td0, label=\"values (td0)\")\nplt.plot(frames[-len(values_tdlambda) :], values_tdlambda, label=\"values (td(lambda))\")\nplt.xlabel(\"frames collected\")", "choices": [{"text": "plt.title(\"value\")"}], "metadata": {"task_id": "pytorch_rl/189", "ground_truth": "plt.title(\"value\")", "fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "context_start_lineno": 675, "line_no": 825, "query_window": {"context": "    alpha=0.5,\n)\nplt.plot(traj_count_td0[-len(mavgs_td0) :], mavgs_td0, label=\"mavg (td0)\")\nplt.plot(\n    traj_count_tdlambda[-len(mavgs_tdlambda) :],\n    mavgs_tdlambda,\n    label=\"mavg (td(lambda))\",\n)\nplt.xlabel(\"trajectories collected\")\nplt.legend()\nplt.subplot(3, 2, 3)\nplt.plot(frames[-len(losses_td0) :], losses_td0, label=\"loss (td0)\")\nplt.plot(frames[-len(losses_tdlambda) :], losses_tdlambda, label=\"loss (td(lambda))\")\nplt.xlabel(\"frames collected\")\nplt.title(\"loss\")\nplt.legend()\nplt.subplot(3, 2, 4)\nplt.plot(frames[-len(values_td0) :], values_td0, label=\"values (td0)\")\nplt.plot(frames[-len(values_tdlambda) :], values_tdlambda, label=\"values (td(lambda))\")\nplt.xlabel(\"frames collected\")", "metadata": {"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 825, "task_id": "pytorch_rl/189", "start_line_no": 805, "end_line_no": 825, "window_size": 20, "context_start_lineno": 675, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "                plt.clf()\n            plt.figure(figsize=(15, 15))\n            plt.subplot(3, 2, 1)\n            plt.plot(frames[-len(evals) :], evals, label=\"return\")\n            plt.plot(frames[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"frames collected\")\n            plt.ylabel(\"trajectory length (= return)\")\n            plt.subplot(3, 2, 2)\n            plt.plot(traj_count[-len(evals) :], evals, label=\"return\")\n            plt.plot(traj_count[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"trajectories collected\")\n            plt.legend()\n            plt.subplot(3, 2, 3)\n            plt.plot(frames[-len(losses) :], losses)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"loss\")\n            plt.subplot(3, 2, 4)\n            plt.plot(frames[-len(values) :], values)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"value\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.575}, {"context": "            plt.xlabel(\"trajectories collected\")\n            plt.legend()\n            plt.subplot(3, 2, 3)\n            plt.plot(frames[-len(losses) :], losses)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"loss\")\n            plt.subplot(3, 2, 4)\n            plt.plot(frames[-len(values) :], values)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"value\")\n            plt.subplot(3, 2, 5)\n            plt.plot(frames[-len(grad_vals) :], grad_vals)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"grad norm\")\n            if len(traj_lengths):\n                plt.subplot(3, 2, 6)\n                plt.plot(traj_lengths)\n                plt.xlabel(\"batches\")\n                plt.title(\"traj length (training)\")\n        plt.savefig(\"dqn_td0.png\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4878048780487805}, {"context": "        losses.append(error.item())\n        values.append(action_value.mean().item())\n        traj_count.append(prev_traj_count + data[\"done\"].sum().item())\n        prev_traj_count = traj_count[-1]\n        # plots\n        if j % 10 == 0:\n            if is_notebook():\n                display.clear_output(wait=True)\n                display.display(plt.gcf())\n            else:\n                plt.clf()\n            plt.figure(figsize=(15, 15))\n            plt.subplot(3, 2, 1)\n            plt.plot(frames[-len(evals) :], evals, label=\"return\")\n            plt.plot(frames[-len(mavgs) :], mavgs, label=\"mavg\")\n            plt.xlabel(\"frames collected\")\n            plt.ylabel(\"trajectory length (= return)\")\n            plt.subplot(3, 2, 2)\n            plt.plot(traj_count[-len(evals) :], evals, label=\"return\")\n            plt.plot(traj_count[-len(mavgs) :], mavgs, label=\"mavg\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3305785123966942}, {"context": "            plt.subplot(3, 2, 5)\n            plt.plot(frames[-len(grad_vals) :], grad_vals)\n            plt.xlabel(\"frames collected\")\n            plt.title(\"grad norm\")\n            if len(traj_lengths):\n                plt.subplot(3, 2, 6)\n                plt.plot(traj_lengths)\n                plt.xlabel(\"batches\")\n                plt.title(\"traj length (training)\")\n        plt.savefig(\"dqn_td0.png\")\n        if is_notebook():\n            plt.show()\n\n    # update policy weights\n    data_collector.update_policy_weights_()\n\nif is_notebook():\n    display.clear_output(wait=True)\n    display.display(plt.gcf())\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 480, "start_line_no": 470, "end_line_no": 490, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3113207547169811}, {"context": "###############################################################################\n\n# save results\ntorch.save(\n    {\n        \"frames\": frames,\n        \"evals\": evals,\n        \"mavgs\": mavgs,\n        \"losses\": losses,\n        \"values\": values,\n        \"grad_vals\": grad_vals,\n        \"traj_lengths_training\": traj_lengths,\n        \"traj_count\": traj_count,\n        \"weights\": (params,),\n    },\n    \"saved_results_td0.pt\",\n)\n\n###############################################################################\n# TD-lambda", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30337078651685395}, {"context": "\n@pytest.mark.parametrize(\"stack\", [False, True])\ndef test_rb_trajectories(stack):\n    traj_td = TensorDict(\n        {\"obs\": torch.randn(3, 4, 5), \"actions\": torch.randn(3, 4, 2)},\n        batch_size=[3, 4],\n    )\n    if stack:\n        traj_td = torch.stack([td.to_tensordict() for td in traj_td], 0)\n\n    rb = TensorDictPrioritizedReplayBuffer(\n        alpha=0.7,\n        beta=0.9,\n        priority_key=\"td_error\",\n        storage=ListStorage(5),\n    )\n    rb.extend(traj_td)\n    sampled_td = rb.sample(3)\n    sampled_td.set(\"td_error\", torch.rand(3))\n    rb.update_tensordict_priority(sampled_td)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb.py"], "line_no": 670, "start_line_no": 660, "end_line_no": 680, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21374045801526717}, {"context": "###############################################################################\n# **Note**: As already mentioned above, to get a more reasonable performance,\n# use a greater value for ``total_frames`` e.g. 500000.\n\n\nplt.figure(figsize=(15, 15))\nplt.imshow(plt.imread(\"dqn_td0.png\"))\nplt.tight_layout()\nplt.axis(\"off\")\n\n###############################################################################\n\n# save results\ntorch.save(\n    {\n        \"frames\": frames,\n        \"evals\": evals,\n        \"mavgs\": mavgs,\n        \"losses\": losses,\n        \"values\": values,", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_dqn.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21367521367521367}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmark/pFL-Bench/res_analysis_plot/render_paper_res.py\n# --------------------------------------------------\n#     res_to_print_matrix = highlight_tex_res_in_table(res_to_print_matrix,\n#                                                      rank_order=rank_order)\n#     for res_to_print in res_to_print_matrix:\n#         print(\"&\".join(res_to_print) + \"\\\\\\\\\")\n# \n#     print(\"\\n=============res_of_each_line [Fairness]===============\" +\n#           \",\".join(list(filters_each_line_table.keys())))\n#     res_to_print_matrix = []\n#     for key in expected_method_names:\n#         res_to_print = [\n#             \"{:.2f}\".format(v * 100) if v != \"-\" else v\n#             for v in res_of_each_line_fair[key]\n#         ]\n#         res_to_print = [key] + res_to_print\n#         res_to_print_matrix.append(res_to_print)\n#         # print(\"&\".join(res_to_print) + \"\\\\\\\\\")\n# \n#     colum_order_per_data = [\"+\", \"-\", \"+\"]\n#     # \"+\" indicates the larger, the better\n#     rank_order = colum_order_per_data * len(filters_each_line_table)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmark/pFL-Bench/res_analysis_plot/render_paper_res.py\n# --------------------------------------------------\n#         res_of_each_line_commu_acc_trade[key] = []\n#         dataset_num = 2 if \"cola\" in list(\n#             filters_each_line_table.keys()) else 3\n#         for i in range(dataset_num):\n#             res_of_each_line_commu_acc_trade[key].extend(\n#                 [str(res_of_each_line_efficiency[key][i * 4])] + \\\n#                 [str(res_of_each_line_efficiency[key][i * 4 + 1])] + \\\n#                 [\"{:.2f}\".format(v * 100) if v != \"-\" else v for v in\n#                  res_of_each_line_generalization[key][i * 3:i * 3 + 1]]\n#             )\n# \n#         res_to_print = [str(v) for v in res_of_each_line_commu_acc_trade[key]]\n#         res_to_print = [key] + res_to_print\n#         res_to_print_matrix.append(res_to_print)\n#         # print(\"&\".join(res_to_print)+ \"\\\\\\\\\")\n# \n#     colum_order_per_data = [\"-\", \"-\", \"+\"]\n#     # \"+\" indicates the larger, the better\n#     rank_order = colum_order_per_data * len(filters_each_line_table)\n#     res_to_print_matrix = highlight_tex_res_in_table(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmark/pFL-Bench/res_analysis_plot/wandb_to_latex_res.py\n# --------------------------------------------------\n#         res_to_print = [sorted_method_name_to_print[key]] + res_to_print\n#         #print(\",\".join(res_to_print))\n#         res_to_print_matrix.append(res_to_print)\n# \n#     colum_order_per_data = [\"-\", \"-\", \"-\"]\n#     # \"+\" indicates the larger, the better\n#     rank_order = colum_order_per_data * len(filters_each_line_table)\n#     res_to_print_matrix = highlight_tex_res_in_table(\n#         res_to_print_matrix,\n#         rank_order=rank_order,\n#         filter_out=[\"Global-Train\"])\n#     for res_to_print in res_to_print_matrix:\n#         print(\"&\".join(res_to_print) + \"\\\\\\\\\")\n# \n#     #print(\"\\n=============res_of_each_line [All Efficiency]===============\" + \",\".join(\n#     #    list(filters_each_line_table.keys())))\n#     ## FLOPS, UPLOAD, DOWNLOAD\n# \n#     #for key in sorted_method_name_to_print:\n#     #    res_to_print = [str(v) for v in res_of_each_line_efficiency[key]]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmark/pFL-Bench/res_analysis_plot/wandb_to_latex_res.py\n# --------------------------------------------------\n#         res_of_each_line_commu_acc_trade[key] = []\n#         for i in range(dataset_num):\n#             try:\n#                 res_of_each_line_commu_acc_trade[key].extend(\n#                     [str(res_of_each_line_efficiency[key][i * 4])] + \\\n#                     [str(res_of_each_line_efficiency[key][i * 4 + 1])] + \\\n#                     [\"{:.2f}\".format(v * times_ratio) if v != \"-\" else v for v in\n#                      res_of_each_line_generalization[key][i * 3:i * 3 + 1]]\n#                 )\n#             except:\n#                 print(f\"error with index i={i}\")\n# \n#         res_to_print = [str(v) for v in res_of_each_line_commu_acc_trade[key]]\n#         res_to_print = [sorted_method_name_to_print[key]] + res_to_print\n#         #print(\",\".join(res_to_print))\n#         res_to_print_matrix.append(res_to_print)\n# \n#     colum_order_per_data = [\"-\", \"-\", \"-\"]\n#     # \"+\" indicates the larger, the better\n#     rank_order = colum_order_per_data * len(filters_each_line_table)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmark/pFL-Bench/res_analysis_plot/wandb_to_latex_res.py\n# --------------------------------------------------\n#           \",\".join(list(filters_each_line_table.keys())))\n#     # Acc, Unseen-ACC, Delta\n#     res_to_print_matrix = []\n#     times_ratio = 100 if percent else 1\n#     for key in sorted_method_name_to_print:\n#         res_to_print = [\n#             \"{:.2f}\".format(v * times_ratio) if v != \"-\" else v\n#             for v in res_of_each_line_generalization[key]\n#         ]\n#         res_to_print = [sorted_method_name_to_print[key]] + res_to_print\n#         #print(\",\".join(res_to_print))\n#         res_to_print_matrix.append(res_to_print)\n# \n#     colum_order_per_data = [\"-\", \"-\",\n#                             \"-\"]  # for the loss, the smaller the better\n#     # \"+\" indicates the larger, the better\n#     rank_order = colum_order_per_data * len(filters_each_line_table)\n#     res_to_print_matrix = highlight_tex_res_in_table(res_to_print_matrix,\n#                                                      rank_order=rank_order)\n#     for res_to_print in res_to_print_matrix:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\" in sub or \"cora\" in sub or \"cola\" in sub or \"pubmed\" in sub or \"citeseer\" in sub or \"sst2\" in sub \\\n                        or \"s02\" in sub or \"s005\" in sub or \"s01\" in sub \\\n                        or \"alpha5\" in sub or \"alpha0.5\" in sub or \"alpha0.1\" in sub:\n                    pass\n                else:\n                    filter_split_res.append(sub)\n            method_header = \"-\".join(sorted(filter_split_res))\n            if method_header in unseen_keys:\n                unseen_keys.remove(method_header)\n\n            # save config\n            parent_dir = os.path.join(\n                os.path.dirname(os.path.abspath(__file__)), \"..\")\n            best_cfg_dir = os.path.join(parent_dir, \"yaml_best_rums\")\n            os.makedirs(best_cfg_dir, exist_ok=True)\n            yaml_f_name = f\"best_{sorted_keys[method_header]}_on_{data_name}.yaml\"\n            with open(os.path.join(best_cfg_dir, yaml_f_name), 'w') as yml_f:\n                yaml.dump(best_run_cfg, yml_f, allow_unicode=True)\n\n            if method_header not in res_of_each_line_generalization:\n                res_of_each_line_generalization[\n                    method_header] = res_all_generalization\n                res_of_each_line_fair[method_header] = res_all_fair\n                res_of_each_line_efficiency[method_header] = res_all_efficiency\n            else:\n                res_of_each_line_generalization[method_header].extend(\n                    res_all_generalization)\n                res_of_each_line_fair[method_header].extend(res_all_fair)\n                res_of_each_line_efficiency[method_header].extend(\n                    res_all_efficiency)\n\n        for missing_header in unseen_keys:\n            print(\n                f\"the header is missing {missing_header} in dataset {data_name}\"\n            )\n            if missing_header not in res_of_each_line_generalization:\n                res_of_each_line_generalization[missing_header] = [\"-\"] * 3\n                res_of_each_line_fair[missing_header] = [\"-\"] * 3\n                res_of_each_line_efficiency[missing_header] = [\"-\"] * 4\n            else:\n                res_of_each_line_generalization[missing_header].extend([\"-\"] *\n                                                                       3)\n                res_of_each_line_fair[missing_header].extend([\"-\"] * 3)\n                res_of_each_line_efficiency[missing_header].extend([\"-\"] * 4)\n\n    print(\"\\n=============res_of_each_line [Generalization]===============\" +\n          \",\".join(list(filters_each_line_table.keys())))\n    # Acc, Unseen-ACC, Delta\n    for key in sorted_keys:\n        res_to_print = [\n            \"{:.2f}\".format(v * 100) if v != \"-\" else v\n            for v in res_of_each_line_generalization[key]\n        ]\n        res_to_print = [sorted_keys[key]] + res_to_print\n        print(\",\".join(res_to_print))\n    print(\"\\n=============res_of_each_line [Fairness]===============\" +\n          \",\".join(list(filters_each_line_table.keys())))\n    for key in sorted_keys:\n        res_to_print = [\n            \"{:.2f}\".format(v * 100) if v != \"-\" else v\n            for v in res_of_each_line_fair[key]\n        ]\n        res_to_print = [sorted_keys[key]] + res_to_print\n        print(\",\".join(res_to_print))\n    print(\"\\n=============res_of_each_line [All Efficiency]===============\" +\n          \",\".join(list(filters_each_line_table.keys())))\n    # FLOPS, UPLOAD, DOWNLOAD\n    for key in sorted_keys:\n        res_to_print = [str(v) for v in res_of_each_line_efficiency[key]]\n        res_to_print = [sorted_keys[key]] + res_to_print\n        print(\",\".join(res_to_print))\n    print(\n        \"\\n=============res_of_each_line [flops, communication, acc]===============\"\n        + \",\".join(list(filters_each_line_table.keys())))\n    for key in sorted_keys:\n        res_of_each_line_commu_acc_trade[key] = []\n        dataset_num = 2 if \"cola\" in list(\n            filters_each_line_table.keys()) else 3\n        for i in range(dataset_num):\n            res_of_each_line_commu_acc_trade[key].extend(\n                [str(res_of_each_line_efficiency[key][i * 4])] + \\\n                [str(res_of_each_line_efficiency[key][i * 4 + 1])] + \\\n                [\"{:.2f}\".format(v * 100) if v != \"-\" else v for v in res_of_each_line_fair[key][i * 3:i * 3 + 1]]\n            )\n\n        res_to_print = [str(v) for v in res_of_each_line_commu_acc_trade[key]]\n        res_to_print = [sorted_keys[key]] + res_to_print\n        print(\",\".join(res_to_print))\n    print(\n        \"\\n=============res_of_each_line [converge_round, acc]===============\"\n        + \",\".join(list(filters_each_line_table.keys())))\n    for key in sorted_keys:\n        res_of_each_line_conver_acc_trade[key] = []\n        dataset_num = 2 if \"cola\" in list(\n            filters_each_line_table.keys()) else 3\n        for i in range(dataset_num):\n            res_of_each_line_conver_acc_trade[key].extend(\n                [str(res_of_each_line_efficiency[key][i * 4 + 3])] + \\\n                # [str(res_of_each_line_efficiency[key][i * 4 + 4])] + \\\n                [\"{:.2f}\".format(v * 100) if v != \"-\" else v for v in res_of_each_line_fair[key][i * 3:i * 3 + 1]]\n            )\n\n        res_to_print = [str(v) for v in res_of_each_line_conver_acc_trade[key]]\n        res_to_print = [sorted_keys[key]] + res_to_print\n        print(\",\".join(res_to_print))\n    # print(\"\\n=============res_of_all_sweeps [Generalization]===============\")\n    # for key in sorted(res_of_all_sweeps.keys()):\n    #     res_to_print = [\"{:.2f}\".format(v * 100) if v != \"-\" else v for v in res_of_all_sweeps[key]]\n    #     res_to_print = [key] + res_to_print\n    #     print(\",\".join(res_to_print))\n    #\n\n\ndef generate_repeat_scripts(best_cfg_path, seed_sets=None):\n    file_cnt = 0\n    if seed_sets is None:\n        seed_sets = [2, 3]\n    from os import listdir\n    from os.path import isfile, join\n    onlyfiles = [\n        f for f in listdir(best_cfg_path) if isfile(join(best_cfg_path, f))\n    ]", "choices": [{"text": "else:"}], "metadata": {"task_id": "alibaba_FederatedScope/69", "ground_truth": "    for file_name in onlyfiles:", "fpath_tuple": ["alibaba_FederatedScope", "benchmark", "pFL-Bench", "res_analysis_plot", "repeat_best_exp.py"], "context_start_lineno": 404, "line_no": 526, "query_window": {"context": "        res_to_print = [str(v) for v in res_of_each_line_conver_acc_trade[key]]\n        res_to_print = [sorted_keys[key]] + res_to_print\n        print(\",\".join(res_to_print))\n    # print(\"\\n=============res_of_all_sweeps [Generalization]===============\")\n    # for key in sorted(res_of_all_sweeps.keys()):\n    #     res_to_print = [\"{:.2f}\".format(v * 100) if v != \"-\" else v for v in res_of_all_sweeps[key]]\n    #     res_to_print = [key] + res_to_print\n    #     print(\",\".join(res_to_print))\n    #\n\n\ndef generate_repeat_scripts(best_cfg_path, seed_sets=None):\n    file_cnt = 0\n    if seed_sets is None:\n        seed_sets = [2, 3]\n    from os import listdir\n    from os.path import isfile, join\n    onlyfiles = [\n        f for f in listdir(best_cfg_path) if isfile(join(best_cfg_path, f))\n    ]", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "benchmark", "pFL-Bench", "res_analysis_plot", "repeat_best_exp.py"], "line_no": 526, "task_id": "alibaba_FederatedScope/69", "start_line_no": 506, "end_line_no": 526, "window_size": 20, "context_start_lineno": 404, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "                res_of_each_line_generalization[missing_header] = [\"-\"] * 3\n                res_of_each_line_fair[missing_header] = [\"-\"] * 3\n                res_of_each_line_efficiency[missing_header] = [\"-\"] * 4\n            else:\n                res_of_each_line_generalization[missing_header].extend([\"-\"] *\n                                                                       3)\n                res_of_each_line_fair[missing_header].extend([\"-\"] * 3)\n                res_of_each_line_efficiency[missing_header].extend([\"-\"] * 4)\n\n    print(\"\\n=============res_of_each_line [Generalization]===============\" +\n          \",\".join(list(filters_each_line_table.keys())))\n    # Acc, Unseen-ACC, Delta\n    res_to_print_matrix = []\n    times_ratio = 100 if percent else 1\n    for key in sorted_method_name_to_print:\n        res_to_print = [\n            \"{:.2f}\".format(v * times_ratio) if v != \"-\" else v\n            for v in res_of_each_line_generalization[key]\n        ]\n        res_to_print = [sorted_method_name_to_print[key]] + res_to_print", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "benchmark", "pFL-Bench", "res_analysis_plot", "wandb_to_latex_res.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.43884892086330934}, {"context": "    #    res_to_print = [sorted_method_name_to_print[key]] + res_to_print\n    #    print(\",\".join(res_to_print))\n    print(\n        \"\\n=============res_of_each_line [flops, communication, acc/loss]===============\"\n        + \",\".join(list(filters_each_line_table.keys())))\n    res_to_print_matrix = []\n\n    dataset_num = 2 if \"cola\" or \"movie\" in list(\n        filters_each_line_table.keys()) else 3\n    for key in sorted_method_name_to_print:\n        res_of_each_line_commu_acc_trade[key] = []\n        for i in range(dataset_num):\n            try:\n                res_of_each_line_commu_acc_trade[key].extend(\n                    [str(res_of_each_line_efficiency[key][i * 4])] + \\\n                    [str(res_of_each_line_efficiency[key][i * 4 + 1])] + \\\n                    [\"{:.2f}\".format(v * times_ratio) if v != \"-\" else v for v in\n                     res_of_each_line_generalization[key][i * 3:i * 3 + 1]]\n                )\n            except:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "benchmark", "pFL-Bench", "res_analysis_plot", "wandb_to_latex_res.py"], "line_no": 670, "start_line_no": 660, "end_line_no": 680, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.41025641025641024}, {"context": "        print(\"&\".join(res_to_print) + \"\\\\\\\\\")\n\n    print(\"\\n=============res_of_each_line [Fairness]===============\" +\n          \",\".join(list(filters_each_line_table.keys())))\n    res_to_print_matrix = []\n    for key in sorted_method_name_to_print:\n        res_to_print = [\n            \"{:.2f}\".format(v * times_ratio) if v != \"-\" else v\n            for v in res_of_each_line_fair[key]\n        ]\n        res_to_print = [sorted_method_name_to_print[key]] + res_to_print\n        #print(\",\".join(res_to_print))\n        res_to_print_matrix.append(res_to_print)\n\n    colum_order_per_data = [\"-\", \"-\", \"-\"]\n    # \"+\" indicates the larger, the better\n    rank_order = colum_order_per_data * len(filters_each_line_table)\n    res_to_print_matrix = highlight_tex_res_in_table(\n        res_to_print_matrix,\n        rank_order=rank_order,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "benchmark", "pFL-Bench", "res_analysis_plot", "wandb_to_latex_res.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4068965517241379}, {"context": "    # for key in expected_method_names:\n    #    res_to_print = [str(v) for v in res_of_each_line_efficiency[key]]\n    #    res_to_print = [key] + res_to_print\n    #    print(\"&\".join(res_to_print) + \"\\\\\\\\\")\n\n    print(\n        \"\\n=============res_of_each_line [flops, communication, acc]===============\"\n        + \",\".join(list(filters_each_line_table.keys())))\n    res_to_print_matrix = []\n    for key in expected_method_names:\n        res_of_each_line_commu_acc_trade[key] = []\n        dataset_num = 2 if \"cola\" in list(\n            filters_each_line_table.keys()) else 3\n        for i in range(dataset_num):\n            res_of_each_line_commu_acc_trade[key].extend(\n                [str(res_of_each_line_efficiency[key][i * 4])] + \\\n                [str(res_of_each_line_efficiency[key][i * 4 + 1])] + \\\n                [\"{:.2f}\".format(v * 100) if v != \"-\" else v for v in\n                 res_of_each_line_generalization[key][i * 3:i * 3 + 1]]\n            )", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "benchmark", "pFL-Bench", "res_analysis_plot", "render_paper_res.py"], "line_no": 570, "start_line_no": 560, "end_line_no": 580, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4066666666666667}, {"context": "            \"{:.2f}\".format(v * 100) if v != \"-\" else v\n            for v in res_of_each_line_generalization[key]\n        ]\n        res_to_print = [key] + res_to_print\n        res_to_print_matrix.append(res_to_print)\n        # print(\"&\".join(res_to_print) + \"\\\\\\\\\")\n\n    colum_order_per_data = [\"+\", \"+\", \"+\"]\n    # \"+\" indicates the larger, the better\n    rank_order = colum_order_per_data * len(filters_each_line_table)\n    res_to_print_matrix = highlight_tex_res_in_table(res_to_print_matrix,\n                                                     rank_order=rank_order)\n    for res_to_print in res_to_print_matrix:\n        print(\"&\".join(res_to_print) + \"\\\\\\\\\")\n\n    print(\"\\n=============res_of_each_line [Fairness]===============\" +\n          \",\".join(list(filters_each_line_table.keys())))\n    res_to_print_matrix = []\n    for key in expected_method_names:\n        res_to_print = [", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "benchmark", "pFL-Bench", "res_analysis_plot", "render_paper_res.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3819444444444444}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/pyvizier/converters/core.py\n# --------------------------------------------------\n#     \"\"\"dtype of the array returned by convert().\"\"\"\n#     return self.output_spec.dtype\n# \n#   @property\n#   def output_spec(self) -> NumpyArraySpec:\n#     return self._output_spec\n# \n#   @property\n#   def parameter_config(self) -> pyvizier.ParameterConfig:\n#     \"\"\"Original parameter config that this converter is defined on.\"\"\"\n#     return self._parameter_config\n# \n# \n# class ModelOutputConverter(metaclass=abc.ABCMeta):\n#   \"\"\"Metric converter interface.\n# \n#   Unlike ModelInputConverter, this class is currently designed to always\n#   output a single-dimensional metric. This is because in standard Keras\n#   workflows, output shapes must be known when defining a model. (In contrast,\n#   input shapes are required at the time of _building_ a model.)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/clients.py\n# --------------------------------------------------\n# @attr.define\n# class Study(client_abc.StudyInterface):\n#   \"\"\"Responsible for study-level operations.\"\"\"\n# \n#   _client: vizier_client.VizierClient = attr.field()\n# \n#   @property\n#   def resource_name(self) -> str:\n#     return self._client.study_resource_name\n# \n#   def _trial_client(self, trial: vz.Trial) -> Trial:\n#     \"\"\"Returns the client for the vz.Trial object.\"\"\"\n#     return Trial(self._client, trial.id)\n# \n#   def suggest(\n#       self, *, count: Optional[int] = None, client_id: str = 'default_client_id'\n#   ) -> Collection[Trial]:\n#     return [\n#         self._trial_client(t)\n#         for t in self._client.get_suggestions(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/vizier_client.py\n# --------------------------------------------------\n#     logging.info('Trial deleted: %s', trial_id)\n# \n#   def delete_study(self, study_resource_name: Optional[str] = None) -> None:\n#     \"\"\"Deletes study from datastore.\"\"\"\n#     study_resource_name = study_resource_name or (\n#         resources.StudyResource(self._owner_id, self._study_id).name\n#     )\n#     request = vizier_service_pb2.DeleteStudyRequest(name=study_resource_name)\n#     self._service.DeleteStudy(request)\n#     logging.info('Study deleted: %s', study_resource_name)\n# \n#   def get_study_config(\n#       self, study_resource_name: Optional[str] = None\n#   ) -> pyvizier.StudyConfig:\n#     \"\"\"Returns the study config.\"\"\"\n#     study_resource_name = study_resource_name or (\n#         resources.StudyResource(self._owner_id, self._study_id).name\n#     )\n#     request = vizier_service_pb2.GetStudyRequest(name=study_resource_name)\n#     study = self._service.GetStudy(request)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyglove/pythia.py\n# --------------------------------------------------\n#   @property\n#   def early_stopping_policy(self) -> Optional[pg.tuning.EarlyStoppingPolicy]:\n#     return self._early_stopping_policy\n# \n#   @property\n#   def _metric_names(self) -> Sequence[str]:\n#     return self._converter.metrics_to_optimize\n# \n#   def update(self, tuner_trial: pg.tuning.Trial) -> bool:\n#     \"\"\"Update a single tuner Trial.\n# \n#     Args:\n#       tuner_trial: If the trial id was previously seen, update is no-op.\n# \n#     Returns:\n#       True if the trial was added.\n#     \"\"\"\n#     if tuner_trial.id in self._incorporated_trial_ids:\n#       return False\n#     logging.info(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/vizier_client.py\n# --------------------------------------------------\n#   @property\n#   def study_resource_name(self) -> str:\n#     return self._study_resource_name\n# \n#   def get_suggestions(\n#       self, suggestion_count: int, *, client_id_override: Optional[str] = None\n#   ) -> List[pyvizier.Trial]:\n#     \"\"\"Gets a list of suggested Trials.\n# \n#     Args:\n#         suggestion_count: The number of suggestions to request.\n#         client_id_override: If set, overrides self._client_id for this call.\n# \n#     Returns:\n#       A list of PyVizier Trials. This may be an empty list if:\n#       1. A finite search space has been exhausted.\n#       2. If max_num_trials has been reached.\n#       3. Or if there are no longer any trials that match a supplied Context.\n# \n#     Raises:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyglove/pythia.py\n# --------------------------------------------------\n# \n#     Args:\n#       tuner_trial: If the trial id was previously seen, update is no-op.\n# \n#     Returns:\n#       True if the trial was added.\n#     \"\"\"\n#     if tuner_trial.id in self._incorporated_trial_ids:\n#       return False\n#     logging.info(\n#         'Updating TunerTrial %s to algorithm: %s', tuner_trial, self._algorithm\n#     )\n#     reward = tuner_trial.get_reward_for_feedback(self._metric_names)\n#     if reward is not None:\n#       self._algorithm.feedback(tuner_trial.dna, reward)\n#       self._incorporated_trial_ids.add(tuner_trial.id)\n#       return True\n#     return False\n# \n#   def suggest(self, request: pythia.SuggestRequest) -> pythia.SuggestDecision:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/clients.py\n# --------------------------------------------------\n# \n#   @property\n#   def parameters(self) -> Mapping[str, Any]:\n#     trial = self.materialize(include_all_measurements=False)\n#     study_config = self._client.get_study_config()\n#     return study_config.trial_parameters(vz.TrialConverter.to_proto(trial))\n# \n#   def delete(self) -> None:\n#     self._client.delete_trial(self._id)\n# \n#   def update_metadata(self, delta: vz.Metadata) -> None:\n#     actual_delta = vz.MetadataDelta(on_trials={self._id: delta})\n#     self._client.update_metadata(actual_delta)\n# \n#   def complete(\n#       self,\n#       measurement: Optional[vz.Measurement] = None,\n#       *,\n#       infeasible_reason: Optional[str] = None,\n#   ) -> Optional[vz.Measurement]:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"Defines core components for tuner integration.\"\"\"\n\nimport collections\nimport contextlib\nimport datetime\nimport typing\nfrom typing import Any, Optional, Sequence\n\nfrom absl import logging\nimport attr\nimport pyglove as pg\nfrom vizier import pyvizier as vz\nfrom vizier._src.pyglove import constants\nfrom vizier._src.pyglove import converters\nfrom vizier.client import client_abc\n\n\ndef _trial_status_legacy_value(status: vz.TrialStatus) -> str:\n  # PENDING was renamed to ACTIVE.\n  if status == vz.TrialStatus.ACTIVE:\n    return 'PENDING'\n  return status.value\n\n\nclass VizierTrial(pg.tuning.Trial):\n  \"\"\"Override Trial to lazy load DNA and metadata upon access.\n\n  When we construct a `Trial` object, it doesn't pop up DNA, measurements and\n  metadata from vizier trial proto immediately. This is because that a study\n  may consists of thousands of trials, if we load them at construction time, it\n  would take minutes, which is not acceptable. So we made the `Trial` object\n  lazily load these properties upon access, reducing the construction time into\n  a few seconds.\n  \"\"\"\n\n  def __init__(self, converter: converters.VizierConverter, trial: vz.Trial,\n               **kwargs):\n    super().__init__(\n        dna=pg.DNA(None),\n        id=trial.id,\n        description=trial.description,\n        final_measurement=converter.to_tuner_measurement(\n            trial.final_measurement),\n        status=_trial_status_legacy_value(trial.status),\n        created_time=int(trial.creation_time.timestamp()),\n        completed_time=int((trial.completion_time or\n                            datetime.datetime.fromtimestamp(0)).timestamp()),\n        infeasible=trial.infeasible,\n        **kwargs)\n    self._converter = converter\n    self._trial = trial\n\n  @property\n  def dna(self) -> pg.DNA:\n    \"\"\"Returns lazy loaded DNA.\"\"\"\n    if (self.sym_init_args.dna.value is None and\n        not self.sym_init_args.dna.children):\n      self.sym_init_args.dna = self._converter.to_dna(self._trial)\n    return self.sym_init_args.dna\n\n  @property\n  def metadata(self) -> dict[str, Any]:\n    \"\"\"Returns lazy loaded metadata.\"\"\"\n    if not self.sym_init_args.metadata and self._trial:\n      self.sym_init_args.metadata = converters.get_pyglove_metadata(self._trial)\n    return self.sym_init_args.metadata\n\n  @property\n  def related_links(self) -> dict[str, str]:\n    \"\"\"Returns lazy loaded related links.\"\"\"\n    if not self.sym_init_args.related_links and self._trial:\n      self.sym_init_args.related_links = dict(\n          self._trial.metadata.ns(constants.METADATA_NAMESPACE).ns(\n              constants.RELATED_LINKS_NAMESPACE))\n    return self.sym_init_args.related_links\n\n  @property\n  def measurements(self) -> list[pg.tuning.Measurement]:\n    \"\"\"Returns lazy loaded measurements.\"\"\"\n    if not self.sym_init_args.measurements:\n      self.sym_init_args.measurements = [\n          self._converter.to_tuner_measurement(m)\n          for m in self._trial.measurements\n      ]\n    return self.sym_init_args.measurements\n\n  def format(self, *args, **kwargs):\n    \"\"\"Fetch lazy bound properties before print.\"\"\"\n    # NOTE(daiyip): `format` depends on the symbolic attributes to generate\n    # the string representation. Since the following symbolic attributes are\n    # lazily assigned upon property accesses, we prefetch them before calling\n    # the `format`. Otherwise, the symbolic attributes are just default values\n    # set at __init__ time.\n    _, _, _, _ = self.dna, self.measurements, self.metadata, self.related_links\n    return super().format(*args, **kwargs)\n\n\nclass Feedback(pg.tuning.Feedback):\n  \"\"\"Tuning feedback for a vizier trial.\"\"\"\n\n  def __init__(self, vizier_trial: client_abc.TrialInterface,\n               converter: converters.VizierConverter):\n    \"\"\"Constructor.\n\n    Args:\n      vizier_trial: Vizier trial (cross-platform).\n      converter: Vizier-Pyglove converter.\n    \"\"\"\n    super().__init__(converter.metrics_to_optimize)\n    self._converter = converter\n    self._trial_client = vizier_trial\n    self._trial = self._trial_client.materialize()\n    self._dna_spec = converter.dna_spec\n    self._discard_reward = 'reward' not in converter.metrics_to_optimize\n\n  @property\n  def id(self) -> int:\n    \"\"\"Gets Trial ID as ID.\"\"\"\n    return self._trial_client.id\n\n  @property\n  def dna(self) -> pg.DNA:\n    \"\"\"Gets DNA of current trial.\"\"\"\n    return self._converter.to_dna(self._trial)\n\n  def get_trial(self) -> pg.tuning.Trial:\n    \"\"\"Gets current trial with all fields up-to-date.\"\"\"\n    self._trial = self._trial_client.materialize()\n    return VizierTrial(self._converter, self._trial)\n\n  @property\n  def checkpoint_to_warm_start_from(self) -> Optional[str]:\n    \"\"\"Gets checkpoint path to warm start from. Refreshes `_trial`.\"\"\"\n    # TODO: Add official support.", "choices": [{"text": "to_dna"}], "metadata": {"task_id": "google_vizier/57", "ground_truth": "    self._trial = self._trial_client.materialize()", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "core.py"], "context_start_lineno": 0, "line_no": 150, "query_window": {"context": "\n  @property\n  def id(self) -> int:\n    \"\"\"Gets Trial ID as ID.\"\"\"\n    return self._trial_client.id\n\n  @property\n  def dna(self) -> pg.DNA:\n    \"\"\"Gets DNA of current trial.\"\"\"\n    return self._converter.to_dna(self._trial)\n\n  def get_trial(self) -> pg.tuning.Trial:\n    \"\"\"Gets current trial with all fields up-to-date.\"\"\"\n    self._trial = self._trial_client.materialize()\n    return VizierTrial(self._converter, self._trial)\n\n  @property\n  def checkpoint_to_warm_start_from(self) -> Optional[str]:\n    \"\"\"Gets checkpoint path to warm start from. Refreshes `_trial`.\"\"\"\n    # TODO: Add official support.", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "core.py"], "line_no": 150, "task_id": "google_vizier/57", "start_line_no": 130, "end_line_no": 150, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "  This class owns a Vizier client of the Study that contains the Trial that\n  it is associated with.\n  \"\"\"\n\n  _client: vizier_client.VizierClient = attr.field()\n  _id: int = attr.field(validator=attr.validators.instance_of(int))\n\n  @property\n  def id(self) -> int:\n    return self._id\n\n  @property\n  def parameters(self) -> Mapping[str, Any]:\n    trial = self.materialize(include_all_measurements=False)\n    study_config = self._client.get_study_config()\n    return study_config.trial_parameters(vz.TrialConverter.to_proto(trial))\n\n  def delete(self) -> None:\n    self._client.delete_trial(self._id)\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "clients.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.30656934306569344}, {"context": "  @property\n  def early_stopping_policy(self) -> Optional[pg.tuning.EarlyStoppingPolicy]:\n    return self._early_stopping_policy\n\n  @property\n  def _metric_names(self) -> Sequence[str]:\n    return self._converter.metrics_to_optimize\n\n  def update(self, tuner_trial: pg.tuning.Trial) -> bool:\n    \"\"\"Update a single tuner Trial.\n\n    Args:\n      tuner_trial: If the trial id was previously seen, update is no-op.\n\n    Returns:\n      True if the trial was added.\n    \"\"\"\n    if tuner_trial.id in self._incorporated_trial_ids:\n      return False\n    logging.info(", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "pythia.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3}, {"context": "    )\n\n  @property\n  def _owner_id(self) -> str:\n    return self._study_resource.owner_id\n\n  @property\n  def _study_id(self) -> str:\n    return self._study_resource.study_id\n\n  @property\n  def study_resource_name(self) -> str:\n    return self._study_resource_name\n\n  def get_suggestions(\n      self, suggestion_count: int, *, client_id_override: Optional[str] = None\n  ) -> List[pyvizier.Trial]:\n    \"\"\"Gets a list of suggested Trials.\n\n    Args:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "vizier_client.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2894736842105263}, {"context": "  _algorithm: pg.geno.DNAGenerator = attr.field()\n  _incorporated_trial_ids: set[int] = attr.field(factory=set)\n  _early_stopping_policy: Optional[pg.tuning.EarlyStoppingPolicy] = attr.field(\n      default=None\n  )\n\n  @property\n  def algorithm(self) -> pg.geno.DNAGenerator:\n    return self._algorithm\n\n  @property\n  def early_stopping_policy(self) -> Optional[pg.tuning.EarlyStoppingPolicy]:\n    return self._early_stopping_policy\n\n  @property\n  def _metric_names(self) -> Sequence[str]:\n    return self._converter.metrics_to_optimize\n\n  def update(self, tuner_trial: pg.tuning.Trial) -> bool:\n    \"\"\"Update a single tuner Trial.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "pythia.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2878787878787879}, {"context": "    trial_proto = self._service.CreateTrial(request)\n    return pyvizier.TrialConverter.from_proto(trial_proto)\n\n  def delete_trial(self, trial_id: int) -> None:\n    \"\"\"Deletes trial from datastore.\"\"\"\n    request_trial_name = resources.TrialResource(\n        self._owner_id, self._study_id, trial_id\n    ).name\n    request = vizier_service_pb2.DeleteTrialRequest(name=request_trial_name)\n    self._service.DeleteTrial(request)\n    logging.info('Trial deleted: %s', trial_id)\n\n  def delete_study(self, study_resource_name: Optional[str] = None) -> None:\n    \"\"\"Deletes study from datastore.\"\"\"\n    study_resource_name = study_resource_name or (\n        resources.StudyResource(self._owner_id, self._study_id).name\n    )\n    request = vizier_service_pb2.DeleteStudyRequest(name=study_resource_name)\n    self._service.DeleteStudy(request)\n    logging.info('Study deleted: %s', study_resource_name)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "vizier_client.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2713178294573643}, {"context": "\n  def __iter__(self) -> Iterator[Trial]:\n    for trial in self._iterable_factory():\n      yield Trial(self._client, trial.id)\n\n  def get(self) -> Iterator[vz.Trial]:\n    for trial in self._iterable_factory():\n      yield trial\n\n\n@attr.define\nclass Study(client_abc.StudyInterface):\n  \"\"\"Responsible for study-level operations.\"\"\"\n\n  _client: vizier_client.VizierClient = attr.field()\n\n  @property\n  def resource_name(self) -> str:\n    return self._client.study_resource_name\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "clients.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.265625}, {"context": "  def _convert_continuous(self, trial: pyvizier.Trial):\n    \"\"\"Called by `convert()` if configured for a continuous parameter.\"\"\"\n    raw_value = self._getter(trial)\n    if raw_value is None:\n      return np.nan\n    else:\n      return raw_value\n\n  @property\n  def dtype(self):\n    \"\"\"dtype of the array returned by convert().\"\"\"\n    return self.output_spec.dtype\n\n  @property\n  def output_spec(self) -> NumpyArraySpec:\n    return self._output_spec\n\n  @property\n  def parameter_config(self) -> pyvizier.ParameterConfig:\n    \"\"\"Original parameter config that this converter is defined on.\"\"\"", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "pyvizier", "converters", "core.py"], "line_no": 680, "start_line_no": 670, "end_line_no": 690, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2631578947368421}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#     )\n#     env_serial = SerialEnv(\n#         N, create_env_fn, selected_keys=selected_keys, create_env_kwargs=kwargs\n#     )\n#     if transformed_out:\n#         if env_name == \"ALE/Pong-v5\":\n# \n#             def t_out():\n#                 return (\n#                     Compose(*[ToTensorImage(), RewardClipping(0, 0.1)])\n#                     if not transformed_in\n#                     else Compose(*[ObservationNorm(in_keys=[\"pixels\"], loc=0, scale=1)])\n#                 )\n# \n#             env0 = TransformedEnv(\n#                 env0,\n#                 t_out(),\n#             )\n#             env_parallel = TransformedEnv(\n#                 env_parallel,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#             env0 = TransformedEnv(\n#                 env0,\n#                 t_out(),\n#             )\n#             env_parallel = TransformedEnv(\n#                 env_parallel,\n#                 t_out(),\n#             )\n#             env_serial = TransformedEnv(\n#                 env_serial,\n#                 t_out(),\n#             )\n# \n#     return env_parallel, env_serial, env0\n# \n# \n# class TestModelBasedEnvBase:\n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     def test_mb_rollout(self, device, seed=0):\n#         torch.manual_seed(seed)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#                     GymEnv(env_name, frame_skip=frame_skip, device=device),\n#                     Compose(\n#                         ObservationNorm(in_keys=[\"observation\"], loc=0.5, scale=1.1),\n#                         RewardClipping(0, 0.1),\n#                     ),\n#                 )\n# \n#     env0 = create_env_fn()\n#     env_parallel = ParallelEnv(\n#         N, create_env_fn, selected_keys=selected_keys, create_env_kwargs=kwargs\n#     )\n#     env_serial = SerialEnv(\n#         N, create_env_fn, selected_keys=selected_keys, create_env_kwargs=kwargs\n#     )\n#     if transformed_out:\n#         if env_name == \"ALE/Pong-v5\":\n# \n#             def t_out():\n#                 return (\n#                     Compose(*[ToTensorImage(), RewardClipping(0, 0.1)])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#                     if not transformed_in\n#                     else Compose(*[ObservationNorm(in_keys=[\"pixels\"], loc=0, scale=1)])\n#                 )\n# \n#             env0 = TransformedEnv(\n#                 env0,\n#                 t_out(),\n#             )\n#             env_parallel = TransformedEnv(\n#                 env_parallel,\n#                 t_out(),\n#             )\n#             env_serial = TransformedEnv(\n#                 env_serial,\n#                 t_out(),\n#             )\n#         else:\n# \n#             def t_out():\n#                 return (\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#                 t_out(),\n#             )\n#             env_serial = TransformedEnv(\n#                 env_serial,\n#                 t_out(),\n#             )\n#         else:\n# \n#             def t_out():\n#                 return (\n#                     Compose(\n#                         ObservationNorm(in_keys=[\"observation\"], loc=0.5, scale=1.1),\n#                         RewardClipping(0, 0.1),\n#                     )\n#                     if not transformed_in\n#                     else Compose(\n#                         ObservationNorm(in_keys=[\"observation\"], loc=1.0, scale=1.0)\n#                     )\n#                 )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n# \n# def _make_envs(\n#     env_name,\n#     frame_skip,\n#     transformed_in,\n#     transformed_out,\n#     N,\n#     selected_keys=None,\n#     device=\"cpu\",\n#     kwargs=None,\n# ):\n#     torch.manual_seed(0)\n#     if not transformed_in:\n# \n#         def create_env_fn():\n#             return GymEnv(env_name, frame_skip=frame_skip, device=device)\n# \n#     else:\n#         if env_name == \"ALE/Pong-v5\":\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n# ):\n#     torch.manual_seed(0)\n#     if not transformed_in:\n# \n#         def create_env_fn():\n#             return GymEnv(env_name, frame_skip=frame_skip, device=device)\n# \n#     else:\n#         if env_name == \"ALE/Pong-v5\":\n# \n#             def create_env_fn():\n#                 return TransformedEnv(\n#                     GymEnv(env_name, frame_skip=frame_skip, device=device),\n#                     Compose(*[ToTensorImage(), RewardClipping(0, 0.1)]),\n#                 )\n# \n#         else:\n# \n#             def create_env_fn():\n#                 return TransformedEnv(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_libs.py\n# --------------------------------------------------\n#             env = VmasEnv(\n#                 scenario_name=scenario_name,\n#                 num_envs=num_envs,\n#                 n_agents=n_agents,\n#                 continuous_actions=continuous_actions,\n#             )\n#             env.set_seed(0)\n#             return env\n# \n#         env = ParallelEnv(n_workers, make_vmas)\n#         tensordict = env.rollout(max_steps=n_rollout_samples)\n# \n#         assert tensordict.shape == torch.Size(\n#             [n_workers, list(env.n_agents)[0], list(env.num_envs)[0], n_rollout_samples]\n#         )\n# \n#     @pytest.mark.parametrize(\"num_envs\", [1, 10])\n#     @pytest.mark.parametrize(\"n_workers\", [1, 3])\n#     def test_vmas_reset(\n#         self,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n_make():\n                return DMControlEnv(\"humanoid\", tasks[0])\n\n        elif len(set(tasks)) == 1 and len(tasks) == 3:\n            single_task = True\n            env_make = [lambda: DMControlEnv(\"humanoid\", tasks[0])] * 3\n        else:\n            single_task = False\n            env_make = [\n                lambda task=task: DMControlEnv(\"humanoid\", task) for task in tasks\n            ]\n\n        if not share_individual_td and not single_task:\n            with pytest.raises(\n                ValueError, match=\"share_individual_td must be set to None\"\n            ):\n                SerialEnv(3, env_make, share_individual_td=share_individual_td)\n            with pytest.raises(\n                ValueError, match=\"share_individual_td must be set to None\"\n            ):\n                ParallelEnv(3, env_make, share_individual_td=share_individual_td)\n            return\n\n        env_serial = SerialEnv(3, env_make, share_individual_td=share_individual_td)\n        env_serial.start()\n        assert env_serial._single_task is single_task\n        env_parallel = ParallelEnv(3, env_make, share_individual_td=share_individual_td)\n        env_parallel.start()\n        assert env_parallel._single_task is single_task\n\n        env_serial.set_seed(0)\n        torch.manual_seed(0)\n        td_serial = env_serial.rollout(max_steps=50)\n\n        env_parallel.set_seed(0)\n        torch.manual_seed(0)\n        td_parallel = env_parallel.rollout(max_steps=50)\n\n        assert_allclose_td(td_serial, td_parallel)\n\n    @pytest.mark.skipif(not _has_dmc, reason=\"no dm_control\")\n    def test_multitask(self):\n        env1 = DMControlEnv(\"humanoid\", \"stand\")\n        env1_obs_keys = list(env1.observation_spec.keys())\n        env2 = DMControlEnv(\"humanoid\", \"walk\")\n        env2_obs_keys = list(env2.observation_spec.keys())\n\n        assert len(env1_obs_keys)\n        assert len(env2_obs_keys)\n\n        def env1_maker():\n            return TransformedEnv(\n                DMControlEnv(\"humanoid\", \"stand\"),\n                Compose(\n                    CatTensors(env1_obs_keys, \"observation_stand\", del_keys=False),\n                    CatTensors(env1_obs_keys, \"observation\"),\n                    DoubleToFloat(\n                        in_keys=[\"observation_stand\", \"observation\"],\n                        in_keys_inv=[\"action\"],\n                    ),\n                ),\n            )\n\n        def env2_maker():\n            return TransformedEnv(\n                DMControlEnv(\"humanoid\", \"walk\"),\n                Compose(\n                    CatTensors(env2_obs_keys, \"observation_walk\", del_keys=False),\n                    CatTensors(env2_obs_keys, \"observation\"),\n                    DoubleToFloat(\n                        in_keys=[\"observation_walk\", \"observation\"],\n                        in_keys_inv=[\"action\"],\n                    ),\n                ),\n            )\n\n        env = ParallelEnv(2, [env1_maker, env2_maker])\n        # env = SerialEnv(2, [env1_maker, env2_maker])\n        assert not env._single_task\n\n        td = env.rollout(10, return_contiguous=False)\n        assert \"observation_walk\" not in td.keys()\n        assert \"observation_walk\" in td[1].keys()\n        assert \"observation_walk\" not in td[0].keys()\n        assert \"observation_stand\" in td[0].keys()\n        assert \"observation_stand\" not in td[1].keys()\n        assert \"observation_walk\" in td[:, 0][1].keys()\n        assert \"observation_walk\" not in td[:, 0][0].keys()\n        assert \"observation_stand\" in td[:, 0][0].keys()\n        assert \"observation_stand\" not in td[:, 0][1].keys()\n\n    @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n    @pytest.mark.parametrize(\"env_name\", [PONG_VERSIONED, PENDULUM_VERSIONED])\n    @pytest.mark.parametrize(\"frame_skip\", [4, 1])\n    @pytest.mark.parametrize(\"transformed_in\", [False, True])\n    @pytest.mark.parametrize(\"transformed_out\", [False, True])\n    def test_parallel_env(\n        self, env_name, frame_skip, transformed_in, transformed_out, T=10, N=3\n    ):\n        env_parallel, env_serial, env0 = _make_envs(\n            env_name,\n            frame_skip,\n            transformed_in=transformed_in,\n            transformed_out=transformed_out,\n            N=N,\n        )\n\n        td = TensorDict(\n            source={\"action\": env0.action_spec.rand((N,))},\n            batch_size=[\n                N,\n            ],\n        )\n        td1 = env_parallel.step(td)\n        assert not td1.is_shared()\n        assert \"done\" in td1.keys()\n        assert \"reward\" in td1.keys()\n\n        with pytest.raises(RuntimeError):\n            # number of actions does not match number of workers\n            td = TensorDict(\n                source={\"action\": env0.action_spec.rand((N - 1,))}, batch_size=[N - 1]\n            )\n            _ = env_parallel.step(td)\n\n        td_reset = TensorDict(\n            source={\"_reset\": torch.zeros(N, dtype=torch.bool).bernoulli_()},\n            batch_size=[\n                N,\n            ],\n        )\n        env_parallel.reset(tensordict=td_reset)\n\n        td = env_parallel.rollout(policy=None, max_steps=T)\n        assert (\n            td.shape == torch.Size([N, T]) or td.get(\"done\").sum(1).all()\n        ), f\"{td.shape}, {td.get('done').sum(1)}\"\n        env_parallel.close()\n        # env_serial.close()  # never opened\n        env0.close()\n\n    @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n    @pytest.mark.parametrize(\"env_name\", [PENDULUM_VERSIONED])\n    @pytest.mark.parametrize(\"frame_skip\", [4, 1])\n    @pytest.mark.parametrize(\"transformed_in\", [True, False])\n    @pytest.mark.parametrize(\"transformed_out\", [True, False])\n    @pytest.mark.parametrize(\n        \"selected_keys\",\n        [\n            [\"action\", \"observation\", \"next_observation\", \"done\", \"reward\"],\n            [\"hidden\", \"action\", \"observation\", \"next_observation\", \"done\", \"reward\"],\n            None,\n        ],\n    )\n    def test_parallel_env_with_policy(\n        self,\n        env_name,\n        frame_skip,\n        transformed_in,\n        transformed_out,\n        selected_keys,\n        T=10,\n        N=3,\n    ):\n        env_parallel, env_serial, env0 = _make_envs(\n            env_name,\n            frame_skip,\n            transformed_in=transformed_in,\n            transformed_out=transformed_out,\n            N=N,\n            selected_keys=selected_keys,\n        )\n\n        policy = ActorCriticOperator(\n            SafeModule(", "choices": [{"text": "ParallelEnv receives the list of environment creation functions and creates a parallel environment with the specified number of workers."}], "metadata": {"task_id": "pytorch_rl/148", "ground_truth": "                spec=None,", "fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "context_start_lineno": 388, "line_no": 563, "query_window": {"context": "        self,\n        env_name,\n        frame_skip,\n        transformed_in,\n        transformed_out,\n        selected_keys,\n        T=10,\n        N=3,\n    ):\n        env_parallel, env_serial, env0 = _make_envs(\n            env_name,\n            frame_skip,\n            transformed_in=transformed_in,\n            transformed_out=transformed_out,\n            N=N,\n            selected_keys=selected_keys,\n        )\n\n        policy = ActorCriticOperator(\n            SafeModule(", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 563, "task_id": "pytorch_rl/148", "start_line_no": 543, "end_line_no": 563, "window_size": 20, "context_start_lineno": 388, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    def test_vmas_parallel(\n        self,\n        scenario_name,\n        num_envs,\n        n_workers,\n        continuous_actions,\n        n_agents=5,\n        n_rollout_samples=3,\n    ):\n        def make_vmas():\n            env = VmasEnv(\n                scenario_name=scenario_name,\n                num_envs=num_envs,\n                n_agents=n_agents,\n                continuous_actions=continuous_actions,\n            )\n            env.set_seed(0)\n            return env\n\n        env = ParallelEnv(n_workers, make_vmas)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_libs.py"], "line_no": 670, "start_line_no": 660, "end_line_no": 680, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28205128205128205}, {"context": "\ndef _make_envs(\n    env_name,\n    frame_skip,\n    transformed_in,\n    transformed_out,\n    N,\n    selected_keys=None,\n    device=\"cpu\",\n    kwargs=None,\n):\n    torch.manual_seed(0)\n    if not transformed_in:\n\n        def create_env_fn():\n            return GymEnv(env_name, frame_skip=frame_skip, device=device)\n\n    else:\n        if env_name == \"ALE/Pong-v5\":\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.27906976744186046}, {"context": "    ).all()\n    assert (\n        torch.arange(first + 1, first + 101, device=device)\n        == td_out.get(\"reward\").squeeze()\n    ).all()\n    assert (\n        torch.arange(first, first + 100, device=device)\n        == td_out.get(\"action\").squeeze()\n    ).all()\n\n\ndef _make_envs(\n    env_name,\n    frame_skip,\n    transformed_in,\n    transformed_out,\n    N,\n    selected_keys=None,\n    device=\"cpu\",\n    kwargs=None,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26506024096385544}, {"context": "                    if not transformed_in\n                    else Compose(*[ObservationNorm(in_keys=[\"pixels\"], loc=0, scale=1)])\n                )\n\n            env0 = TransformedEnv(\n                env0,\n                t_out(),\n            )\n            env_parallel = TransformedEnv(\n                env_parallel,\n                t_out(),\n            )\n            env_serial = TransformedEnv(\n                env_serial,\n                t_out(),\n            )\n        else:\n\n            def t_out():\n                return (", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2597402597402597}, {"context": "    )\n    env_serial = SerialEnv(\n        N, create_env_fn, selected_keys=selected_keys, create_env_kwargs=kwargs\n    )\n    if transformed_out:\n        if env_name == \"ALE/Pong-v5\":\n\n            def t_out():\n                return (\n                    Compose(*[ToTensorImage(), RewardClipping(0, 0.1)])\n                    if not transformed_in\n                    else Compose(*[ObservationNorm(in_keys=[\"pixels\"], loc=0, scale=1)])\n                )\n\n            env0 = TransformedEnv(\n                env0,\n                t_out(),\n            )\n            env_parallel = TransformedEnv(\n                env_parallel,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.24752475247524752}, {"context": "            def create_env_fn():\n                return TransformedEnv(\n                    GymEnv(env_name, frame_skip=frame_skip, device=device),\n                    Compose(*[ToTensorImage(), RewardClipping(0, 0.1)]),\n                )\n\n        else:\n\n            def create_env_fn():\n                return TransformedEnv(\n                    GymEnv(env_name, frame_skip=frame_skip, device=device),\n                    Compose(\n                        ObservationNorm(in_keys=[\"observation\"], loc=0.5, scale=1.1),\n                        RewardClipping(0, 0.1),\n                    ),\n                )\n\n    env0 = create_env_fn()\n    env_parallel = ParallelEnv(\n        N, create_env_fn, selected_keys=selected_keys, create_env_kwargs=kwargs", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.24742268041237114}, {"context": "                    Compose(\n                        ObservationNorm(in_keys=[\"observation\"], loc=0.5, scale=1.1),\n                        RewardClipping(0, 0.1),\n                    )\n                    if not transformed_in\n                    else Compose(\n                        ObservationNorm(in_keys=[\"observation\"], loc=1.0, scale=1.0)\n                    )\n                )\n\n            env0 = TransformedEnv(\n                env0,\n                t_out(),\n            )\n            env_parallel = TransformedEnv(\n                env_parallel,\n                t_out(),\n            )\n            env_serial = TransformedEnv(\n                env_serial,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.24358974358974358}, {"context": "                    GymEnv(env_name, frame_skip=frame_skip, device=device),\n                    Compose(\n                        ObservationNorm(in_keys=[\"observation\"], loc=0.5, scale=1.1),\n                        RewardClipping(0, 0.1),\n                    ),\n                )\n\n    env0 = create_env_fn()\n    env_parallel = ParallelEnv(\n        N, create_env_fn, selected_keys=selected_keys, create_env_kwargs=kwargs\n    )\n    env_serial = SerialEnv(\n        N, create_env_fn, selected_keys=selected_keys, create_env_kwargs=kwargs\n    )\n    if transformed_out:\n        if env_name == \"ALE/Pong-v5\":\n\n            def t_out():\n                return (\n                    Compose(*[ToTensorImage(), RewardClipping(0, 0.1)])", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.24074074074074073}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/benchmarks/experimenters/synthetic/bbob.py\n# --------------------------------------------------\n#     alpha: Function parameter.\n#     dim: Dimension of matrix created.\n# \n#   Returns:\n#     Diagonal matrix of dimension dim with values determined by alpha.\n#   \"\"\"\n#   lambda_alpha = np.zeros([dim, dim])\n#   for i in range(dim):\n#     exp = (0.5 * (float(i) / (dim - 1))) if dim > 1 else 0.5\n#     lambda_alpha[i, i] = alpha**exp\n#   return lambda_alpha\n# \n# \n# def ArrayMap(vector: np.ndarray, fn: Callable[[float], float]) -> np.ndarray:\n#   \"\"\"Create a new array by mapping fn() to each element of the original array.\n# \n#   Args:\n#     vector: ndarray to be mapped.\n#     fn: scalar function for mapping.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/benchmarks/experimenters/synthetic/bbob.py\n# --------------------------------------------------\n#       dim,\n#   ])\n#   for i in range(dim):\n#     if dim > 1:\n#       s[i] = 10**(0.5 * (i / (dim - 1.0)))\n#     else:\n#       s[i] = 10**0.5\n#     if i % 2 == 0 and to_sz[i] > 0:\n#       s[i] *= 10\n#   return s\n# \n# \n# def Fpen(vector: np.ndarray) -> float:\n#   \"\"\"The BBOB Fpen function.\n# \n#   Args:\n#     vector: ndarray.\n# \n#   Returns:\n#     float representing Fpen(vector).\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/benchmarks/experimenters/synthetic/bbob.py\n# --------------------------------------------------\n#   return float(np.sum(arr * arr))\n# \n# \n# def Rastrigin(arr: np.ndarray, seed: int = 0) -> float:\n#   \"\"\"Implementation for BBOB Rastrigin function.\"\"\"\n#   dim = len(arr)\n#   arr.shape = (dim, 1)\n#   z = np.matmul(_R(dim, seed, b\"R\"), arr)\n#   z = Tasy(ArrayMap(z, Tosz), 0.2)\n#   z = np.matmul(_R(dim, seed, b\"Q\"), z)\n#   z = np.matmul(LambdaAlpha(10.0, dim), z)\n#   z = np.matmul(_R(dim, seed, b\"R\"), z)\n#   return float(10 * (dim - np.sum(np.cos(2 * math.pi * z))) +\n#                np.sum(z * z, axis=0))\n# \n# \n# def BuecheRastrigin(arr: np.ndarray, seed: int = 0) -> float:\n#   \"\"\"Implementation for BBOB BuecheRastrigin function.\"\"\"\n#   del seed\n#   dim = len(arr)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/benchmarks/experimenters/synthetic/bbob.py\n# --------------------------------------------------\n#       exp = 1 + beta * t * (val**0.5)\n#     else:\n#       exp = 1\n#     result[i] = val**exp\n#   return result\n# \n# \n# def SIndex(dim: int, to_sz) -> float:\n#   \"\"\"Calculate the BBOB s_i.\n# \n#   Assumes i is 0-index based.\n# \n#   Args:\n#     dim: dimension\n#     to_sz: values\n# \n#   Returns:\n#     float representing SIndex(i, d, to_sz).\n#   \"\"\"\n#   s = np.zeros([\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/benchmarks/experimenters/synthetic/bbob.py\n# --------------------------------------------------\n# \n# \n# def Fpen(vector: np.ndarray) -> float:\n#   \"\"\"The BBOB Fpen function.\n# \n#   Args:\n#     vector: ndarray.\n# \n#   Returns:\n#     float representing Fpen(vector).\n#   \"\"\"\n#   return sum([max(0.0, (abs(x) - 5.0))**2 for x in vector.flat])\n# \n# \n# def _Hash(*seeds: Any) -> int:\n#   \"\"\"Returns a stable hash that fits in a positive int64.\"\"\"\n#   message = hashlib.sha256()\n#   for s in seeds:\n#     message.update(bytes(s))\n#   # Limit the size of the returned value to fit into a np.int64.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/benchmarks/experimenters/synthetic/bbob.py\n# --------------------------------------------------\n#   arr.shape = (dim, 1)\n#   t = ArrayMap(arr, Tosz)\n#   l = SIndex(dim, arr) * t.flat\n# \n#   term1 = 10 * (dim - np.sum(np.cos(2 * math.pi * l), axis=0))\n#   term2 = np.sum(l * l, axis=0)\n#   term3 = 100 * Fpen(arr)\n#   return float(term1 + term2 + term3)\n# \n# \n# def LinearSlope(arr: np.ndarray, seed: int = 0) -> float:\n#   \"\"\"Implementation for BBOB LinearSlope function.\"\"\"\n#   dim = len(arr)\n#   arr.shape = (dim, 1)\n#   r = _R(dim, seed, b\"R\")\n#   z = np.matmul(r, arr)\n#   result = 0.0\n#   for i in range(dim):\n#     s = 10**(i / float(dim - 1) if dim > 1 else 1)\n#     z_opt = 5 * np.sum(np.abs(r[i, :]))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/benchmarks/experimenters/synthetic/bbob.py\n# --------------------------------------------------\n#   z = np.matmul(LambdaAlpha(10.0, dim), z)\n#   z = np.matmul(_R(dim, seed, b\"R\"), z)\n#   return float(10 * (dim - np.sum(np.cos(2 * math.pi * z))) +\n#                np.sum(z * z, axis=0))\n# \n# \n# def BuecheRastrigin(arr: np.ndarray, seed: int = 0) -> float:\n#   \"\"\"Implementation for BBOB BuecheRastrigin function.\"\"\"\n#   del seed\n#   dim = len(arr)\n#   arr.shape = (dim, 1)\n#   t = ArrayMap(arr, Tosz)\n#   l = SIndex(dim, arr) * t.flat\n# \n#   term1 = 10 * (dim - np.sum(np.cos(2 * math.pi * l), axis=0))\n#   term2 = np.sum(l * l, axis=0)\n#   term3 = 100 * Fpen(arr)\n#   return float(term1 + term2 + term3)\n# \n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n / float(dim - 1) if dim > 1 else 1)\n    z_opt = 5 * np.sum(np.abs(r[i, :]))\n    result += float(s * (z_opt - z[i]))\n  return result\n\n\ndef AttractiveSector(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Attractive Sector function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  x_opt = np.array([1 if i % 2 == 0 else -1 for i in range(dim)])\n  x_opt.shape = (dim, 1)\n  z_vec = np.matmul(_R(dim, seed, b\"R\"), arr - x_opt)\n  z_vec = np.matmul(LambdaAlpha(10.0, dim), z_vec)\n  z_vec = np.matmul(_R(dim, seed, b\"Q\"), z_vec)\n\n  result = 0.0\n  for i in range(dim):\n    z = z_vec[i, 0]\n    s = 100 if z * x_opt[i] > 0 else 1\n    result += (s * z)**2\n\n  return math.pow(Tosz(result), 0.9)\n\n\ndef StepEllipsoidal(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB StepEllipsoidal function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  z_hat = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z_hat = np.matmul(LambdaAlpha(10.0, dim), z_hat)\n  z_tilde = np.array([\n      math.floor(0.5 + z) if (z > 0.5) else (math.floor(0.5 + 10 * z) / 10)\n      for z in z_hat.flat\n  ])\n  z_tilde = np.matmul(_R(dim, seed, b\"Q\"), z_tilde)\n  s = 0.0\n  for i, val in enumerate(z_tilde):\n    exponent = 2.0 * float(i) / (dim - 1.0) if dim > 1.0 else 2.0\n    s += 10.0**exponent * val**2\n  value = max(abs(z_hat[0, 0]) / 1000, s)\n  return 0.1 * value + Fpen(arr)\n\n\ndef RosenbrockRotated(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB RosenbrockRotated function.\"\"\"\n  dim = len(arr)\n  r_x = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z = max(1.0, (dim**0.5) / 8.0) * r_x + 0.5 * np.ones((dim,))\n  return float(\n      sum([\n          100.0 * (z[i]**2 - z[i + 1])**2 + (z[i] - 1)**2\n          for i in range(dim - 1)\n      ]))\n\n\ndef Ellipsoidal(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Ellipsoidal function.\"\"\"\n  del seed\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  z_vec = ArrayMap(arr, Tosz)\n  s = 0.0\n  for i in range(dim):\n    exp = 6.0 * i / (dim - 1) if dim > 1 else 6.0\n    s += float(10**exp * z_vec[i] * z_vec[i])\n  return s\n\n\ndef Discus(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Discus function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  r_x = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z_vec = ArrayMap(r_x, Tosz)\n  return float(10**6 * z_vec[0] * z_vec[0]) + sum(\n      [z * z for z in z_vec[1:].flat])\n\n\ndef BentCigar(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB BentCigar function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  z_vec = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z_vec = Tasy(z_vec, 0.5)\n  z_vec = np.matmul(_R(dim, seed, b\"R\"), z_vec)\n  return float(z_vec[0]**2) + 10**6 * np.sum(z_vec[1:]**2)\n\n\ndef SharpRidge(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB SharpRidge function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  z_vec = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z_vec = np.matmul(LambdaAlpha(10, dim), z_vec)\n  z_vec = np.matmul(_R(dim, seed, b\"Q\"), z_vec)\n  return z_vec[0, 0]**2 + 100 * np.sum(z_vec[1:]**2)**0.5\n\n\ndef DifferentPowers(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB DifferentPowers function.\"\"\"\n  dim = len(arr)\n  z = np.matmul(_R(dim, seed, b\"R\"), arr)\n  s = 0.0\n  for i in range(dim):\n    exp = 2 + 4 * i / (dim - 1) if dim > 1 else 6\n    s += abs(z[i])**exp\n  return s**0.5\n\n\ndef Weierstrass(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Weierstrass function.\"\"\"\n  k_order = 12\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  z = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z = ArrayMap(z, Tosz)\n  z = np.matmul(_R(dim, seed, b\"Q\"), z)\n  z = np.matmul(LambdaAlpha(1.0 / 100.0, dim), z)\n  f0 = sum([0.5**k * math.cos(math.pi * 3**k) for k in range(k_order)])\n\n  s = 0.0\n  for i in range(dim):\n    for k in range(k_order):\n      s += 0.5**k * math.cos(2 * math.pi * (3**k) * (z[i] + 0.5))\n\n  return float(10 * (s / dim - f0)**3) + 10 * Fpen(arr) / dim\n\n\ndef SchaffersF7(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Weierstrass function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  if dim == 1:\n    return 0.0\n  z = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z = Tasy(z, 0.5)\n  z = np.matmul(_R(dim, seed, b\"Q\"), z)\n  z = np.matmul(LambdaAlpha(10.0, dim), z)\n\n  s_arr = np.zeros(dim - 1)\n  for i in range(dim - 1):\n    s_arr[i] = float((z[i]**2 + z[i + 1]**2)**0.5)", "choices": [{"text": ""}], "metadata": {"task_id": "google_vizier/186", "ground_truth": "  s = 0.0", "fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "context_start_lineno": 238, "line_no": 381, "query_window": {"context": "    for k in range(k_order):\n      s += 0.5**k * math.cos(2 * math.pi * (3**k) * (z[i] + 0.5))\n\n  return float(10 * (s / dim - f0)**3) + 10 * Fpen(arr) / dim\n\n\ndef SchaffersF7(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Weierstrass function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  if dim == 1:\n    return 0.0\n  z = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z = Tasy(z, 0.5)\n  z = np.matmul(_R(dim, seed, b\"Q\"), z)\n  z = np.matmul(LambdaAlpha(10.0, dim), z)\n\n  s_arr = np.zeros(dim - 1)\n  for i in range(dim - 1):\n    s_arr[i] = float((z[i]**2 + z[i + 1]**2)**0.5)", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "line_no": 381, "task_id": "google_vizier/186", "start_line_no": 361, "end_line_no": 381, "window_size": 20, "context_start_lineno": 238, "repo": "google_vizier"}}, "top_k_context": [{"context": "  return float(np.sum(arr * arr))\n\n\ndef Rastrigin(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Rastrigin function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  z = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z = Tasy(ArrayMap(z, Tosz), 0.2)\n  z = np.matmul(_R(dim, seed, b\"Q\"), z)\n  z = np.matmul(LambdaAlpha(10.0, dim), z)\n  z = np.matmul(_R(dim, seed, b\"R\"), z)\n  return float(10 * (dim - np.sum(np.cos(2 * math.pi * z))) +\n               np.sum(z * z, axis=0))\n\n\ndef BuecheRastrigin(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB BuecheRastrigin function.\"\"\"\n  del seed\n  dim = len(arr)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.5462184873949579}, {"context": "  z = np.matmul(LambdaAlpha(10.0, dim), z)\n  z = np.matmul(_R(dim, seed, b\"R\"), z)\n  return float(10 * (dim - np.sum(np.cos(2 * math.pi * z))) +\n               np.sum(z * z, axis=0))\n\n\ndef BuecheRastrigin(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB BuecheRastrigin function.\"\"\"\n  del seed\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  t = ArrayMap(arr, Tosz)\n  l = SIndex(dim, arr) * t.flat\n\n  term1 = 10 * (dim - np.sum(np.cos(2 * math.pi * l), axis=0))\n  term2 = np.sum(l * l, axis=0)\n  term3 = 100 * Fpen(arr)\n  return float(term1 + term2 + term3)\n\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.515625}, {"context": "      dim,\n  ])\n  for i in range(dim):\n    if dim > 1:\n      s[i] = 10**(0.5 * (i / (dim - 1.0)))\n    else:\n      s[i] = 10**0.5\n    if i % 2 == 0 and to_sz[i] > 0:\n      s[i] *= 10\n  return s\n\n\ndef Fpen(vector: np.ndarray) -> float:\n  \"\"\"The BBOB Fpen function.\n\n  Args:\n    vector: ndarray.\n\n  Returns:\n    float representing Fpen(vector).", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4180327868852459}, {"context": "    beta: Function parameter\n\n  Returns:\n    ndarray with values determined by beta.\n  \"\"\"\n  dim = len(vector)\n  result = np.zeros([dim, 1])\n  for i, val in enumerate(vector.flat):\n    if val > 0:\n      t = i / (dim - 1.0) if dim > 1 else 1\n      exp = 1 + beta * t * (val**0.5)\n    else:\n      exp = 1\n    result[i] = val**exp\n  return result\n\n\ndef SIndex(dim: int, to_sz) -> float:\n  \"\"\"Calculate the BBOB s_i.\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3684210526315789}, {"context": "  # The \"Q\" part of a Q-R decomposition is orthonormal, so $result is a pure\n  # rotation matrix.  If elements of $b are independent normal, then the\n  # distribution of rotations is uniform over the hypersphere.\n  return np.linalg.qr(b.reshape(dim, dim))[0]\n\n\n## BBOB Functions.\ndef Sphere(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Sphere function.\"\"\"\n  del seed\n  return float(np.sum(arr * arr))\n\n\ndef Rastrigin(arr: np.ndarray, seed: int = 0) -> float:\n  \"\"\"Implementation for BBOB Rastrigin function.\"\"\"\n  dim = len(arr)\n  arr.shape = (dim, 1)\n  z = np.matmul(_R(dim, seed, b\"R\"), arr)\n  z = Tasy(ArrayMap(z, Tosz), 0.2)\n  z = np.matmul(_R(dim, seed, b\"Q\"), z)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3584905660377358}, {"context": "  Assumes i is 0-index based.\n\n  Args:\n    dim: dimension\n    to_sz: values\n\n  Returns:\n    float representing SIndex(i, d, to_sz).\n  \"\"\"\n  s = np.zeros([\n      dim,\n  ])\n  for i in range(dim):\n    if dim > 1:\n      s[i] = 10**(0.5 * (i / (dim - 1.0)))\n    else:\n      s[i] = 10**0.5\n    if i % 2 == 0 and to_sz[i] > 0:\n      s[i] *= 10\n  return s", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.32558139534883723}, {"context": "      pyvizier.MetricInformation(\n          name=metric_name, goal=pyvizier.ObjectiveMetricGoal.MINIMIZE))\n  return problem_statement\n\n\n## Utility Functions for BBOB.\ndef LambdaAlpha(alpha: float, dim: int) -> np.ndarray:\n  \"\"\"The BBOB LambdaAlpha matrix creation function.\n\n  Args:\n    alpha: Function parameter.\n    dim: Dimension of matrix created.\n\n  Returns:\n    Diagonal matrix of dimension dim with values determined by alpha.\n  \"\"\"\n  lambda_alpha = np.zeros([dim, dim])\n  for i in range(dim):\n    exp = (0.5 * (float(i) / (dim - 1))) if dim > 1 else 0.5\n    lambda_alpha[i, i] = alpha**exp", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "synthetic", "bbob.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3248407643312102}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n#             scheduler_config = self.get_scheduler_config()\n#             scheduler = scheduler_class(**scheduler_config)\n# \n#             sample = self.dummy_sample\n#             residual = 0.1 * sample\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 scheduler.set_timesteps(num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             # copy over dummy past residuals (must be done after set_timesteps)\n#             dummy_past_residuals = [residual + 0.2, residual + 0.15, residual + 0.1, residual + 0.05]\n#             scheduler.ets = dummy_past_residuals[:]\n# \n#             output_0 = scheduler.step_prk(residual, 0, sample, **kwargs).prev_sample\n#             output_1 = scheduler.step_prk(residual, 1, sample, **kwargs).prev_sample\n# \n#             self.assertEqual(output_0.shape, sample.shape)\n#             self.assertEqual(output_0.shape, output_1.shape)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler_flax.py\n# --------------------------------------------------\n#             residual = 0.1 * sample\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 state = scheduler.set_timesteps(state, num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             output_0 = scheduler.step(state, residual, 0, sample, **kwargs).prev_sample\n#             output_1 = scheduler.step(state, residual, 1, sample, **kwargs).prev_sample\n# \n#             self.assertEqual(output_0.shape, sample.shape)\n#             self.assertEqual(output_0.shape, output_1.shape)\n# \n#     def test_timesteps(self):\n#         for timesteps in [100, 500, 1000]:\n#             self.check_over_configs(num_train_timesteps=timesteps)\n# \n#     def test_steps_offset(self):\n#         for steps_offset in [0, 1]:\n#             self.check_over_configs(steps_offset=steps_offset)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n# \n#             # copy over dummy past residuals (must be done after set_timesteps)\n#             dummy_past_residuals = [residual + 0.2, residual + 0.15, residual + 0.1, residual + 0.05]\n#             scheduler.ets = dummy_past_residuals[:]\n# \n#             output_0 = scheduler.step_prk(residual, 0, sample, **kwargs).prev_sample\n#             output_1 = scheduler.step_prk(residual, 1, sample, **kwargs).prev_sample\n# \n#             self.assertEqual(output_0.shape, sample.shape)\n#             self.assertEqual(output_0.shape, output_1.shape)\n# \n#             output_0 = scheduler.step_plms(residual, 0, sample, **kwargs).prev_sample\n#             output_1 = scheduler.step_plms(residual, 1, sample, **kwargs).prev_sample\n# \n#             self.assertEqual(output_0.shape, sample.shape)\n#             self.assertEqual(output_0.shape, output_1.shape)\n# \n#     def test_timesteps(self):\n#         for timesteps in [100, 1000]:\n#             self.check_over_configs(num_train_timesteps=timesteps)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler.py\n# --------------------------------------------------\n#             else:\n#                 sample = self.dummy_sample\n#                 residual = 0.1 * sample\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 scheduler.set_timesteps(num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             output_0 = scheduler.step(residual, timestep_0, sample, **kwargs).prev_sample\n#             output_1 = scheduler.step(residual, timestep_1, sample, **kwargs).prev_sample\n# \n#             self.assertEqual(output_0.shape, sample.shape)\n#             self.assertEqual(output_0.shape, output_1.shape)\n# \n#     def test_scheduler_outputs_equivalence(self):\n#         def set_nan_tensor_to_zero(t):\n#             t[t != t] = 0\n#             return t\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler_flax.py\n# --------------------------------------------------\n#                 state = scheduler.set_timesteps(state, num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# \n#             output_0 = scheduler.step(state, residual, 0, sample, key, **kwargs).prev_sample\n#             output_1 = scheduler.step(state, residual, 1, sample, key, **kwargs).prev_sample\n# \n#             self.assertEqual(output_0.shape, sample.shape)\n#             self.assertEqual(output_0.shape, output_1.shape)\n# \n#     def test_scheduler_outputs_equivalence(self):\n#         def set_nan_tensor_to_zero(t):\n#             return t.at[t != t].set(0)\n# \n#         def recursive_check(tuple_object, dict_object):\n#             if isinstance(tuple_object, (List, Tuple)):\n#                 for tuple_iterable_value, dict_iterable_value in zip(tuple_object, dict_object.values()):\n#                     recursive_check(tuple_iterable_value, dict_iterable_value)\n#             elif isinstance(tuple_object, Dict):\n#                 for tuple_iterable_value, dict_iterable_value in zip(tuple_object.values(), dict_object.values()):\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nsize = 4\n        num_channels = 3\n        height = 8\n        width = 8\n\n        num_elems = batch_size * num_channels * height * width\n        sample = torch.arange(num_elems)\n        sample = sample.reshape(num_channels, height, width, batch_size)\n        sample = sample / num_elems\n        sample = sample.permute(3, 0, 1, 2)\n\n        return sample\n\n    def dummy_model(self):\n        def model(sample, t, *args):\n            return sample * t / (t + 1)\n\n        return model\n\n    def get_scheduler_config(self, **kwargs):\n        config = {\n            \"num_train_timesteps\": 2000,\n            \"snr\": 0.15,\n            \"sigma_min\": 0.01,\n            \"sigma_max\": 1348,\n            \"sampling_eps\": 1e-5,\n        }\n\n        config.update(**kwargs)\n        return config\n\n    def check_over_configs(self, time_step=0, **config):\n        kwargs = dict(self.forward_default_kwargs)\n\n        for scheduler_class in self.scheduler_classes:\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            scheduler_config = self.get_scheduler_config(**config)\n            scheduler = scheduler_class(**scheduler_config)\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            output = scheduler.step_pred(\n                residual, time_step, sample, generator=torch.manual_seed(0), **kwargs\n            ).prev_sample\n            new_output = new_scheduler.step_pred(\n                residual, time_step, sample, generator=torch.manual_seed(0), **kwargs\n            ).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n            output = scheduler.step_correct(residual, sample, generator=torch.manual_seed(0), **kwargs).prev_sample\n            new_output = new_scheduler.step_correct(\n                residual, sample, generator=torch.manual_seed(0), **kwargs\n            ).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler correction are not identical\"\n\n    def check_over_forward(self, time_step=0, **forward_kwargs):\n        kwargs = dict(self.forward_default_kwargs)\n        kwargs.update(forward_kwargs)\n\n        for scheduler_class in self.scheduler_classes:\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            output = scheduler.step_pred(\n                residual, time_step, sample, generator=torch.manual_seed(0), **kwargs\n            ).prev_sample\n            new_output = new_scheduler.step_pred(\n                residual, time_step, sample, generator=torch.manual_seed(0), **kwargs\n            ).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n            output = scheduler.step_correct(residual, sample, generator=torch.manual_seed(0), **kwargs).prev_sample\n            new_output = new_scheduler.step_correct(\n                residual, sample, generator=torch.manual_seed(0), **kwargs\n            ).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler correction are not identical\"\n\n    def test_timesteps(self):\n        for timesteps in [10, 100, 1000]:\n            self.check_over_configs(num_train_timesteps=timesteps)\n\n    def test_sigmas(self):\n        for sigma_min, sigma_max in zip([0.0001, 0.001, 0.01], [1, 100, 1000]):\n            self.check_over_configs(sigma_min=sigma_min, sigma_max=sigma_max)\n\n    def test_time_indices(self):\n        for t in [0.1, 0.5, 0.75]:\n            self.check_over_forward(time_step=t)\n\n    def test_full_loop_no_noise(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        scheduler_class = self.scheduler_classes[0]\n        scheduler_config = self.get_scheduler_config()\n        scheduler = scheduler_class(**scheduler_config)\n\n        num_inference_steps = 3\n\n        model = self.dummy_model()\n        sample = self.dummy_sample_deter\n\n        scheduler.set_sigmas(num_inference_steps)\n        scheduler.set_timesteps(num_inference_steps)\n        generator = torch.manual_seed(0)\n\n        for i, t in enumerate(scheduler.timesteps):\n            sigma_t = scheduler.sigmas[i]\n\n            for _ in range(scheduler.config.correct_steps):\n                with torch.no_grad():\n                    model_output = model(sample, sigma_t)\n                sample = scheduler.step_correct(model_output, sample, generator=generator, **kwargs).prev_sample\n\n            with torch.no_grad():\n                model_output = model(sample, sigma_t)\n\n            output = scheduler.step_pred(model_output, t, sample, generator=generator, **kwargs)\n            sample, _ = output.prev_sample, output.prev_sample_mean\n\n        result_sum = torch.sum(torch.abs(sample))\n        result_mean = torch.mean(torch.abs(sample))\n\n        assert np.isclose(result_sum.item(), 14372758528.0)\n        assert np.isclose(result_mean.item(), 18714530.0)\n\n    def test_step_shape(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output_0 = scheduler.step_pred(residual, 0, sample, generator=torch.manual_seed(0), **kwargs).prev_sample\n            output_1 = scheduler.step_pred(residual, 1, sample, generator=torch.manual_seed(0), **kwargs).prev_sample\n\n            self.assertEqual(output_0.shape, sample.shape)\n            self.assertEqual(output_0.shape, output_1.shape)\n\n\nclass LMSDiscreteSchedulerTest(SchedulerCommonTest):\n    scheduler_classes = (LMSDiscreteScheduler,)", "choices": [{"text": "scheduler_classes = (LMSDiscreteScheduler,)"}], "metadata": {"task_id": "huggingface_diffusers/139", "ground_truth": "    num_inference_steps = 10", "fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "context_start_lineno": 1484, "line_no": 1650, "query_window": {"context": "            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output_0 = scheduler.step_pred(residual, 0, sample, generator=torch.manual_seed(0), **kwargs).prev_sample\n            output_1 = scheduler.step_pred(residual, 1, sample, generator=torch.manual_seed(0), **kwargs).prev_sample\n\n            self.assertEqual(output_0.shape, sample.shape)\n            self.assertEqual(output_0.shape, output_1.shape)\n\n\nclass LMSDiscreteSchedulerTest(SchedulerCommonTest):\n    scheduler_classes = (LMSDiscreteScheduler,)", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 1650, "task_id": "huggingface_diffusers/139", "start_line_no": 1630, "end_line_no": 1650, "window_size": 20, "context_start_lineno": 1484, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()\n\n            sample, key = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                state = scheduler.set_timesteps(state, num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output_0 = scheduler.step(state, residual, 0, sample, key, **kwargs).prev_sample\n            output_1 = scheduler.step(state, residual, 1, sample, key, **kwargs).prev_sample\n\n            self.assertEqual(output_0.shape, sample.shape)\n            self.assertEqual(output_0.shape, output_1.shape)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6868686868686869}, {"context": "                timestep_1 = float(timestep_1)\n\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            if scheduler_class == VQDiffusionScheduler:\n                num_vec_classes = scheduler_config[\"num_vec_classes\"]\n                sample = self.dummy_sample(num_vec_classes)\n                model = self.dummy_model(num_vec_classes)\n                residual = model(sample, timestep_0)\n            else:\n                sample = self.dummy_sample\n                residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output_0 = scheduler.step(residual, timestep_0, sample, **kwargs).prev_sample", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6442307692307693}, {"context": "            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            # copy over dummy past residuals (must be done after set_timesteps)\n            dummy_past_residuals = [residual + 0.2, residual + 0.15, residual + 0.1, residual + 0.05]\n            scheduler.ets = dummy_past_residuals[:]\n\n            output_0 = scheduler.step_prk(residual, 0, sample, **kwargs).prev_sample\n            output_1 = scheduler.step_prk(residual, 1, sample, **kwargs).prev_sample\n\n            self.assertEqual(output_0.shape, sample.shape)\n            self.assertEqual(output_0.shape, output_1.shape)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 1350, "start_line_no": 1340, "end_line_no": 1360, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6228070175438597}, {"context": "        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()\n\n            sample, _ = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                state = scheduler.set_timesteps(state, num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output_0 = scheduler.step(state, residual, 0, sample, **kwargs).prev_sample\n            output_1 = scheduler.step(state, residual, 1, sample, **kwargs).prev_sample\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5943396226415094}, {"context": "            sample = scheduler.step_plms(residual, t, sample).prev_sample\n\n        return sample\n\n    def test_step_shape(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            sample = self.dummy_sample\n            residual = 0.1 * sample\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 1340, "start_line_no": 1330, "end_line_no": 1350, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5925925925925926}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/predictive/base.py\n# --------------------------------------------------\n#         .. math::\n#             \\text{argmax}_y\\ p(y|x, \\mathcal{D}),\n# \n#         where:\n#          - :math:`x` is an observed input variable;\n#          - :math:`\\mathcal{D}` is the observed training data set;\n#          - :math:`y` is the target variable to optimize upon.\n# \n#         Parameters\n#         ----------\n#         inputs_loader : InputsLoader\n#             A loader of input data points.\n#         n_posterior_samples : int\n#             Number of samples to draw from the posterior distribution for each input.\n#         means : Optional[jnp.ndarray] = None\n#             An estimate of the predictive mean.\n#         rng : Optional[PRNGKeyArray]\n#             A random number generator. If not passed, this will be taken from the attributes of this class.\n#         distribute: bool\n#             Whether to distribute computation over multiple devices, if available.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n#         calibrated: bool = True,\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate a credible interval of the target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n#         outputs: Array\n#             Model outputs.\n#         n_target_samples: int\n#             Number of target samples to draw for each output.\n#         error: float\n#             The interval error. This must be a number between 0 and 1, extremes included. For example,\n#             `error=0.05` corresponds to a 95% level of credibility.\n#         interval_type: str\n#             The interval type. We support \"two-tailed\" (default), \"right-tailed\" and \"left-tailed\".\n#         rng : Optional[PRNGKeyArray]\n#             A random number generator. If not passed, this will be taken from the attributes of this class.\n#         calibrated : bool\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n#         n_target_samples: Optional[int]\n#             Number of target samples to draw when computing quantiles.\n#         rng: Optional[PRNGKeyArray]\n#             A random number generator.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated quantiles for each output.\n#         \"\"\"\n#         if calibrated:\n#             self._check_calibrated()\n#             state = self.state.get()\n#             outputs = self.output_calib_manager.apply(\n#                 params=state.params[\"output_calibrator\"],\n#                 outputs=outputs,\n#                 mutable=state.mutable[\"output_calibrator\"],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/predictive/base.py\n# --------------------------------------------------\n#     ) -> jnp.ndarray:\n#         r\"\"\"\n#         Sample parameters from the posterior distribution state and compute calibrated outputs.\n# \n#         Parameters\n#         ----------\n#         inputs_loader : InputsLoader\n#             A loader of input data points.\n#         n_output_samples : int\n#             Number of output samples to draw for each input.\n#         rng: Optional[PRNGKeyArray]\n#             A random number generator. If not passed, this will be taken from the attributes of this class.\n#         distribute: bool\n#             Whether to distribute computation over multiple devices, if available.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Samples of calibrated outputs.\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/likelihood/regression.py\n# --------------------------------------------------\n#         calib_mutable: Optional[CalibMutable] = None,\n#         n_target_samples: Optional[int] = 30,\n#         target_samples: Optional[jnp.ndarray] = None,\n#         rng: Optional[PRNGKeyArray] = None,\n#         distribute: bool = True,\n#         **kwargs\n#     ) -> Union[float, jnp.ndarray]:\n#         \"\"\"\n#         Estimate the `q`-th quantiles of the likelihood function.\n# \n#         Parameters\n#         ----------\n#         q: Union[float, jnp.ndarray, np.ndarray]\n#             Quantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\n#         params : Params\n#             The random parameters of the probabilistic model.\n#         inputs_loader : InputsLoader\n#             A loader of input data points.\n#         mutable : Optional[Mutable]\n#             The mutable objects used to evaluate the models.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the quantile of the target variable given the output, with respect to the predictive distribution.\n# \n#         Parameters\n#         ----------\n#         q: Union[float, Array, List]\n#             Quantile(s) to estimate.\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         n_target_samples: Optional[int]\n#             Number of target samples to draw when computing quantiles.\n#         rng: Optional[PRNGKeyArray]\n#             A random number generator.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/likelihood/regression.py\n# --------------------------------------------------\n#         Parameters\n#         ----------\n#         q: Union[float, jnp.ndarray, np.ndarray]\n#             Quantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\n#         params : Params\n#             The random parameters of the probabilistic model.\n#         inputs_loader : InputsLoader\n#             A loader of input data points.\n#         mutable : Optional[Mutable]\n#             The mutable objects used to evaluate the models.\n#         calib_params : Optional[CalibParams]\n#             The calibration parameters of the probabilistic model.\n#         calib_mutable : Optional[CalibMutable]\n#             The calibration mutable objects used to evaluate the calibrators.\n#         n_target_samples : int\n#             Number of target samples to sample for each input data point.\n#         target_samples: Optional[jnp.ndarray] = None\n#             Samples of the target variable for each input, used to estimate the quantiles.\n#         rng: Optional[PRNGKeyArray]\n#             A random number generator. If not passed, this will be taken from the attributes of this class.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nget()\n        key1, *keys = random.split(rng, 1 + n_posterior_samples)\n\n        ensemble_outputs = self.sample_calibrated_outputs(\n            inputs_loader=inputs_loader,\n            n_output_samples=n_posterior_samples,\n            rng=key1,\n            distribute=distribute,\n        )\n\n        ensemble_target_samples = lax.map(\n            lambda variables: self.likelihood.prob_output_layer.sample(\n                n_target_samples, variables[0], rng=variables[1]\n            ),\n            (ensemble_outputs, jnp.array(keys)),\n        )\n\n        def fun(i, _curr_sum):\n            @vmap\n            def _log_pred_fun(target_sample: jnp.ndarray):\n                logps = self.likelihood.prob_output_layer.log_prob(\n                    ensemble_outputs, target_sample\n                )\n                return jsp.special.logsumexp(logps, 0) - jnp.log(n_posterior_samples)\n\n            log_preds = _log_pred_fun(ensemble_target_samples[i])\n            log_liks = self.likelihood.prob_output_layer.log_prob(\n                ensemble_outputs[i], ensemble_target_samples[i]\n            )\n            _curr_sum -= jnp.mean(log_preds - log_liks, 0)\n            return _curr_sum\n\n        curr_sum = fun(0, 0.0)\n        curr_sum = lax.fori_loop(1, n_posterior_samples, fun, curr_sum)\n        return curr_sum / n_posterior_samples\n\n    def entropy(\n        self,\n        inputs_loader: InputsLoader,\n        n_posterior_samples: int = 30,\n        n_target_samples: int = 30,\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,\n    ) -> jnp.ndarray:\n        r\"\"\"\n        Estimate the predictive entropy, that is\n\n        .. math::\n            -\\mathbb{E}_{Y|x, \\mathcal{D}}[\\log p(Y|x, \\mathcal{D})],\n\n        where:\n         - :math:`x` is an observed input variable;\n         - :math:`Y` is a random target variable;\n         - :math:`\\mathcal{D}` is the observed training data set;\n         - :math:`W` denotes the random model parameters.\n\n        Parameters\n        ----------\n        inputs_loader : InputsLoader\n            A loader of input data points.\n        n_target_samples: int\n            Number of target samples to draw for each input.\n        n_posterior_samples : int\n            Number of samples to draw from the posterior distribution for each input.\n        rng : Optional[PRNGKeyArray]\n            A random number generator. If not passed, this will be taken from the attributes of this class.\n        distribute: bool\n            Whether to distribute computation over multiple devices, if available.\n\n        Returns\n        -------\n        jnp.ndarray\n            An estimate of the predictive entropy for each input.\n        \"\"\"\n        if rng is None:\n            rng = self.rng.get()\n        key1, *keys = random.split(rng, 1 + n_posterior_samples)\n\n        ensemble_outputs = self.sample_calibrated_outputs(\n            inputs_loader=inputs_loader,\n            n_output_samples=n_posterior_samples,\n            rng=key1,\n            distribute=distribute,\n        )\n\n        ensemble_target_samples = lax.map(\n            lambda variables: self.likelihood.prob_output_layer.sample(\n                n_target_samples, variables[0], rng=variables[1]\n            ),\n            (ensemble_outputs, jnp.array(keys)),\n        )\n\n        def fun(i, _curr_sum):\n            @vmap\n            def _log_pred_fun(target_sample: jnp.ndarray):\n                logps = self.likelihood.prob_output_layer.log_prob(\n                    ensemble_outputs, target_sample\n                )\n                return jsp.special.logsumexp(logps, 0) - jnp.log(n_posterior_samples)\n\n            log_preds = _log_pred_fun(ensemble_target_samples[i])\n            _curr_sum -= jnp.mean(log_preds, 0)\n            return _curr_sum\n\n        curr_sum = fun(0, 0.0)\n        curr_sum = lax.fori_loop(1, n_posterior_samples, fun, curr_sum)\n        return curr_sum / n_posterior_samples\n\n    def credible_interval(\n        self,\n        inputs_loader: InputsLoader,\n        n_target_samples: int = 30,\n        error: float = 0.05,\n        interval_type: str = \"two-tailed\",\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,\n    ) -> jnp.ndarray:\n        r\"\"\"\n        Estimate credible intervals for the target variable. This is supported only if the target variable is scalar.\n\n        Parameters\n        ----------\n        inputs_loader : InputsLoader\n            A loader of input data points.\n        n_target_samples: int\n            Number of target samples to draw for each input.\n        error: float\n            The interval error. This must be a number between 0 and 1, extremes included. For example,\n            `error=0.05` corresponds to a 95% level of credibility.\n        interval_type: str\n            The interval type. We support \"two-tailed\" (default), \"right-tailed\" and \"left-tailed\".\n        rng : Optional[PRNGKeyArray]\n            A random number generator. If not passed, this will be taken from the attributes of this class.\n        distribute: bool\n            Whether to distribute computation over multiple devices, if available.\n\n        Returns\n        -------\n        jnp.ndarray\n            A credibility interval for each of the inputs.\n        \"\"\"\n        supported_types = [\"two-tailed\", \"right-tailed\", \"left-tailed\"]\n        if interval_type not in supported_types:\n            raise ValueError(\n                \"`type={}` not recognised. Please choose among the following supported types: {}.\".format(\n                    supported_types\n                )\n            )\n        q = (\n            jnp.array([0.5 * error, 1 - 0.5 * error])\n            if interval_type == \"two-tailed\"\n            else error\n            if interval_type == \"left-tailed\"\n            else 1 - error\n        )\n        qq = self.quantile(\n            q=q,\n            inputs_loader=inputs_loader,\n            n_target_samples=n_target_samples,\n            rng=rng,\n            distribute=distribute,\n        )\n        if qq.shape[-1] != 1:\n            raise ValueError(\n                \"\"\"Credibility intervals are only supported for scalar target variables.\"\"\"\n            )\n        if interval_type == \"two-tailed\":\n            lq, uq = qq.squeeze(2)\n            return jnp.array(list(zip(lq, uq)))\n        else:\n            return qq\n\n    def quantile(\n        self,\n        q: Union[float, Array, List],\n        inputs_loader: InputsLoader,\n        n_target_samples: Optional[int] = 30,\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,\n    ) -> Union[float, jnp.ndarray]:\n        r\"\"\"\n        Estimate the `q`-th quantiles of the predictive probability density function.\n\n        Parameters\n        ----------\n        q : Union[float, Array, List]\n            Quantile or sequence of quantiles to compute. Each of these must be between 0 and 1, extremes included.\n        inputs_loader : InputsLoader\n            A loader of input data points.\n        n_target_samples : int", "choices": [{"text": "Number of target samples to draw when computing quantiles."}], "metadata": {"task_id": "awslabs_fortuna/189", "ground_truth": "            Number of target samples to sample for each input data point.", "fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "regression.py"], "context_start_lineno": 152, "line_no": 342, "query_window": {"context": "            return qq\n\n    def quantile(\n        self,\n        q: Union[float, Array, List],\n        inputs_loader: InputsLoader,\n        n_target_samples: Optional[int] = 30,\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,\n    ) -> Union[float, jnp.ndarray]:\n        r\"\"\"\n        Estimate the `q`-th quantiles of the predictive probability density function.\n\n        Parameters\n        ----------\n        q : Union[float, Array, List]\n            Quantile or sequence of quantiles to compute. Each of these must be between 0 and 1, extremes included.\n        inputs_loader : InputsLoader\n            A loader of input data points.\n        n_target_samples : int", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "regression.py"], "line_no": 342, "task_id": "awslabs_fortuna/189", "start_line_no": 322, "end_line_no": 342, "window_size": 20, "context_start_lineno": 152, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        calib_mutable: Optional[CalibMutable] = None,\n        n_target_samples: Optional[int] = 30,\n        target_samples: Optional[jnp.ndarray] = None,\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,\n        **kwargs\n    ) -> Union[float, jnp.ndarray]:\n        \"\"\"\n        Estimate the `q`-th quantiles of the likelihood function.\n\n        Parameters\n        ----------\n        q: Union[float, jnp.ndarray, np.ndarray]\n            Quantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\n        params : Params\n            The random parameters of the probabilistic model.\n        inputs_loader : InputsLoader\n            A loader of input data points.\n        mutable : Optional[Mutable]\n            The mutable objects used to evaluate the models.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "regression.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6129032258064516}, {"context": "            prob_output_layer=prob_output_layer,\n        )\n\n    def quantile(\n        self,\n        q: Union[float, Array, List],\n        outputs: Array,\n        n_target_samples: Optional[int] = 30,\n        rng: Optional[PRNGKeyArray] = None,\n        calibrated: bool = True,\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the quantile of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        q: Union[float, Array, List]\n            Quantile(s) to estimate.\n        outputs : jnp.ndarray\n            Model outputs.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5045045045045045}, {"context": "\n        return -jnp.mean(_log_lik_fun(samples), 0)\n\n    def quantile(\n        self,\n        q: Union[float, jnp.ndarray, np.ndarray],\n        params: Optional[Params] = None,\n        inputs_loader: Optional[InputsLoader] = None,\n        mutable: Optional[Mutable] = None,\n        calib_params: Optional[CalibParams] = None,\n        calib_mutable: Optional[CalibMutable] = None,\n        n_target_samples: Optional[int] = 30,\n        target_samples: Optional[jnp.ndarray] = None,\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,\n        **kwargs\n    ) -> Union[float, jnp.ndarray]:\n        \"\"\"\n        Estimate the `q`-th quantiles of the likelihood function.\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "regression.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.49586776859504134}, {"context": "            return outs.squeeze(0)\n\n        return lax.map(_sample, keys)\n\n    def sample_calibrated_outputs(\n        self,\n        inputs_loader: InputsLoader,\n        n_output_samples: int = 1,\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,\n    ) -> jnp.ndarray:\n        r\"\"\"\n        Sample parameters from the posterior distribution state and compute calibrated outputs.\n\n        Parameters\n        ----------\n        inputs_loader : InputsLoader\n            A loader of input data points.\n        n_output_samples : int\n            Number of output samples to draw for each input.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "base.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4672131147540984}, {"context": "    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the quantile of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        q: Union[float, Array, List]\n            Quantile(s) to estimate.\n        outputs : jnp.ndarray\n            Model outputs.\n        n_target_samples: Optional[int]\n            Number of target samples to draw when computing quantiles.\n        rng: Optional[PRNGKeyArray]\n            A random number generator.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.43410852713178294}, {"context": "            )\n        return self.prob_output_layer.quantile(q, outputs, n_target_samples, rng)\n\n    def credible_interval(\n        self,\n        outputs: Array,\n        n_target_samples: int = 30,\n        error: float = 0.05,\n        interval_type: str = \"two-tailed\",\n        rng: Optional[PRNGKeyArray] = None,\n        calibrated: bool = True,\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate a credible interval of the target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs: Array\n            Model outputs.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.42276422764227645}, {"context": "        self,\n        inputs_loader: InputsLoader,\n        n_posterior_samples: int = 30,\n        means: Optional[jnp.ndarray] = None,\n        rng: Optional[PRNGKeyArray] = None,\n        distribute: bool = True,\n    ) -> jnp.ndarray:\n        r\"\"\"\n        Estimate the predictive mode of the target variable, that is\n\n        .. math::\n            \\text{argmax}_y\\ p(y|x, \\mathcal{D}),\n\n        where:\n         - :math:`x` is an observed input variable;\n         - :math:`\\mathcal{D}` is the observed training data set;\n         - :math:`y` is the target variable to optimize upon.\n\n        Parameters\n        ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "base.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4153846153846154}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_trainer.py\n# --------------------------------------------------\n#                 state,\n#                 {\"loss\": 1, \"logging_kwargs\": {\"metric1:\": 0.1, \"metrics2\": 0.2}},\n#                 batch,\n#                 (),\n#                 {},\n#             )\n#         msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n#         self.assertEqual(\n#             training_losses_and_metrics, {\"loss\": 1, \"metric1:\": 0.1, \"metrics2\": 0.2}\n#         )\n# \n#         trainer = FakeTrainer(\n#             predict_fn=lambda x: x,\n#             disable_training_metrics_computation=False,\n#             save_checkpoint_dir=\"tmp_dir\",\n#             save_every_n_steps=1,\n#             keep_top_n_checkpoints=3,\n#         )\n# \n#         with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_trainer.py\n# --------------------------------------------------\n#                 {\"loss\": 1, \"logging_kwargs\": {\"metric1:\": 0.1, \"metrics2\": 0.2}},\n#                 batch,\n#                 None,\n#                 {},\n#             )\n#         msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n#         self.assertEqual(\n#             training_losses_and_metrics, {\"loss\": 1, \"metric1:\": 0.1, \"metrics2\": 0.2}\n#         )\n# \n#     def test_training_step_end_ok(self):\n#         trainer = FakeTrainer(\n#             predict_fn=lambda x: x,\n#             disable_training_metrics_computation=False,\n#             save_checkpoint_dir=\"tmp_dir\",\n#             save_every_n_steps=1,\n#             keep_top_n_checkpoints=3,\n#         )\n#         state = FakeTrainState()\n#         batch = [[1, 2, 3], [0, 0, 1]]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_trainer.py\n# --------------------------------------------------\n#         state = FakeTrainState()\n#         batch = [[1, 2, 3], [0, 0, 1]]\n#         with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n#             with self.assertRaises(KeyError):\n#                 trainer.training_step_end(1, state, {}, batch, (), {})\n#         msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n# \n#         with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n#             with self.assertRaises(KeyError):\n#                 trainer.training_step_end(1, state, {\"loss\": 1}, batch, (), {})\n#         msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n# \n#         with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n#             with self.assertRaises(KeyError):\n#                 trainer.training_step_end(\n#                     1, state, {\"loss\": 1, \"logging_kwargs\": None}, batch, (), {}\n#                 )\n#         msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n# \n#     def test_training_step_end_ok_no_training_metrics_computation(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/training/mixin.py\n# --------------------------------------------------\n#         ):\n#             if early_stopping_verbose:\n#                 logging.warning(\n#                     f\"`early_stopping_mode={early_stopping_mode}` is not a valid. Early stopping will be disabled.\"\n#                 )\n#         else:\n#             self._early_stopping = EarlyStopping(\n#                 min_delta=early_stopping_min_delta, patience=early_stopping_patience\n#             )\n#             if early_stopping_verbose:\n#                 logging.info(\"If validation data are provided, early stopping will be enabled.\")\n# \n#     @property\n#     def is_early_stopping_active(self) -> bool:\n#         return not (\n#             (self.early_stopping_patience is None or self.early_stopping_patience <= 0)\n#             or (\n#                 self.early_stopping_mode is None\n#                 or self.early_stopping_mode not in (\"min\", \"max\")\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_trainer.py\n# --------------------------------------------------\n# \n#         trainer = FakeTrainer(\n#             predict_fn=lambda x: x,\n#             disable_training_metrics_computation=False,\n#             save_checkpoint_dir=\"tmp_dir\",\n#             save_every_n_steps=1,\n#             keep_top_n_checkpoints=3,\n#         )\n# \n#         with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n#             training_losses_and_metrics = trainer.training_step_end(\n#                 1, state, {\"loss\": 1, \"logging_kwargs\": None}, batch, None, {}\n#             )\n#         msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n#         self.assertEqual(training_losses_and_metrics, {\"loss\": 1})\n# \n#         with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n#             training_losses_and_metrics = trainer.training_step_end(\n#                 1,\n#                 state,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_trainer.py\n# --------------------------------------------------\n#     def test_training_step_end_ok(self):\n#         trainer = FakeTrainer(\n#             predict_fn=lambda x: x,\n#             disable_training_metrics_computation=False,\n#             save_checkpoint_dir=\"tmp_dir\",\n#             save_every_n_steps=1,\n#             keep_top_n_checkpoints=3,\n#         )\n#         state = FakeTrainState()\n#         batch = [[1, 2, 3], [0, 0, 1]]\n# \n#         def train_m1(a, b):\n#             return 12.0\n# \n#         with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n#             training_losses_and_metrics = trainer.training_step_end(\n#                 1,\n#                 state,\n#                 {\"loss\": 1, \"logging_kwargs\": None, \"outputs\": [10, 20, 30]},\n#                 batch,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n1)),\n                    encoded_name=PosteriorState.encoded_name,\n                    mutable=None,\n                    opt_state=dict(model=1),\n                    calib_params=None,\n                    calib_mutable=None,\n                )\n                restored_state = trainer.restore_checkpoint(\n                    tmp_dir, prefix=\"test_prefix_\"\n                )\n                mc.restore_checkpoint.assert_called_with(\n                    ckpt_dir=tmp_dir,\n                    target=None,\n                    step=None,\n                    prefix=\"test_prefix_\",\n                    parallel=True,\n                )\n\n\nclass TestEarlyStoppingMixins(unittest.TestCase):\n    def test_early_stopping_is_not_active(self):\n        trainer = FakeTrainerWithEarlyStopping()\n        with self.assertRaises(AttributeError):\n            _ = trainer._early_stopping\n        self.assertFalse(trainer.is_early_stopping_active)\n\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"val_loss\",\n            early_stopping_min_delta=1,\n            early_stopping_patience=0,\n            early_stopping_mode=\"min\",\n        )\n        with self.assertRaises(AttributeError):\n            _ = trainer._early_stopping\n        self.assertFalse(trainer.is_early_stopping_active)\n\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"val_loss\",\n            early_stopping_min_delta=1,\n            early_stopping_patience=0,\n            early_stopping_mode=\"not_valid\",\n        )\n        with self.assertRaises(AttributeError):\n            _ = trainer._early_stopping\n        self.assertFalse(trainer.is_early_stopping_active)\n\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"val_loss\",\n            early_stopping_min_delta=1,\n            early_stopping_patience=0,\n            early_stopping_mode=\"not_valid\",\n        )\n        with self.assertRaises(AttributeError):\n            _ = trainer._early_stopping\n        self.assertFalse(trainer.is_early_stopping_active)\n\n    def test_is_early_stopping_active(self):\n        trainer = FakeTrainerWithEarlyStopping()\n        self.assertFalse(trainer.is_early_stopping_active)\n\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"val_loss\",\n            early_stopping_min_delta=1,\n            early_stopping_patience=2,\n            early_stopping_mode=\"min\",\n        )\n        self.assertTrue(trainer.is_early_stopping_active)\n\n    def test_early_stopping_update_when_not_active(self):\n        validation_metrics = {\"metric1\": 1, \"metric2\": 2}\n        trainer = FakeTrainerWithEarlyStopping()\n        self.assertIsNone(trainer.early_stopping_update(validation_metrics))\n\n    def test_early_stopping_update_non_existing_metric(self):\n        validation_metrics = {\"metric1\": 1, \"metric2\": 2}\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"val_loss\",\n            early_stopping_min_delta=1,\n            early_stopping_patience=2,\n            early_stopping_mode=\"min\",\n        )\n        with self.assertRaises(KeyError):\n            trainer.early_stopping_update(validation_metrics)\n\n    def test_early_stopping_update_ok_min(self):\n        validation_metrics_step1 = {\"metric1\": 1, \"metric2\": 2}\n        validation_metrics_step2 = {\"metric1\": 0.8, \"metric2\": 2}\n        validation_metrics_step3 = {\"metric1\": 0.6, \"metric2\": 2}\n        validation_metrics_step4 = {\"metric1\": 1.1, \"metric2\": 2}\n        validation_metrics_step5 = {\"metric1\": 1, \"metric2\": 2}\n\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"metric1\",\n            early_stopping_min_delta=0,\n            early_stopping_patience=1,\n            early_stopping_mode=\"min\",\n        )\n        improved = trainer.early_stopping_update(validation_metrics_step1)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step2)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step3)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step4)\n        self.assertFalse(improved)\n        self.assertFalse(trainer._early_stopping.should_stop)\n        improved = trainer.early_stopping_update(validation_metrics_step5)\n        self.assertFalse(improved)\n        self.assertTrue(trainer._early_stopping.should_stop)\n\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"metric1\",\n            early_stopping_min_delta=0,\n            early_stopping_patience=2,\n            early_stopping_mode=\"min\",\n        )\n        improved = trainer.early_stopping_update(validation_metrics_step1)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step2)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step3)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step4)\n        self.assertFalse(improved)\n        self.assertFalse(trainer._early_stopping.should_stop)\n        improved = trainer.early_stopping_update(validation_metrics_step5)\n        self.assertFalse(improved)\n        self.assertFalse(trainer._early_stopping.should_stop)\n        improved = trainer.early_stopping_update(validation_metrics_step5)\n        self.assertFalse(improved)\n        self.assertTrue(trainer._early_stopping.should_stop)\n\n    def test_early_stopping_update_ok_max(self):\n        validation_metrics_step1 = {\"metric1\": 1, \"metric2\": 2}\n        validation_metrics_step2 = {\"metric1\": 1.6, \"metric2\": 2}\n        validation_metrics_step3 = {\"metric1\": 1.8, \"metric2\": 2}\n        validation_metrics_step4 = {\"metric1\": 0.1, \"metric2\": 2}\n        validation_metrics_step5 = {\"metric1\": 0.2, \"metric2\": 2}\n\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"metric1\",\n            early_stopping_min_delta=0,\n            early_stopping_patience=2,\n            early_stopping_mode=\"max\",\n        )\n        improved = trainer.early_stopping_update(validation_metrics_step1)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step2)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step3)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step4)\n        self.assertFalse(improved)\n        self.assertFalse(trainer._early_stopping.should_stop)\n        improved = trainer.early_stopping_update(validation_metrics_step5)", "choices": [{"text": "self.assertFalse(improved)"}], "metadata": {"task_id": "awslabs_fortuna/152", "ground_truth": "        self.assertFalse(improved)", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_mixin.py"], "context_start_lineno": 104, "line_no": 259, "query_window": {"context": "        validation_metrics_step3 = {\"metric1\": 1.8, \"metric2\": 2}\n        validation_metrics_step4 = {\"metric1\": 0.1, \"metric2\": 2}\n        validation_metrics_step5 = {\"metric1\": 0.2, \"metric2\": 2}\n\n        trainer = FakeTrainerWithEarlyStopping(\n            early_stopping_monitor=\"metric1\",\n            early_stopping_min_delta=0,\n            early_stopping_patience=2,\n            early_stopping_mode=\"max\",\n        )\n        improved = trainer.early_stopping_update(validation_metrics_step1)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step2)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step3)\n        self.assertTrue(improved)\n        improved = trainer.early_stopping_update(validation_metrics_step4)\n        self.assertFalse(improved)\n        self.assertFalse(trainer._early_stopping.should_stop)\n        improved = trainer.early_stopping_update(validation_metrics_step5)", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_mixin.py"], "line_no": 259, "task_id": "awslabs_fortuna/152", "start_line_no": 239, "end_line_no": 259, "window_size": 20, "context_start_lineno": 104, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "                {\"loss\": 1, \"logging_kwargs\": {\"metric1:\": 0.1, \"metrics2\": 0.2}},\n                batch,\n                None,\n                {},\n            )\n        msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n        self.assertEqual(\n            training_losses_and_metrics, {\"loss\": 1, \"metric1:\": 0.1, \"metrics2\": 0.2}\n        )\n\n    def test_training_step_end_ok(self):\n        trainer = FakeTrainer(\n            predict_fn=lambda x: x,\n            disable_training_metrics_computation=False,\n            save_checkpoint_dir=\"tmp_dir\",\n            save_every_n_steps=1,\n            keep_top_n_checkpoints=3,\n        )\n        state = FakeTrainState()\n        batch = [[1, 2, 3], [0, 0, 1]]", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_trainer.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3008130081300813}, {"context": "                state,\n                {\"loss\": 1, \"logging_kwargs\": {\"metric1:\": 0.1, \"metrics2\": 0.2}},\n                batch,\n                (),\n                {},\n            )\n        msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n        self.assertEqual(\n            training_losses_and_metrics, {\"loss\": 1, \"metric1:\": 0.1, \"metrics2\": 0.2}\n        )\n\n        trainer = FakeTrainer(\n            predict_fn=lambda x: x,\n            disable_training_metrics_computation=False,\n            save_checkpoint_dir=\"tmp_dir\",\n            save_every_n_steps=1,\n            keep_top_n_checkpoints=3,\n        )\n\n        with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_trainer.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.29411764705882354}, {"context": "        self.early_stopping_patience = early_stopping_patience\n\n        if early_stopping_patience is None or early_stopping_patience <= 0:\n            if early_stopping_verbose:\n                logging.info(\n                    f\"Early stopping not enabled. Set `early_stopping_patience>=0` to enable it.\"\n                )\n        elif self.early_stopping_mode is None or self.early_stopping_mode not in (\n            \"min\",\n            \"max\",\n        ):\n            if early_stopping_verbose:\n                logging.warning(\n                    f\"`early_stopping_mode={early_stopping_mode}` is not a valid. Early stopping will be disabled.\"\n                )\n        else:\n            self._early_stopping = EarlyStopping(\n                min_delta=early_stopping_min_delta, patience=early_stopping_patience\n            )\n            if early_stopping_verbose:", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "training", "mixin.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2897196261682243}, {"context": "        self.assertFalse(trainer.is_early_stopping_active)\n\n    def test_training_step_end_missing_keys(self):\n        trainer = FakeTrainer(\n            predict_fn=lambda x: x,\n            disable_training_metrics_computation=False,\n            save_checkpoint_dir=\"tmp_dir\",\n            save_every_n_steps=1,\n            keep_top_n_checkpoints=3,\n        )\n        state = FakeTrainState()\n        batch = [[1, 2, 3], [0, 0, 1]]\n        with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n            with self.assertRaises(KeyError):\n                trainer.training_step_end(1, state, {}, batch, (), {})\n        msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n\n        with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n            with self.assertRaises(KeyError):\n                trainer.training_step_end(1, state, {\"loss\": 1}, batch, (), {})", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_trainer.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2857142857142857}, {"context": "            training_losses_and_metrics = trainer.training_step_end(\n                1, state, {\"loss\": 1, \"logging_kwargs\": None}, batch, None, {}\n            )\n        msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n        self.assertEqual(training_losses_and_metrics, {\"loss\": 1})\n\n        with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n            training_losses_and_metrics = trainer.training_step_end(\n                1,\n                state,\n                {\"loss\": 1, \"logging_kwargs\": {\"metric1:\": 0.1, \"metrics2\": 0.2}},\n                batch,\n                None,\n                {},\n            )\n        msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n        self.assertEqual(\n            training_losses_and_metrics, {\"loss\": 1, \"metric1:\": 0.1, \"metrics2\": 0.2}\n        )\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_trainer.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.28440366972477066}, {"context": "        with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n            training_losses_and_metrics = trainer.training_step_end(\n                1, state, {\"loss\": 1, \"logging_kwargs\": None}, batch, (), {}\n            )\n        msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n        self.assertEqual(training_losses_and_metrics, {\"loss\": 1})\n\n        with unittest.mock.patch.object(trainer, \"save_checkpoint\") as msc:\n            training_losses_and_metrics = trainer.training_step_end(\n                1,\n                state,\n                {\"loss\": 1, \"logging_kwargs\": {\"metric1:\": 0.1, \"metrics2\": 0.2}},\n                batch,\n                (),\n                {},\n            )\n        msc.assert_called_once_with(state, \"tmp_dir\", keep=3)\n        self.assertEqual(\n            training_losses_and_metrics, {\"loss\": 1, \"metric1:\": 0.1, \"metrics2\": 0.2}\n        )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_trainer.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.2818181818181818}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry_algo.py\n# --------------------------------------------------\n#         f.write(\"4. a2c\\n\")\n# \n# \n# @pytest.mark.algotest\n# def test_rainbow():\n#     config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n#     try:\n#         serial_pipeline(config, seed=0)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     with open(\"./algo_record.log\", \"a+\") as f:\n#         f.write(\"5. rainbow\\n\")\n# \n# \n# @pytest.mark.algotest\n# def test_ppo():\n#     config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n#     try:\n#         ppo_main(config[0], seed=0)\n#     except Exception:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry_algo.py\n# --------------------------------------------------\n#     try:\n#         serial_pipeline(config, seed=0)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     with open(\"./algo_record.log\", \"a+\") as f:\n#         f.write(\"16. impala\\n\")\n# \n# \n# @pytest.mark.algotest\n# def test_iqn():\n#     config = [deepcopy(cartpole_iqn_config), deepcopy(cartpole_iqn_create_config)]\n#     try:\n#         serial_pipeline(config, seed=0)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     with open(\"./algo_record.log\", \"a+\") as f:\n#         f.write(\"17. iqn\\n\")\n# \n# \n# @pytest.mark.algotest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry_algo.py\n# --------------------------------------------------\n# def test_her_dqn():\n#     try:\n#         bitflip_dqn_main(bitflip_her_dqn_config, seed=0)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     with open(\"./algo_record.log\", \"a+\") as f:\n#         f.write(\"18. her dqn\\n\")\n# \n# \n# @pytest.mark.algotest\n# def test_ppg():\n#     try:\n#         ppg_main(cartpole_ppg_config, seed=0)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     with open(\"./algo_record.log\", \"a+\") as f:\n#         f.write(\"19. ppg\\n\")\n# \n# \n# @pytest.mark.algotest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry_algo.py\n# --------------------------------------------------\n# @pytest.mark.algotest\n# def test_a2c_with_nstep_return():\n#     config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n#     config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n#     config[0].policy.collect.discount_factor = 0.9\n#     config[0].policy.collect.nstep = 3\n#     try:\n#         serial_pipeline(config, seed=0)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n#     with open(\"./algo_record.log\", \"a+\") as f:\n#         f.write(\"12. a2c with nstep return\\n\")\n# \n# \n# # @pytest.mark.algotest\n# def test_atoc():\n#     config = [deepcopy(cooperative_navigation_atoc_config), deepcopy(cooperative_navigation_atoc_create_config)]\n#     try:\n#         serial_pipeline(config, seed=0)\n#     except Exception:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry_reward_model.py\n# --------------------------------------------------\n#         config, seed=0, state_dict=state_dict, expert_data_path=expert_data_path, collect_count=collect_count\n#     )\n#     # irl + rl training\n#     cp_cartpole_dqn_config = deepcopy(cartpole_dqn_config)\n#     cp_cartpole_dqn_create_config = deepcopy(cartpole_dqn_create_config)\n#     cp_cartpole_dqn_create_config.reward_model = dict(type=reward_model_config.type)\n#     reward_model_config['expert_data_path'] = expert_data_path\n#     cp_cartpole_dqn_config.reward_model = reward_model_config\n#     serial_pipeline_reward_model((cp_cartpole_dqn_config, cp_cartpole_dqn_create_config), seed=0, max_iterations=2)\n# \n#     os.popen(\"rm -rf ckpt_* log expert_data.pkl\")\n# \n# \n# @pytest.mark.unittest\n# def test_rnd():\n#     config = [deepcopy(cartpole_ppo_rnd_config), deepcopy(cartpole_ppo_rnd_create_config)]\n#     try:\n#         serial_pipeline_reward_model(config, seed=0, max_iterations=2)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry_sqil.py\n# --------------------------------------------------\n# from ding.entry import serial_pipeline\n# from ding.entry.serial_entry_sqil import serial_pipeline_sqil\n# from dizoo.classic_control.cartpole.config.cartpole_sql_config import cartpole_sql_config, cartpole_sql_create_config\n# from dizoo.classic_control.cartpole.config.cartpole_sqil_config import cartpole_sqil_config, cartpole_sqil_create_config\n# \n# \n# @pytest.mark.unittest\n# def test_sqil():\n#     expert_policy_state_dict_path = './expert_policy.pth'\n#     config = [deepcopy(cartpole_sql_config), deepcopy(cartpole_sql_create_config)]\n#     expert_policy = serial_pipeline(config, seed=0)\n#     torch.save(expert_policy.collect_mode.state_dict(), expert_policy_state_dict_path)\n# \n#     config = [deepcopy(cartpole_sqil_config), deepcopy(cartpole_sqil_create_config)]\n#     config[0].policy.collect.demonstration_info_path = expert_policy_state_dict_path\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline_sqil(config, [cartpole_sql_config, cartpole_sql_create_config], seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\ntran_config, cooperative_navigation_qtran_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_atoc_config, cooperative_navigation_atoc_create_config  # noqa\nfrom dizoo.league_demo.league_demo_ppo_config import league_demo_ppo_config\nfrom dizoo.league_demo.selfplay_demo_ppo_main import main as selfplay_main\nfrom dizoo.league_demo.league_demo_ppo_main import main as league_main\nfrom dizoo.classic_control.pendulum.config.pendulum_sac_data_generation_default_config import pendulum_sac_data_genearation_default_config, pendulum_sac_data_genearation_default_create_config  # noqa\nfrom dizoo.classic_control.pendulum.config.pendulum_cql_config import pendulum_cql_default_config, pendulum_cql_default_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_qrdqn_generation_data_config import cartpole_qrdqn_generation_data_config, cartpole_qrdqn_generation_data_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_cql_config import cartpole_discrete_cql_config, cartpole_discrete_cql_create_config  # noqa\n\n\n@pytest.mark.unittest\n@pytest.mark.dqn\ndef test_dqn():\n    config = [deepcopy(cartpole_dqn_config), deepcopy(cartpole_dqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n    finally:\n        os.popen('rm -rf log ckpt*')\n\n\n@pytest.mark.unittest\ndef test_ddpg():\n    config = [deepcopy(pendulum_ddpg_config), deepcopy(pendulum_ddpg_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_td3():\n    config = [deepcopy(pendulum_td3_config), deepcopy(pendulum_td3_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_rainbow():\n    config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_iqn():\n    config = [deepcopy(cartpole_iqn_config), deepcopy(cartpole_iqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_c51():\n    config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_qrdqn():\n    config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_ppo():\n    config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        ppo_main(config[0], seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sac():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_sac_auto_alpha():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    config[0].policy.learn.is_auto_alpha = True\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_r2d2():\n    config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_impala():\n    config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_her_dqn():\n    bitflip_her_dqn_config.policy.cuda = False", "choices": [{"text": "config = [deepcopy(bitflip_her_dqn_config), deepcopy(bitflip_her_dqn_create_config)]"}], "metadata": {"task_id": "opendilab_ACE/171", "ground_truth": "    try:", "fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "context_start_lineno": 31, "line_no": 192, "query_window": {"context": "    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_impala():\n    config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_her_dqn():\n    bitflip_her_dqn_config.policy.cuda = False", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 192, "task_id": "opendilab_ACE/171", "start_line_no": 172, "end_line_no": 192, "window_size": 20, "context_start_lineno": 31, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "def test_sqil():\n    expert_policy_state_dict_path = './expert_policy.pth'\n    config = [deepcopy(cartpole_sql_config), deepcopy(cartpole_sql_create_config)]\n    expert_policy = serial_pipeline(config, seed=0)\n    torch.save(expert_policy.collect_mode.state_dict(), expert_policy_state_dict_path)\n\n    config = [deepcopy(cartpole_sqil_config), deepcopy(cartpole_sqil_create_config)]\n    config[0].policy.collect.demonstration_info_path = expert_policy_state_dict_path\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline_sqil(config, [cartpole_sql_config, cartpole_sql_create_config], seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_sqil.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 23, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5652173913043478}, {"context": "    serial_pipeline_reward_model((cp_cartpole_dqn_config, cp_cartpole_dqn_create_config), seed=0, max_iterations=2)\n\n    os.popen(\"rm -rf ckpt_* log expert_data.pkl\")\n\n\n@pytest.mark.unittest\ndef test_rnd():\n    config = [deepcopy(cartpole_ppo_rnd_config), deepcopy(cartpole_ppo_rnd_create_config)]\n    try:\n        serial_pipeline_reward_model(config, seed=0, max_iterations=2)\n    except Exception:\n        assert False, \"pipeline fail\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_reward_model.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 72, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5473684210526316}, {"context": "def test_r2d2():\n    config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"11. r2d2\\n\")\n\n\n@pytest.mark.algotest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5294117647058824}, {"context": "    config = [deepcopy(cartpole_iqn_config), deepcopy(cartpole_iqn_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"17. iqn\\n\")\n\n\n@pytest.mark.algotest\ndef test_her_dqn():\n    try:\n        bitflip_dqn_main(bitflip_her_dqn_config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"18. her dqn\\n\")\n\n\n@pytest.mark.algotest", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5102040816326531}, {"context": "        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"15. qmix\\n\")\n\n\n@pytest.mark.algotest\ndef test_impala():\n    config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"16. impala\\n\")\n\n\n@pytest.mark.algotest\ndef test_iqn():", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5052631578947369}, {"context": "\n\n@pytest.mark.algotest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"4. a2c\\n\")\n\n\n@pytest.mark.algotest\ndef test_rainbow():\n    config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_xgb.py\n# tests/test_vertical_fl.py\n# --------------------------------------------------\n# # Copyright (c) Alibaba, Inc. and its affiliates.\n# import unittest\n# \n# from federatedscope.core.auxiliaries.data_builder import get_data\n# from federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\n# from federatedscope.core.auxiliaries.utils import setup_seed\n# from federatedscope.core.auxiliaries.logging import update_logger\n# from federatedscope.core.configs.config import global_cfg\n# from federatedscope.core.auxiliaries.runner_builder import get_runner\n# \n# \n# class XGBTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config(self, cfg):\n#         backup_cfg = cfg.clone()\n# \n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_fedsageplus.py\n# tests/test_finetune_lr.py\n# tests/test_fedopt.py\n# tests/test_backdoor_attack.py\n# tests/test_PIA_toy.py\n# tests/test_pfedme.py\n# tests/test_unseen_clients_lr.py\n# tests/test_asyn_cifar10.py\n# tests/test_graph_node_trainer.py\n# tests/test_femnist.py\n# tests/test_MIA_gradient_ascent.py\n# tests/test_optimizer.py\n# tests/test_CRA_gan_attack.py\n# tests/test_efficient_simulation.py\n# tests/test_toy_lr.py\n# tests/test_external_dataset.py\n# tests/test_global_train_lr.py\n# tests/test_nbafl.py\n# tests/test_fedprox.py\n# tests/test_fedem.py\n# tests/test_rec_opt_attack.py\n# tests/test_mf.py\n# tests/test_rec_IG_opt_attack.py\n# tests/test_ditto.py\n# --------------------------------------------------\n# # Copyright (c) Alibaba, Inc. and its affiliates.\n# import unittest\n# \n# from federatedscope.core.auxiliaries.data_builder import get_data\n# from federatedscope.core.auxiliaries.utils import setup_seed\n# from federatedscope.core.auxiliaries.logging import update_logger\n# from federatedscope.core.configs.config import global_cfg\n# from federatedscope.core.auxiliaries.runner_builder import get_runner\n# from federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n# \n# \n# class FedSagePlusTest(unittest.TestCase):\n#     def setUp(self):\n#         print(('Testing %s.%s' % (type(self).__name__, self._testMethodName)))\n# \n#     def set_config_fedsageplus(self, cfg):\n#         backup_cfg = cfg.clone()\n# \n#         import torch\n#         cfg.use_gpu = torch.cuda.is_available()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/hpo.py\n# --------------------------------------------------\n# import os\n# import sys\n# \n# DEV_MODE = False  # simplify the federatedscope re-setup everytime we change\n# # the source codes of federatedscope\n# if DEV_MODE:\n#     file_dir = os.path.join(os.path.dirname(__file__), '..')\n#     sys.path.append(file_dir)\n# \n# from federatedscope.core.auxiliaries.utils import setup_seed\n# from federatedscope.core.auxiliaries.logging import update_logger\n# from federatedscope.core.cmd_args import parse_args, parse_client_cfg\n# from federatedscope.core.configs.config import global_cfg, CfgNode\n# from federatedscope.autotune import get_scheduler, run_scheduler\n# \n# if os.environ.get('https_proxy'):\n#     del os.environ['https_proxy']\n# if os.environ.get('http_proxy'):\n#     del os.environ['http_proxy']\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/main.py\n# --------------------------------------------------\n# import os\n# import sys\n# \n# DEV_MODE = False  # simplify the federatedscope re-setup everytime we change\n# # the source codes of federatedscope\n# if DEV_MODE:\n#     file_dir = os.path.join(os.path.dirname(__file__), '..')\n#     sys.path.append(file_dir)\n# \n# from federatedscope.core.cmd_args import parse_args, parse_client_cfg\n# from federatedscope.core.auxiliaries.data_builder import get_data\n# from federatedscope.core.auxiliaries.utils import setup_seed\n# from federatedscope.core.auxiliaries.logging import update_logger\n# from federatedscope.core.auxiliaries.worker_builder import get_client_cls, \\\n#     get_server_cls\n# from federatedscope.core.configs.config import global_cfg, CfgNode\n# from federatedscope.core.auxiliaries.runner_builder import get_runner\n# \n# if os.environ.get('https_proxy'):\n#     del os.environ['https_proxy']\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_yaml.py\n# --------------------------------------------------\n# # Copyright (c) Alibaba, Inc. and its affiliates.\n# import os\n# import logging\n# import unittest\n# \n# from federatedscope.core.configs.config import global_cfg\n# \n# logger = logging.getLogger(__name__)\n# \n# \n# class YAMLTest(unittest.TestCase):\n#     def setUp(self):\n#         self.exclude_all = ['benchmark', 'scripts', 'federatedscope/autotune']\n#         self.exclude_file = [\n#             '.pre-commit-config.yaml', 'meta.yaml',\n#             'federatedscope/gfl/baseline/isolated_gin_minibatch_on_cikmcup_per_client.yaml',\n#             'federatedscope/gfl/baseline/fedavg_gin_minibatch_on_cikmcup_per_client.yaml',\n#             'federatedscope/gfl/baseline/mini_graph_dc/fedavg_per_client.yaml'\n#         ]\n#         self.exclude_str = ['config.yaml', 'config_client']\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n# mypy: ignore-errors\nimport os\nimport stat\nimport subprocess\n\nfrom jupyter_core.paths import jupyter_data_dir\n\nc = get_config()  # noqa: F821", "choices": [{"text": "c.IPKernelApp.pylab = 'inline'"}], "metadata": {"task_id": "alibaba_FederatedScope/150", "ground_truth": "c.ServerApp.ip = \"0.0.0.0\"", "fpath_tuple": ["alibaba_FederatedScope", "environment", "docker_files", "federatedscope-jupyterhub", "jupyter_server_config.py"], "context_start_lineno": 0, "line_no": 10, "query_window": {"context": "# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n# mypy: ignore-errors\nimport os\nimport stat\nimport subprocess\n\nfrom jupyter_core.paths import jupyter_data_dir\n\nc = get_config()  # noqa: F821", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "environment", "docker_files", "federatedscope-jupyterhub", "jupyter_server_config.py"], "line_no": 10, "task_id": "alibaba_FederatedScope/150", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport os\nimport logging\nimport unittest\n\nfrom federatedscope.core.configs.config import global_cfg\n\nlogger = logging.getLogger(__name__)\n\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_yaml.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2077922077922078}, {"context": "import os\nimport sys\n\nDEV_MODE = False  # simplify the federatedscope re-setup everytime we change\n# the source codes of federatedscope\nif DEV_MODE:\n    file_dir = os.path.join(os.path.dirname(__file__), '..')\n    sys.path.append(file_dir)\n\nfrom federatedscope.core.cmd_args import parse_args, parse_client_cfg", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "main.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.20652173913043478}, {"context": "import os\nimport sys\n\nDEV_MODE = False  # simplify the federatedscope re-setup everytime we change\n# the source codes of federatedscope\nif DEV_MODE:\n    file_dir = os.path.join(os.path.dirname(__file__), '..')\n    sys.path.append(file_dir)\n\nfrom federatedscope.core.auxiliaries.utils import setup_seed", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "hpo.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.20652173913043478}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\nfrom federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_fedsageplus.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_finetune_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_fedopt.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_backdoor_attack.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_PIA_toy.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_pfedme.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_unseen_clients_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_asyn_cifar10.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_graph_node_trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_femnist.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_MIA_gradient_ascent.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_optimizer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_CRA_gan_attack.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_efficient_simulation.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_toy_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_external_dataset.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_global_train_lr.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_nbafl.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_fedprox.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_fedem.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_rec_opt_attack.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_mf.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_rec_IG_opt_attack.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_ditto.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.19047619047619047}, {"context": "# Copyright (c) Alibaba, Inc. and its affiliates.\nimport unittest\n\nfrom federatedscope.core.auxiliaries.data_builder import get_data\nfrom federatedscope.core.auxiliaries.worker_builder import get_client_cls, get_server_cls\nfrom federatedscope.core.auxiliaries.utils import setup_seed\nfrom federatedscope.core.auxiliaries.logging import update_logger\nfrom federatedscope.core.configs.config import global_cfg\nfrom federatedscope.core.auxiliaries.runner_builder import get_runner\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_xgb.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}, {"fpath_tuple": ["alibaba_FederatedScope", "tests", "test_vertical_fl.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.19047619047619047}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/conformal/classification/simple_prediction.py\n# --------------------------------------------------\n#         error: float\n#             The coverage error. This must be a scalar between 0 and 1, extremes included.\n#         quantile: Optional[float]\n#             Conformal quantiles. This should be the output of\n#             :meth:`~fortuna.conformal.classification.simple_prediction.SimplePredictionConformalClassifier.quantile`.\n# \n#         Returns\n#         -------\n#         List[List[int, ...]]\n#             The coverage sets.\n#         \"\"\"\n#         if test_probs.ndim != 2:\n#             raise ValueError(\n#                 \"\"\"`test_probs` must be a two-dimensional array. The first dimension is over the validation\n#             inputs. The second is over the classes.\"\"\"\n#             )\n# \n#         if quantile is None:\n#             quantile = self.quantile(val_probs, val_targets, error)\n#         return [jnp.where(prob > 1 - quantile)[0].tolist() for prob in test_probs]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/conformal/regression/onedim_uncertainty.py\n# --------------------------------------------------\n#             raise ValueError(\n#                 \"\"\"`val_preds` must be a two-dimensional array. The second dimension must have only one\n#             component.\"\"\"\n#             )\n#         if val_uncertainties.ndim != 2 or val_uncertainties.shape[1] != 1:\n#             raise ValueError(\n#                 \"\"\"`val_uncertainties` must be a two-dimensional array. The second dimension must have only\n#             one component.\"\"\"\n#             )\n#         if (val_uncertainties <= 0).any():\n#             raise ValueError(\n#                 \"\"\"All elements in `val_uncertainties` must be strictly positive.\"\"\"\n#             )\n#         if val_targets.shape[1] != 1:\n#             raise ValueError(\n#                 \"\"\"The second dimension of the array(s) in `val_targets` must have only one component.\"\"\"\n#             )\n#         return (jnp.abs(val_targets - val_preds) / val_uncertainties).squeeze(1)\n# \n#     def quantile(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/conformal/classification/simple_prediction.py\n# --------------------------------------------------\n#         Returns\n#         -------\n#         jnp.ndarray\n#             The conformal scores.\n#         \"\"\"\n#         if val_probs.ndim != 2:\n#             raise ValueError(\n#                 \"\"\"`val_probs` must be a two-dimensional array. The first dimension is over the validation\n#             inputs. The second is over the classes.\"\"\"\n#             )\n# \n#         @vmap\n#         def score_fn(prob, target):\n#             return 1 - prob[target]\n# \n#         return score_fn(val_probs, val_targets)\n# \n#     def quantile(\n#         self,\n#         val_probs: Array,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/conformal/regression/quantile.py\n# --------------------------------------------------\n#         val_lower_bounds: Array,\n#         val_upper_bounds: Array,\n#         val_targets: Array,\n#         error: float,\n#         scores: Optional[Array] = None,\n#     ) -> Array:\n#         \"\"\"\n#         Compute a quantile of the scores.\n# \n#         Parameters\n#         ----------\n#         val_lower_bounds: Array\n#             Interval lower bounds computed on a validation set.\n#         val_upper_bounds: Array\n#             Interval upper bounds computed on a validation set.\n#         val_targets: Array\n#             A two-dimensional array of validation target variables.\n#         error: float\n#             Coverage error. This must be a scalar between 0 and 1, extremes included. This should correspond to the\n#             coverage error for which `val_lower_bounds`, `val_upper_bounds`, `test_lower_bounds` and\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/conformal/classification/simple_prediction.py\n# --------------------------------------------------\n#         val_targets: Array,\n#         error: float = 0.05,\n#         scores: Optional[Array] = None,\n#     ) -> Array:\n#         \"\"\"\n#         Compute a quantile of the scores.\n# \n#         Parameters\n#         ----------\n#         val_probs: Array\n#             A two-dimensional array of class probabilities for each validation data point.\n#         val_targets: Array\n#             A one-dimensional array of validation target variables.\n#         error: float\n#             Coverage error. This must be a scalar between 0 and 1, extremes included.\n#         scores: Optional[Array]\n#             The conformal scores. This should be the output of\n#             :meth:`~fortuna.conformal.classification.simple_prediction.SimplePredictionConformalClassifier.score`.\n# \n#         Returns\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/conformal/classification/simple_prediction.py\n# --------------------------------------------------\n#         error: float\n#             The coverage error. This must be a scalar between 0 and 1, extremes included.\n#         quantile: Optional[float]\n#             Conformal quantiles. This should be the output of\n#             :meth:`~fortuna.conformal.classification.simple_prediction.SimplePredictionConformalClassifier.quantile`.\n# \n#         Returns\n#         -------\n#         List[List[int, ...]]\n#             The coverage sets.\n#         \"\"\"\n#         if test_probs.ndim != 2:\n#             raise ValueError(\n#                 \"\"\"`test_probs` must be a two-dimensional array. The first dimension is over the validation\n#             inputs. The second is over the classes.\"\"\"\n#             )\n# \n#         if quantile is None:\n#             quantile = self.quantile(val_probs, val_targets, error)\n#         return [jnp.where(prob > 1 - quantile)[0].tolist() for prob in test_probs]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/conformal/classification/simple_prediction.py\n# --------------------------------------------------\n# \n#         @vmap\n#         def score_fn(prob, target):\n#             return 1 - prob[target]\n# \n#         return score_fn(val_probs, val_targets)\n# \n#     def quantile(\n#         self,\n#         val_probs: Array,\n#         val_targets: Array,\n#         error: float = 0.05,\n#         scores: Optional[Array] = None,\n#     ) -> Array:\n#         \"\"\"\n#         Compute a quantile of the scores.\n# \n#         Parameters\n#         ----------\n#         val_probs: Array\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import List, Optional\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom jax import vmap\n\nfrom fortuna.typing import Array\n\n\nclass AdaptivePredictionConformalClassifier:\n    def score(self, val_probs: Array, val_targets: Array,) -> jnp.ndarray:\n        \"\"\"\n        Compute score function.\n\n        Parameters\n        ----------\n        val_probs: Array\n            A two-dimensional array of class probabilities for each validation data point.\n        val_targets: Array\n            A one-dimensional array of validation target variables.\n\n        Returns\n        -------\n        jnp.ndarray\n            The conformal scores.\n        \"\"\"\n        if val_probs.ndim != 2:\n            raise ValueError(\n                \"\"\"`val_probs` must be a two-dimensional array. The first dimension is over the validation\n            inputs. The second is over the classes.\"\"\"\n            )\n\n        perms = jnp.argsort(val_probs, axis=1)[:, ::-1]\n        inv_perms = jnp.argsort(perms, axis=1)\n\n        @vmap\n        def score_fn(prob, perm, inv_perm, target):\n            sorted_prob = prob[perm]\n            return jnp.cumsum(sorted_prob)[inv_perm[target]]\n\n        return score_fn(val_probs, perms, inv_perms, val_targets)\n\n    def quantile(\n        self,\n        val_probs: Array,\n        val_targets: Array,\n        error: float = 0.05,", "choices": [{"text": ""}], "metadata": {"task_id": "awslabs_fortuna/185", "ground_truth": "        scores: Optional[Array] = None,", "fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "classification", "adaptive_prediction.py"], "context_start_lineno": 0, "line_no": 47, "query_window": {"context": "            raise ValueError(\n                \"\"\"`val_probs` must be a two-dimensional array. The first dimension is over the validation\n            inputs. The second is over the classes.\"\"\"\n            )\n\n        perms = jnp.argsort(val_probs, axis=1)[:, ::-1]\n        inv_perms = jnp.argsort(perms, axis=1)\n\n        @vmap\n        def score_fn(prob, perm, inv_perm, target):\n            sorted_prob = prob[perm]\n            return jnp.cumsum(sorted_prob)[inv_perm[target]]\n\n        return score_fn(val_probs, perms, inv_perms, val_targets)\n\n    def quantile(\n        self,\n        val_probs: Array,\n        val_targets: Array,\n        error: float = 0.05,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "classification", "adaptive_prediction.py"], "line_no": 47, "task_id": "awslabs_fortuna/185", "start_line_no": 27, "end_line_no": 47, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        Returns\n        -------\n        jnp.ndarray\n            The conformal scores.\n        \"\"\"\n        if val_probs.ndim != 2:\n            raise ValueError(\n                \"\"\"`val_probs` must be a two-dimensional array. The first dimension is over the validation\n            inputs. The second is over the classes.\"\"\"\n            )\n\n        @vmap\n        def score_fn(prob, target):\n            return 1 - prob[target]\n\n        return score_fn(val_probs, val_targets)\n\n    def quantile(\n        self,\n        val_probs: Array,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "classification", "simple_prediction.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6153846153846154}, {"context": "            The coverage sets.\n        \"\"\"\n        if test_probs.ndim != 2:\n            raise ValueError(\n                \"\"\"`test_probs` must be a two-dimensional array. The first dimension is over the validation\n            inputs. The second is over the classes.\"\"\"\n            )\n\n        if quantile is None:\n            quantile = self.quantile(val_probs, val_targets, error)\n        return [jnp.where(prob > 1 - quantile)[0].tolist() for prob in test_probs]", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "classification", "simple_prediction.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 111, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.46956521739130436}, {"context": "\n        @vmap\n        def score_fn(prob, target):\n            return 1 - prob[target]\n\n        return score_fn(val_probs, val_targets)\n\n    def quantile(\n        self,\n        val_probs: Array,\n        val_targets: Array,\n        error: float = 0.05,\n        scores: Optional[Array] = None,\n    ) -> Array:\n        \"\"\"\n        Compute a quantile of the scores.\n\n        Parameters\n        ----------\n        val_probs: Array", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "classification", "simple_prediction.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4326923076923077}, {"context": "            raise ValueError(\n                \"\"\"The second dimension of `val_targets` must have only one component.\"\"\"\n            )\n        val_targets = val_targets.squeeze(1)\n        return jnp.maximum(\n            val_lower_bounds - val_targets, val_targets - val_upper_bounds\n        )\n\n    def quantile(\n        self,\n        val_lower_bounds: Array,\n        val_upper_bounds: Array,\n        val_targets: Array,\n        error: float,\n        scores: Optional[Array] = None,\n    ) -> Array:\n        \"\"\"\n        Compute a quantile of the scores.\n\n        Parameters", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "regression", "quantile.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.39473684210526316}, {"context": "        \"\"\"\n        Compute score function.\n\n        Parameters\n        ----------\n        val_probs: Array\n            A two-dimensional array of class probabilities for each validation data point.\n        val_targets: Array\n            A one-dimensional array of validation target variables.\n\n        Returns\n        -------\n        jnp.ndarray\n            The conformal scores.\n        \"\"\"\n        if val_probs.ndim != 2:\n            raise ValueError(\n                \"\"\"`val_probs` must be a two-dimensional array. The first dimension is over the validation\n            inputs. The second is over the classes.\"\"\"\n            )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "classification", "simple_prediction.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3898305084745763}, {"context": "            dimension is over the validation inputs. The second must have only one component.\n        val_targets: Array\n            A two-dimensional array of validation target variables.\n\n        Returns\n        -------\n        jnp.ndarray\n            Scores.\n        \"\"\"\n        if val_preds.ndim != 2 or val_preds.shape[1] != 1:\n            raise ValueError(\n                \"\"\"`val_preds` must be a two-dimensional array. The second dimension must have only one\n            component.\"\"\"\n            )\n        if val_uncertainties.ndim != 2 or val_uncertainties.shape[1] != 1:\n            raise ValueError(\n                \"\"\"`val_uncertainties` must be a two-dimensional array. The second dimension must have only\n            one component.\"\"\"\n            )\n        if (val_uncertainties <= 0).any():", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "regression", "onedim_uncertainty.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3865546218487395}, {"context": "            A one-dimensional array of validation target variables.\n        error: float\n            The coverage error. This must be a scalar between 0 and 1, extremes included.\n        quantile: Optional[float]\n            Conformal quantiles. This should be the output of\n            :meth:`~fortuna.conformal.classification.simple_prediction.SimplePredictionConformalClassifier.quantile`.\n\n        Returns\n        -------\n        List[List[int, ...]]\n            The coverage sets.\n        \"\"\"\n        if test_probs.ndim != 2:\n            raise ValueError(\n                \"\"\"`test_probs` must be a two-dimensional array. The first dimension is over the validation\n            inputs. The second is over the classes.\"\"\"\n            )\n\n        if quantile is None:\n            quantile = self.quantile(val_probs, val_targets, error)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "conformal", "classification", "simple_prediction.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3673469387755102}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/base_parallel_collector.py\n# --------------------------------------------------\n#     def close(self) -> None:\n#         if self._end_flag:\n#             return\n#         self._end_flag = True\n#         self._join_thread()\n# \n#     def _iter_after_hook(self):\n#         # log_buffer -> tick_monitor -> monitor.step\n#         for k, v in self._log_buffer.items():\n#             setattr(self._monitor, k, v)\n#         self._monitor.time.step()\n#         # Print info\n#         if self._iter_count % self._cfg.print_freq == 0:\n#             self.debug('{}TimeStep{}{}'.format('=' * 35, self._iter_count, '=' * 35))\n#             # tick_monitor -> var_dict\n#             var_dict = {}\n#             for k in self._log_buffer:\n#                 for attr in self._monitor.get_property_attribute(k):\n#                     k_attr = k + '_' + attr\n#                     var_dict[k_attr] = getattr(self._monitor, attr)[k]()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/masac.py\n# --------------------------------------------------\n#         return ret\n# \n#     def _load_state_dict_learn(self, state_dict: Dict[str, Any]) -> None:\n#         self._learn_model.load_state_dict(state_dict['model'])\n#         self._optimizer_q.load_state_dict(state_dict['optimizer_q'])\n#         # if self._value_network:\n#         #    self._optimizer_value.load_state_dict(state_dict['optimizer_value'])\n#         self._optimizer_policy.load_state_dict(state_dict['optimizer_policy'])\n#         if self._auto_alpha:\n#             self._alpha_optim.load_state_dict(state_dict['optimizer_alpha'])\n# \n#     def _init_collect(self) -> None:\n#         r\"\"\"\n#         Overview:\n#             Collect mode init method. Called by ``self.__init__``.\n#             Init traj and unroll length, collect model.\n#             Use action noise for exploration.\n#         \"\"\"\n#         self._unroll_len = self._cfg.collect.unroll_len\n#         # self._collect_model = model_wrap(self._model, wrapper_name='multinomial_sample')  # TODO(pu)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/tests/speed_test/fake_env.py\n# --------------------------------------------------\n#         return obs\n# \n#     def close(self) -> None:\n#         pass\n# \n#     def seed(self, seed: Optional[int] = None) -> None:\n#         if seed is not None:\n#             self._seed = seed\n#         np.random.seed(self._seed)\n# \n#     def step(self, action: np.ndarray) -> BaseEnvTimestep:\n#         env_sleep(random_change(self._step_time))\n#         self._step_count += 1\n#         obs = np.random.randn(self._obs_dim).astype(np.float32)\n#         rew = np.random.randint(2)\n#         done = True if self._step_count == self._episode_step else False\n#         info = {}\n#         self._final_eval_reward += rew\n#         if done:\n#             info['final_eval_reward'] = self._final_eval_reward\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/zergling_parallel_collector.py\n# --------------------------------------------------\n#         actions = {env_id: output['action'] for env_id, output in policy_output.items()}\n#         return actions\n# \n#     # override\n#     def _env_step(self, actions: Dict[int, Any]) -> Dict[int, Any]:\n#         return self._env_manager.step(actions)\n# \n#     # override\n#     def _process_timestep(self, timestep: Dict[int, namedtuple]) -> None:\n#         send_data_time = []\n#         for env_id, t in timestep.items():\n#             if t.info.get('abnormal', False):\n#                 # if there is a abnormal timestep, reset all the related variable, also this env has been reset\n#                 self._traj_buffer[env_id].clear()\n#                 self._obs_pool.reset(env_id)\n#                 self._policy_output_pool.reset(env_id)\n#                 self._policy.reset([env_id])\n#                 continue\n#             self._total_step += 1\n#             if t.done:  # must be executed before send_metadata\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/zergling_parallel_collector.py\n# --------------------------------------------------\n#             del self._update_policy_thread\n# \n#     # override\n#     def close(self) -> None:\n#         if self._end_flag:\n#             return\n#         self._end_flag = True\n#         time.sleep(1)\n#         if hasattr(self, '_env_manager'):\n#             self._env_manager.close()\n#         self._join_thread()\n# \n#     # override\n#     def _policy_inference(self, obs: Dict[int, Any]) -> Dict[int, Any]:\n#         self._obs_pool.update(obs)\n#         if self._eval_flag:\n#             policy_output = self._policy.forward(obs)\n#         else:\n#             policy_output = self._policy.forward(obs, **self._cfg.collect_setting)\n#         self._policy_output_pool.update(policy_output)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/zergling_parallel_collector.py\n# --------------------------------------------------\n#         self._join_thread()\n# \n#     # override\n#     def _policy_inference(self, obs: Dict[int, Any]) -> Dict[int, Any]:\n#         self._obs_pool.update(obs)\n#         if self._eval_flag:\n#             policy_output = self._policy.forward(obs)\n#         else:\n#             policy_output = self._policy.forward(obs, **self._cfg.collect_setting)\n#         self._policy_output_pool.update(policy_output)\n#         actions = {env_id: output['action'] for env_id, output in policy_output.items()}\n#         return actions\n# \n#     # override\n#     def _env_step(self, actions: Dict[int, Any]) -> Dict[int, Any]:\n#         return self._env_manager.step(actions)\n# \n#     # override\n#     def _process_timestep(self, timestep: Dict[int, namedtuple]) -> None:\n#         send_data_time = []\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import Dict, Any, List\nimport copy\nimport time\nimport uuid\nfrom collections import namedtuple\nfrom threading import Thread\nfrom functools import partial\nimport numpy as np\nimport torch\nfrom easydict import EasyDict\n\nfrom ding.policy import create_policy, Policy\nfrom ding.envs import get_vec_env_setting, create_env_manager\nfrom ding.utils import get_data_compressor, pretty_print, PARALLEL_COLLECTOR_REGISTRY\nfrom ding.envs import BaseEnvTimestep, BaseEnvManager\nfrom .base_parallel_collector import BaseParallelCollector\nfrom .base_serial_collector import CachePool, TrajBuffer\n\nINF = float(\"inf\")\n\n\n@PARALLEL_COLLECTOR_REGISTRY.register('marine')\nclass MarineParallelCollector(BaseParallelCollector):\n    \"\"\"\n    Feature:\n      - one policy or two policies, many envs\n      - async envs(step + reset)\n      - batch network eval\n      - different episode length env\n      - periodic policy update\n      - metadata + stepdata\n    \"\"\"\n    config = dict(\n        print_freq=5,\n        compressor='lz4',\n        update_policy_second=3,\n        # The following keys is set by the commander\n        # env\n        # policy\n        # collect_setting\n        # eval_flag\n        # policy_update_path\n    )\n\n    # override\n    def __init__(self, cfg: dict) -> None:\n        super().__init__(cfg)\n        self._update_policy_thread = Thread(\n            target=self._update_policy_periodically, args=(), name='update_policy', daemon=True\n        )\n        self._start_time = time.time()\n        self._compressor = get_data_compressor(self._cfg.compressor)\n\n        # create env\n        self._env_cfg = self._cfg.env\n        env_manager = self._setup_env_manager(self._env_cfg)\n        self.env_manager = env_manager\n\n        # create policy\n        if self._eval_flag:\n            assert len(self._cfg.policy) == 1\n            policy = [create_policy(self._cfg.policy[0], enable_field=['eval']).eval_mode]\n            self.policy = policy\n            self._policy_is_active = [None]\n            self._policy_iter = [None]\n            self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n            self._traj_buffer = {env_id: [TrajBuffer(self._traj_len)] for env_id in range(self._env_num)}\n        else:\n            assert len(self._cfg.policy) == 2\n            policy = [create_policy(self._cfg.policy[i], enable_field=['collect']).collect_mode for i in range(2)]\n            self.policy = policy\n            self._policy_is_active = [None for _ in range(2)]\n            self._policy_iter = [None for _ in range(2)]\n            self._traj_buffer_length = self._traj_len if self._traj_len != INF else None\n            self._traj_buffer = {\n                env_id: [TrajBuffer(self._traj_buffer_length) for _ in range(len(policy))]\n                for env_id in range(self._env_num)\n            }\n        # self._first_update_policy = True\n\n        self._episode_result = [[] for k in range(self._env_num)]\n        self._obs_pool = CachePool('obs', self._env_num)\n        self._policy_output_pool = CachePool('policy_output', self._env_num)\n        self._total_step = 0\n        self._total_sample = 0\n        self._total_episode = 0\n\n    @property\n    def policy(self) -> List[Policy]:\n        return self._policy\n\n    # override\n    @policy.setter\n    def policy(self, _policy: List[Policy]) -> None:\n        self._policy = _policy\n        self._n_episode = _policy[0].get_attribute('cfg').collect.get('n_episode', None)\n        self._n_sample = _policy[0].get_attribute('cfg').collect.get('n_sample', None)\n        assert any(\n            [t is None for t in [self._n_sample, self._n_episode]]\n        ), \"n_episode/n_sample in policy cfg can't be not None at the same time\"\n        # TODO(nyz) the same definition of traj_len in serial and parallel\n        if self._n_episode is not None:\n            self._traj_len = INF\n        elif self._n_sample is not None:\n            self._traj_len = self._n_sample\n\n    @property\n    def env_manager(self, _env_manager) -> None:\n        self._env_manager = _env_manager\n\n    # override\n    @env_manager.setter\n    def env_manager(self, _env_manager: BaseEnvManager) -> None:\n        self._env_manager = _env_manager\n        self._env_manager.launch()\n        self._env_num = self._env_manager.env_num\n        self._predefined_episode_count = self._env_num * self._env_manager._episode_num\n\n    def _setup_env_manager(self, cfg: EasyDict) -> BaseEnvManager:\n        env_fn, collector_env_cfg, evaluator_env_cfg = get_vec_env_setting(cfg)\n        if self._eval_flag:\n            env_cfg = evaluator_env_cfg\n        else:\n            env_cfg = collector_env_cfg\n        env_manager = create_env_manager(cfg.manager, [partial(env_fn, cfg=c) for c in env_cfg])\n        return env_manager\n\n    def _start_thread(self) -> None:\n        # evaluator doesn't need to update policy periodically, only updating policy when starts\n        if not self._eval_flag:\n            self._update_policy_thread.start()\n\n    def _join_thread(self) -> None:\n        if not self._eval_flag:\n            self._update_policy_thread.join()\n            del self._update_policy_thread\n\n    # override\n    def close(self) -> None:\n        if self._end_flag:\n            return\n        self._end_flag = True\n        time.sleep(1)\n        if hasattr(self, '_env_manager'):\n            self._env_manager.close()\n        self._join_thread()\n\n    # override\n    def _policy_inference(self, obs: Dict[int, Any]) -> Dict[int, Any]:\n        env_ids = list(obs.keys())\n        if len(self._policy) > 1:", "choices": [{"text": "policy_output = self.policy[env_ids[env_id] % 2].forward(obs[env_id])"}], "metadata": {"task_id": "opendilab_ACE/175", "ground_truth": "            assert not self._eval_flag", "fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "marine_parallel_collector.py"], "context_start_lineno": 0, "line_no": 151, "query_window": {"context": "\n    def _join_thread(self) -> None:\n        if not self._eval_flag:\n            self._update_policy_thread.join()\n            del self._update_policy_thread\n\n    # override\n    def close(self) -> None:\n        if self._end_flag:\n            return\n        self._end_flag = True\n        time.sleep(1)\n        if hasattr(self, '_env_manager'):\n            self._env_manager.close()\n        self._join_thread()\n\n    # override\n    def _policy_inference(self, obs: Dict[int, Any]) -> Dict[int, Any]:\n        env_ids = list(obs.keys())\n        if len(self._policy) > 1:", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "marine_parallel_collector.py"], "line_no": 151, "task_id": "opendilab_ACE/175", "start_line_no": 131, "end_line_no": 151, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "            del self._update_policy_thread\n\n    # override\n    def close(self) -> None:\n        if self._end_flag:\n            return\n        self._end_flag = True\n        time.sleep(1)\n        if hasattr(self, '_env_manager'):\n            self._env_manager.close()\n        self._join_thread()\n\n    # override\n    def _policy_inference(self, obs: Dict[int, Any]) -> Dict[int, Any]:\n        self._obs_pool.update(obs)\n        if self._eval_flag:\n            policy_output = self._policy.forward(obs)\n        else:\n            policy_output = self._policy.forward(obs, **self._cfg.collect_setting)\n        self._policy_output_pool.update(policy_output)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "zergling_parallel_collector.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.7567567567567568}, {"context": "        return env_manager\n\n    def _start_thread(self) -> None:\n        # evaluator doesn't need to update policy periodically, only updating policy when starts\n        if not self._eval_flag:\n            self._update_policy_thread.start()\n\n    def _join_thread(self) -> None:\n        if not self._eval_flag:\n            self._update_policy_thread.join()\n            del self._update_policy_thread\n\n    # override\n    def close(self) -> None:\n        if self._end_flag:\n            return\n        self._end_flag = True\n        time.sleep(1)\n        if hasattr(self, '_env_manager'):\n            self._env_manager.close()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "zergling_parallel_collector.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5875}, {"context": "        self._join_thread()\n\n    # override\n    def _policy_inference(self, obs: Dict[int, Any]) -> Dict[int, Any]:\n        self._obs_pool.update(obs)\n        if self._eval_flag:\n            policy_output = self._policy.forward(obs)\n        else:\n            policy_output = self._policy.forward(obs, **self._cfg.collect_setting)\n        self._policy_output_pool.update(policy_output)\n        actions = {env_id: output['action'] for env_id, output in policy_output.items()}\n        return actions\n\n    # override\n    def _env_step(self, actions: Dict[int, Any]) -> Dict[int, Any]:\n        return self._env_manager.step(actions)\n\n    # override\n    def _process_timestep(self, timestep: Dict[int, namedtuple]) -> None:\n        send_data_time = []", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "zergling_parallel_collector.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4444444444444444}, {"context": "        self.reset()\n\n    def reset(self) -> np.ndarray:\n        if hasattr(self, '_seed'):\n            self.seed()\n        self._episode_step = int(random_change(self._episode_step_base))\n        env_sleep(random_change(self._reset_time))\n        self._step_count = 0\n        self._final_eval_reward = 0\n        obs = np.random.randn(self._obs_dim)\n        return obs\n\n    def close(self) -> None:\n        pass\n\n    def seed(self, seed: Optional[int] = None) -> None:\n        if seed is not None:\n            self._seed = seed\n        np.random.seed(self._seed)\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "tests", "speed_test", "fake_env.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3804347826086957}, {"context": "    def _state_dict_learn(self) -> Dict[str, Any]:\n        ret = {\n            'model': self._learn_model.state_dict(),\n            'optimizer_q': self._optimizer_q.state_dict(),\n            'optimizer_policy': self._optimizer_policy.state_dict(),\n        }\n        # if self._value_network:\n        #    ret.update({'optimizer_value': self._optimizer_value.state_dict()})\n        if self._auto_alpha:\n            ret.update({'optimizer_alpha': self._alpha_optim.state_dict()})\n        return ret\n\n    def _load_state_dict_learn(self, state_dict: Dict[str, Any]) -> None:\n        self._learn_model.load_state_dict(state_dict['model'])\n        self._optimizer_q.load_state_dict(state_dict['optimizer_q'])\n        # if self._value_network:\n        #    self._optimizer_value.load_state_dict(state_dict['optimizer_value'])\n        self._optimizer_policy.load_state_dict(state_dict['optimizer_policy'])\n        if self._auto_alpha:\n            self._alpha_optim.load_state_dict(state_dict['optimizer_alpha'])", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "masac.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3793103448275862}, {"context": "            obs = to_tensor(obs, dtype=torch.float32)\n            action = self._policy_inference(obs)\n            action = to_ndarray(action)\n            timestep = self._env_step(action)\n            timestep = to_tensor(timestep, dtype=torch.float32)\n            self._process_timestep(timestep)\n            self._iter_after_hook()\n            if self._env_manager.done:\n                break\n\n    def close(self) -> None:\n        if self._end_flag:\n            return\n        self._end_flag = True\n        self._join_thread()\n\n    def _iter_after_hook(self):\n        # log_buffer -> tick_monitor -> monitor.step\n        for k, v in self._log_buffer.items():\n            setattr(self._monitor, k, v)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "base_parallel_collector.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.36538461538461536}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/worker/server.py\n# --------------------------------------------------\n#                 for key in client_eval_results.keys():\n#                     res = client_eval_results[key]\n#                     if isinstance(res, dict):\n#                         for k, v in res.items():\n#                             cur_key = key + '_' + k\n#                             if key not in metrics_all_clients:\n#                                 metrics_all_clients[cur_key] = list()\n#                             metrics_all_clients[cur_key].append(float(v))\n#                     else:\n#                         if key not in metrics_all_clients:\n#                             metrics_all_clients[key] = list()\n#                         metrics_all_clients[key].append(float(res))\n#         formatted_logs = self._monitor.format_eval_res(\n#             metrics_all_clients,\n#             rnd=self.state + 1,\n#             role='Server #',\n#             forms=self._cfg.eval.report)\n#         logger.info(formatted_logs)\n#         self._monitor.save_formatted_results(formatted_logs)\n#         return formatted_logs\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/worker/vertical_server.py\n# --------------------------------------------------\n#         if self.state % self._cfg.eval.freq == 0 and self.state != \\\n#                 self.total_round_num:\n#             metrics = self.evaluate()\n#             self._monitor.update_best_result(self.best_results,\n#                                              metrics,\n#                                              results_type='server_global_eval')\n#             formatted_logs = self._monitor.format_eval_res(\n#                 metrics,\n#                 rnd=self.state,\n#                 role='Server #',\n#                 forms=self._cfg.eval.report)\n#             logger.info(formatted_logs)\n# \n#         if self.state < self.total_round_num:\n#             # Move to next round of training\n#             logger.info(f'----------- Starting a new training round (Round '\n#                         f'#{self.state}) -------------')\n#             self.broadcast_model_para()\n#         else:\n#             metrics = self.evaluate()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/worker/vertical_server.py\n# --------------------------------------------------\n#                 forms=self._cfg.eval.report)\n#             logger.info(formatted_logs)\n# \n#         if self.state < self.total_round_num:\n#             # Move to next round of training\n#             logger.info(f'----------- Starting a new training round (Round '\n#                         f'#{self.state}) -------------')\n#             self.broadcast_model_para()\n#         else:\n#             metrics = self.evaluate()\n#             self._monitor.update_best_result(self.best_results,\n#                                              metrics,\n#                                              results_type='server_global_eval')\n#             formatted_logs = self._monitor.format_eval_res(\n#                 metrics,\n#                 rnd=self.state,\n#                 role='Server #',\n#                 forms=self._cfg.eval.report)\n#             logger.info(formatted_logs)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/worker/vertical_server.py\n# --------------------------------------------------\n#         else:\n#             metrics = self.evaluate()\n#             self._monitor.update_best_result(self.best_results,\n#                                              metrics,\n#                                              results_type='server_global_eval')\n#             formatted_logs = self._monitor.format_eval_res(\n#                 metrics,\n#                 rnd=self.state,\n#                 role='Server #',\n#                 forms=self._cfg.eval.report)\n#             logger.info(formatted_logs)\n# \n#     def evaluate(self):\n#         test_x = self.data['test']['x']\n#         test_y = self.data['test']['y']\n#         loss = np.mean(\n#             np.log(1 + np.exp(-test_y * np.matmul(test_x, self.theta))))\n#         acc = np.mean((test_y * np.matmul(test_x, self.theta)) > 0)\n# \n#         return {'test_loss': loss, 'test_acc': acc, 'test_total': len(test_y)}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/server.py\n# --------------------------------------------------\n#                     self.history_results, formatted_eval_res)\n#                 self._monitor.save_formatted_results(formatted_eval_res)\n#                 logger.info(formatted_eval_res)\n#             self.check_and_save()\n#         else:\n#             # Preform evaluation in clients\n#             self.broadcast_model_para(msg_type='evaluate',\n#                                       filter_unseen_clients=False)\n# \n#     def callback_funcs_model_para(self, message: Message):\n#         \"\"\"\n#         The handling function for receiving model parameters, which triggers \\\n#         ``check_and_move_on`` (perform aggregation when enough feedback has \\\n#         been received). This handling function is widely used in various FL \\\n#         courses.\n# \n#         Arguments:\n#             message: The received message.\n#         \"\"\"\n#         if self.is_finish:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/worker/vertical_server.py\n# --------------------------------------------------\n#         else:\n#             metrics = self.evaluate()\n#             self._monitor.update_best_result(self.best_results,\n#                                              metrics,\n#                                              results_type='server_global_eval')\n#             formatted_logs = self._monitor.format_eval_res(\n#                 metrics,\n#                 rnd=self.state,\n#                 role='Server #',\n#                 forms=self._cfg.eval.report)\n#             logger.info(formatted_logs)\n# \n#     def evaluate(self):\n#         test_x = self.data['test']['x']\n#         test_y = self.data['test']['y']\n#         loss = np.mean(\n#             np.log(1 + np.exp(-test_y * np.matmul(test_x, self.theta))))\n#         acc = np.mean((test_y * np.matmul(test_x, self.theta)) > 0)\n# \n#         return {'test_loss': loss, 'test_acc': acc, 'test_total': len(test_y)}\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nmodel[tree_num][0].indicator = np.ones(self.test_x.shape[0])\n        self._test_for_node(tree_num, node_num=0)\n\n    def _fetch_test_data(self):\n        test_x = self.data['test']['x']\n        test_y = self.data['test']['y'] if 'y' in self.data['test'] else None\n\n        return test_x, test_y\n\n    def _feedback_eval_metrics(self):\n        test_loss = self.criterion.get_loss(self.test_y, self.test_result)\n        metrics = self.criterion.get_metric(self.test_y, self.test_result)\n        modified_metrics = dict()\n        for key in metrics.keys():\n            if 'test' not in key:\n                modified_metrics['test_' + key] = metrics[key]\n            else:\n                modified_metrics[key] = metrics[key]\n        modified_metrics.update({\n            'test_loss': test_loss,\n            'test_total': len(self.test_y)\n        })\n\n        self.comm_manager.send(\n            Message(msg_type='eval_metric',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[self.server_id],\n                    content=modified_metrics))\n        self.comm_manager.send(\n            Message(msg_type='feature_importance',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[self.server_id],\n                    content=self.feature_importance))\n        self.comm_manager.send(\n            Message(msg_type='ask_for_feature_importance',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[\n                        each\n                        for each in list(self.comm_manager.neighbors.keys())\n                        if each != self.server_id\n                    ],\n                    content='None'))\n\n    def _test_for_node(self, tree_num, node_num):\n        # All nodes have been traversed\n        if node_num >= 2**self.model.max_depth - 1:\n            if (\n                    tree_num + 1\n            ) % self._cfg.eval.freq == 0 or \\\n                    tree_num + 1 == self._cfg.model.num_of_trees:\n                self._feedback_eval_metrics()\n            self.eval_finish_flag = True\n            self._check_eval_finish(tree_num)\n        # The client owns the weight\n        elif self.model[tree_num][node_num].weight:\n            self.test_result += self.model[tree_num][\n                node_num].indicator * self.model[tree_num][\n                    node_num].weight * self._cfg.train.optimizer.eta\n            self._test_for_node(tree_num, node_num + 1)\n        # Other client owns the weight, need to communicate\n        elif self.model[tree_num][node_num].member:\n            self.comm_manager.send(\n                Message(msg_type='split_request',\n                        sender=self.ID,\n                        state=self.state,\n                        receiver=[self.model[tree_num][node_num].member],\n                        content=(tree_num, node_num)))\n        else:\n            self._test_for_node(tree_num, node_num + 1)\n\n    def callback_func_for_split_request(self, message: Message):\n        if self.test_x is None:\n            self.test_x, self.test_y = self._fetch_test_data()\n            self.test_result = np.zeros(self.test_x.shape[0])\n        tree_num, node_num = message.content\n        sender = message.sender\n        feature_idx = self.model[tree_num][node_num].feature_idx\n        feature_value = self.model[tree_num][node_num].feature_value\n        left_child, right_child = self.model[tree_num].split_childern(\n            self.test_x[:, feature_idx], feature_value)\n        self.comm_manager.send(\n            Message(msg_type='split_result',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[sender],\n                    content=(tree_num, node_num, left_child, right_child)))\n\n    def callback_func_for_split_result(self, message: Message):\n        tree_num, node_num, left_child, right_child = message.content\n        self.model[tree_num][2 * node_num + 1].indicator = self.model[\n            tree_num][node_num].indicator * left_child\n        self.model[tree_num][2 * node_num + 2].indicator = self.model[\n            tree_num][node_num].indicator * right_child\n        self._test_for_node(tree_num, node_num + 1)\n\n    def callback_func_for_feature_importance(self, message: Message):\n        state = message.state\n        self.comm_manager.send(\n            Message(msg_type='feature_importance',\n                    sender=self.ID,\n                    state=state,\n                    receiver=[self.server_id],\n                    content=self.feature_importance))\n\n    # Bind method to instance\n    client.eval = types.MethodType(eval, client)\n    client._fetch_test_data = types.MethodType(_fetch_test_data, client)\n    client._test_for_node = types.MethodType(_test_for_node, client)\n    client._feedback_eval_metrics = types.MethodType(_feedback_eval_metrics,\n                                                     client)\n    client.callback_func_for_split_request = types.MethodType(\n        callback_func_for_split_request, client)\n    client.callback_func_for_split_result = types.MethodType(\n        callback_func_for_split_result, client)\n    client.callback_func_for_feature_importance = types.MethodType(\n        callback_func_for_feature_importance, client)\n\n    # Register handler functions\n    client.register_handlers('split_request',\n                             client.callback_func_for_split_request)\n    client.register_handlers('split_result',\n                             client.callback_func_for_split_result)\n    client.register_handlers('ask_for_feature_importance',\n                             client.callback_func_for_feature_importance)\n\n    return client\n\n\ndef wrap_server_for_evaluation(server):\n    def _check_and_save_result(self):\n\n        state = max(self.msg_buffer['eval'].keys())\n        buffer = self.msg_buffer['eval'][state]\n        if len(buffer['feature_importance']\n               ) == self.client_num and buffer['metrics'] is not None:\n            self.state = state\n            self.feature_importance = dict(\n                sorted(buffer['feature_importance'].items(),\n                       key=lambda x: x[0]))\n            self.metrics = buffer['metrics']\n            self._monitor.update_best_result(self.best_results,\n                                             self.metrics,\n                                             results_type='server_global_eval')\n            self._monitor.add_items_to_best_result(\n                self.best_results,\n                self.feature_importance,\n                results_type='feature_importance')\n            formatted_logs = self._monitor.format_eval_res(\n                self.metrics,\n                rnd=self.state,\n                role='Server #',\n                forms=self._cfg.eval.report)\n            formatted_logs['feature_importance'] = self.feature_importance\n            logger.info(formatted_logs)\n\n            if self.state + 1 == self._cfg.model.num_of_trees:\n                self.terminate()\n\n    def callback_func_for_feature_importance(self, message: Message):\n        # Save the feature importance\n        feature_importance = message.content", "choices": [{"text": "\"\"\"Based on the above, complete the following code:\"\"\""}], "metadata": {"task_id": "alibaba_FederatedScope/27", "ground_truth": "        sender = message.sender", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "evaluation_wrapper.py"], "context_start_lineno": 16, "line_no": 180, "query_window": {"context": "                                             self.metrics,\n                                             results_type='server_global_eval')\n            self._monitor.add_items_to_best_result(\n                self.best_results,\n                self.feature_importance,\n                results_type='feature_importance')\n            formatted_logs = self._monitor.format_eval_res(\n                self.metrics,\n                rnd=self.state,\n                role='Server #',\n                forms=self._cfg.eval.report)\n            formatted_logs['feature_importance'] = self.feature_importance\n            logger.info(formatted_logs)\n\n            if self.state + 1 == self._cfg.model.num_of_trees:\n                self.terminate()\n\n    def callback_func_for_feature_importance(self, message: Message):\n        # Save the feature importance\n        feature_importance = message.content", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "evaluation_wrapper.py"], "line_no": 180, "task_id": "alibaba_FederatedScope/27", "start_line_no": 160, "end_line_no": 180, "window_size": 20, "context_start_lineno": 16, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "                forms=self._cfg.eval.report)\n            logger.info(formatted_logs)\n\n        if self.state < self.total_round_num:\n            # Move to next round of training\n            logger.info(f'----------- Starting a new training round (Round '\n                        f'#{self.state}) -------------')\n            self.broadcast_model_para()\n        else:\n            metrics = self.evaluate()\n            self._monitor.update_best_result(self.best_results,\n                                             metrics,\n                                             results_type='server_global_eval')\n            formatted_logs = self._monitor.format_eval_res(\n                metrics,\n                rnd=self.state,\n                role='Server #',\n                forms=self._cfg.eval.report)\n            logger.info(formatted_logs)\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "worker", "vertical_server.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4482758620689655}, {"context": "                    metrics,\n                    rnd=self.state,\n                    role='Server #',\n                    forms=self._cfg.eval.report,\n                    return_raw=self._cfg.federate.make_global_eval)\n                self._monitor.update_best_result(\n                    self.best_results,\n                    formatted_eval_res['Results_raw'],\n                    results_type=\"server_global_eval\")\n                self.history_results = merge_dict_of_results(\n                    self.history_results, formatted_eval_res)\n                self._monitor.save_formatted_results(formatted_eval_res)\n                logger.info(formatted_eval_res)\n            self.check_and_save()\n        else:\n            # Preform evaluation in clients\n            self.broadcast_model_para(msg_type='evaluate',\n                                      filter_unseen_clients=False)\n\n    def callback_funcs_model_para(self, message: Message):", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "server.py"], "line_no": 880, "start_line_no": 870, "end_line_no": 890, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4426229508196721}, {"context": "            self._monitor.update_best_result(self.best_results,\n                                             metrics,\n                                             results_type='server_global_eval')\n            formatted_logs = self._monitor.format_eval_res(\n                metrics,\n                rnd=self.state,\n                role='Server #',\n                forms=self._cfg.eval.report)\n            logger.info(formatted_logs)\n\n    def evaluate(self):\n        test_x = self.data['test']['x']\n        test_y = self.data['test']['y']\n        loss = np.mean(\n            np.log(1 + np.exp(-test_y * np.matmul(test_x, self.theta))))\n        acc = np.mean((test_y * np.matmul(test_x, self.theta)) > 0)\n\n        return {'test_loss': loss, 'test_acc': acc, 'test_total': len(test_y)}", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "worker", "vertical_server.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 128, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.44166666666666665}, {"context": "        if self.state % self._cfg.eval.freq == 0 and self.state != \\\n                self.total_round_num:\n            metrics = self.evaluate()\n            self._monitor.update_best_result(self.best_results,\n                                             metrics,\n                                             results_type='server_global_eval')\n            formatted_logs = self._monitor.format_eval_res(\n                metrics,\n                rnd=self.state,\n                role='Server #',\n                forms=self._cfg.eval.report)\n            logger.info(formatted_logs)\n\n        if self.state < self.total_round_num:\n            # Move to next round of training\n            logger.info(f'----------- Starting a new training round (Round '\n                        f'#{self.state}) -------------')\n            self.broadcast_model_para()\n        else:\n            metrics = self.evaluate()", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "worker", "vertical_server.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.43089430894308944}, {"context": "    def callback_funcs_for_encryped_gradient(self, message: Message):\n        sample_num, en_v = message.content\n\n        v = np.reshape(\n            [self.private_key.decrypt(x) for x in np.reshape(en_v, -1)],\n            [sample_num, -1])\n        avg_gradients = np.mean(v, axis=0)\n        self.theta = self.theta - self.lr * avg_gradients\n\n        self.state += 1\n        if self.state % self._cfg.eval.freq == 0 and self.state != \\\n                self.total_round_num:\n            metrics = self.evaluate()\n            self._monitor.update_best_result(self.best_results,\n                                             metrics,\n                                             results_type='server_global_eval')\n            formatted_logs = self._monitor.format_eval_res(\n                metrics,\n                rnd=self.state,\n                role='Server #',", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "worker", "vertical_server.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.41044776119402987}, {"context": "                for key in client_eval_results.keys():\n                    res = client_eval_results[key]\n                    if isinstance(res, dict):\n                        for k, v in res.items():\n                            cur_key = key + '_' + k\n                            if key not in metrics_all_clients:\n                                metrics_all_clients[cur_key] = list()\n                            metrics_all_clients[cur_key].append(float(v))\n                    else:\n                        if key not in metrics_all_clients:\n                            metrics_all_clients[key] = list()\n                        metrics_all_clients[key].append(float(res))\n        formatted_logs = self._monitor.format_eval_res(\n            metrics_all_clients,\n            rnd=self.state + 1,\n            role='Server #',\n            forms=self._cfg.eval.report)\n        logger.info(formatted_logs)\n        self._monitor.save_formatted_results(formatted_logs)\n        return formatted_logs", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "worker", "server.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3813559322033898}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config_test.py\n# --------------------------------------------------\n#                 name='objective', goal=vz.ObjectiveMetricGoal.MAXIMIZE\n#             )\n#         ]\n#     )\n#     root = py_study_config.search_space.root\n#     root.add_float_param('learning_rate', 0.01, 3.0)\n#     root.add_int_param('units', 10, 1000, scale_type=vz.ScaleType.LOG)\n#     root.add_discrete_param('batch_size', [8, 16, 32])\n#     root.add_discrete_param(\n#         'floating_point_param', [8., 16., 32.], auto_cast=False)\n#     root.add_categorical_param('activation', ['tanh', 'relu'])\n#     root.add_bool_param('synchronous')\n# \n#     pytrial = vz.Trial(id=1)\n#     pytrial.parameters = {\n#         'activation': vz.ParameterValue(value='relu'),\n#         'synchronous': vz.ParameterValue(value=True),\n#         'batch_size': vz.ParameterValue(value=32),\n#         'floating_point_param': vz.ParameterValue(value=32.0),\n#         'learning_rate': vz.ParameterValue(value=0.5),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config_test.py\n# --------------------------------------------------\n#     root.add_categorical_param('activation', ['tanh', 'relu'])\n#     root.add_bool_param('synchronous')\n# \n#     pytrial = vz.Trial(id=1)\n#     pytrial.parameters = {\n#         'activation': vz.ParameterValue(value='relu'),\n#         'synchronous': vz.ParameterValue(value=True),\n#         'batch_size': vz.ParameterValue(value=32),\n#         'floating_point_param': vz.ParameterValue(value=32.0),\n#         'learning_rate': vz.ParameterValue(value=0.5),\n#         'units': vz.ParameterValue(value=50),\n#     }\n#     parameters = py_study_config._pytrial_parameters(pytrial)\n#     expected = {\n#         'learning_rate': 0.5,\n#         'units': 50,\n#         'activation': 'relu',\n#         'batch_size': 32,\n#         'floating_point_param': 32.,\n#         'synchronous': True\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config_test.py\n# --------------------------------------------------\n#     trial_proto.parameters.add(\n#         parameter_id='units', value=struct_pb2.Value(number_value=50))\n# \n#     parameters = py_study_config.trial_parameters(trial_proto)\n#     expected = {\n#         'learning_rate': 0.5,\n#         'units': 50,\n#         'activation': 'relu',\n#         'batch_size': 32,\n#         'floating_point_param': 32.,\n#         'synchronous': True\n#     }\n#     self.assertEqual(expected, parameters)\n#     self.assertIsInstance(parameters['batch_size'], int)\n#     self.assertIsInstance(parameters['floating_point_param'], float)\n# \n#   def testPyTrialToDict(self):\n#     py_study_config = vz.StudyConfig(\n#         metric_information=[\n#             vz.MetricInformation(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config_test.py\n# --------------------------------------------------\n#         'synchronous': True\n#     }\n#     self.assertEqual(expected, parameters)\n#     self.assertIsInstance(parameters['batch_size'], int)\n#     self.assertIsInstance(parameters['floating_point_param'], float)\n# \n#   def testPyTrialToDict(self):\n#     py_study_config = vz.StudyConfig(\n#         metric_information=[\n#             vz.MetricInformation(\n#                 name='objective', goal=vz.ObjectiveMetricGoal.MAXIMIZE\n#             )\n#         ]\n#     )\n#     root = py_study_config.search_space.root\n#     root.add_float_param('learning_rate', 0.01, 3.0)\n#     root.add_int_param('units', 10, 1000, scale_type=vz.ScaleType.LOG)\n#     root.add_discrete_param('batch_size', [8, 16, 32])\n#     root.add_discrete_param(\n#         'floating_point_param', [8., 16., 32.], auto_cast=False)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config_test.py\n# --------------------------------------------------\n#     }\n#     self.assertEqual(expected, parameters)\n#     self.assertIsInstance(parameters['batch_size'], int)\n#     self.assertIsInstance(parameters['floating_point_param'], float)\n# \n#   def testTrialToDictWithoutExternalType(self):\n#     \"\"\"Test conversion when external types are not specified.\"\"\"\n#     proto = study_pb2.StudySpec()\n#     proto.parameters.add(\n#         parameter_id='learning_rate',\n#         double_value_spec=study_pb2.StudySpec.ParameterSpec.DoubleValueSpec(\n#             min_value=1e-4, max_value=0.1),\n#         scale_type=study_pb2.StudySpec.ParameterSpec.ScaleType.UNIT_LOG_SCALE)\n#     proto.parameters.add(\n#         parameter_id='batch_size',\n#         discrete_value_spec=study_pb2.StudySpec.ParameterSpec.DiscreteValueSpec(\n#             values=[1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0]))\n#     proto.parameters.add(\n#         parameter_id='training_steps',\n#         discrete_value_spec=study_pb2.StudySpec.ParameterSpec.DiscreteValueSpec(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config_test.py\n# --------------------------------------------------\n#         'units': vz.ParameterValue(value=50),\n#     }\n#     parameters = py_study_config._pytrial_parameters(pytrial)\n#     expected = {\n#         'learning_rate': 0.5,\n#         'units': 50,\n#         'activation': 'relu',\n#         'batch_size': 32,\n#         'floating_point_param': 32.,\n#         'synchronous': True\n#     }\n#     self.assertEqual(expected, parameters)\n#     self.assertIsInstance(parameters['batch_size'], int)\n#     self.assertIsInstance(parameters['floating_point_param'], float)\n# \n#   def testTrialToDictWithoutExternalType(self):\n#     \"\"\"Test conversion when external types are not specified.\"\"\"\n#     proto = study_pb2.StudySpec()\n#     proto.parameters.add(\n#         parameter_id='learning_rate',\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nSpec.DiscreteValueSpec(\n            values=[1000.0, 10000.0]))\n    proto.observation_noise = study_pb2.StudySpec.ObservationNoise.HIGH\n    proto.metrics.add(\n        metric_id='loss', goal=study_pb2.StudySpec.MetricSpec.MINIMIZE)\n\n    trial_proto = study_pb2.Trial()\n    trial_proto.id = str(1)\n    trial_proto.parameters.add(\n        parameter_id='batch_size', value=struct_pb2.Value(number_value=128.0))\n    trial_proto.parameters.add(\n        parameter_id='learning_rate',\n        value=struct_pb2.Value(number_value=1.2137854406366652E-4))\n    trial_proto.parameters.add(\n        parameter_id='training_steps',\n        value=struct_pb2.Value(number_value=10000.0))\n\n    py_study_config = vz.StudyConfig.from_proto(proto)\n    self.assertEqual(\n        py_study_config.observation_noise, vz.ObservationNoise.HIGH\n    )\n    parameters = py_study_config.trial_parameters(trial_proto)\n    self.assertEqual(\n        py_study_config.observation_noise, vz.ObservationNoise.HIGH\n    )\n    expected = {\n        'batch_size': 128,\n        'learning_rate': 1.2137854406366652E-4,\n        'training_steps': 10000.0\n    }\n    self.assertEqual(expected, parameters)\n    self.assertIsInstance(parameters['learning_rate'], float)\n    self.assertIsInstance(parameters['batch_size'], float)\n    self.assertIsInstance(parameters['training_steps'], float)\n\n  @absltest.skip('???')\n  def testTrialToDictMultidimensional(self):\n    py_study_config = vz.StudyConfig(\n        metric_information=[\n            vz.MetricInformation(\n                name='objective', goal=vz.ObjectiveMetricGoal.MAXIMIZE\n            )\n        ]\n    )\n    root = py_study_config.search_space.root\n    for index in (0, 1):\n      root.add_float_param('learning_rate', 0.01, 3.0, index=index)\n      root.add_int_param(\n          'units', 10, 1000, scale_type=vz.ScaleType.LOG, index=index\n      )\n      root.add_categorical_param('activation', ['tanh', 'relu'], index=index)\n      root.add_bool_param('synchronous', index=index)\n      root.add_discrete_param('batch_size', [8, 16, 32], index=index)\n    root.add_discrete_param(\n        'floating_point_param', [8., 16., 32.], auto_cast=False)\n\n    trial_proto = study_pb2.Trial()\n    trial_proto.id = str(2)\n    trial_proto.parameters.add(\n        parameter_id='learning_rate[0]',\n        value=struct_pb2.Value(number_value=0.5))\n    trial_proto.parameters.add(\n        parameter_id='learning_rate[1]',\n        value=struct_pb2.Value(number_value=0.1))\n    trial_proto.parameters.add(\n        parameter_id='units[0]', value=struct_pb2.Value(number_value=50))\n    trial_proto.parameters.add(\n        parameter_id='units[1]', value=struct_pb2.Value(number_value=200))\n    trial_proto.parameters.add(\n        parameter_id='activation[0]',\n        value=struct_pb2.Value(string_value='relu'))\n    trial_proto.parameters.add(\n        parameter_id='activation[1]',\n        value=struct_pb2.Value(string_value='relu'))\n    trial_proto.parameters.add(\n        parameter_id='synchronus[0]',\n        value=struct_pb2.Value(string_value='true'))\n    trial_proto.parameters.add(\n        parameter_id='synchronus[1]',\n        value=struct_pb2.Value(string_value='false'))\n    trial_proto.parameters.add(\n        parameter_id='batch_size[0]', value=struct_pb2.Value(number_value=32.0))\n    trial_proto.parameters.add(\n        parameter_id='batch_size[1]', value=struct_pb2.Value(number_value=8.0))\n    trial_proto.parameters.add(\n        parameter_id='floating_point_param',\n        value=struct_pb2.Value(number_value=16.0))\n    parameters = py_study_config.trial_parameters(trial_proto)\n    expected = {\n        'learning_rate': [0.5, 0.1],\n        'units': [50, 200],\n        'activation': ['relu', 'relu'],\n        'batch_size': [32, 8],\n        'synchronous': [True, False],\n        'floating_point_param': 16.,\n    }\n    self.assertEqual(expected, parameters)\n\n  def testPyTrialToDictMultidimensional(self):\n    py_study_config = vz.StudyConfig(\n        metric_information=[\n            vz.MetricInformation(\n                name='objective', goal=vz.ObjectiveMetricGoal.MAXIMIZE\n            )\n        ]\n    )\n    root = py_study_config.search_space.root\n    for index in (0, 1):\n      root.add_float_param('learning_rate', 0.01, 3.0, index=index)\n      root.add_int_param(\n          'units', 10, 1000, scale_type=vz.ScaleType.LOG, index=index\n      )\n      root.add_categorical_param('activation', ['tanh', 'relu'], index=index)\n      root.add_bool_param('synchronous', index=index)\n      root.add_discrete_param('batch_size', [8, 16, 32], index=index)\n    root.add_discrete_param(\n        'floating_point_param', [8., 16., 32.], auto_cast=False)\n\n    pytrial = vz.Trial(id=2)\n    pytrial.parameters = {\n        'learning_rate[0]': vz.ParameterValue(value=0.5),\n        'learning_rate[1]': vz.ParameterValue(value=0.1),\n        'units[0]': vz.ParameterValue(value=50),\n        'units[1]': vz.ParameterValue(value=200),\n        'activation[0]': vz.ParameterValue(value='relu'),\n        'activation[1]': vz.ParameterValue(value='relu'),\n        'synchronous[0]': vz.ParameterValue(value=True),\n        'synchronous[1]': vz.ParameterValue(value=False),\n        'batch_size[0]': vz.ParameterValue(value=32.0),\n        'batch_size[1]': vz.ParameterValue(value=8.0),\n        'floating_point_param': vz.ParameterValue(value=16.0),\n    }\n    parameters = py_study_config._pytrial_parameters(pytrial)\n    expected = {\n        'learning_rate': [0.5, 0.1],\n        'units': [50, 200],\n        'activation': ['relu', 'relu'],\n        'batch_size': [32, 8],\n        'synchronous': [True, False],\n        'floating_point_param': 16.,\n    }\n    self.assertEqual(expected, parameters)\n\n  def testGinConfigMultiDimensional(self):", "choices": [{"text": "py_study_config = vz.StudyConfig("}], "metadata": {"task_id": "google_vizier/117", "ground_truth": "    py_study_config = vz.StudyConfig(", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "context_start_lineno": 399, "line_no": 543, "query_window": {"context": "        'activation[0]': vz.ParameterValue(value='relu'),\n        'activation[1]': vz.ParameterValue(value='relu'),\n        'synchronous[0]': vz.ParameterValue(value=True),\n        'synchronous[1]': vz.ParameterValue(value=False),\n        'batch_size[0]': vz.ParameterValue(value=32.0),\n        'batch_size[1]': vz.ParameterValue(value=8.0),\n        'floating_point_param': vz.ParameterValue(value=16.0),\n    }\n    parameters = py_study_config._pytrial_parameters(pytrial)\n    expected = {\n        'learning_rate': [0.5, 0.1],\n        'units': [50, 200],\n        'activation': ['relu', 'relu'],\n        'batch_size': [32, 8],\n        'synchronous': [True, False],\n        'floating_point_param': 16.,\n    }\n    self.assertEqual(expected, parameters)\n\n  def testGinConfigMultiDimensional(self):", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "line_no": 543, "task_id": "google_vizier/117", "start_line_no": 523, "end_line_no": 543, "window_size": 20, "context_start_lineno": 399, "repo": "google_vizier"}}, "top_k_context": [{"context": "    root.add_categorical_param('activation', ['tanh', 'relu'])\n    root.add_bool_param('synchronous')\n\n    pytrial = vz.Trial(id=1)\n    pytrial.parameters = {\n        'activation': vz.ParameterValue(value='relu'),\n        'synchronous': vz.ParameterValue(value=True),\n        'batch_size': vz.ParameterValue(value=32),\n        'floating_point_param': vz.ParameterValue(value=32.0),\n        'learning_rate': vz.ParameterValue(value=0.5),\n        'units': vz.ParameterValue(value=50),\n    }\n    parameters = py_study_config._pytrial_parameters(pytrial)\n    expected = {\n        'learning_rate': 0.5,\n        'units': 50,\n        'activation': 'relu',\n        'batch_size': 32,\n        'floating_point_param': 32.,\n        'synchronous': True", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.5686274509803921}, {"context": "        'units': vz.ParameterValue(value=50),\n    }\n    parameters = py_study_config._pytrial_parameters(pytrial)\n    expected = {\n        'learning_rate': 0.5,\n        'units': 50,\n        'activation': 'relu',\n        'batch_size': 32,\n        'floating_point_param': 32.,\n        'synchronous': True\n    }\n    self.assertEqual(expected, parameters)\n    self.assertIsInstance(parameters['batch_size'], int)\n    self.assertIsInstance(parameters['floating_point_param'], float)\n\n  def testTrialToDictWithoutExternalType(self):\n    \"\"\"Test conversion when external types are not specified.\"\"\"\n    proto = study_pb2.StudySpec()\n    proto.parameters.add(\n        parameter_id='learning_rate',", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.5289256198347108}, {"context": "    trial_proto.parameters.add(\n        parameter_id='units', value=struct_pb2.Value(number_value=50))\n\n    parameters = py_study_config.trial_parameters(trial_proto)\n    expected = {\n        'learning_rate': 0.5,\n        'units': 50,\n        'activation': 'relu',\n        'batch_size': 32,\n        'floating_point_param': 32.,\n        'synchronous': True\n    }\n    self.assertEqual(expected, parameters)\n    self.assertIsInstance(parameters['batch_size'], int)\n    self.assertIsInstance(parameters['floating_point_param'], float)\n\n  def testPyTrialToDict(self):\n    py_study_config = vz.StudyConfig(\n        metric_information=[\n            vz.MetricInformation(", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.5169491525423728}, {"context": "        parameter_id='activation', value=struct_pb2.Value(string_value='relu'))\n    trial_proto.parameters.add(\n        parameter_id='synchronus', value=struct_pb2.Value(string_value='true'))\n    trial_proto.parameters.add(\n        parameter_id='batch_size', value=struct_pb2.Value(number_value=32))\n    trial_proto.parameters.add(\n        parameter_id='floating_point_param',\n        value=struct_pb2.Value(number_value=32))\n    trial_proto.parameters.add(\n        parameter_id='learning_rate', value=struct_pb2.Value(number_value=0.5))\n    trial_proto.parameters.add(\n        parameter_id='units', value=struct_pb2.Value(number_value=50))\n\n    parameters = py_study_config.trial_parameters(trial_proto)\n    expected = {\n        'learning_rate': 0.5,\n        'units': 50,\n        'activation': 'relu',\n        'batch_size': 32,\n        'floating_point_param': 32.,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.45098039215686275}, {"context": "                name='objective', goal=vz.ObjectiveMetricGoal.MAXIMIZE\n            )\n        ]\n    )\n    root = py_study_config.search_space.root\n    root.add_float_param('learning_rate', 0.01, 3.0)\n    root.add_int_param('units', 10, 1000, scale_type=vz.ScaleType.LOG)\n    root.add_discrete_param('batch_size', [8, 16, 32])\n    root.add_discrete_param(\n        'floating_point_param', [8., 16., 32.], auto_cast=False)\n    root.add_categorical_param('activation', ['tanh', 'relu'])\n    root.add_bool_param('synchronous')\n\n    pytrial = vz.Trial(id=1)\n    pytrial.parameters = {\n        'activation': vz.ParameterValue(value='relu'),\n        'synchronous': vz.ParameterValue(value=True),\n        'batch_size': vz.ParameterValue(value=32),\n        'floating_point_param': vz.ParameterValue(value=32.0),\n        'learning_rate': vz.ParameterValue(value=0.5),", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "line_no": 360, "start_line_no": 350, "end_line_no": 370, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4253731343283582}, {"context": "        'synchronous': True\n    }\n    self.assertEqual(expected, parameters)\n    self.assertIsInstance(parameters['batch_size'], int)\n    self.assertIsInstance(parameters['floating_point_param'], float)\n\n  def testPyTrialToDict(self):\n    py_study_config = vz.StudyConfig(\n        metric_information=[\n            vz.MetricInformation(\n                name='objective', goal=vz.ObjectiveMetricGoal.MAXIMIZE\n            )\n        ]\n    )\n    root = py_study_config.search_space.root\n    root.add_float_param('learning_rate', 0.01, 3.0)\n    root.add_int_param('units', 10, 1000, scale_type=vz.ScaleType.LOG)\n    root.add_discrete_param('batch_size', [8, 16, 32])\n    root.add_discrete_param(\n        'floating_point_param', [8., 16., 32.], auto_cast=False)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/dataset/get_data.py\n# --------------------------------------------------\n# \n#         return {\n#             'train': self.train_data,\n#             'val': self.val_data,\n#             'test': self.test_data\n#         }\n# \n#     def _load(self, dataset, split, num_of_client):\n#         data_dir = os.path.join(self.data_dir, dataset)\n#         if not os.path.exists(data_dir):\n#             logger.info(f'Start tp download the dataset {dataset} ...')\n#             self._download_and_extract(dataset)\n# \n#         # read data\n#         data = []\n#         if dataset == 'imdb':\n#             pos_files = os.listdir(os.path.join(data_dir, split, 'pos'))\n#             neg_files = os.listdir(os.path.join(data_dir, split, 'neg'))\n#             for file in pos_files:\n#                 path = os.path.join(data_dir, split, 'pos', file)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/trainer/trainer.py\n# --------------------------------------------------\n#             ordered_g, ordered_h = self._get_ordered_gh(\n#                 tree_num, node_num, feature_idx)\n#             for value_idx in range(instance_num):\n#                 gain = self.model[tree_num].cal_gain(ordered_g, ordered_h,\n#                                                      value_idx)\n# \n#                 if gain > best_gain:\n#                     best_gain = gain\n#                     split_ref['feature_idx'] = feature_idx\n#                     split_ref['value_idx'] = value_idx\n# \n#         return best_gain, split_ref\n# \n#     def _compute_for_root(self, tree_num):\n#         g, h = self.criterion.get_grad_and_hess(self.batch_y, self.batch_y_hat)\n#         node_num = 0\n#         self.model[tree_num][node_num].grad = g\n#         self.model[tree_num][node_num].hess = h\n#         self.model[tree_num][node_num].indicator = np.ones(len(self.batch_y))\n#         return self._compute_for_node(tree_num, node_num=node_num)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/contrib/data/mini_graph_dt.py\n# --------------------------------------------------\n#         def _load(self, idx, split):\n#             try:\n#                 data = torch.load(\n#                     os.path.join(self.processed_dir, str(idx), f'{split}.pt'))\n#             except:\n#                 data = None\n#             return data\n# \n#         def process(self):\n#             np.random.seed(0)\n#             for idx, name in enumerate(self.DATA_NAME):\n#                 if name in ['BACE', 'BBBP', 'CLINTOX']:\n#                     dataset = MoleculeNet(self.root, name)\n#                     featurizer = GenFeatures()\n#                     ds = []\n#                     for graph in dataset:\n#                         graph = featurizer(graph)\n#                         ds.append(\n#                             Data(edge_index=graph.edge_index,\n#                                  x=graph.x,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/dataset/cikm_cup.py\n# --------------------------------------------------\n#         ])\n# \n#     def _load(self, idx, split):\n#         try:\n#             data = torch.load(\n#                 os.path.join(self.processed_dir, str(idx), f'{split}.pt'))\n#         except:\n#             data = None\n#         return data\n# \n#     def process(self):\n#         pass\n# \n#     def __getitem__(self, idx):\n#         data = {}\n#         for split in ['train', 'val', 'test']:\n#             split_data = self._load(idx, split)\n#             if split_data:\n#                 data[split] = split_data\n#         return data\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/trainers/tf_trainer.py\n# --------------------------------------------------\n#         else:\n#             raise TypeError(\"Type of data should be dict.\")\n#         return init_dict\n# \n#     def register_default_hooks_train(self):\n#         self.register_hook_in_train(self._hook_on_fit_start_init,\n#                                     \"on_fit_start\")\n#         self.register_hook_in_train(self._hook_on_epoch_start,\n#                                     \"on_epoch_start\")\n#         self.register_hook_in_train(self._hook_on_batch_start_init,\n#                                     \"on_batch_start\")\n#         self.register_hook_in_train(self._hook_on_batch_forward,\n#                                     \"on_batch_forward\")\n#         self.register_hook_in_train(self._hook_on_batch_forward_regularizer,\n#                                     \"on_batch_forward\")\n#         self.register_hook_in_train(self._hook_on_batch_backward,\n#                                     \"on_batch_backward\")\n#         self.register_hook_in_train(self._hook_on_batch_end, \"on_batch_end\")\n#         self.register_hook_in_train(self._hook_on_fit_end, \"on_fit_end\")\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/trainer/trainer.py\n# --------------------------------------------------\n#             if ctx.optimizer is None or ctx.scheduler is None:\n#                 ctx.optimizer, ctx.scheduler = \\\n#                     self.setup_optimizer_and_scheduler(ctx)\n#                 setattr(ctx, f'{ctx.cur_mode}_optimizer', ctx.optimizer)\n#                 setattr(ctx, f'{ctx.cur_mode}_scheduler', ctx.scheduler)\n#             if ctx.cfg.federate.atc_load_from and self.load_ckpt:\n#                 self._load_model(ctx)\n#                 self.load_ckpt = False\n# \n#         if ctx.cur_split == 'train' and ctx.cfg.federate.atc_load_from \\\n#                 and self.load_ckpt:\n#             self._load_model(ctx)\n#             self.load_ckpt = False\n# \n#         # prepare statistics\n#         ctx.loss_agg = CtxVar(AverageMeter(), LIFECYCLE.ROUTINE)\n#         ctx.loss_batch_total = CtxVar(0, LIFECYCLE.ROUTINE)\n#         ctx.loss_regular_total = CtxVar(0, LIFECYCLE.ROUTINE)\n#         ctx.num_samples = CtxVar(0, LIFECYCLE.ROUTINE)\n#         ctx.accum_steps = CtxVar(0, LIFECYCLE.ROUTINE)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n parameter ``${LIFECYCLE}`` can be chosen from \\\n        ``LIFECYCLE.BATCH``, ``LIFECYCLE.EPOCH`` and ``LIFECYCLE.ROUTINE``. \\\n        Then the variable ``ctx.${NAME_VARIABLE}`` will be deleted at \\\n        the end of the corresponding stage\n            - ``LIFECYCLE.BATCH``: the variables will \\\n            be deleted after running a batch\n            - ``LIFECYCLE.EPOCH``: the variables will be \\\n            deleted after running a epoch\n            - ``LIFECYCLE.ROUTINE``: the variables will be \\\n            deleted after running a routine\n        More details please refer to our\n        [tutorial](https://federatedscope.io/docs/trainer/).\n\n        We classify and show the default attributes below:\n\n        Data-related attributes\n          - ``ctx.data``: the raw data (not split) the trainer holds\n          - ``ctx.num_samples``: the number of samples used in training\n          - ``ctx.train_data``, ``ctx.val_data``, ``ctx.test_data``: the \\\n          split data the trainer holds\n          - ``ctx.train_loader``, ``ctx.val_loader``, ``ctx.test_loader``: \\\n          the DataLoader of each split data\n          - ``ctx.num_train_data``, ``ctx.num_val_data``, \\\n          ``ctx.num_test_data``: the number of samples of  the split data \\\n          Model-related attributes\n          - ``ctx.model``: the model used\n          - ``ctx.models``: the multi models if use\n          - ``ctx.mirrored_models``: the mirrored models\n          - ``ctx.trainable_para_names``: the trainable parameter names of \\\n          the model\n        Optimizer-related attributes\n          - ``ctx.optimizer``: see ``torch.optim``\n          - ``ctx.scheduler``: decays the learning rate of each parameter group\n          - ``ctx.criterion``: loss/criterion function\n          - ``ctx.regularizer``: regular terms\n          - ``ctx.grad_clip``: gradient clipping\n        Mode-related attributes\n          - ``ctx.cur_mode``: mode of trainer, which is one of ``['train', \\\n          'val', 'test']``\n          - ``ctx.mode_stack``: stack of mode, only used for switching mode\n          - ``ctx.cur_split``: split of data, which is one of ``['train', \\\n          'val', 'test']`` (Note: use ``train`` data in ``test`` mode is \\\n          allowed)\n          - ``ctx.split_stack``: stack of split, only used for switching data \\\n          split\n        Metric-related attributes\n          - ``ctx.loss_batch_total``: Loss of current batch\n          - ``ctx.loss_regular_total``: Loss of regular term\n          - ``ctx.y_true``:  true label of batch data\n          - ``ctx.y_prob``: output of the model with batch data as input\n          - ``ctx.ys_true``: true label of data\n          - ``ctx.ys_prob``: output of the model\n          - ``ctx.eval_metrics``: evaluation metrics calculated by \\\n          ``ctx.monitor``\n          - ``ctx.monitor``: used for monitor trainer's behavior and statistics\n        Other (statistics) attributes (@property, query from ``cfg`` if not \\\n        set)\n          - ``ctx.cfg``: configuration of FL course\n          - ``ctx.device``: current device, such as ``cpu`` and ``gpu0``.\n          - ``ctx.num_train_batch_last_epoch``, \\\n          ``ctx.num_total_train_batch``: the number of batch\n          - ``ctx.num_train_epoch``, ``ctx.num_val_epoch``, \\\n          ``ctx.num_test_epoch``: the number of epoch in each data split\n          - ``ctx.num_train_batch``, ``ctx.num_val_batch``, \\\n          ``ctx.num_test_batch``: the number of batch in each data split\n    \"\"\"\n    def __init__(self, model, cfg, data=None, device=None):\n        super(Context, self).__init__({})\n\n        self.cfg = cfg\n        self.model = model\n        self.data = data\n        self.device = device\n\n        self.cur_mode = None\n        self.mode_stack = list()\n\n        self.cur_split = None\n        self.split_stack = list()\n\n        self.lifecycles = collections.defaultdict(set)\n\n        # Setup optimize-related context variable\n        if self.cfg.backend == 'torch':\n            self.trainable_para_names = get_trainable_para_names(self.model)\n            # TODO: make `criterion` and `regularizer` @property and cached\n            #  to compare whether changes happen\n            self.criterion = get_criterion(self.cfg.criterion.type,\n                                           self.device)\n            self.regularizer = get_regularizer(self.cfg.regularizer.type)\n            self.grad_clip = self.cfg.grad.grad_clip\n        elif self.cfg.backend == 'tensorflow':\n            self.trainable_para_names = self.model.trainable_variables()\n            self.criterion = None\n            self.regularizer = None\n            self.optimizer = None\n            self.grad_clip = None\n\n    # Train related property, query from `cfg` if not set\n    @property\n    def num_train_batch(self):\n        if self.get('num_train_batch'):\n            return self.get('num_train_batch')\n        return self._calculate_batch_epoch_num(mode='train')[0]\n\n    @property\n    def num_train_batch_last_epoch(self):\n        if self.get('num_train_batch_last_epoch'):\n            return self.get('num_train_batch_last_epoch')\n        return self._calculate_batch_epoch_num(mode='train')[1]\n\n    @property\n    def num_train_epoch(self):\n        if self.get('num_train_epoch'):\n            return self.get('num_train_epoch')\n        return self._calculate_batch_epoch_num(mode='train')[2]\n\n    @property\n    def num_total_train_batch(self):\n        if self.get('num_total_train_batch'):\n            return self.get('num_total_train_batch')\n        return self._calculate_batch_epoch_num(mode='train')[3]\n\n    # Val related property, query from `cfg` if not set\n    @property\n    def num_val_batch(self):\n        if self.get('num_val_batch'):\n            return self.get('num_val_batch')\n        return self._calculate_batch_epoch_num(mode='val')[0]\n\n    @property\n    def num_val_epoch(self):\n        if self.get('num_val_epoch'):\n            return self.get('num_val_epoch')\n        return self._calculate_batch_epoch_num(mode='val')[2]\n\n    # Test related property, query from `cfg` if not set\n    @property\n    def num_test_batch(self):\n        if self.get('num_test_batch'):\n            return self.get('num_test_batch')\n        return self._calculate_batch_epoch_num(mode='test')[0]\n\n    @property\n    def num_test_epoch(self):\n        if self.get('num_test_epoch'):\n            return self.get('num_test_epoch')\n        return self._calculate_batch_epoch_num(mode='test')[2]\n\n    def _calculate_batch_epoch_num(self, mode='train'):\n        if self.cur_mode is not None and self.cur_mode != mode:\n            logger.warning(\n                f'cur_mode `{self.cur_mode}` mismatch mode `{mode}`, '", "choices": [{"text": "{self.cur_mode}"}], "metadata": {"task_id": "alibaba_FederatedScope/24", "ground_truth": "                f'will use `{mode}` to calculate `ctx.var`.')", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "trainers", "context.py"], "context_start_lineno": 72, "line_no": 225, "query_window": {"context": "            return self.get('num_val_epoch')\n        return self._calculate_batch_epoch_num(mode='val')[2]\n\n    # Test related property, query from `cfg` if not set\n    @property\n    def num_test_batch(self):\n        if self.get('num_test_batch'):\n            return self.get('num_test_batch')\n        return self._calculate_batch_epoch_num(mode='test')[0]\n\n    @property\n    def num_test_epoch(self):\n        if self.get('num_test_epoch'):\n            return self.get('num_test_epoch')\n        return self._calculate_batch_epoch_num(mode='test')[2]\n\n    def _calculate_batch_epoch_num(self, mode='train'):\n        if self.cur_mode is not None and self.cur_mode != mode:\n            logger.warning(\n                f'cur_mode `{self.cur_mode}` mismatch mode `{mode}`, '", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "trainers", "context.py"], "line_no": 225, "task_id": "alibaba_FederatedScope/24", "start_line_no": 205, "end_line_no": 225, "window_size": 20, "context_start_lineno": 72, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "                                f'num_{self.ctx.cur_mode}_batch_last_epoch',\n                                None) - 1:\n                    break\n\n    def _hook_on_fit_start_init(self, ctx):\n        ctx.model.to(ctx.device)\n\n        if ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:\n            ctx.optimizer = ctx.get(f'{ctx.cur_mode}_optimizer', None)\n            ctx.scheduler = ctx.get(f'{ctx.cur_mode}_scheduler', None)\n            if ctx.optimizer is None or ctx.scheduler is None:\n                ctx.optimizer, ctx.scheduler = \\\n                    self.setup_optimizer_and_scheduler(ctx)\n                setattr(ctx, f'{ctx.cur_mode}_optimizer', ctx.optimizer)\n                setattr(ctx, f'{ctx.cur_mode}_scheduler', ctx.scheduler)\n            if ctx.cfg.federate.atc_load_from and self.load_ckpt:\n                self._load_model(ctx)\n                self.load_ckpt = False\n\n        if ctx.cur_split == 'train' and ctx.cfg.federate.atc_load_from \\", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "trainer", "trainer.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.30578512396694213}, {"context": "        \"\"\"\n        init_dict = dict()\n        if isinstance(data, dict):\n            for mode in [\"train\", \"val\", \"test\"]:\n                init_dict[\"{}_data\".format(mode)] = None\n                init_dict[\"{}_loader\".format(mode)] = None\n                init_dict[\"num_{}_data\".format(mode)] = 0\n                if data.get(mode, None) is not None:\n                    init_dict[\"{}_data\".format(mode)] = data.get(mode)\n                    init_dict[\"num_{}_data\".format(mode)] = len(data.get(mode))\n        else:\n            raise TypeError(\"Type of data should be dict.\")\n        return init_dict\n\n    def register_default_hooks_train(self):\n        self.register_hook_in_train(self._hook_on_fit_start_init,\n                                    \"on_fit_start\")\n        self.register_hook_in_train(self._hook_on_epoch_start,\n                                    \"on_epoch_start\")\n        self.register_hook_in_train(self._hook_on_batch_start_init,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "trainers", "tf_trainer.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.28448275862068967}, {"context": "        try:\n            data = torch.load(\n                os.path.join(self.processed_dir, str(idx), f'{split}.pt'))\n        except:\n            data = None\n        return data\n\n    def process(self):\n        pass\n\n    def __getitem__(self, idx):\n        data = {}\n        for split in ['train', 'val', 'test']:\n            split_data = self._load(idx, split)\n            if split_data:\n                data[split] = split_data\n        return data", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "dataset", "cikm_cup.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 47, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.28431372549019607}, {"context": "\n        def __getitem__(self, idx):\n            if idx not in self.IN_MEMORY_DATA:\n                self.IN_MEMORY_DATA[idx] = {}\n                for split in ['train', 'val', 'test']:\n                    split_data = self._load(idx, split)\n                    if split_data:\n                        self.IN_MEMORY_DATA[idx][split] = split_data\n            return self.IN_MEMORY_DATA[idx]\n\n        def _load(self, idx, split):\n            try:\n                data = torch.load(\n                    os.path.join(self.processed_dir, str(idx), f'{split}.pt'))\n            except:\n                data = None\n            return data\n\n        def process(self):\n            np.random.seed(0)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "contrib", "data", "mini_graph_dt.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2767857142857143}, {"context": "        ordered_h = self.model[tree_num][node_num].hess[order]\n        return ordered_g, ordered_h\n\n    def _get_best_gain(self, tree_num, node_num):\n        best_gain = 0\n        split_ref = {'feature_idx': None, 'value_idx': None}\n\n        instance_num = self.batch_x.shape[0]\n        feature_num = len(self.feature_order)\n        for feature_idx in range(feature_num):\n            ordered_g, ordered_h = self._get_ordered_gh(\n                tree_num, node_num, feature_idx)\n            for value_idx in range(instance_num):\n                gain = self.model[tree_num].cal_gain(ordered_g, ordered_h,\n                                                     value_idx)\n\n                if gain > best_gain:\n                    best_gain = gain\n                    split_ref['feature_idx'] = feature_idx\n                    split_ref['value_idx'] = value_idx", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "trainer", "trainer.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2702702702702703}, {"context": "                for data in train_and_val_data\n            ]\n            each_val_data = [\n                data[-int(self.split[1] * len(data)):]\n                for data in train_and_val_data\n            ]\n            each_test_data = self._load(each_data, 'test', each_client_num)\n            self.train_data.extend(each_train_data)\n            self.val_data.extend(each_val_data)\n            self.test_data.extend(each_test_data)\n\n        return {\n            'train': self.train_data,\n            'val': self.val_data,\n            'test': self.test_data\n        }\n\n    def _load(self, dataset, split, num_of_client):\n        data_dir = os.path.join(self.data_dir, dataset)\n        if not os.path.exists(data_dir):", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "get_data.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2647058823529412}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/pyvizier/converters/core_test.py\n# --------------------------------------------------\n#       dict(dtype='float32'),\n#       dict(dtype='float64'),\n#   ])\n#   def test_zero_range_reverse_log_double(self, dtype):\n#     converter = core.DefaultModelInputConverter(\n#         pyvizier.ParameterConfig.factory(\n#             'x1',\n#             bounds=(np.exp(0.9), np.exp(0.9)),\n#             scale_type=pyvizier.ScaleType.REVERSE_LOG,\n#         ),\n#         scale=True,\n#         onehot_embed=True,\n#         float_dtype=dtype,\n#     )\n#     actual = converter.convert([\n#         Trial(parameters={'x1': pyvizier.ParameterValue(np.exp(0.9))}),\n#         Trial(parameters={'x1': pyvizier.ParameterValue(np.exp(1.2))}),\n#         Trial(parameters={'x1': pyvizier.ParameterValue('a')}),\n#         Trial(),\n#     ])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/benchmarks/experimenters/nasbench101_experimenter.py\n# --------------------------------------------------\n#         trial.complete(\n#             pyvizier.Measurement(\n#                 metrics={k: results[k] for k in self._metric_names}))\n#       else:\n#         trial.complete(\n#             pyvizier.Measurement(), infeasibility_reason='Not in search space.')\n# \n#   def _trial_to_model_spec(self, trial: pyvizier.Trial):\n#     matrix = np.zeros((self._num_vertices, self._num_vertices), dtype=int)\n#     for y in range(self._num_vertices):\n#       for x in range(self._num_vertices):\n#         if y > x:\n#           matrix[x][y] = int(\n#               trial.parameters['{}_{}'.format(x, y)].value == 'True')\n# \n#     base_ops = []\n#     for i in range(self._op_spots):\n#       base_ops.append(trial.parameters['ops_{}'.format(i)].value)\n#     ops = [self._input_op] + base_ops + [self._output_op]\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/pyvizier/converters/core_test.py\n# --------------------------------------------------\n#         float_dtype=dtype,\n#     )\n#     actual = converter.convert([\n#         Trial(parameters={'x1': pyvizier.ParameterValue(0.9)}),\n#         Trial(parameters={'x1': pyvizier.ParameterValue(1.0)}),\n#         Trial(parameters={'x1': pyvizier.ParameterValue('a')}),\n#         Trial(),\n#     ])\n#     expected = np.asarray([[0.0], [0.0], [np.NaN], [np.NaN]], dtype)\n#     np.testing.assert_equal(expected, actual)\n# \n#   @parameterized.parameters([\n#       dict(dtype=np.float32),\n#       dict(dtype=np.float64),\n#       dict(dtype='float32'),\n#       dict(dtype='float64'),\n#   ])\n#   def test_zero_range_log_double(self, dtype):\n#     converter = core.DefaultModelInputConverter(\n#         pyvizier.ParameterConfig.factory(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/pyvizier/converters/core_test.py\n# --------------------------------------------------\n#         scale=True,\n#         onehot_embed=True,\n#         float_dtype=dtype,\n#     )\n#     actual = converter.convert([\n#         Trial(parameters={'x1': pyvizier.ParameterValue(np.exp(0.9))}),\n#         Trial(parameters={'x1': pyvizier.ParameterValue(np.exp(1.2))}),\n#         Trial(parameters={'x1': pyvizier.ParameterValue('a')}),\n#         Trial(),\n#     ])\n#     expected = np.asarray([[0.0], [0.0], [np.NaN], [np.NaN]], dtype=dtype)\n#     np.testing.assert_equal(expected, actual)\n# \n#   @parameterized.parameters([\n#       dict(dtype=np.float32),\n#       dict(dtype=np.float64),\n#       dict(dtype='float32'),\n#       dict(dtype='float64'),\n#   ])\n#   def test_double_into_scaled_double(self, dtype):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config_test.py\n# --------------------------------------------------\n#         key: \"key\"\n#         value: \"value\"\n#       }\n#       metadata {\n#         key: \"proto\"\n#         proto {\n#           [type.googleapis.com/vizier.Trial] {\n#             id: '1'\n#           }\n#         }\n#       }\n#     \"\"\", proto)\n#     from_proto = sc.from_proto(proto).metadata\n#     self.assertCountEqual(sc.metadata, from_proto)\n# \n#   def testCreation(self):\n#     sc = vz.StudyConfig()\n#     sc.algorithm = vz.Algorithm.RANDOM_SEARCH\n#     sc.metric_information.append(\n#         vz.MetricInformation(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/pyvizier/converters/core_test.py\n# --------------------------------------------------\n#     ])\n#     expected = np.asarray([[0.0], [1.0]], dtype)\n#     np.testing.assert_allclose(expected, actual)\n#     self.assertEqual(expected.dtype, actual.dtype)\n# \n#   @parameterized.parameters([\n#       dict(dtype=np.float32),\n#       dict(dtype=np.float64),\n#       dict(dtype='float32'),\n#       dict(dtype='float64'),\n#   ])\n#   def test_double_into_double_log_inverse(self, dtype):\n#     converter = core.DefaultModelInputConverter(\n#         pyvizier.ParameterConfig.factory(\n#             'x1', bounds=(1e-4, 1e2), scale_type=pyvizier.ScaleType.LOG\n#         ),\n#         scale=True,\n#         float_dtype=dtype,\n#     )\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"Setup for pip package.\"\"\"\nimport os\nimport sys\nfrom setuptools import find_namespace_packages\nfrom setuptools import setup\nfrom setuptools.command.build import build\n\n\ndef _get_version():\n  with open('vizier/__init__.py') as fp:\n    for line in fp:\n      if line.startswith('__version__'):\n        g = {}\n        exec(line, g)  # pylint: disable=exec-used\n        return g['__version__']\n    raise ValueError('`__version__` not defined in `vizier/__init__.py`')\n\n\ndef _strip_comments_from_line(s: str) -> str:\n  \"\"\"Parses a line of a requirements.txt file.\"\"\"\n  requirement, *_ = s.split('#')\n  return requirement.strip()\n\n\ndef _parse_requirements(requirements_txt_path: str) -> list[str]:\n  \"\"\"Returns a list of dependencies for setup() from requirements.txt.\"\"\"\n\n  # Currently a requirements.txt is being used to specify dependencies. In order\n  # to avoid specifying it in two places, we're going to use that file as the\n  # source of truth.\n  with open(requirements_txt_path) as fp:\n    # Parse comments.\n    lines = [_strip_comments_from_line(line) for line in fp.read().splitlines()]\n    # Remove empty lines and direct github repos (not allowed in PyPI setups)\n    return [l for l in lines if (l and 'github.com' not in l)]\n\n\nclass BuildCmd(build):\n  \"\"\"Custom installation script to build the protos.\"\"\"\n\n  def run(self):\n    current_path = os.path.dirname(os.path.realpath(__file__))\n    sys.stdout.write('current_path: {}'.format(current_path))\n    with os.scandir('.') as it:\n      for entry in it:\n        if entry.name.startswith('build_protos.sh'):\n          sys.stdout.write('{}'.format(entry))\n    if os.system('bash build_protos.sh'):\n      raise OSError('Failed to run build_protos.sh')\n    build.run(self)\n\n\n_VERSION = _get_version()\n\nsetup(\n    name='google-vizier',\n    version=_VERSION,\n    url='https://github.com/google/vizier',\n    license='Apache License 2.0',\n    author='Vizier Team',\n    description=(\n        'Open Source Vizier: Distributed service framework for blackbox'\n        ' optimization and research.'\n    ),\n    long_description=open('README.md').read(),\n    long_description_content_type='text/markdown',\n    author_email='oss-vizier-dev@google.com',\n    # Contained modules and scripts.\n    packages=find_namespace_packages(\n        include=['vizier*'], exclude=['*_test.py', 'examples']\n    ),\n    install_requires=_parse_requirements('requirements.txt'),\n    extras_require={", "choices": [{"text": "\"protobuf\": _parse_requirements(\"requirements-protobuf.txt\"),"}], "metadata": {"task_id": "google_vizier/64", "ground_truth": "        'jax': _parse_requirements('requirements-jax.txt'),", "fpath_tuple": ["google_vizier", "setup.py"], "context_start_lineno": 0, "line_no": 89, "query_window": {"context": "\nsetup(\n    name='google-vizier',\n    version=_VERSION,\n    url='https://github.com/google/vizier',\n    license='Apache License 2.0',\n    author='Vizier Team',\n    description=(\n        'Open Source Vizier: Distributed service framework for blackbox'\n        ' optimization and research.'\n    ),\n    long_description=open('README.md').read(),\n    long_description_content_type='text/markdown',\n    author_email='oss-vizier-dev@google.com',\n    # Contained modules and scripts.\n    packages=find_namespace_packages(\n        include=['vizier*'], exclude=['*_test.py', 'examples']\n    ),\n    install_requires=_parse_requirements('requirements.txt'),\n    extras_require={", "metadata": {"fpath_tuple": ["google_vizier", "setup.py"], "line_no": 89, "task_id": "google_vizier/64", "start_line_no": 69, "end_line_no": 89, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "        pyvizier.ParameterConfig.factory(\n            'x1', bounds=(1e-4, 1e2), scale_type=pyvizier.ScaleType.LOG\n        ),\n        scale=True,\n        float_dtype=dtype,\n    )\n\n    actual = converter.convert([\n        Trial(parameters={'x1': pyvizier.ParameterValue(1e-4)}),\n        Trial(parameters={'x1': pyvizier.ParameterValue(1e2)}),\n    ])\n    expected = np.asarray([[0.0], [1.0]], dtype)\n    np.testing.assert_allclose(expected, actual)\n    self.assertEqual(expected.dtype, actual.dtype)\n\n  @parameterized.parameters([\n      dict(dtype=np.float32),\n      dict(dtype=np.float64),\n      dict(dtype='float32'),\n      dict(dtype='float64'),", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "pyvizier", "converters", "core_test.py"], "line_no": 750, "start_line_no": 740, "end_line_no": 760, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.14457831325301204}, {"context": "    sc.metadata['proto'] = empty_trial\n\n    proto = sc.to_proto()\n    compare.assertProto2Contains(\n        self, \"\"\"metadata {\n        key: \"key\"\n        ns: \":ns\"\n        value: \"ns-value\"\n      }\n      metadata {\n        key: \"key\"\n        value: \"value\"\n      }\n      metadata {\n        key: \"proto\"\n        proto {\n          [type.googleapis.com/vizier.Trial] {\n            id: '1'\n          }\n        }", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config_test.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.13986013986013987}, {"context": "      dict(dtype='float32'),\n      dict(dtype='float64'),\n  ])\n  def test_zero_range_reverse_log_double(self, dtype):\n    converter = core.DefaultModelInputConverter(\n        pyvizier.ParameterConfig.factory(\n            'x1',\n            bounds=(np.exp(0.9), np.exp(0.9)),\n            scale_type=pyvizier.ScaleType.REVERSE_LOG,\n        ),\n        scale=True,\n        onehot_embed=True,\n        float_dtype=dtype,\n    )\n    actual = converter.convert([\n        Trial(parameters={'x1': pyvizier.ParameterValue(np.exp(0.9))}),\n        Trial(parameters={'x1': pyvizier.ParameterValue(np.exp(1.2))}),\n        Trial(parameters={'x1': pyvizier.ParameterValue('a')}),\n        Trial(),\n    ])", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "pyvizier", "converters", "core_test.py"], "line_no": 890, "start_line_no": 880, "end_line_no": 900, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.13953488372093023}, {"context": "      dict(dtype='float32'),\n      dict(dtype='float64'),\n  ])\n  def test_zero_range_linear_double(self, dtype):\n    converter = core.DefaultModelInputConverter(\n        pyvizier.ParameterConfig.factory(\n            'x1', bounds=(0.9, 0.9), scale_type=pyvizier.ScaleType.LINEAR\n        ),\n        scale=True,\n        onehot_embed=True,\n        float_dtype=dtype,\n    )\n    actual = converter.convert([\n        Trial(parameters={'x1': pyvizier.ParameterValue(0.9)}),\n        Trial(parameters={'x1': pyvizier.ParameterValue(1.0)}),\n        Trial(parameters={'x1': pyvizier.ParameterValue('a')}),\n        Trial(),\n    ])\n    expected = np.asarray([[0.0], [0.0], [np.NaN], [np.NaN]], dtype)\n    np.testing.assert_equal(expected, actual)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "pyvizier", "converters", "core_test.py"], "line_no": 840, "start_line_no": 830, "end_line_no": 850, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.1388888888888889}, {"context": "        'validation_accuracy', 'test_accuracy'\n    ]\n\n  def evaluate(self, suggestions: Sequence[pyvizier.Trial]):\n    \"\"\"Evaluates and completes the Trial using NASBench-101 querying.\"\"\"\n\n    for trial in suggestions:\n      spec = self._trial_to_model_spec(trial)\n      if self._nasbench.is_valid(spec):\n        results = self._nasbench.query(spec)\n        trial.complete(\n            pyvizier.Measurement(\n                metrics={k: results[k] for k in self._metric_names}))\n      else:\n        trial.complete(\n            pyvizier.Measurement(), infeasibility_reason='Not in search space.')\n\n  def _trial_to_model_spec(self, trial: pyvizier.Trial):\n    matrix = np.zeros((self._num_vertices, self._num_vertices), dtype=int)\n    for y in range(self._num_vertices):", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "benchmarks", "experimenters", "nasbench101_experimenter.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.13829787234042554}, {"context": "        Trial(parameters={'x1': pyvizier.ParameterValue(np.exp(1.2))}),\n        Trial(parameters={'x1': pyvizier.ParameterValue('a')}),\n        Trial(),\n    ])\n    expected = np.asarray([[0.0], [0.0], [np.NaN], [np.NaN]], dtype=dtype)\n    np.testing.assert_equal(expected, actual)\n\n  @parameterized.parameters([\n      dict(dtype=np.float32),\n      dict(dtype=np.float64),\n      dict(dtype='float32'),\n      dict(dtype='float64'),\n  ])\n  def test_zero_range_reverse_log_double(self, dtype):\n    converter = core.DefaultModelInputConverter(\n        pyvizier.ParameterConfig.factory(\n            'x1',\n            bounds=(np.exp(0.9), np.exp(0.9)),\n            scale_type=pyvizier.ScaleType.REVERSE_LOG,\n        ),", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "pyvizier", "converters", "core_test.py"], "line_no": 880, "start_line_no": 870, "end_line_no": 890, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.13812154696132597}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_trainer_evaluator_parity.py\n# --------------------------------------------------\n#         model_name = \"prajjwal1/bert-tiny-mnli\"\n#         max_eval_samples = 150\n# \n#         subprocess.run(\n#             \"git sparse-checkout set examples/pytorch/text-classification\",\n#             shell=True,\n#             cwd=os.path.join(self.dir_path, \"transformers\"),\n#         )\n# \n#         subprocess.run(\n#             f\"python examples/pytorch/text-classification/run_glue.py\"\n#             f\" --model_name_or_path {model_name}\"\n#             f\" --task_name mnli\"\n#             f\" --do_eval\"\n#             f\" --max_seq_length 256\"\n#             f\" --output_dir {os.path.join(self.dir_path, 'textclassification_mnli_transformers')}\"\n#             f\" --max_eval_samples {max_eval_samples}\",\n#             shell=True,\n#             cwd=os.path.join(self.dir_path, \"transformers\"),\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_trainer_evaluator_parity.py\n# --------------------------------------------------\n# \n#     def test_question_answering_parity(self):\n#         model_name_v1 = \"anas-awadalla/bert-tiny-finetuned-squad\"\n#         model_name_v2 = \"mrm8488/bert-tiny-finetuned-squadv2\"\n# \n#         subprocess.run(\n#             \"git sparse-checkout set examples/pytorch/question-answering\",\n#             shell=True,\n#             cwd=os.path.join(self.dir_path, \"transformers\"),\n#         )\n# \n#         # test squad_v1-like dataset\n#         subprocess.run(\n#             f\"python examples/pytorch/question-answering/run_qa.py\"\n#             f\" --model_name_or_path {model_name_v1}\"\n#             f\" --dataset_name squad\"\n#             f\" --do_eval\"\n#             f\" --output_dir {os.path.join(self.dir_path, 'questionanswering_squad_transformers')}\"\n#             f\" --max_eval_samples 100\"\n#             f\" --max_seq_length 384\",\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_trainer_evaluator_parity.py\n# --------------------------------------------------\n#             model_or_pipeline=pipe,\n#             data=eval_dataset,\n#             metric=\"accuracy\",\n#             input_column=\"image\",\n#             label_column=\"labels\",\n#             label_mapping=model.config.label2id,\n#             strategy=\"simple\",\n#         )\n# \n#         self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"accuracy\"])\n# \n#     def test_question_answering_parity(self):\n#         model_name_v1 = \"anas-awadalla/bert-tiny-finetuned-squad\"\n#         model_name_v2 = \"mrm8488/bert-tiny-finetuned-squadv2\"\n# \n#         subprocess.run(\n#             \"git sparse-checkout set examples/pytorch/question-answering\",\n#             shell=True,\n#             cwd=os.path.join(self.dir_path, \"transformers\"),\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_trainer_evaluator_parity.py\n# --------------------------------------------------\n# \n#         self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"accuracy\"])\n# \n#     def test_image_classification_parity(self):\n#         # we can not compare to the Pytorch transformers example, that uses custom preprocessing on the images\n#         model_name = \"douwekiela/resnet-18-finetuned-dogfood\"\n#         dataset_name = \"beans\"\n#         max_eval_samples = 120\n# \n#         raw_dataset = load_dataset(dataset_name, split=\"validation\")\n#         eval_dataset = raw_dataset.select(range(max_eval_samples))\n# \n#         feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n#         model = AutoModelForImageClassification.from_pretrained(model_name)\n# \n#         def collate_fn(examples):\n#             pixel_values = torch.stack(\n#                 [torch.tensor(feature_extractor(example[\"image\"])[\"pixel_values\"][0]) for example in examples]\n#             )\n#             labels = torch.tensor([example[\"labels\"] for example in examples])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_trainer_evaluator_parity.py\n# --------------------------------------------------\n#             input_column=\"sentence\",\n#             label_column=\"label\",\n#             label_mapping={\"negative\": 0, \"positive\": 1},\n#             strategy=\"simple\",\n#         )\n# \n#         self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"accuracy\"])\n# \n#     @slow\n#     def test_text_classification_parity_two_columns(self):\n#         model_name = \"prajjwal1/bert-tiny-mnli\"\n#         max_eval_samples = 150\n# \n#         subprocess.run(\n#             \"git sparse-checkout set examples/pytorch/text-classification\",\n#             shell=True,\n#             cwd=os.path.join(self.dir_path, \"transformers\"),\n#         )\n# \n#         subprocess.run(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_trainer_evaluator_parity.py\n# --------------------------------------------------\n#             os.path.join(self.dir_path, \"tokenclassification_conll2003_transformers\", \"eval_results.json\"), \"r\"\n#         ) as f:\n#             transformers_results = json.load(f)\n# \n#         eval_dataset = load_dataset(\"conll2003\", split=f\"validation[:{n_samples}]\")\n# \n#         pipe = pipeline(task=\"token-classification\", model=model_name)\n# \n#         e = evaluator(task=\"token-classification\")\n#         evaluator_results = e.compute(\n#             model_or_pipeline=pipe,\n#             data=eval_dataset,\n#             metric=\"seqeval\",\n#             input_column=\"tokens\",\n#             label_column=\"ner_tags\",\n#             strategy=\"simple\",\n#         )\n# \n#         self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"overall_accuracy\"])\n#         self.assertEqual(transformers_results[\"eval_f1\"], evaluator_results[\"overall_f1\"])\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n, Evaluator._infer_device(), self.pipe\n            )\n\n            # tf accelerator found and pipeline instantiated on CPU\n            pt_available = False\n            tf_available = True\n            self.assertRaises(\n                ValueError, Evaluator.check_for_mismatch_in_device_setup, Evaluator._infer_device(), self.pipe\n            )\n\n    def test_pipe_init(self):\n        self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            input_column=\"text\",\n            label_column=\"label\",\n            label_mapping=self.label_mapping,\n        )\n\n    def test_model_init(self):\n        self.evaluator.compute(\n            model_or_pipeline=self.default_model,\n            tokenizer=self.default_tokenizer,\n            data=self.data,\n            input_column=\"text\",\n            label_column=\"label\",\n            label_mapping=self.label_mapping,\n        )\n\n    def test_model_str_init(self):\n        self.evaluator.compute(\n            model_or_pipeline=self.default_ckpt,\n            data=self.data,\n            input_column=\"text\",\n            label_column=\"label\",\n            label_mapping=self.label_mapping,\n        )\n\n\nclass TestTextClassificationEvaluator(TestCase):\n    def setUp(self):\n        self.data = Dataset.from_dict({\"label\": [1, 0], \"text\": [\"great movie\", \"horrible movie\"]})\n        self.default_model = \"lvwerra/distilbert-imdb\"\n        self.input_column = \"text\"\n        self.label_column = \"label\"\n        self.pipe = DummyTextClassificationPipeline()\n        self.perf_pipe = DummyTextClassificationPipeline(sleep_time=0.1)\n        self.evaluator = evaluator(\"text-classification\")\n        self.label_mapping = {\"NEGATIVE\": 0.0, \"POSITIVE\": 1.0}\n\n    def test_pipe_init(self):\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            input_column=\"text\",\n            label_column=\"label\",\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    @slow\n    def test_model_init(self):\n        results = self.evaluator.compute(\n            model_or_pipeline=self.default_model,\n            data=self.data,\n            metric=\"accuracy\",\n            input_column=self.input_column,\n            label_column=self.label_column,\n            label_mapping=self.label_mapping,\n        )\n\n        model = AutoModelForSequenceClassification.from_pretrained(self.default_model)\n        tokenizer = AutoTokenizer.from_pretrained(self.default_model)\n\n        self.assertEqual(results[\"accuracy\"], 1.0)\n        results = self.evaluator.compute(\n            model_or_pipeline=model,\n            data=self.data,\n            metric=\"accuracy\",\n            tokenizer=tokenizer,\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    def test_class_init(self):\n        evaluator = TextClassificationEvaluator()\n        self.assertEqual(evaluator.task, \"text-classification\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"f1\",\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"f1\"], 1.0)\n\n    @slow\n    def test_default_pipe_init(self):\n        results = self.evaluator.compute(\n            data=self.data,\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    def test_data_loading(self):\n\n        # Test passing in dataset by name with split\n        data = self.evaluator.load_data(\"evaluate/imdb-ci\", split=\"test[:1]\")\n        self.evaluator.prepare_data(data=data, input_column=\"text\", label_column=\"label\", second_input_column=None)\n\n        # Test passing in dataset by name without split and inferring the optimal split\n        data = self.evaluator.load_data(\"evaluate/imdb-ci\")\n        self.evaluator.prepare_data(data=data, input_column=\"text\", label_column=\"label\", second_input_column=None)\n\n        # Test that it chooses the correct one (e.g. imdb only has train and test, but no validation)\n        self.assertEqual(data.split, \"test\")\n\n        # Test that the data point returned is correct; this maps to the first example in the dataset\n        self.assertEqual(data[0][\"text\"], \"I love movies about whales!\")\n\n        # Test loading subset of a dataset with the `name` field\n        data = self.evaluator.load_data(\"evaluate/glue-ci\", subset=\"cola\", split=\"test\")\n        self.assertEqual(isinstance(data, Dataset), True)\n\n        # Test loading subset of a dataset with the `name` field and having it infer the split\n        data = self.evaluator.load_data(\"evaluate/glue-ci\", subset=\"cola\")\n        self.assertEqual(isinstance(data, Dataset), True)\n\n    def test_overwrite_default_metric(self):\n        accuracy = load(\"accuracy\")\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=accuracy,\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"accuracy\",\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    def test_bootstrap(self):\n        data = Dataset.from_dict({\"label\": [1, 0, 0], \"text\": [\"great movie\", \"great movie\", \"horrible movie\"]})\n\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=data,\n            metric=\"accuracy\",\n            label_mapping=self.label_mapping,\n            strategy=\"bootstrap\",\n            n_resamples=10,\n            random_state=0,\n        )\n        self.assertAlmostEqual(results[\"accuracy\"][\"score\"], 0.666666, 5)\n        self.assertAlmostEqual(results[\"accuracy\"][\"confidence_interval\"][0], 0.33333, 5)\n        self.assertAlmostEqual(results[\"accuracy\"][\"confidence_interval\"][1], 0.666666, 5)\n        self.assertAlmostEqual(results[\"accuracy\"][\"standard_error\"], 0.22498, 5)\n\n    def test_perf(self):\n        results = self.evaluator.compute(\n            model_or_pipeline=self.perf_pipe,\n            data=self.data,\n            metric=\"accuracy\",\n            input_column=self.input_column,\n            label_column=self.label_column,\n            label_mapping=self.label_mapping,\n            n_resamples=10,\n            random_state=0,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)", "choices": [{"text": "results[\"accuracy\"], 1.0"}], "metadata": {"task_id": "huggingface_evaluate/188", "ground_truth": "        self.assertAlmostEqual(results[\"total_time_in_seconds\"], 0.1, 1)", "fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "context_start_lineno": 191, "line_no": 366, "query_window": {"context": "            n_resamples=10,\n            random_state=0,\n        )\n        self.assertAlmostEqual(results[\"accuracy\"][\"score\"], 0.666666, 5)\n        self.assertAlmostEqual(results[\"accuracy\"][\"confidence_interval\"][0], 0.33333, 5)\n        self.assertAlmostEqual(results[\"accuracy\"][\"confidence_interval\"][1], 0.666666, 5)\n        self.assertAlmostEqual(results[\"accuracy\"][\"standard_error\"], 0.22498, 5)\n\n    def test_perf(self):\n        results = self.evaluator.compute(\n            model_or_pipeline=self.perf_pipe,\n            data=self.data,\n            metric=\"accuracy\",\n            input_column=self.input_column,\n            label_column=self.label_column,\n            label_mapping=self.label_mapping,\n            n_resamples=10,\n            random_state=0,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)", "metadata": {"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 366, "task_id": "huggingface_evaluate/188", "start_line_no": 346, "end_line_no": 366, "window_size": 20, "context_start_lineno": 191, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "\n        e = evaluator(task=\"token-classification\")\n        evaluator_results = e.compute(\n            model_or_pipeline=pipe,\n            data=eval_dataset,\n            metric=\"seqeval\",\n            input_column=\"tokens\",\n            label_column=\"ner_tags\",\n            strategy=\"simple\",\n        )\n\n        self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"overall_accuracy\"])\n        self.assertEqual(transformers_results[\"eval_f1\"], evaluator_results[\"overall_f1\"])", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_trainer_evaluator_parity.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 313, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.39805825242718446}, {"context": "\n        eval_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation[:80]\")\n\n        pipe = pipeline(task=\"text-classification\", model=model_name, tokenizer=model_name)\n\n        task_evaluator = evaluator(task=\"text-classification\")\n        evaluator_results = task_evaluator.compute(\n            model_or_pipeline=pipe,\n            data=eval_dataset,\n            metric=\"accuracy\",\n            input_column=\"sentence\",\n            label_column=\"label\",\n            label_mapping={\"negative\": 0, \"positive\": 1},\n            strategy=\"simple\",\n        )\n\n        self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"accuracy\"])\n\n    @slow\n    def test_text_classification_parity_two_columns(self):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_trainer_evaluator_parity.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3828125}, {"context": "        task_evaluator = evaluator(task=\"text-classification\")\n        evaluator_results = task_evaluator.compute(\n            model_or_pipeline=pipe,\n            data=eval_dataset,\n            metric=\"accuracy\",\n            input_column=\"premise\",\n            second_input_column=\"hypothesis\",\n            label_column=\"label\",\n            label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1, \"LABEL_2\": 2},\n        )\n\n        self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"accuracy\"])\n\n    def test_image_classification_parity(self):\n        # we can not compare to the Pytorch transformers example, that uses custom preprocessing on the images\n        model_name = \"douwekiela/resnet-18-finetuned-dogfood\"\n        dataset_name = \"beans\"\n        max_eval_samples = 120\n\n        raw_dataset = load_dataset(dataset_name, split=\"validation\")", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_trainer_evaluator_parity.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3618421052631579}, {"context": "\n        with open(\n            f\"{os.path.join(self.dir_path, 'imageclassification_beans_transformers', 'eval_results.json')}\", \"r\"\n        ) as f:\n            transformers_results = json.load(f)\n\n        pipe = pipeline(task=\"image-classification\", model=model_name, feature_extractor=model_name)\n\n        task_evaluator = evaluator(task=\"image-classification\")\n        evaluator_results = task_evaluator.compute(\n            model_or_pipeline=pipe,\n            data=eval_dataset,\n            metric=\"accuracy\",\n            input_column=\"image\",\n            label_column=\"labels\",\n            label_mapping=model.config.label2id,\n            strategy=\"simple\",\n        )\n\n        self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"accuracy\"])", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_trainer_evaluator_parity.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3515625}, {"context": "            model_or_pipeline=pipe,\n            data=eval_dataset,\n            metric=\"accuracy\",\n            input_column=\"image\",\n            label_column=\"labels\",\n            label_mapping=model.config.label2id,\n            strategy=\"simple\",\n        )\n\n        self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"accuracy\"])\n\n    def test_question_answering_parity(self):\n        model_name_v1 = \"anas-awadalla/bert-tiny-finetuned-squad\"\n        model_name_v2 = \"mrm8488/bert-tiny-finetuned-squadv2\"\n\n        subprocess.run(\n            \"git sparse-checkout set examples/pytorch/question-answering\",\n            shell=True,\n            cwd=os.path.join(self.dir_path, \"transformers\"),\n        )", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_trainer_evaluator_parity.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3357142857142857}, {"context": "            input_column=\"sentence\",\n            label_column=\"label\",\n            label_mapping={\"negative\": 0, \"positive\": 1},\n            strategy=\"simple\",\n        )\n\n        self.assertEqual(transformers_results[\"eval_accuracy\"], evaluator_results[\"accuracy\"])\n\n    @slow\n    def test_text_classification_parity_two_columns(self):\n        model_name = \"prajjwal1/bert-tiny-mnli\"\n        max_eval_samples = 150\n\n        subprocess.run(\n            \"git sparse-checkout set examples/pytorch/text-classification\",\n            shell=True,\n            cwd=os.path.join(self.dir_path, \"transformers\"),\n        )\n\n        subprocess.run(", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_trainer_evaluator_parity.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.32592592592592595}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/wildcard_stable_diffusion.py\n# --------------------------------------------------\n#                 expense of slower inference.\n#             guidance_scale (`float`, *optional*, defaults to 7.5):\n#                 Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n#                 `guidance_scale` is defined as `w` of equation 2. of [Imagen\n#                 Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n#                 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n#                 usually at the expense of lower image quality.\n#             negative_prompt (`str` or `List[str]`, *optional*):\n#                 The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n#                 if `guidance_scale` is less than `1`).\n#             num_images_per_prompt (`int`, *optional*, defaults to 1):\n#                 The number of images to generate per prompt.\n#             eta (`float`, *optional*, defaults to 0.0):\n#                 Corresponds to parameter eta (\u03b7) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n#                 [`schedulers.DDIMScheduler`], will be ignored for others.\n#             generator (`torch.Generator`, *optional*):\n#                 A [torch generator](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make generation\n#                 deterministic.\n#             latents (`torch.FloatTensor`, *optional*):\n#                 Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_upscale.py\n# --------------------------------------------------\n#             image (`PIL.Image.Image` or List[`PIL.Image.Image`] or `torch.FloatTensor`):\n#                 `Image`, or tensor representing an image batch which will be upscaled. *\n#             num_inference_steps (`int`, *optional*, defaults to 50):\n#                 The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n#                 expense of slower inference.\n#             guidance_scale (`float`, *optional*, defaults to 7.5):\n#                 Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n#                 `guidance_scale` is defined as `w` of equation 2. of [Imagen\n#                 Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n#                 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n#                 usually at the expense of lower image quality.\n#             negative_prompt (`str` or `List[str]`, *optional*):\n#                 The prompt or prompts not to guide the image generation. If not defined, one has to pass\n#                 `negative_prompt_embeds`. instead. Ignored when not using guidance (i.e., ignored if `guidance_scale`\n#                 is less than `1`).\n#             num_images_per_prompt (`int`, *optional*, defaults to 1):\n#                 The number of images to generate per prompt.\n#             eta (`float`, *optional*, defaults to 0.0):\n#                 Corresponds to parameter eta (\u03b7) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n#                 [`schedulers.DDIMScheduler`], will be ignored for others.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/text_inpainting.py\n# --------------------------------------------------\n#                 The width in pixels of the generated image.\n#             num_inference_steps (`int`, *optional*, defaults to 50):\n#                 The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n#                 expense of slower inference.\n#             guidance_scale (`float`, *optional*, defaults to 7.5):\n#                 Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n#                 `guidance_scale` is defined as `w` of equation 2. of [Imagen\n#                 Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n#                 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n#                 usually at the expense of lower image quality.\n#             negative_prompt (`str` or `List[str]`, *optional*):\n#                 The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n#                 if `guidance_scale` is less than `1`).\n#             num_images_per_prompt (`int`, *optional*, defaults to 1):\n#                 The number of images to generate per prompt.\n#             eta (`float`, *optional*, defaults to 0.0):\n#                 Corresponds to parameter eta (\u03b7) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n#                 [`schedulers.DDIMScheduler`], will be ignored for others.\n#             generator (`torch.Generator`, *optional*):\n#                 A [torch generator](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make generation\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\n# --------------------------------------------------\n#                 The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n#                 expense of slower inference.\n#             guidance_scale (`float`, *optional*, defaults to 7.5):\n#                 Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n#                 `guidance_scale` is defined as `w` of equation 2. of [Imagen\n#                 Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n#                 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n#                 usually at the expense of lower image quality.\n#             negative_prompt (`str` or `List[str]`, *optional*):\n#                 The prompt or prompts not to guide the image generation. If not defined, one has to pass\n#                 `negative_prompt_embeds`. instead. If not defined, one has to pass `negative_prompt_embeds`. instead.\n#                 Ignored when not using guidance (i.e., ignored if `guidance_scale` is less than `1`).\n#             num_images_per_prompt (`int`, *optional*, defaults to 1):\n#                 The number of images to generate per prompt.\n#             eta (`float`, *optional*, defaults to 0.0):\n#                 Corresponds to parameter eta (\u03b7) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n#                 [`schedulers.DDIMScheduler`], will be ignored for others.\n#             generator (`torch.Generator` or `List[torch.Generator]`, *optional*):\n#                 One or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)\n#                 to make generation deterministic.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n isinstance(image, PIL.Image.Image):\n        image = [image]\n\n    if isinstance(image[0], PIL.Image.Image):\n        w, h = image[0].size\n        w, h = map(lambda x: x - x % 8, (w, h))  # resize to integer multiple of 8\n\n        image = [np.array(i.resize((w, h), resample=PIL_INTERPOLATION[\"lanczos\"]))[None, :] for i in image]\n        image = np.concatenate(image, axis=0)\n        image = np.array(image).astype(np.float32) / 255.0\n        image = image.transpose(0, 3, 1, 2)\n        image = 2.0 * image - 1.0\n        image = torch.from_numpy(image)\n    elif isinstance(image[0], torch.Tensor):\n        image = torch.cat(image, dim=0)\n    return image\n\n\nclass StableDiffusionInstructPix2PixPipeline(DiffusionPipeline):\n    r\"\"\"\n    Pipeline for pixel-level image editing by following text instructions. Based on Stable Diffusion.\n\n    This model inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods the\n    library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)\n\n    Args:\n        vae ([`AutoencoderKL`]):\n            Variational Auto-Encoder (VAE) Model to encode and decode images to and from latent representations.\n        text_encoder ([`CLIPTextModel`]):\n            Frozen text-encoder. Stable Diffusion uses the text portion of\n            [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel), specifically\n            the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14) variant.\n        tokenizer (`CLIPTokenizer`):\n            Tokenizer of class\n            [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).\n        unet ([`UNet2DConditionModel`]): Conditional U-Net architecture to denoise the encoded image latents.\n        scheduler ([`SchedulerMixin`]):\n            A scheduler to be used in combination with `unet` to denoise the encoded image latents. Can be one of\n            [`DDIMScheduler`], [`LMSDiscreteScheduler`], or [`PNDMScheduler`].\n        safety_checker ([`StableDiffusionSafetyChecker`]):\n            Classification module that estimates whether generated images could be considered offensive or harmful.\n            Please, refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5) for details.\n        feature_extractor ([`CLIPFeatureExtractor`]):\n            Model that extracts features from generated images to be used as inputs for the `safety_checker`.\n    \"\"\"\n    _optional_components = [\"safety_checker\", \"feature_extractor\"]\n\n    def __init__(\n        self,\n        vae: AutoencoderKL,\n        text_encoder: CLIPTextModel,\n        tokenizer: CLIPTokenizer,\n        unet: UNet2DConditionModel,\n        scheduler: KarrasDiffusionSchedulers,\n        safety_checker: StableDiffusionSafetyChecker,\n        feature_extractor: CLIPFeatureExtractor,\n        requires_safety_checker: bool = True,\n    ):\n        super().__init__()\n\n        if safety_checker is None and requires_safety_checker:\n            logger.warning(\n                f\"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure\"\n                \" that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered\"\n                \" results in services or applications open to the public. Both the diffusers team and Hugging Face\"\n                \" strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling\"\n                \" it only for use-cases that involve analyzing network behavior or auditing its results. For more\"\n                \" information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\"\n            )\n\n        if safety_checker is not None and feature_extractor is None:\n            raise ValueError(\n                \"Make sure to define a feature extractor when loading {self.__class__} if you want to use the safety\"\n                \" checker. If you do not want to use the safety checker, you can pass `'safety_checker=None'` instead.\"\n            )\n\n        self.register_modules(\n            vae=vae,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,\n            unet=unet,\n            scheduler=scheduler,\n            safety_checker=safety_checker,\n            feature_extractor=feature_extractor,\n        )\n        self.vae_scale_factor = 2 ** (len(self.vae.config.block_out_channels) - 1)\n        self.register_to_config(requires_safety_checker=requires_safety_checker)\n\n    @torch.no_grad()\n    def __call__(\n        self,\n        prompt: Union[str, List[str]] = None,\n        image: Union[torch.FloatTensor, PIL.Image.Image] = None,\n        num_inference_steps: int = 100,\n        guidance_scale: float = 7.5,\n        image_guidance_scale: float = 1.5,\n        negative_prompt: Optional[Union[str, List[str]]] = None,\n        num_images_per_prompt: Optional[int] = 1,\n        eta: float = 0.0,\n        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n        latents: Optional[torch.FloatTensor] = None,\n        prompt_embeds: Optional[torch.FloatTensor] = None,\n        negative_prompt_embeds: Optional[torch.FloatTensor] = None,\n        output_type: Optional[str] = \"pil\",\n        return_dict: bool = True,\n        callback: Optional[Callable[[int, int, torch.FloatTensor], None]] = None,\n        callback_steps: Optional[int] = 1,\n    ):\n        r\"\"\"\n        Function invoked when calling the pipeline for generation.\n\n        Args:\n             prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.\n                instead.\n            image (`PIL.Image.Image`):\n                `Image`, or tensor representing an image batch which will be repainted according to `prompt`.\n            num_inference_steps (`int`, *optional*, defaults to 100):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality. This pipeline requires a value of at least `1`.\n            image_guidance_scale (`float`, *optional*, defaults to 1.5):\n                Image guidance scale is to push the generated image towards the inital image `image`. Image guidance\n                scale is enabled by setting `image_guidance_scale > 1`. Higher image guidance scale encourages to\n                generate images that are closely linked to the source image `image`, usually at the expense of lower", "choices": [{"text": "1`."}], "metadata": {"task_id": "huggingface_diffusers/130", "ground_truth": "                image quality. This pipeline requires a value of at least `1`.", "fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_stable_diffusion_instruct_pix2pix.py"], "context_start_lineno": 38, "line_no": 168, "query_window": {"context": "\n        Args:\n             prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.\n                instead.\n            image (`PIL.Image.Image`):\n                `Image`, or tensor representing an image batch which will be repainted according to `prompt`.\n            num_inference_steps (`int`, *optional*, defaults to 100):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality. This pipeline requires a value of at least `1`.\n            image_guidance_scale (`float`, *optional*, defaults to 1.5):\n                Image guidance scale is to push the generated image towards the inital image `image`. Image guidance\n                scale is enabled by setting `image_guidance_scale > 1`. Higher image guidance scale encourages to\n                generate images that are closely linked to the source image `image`, usually at the expense of lower", "metadata": {"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_stable_diffusion_instruct_pix2pix.py"], "line_no": 168, "task_id": "huggingface_diffusers/130", "start_line_no": 148, "end_line_no": 168, "window_size": 20, "context_start_lineno": 38, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "\n        Args:\n            prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.\n                instead.\n            height (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.\n            negative_prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts not to guide the image generation. If not defined, one has to pass", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_stable_diffusion.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7530120481927711}, {"context": "            prompt (`str` or `List[str]`):\n                The prompt or prompts to guide the image generation.\n            image (`PIL.Image.Image`):\n                `Image`, or tensor representing an image batch which will be inpainted, *i.e.* parts of the image will\n                be masked out with `mask_image` and repainted according to `prompt`.\n            text (`str``):\n                The text to use to generate the mask.\n            height (`int`, *optional*, defaults to 512):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to 512):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "text_inpainting.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7426900584795322}, {"context": "        callback: Optional[Callable[[int, int, torch.FloatTensor], None]] = None,\n        callback_steps: Optional[int] = 1,\n    ):\n        r\"\"\"\n        Function invoked when calling the pipeline for generation.\n\n        Args:\n            prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.\n                instead.\n            image (`PIL.Image.Image` or List[`PIL.Image.Image`] or `torch.FloatTensor`):\n                `Image`, or tensor representing an image batch which will be upscaled. *\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stable_diffusion", "pipeline_stable_diffusion_upscale.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7336956521739131}, {"context": "\n        Args:\n            prompt (`str` or `List[str]`):\n                The prompt or prompts to guide the image generation.\n            height (`int`, *optional*, defaults to 512):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to 512):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.\n            negative_prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n                if `guidance_scale` is less than `1`).", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "wildcard_stable_diffusion.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6941176470588235}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/dataset/leaf_nlp.py\n# --------------------------------------------------\n#                     else:\n#                         continue\n#                     save_path = osp.join(self.processed_dir,\n#                                          f\"task_{reddit_idx.index(user)}\")\n#                 else:\n#                     train_data, test_data, train_targets, test_targets =\\\n#                         train_test_split(\n#                             data,\n#                             targets,\n#                             train_size=self.tr_frac,\n#                             random_state=self.seed\n#                         )\n# \n#                     if self.val_frac > 0:\n#                         try:\n#                             val_data, test_data, val_targets, test_targets = \\\n#                                 train_test_split(\n#                                     test_data,\n#                                     test_targets,\n#                                     train_size=self.val_frac / (\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/cv/dataset/leaf_cv.py\n# --------------------------------------------------\n#                         train_test_split(\n#                             test_data,\n#                             test_targets,\n#                             train_size=self.val_frac / (1.-self.tr_frac),\n#                             random_state=self.seed\n#                         )\n# \n#                 else:\n#                     val_data, val_targets = None, None\n#                 save_path = osp.join(self.processed_dir, f\"task_{idx}\")\n#                 os.makedirs(save_path, exist_ok=True)\n# \n#                 save_local_data(dir_path=save_path,\n#                                 train_data=train_data,\n#                                 train_targets=train_targets,\n#                                 test_data=test_data,\n#                                 test_targets=test_targets,\n#                                 val_data=val_data,\n#                                 val_targets=val_targets)\n#                 idx += 1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/dataset/leaf_nlp.py\n# --------------------------------------------------\n#                                     train_size=self.val_frac / (\n#                                             1.-self.tr_frac),\n#                                     random_state=self.seed\n#                                 )\n#                         except:\n#                             val_data, val_targets = None, None\n# \n#                     else:\n#                         val_data, val_targets = None, None\n#                     save_path = osp.join(self.processed_dir, f\"task_{idx}\")\n#                 os.makedirs(save_path, exist_ok=True)\n# \n#                 save_local_data(dir_path=save_path,\n#                                 train_data=train_data,\n#                                 train_targets=train_targets,\n#                                 test_data=test_data,\n#                                 test_targets=test_targets,\n#                                 val_data=val_data,\n#                                 val_targets=val_targets)\n#                 idx += 1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/dataset/leaf_twitter.py\n# --------------------------------------------------\n#                                 test_targets,\n#                                 train_size=self.val_frac / (1. - self.tr_frac),\n#                                 random_state=self.seed\n#                             )\n#                     except:\n#                         val_data, val_targets = None, None\n# \n#                 else:\n#                     val_data, val_targets = None, None\n#                 save_path = osp.join(self.processed_dir, f\"task_{idx}\")\n#                 os.makedirs(save_path, exist_ok=True)\n# \n#                 save_local_data(dir_path=save_path,\n#                                 train_data=train_data,\n#                                 train_targets=train_targets,\n#                                 test_data=test_data,\n#                                 test_targets=test_targets,\n#                                 val_data=val_data,\n#                                 val_targets=val_targets)\n#                 idx += 1\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/dataset/leaf_synthetic.py\n# --------------------------------------------------\n#     def process(self):\n#         for task_id in range(self.n_tasks):\n#             save_path = os.path.join(self.processed_dir, f\"task_{task_id}\")\n#             os.makedirs(save_path, exist_ok=True)\n# \n#             train_data, train_targets = self.generate_data(\n#                 task_id, self.num_samples[task_id])\n#             test_data, test_targets = self.generate_data(task_id, self.n_test)\n# \n#             if self.n_val > 0:\n#                 val_data, val_targets = self.generate_data(task_id, self.n_val)\n#             else:\n#                 val_data, val_targets = None, None\n#             save_local_data(dir_path=save_path,\n#                             train_data=train_data,\n#                             train_targets=train_targets,\n#                             test_data=test_data,\n#                             test_targets=test_targets,\n#                             val_data=val_data,\n#                             val_targets=val_targets)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/dataset/leaf_synthetic.py\n# --------------------------------------------------\n#     def process(self):\n#         for task_id in range(self.n_tasks):\n#             save_path = os.path.join(self.processed_dir, f\"task_{task_id}\")\n#             os.makedirs(save_path, exist_ok=True)\n# \n#             train_data, train_targets = self.generate_data(\n#                 task_id, self.num_samples[task_id])\n#             test_data, test_targets = self.generate_data(task_id, self.n_test)\n# \n#             if self.n_val > 0:\n#                 val_data, val_targets = self.generate_data(task_id, self.n_val)\n#             else:\n#                 val_data, val_targets = None, None\n#             save_local_data(dir_path=save_path,\n#                             train_data=train_data,\n#                             train_targets=train_targets,\n#                             test_data=test_data,\n#                             test_targets=test_targets,\n#                             val_data=val_data,\n#                             val_targets=val_targets)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n@')\n\n    # Comply with the original train/val/test\n    dataset = DATA_LOAD_FUNCS[package.lower()](name, splits, modified_config)\n    data_split_tuple = (dataset.get('train'), dataset.get('val'),\n                        dataset.get('test'))\n\n    return data_split_tuple, modified_config\n\n\ndef convert_data_mode(data, config):\n    \"\"\"\n    Convert ``StandaloneDataDict`` to ``ClientData`` in ``distributed`` mode.\n\n    Args:\n        data: ``StandaloneDataDict``\n        config: configuration of FL course, see `federatedscope.core.configs`\n\n    Returns:\n        ``StandaloneDataDict`` in ``standalone`` mode, or ``ClientData`` in \\\n        ``distributed`` mode.\n    \"\"\"\n    if config.federate.mode.lower() == 'standalone':\n        return data\n    else:\n        # Invalid data_idx\n        if config.distribute.data_idx == -1:\n            return data\n        elif config.distribute.data_idx not in data.keys():\n            data_idx = np.random.choice(list(data.keys()))\n            logger.warning(\n                f\"The provided data_idx={config.distribute.data_idx} is \"\n                f\"invalid, so that we randomly sample a data_idx as {data_idx}\"\n            )\n        else:\n            data_idx = config.distribute.data_idx\n        return data[data_idx]\n\n\ndef get_func_args(func):\n    \"\"\"\n    Get the set of arguments that the function expects.\n\n    Args:\n        func: function to be analysis\n\n    Returns:\n        Arguments  that the function expects\n    \"\"\"\n    sign = inspect.signature(func).parameters.values()\n    sign = set([val.name for val in sign])\n    return sign\n\n\ndef filter_dict(func, kwarg):\n    \"\"\"\n    Filters out the common keys of kwarg that are not in kwarg.\n\n    Args:\n        func: function to be filtered\n        kwarg: dict to filter\n\n    Returns:\n        Filtered dict of arguments of the function.\n    \"\"\"\n    sign = get_func_args(func)\n    common_args = sign.intersection(kwarg.keys())\n    filtered_dict = {key: kwarg[key] for key in common_args}\n    return filtered_dict\n\n\ndef merge_data(all_data, merged_max_data_id=None, specified_dataset_name=None):\n    \"\"\"\n    Merge data from client 1 to ``merged_max_data_id`` contained in given \\\n    ``all_data``.\n\n    Args:\n        all_data: ``StandaloneDataDict``\n        merged_max_data_id: max merged data index\n        specified_dataset_name: split name to be merged\n\n    Returns:\n        Merged data.\n    \"\"\"\n    import torch.utils.data\n    from federatedscope.core.data.wrap_dataset import WrapDataset\n\n    # Assert\n    if merged_max_data_id is None:\n        merged_max_data_id = len(all_data) - 1\n    assert merged_max_data_id >= 1\n    if specified_dataset_name is None:\n        dataset_names = list(all_data[1].keys())  # e.g., train, test, val\n    else:\n        if not isinstance(specified_dataset_name, list):\n            specified_dataset_name = [specified_dataset_name]\n        dataset_names = specified_dataset_name\n    assert len(dataset_names) >= 1, \\\n        \"At least one sub-dataset is required in client 1\"\n\n    data_name = \"test\" if \"test\" in dataset_names else dataset_names[0]\n    id_contain_all_dataset_key = -1\n    # check the existence of the data to be merged\n    for client_id in range(1, merged_max_data_id + 1):\n        contain_all_dataset_key = True\n        for dataset_name in dataset_names:\n            if dataset_name not in all_data[client_id]:\n                contain_all_dataset_key = False\n                logger.warning(f'Client {client_id} does not contain '\n                               f'dataset key {dataset_name}.')\n        if id_contain_all_dataset_key == -1 and contain_all_dataset_key:\n            id_contain_all_dataset_key = client_id\n    assert id_contain_all_dataset_key != -1, \\\n        \"At least one client within [1, merged_max_data_id] should contain \" \\\n        \"all the key for expected dataset names.\"\n\n    if issubclass(type(all_data[id_contain_all_dataset_key][data_name]),\n                  torch.utils.data.DataLoader):\n        if isinstance(all_data[id_contain_all_dataset_key][data_name].dataset,\n                      WrapDataset):\n            # e.g., x, y\n            data_elem_names = list(all_data[id_contain_all_dataset_key]\n                                   [data_name].dataset.dataset.keys())\n            merged_data = {name: defaultdict(list) for name in dataset_names}\n            for data_id in range(1, merged_max_data_id + 1):\n                for d_name in dataset_names:\n                    if d_name not in all_data[data_id]:\n                        continue\n                    for elem_name in data_elem_names:\n                        merged_data[d_name][elem_name].append(\n                            all_data[data_id]\n                            [d_name].dataset.dataset[elem_name])\n            for d_name in dataset_names:\n                for elem_name in data_elem_names:\n                    merged_data[d_name][elem_name] = np.concatenate(\n                        merged_data[d_name][elem_name])\n                merged_data[d_name] = WrapDataset(merged_data[d_name])\n        else:\n            client_data = {\n                key: []\n                for key in all_data[id_contain_all_dataset_key].keys()\n            }\n            for data_id in range(1, merged_max_data_id + 1):\n                for d_name in dataset_names:\n                    if d_name not in all_data[data_id]:\n                        continue\n                    else:\n                        client_data[d_name].append(\n                            all_data[data_id][d_name].dataset)\n            merged_data = {\n                key: torch.utils.data.ConcatDataset(client_data[key])\n                for key in dataset_names\n            }\n    else:\n        raise NotImplementedError(\n            \"Un-supported type when merging data across different clients.\"\n            f\"Your data type is \"\n            f\"{type(all_data[id_contain_all_dataset_key][data_name])}. \"\n            f\"Currently we only support the following forms: \"\n            \" 1): {data_id: {train: {x:ndarray, y:ndarray}} }\"\n            \" 2): {data_id: {train: DataLoader }\")\n    return merged_data\n\n\ndef save_local_data(dir_path,\n                    train_data=None,\n                    train_targets=None,\n                    test_data=None,\n                    test_targets=None,\n                    val_data=None,\n                    val_targets=None):\n    r\"\"\"\n    Save data to disk. Source: \\\n    https://github.com/omarfoq/FedEM/blob/main/data/femnist/generate_data.py\n\n    Args:\n        train_data: x of train data\n        train_targets: y of train data\n        test_data: x of test data", "choices": [{"text": "test_targets: y of test data"}], "metadata": {"task_id": "alibaba_FederatedScope/90", "ground_truth": "        test_targets: y of test data", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "data", "utils.py"], "context_start_lineno": 534, "line_no": 713, "query_window": {"context": "            \" 1): {data_id: {train: {x:ndarray, y:ndarray}} }\"\n            \" 2): {data_id: {train: DataLoader }\")\n    return merged_data\n\n\ndef save_local_data(dir_path,\n                    train_data=None,\n                    train_targets=None,\n                    test_data=None,\n                    test_targets=None,\n                    val_data=None,\n                    val_targets=None):\n    r\"\"\"\n    Save data to disk. Source: \\\n    https://github.com/omarfoq/FedEM/blob/main/data/femnist/generate_data.py\n\n    Args:\n        train_data: x of train data\n        train_targets: y of train data\n        test_data: x of test data", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "data", "utils.py"], "line_no": 713, "task_id": "alibaba_FederatedScope/90", "start_line_no": 693, "end_line_no": 713, "window_size": 20, "context_start_lineno": 534, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "            if self.n_val > 0:\n                val_data, val_targets = self.generate_data(task_id, self.n_val)\n            else:\n                val_data, val_targets = None, None\n            save_local_data(dir_path=save_path,\n                            train_data=train_data,\n                            train_targets=train_targets,\n                            test_data=test_data,\n                            test_targets=test_targets,\n                            val_data=val_data,\n                            val_targets=val_targets)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "dataset", "leaf_synthetic.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 201, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.25274725274725274}, {"context": "\n    def process(self):\n        for task_id in range(self.n_tasks):\n            save_path = os.path.join(self.processed_dir, f\"task_{task_id}\")\n            os.makedirs(save_path, exist_ok=True)\n\n            train_data, train_targets = self.generate_data(\n                task_id, self.num_samples[task_id])\n            test_data, test_targets = self.generate_data(task_id, self.n_test)\n\n            if self.n_val > 0:\n                val_data, val_targets = self.generate_data(task_id, self.n_val)\n            else:\n                val_data, val_targets = None, None\n            save_local_data(dir_path=save_path,\n                            train_data=train_data,\n                            train_targets=train_targets,\n                            test_data=test_data,\n                            test_targets=test_targets,\n                            val_data=val_data,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "dataset", "leaf_synthetic.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.24786324786324787}, {"context": "                        val_data, val_targets = None, None\n\n                else:\n                    val_data, val_targets = None, None\n                save_path = osp.join(self.processed_dir, f\"task_{idx}\")\n                os.makedirs(save_path, exist_ok=True)\n\n                save_local_data(dir_path=save_path,\n                                train_data=train_data,\n                                train_targets=train_targets,\n                                test_data=test_data,\n                                test_targets=test_targets,\n                                val_data=val_data,\n                                val_targets=val_targets)\n                idx += 1", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "dataset", "leaf_twitter.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 225, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.24761904761904763}, {"context": "                                            1.-self.tr_frac),\n                                    random_state=self.seed\n                                )\n                        except:\n                            val_data, val_targets = None, None\n\n                    else:\n                        val_data, val_targets = None, None\n                    save_path = osp.join(self.processed_dir, f\"task_{idx}\")\n                os.makedirs(save_path, exist_ok=True)\n\n                save_local_data(dir_path=save_path,\n                                train_data=train_data,\n                                train_targets=train_targets,\n                                test_data=test_data,\n                                test_targets=test_targets,\n                                val_data=val_data,\n                                val_targets=val_targets)\n                idx += 1", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "dataset", "leaf_nlp.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 269, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.23684210526315788}, {"context": "                            test_targets,\n                            train_size=self.val_frac / (1.-self.tr_frac),\n                            random_state=self.seed\n                        )\n\n                else:\n                    val_data, val_targets = None, None\n                save_path = osp.join(self.processed_dir, f\"task_{idx}\")\n                os.makedirs(save_path, exist_ok=True)\n\n                save_local_data(dir_path=save_path,\n                                train_data=train_data,\n                                train_targets=train_targets,\n                                test_data=test_data,\n                                test_targets=test_targets,\n                                val_data=val_data,\n                                val_targets=val_targets)\n                idx += 1", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "cv", "dataset", "leaf_cv.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 178, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.23076923076923078}, {"context": "                    train_targets, test_targets, val_targets = None, None, None\n                    if file.startswith('train'):\n                        train_data = data\n                        train_targets = targets\n                    elif file.startswith('test'):\n                        test_data = data\n                        test_targets = targets\n                    elif file.startswith('val'):\n                        val_data = data\n                        val_targets = targets\n                    else:\n                        continue\n                    save_path = osp.join(self.processed_dir,\n                                         f\"task_{reddit_idx.index(user)}\")\n                else:\n                    train_data, test_data, train_targets, test_targets =\\\n                        train_test_split(\n                            data,\n                            targets,\n                            train_size=self.tr_frac,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "dataset", "leaf_nlp.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.22807017543859648}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/worker/vertical_client.py\n# --------------------------------------------------\n# \n#     def callback_funcs_for_public_keys(self, message: Message):\n#         self.public_key = message.content\n# \n#     def callback_funcs_for_model_para(self, message: Message):\n#         self.theta = message.content\n#         if self.own_label:\n#             index, input_x, input_y = self.sample_data()\n#             self.batch_index = index\n#             u_A = 0.25 * np.matmul(input_x, self.theta) - 0.5 * input_y\n#             en_u_A = [self.public_key.encrypt(x) for x in u_A]\n# \n#             self.comm_manager.send(\n#                 Message(msg_type='encryped_gradient_u',\n#                         sender=self.ID,\n#                         receiver=[\n#                             each for each in self.comm_manager.neighbors\n#                             if each != self.server_id\n#                         ],\n#                         state=self.state,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/sampler.py\n# --------------------------------------------------\n#         \"\"\"\n#         if shuffle:\n#             self.candidate_iterator = self.permutation()\n# \n#         sampled_clients = list()\n#         for i in range(size):\n#             # To find an idle client\n#             while True:\n#                 try:\n#                     item = next(self.candidate_iterator)\n#                 except StopIteration:\n#                     self.candidate_iterator = self.permutation()\n#                     item = next(self.candidate_iterator)\n# \n#                 if self.client_state[item] == 1:\n#                     break\n# \n#             sampled_clients.append(item)\n#             self.change_state(item, 'working')\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/worker/vertical_client.py\n# --------------------------------------------------\n#         self.dataloader = batch_iter(self.data['train'],\n#                                      self._cfg.dataloader.batch_size,\n#                                      shuffled=True)\n# \n#     def sample_data(self, index=None):\n#         if index is None:\n#             assert self.own_label\n#             return next(self.dataloader)\n#         else:\n#             return self.data['train']['x'][index]\n# \n#     def callback_funcs_for_public_keys(self, message: Message):\n#         self.public_key = message.content\n# \n#     def callback_funcs_for_model_para(self, message: Message):\n#         self.theta = message.content\n#         if self.own_label:\n#             index, input_x, input_y = self.sample_data()\n#             self.batch_index = index\n#             u_A = 0.25 * np.matmul(input_x, self.theta) - 0.5 * input_y\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/trainer/trainer.py\n# --------------------------------------------------\n#                                      shuffled=True)\n#         self.criterion = get_vertical_loss(self.cfg.criterion.type)\n#         batch_index, self.batch_x, self.batch_y = self._fetch_train_data(index)\n#         feature_order = self._get_feature_order(self.batch_x)\n#         if index is None:\n#             self.batch_y_hat = np.random.uniform(low=0.0,\n#                                                  high=1.0,\n#                                                  size=len(self.batch_y))\n#             self.batch_z = 0\n#         return batch_index, feature_order\n# \n#     def train(self, feature_order=None, tree_num=0, node_num=None):\n#         # Start to build a tree\n#         if node_num is None:\n#             if tree_num == 0 and feature_order is not None:\n#                 self.feature_order = feature_order\n#             return self._compute_for_root(tree_num=tree_num)\n#         # Continue training\n#         else:\n#             return self._compute_for_node(tree_num, node_num)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/dataloader/utils.py\n# --------------------------------------------------\n#         batch_size (int): the batch size\n#         shuffled (bool): whether to shuffle the data at the start of each epoch\n#     :returns: sample index, batch of x, batch_of y\n#     :rtype: int, ndarray, ndarry\n#     \"\"\"\n# \n#     assert 'x' in data and 'y' in data\n#     data_x = data['x']\n#     data_y = data['y']\n#     data_size = len(data_y)\n#     num_batches_per_epoch = math.ceil(data_size / batch_size)\n# \n#     while True:\n#         shuffled_index = np.random.permutation(\n#             np.arange(data_size)) if shuffled else np.arange(data_size)\n#         for batch in range(num_batches_per_epoch):\n#             start_index = batch * batch_size\n#             end_index = min(data_size, (batch + 1) * batch_size)\n#             sample_index = shuffled_index[start_index:end_index]\n#             yield sample_index, data_x[sample_index], data_y[sample_index]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/dataloader/utils.py\n# --------------------------------------------------\n#         batch_size (int): the batch size\n#         shuffled (bool): whether to shuffle the data at the start of each epoch\n#     :returns: sample index, batch of x, batch_of y\n#     :rtype: int, ndarray, ndarry\n#     \"\"\"\n# \n#     assert 'x' in data and 'y' in data\n#     data_x = data['x']\n#     data_y = data['y']\n#     data_size = len(data_y)\n#     num_batches_per_epoch = math.ceil(data_size / batch_size)\n# \n#     while True:\n#         shuffled_index = np.random.permutation(\n#             np.arange(data_size)) if shuffled else np.arange(data_size)\n#         for batch in range(num_batches_per_epoch):\n#             start_index = batch * batch_size\n#             end_index = min(data_size, (batch + 1) * batch_size)\n#             sample_index = shuffled_index[start_index:end_index]\n#             yield sample_index, data_x[sample_index], data_y[sample_index]\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport logging\nimport math\nimport os\nimport random\nimport signal\nimport pickle\n\nimport numpy as np\n\ntry:\n    import torch\nexcept ImportError:\n    torch = None\n\ntry:\n    import tensorflow as tf\nexcept ImportError:\n    tf = None\n\nlogger = logging.getLogger(__name__)\n\n\n# ****** Worker-related utils ******\nclass Timeout(object):\n    def __init__(self, seconds, max_failure=5):\n        self.seconds = seconds\n        self.max_failure = max_failure\n\n    def __enter__(self):\n        def signal_handler(signum, frame):\n            raise TimeoutError()\n\n        if self.seconds > 0:\n            signal.signal(signal.SIGALRM, signal_handler)\n            signal.alarm(self.seconds)\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        signal.alarm(0)\n\n    def reset(self):\n        signal.alarm(self.seconds)\n\n    def block(self):\n        signal.alarm(0)\n\n    def exceed_max_failure(self, num_failure):\n        return num_failure > self.max_failure\n\n\ndef batch_iter(data, batch_size=64, shuffled=True):\n    assert 'x' in data and 'y' in data\n    data_x = data['x']\n    data_y = data['y']\n    data_size = len(data_y)\n    num_batches_per_epoch = math.ceil(data_size / batch_size)\n\n    while True:\n        shuffled_index = np.random.permutation(\n            np.arange(data_size)) if shuffled else np.arange(data_size)\n        for batch in range(num_batches_per_epoch):", "choices": [{"text": "start_index = batch * batch_size"}], "metadata": {"task_id": "alibaba_FederatedScope/57", "ground_truth": "            start_index = batch * batch_size", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "auxiliaries", "utils.py"], "context_start_lineno": 0, "line_no": 61, "query_window": {"context": "        signal.alarm(self.seconds)\n\n    def block(self):\n        signal.alarm(0)\n\n    def exceed_max_failure(self, num_failure):\n        return num_failure > self.max_failure\n\n\ndef batch_iter(data, batch_size=64, shuffled=True):\n    assert 'x' in data and 'y' in data\n    data_x = data['x']\n    data_y = data['y']\n    data_size = len(data_y)\n    num_batches_per_epoch = math.ceil(data_size / batch_size)\n\n    while True:\n        shuffled_index = np.random.permutation(\n            np.arange(data_size)) if shuffled else np.arange(data_size)\n        for batch in range(num_batches_per_epoch):", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "auxiliaries", "utils.py"], "line_no": 61, "task_id": "alibaba_FederatedScope/57", "start_line_no": 41, "end_line_no": 61, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "        batch_size (int): the batch size\n        shuffled (bool): whether to shuffle the data at the start of each epoch\n    :returns: sample index, batch of x, batch_of y\n    :rtype: int, ndarray, ndarry\n    \"\"\"\n\n    assert 'x' in data and 'y' in data\n    data_x = data['x']\n    data_y = data['y']\n    data_size = len(data_y)\n    num_batches_per_epoch = math.ceil(data_size / batch_size)\n\n    while True:\n        shuffled_index = np.random.permutation(\n            np.arange(data_size)) if shuffled else np.arange(data_size)\n        for batch in range(num_batches_per_epoch):\n            start_index = batch * batch_size\n            end_index = min(data_size, (batch + 1) * batch_size)\n            sample_index = shuffled_index[start_index:end_index]\n            yield sample_index, data_x[sample_index], data_y[sample_index]", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "dataloader", "utils.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.46551724137931033}, {"context": "import numpy as np\nimport math\n\n\ndef batch_iter(data, batch_size, shuffled=True):\n    \"\"\"\n    A batch iteration\n\n    Arguments:\n        data(dict): data\n        batch_size (int): the batch size\n        shuffled (bool): whether to shuffle the data at the start of each epoch\n    :returns: sample index, batch of x, batch_of y\n    :rtype: int, ndarray, ndarry\n    \"\"\"\n\n    assert 'x' in data and 'y' in data\n    data_x = data['x']\n    data_y = data['y']\n    data_size = len(data_y)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "dataloader", "utils.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2972972972972973}, {"context": "        self.eta = config.train.optimizer.eta\n\n        self.batch_x = None\n        self.batch_y = None\n        self.batch_y_hat = None\n        self.batch_z = None\n\n    def prepare_for_train(self, index=None):\n        self.dataloader = batch_iter(self.data['train'],\n                                     self.cfg.dataloader.batch_size,\n                                     shuffled=True)\n        self.criterion = get_vertical_loss(self.cfg.criterion.type)\n        batch_index, self.batch_x, self.batch_y = self._fetch_train_data(index)\n        feature_order = self._get_feature_order(self.batch_x)\n        if index is None:\n            self.batch_y_hat = np.random.uniform(low=0.0,\n                                                 high=1.0,\n                                                 size=len(self.batch_y))\n            self.batch_z = 0\n        return batch_index, feature_order", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "trainer", "trainer.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2966101694915254}, {"context": "                               self.callback_funcs_for_public_keys)\n        self.register_handlers('model_para',\n                               self.callback_funcs_for_model_para)\n        self.register_handlers('encryped_gradient_u',\n                               self.callback_funcs_for_encryped_gradient_u)\n        self.register_handlers('encryped_gradient_v',\n                               self.callback_funcs_for_encryped_gradient_v)\n\n    def _init_data_related_var(self):\n        self.own_label = ('y' in self.data['train'])\n        self.dataloader = batch_iter(self.data['train'],\n                                     self._cfg.dataloader.batch_size,\n                                     shuffled=True)\n\n    def sample_data(self, index=None):\n        if index is None:\n            assert self.own_label\n            return next(self.dataloader)\n        else:\n            return self.data['train']['x'][index]", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "worker", "vertical_client.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2786885245901639}, {"context": "        permutation = np.random.permutation(np.arange(self.bins))\n        for i in permutation:\n            np.random.shuffle(self.grouped_clients[i])\n            candidates.extend(self.grouped_clients[i])\n\n        return iter(candidates)\n\n    def sample(self, size, shuffle=False):\n        \"\"\"\n        To sample clients\n        \"\"\"\n        if shuffle:\n            self.candidate_iterator = self.permutation()\n\n        sampled_clients = list()\n        for i in range(size):\n            # To find an idle client\n            while True:\n                try:\n                    item = next(self.candidate_iterator)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "sampler.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.27586206896551724}, {"context": "        self.dataloader = batch_iter(self.data['train'],\n                                     self._cfg.dataloader.batch_size,\n                                     shuffled=True)\n\n    def sample_data(self, index=None):\n        if index is None:\n            assert self.own_label\n            return next(self.dataloader)\n        else:\n            return self.data['train']['x'][index]\n\n    def callback_funcs_for_public_keys(self, message: Message):\n        self.public_key = message.content\n\n    def callback_funcs_for_model_para(self, message: Message):\n        self.theta = message.content\n        if self.own_label:\n            index, input_x, input_y = self.sample_data()\n            self.batch_index = index\n            u_A = 0.25 * np.matmul(input_x, self.theta) - 0.5 * input_y", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "worker", "vertical_client.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.27419354838709675}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#     @pytest.mark.parametrize(\"safe\", [True, False])\n#     @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n#     def test_functional_with_buffer_probabilistic(self, safe, spec_type):\n#         torch.manual_seed(0)\n#         param_multiplier = 2\n# \n#         tdnet = SafeModule(\n#             module=NormalParamWrapper(nn.BatchNorm1d(32 * param_multiplier)),\n#             spec=None,\n#             in_keys=[\"in\"],\n#             out_keys=[\"loc\", \"scale\"],\n#         )\n# \n#         if spec_type is None:\n#             spec = None\n#         elif spec_type == \"bounded\":\n#             spec = BoundedTensorSpec(-0.1, 0.1, 32)\n#         elif spec_type == \"unbounded\":\n#             spec = UnboundedContinuousTensorSpec(32)\n#         else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n# \n#         net = nn.Linear(3, 4 * param_multiplier)\n# \n#         if spec_type is None:\n#             spec = None\n#         elif spec_type == \"bounded\":\n#             spec = BoundedTensorSpec(-0.1, 0.1, 4)\n#         elif spec_type == \"unbounded\":\n#             spec = UnboundedContinuousTensorSpec(4)\n# \n#         if safe and spec is None:\n#             with pytest.raises(\n#                 RuntimeError,\n#                 match=\"is not a valid configuration as the tensor specs are not \"\n#                 \"specified\",\n#             ):\n#                 tdmodule = SafeModule(\n#                     spec=spec,\n#                     module=net,\n#                     in_keys=[\"in\"],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#     @pytest.mark.parametrize(\"safe\", [True, False])\n#     @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n#     def test_functional_with_buffer(self, safe, spec_type):\n#         torch.manual_seed(0)\n#         param_multiplier = 1\n# \n#         net = nn.BatchNorm1d(32 * param_multiplier)\n#         params = make_functional(net)\n# \n#         if spec_type is None:\n#             spec = None\n#         elif spec_type == \"bounded\":\n#             spec = BoundedTensorSpec(-0.1, 0.1, 32)\n#         elif spec_type == \"unbounded\":\n#             spec = UnboundedContinuousTensorSpec(32)\n# \n#         if safe and spec is None:\n#             with pytest.raises(\n#                 RuntimeError,\n#                 match=\"is not a valid configuration as the tensor specs are not \"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#     @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n#     def test_functional_probabilistic(self, safe, spec_type):\n#         torch.manual_seed(0)\n#         param_multiplier = 2\n# \n#         tdnet = SafeModule(\n#             module=NormalParamWrapper(nn.Linear(3, 4 * param_multiplier)),\n#             spec=None,\n#             in_keys=[\"in\"],\n#             out_keys=[\"loc\", \"scale\"],\n#         )\n# \n#         if spec_type is None:\n#             spec = None\n#         elif spec_type == \"bounded\":\n#             spec = BoundedTensorSpec(-0.1, 0.1, 4)\n#         elif spec_type == \"unbounded\":\n#             spec = UnboundedContinuousTensorSpec(4)\n#         else:\n#             raise NotImplementedError\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#         else:\n#             net = nn.Linear(3, 4 * param_multiplier)\n# \n#         if spec_type is None:\n#             spec = None\n#         elif spec_type == \"bounded\":\n#             spec = BoundedTensorSpec(-0.1, 0.1, 4)\n#         elif spec_type == \"unbounded\":\n#             spec = UnboundedContinuousTensorSpec(4)\n# \n#         if safe and spec is None:\n#             with pytest.raises(\n#                 RuntimeError,\n#                 match=\"is not a valid configuration as the tensor specs are not \"\n#                 \"specified\",\n#             ):\n#                 tensordict_module = SafeModule(\n#                     module=net,\n#                     spec=spec,\n#                     in_keys=[\"in\"],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#     def test_functional(self, safe, spec_type):\n#         torch.manual_seed(0)\n#         param_multiplier = 1\n# \n#         net = nn.Linear(3, 4 * param_multiplier)\n# \n#         params = make_functional(net)\n# \n#         if spec_type is None:\n#             spec = None\n#         elif spec_type == \"bounded\":\n#             spec = BoundedTensorSpec(-0.1, 0.1, 4)\n#         elif spec_type == \"unbounded\":\n#             spec = UnboundedContinuousTensorSpec(4)\n# \n#         if safe and spec is None:\n#             with pytest.raises(\n#                 RuntimeError,\n#                 match=\"is not a valid configuration as the tensor specs are not \"\n#                 \"specified\",\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#         torch.manual_seed(0)\n#         param_multiplier = 2\n#         if lazy:\n#             net = nn.LazyLinear(4 * param_multiplier)\n#         else:\n#             net = nn.Linear(3, 4 * param_multiplier)\n# \n#         in_keys = [\"in\"]\n#         net = SafeModule(\n#             module=NormalParamWrapper(net),\n#             spec=None,\n#             in_keys=in_keys,\n#             out_keys=out_keys,\n#         )\n# \n#         if spec_type is None:\n#             spec = None\n#         elif spec_type == \"bounded\":\n#             spec = BoundedTensorSpec(-0.1, 0.1, 4)\n#         elif spec_type == \"unbounded\":\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n        else:\n            raise NotImplementedError\n\n        kwargs = {\"distribution_class\": TanhNormal}\n\n        if safe and spec is None:\n            with pytest.raises(\n                RuntimeError,\n                match=\"is not a valid configuration as the tensor specs are not \"\n                \"specified\",\n            ):\n                prob_module = SafeProbabilisticModule(\n                    in_keys=[\"loc\", \"scale\"],\n                    out_keys=[\"out\"],\n                    spec=spec,\n                    safe=safe,\n                    **kwargs,\n                )\n            return\n        else:\n            prob_module = SafeProbabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=safe,\n                **kwargs,\n            )\n\n        tdmodule = SafeProbabilisticSequential(tdnet, prob_module)\n        params = make_functional(tdmodule)\n\n        # vmap = True\n        params = params.expand(10)\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        if safe and spec_type == \"bounded\":\n            with pytest.raises(\n                RuntimeError, match=\"vmap cannot be used with safe=True\"\n            ):\n                td_out = vmap(tdmodule, (None, 0))(td, params)\n            return\n        else:\n            td_out = vmap(tdmodule, (None, 0))(td, params)\n        assert td_out is not td\n        assert td_out.shape == torch.Size([10, 3])\n        assert td_out.get(\"out\").shape == torch.Size([10, 3, 4])\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td_out.get(\"out\") > 0.1) | (td_out.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td_out.get(\"out\") < 0.1) | (td_out.get(\"out\") > -0.1)).all()\n\n        # vmap = (0, 0)\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        td_repeat = td.expand(10, *td.batch_size)\n        td_out = vmap(tdmodule, (0, 0))(td_repeat, params)\n        assert td_out is not td\n        assert td_out.shape == torch.Size([10, 3])\n        assert td_out.get(\"out\").shape == torch.Size([10, 3, 4])\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td_out.get(\"out\") > 0.1) | (td_out.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td_out.get(\"out\") < 0.1) | (td_out.get(\"out\") > -0.1)).all()\n\n\nclass TestTDSequence:\n    def test_in_key_warning(self):\n        with pytest.warns(UserWarning, match='key \"_\" is for ignoring output'):\n            tensordict_module = SafeModule(\n                nn.Linear(3, 4), in_keys=[\"_\"], out_keys=[\"out1\"]\n            )\n        with pytest.warns(UserWarning, match='key \"_\" is for ignoring output'):\n            tensordict_module = SafeModule(\n                nn.Linear(3, 4), in_keys=[\"_\", \"key2\"], out_keys=[\"out1\"]\n            )\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    @pytest.mark.parametrize(\"lazy\", [True, False])\n    def test_stateful(self, safe, spec_type, lazy):\n        torch.manual_seed(0)\n        param_multiplier = 1\n        if lazy:\n            net1 = nn.LazyLinear(4)\n            dummy_net = nn.LazyLinear(4)\n            net2 = nn.LazyLinear(4 * param_multiplier)\n        else:\n            net1 = nn.Linear(3, 4)\n            dummy_net = nn.Linear(4, 4)\n            net2 = nn.Linear(4, 4 * param_multiplier)\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n\n        kwargs = {}\n\n        if safe and spec is None:\n            pytest.skip(\"safe and spec is None is checked elsewhere\")\n        else:\n            tdmodule1 = SafeModule(\n                net1,\n                spec=None,\n                in_keys=[\"in\"],\n                out_keys=[\"hidden\"],\n                safe=False,\n            )\n            dummy_tdmodule = SafeModule(\n                dummy_net,\n                spec=None,\n                in_keys=[\"hidden\"],\n                out_keys=[\"hidden\"],\n                safe=False,\n            )\n            tdmodule2 = SafeModule(\n                spec=spec,\n                module=net2,\n                in_keys=[\"hidden\"],\n                out_keys=[\"out\"],\n                safe=False,\n                **kwargs,\n            )\n            tdmodule = SafeSequential(tdmodule1, dummy_tdmodule, tdmodule2)\n\n        assert hasattr(tdmodule, \"__setitem__\")\n        assert len(tdmodule) == 3\n        tdmodule[1] = tdmodule2\n        assert len(tdmodule) == 3\n\n        assert hasattr(tdmodule, \"__delitem__\")\n        assert len(tdmodule) == 3\n        del tdmodule[2]\n        assert len(tdmodule) == 2\n\n        assert hasattr(tdmodule, \"__getitem__\")\n        assert tdmodule[0] is tdmodule1\n        assert tdmodule[1] is tdmodule2\n\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        tdmodule(td)\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 4])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    @pytest.mark.parametrize(\"lazy\", [True, False])\n    def test_stateful_probabilistic(self, safe, spec_type, lazy):\n        torch.manual_seed(0)\n        param_multiplier = 2\n        if lazy:\n            net1 = nn.LazyLinear(4)\n            dummy_net = nn.LazyLinear(4)\n            net2 = nn.LazyLinear(4 * param_multiplier)\n        else:\n            net1 = nn.Linear(3, 4)\n            dummy_net = nn.Linear(4, 4)\n            net2 = nn.Linear(4, 4 * param_multiplier)\n        net2 = NormalParamWrapper(net2)\n\n        if spec_type is None:", "choices": [{"text": "spec = None"}], "metadata": {"task_id": "pytorch_rl/23", "ground_truth": "            spec = None", "fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "context_start_lineno": 542, "line_no": 717, "query_window": {"context": "        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    @pytest.mark.parametrize(\"lazy\", [True, False])\n    def test_stateful_probabilistic(self, safe, spec_type, lazy):\n        torch.manual_seed(0)\n        param_multiplier = 2\n        if lazy:\n            net1 = nn.LazyLinear(4)\n            dummy_net = nn.LazyLinear(4)\n            net2 = nn.LazyLinear(4 * param_multiplier)\n        else:\n            net1 = nn.Linear(3, 4)\n            dummy_net = nn.Linear(4, 4)\n            net2 = nn.Linear(4, 4 * param_multiplier)\n        net2 = NormalParamWrapper(net2)\n\n        if spec_type is None:", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 717, "task_id": "pytorch_rl/23", "start_line_no": 697, "end_line_no": 717, "window_size": 20, "context_start_lineno": 542, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    @pytest.mark.parametrize(\"out_keys\", [[\"loc\", \"scale\"], [\"loc_1\", \"scale_1\"]])\n    @pytest.mark.parametrize(\"lazy\", [True, False])\n    @pytest.mark.parametrize(\"exp_mode\", [\"mode\", \"random\", None])\n    def test_stateful_probabilistic(self, safe, spec_type, lazy, exp_mode, out_keys):\n        torch.manual_seed(0)\n        param_multiplier = 2\n        if lazy:\n            net = nn.LazyLinear(4 * param_multiplier)\n        else:\n            net = nn.Linear(3, 4 * param_multiplier)\n\n        in_keys = [\"in\"]\n        net = SafeModule(\n            module=NormalParamWrapper(net),", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.8}, {"context": "        assert td.get(\"out\").shape == torch.Size([3, 4])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    def test_functional(self, safe, spec_type):\n        torch.manual_seed(0)\n        param_multiplier = 1\n\n        net = nn.Linear(3, 4 * param_multiplier)\n\n        params = make_functional(net)\n\n        if spec_type is None:\n            spec = None", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7256637168141593}, {"context": "            )\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    @pytest.mark.parametrize(\"lazy\", [True, False])\n    def test_stateful(self, safe, spec_type, lazy):\n        torch.manual_seed(0)\n        param_multiplier = 1\n        if lazy:\n            net = nn.LazyLinear(4 * param_multiplier)\n        else:\n            net = nn.Linear(3, 4 * param_multiplier)\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6727272727272727}, {"context": "        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 4])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    def test_functional_probabilistic(self, safe, spec_type):\n        torch.manual_seed(0)\n        param_multiplier = 2\n\n        tdnet = SafeModule(\n            module=NormalParamWrapper(nn.Linear(3, 4 * param_multiplier)),\n            spec=None,\n            in_keys=[\"in\"],\n            out_keys=[\"loc\", \"scale\"],", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.664}, {"context": "        tensordict_module(td, params=params)\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 4])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    def test_functional_with_buffer(self, safe, spec_type):\n        torch.manual_seed(0)\n        param_multiplier = 1\n\n        net = nn.BatchNorm1d(32 * param_multiplier)\n        params = make_functional(net)\n\n        if spec_type is None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6349206349206349}, {"context": "            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.skipif(\n        not _has_functorch, reason=\"vmap can only be used with functorch\"\n    )\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    def test_vmap(self, safe, spec_type):\n        torch.manual_seed(0)\n        param_multiplier = 1\n\n        net = nn.Linear(3, 4 * param_multiplier)\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6328125}, {"context": "        tdmodule(td, params=params)\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 32])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    def test_functional_with_buffer_probabilistic(self, safe, spec_type):\n        torch.manual_seed(0)\n        param_multiplier = 2\n\n        tdnet = SafeModule(\n            module=NormalParamWrapper(nn.BatchNorm1d(32 * param_multiplier)),\n            spec=None,\n            in_keys=[\"in\"],", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6015037593984962}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env/ding_env_wrapper.py\n# --------------------------------------------------\n#                 value={\n#                     'min': obs_space.low,\n#                     'max': obs_space.high,\n#                     'dtype': np.float32\n#                 },\n#             ),\n#             act_space=EnvElementInfo(\n#                 shape=(act_space.n, ),\n#                 value={\n#                     'min': 0,\n#                     'max': act_space.n,\n#                     'dtype': np.float32\n#                 },\n#             ),\n#             rew_space=EnvElementInfo(\n#                 shape=1,\n#                 value={\n#                     'min': -1,\n#                     'max': 1,\n#                     'dtype': np.float32\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env/base_env.py\n# --------------------------------------------------\n#         \"\"\"\n#         collector_env_num = cfg.pop('collector_env_num')\n#         return [cfg for _ in range(collector_env_num)]\n# \n#     @staticmethod\n#     def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n#         \"\"\"\n#         Overview:\n#             Return a list of all of the environment from input config.\n#         Arguments:\n#             - cfg (:obj:`Dict`) Env config, same config where ``self.__init__()`` takes arguments from\n#         Returns:\n#             - List of ``cfg`` including all of the evaluator env's config\n#         \"\"\"\n#         evaluator_env_num = cfg.pop('evaluator_env_num')\n#         return [cfg for _ in range(evaluator_env_num)]\n# \n#     # optional method\n#     def enable_save_replay(self, replay_path: str) -> None:\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env/ding_env_wrapper.py\n# --------------------------------------------------\n#         cfg = copy.deepcopy(cfg)\n#         cfg.is_train = True\n#         return [cfg for _ in range(actor_env_num)]\n# \n#     @staticmethod\n#     def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n#         evaluator_env_num = cfg.pop('evaluator_env_num')\n#         cfg = copy.deepcopy(cfg)\n#         cfg.is_train = False\n#         return [cfg for _ in range(evaluator_env_num)]\n# \n#     def enable_save_replay(self, replay_path: Optional[str] = None) -> None:\n#         if replay_path is None:\n#             replay_path = './video'\n#         self._replay_path = replay_path\n#         # this function can lead to the meaningless result\n#         # disable_gym_view_window()\n#         self._env = gym.wrappers.Monitor(\n#             self._env, self._replay_path, video_callable=lambda episode_id: True, force=True\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/tests/speed_test/fake_env.py\n# --------------------------------------------------\n#             }),\n#             rew_space=T((1, ), {\n#                 'min': 0.0,\n#                 'max': 1.0\n#             }),\n#             use_wrappers=None,\n#         )\n# \n#     def __repr__(self) -> str:\n#         return \"DI-engine Fake Env for collector profile test\"\n# \n#     @staticmethod\n#     def create_collector_env_cfg(cfg: dict) -> List[dict]:\n#         collector_env_num = cfg.get('collector_env_num', 1)\n#         return [cfg for _ in range(collector_env_num)]\n# \n#     @staticmethod\n#     def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n#         evaluator_env_num = cfg.get('evaluator_env_num', 1)\n#         return [cfg for _ in range(evaluator_env_num)]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/collector/tests/speed_test/fake_env.py\n# --------------------------------------------------\n#             }),\n#             rew_space=T((1, ), {\n#                 'min': 0.0,\n#                 'max': 1.0\n#             }),\n#             use_wrappers=None,\n#         )\n# \n#     def __repr__(self) -> str:\n#         return \"DI-engine Fake Env for collector profile test\"\n# \n#     @staticmethod\n#     def create_collector_env_cfg(cfg: dict) -> List[dict]:\n#         collector_env_num = cfg.get('collector_env_num', 1)\n#         return [cfg for _ in range(collector_env_num)]\n# \n#     @staticmethod\n#     def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n#         evaluator_env_num = cfg.get('evaluator_env_num', 1)\n#         return [cfg for _ in range(evaluator_env_num)]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env/ding_env_wrapper.py\n# --------------------------------------------------\n#                 },\n#             ),\n#             use_wrappers=None\n#         )\n# \n#     def __repr__(self) -> str:\n#         return \"DI-engine Env({})\".format(self._cfg.env_id)\n# \n#     @staticmethod\n#     def create_collector_env_cfg(cfg: dict) -> List[dict]:\n#         actor_env_num = cfg.pop('collector_env_num')\n#         cfg = copy.deepcopy(cfg)\n#         cfg.is_train = True\n#         return [cfg for _ in range(actor_env_num)]\n# \n#     @staticmethod\n#     def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n#         evaluator_env_num = cfg.pop('evaluator_env_num')\n#         cfg = copy.deepcopy(cfg)\n#         cfg.is_train = False\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/envs/env/ding_env_wrapper.py\n# --------------------------------------------------\n#         actor_env_num = cfg.pop('collector_env_num')\n#         cfg = copy.deepcopy(cfg)\n#         cfg.is_train = True\n#         return [cfg for _ in range(actor_env_num)]\n# \n#     @staticmethod\n#     def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n#         evaluator_env_num = cfg.pop('evaluator_env_num')\n#         cfg = copy.deepcopy(cfg)\n#         cfg.is_train = False\n#         return [cfg for _ in range(evaluator_env_num)]\n# \n#     def enable_save_replay(self, replay_path: Optional[str] = None) -> None:\n#         if replay_path is None:\n#             replay_path = './video'\n#         self._replay_path = replay_path\n#         # this function can lead to the meaningless result\n#         # disable_gym_view_window()\n#         self._env = gym.wrappers.Monitor(\n#             self._env, self._replay_path, video_callable=lambda episode_id: True, force=True\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import Any, Union, List\nimport copy\nimport torch\nimport numpy as np\nimport pytest\nimport os\n\nfrom ding.envs import BaseEnv, BaseEnvTimestep, BaseEnvInfo\nfrom ding.envs.common.env_element import EnvElement, EnvElementInfo\nfrom ding.utils import ENV_REGISTRY\nfrom ding.entry import parallel_pipeline\nfrom .fake_cpong_dqn_config import fake_cpong_dqn_config, fake_cpong_dqn_create_config, fake_cpong_dqn_system_config\n\n\n@ENV_REGISTRY.register('fake_competitive_rl')\nclass FakeCompetitiveRlEnv(BaseEnv):\n\n    def __init__(self, cfg: dict) -> None:\n        self._cfg = cfg\n        self._is_evaluator = cfg.is_evaluator\n\n    def reset(self) -> np.ndarray:\n        self._step_times = 0\n        obs_shape = (4, 84, 84)\n        if not self._is_evaluator:\n            obs_shape = (2, ) + obs_shape\n        obs = np.random.randint(0, 256, obs_shape).astype(np.float32)\n        return obs\n\n    def close(self) -> None:\n        pass\n\n    def seed(self, seed: int, dynamic_seed: bool = True) -> None:\n        pass\n\n    def step(self, action: Union[torch.Tensor, np.ndarray, list]) -> BaseEnvTimestep:\n        obs_shape = (4, 84, 84)\n        if not self._is_evaluator:\n            obs_shape = (2, ) + obs_shape\n        obs = np.random.randint(0, 256, obs_shape).astype(np.float32)\n        rew = np.array([1.]) if self._is_evaluator else np.array([1., -1.])\n        done = False if self._step_times < 20 else True\n        info = {}\n        if done:\n            info['final_eval_reward'] = np.array([21.]) if self._is_evaluator else np.array([5., -5.])\n        self._step_times += 1\n        return BaseEnvTimestep(obs, rew, done, info)\n\n    def info(self) -> BaseEnvInfo:\n        return BaseEnvInfo(\n            agent_num=2,\n            obs_space=EnvElementInfo(\n                shape=(2, 4, 84, 84),\n                value={\n                    'min': 0,\n                    'max': 256,\n                    'dtype': np.int\n                },\n            ),\n            act_space=EnvElementInfo(\n                shape=(1, ),\n                value={\n                    'min': 0,\n                    'max': 3,\n                    'dtype': np.float32\n                },\n            ),\n            rew_space=EnvElementInfo(\n                shape=(1, ),\n                value={\n                    'min': np.float32(\"-inf\"),\n                    'max': np.float32(\"inf\"),\n                    'dtype': np.float32\n                },\n            ),\n            use_wrappers=None,\n        )\n\n    def __repr__(self) -> str:\n        return \"Fake Competitve RL Env({})\".format(self._cfg.env_id)\n\n    @staticmethod\n    def create_collector_env_cfg(cfg: dict) -> List[dict]:\n        collector_cfg = copy.deepcopy(cfg)\n        collector_env_num = collector_cfg.pop('collector_env_num', 1)\n        collector_cfg.is_evaluator = False\n        return [collector_cfg for _ in range(collector_env_num)]\n\n    @staticmethod", "choices": [{"text": "def create_evaluator_env_cfg(cfg: dict) -> List[dict]:"}], "metadata": {"task_id": "opendilab_ACE/194", "ground_truth": "    def create_evaluator_env_cfg(cfg: dict) -> List[dict]:", "fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "tests", "test_marine_parallel_collector.py"], "context_start_lineno": 0, "line_no": 89, "query_window": {"context": "                value={\n                    'min': np.float32(\"-inf\"),\n                    'max': np.float32(\"inf\"),\n                    'dtype': np.float32\n                },\n            ),\n            use_wrappers=None,\n        )\n\n    def __repr__(self) -> str:\n        return \"Fake Competitve RL Env({})\".format(self._cfg.env_id)\n\n    @staticmethod\n    def create_collector_env_cfg(cfg: dict) -> List[dict]:\n        collector_cfg = copy.deepcopy(cfg)\n        collector_env_num = collector_cfg.pop('collector_env_num', 1)\n        collector_cfg.is_evaluator = False\n        return [collector_cfg for _ in range(collector_env_num)]\n\n    @staticmethod", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "tests", "test_marine_parallel_collector.py"], "line_no": 89, "task_id": "opendilab_ACE/194", "start_line_no": 69, "end_line_no": 89, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "                },\n            ),\n            use_wrappers=None\n        )\n\n    def __repr__(self) -> str:\n        return \"DI-engine Env({})\".format(self._cfg.env_id)\n\n    @staticmethod\n    def create_collector_env_cfg(cfg: dict) -> List[dict]:\n        actor_env_num = cfg.pop('collector_env_num')\n        cfg = copy.deepcopy(cfg)\n        cfg.is_train = True\n        return [cfg for _ in range(actor_env_num)]\n\n    @staticmethod\n    def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n        evaluator_env_num = cfg.pop('evaluator_env_num')\n        cfg = copy.deepcopy(cfg)\n        cfg.is_train = False", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env", "ding_env_wrapper.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6699029126213593}, {"context": "                    'max': act_space.n,\n                    'dtype': np.float32\n                },\n            ),\n            rew_space=EnvElementInfo(\n                shape=1,\n                value={\n                    'min': -1,\n                    'max': 1,\n                    'dtype': np.float32\n                },\n            ),\n            use_wrappers=None\n        )\n\n    def __repr__(self) -> str:\n        return \"DI-engine Env({})\".format(self._cfg.env_id)\n\n    @staticmethod\n    def create_collector_env_cfg(cfg: dict) -> List[dict]:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env", "ding_env_wrapper.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6132075471698113}, {"context": "                'max': 2\n            }),\n            rew_space=T((1, ), {\n                'min': 0.0,\n                'max': 1.0\n            }),\n            use_wrappers=None,\n        )\n\n    def __repr__(self) -> str:\n        return \"DI-engine Fake Env for collector profile test\"\n\n    @staticmethod\n    def create_collector_env_cfg(cfg: dict) -> List[dict]:\n        collector_env_num = cfg.get('collector_env_num', 1)\n        return [cfg for _ in range(collector_env_num)]\n\n    @staticmethod\n    def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n        evaluator_env_num = cfg.get('evaluator_env_num', 1)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "tests", "speed_test", "fake_env.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5565217391304348}, {"context": "        return \"DI-engine Fake Env for collector profile test\"\n\n    @staticmethod\n    def create_collector_env_cfg(cfg: dict) -> List[dict]:\n        collector_env_num = cfg.get('collector_env_num', 1)\n        return [cfg for _ in range(collector_env_num)]\n\n    @staticmethod\n    def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n        evaluator_env_num = cfg.get('evaluator_env_num', 1)\n        return [cfg for _ in range(evaluator_env_num)]", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "collector", "tests", "speed_test", "fake_env.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 91, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.42718446601941745}, {"context": "        actor_env_num = cfg.pop('collector_env_num')\n        cfg = copy.deepcopy(cfg)\n        cfg.is_train = True\n        return [cfg for _ in range(actor_env_num)]\n\n    @staticmethod\n    def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n        evaluator_env_num = cfg.pop('evaluator_env_num')\n        cfg = copy.deepcopy(cfg)\n        cfg.is_train = False\n        return [cfg for _ in range(evaluator_env_num)]\n\n    def enable_save_replay(self, replay_path: Optional[str] = None) -> None:\n        if replay_path is None:\n            replay_path = './video'\n        self._replay_path = replay_path\n        # this function can lead to the meaningless result\n        # disable_gym_view_window()\n        self._env = gym.wrappers.Monitor(\n            self._env, self._replay_path, video_callable=lambda episode_id: True, force=True", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env", "ding_env_wrapper.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.37857142857142856}, {"context": "\n    @staticmethod\n    def create_collector_env_cfg(cfg: dict) -> List[dict]:\n        \"\"\"\n        Overview:\n            Return a list of all of the environment from input config.\n        Arguments:\n            - cfg (:obj:`Dict`) Env config, same config where ``self.__init__()`` takes arguments from\n        Returns:\n            - List of ``cfg`` including all of the collector env's config\n        \"\"\"\n        collector_env_num = cfg.pop('collector_env_num')\n        return [cfg for _ in range(collector_env_num)]\n\n    @staticmethod\n    def create_evaluator_env_cfg(cfg: dict) -> List[dict]:\n        \"\"\"\n        Overview:\n            Return a list of all of the environment from input config.\n        Arguments:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env", "base_env.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3515625}, {"context": "            info['final_eval_reward'] = self._final_eval_reward\n        return BaseEnvTimestep(obs, rew, done, info)\n\n    def info(self) -> BaseEnvInfo:\n        obs_space = self._env.observation_space\n        act_space = self._env.action_space\n        return BaseEnvInfo(\n            agent_num=1,\n            obs_space=EnvElementInfo(\n                shape=obs_space.shape,\n                value={\n                    'min': obs_space.low,\n                    'max': obs_space.high,\n                    'dtype': np.float32\n                },\n            ),\n            act_space=EnvElementInfo(\n                shape=(act_space.n, ),\n                value={\n                    'min': 0,", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "envs", "env", "ding_env_wrapper.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2992125984251969}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/deprecated.py\n# --------------------------------------------------\n#                 next_td.get(\"state_action_value\") - self.alpha * sample_log_prob\n#             )\n#             state_value = state_value.min(0)[0]\n# \n#         tensordict.set(\"next.state_value\", state_value)\n#         target_value = get_next_state_value(\n#             tensordict,\n#             gamma=self.gamma,\n#             pred_next_val=state_value,\n#         )\n#         tensordict_expand = vmap(self.qvalue_network, (None, 0))(\n#             tensordict.select(*self.qvalue_network.in_keys),\n#             self.qvalue_network_params,\n#         )\n#         pred_val = tensordict_expand.get(\"state_action_value\").squeeze(-1)\n#         td_error = abs(pred_val - target_value)\n#         loss_qval = distance_loss(\n#             pred_val,\n#             target_value.expand_as(pred_val),\n#             loss_function=self.loss_function,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/deprecated.py\n# --------------------------------------------------\n#         tensordict_expand = vmap(self.qvalue_network, (None, 0))(\n#             tensordict.select(*self.qvalue_network.in_keys),\n#             self.qvalue_network_params,\n#         )\n#         pred_val = tensordict_expand.get(\"state_action_value\").squeeze(-1)\n#         td_error = abs(pred_val - target_value)\n#         loss_qval = distance_loss(\n#             pred_val,\n#             target_value.expand_as(pred_val),\n#             loss_function=self.loss_function,\n#         ).mean(0)\n#         tensordict_save.set(\"td_error\", td_error.detach().max(0)[0])\n#         return loss_qval\n# \n#     def _loss_alpha(self, log_pi: Tensor) -> Tensor:\n#         if torch.is_grad_enabled() and not log_pi.requires_grad:\n#             raise RuntimeError(\n#                 \"expected log_pi to require gradient for the alpha loss)\"\n#             )\n#         if self.target_entropy is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/tensordict_module/exploration.py\n# --------------------------------------------------\n#                 ).item(),\n#             )\n# \n#     def _add_noise(self, action: torch.Tensor) -> torch.Tensor:\n#         sigma = self.sigma.item()\n#         noise = torch.normal(\n#             mean=torch.ones(action.shape) * self.mean.item(),\n#             std=torch.ones(action.shape) * self.std.item(),\n#         ).to(action.device)\n#         action = action + noise * sigma\n#         spec = self.spec\n#         if isinstance(spec, CompositeSpec):\n#             spec = spec[self.action_key]\n#         if spec is not None:\n#             action = spec.project(action)\n#         elif self.safe:\n#             raise RuntimeError(\n#                 \"the action spec must be provided to AdditiveGaussianWrapper unless \"\n#                 \"the `safe` keyword argument is turned off at initialization.\"\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/sac.py\n# --------------------------------------------------\n# \n#         tensordict.set(\"next.state_value\", state_value)\n#         target_value = next_state_value(\n#             tensordict,\n#             gamma=self.gamma,\n#             pred_next_val=state_value,\n#         )\n#         tensordict_expand = vmap(self.qvalue_network, (None, 0))(\n#             tensordict.select(*self.qvalue_network.in_keys),\n#             self.qvalue_network_params,\n#         )\n#         pred_val = tensordict_expand.get(\"state_action_value\").squeeze(-1)\n#         td_error = abs(pred_val - target_value)\n#         loss_qval = distance_loss(\n#             pred_val,\n#             target_value.expand_as(pred_val),\n#             loss_function=self.loss_function,\n#         ).mean(0)\n#         return loss_qval, td_error.detach().max(0)[0]\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/redq.py\n# --------------------------------------------------\n#                 )\n#             tensordict_actor[sample_key] = tensordict_actor_dist.rsample()\n#             tensordict_actor[\"sample_log_prob\"] = tensordict_actor_dist.log_prob(\n#                 tensordict_actor[sample_key]\n#             )\n# \n#         # repeat tensordict_actor to match the qvalue size\n#         _actor_loss_td = (\n#             tensordict_actor[0]\n#             .select(*self.qvalue_network.in_keys)\n#             .expand(self.num_qvalue_nets, *tensordict_actor[0].batch_size)\n#         )  # for actor loss\n#         _qval_td = tensordict_select.select(*self.qvalue_network.in_keys).expand(\n#             self.num_qvalue_nets,\n#             *tensordict_select.select(*self.qvalue_network.in_keys).batch_size,\n#         )  # for qvalue loss\n#         _next_val_td = (\n#             tensordict_actor[1]\n#             .select(*self.qvalue_network.in_keys)\n#             .expand(self.sub_sample_len, *tensordict_actor[1].batch_size)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/redq.py\n# --------------------------------------------------\n#             .expand(self.num_qvalue_nets, *tensordict_actor[0].batch_size)\n#         )  # for actor loss\n#         _qval_td = tensordict_select.select(*self.qvalue_network.in_keys).expand(\n#             self.num_qvalue_nets,\n#             *tensordict_select.select(*self.qvalue_network.in_keys).batch_size,\n#         )  # for qvalue loss\n#         _next_val_td = (\n#             tensordict_actor[1]\n#             .select(*self.qvalue_network.in_keys)\n#             .expand(self.sub_sample_len, *tensordict_actor[1].batch_size)\n#         )  # for next value estimation\n#         tensordict_qval = torch.cat(\n#             [\n#                 _actor_loss_td,\n#                 _next_val_td,\n#                 _qval_td,\n#             ],\n#             0,\n#         )\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom numbers import Number\n\nimport torch\n\nfrom tensordict.tensordict import TensorDict, TensorDictBase\n\nfrom torchrl.envs.utils import set_exploration_mode, step_mdp\nfrom torchrl.modules import SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.objectives.utils import (\n    distance_loss,\n    next_state_value as get_next_state_value,\n)\n\ntry:\n    from functorch import vmap\n\n    FUNCTORCH_ERR = \"\"\n    _has_functorch = True\nexcept ImportError as err:\n    FUNCTORCH_ERR = str(err)\n    _has_functorch = False\n\n\nclass TD3Loss(LossModule):\n    \"\"\"TD3 Loss module.\n\n    Args:\n        actor_network (SafeModule): the actor to be trained\n        qvalue_network (SafeModule): a single Q-value network that will be multiplicated as many times as needed.\n        num_qvalue_nets (int, optional): Number of Q-value networks to be trained. Default is 10.\n        gamma (Number, optional): gamma decay factor. Default is 0.99.\n        max_action (float, optional): Maximum action, in MuJoCo environments typically 1.0.\n        policy_noise (float, optional): Standard deviation for the target policy action noise. Default is 0.2.\n        noise_clip (float, optional): Clipping range value for the sampled target policy action noise. Default is 0.5.\n        priotity_key (str, optional): Key where to write the priority value for prioritized replay buffers. Default is\n            `\"td_error\"`.\n        loss_function (str, optional): loss function to be used for the Q-value. Can be one of  `\"smooth_l1\"`, \"l2\",\n            \"l1\", Default is \"smooth_l1\".\n        delay_actor (bool, optional): whether to separate the target actor networks from the actor networks used for\n            data collection. Default is :obj:`False`.\n        delay_qvalue (bool, optional): Whether to separate the target Q value networks from the Q value networks used\n            for data collection. Default is :obj:`False`.\n    \"\"\"\n\n    def __init__(\n        self,\n        actor_network: SafeModule,\n        qvalue_network: SafeModule,\n        num_qvalue_nets: int = 2,\n        gamma: Number = 0.99,\n        policy_noise: float = 0.2,\n        noise_clip: float = 0.5,\n        priotity_key: str = \"td_error\",\n        loss_function: str = \"smooth_l1\",\n        delay_actor: bool = False,\n        delay_qvalue: bool = False,\n    ) -> None:\n        if not _has_functorch:\n            raise ImportError(\n                f\"Failed to import functorch with error message:\\n{FUNCTORCH_ERR}\"\n            )\n\n        super().__init__()\n\n        self.delay_actor = delay_actor\n        self.delay_qvalue = delay_qvalue\n\n        self.convert_to_functional(\n            actor_network,\n            \"actor_network\",\n            create_target_params=self.delay_actor,\n        )\n\n        self.convert_to_functional(\n            qvalue_network,\n            \"qvalue_network\",\n            num_qvalue_nets,\n            create_target_params=self.delay_qvalue,\n            compare_against=list(actor_network.parameters()),\n        )\n\n        self.num_qvalue_nets = num_qvalue_nets\n        self.register_buffer(\"gamma\", torch.tensor(gamma))\n        self.priority_key = priotity_key\n        self.loss_function = loss_function\n        self.policy_noise = policy_noise\n        self.noise_clip = noise_clip\n        self.max_action = actor_network.spec[\"action\"].space.maximum.max().item()\n\n    def forward(self, tensordict: TensorDictBase) -> TensorDictBase:\n        obs_keys = self.actor_network.in_keys\n        tensordict_select = tensordict.select(\n            \"reward\", \"done\", \"next\", *obs_keys, \"action\"\n        )\n\n        actor_params = torch.stack(\n            [self.actor_network_params, self.target_actor_network_params], 0\n        )\n\n        tensordict_actor_grad = tensordict_select.select(\n            *obs_keys\n        )  # to avoid overwriting keys\n        next_td_actor = step_mdp(tensordict_select).select(\n            *self.actor_network.in_keys\n        )  # next_observation ->\n        tensordict_actor = torch.stack([tensordict_actor_grad, next_td_actor], 0)\n        tensordict_actor = tensordict_actor.contiguous()\n\n        with set_exploration_mode(\"mode\"):\n            actor_output_td = vmap(self.actor_network)(\n                tensordict_actor,\n                actor_params,\n            )\n        # add noise to target policy\n        noise = torch.normal(\n            mean=torch.zeros(actor_output_td[1][\"action\"].shape),\n            std=torch.ones(actor_output_td[1][\"action\"].shape) * self.policy_noise,\n        ).to(actor_output_td[1].device)\n        noise = noise.clamp(-self.noise_clip, self.noise_clip)\n\n        next_action = (actor_output_td[1][\"action\"] + noise).clamp(\n            -self.max_action, self.max_action\n        )\n        actor_output_td[1].set(\"action\", next_action, inplace=True)\n        tensordict_actor[\"action\"] = actor_output_td[\"action\"]\n\n        # repeat tensordict_actor to match the qvalue size\n        _actor_loss_td = (\n            tensordict_actor[0]", "choices": [{"text": ".select(*self.qvalue_network.in_keys)"}], "metadata": {"task_id": "pytorch_rl/143", "ground_truth": "            .select(*self.qvalue_network.in_keys)", "fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "td3.py"], "context_start_lineno": 0, "line_no": 135, "query_window": {"context": "            actor_output_td = vmap(self.actor_network)(\n                tensordict_actor,\n                actor_params,\n            )\n        # add noise to target policy\n        noise = torch.normal(\n            mean=torch.zeros(actor_output_td[1][\"action\"].shape),\n            std=torch.ones(actor_output_td[1][\"action\"].shape) * self.policy_noise,\n        ).to(actor_output_td[1].device)\n        noise = noise.clamp(-self.noise_clip, self.noise_clip)\n\n        next_action = (actor_output_td[1][\"action\"] + noise).clamp(\n            -self.max_action, self.max_action\n        )\n        actor_output_td[1].set(\"action\", next_action, inplace=True)\n        tensordict_actor[\"action\"] = actor_output_td[\"action\"]\n\n        # repeat tensordict_actor to match the qvalue size\n        _actor_loss_td = (\n            tensordict_actor[0]", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "td3.py"], "line_no": 135, "task_id": "pytorch_rl/143", "start_line_no": 115, "end_line_no": 135, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "                )\n            tensordict_actor[sample_key] = tensordict_actor_dist.rsample()\n            tensordict_actor[\"sample_log_prob\"] = tensordict_actor_dist.log_prob(\n                tensordict_actor[sample_key]\n            )\n\n        # repeat tensordict_actor to match the qvalue size\n        _actor_loss_td = (\n            tensordict_actor[0]\n            .select(*self.qvalue_network.in_keys)\n            .expand(self.num_qvalue_nets, *tensordict_actor[0].batch_size)\n        )  # for actor loss\n        _qval_td = tensordict_select.select(*self.qvalue_network.in_keys).expand(\n            self.num_qvalue_nets,\n            *tensordict_select.select(*self.qvalue_network.in_keys).batch_size,\n        )  # for qvalue loss\n        _next_val_td = (\n            tensordict_actor[1]\n            .select(*self.qvalue_network.in_keys)\n            .expand(self.sub_sample_len, *tensordict_actor[1].batch_size)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "redq.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3565217391304348}, {"context": "            )\n            if isinstance(self.actor_network, TensorDictSequential):\n                sample_key = self.actor_network[-1].out_keys[0]\n                tensordict_actor_dist = self.actor_network.build_dist_from_params(\n                    td_params\n                )\n            else:\n                sample_key = self.actor_network.out_keys[0]\n                tensordict_actor_dist = self.actor_network.build_dist_from_params(\n                    td_params\n                )\n            tensordict_actor[sample_key] = tensordict_actor_dist.rsample()\n            tensordict_actor[\"sample_log_prob\"] = tensordict_actor_dist.log_prob(\n                tensordict_actor[sample_key]\n            )\n\n        # repeat tensordict_actor to match the qvalue size\n        _actor_loss_td = (\n            tensordict_actor[0]\n            .select(*self.qvalue_network.in_keys)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "redq.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3305084745762712}, {"context": "            state_action_value = next_td.get(\"state_action_value\")\n            if (\n                state_action_value.shape[-len(sample_log_prob.shape) :]\n                != sample_log_prob.shape\n            ):\n                sample_log_prob = sample_log_prob.unsqueeze(-1)\n            state_value = (\n                next_td.get(\"state_action_value\") - self._alpha * sample_log_prob\n            )\n            state_value = state_value.min(0)[0]\n\n        tensordict.set(\"next.state_value\", state_value)\n        target_value = next_state_value(\n            tensordict,\n            gamma=self.gamma,\n            pred_next_val=state_value,\n        )\n        tensordict_expand = vmap(self.qvalue_network, (None, 0))(\n            tensordict.select(*self.qvalue_network.in_keys),\n            self.qvalue_network_params,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "sac.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3225806451612903}, {"context": "        Args:\n            frames (int): number of frames since last step.\n\n        \"\"\"\n        for _ in range(frames):\n            self.sigma.data[0] = max(\n                self.sigma_end.item(),\n                (\n                    self.sigma\n                    - (self.sigma_init - self.sigma_end) / self.annealing_num_steps\n                ).item(),\n            )\n\n    def _add_noise(self, action: torch.Tensor) -> torch.Tensor:\n        sigma = self.sigma.item()\n        noise = torch.normal(\n            mean=torch.ones(action.shape) * self.mean.item(),\n            std=torch.ones(action.shape) * self.std.item(),\n        ).to(action.device)\n        action = action + noise * sigma", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "exploration.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.312}, {"context": "                next_td.get(\"state_action_value\") - self.alpha * sample_log_prob\n            )\n            state_value = state_value.min(0)[0]\n\n        tensordict.set(\"next.state_value\", state_value)\n        target_value = get_next_state_value(\n            tensordict,\n            gamma=self.gamma,\n            pred_next_val=state_value,\n        )\n        tensordict_expand = vmap(self.qvalue_network, (None, 0))(\n            tensordict.select(*self.qvalue_network.in_keys),\n            self.qvalue_network_params,\n        )\n        pred_val = tensordict_expand.get(\"state_action_value\").squeeze(-1)\n        td_error = abs(pred_val - target_value)\n        loss_qval = distance_loss(\n            pred_val,\n            target_value.expand_as(pred_val),\n            loss_function=self.loss_function,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "deprecated.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.312}, {"context": "                next_td,\n                selected_q_params,\n            )\n            state_action_value = next_td.get(\"state_action_value\")\n            if (\n                state_action_value.shape[-len(sample_log_prob.shape) :]\n                != sample_log_prob.shape\n            ):\n                sample_log_prob = sample_log_prob.unsqueeze(-1)\n            state_value = (\n                next_td.get(\"state_action_value\") - self.alpha * sample_log_prob\n            )\n            state_value = state_value.min(0)[0]\n\n        tensordict.set(\"next.state_value\", state_value)\n        target_value = get_next_state_value(\n            tensordict,\n            gamma=self.gamma,\n            pred_next_val=state_value,\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "deprecated.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3103448275862069}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# scripts/convert_vq_diffusion_to_diffusers.py\n# --------------------------------------------------\n#         \"num_vector_embeds\": num_embed,\n#         \"num_embeds_ada_norm\": num_embeds_ada_norm,\n#         \"norm_num_groups\": 32,\n#         \"sample_size\": width,\n#         \"activation_fn\": \"geglu-approximate\",\n#     }\n# \n#     model = Transformer2DModel(**model_kwargs)\n#     return model\n# \n# \n# # done transformer model\n# \n# # transformer checkpoint\n# \n# \n# def transformer_original_checkpoint_to_diffusers_checkpoint(model, checkpoint):\n#     diffusers_checkpoint = {}\n# \n#     transformer_prefix = \"transformer.transformer\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# scripts/convert_vq_diffusion_to_diffusers.py\n# --------------------------------------------------\n# \n# # done transformer model\n# \n# # transformer checkpoint\n# \n# \n# def transformer_original_checkpoint_to_diffusers_checkpoint(model, checkpoint):\n#     diffusers_checkpoint = {}\n# \n#     transformer_prefix = \"transformer.transformer\"\n# \n#     diffusers_latent_image_embedding_prefix = \"latent_image_embedding\"\n#     latent_image_embedding_prefix = f\"{transformer_prefix}.content_emb\"\n# \n#     # DalleMaskImageEmbedding\n#     diffusers_checkpoint.update(\n#         {\n#             f\"{diffusers_latent_image_embedding_prefix}.emb.weight\": checkpoint[\n#                 f\"{latent_image_embedding_prefix}.emb.weight\"\n#             ],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# scripts/convert_vq_diffusion_to_diffusers.py\n# --------------------------------------------------\n#             learned_classifier_free_sampling_embeddings_model,\n#             learned_classifier_free_sampling_checkpoint_file.name,\n#             device_map=\"auto\",\n#         )\n# \n#     # done learned classifier free sampling embeddings\n# \n#     print(f\"saving VQ diffusion model, path: {args.dump_path}\")\n# \n#     pipe = VQDiffusionPipeline(\n#         vqvae=vqvae_model,\n#         transformer=transformer_model,\n#         tokenizer=tokenizer_model,\n#         text_encoder=text_encoder_model,\n#         learned_classifier_free_sampling_embeddings=learned_classifier_free_sampling_embeddings_model,\n#         scheduler=scheduler_model,\n#     )\n#     pipe.save_pretrained(args.dump_path)\n# \n#     print(\"done writing VQ diffusion model\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# scripts/convert_vq_diffusion_to_diffusers.py\n# --------------------------------------------------\n#         learned_classifier_free_sampling_embeddings_model = LearnedClassifierFreeSamplingEmbeddings(\n#             learnable_classifier_free_sampling_embeddings,\n#             hidden_size=text_encoder_model.config.hidden_size,\n#             length=tokenizer_model.model_max_length,\n#         )\n# \n#     learned_classifier_free_sampling_checkpoint = {\n#         \"embeddings\": learned_classifier_free_sampling_embeddings_embeddings.float()\n#     }\n# \n#     with tempfile.NamedTemporaryFile() as learned_classifier_free_sampling_checkpoint_file:\n#         torch.save(learned_classifier_free_sampling_checkpoint, learned_classifier_free_sampling_checkpoint_file.name)\n#         del learned_classifier_free_sampling_checkpoint\n#         del learned_classifier_free_sampling_embeddings_embeddings\n#         load_checkpoint_and_dispatch(\n#             learned_classifier_free_sampling_embeddings_model,\n#             learned_classifier_free_sampling_checkpoint_file.name,\n#             device_map=\"auto\",\n#         )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/vq_diffusion/pipeline_vq_diffusion.py\n# --------------------------------------------------\n#     learned_classifier_free_sampling_embeddings: LearnedClassifierFreeSamplingEmbeddings\n#     scheduler: VQDiffusionScheduler\n# \n#     def __init__(\n#         self,\n#         vqvae: VQModel,\n#         text_encoder: CLIPTextModel,\n#         tokenizer: CLIPTokenizer,\n#         transformer: Transformer2DModel,\n#         scheduler: VQDiffusionScheduler,\n#         learned_classifier_free_sampling_embeddings: LearnedClassifierFreeSamplingEmbeddings,\n#     ):\n#         super().__init__()\n# \n#         self.register_modules(\n#             vqvae=vqvae,\n#             transformer=transformer,\n#             text_encoder=text_encoder,\n#             tokenizer=tokenizer,\n#             scheduler=scheduler,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# scripts/convert_vq_diffusion_to_diffusers.py\n# --------------------------------------------------\n#             learned_classifier_free_sampling_embeddings_model,\n#             learned_classifier_free_sampling_checkpoint_file.name,\n#             device_map=\"auto\",\n#         )\n# \n#     # done learned classifier free sampling embeddings\n# \n#     print(f\"saving VQ diffusion model, path: {args.dump_path}\")\n# \n#     pipe = VQDiffusionPipeline(\n#         vqvae=vqvae_model,\n#         transformer=transformer_model,\n#         tokenizer=tokenizer_model,\n#         text_encoder=text_encoder_model,\n#         learned_classifier_free_sampling_embeddings=learned_classifier_free_sampling_embeddings_model,\n#         scheduler=scheduler_model,\n#     )\n#     pipe.save_pretrained(args.dump_path)\n# \n#     print(\"done writing VQ diffusion model\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/vq_diffusion/pipeline_vq_diffusion.py\n# --------------------------------------------------\n#         learned_classifier_free_sampling_embeddings: LearnedClassifierFreeSamplingEmbeddings,\n#     ):\n#         super().__init__()\n# \n#         self.register_modules(\n#             vqvae=vqvae,\n#             transformer=transformer,\n#             text_encoder=text_encoder,\n#             tokenizer=tokenizer,\n#             scheduler=scheduler,\n#             learned_classifier_free_sampling_embeddings=learned_classifier_free_sampling_embeddings,\n#         )\n# \n#     def _encode_prompt(self, prompt, num_images_per_prompt, do_classifier_free_guidance):\n#         batch_size = len(prompt) if isinstance(prompt, list) else 1\n# \n#         # get prompt text embeddings\n#         text_inputs = self.tokenizer(\n#             prompt,\n#             padding=\"max_length\",\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# coding=utf-8\n# Copyright 2022 HuggingFace Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport gc\nimport unittest\n\nimport numpy as np\nimport torch\n\nfrom diffusers import Transformer2DModel, VQDiffusionPipeline, VQDiffusionScheduler, VQModel\nfrom diffusers.pipelines.vq_diffusion.pipeline_vq_diffusion import LearnedClassifierFreeSamplingEmbeddings\nfrom diffusers.utils import load_numpy, slow, torch_device\nfrom diffusers.utils.testing_utils import require_torch_gpu\nfrom transformers import CLIPTextConfig, CLIPTextModel, CLIPTokenizer\n\n\ntorch.backends.cuda.matmul.allow_tf32 = False\n\n\nclass VQDiffusionPipelineFastTests(unittest.TestCase):\n    def tearDown(self):\n        # clean up the VRAM after each test\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    @property\n    def num_embed(self):\n        return 12\n\n    @property\n    def num_embeds_ada_norm(self):\n        return 12\n\n    @property\n    def text_embedder_hidden_size(self):\n        return 32\n\n    @property\n    def dummy_vqvae(self):\n        torch.manual_seed(0)\n        model = VQModel(\n            block_out_channels=[32, 64],\n            in_channels=3,\n            out_channels=3,\n            down_block_types=[\"DownEncoderBlock2D\", \"DownEncoderBlock2D\"],\n            up_block_types=[\"UpDecoderBlock2D\", \"UpDecoderBlock2D\"],\n            latent_channels=3,\n            num_vq_embeddings=self.num_embed,\n            vq_embed_dim=3,\n        )\n        return model\n\n    @property\n    def dummy_tokenizer(self):\n        tokenizer = CLIPTokenizer.from_pretrained(\"hf-internal-testing/tiny-random-clip\")\n        return tokenizer\n\n    @property\n    def dummy_text_encoder(self):\n        torch.manual_seed(0)\n        config = CLIPTextConfig(\n            bos_token_id=0,\n            eos_token_id=2,\n            hidden_size=self.text_embedder_hidden_size,\n            intermediate_size=37,\n            layer_norm_eps=1e-05,\n            num_attention_heads=4,\n            num_hidden_layers=5,\n            pad_token_id=1,\n            vocab_size=1000,\n        )\n        return CLIPTextModel(config)\n\n    @property\n    def dummy_transformer(self):\n        torch.manual_seed(0)\n\n        height = 12\n        width = 12\n\n        model_kwargs = {\n            \"attention_bias\": True,\n            \"cross_attention_dim\": 32,\n            \"attention_head_dim\": height * width,\n            \"num_attention_heads\": 1,\n            \"num_vector_embeds\": self.num_embed,\n            \"num_embeds_ada_norm\": self.num_embeds_ada_norm,\n            \"norm_num_groups\": 32,\n            \"sample_size\": width,\n            \"activation_fn\": \"geglu-approximate\",\n        }\n\n        model = Transformer2DModel(**model_kwargs)\n        return model\n\n    def test_vq_diffusion(self):\n        device = \"cpu\"\n\n        vqvae = self.dummy_vqvae\n        text_encoder = self.dummy_text_encoder\n        tokenizer = self.dummy_tokenizer\n        transformer = self.dummy_transformer\n        scheduler = VQDiffusionScheduler(self.num_embed)\n        learned_classifier_free_sampling_embeddings = LearnedClassifierFreeSamplingEmbeddings(learnable=False)\n\n        pipe = VQDiffusionPipeline(\n            vqvae=vqvae,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,", "choices": [{"text": "transformer=transformer,"}], "metadata": {"task_id": "huggingface_diffusers/71", "ground_truth": "            transformer=transformer,", "fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "vq_diffusion", "test_vq_diffusion.py"], "context_start_lineno": 0, "line_no": 122, "query_window": {"context": "            \"activation_fn\": \"geglu-approximate\",\n        }\n\n        model = Transformer2DModel(**model_kwargs)\n        return model\n\n    def test_vq_diffusion(self):\n        device = \"cpu\"\n\n        vqvae = self.dummy_vqvae\n        text_encoder = self.dummy_text_encoder\n        tokenizer = self.dummy_tokenizer\n        transformer = self.dummy_transformer\n        scheduler = VQDiffusionScheduler(self.num_embed)\n        learned_classifier_free_sampling_embeddings = LearnedClassifierFreeSamplingEmbeddings(learnable=False)\n\n        pipe = VQDiffusionPipeline(\n            vqvae=vqvae,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "vq_diffusion", "test_vq_diffusion.py"], "line_no": 122, "task_id": "huggingface_diffusers/71", "start_line_no": 102, "end_line_no": 122, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "    learned_classifier_free_sampling_embeddings: LearnedClassifierFreeSamplingEmbeddings\n    scheduler: VQDiffusionScheduler\n\n    def __init__(\n        self,\n        vqvae: VQModel,\n        text_encoder: CLIPTextModel,\n        tokenizer: CLIPTokenizer,\n        transformer: Transformer2DModel,\n        scheduler: VQDiffusionScheduler,\n        learned_classifier_free_sampling_embeddings: LearnedClassifierFreeSamplingEmbeddings,\n    ):\n        super().__init__()\n\n        self.register_modules(\n            vqvae=vqvae,\n            transformer=transformer,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,\n            scheduler=scheduler,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "vq_diffusion", "pipeline_vq_diffusion.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5}, {"context": "    # done learned classifier free sampling embeddings\n\n    print(f\"saving VQ diffusion model, path: {args.dump_path}\")\n\n    pipe = VQDiffusionPipeline(\n        vqvae=vqvae_model,\n        transformer=transformer_model,\n        tokenizer=tokenizer_model,\n        text_encoder=text_encoder_model,\n        learned_classifier_free_sampling_embeddings=learned_classifier_free_sampling_embeddings_model,\n        scheduler=scheduler_model,\n    )\n    pipe.save_pretrained(args.dump_path)\n\n    print(\"done writing VQ diffusion model\")", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "scripts", "convert_vq_diffusion_to_diffusers.py"], "line_no": 920, "start_line_no": 910, "end_line_no": 925, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4188034188034188}, {"context": "        transformer ([`Transformer2DModel`]):\n            Conditional transformer to denoise the encoded image latents.\n        scheduler ([`VQDiffusionScheduler`]):\n            A scheduler to be used in combination with `transformer` to denoise the encoded image latents.\n    \"\"\"\n\n    vqvae: VQModel\n    text_encoder: CLIPTextModel\n    tokenizer: CLIPTokenizer\n    transformer: Transformer2DModel\n    learned_classifier_free_sampling_embeddings: LearnedClassifierFreeSamplingEmbeddings\n    scheduler: VQDiffusionScheduler\n\n    def __init__(\n        self,\n        vqvae: VQModel,\n        text_encoder: CLIPTextModel,\n        tokenizer: CLIPTokenizer,\n        transformer: Transformer2DModel,\n        scheduler: VQDiffusionScheduler,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "vq_diffusion", "pipeline_vq_diffusion.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4132231404958678}, {"context": "    scheduler_model = VQDiffusionScheduler(\n        # the scheduler has the same number of embeddings as the transformer\n        num_vec_classes=transformer_model.num_vector_embeds\n    )\n\n    # done scheduler\n\n    # learned classifier free sampling embeddings\n\n    with init_empty_weights():\n        learned_classifier_free_sampling_embeddings_model = LearnedClassifierFreeSamplingEmbeddings(\n            learnable_classifier_free_sampling_embeddings,\n            hidden_size=text_encoder_model.config.hidden_size,\n            length=tokenizer_model.model_max_length,\n        )\n\n    learned_classifier_free_sampling_checkpoint = {\n        \"embeddings\": learned_classifier_free_sampling_embeddings_embeddings.float()\n    }\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "scripts", "convert_vq_diffusion_to_diffusers.py"], "line_no": 890, "start_line_no": 880, "end_line_no": 900, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.38095238095238093}, {"context": "    with tempfile.NamedTemporaryFile() as learned_classifier_free_sampling_checkpoint_file:\n        torch.save(learned_classifier_free_sampling_checkpoint, learned_classifier_free_sampling_checkpoint_file.name)\n        del learned_classifier_free_sampling_checkpoint\n        del learned_classifier_free_sampling_embeddings_embeddings\n        load_checkpoint_and_dispatch(\n            learned_classifier_free_sampling_embeddings_model,\n            learned_classifier_free_sampling_checkpoint_file.name,\n            device_map=\"auto\",\n        )\n\n    # done learned classifier free sampling embeddings\n\n    print(f\"saving VQ diffusion model, path: {args.dump_path}\")\n\n    pipe = VQDiffusionPipeline(\n        vqvae=vqvae_model,\n        transformer=transformer_model,\n        tokenizer=tokenizer_model,\n        text_encoder=text_encoder_model,\n        learned_classifier_free_sampling_embeddings=learned_classifier_free_sampling_embeddings_model,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "scripts", "convert_vq_diffusion_to_diffusers.py"], "line_no": 910, "start_line_no": 900, "end_line_no": 920, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3787878787878788}, {"context": "        \"num_vector_embeds\": num_embed,\n        \"num_embeds_ada_norm\": num_embeds_ada_norm,\n        \"norm_num_groups\": 32,\n        \"sample_size\": width,\n        \"activation_fn\": \"geglu-approximate\",\n    }\n\n    model = Transformer2DModel(**model_kwargs)\n    return model\n\n\n# done transformer model\n\n# transformer checkpoint\n\n\ndef transformer_original_checkpoint_to_diffusers_checkpoint(model, checkpoint):\n    diffusers_checkpoint = {}\n\n    transformer_prefix = \"transformer.transformer\"", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "scripts", "convert_vq_diffusion_to_diffusers.py"], "line_no": 530, "start_line_no": 520, "end_line_no": 540, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.36607142857142855}, {"context": "    dropout = original_transformer_config[\"resid_pdrop\"]\n    num_embeds_ada_norm = original_diffusion_config[\"diffusion_step\"]\n\n    model_kwargs = {\n        \"attention_bias\": True,\n        \"cross_attention_dim\": context_dim,\n        \"attention_head_dim\": d_head,\n        \"num_layers\": depth,\n        \"dropout\": dropout,\n        \"num_attention_heads\": n_heads,\n        \"num_vector_embeds\": num_embed,\n        \"num_embeds_ada_norm\": num_embeds_ada_norm,\n        \"norm_num_groups\": 32,\n        \"sample_size\": width,\n        \"activation_fn\": \"geglu-approximate\",\n    }\n\n    model = Transformer2DModel(**model_kwargs)\n    return model\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "scripts", "convert_vq_diffusion_to_diffusers.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.2992125984251969}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/seed_resize_stable_diffusion.py\n# --------------------------------------------------\n#                 `attention_head_dim` must be a multiple of `slice_size`.\n#         \"\"\"\n#         if slice_size == \"auto\":\n#             # half the attention head size is usually a good trade-off between\n#             # speed and memory\n#             slice_size = self.unet.config.attention_head_dim // 2\n#         self.unet.set_attention_slice(slice_size)\n# \n#     def disable_attention_slicing(self):\n#         r\"\"\"\n#         Disable sliced attention computation. If `enable_attention_slicing` was previously invoked, this method will go\n#         back to computing attention in one step.\n#         \"\"\"\n#         # set slice_size = `None` to disable `attention slicing`\n#         self.enable_attention_slicing(None)\n# \n#     @torch.no_grad()\n#     def __call__(\n#         self,\n#         prompt: Union[str, List[str]],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/imagic_stable_diffusion.py\n# --------------------------------------------------\n#         When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n#         in several steps. This is useful to save some memory in exchange for a small speed decrease.\n#         Args:\n#             slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n#                 When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n#                 a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,\n#                 `attention_head_dim` must be a multiple of `slice_size`.\n#         \"\"\"\n#         if slice_size == \"auto\":\n#             # half the attention head size is usually a good trade-off between\n#             # speed and memory\n#             slice_size = self.unet.config.attention_head_dim // 2\n#         self.unet.set_attention_slice(slice_size)\n# \n#     def disable_attention_slicing(self):\n#         r\"\"\"\n#         Disable sliced attention computation. If `enable_attention_slicing` was previously invoked, this method will go\n#         back to computing attention in one step.\n#         \"\"\"\n#         # set slice_size = `None` to disable `attention slicing`\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/multilingual_stable_diffusion.py\n# --------------------------------------------------\n# \n#         When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n#         in several steps. This is useful to save some memory in exchange for a small speed decrease.\n# \n#         Args:\n#             slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n#                 When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n#                 a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,\n#                 `attention_head_dim` must be a multiple of `slice_size`.\n#         \"\"\"\n#         if slice_size == \"auto\":\n#             # half the attention head size is usually a good trade-off between\n#             # speed and memory\n#             slice_size = self.unet.config.attention_head_dim // 2\n#         self.unet.set_attention_slice(slice_size)\n# \n#     def disable_attention_slicing(self):\n#         r\"\"\"\n#         Disable sliced attention computation. If `enable_attention_slicing` was previously invoked, this method will go\n#         back to computing attention in one step.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/seed_resize_stable_diffusion.py\n# --------------------------------------------------\n#         r\"\"\"\n#         Enable sliced attention computation.\n# \n#         When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n#         in several steps. This is useful to save some memory in exchange for a small speed decrease.\n# \n#         Args:\n#             slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n#                 When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n#                 a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,\n#                 `attention_head_dim` must be a multiple of `slice_size`.\n#         \"\"\"\n#         if slice_size == \"auto\":\n#             # half the attention head size is usually a good trade-off between\n#             # speed and memory\n#             slice_size = self.unet.config.attention_head_dim // 2\n#         self.unet.set_attention_slice(slice_size)\n# \n#     def disable_attention_slicing(self):\n#         r\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/text_inpainting.py\n# --------------------------------------------------\n#         )\n# \n#     def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n#         r\"\"\"\n#         Enable sliced attention computation.\n# \n#         When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n#         in several steps. This is useful to save some memory in exchange for a small speed decrease.\n# \n#         Args:\n#             slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n#                 When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n#                 a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,\n#                 `attention_head_dim` must be a multiple of `slice_size`.\n#         \"\"\"\n#         if slice_size == \"auto\":\n#             # half the attention head size is usually a good trade-off between\n#             # speed and memory\n#             slice_size = self.unet.config.attention_head_dim // 2\n#         self.unet.set_attention_slice(slice_size)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/img2img_inpainting.py\n# --------------------------------------------------\n# \n#     def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n#         r\"\"\"\n#         Enable sliced attention computation.\n# \n#         When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n#         in several steps. This is useful to save some memory in exchange for a small speed decrease.\n# \n#         Args:\n#             slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n#                 When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n#                 a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,\n#                 `attention_head_dim` must be a multiple of `slice_size`.\n#         \"\"\"\n#         if slice_size == \"auto\":\n#             # half the attention head size is usually a good trade-off between\n#             # speed and memory\n#             slice_size = self.unet.config.attention_head_dim // 2\n#         self.unet.set_attention_slice(slice_size)\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport inspect\nimport time\nfrom pathlib import Path\nfrom typing import Callable, List, Optional, Union\n\nimport numpy as np\nimport torch\n\nfrom diffusers import DiffusionPipeline\nfrom diffusers.configuration_utils import FrozenDict\nfrom diffusers.models import AutoencoderKL, UNet2DConditionModel\nfrom diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\nfrom diffusers.pipelines.stable_diffusion.safety_checker import StableDiffusionSafetyChecker\nfrom diffusers.schedulers import DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler\nfrom diffusers.utils import deprecate, logging\nfrom transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n\n\nlogger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n\n\ndef slerp(t, v0, v1, DOT_THRESHOLD=0.9995):\n    \"\"\"helper function to spherically interpolate two arrays v1 v2\"\"\"\n\n    if not isinstance(v0, np.ndarray):\n        inputs_are_torch = True\n        input_device = v0.device\n        v0 = v0.cpu().numpy()\n        v1 = v1.cpu().numpy()\n\n    dot = np.sum(v0 * v1 / (np.linalg.norm(v0) * np.linalg.norm(v1)))\n    if np.abs(dot) > DOT_THRESHOLD:\n        v2 = (1 - t) * v0 + t * v1\n    else:\n        theta_0 = np.arccos(dot)\n        sin_theta_0 = np.sin(theta_0)\n        theta_t = theta_0 * t\n        sin_theta_t = np.sin(theta_t)\n        s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n        s1 = sin_theta_t / sin_theta_0\n        v2 = s0 * v0 + s1 * v1\n\n    if inputs_are_torch:\n        v2 = torch.from_numpy(v2).to(input_device)\n\n    return v2\n\n\nclass StableDiffusionWalkPipeline(DiffusionPipeline):\n    r\"\"\"\n    Pipeline for text-to-image generation using Stable Diffusion.\n\n    This model inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods the\n    library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)\n\n    Args:\n        vae ([`AutoencoderKL`]):\n            Variational Auto-Encoder (VAE) Model to encode and decode images to and from latent representations.\n        text_encoder ([`CLIPTextModel`]):\n            Frozen text-encoder. Stable Diffusion uses the text portion of\n            [CLIP](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel), specifically\n            the [clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14) variant.\n        tokenizer (`CLIPTokenizer`):\n            Tokenizer of class\n            [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).\n        unet ([`UNet2DConditionModel`]): Conditional U-Net architecture to denoise the encoded image latents.\n        scheduler ([`SchedulerMixin`]):\n            A scheduler to be used in combination with `unet` to denoise the encoded image latents. Can be one of\n            [`DDIMScheduler`], [`LMSDiscreteScheduler`], or [`PNDMScheduler`].\n        safety_checker ([`StableDiffusionSafetyChecker`]):\n            Classification module that estimates whether generated images could be considered offensive or harmful.\n            Please, refer to the [model card](https://huggingface.co/CompVis/stable-diffusion-v1-4) for details.\n        feature_extractor ([`CLIPFeatureExtractor`]):\n            Model that extracts features from generated images to be used as inputs for the `safety_checker`.\n    \"\"\"\n\n    def __init__(\n        self,\n        vae: AutoencoderKL,\n        text_encoder: CLIPTextModel,\n        tokenizer: CLIPTokenizer,\n        unet: UNet2DConditionModel,\n        scheduler: Union[DDIMScheduler, PNDMScheduler, LMSDiscreteScheduler],\n        safety_checker: StableDiffusionSafetyChecker,\n        feature_extractor: CLIPFeatureExtractor,\n    ):\n        super().__init__()\n\n        if hasattr(scheduler.config, \"steps_offset\") and scheduler.config.steps_offset != 1:\n            deprecation_message = (\n                f\"The configuration file of this scheduler: {scheduler} is outdated. `steps_offset`\"\n                f\" should be set to 1 instead of {scheduler.config.steps_offset}. Please make sure \"\n                \"to update the config accordingly as leaving `steps_offset` might led to incorrect results\"\n                \" in future versions. If you have downloaded this checkpoint from the Hugging Face Hub,\"\n                \" it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json`\"\n                \" file\"\n            )\n            deprecate(\"steps_offset!=1\", \"1.0.0\", deprecation_message, standard_warn=False)\n            new_config = dict(scheduler.config)\n            new_config[\"steps_offset\"] = 1\n            scheduler._internal_dict = FrozenDict(new_config)\n\n        if safety_checker is None:\n            logger.warning(\n                f\"You have disabled the safety checker for {self.__class__} by passing `safety_checker=None`. Ensure\"\n                \" that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered\"\n                \" results in services or applications open to the public. Both the diffusers team and Hugging Face\"\n                \" strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling\"\n                \" it only for use-cases that involve analyzing network behavior or auditing its results. For more\"\n                \" information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\"\n            )\n\n        self.register_modules(\n            vae=vae,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,\n            unet=unet,\n            scheduler=scheduler,\n            safety_checker=safety_checker,\n            feature_extractor=feature_extractor,\n        )\n\n    def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n        r\"\"\"\n        Enable sliced attention computation.\n\n        When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n        in several steps. This is useful to save some memory in exchange for a small speed decrease.\n\n        Args:\n            slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):", "choices": [{"text": "\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case, `attention_head_dim` must be a multiple of `slice_size"}], "metadata": {"task_id": "huggingface_diffusers/160", "ground_truth": "                When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If", "fpath_tuple": ["huggingface_diffusers", "examples", "community", "interpolate_stable_diffusion.py"], "context_start_lineno": 0, "line_no": 131, "query_window": {"context": "\n        self.register_modules(\n            vae=vae,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,\n            unet=unet,\n            scheduler=scheduler,\n            safety_checker=safety_checker,\n            feature_extractor=feature_extractor,\n        )\n\n    def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n        r\"\"\"\n        Enable sliced attention computation.\n\n        When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n        in several steps. This is useful to save some memory in exchange for a small speed decrease.\n\n        Args:\n            slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):", "metadata": {"fpath_tuple": ["huggingface_diffusers", "examples", "community", "interpolate_stable_diffusion.py"], "line_no": 131, "task_id": "huggingface_diffusers/160", "start_line_no": 111, "end_line_no": 131, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "\n        self.register_modules(\n            vae=vae,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,\n            unet=unet,\n            scheduler=scheduler,\n            safety_checker=safety_checker,\n            feature_extractor=feature_extractor,\n        )\n\n    def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n        r\"\"\"\n        Enable sliced attention computation.\n\n        When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n        in several steps. This is useful to save some memory in exchange for a small speed decrease.\n\n        Args:\n            slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "img2img_inpainting.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 1.0}, {"context": "        self.register_modules(\n            segmentation_model=segmentation_model,\n            segmentation_processor=segmentation_processor,\n            vae=vae,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,\n            unet=unet,\n            scheduler=scheduler,\n            safety_checker=safety_checker,\n            feature_extractor=feature_extractor,\n        )\n\n    def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n        r\"\"\"\n        Enable sliced attention computation.\n\n        When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n        in several steps. This is useful to save some memory in exchange for a small speed decrease.\n\n        Args:", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "text_inpainting.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.8596491228070176}, {"context": "            vae=vae,\n            text_encoder=text_encoder,\n            tokenizer=tokenizer,\n            unet=unet,\n            scheduler=scheduler,\n            safety_checker=safety_checker,\n            feature_extractor=feature_extractor,\n        )\n\n    def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n        r\"\"\"\n        Enable sliced attention computation.\n\n        When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n        in several steps. This is useful to save some memory in exchange for a small speed decrease.\n\n        Args:\n            slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n                When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n                a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "seed_resize_stable_diffusion.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.8267716535433071}, {"context": "            tokenizer=tokenizer,\n            unet=unet,\n            scheduler=scheduler,\n            safety_checker=safety_checker,\n            feature_extractor=feature_extractor,\n        )\n\n    def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n        r\"\"\"\n        Enable sliced attention computation.\n\n        When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n        in several steps. This is useful to save some memory in exchange for a small speed decrease.\n\n        Args:\n            slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n                When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n                a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,\n                `attention_head_dim` must be a multiple of `slice_size`.\n        \"\"\"", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "multilingual_stable_diffusion.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7424242424242424}, {"context": "            tokenizer=tokenizer,\n            unet=unet,\n            scheduler=scheduler,\n            safety_checker=safety_checker,\n            feature_extractor=feature_extractor,\n        )\n\n    def enable_attention_slicing(self, slice_size: Optional[Union[str, int]] = \"auto\"):\n        r\"\"\"\n        Enable sliced attention computation.\n        When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n        in several steps. This is useful to save some memory in exchange for a small speed decrease.\n        Args:\n            slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n                When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n                a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,\n                `attention_head_dim` must be a multiple of `slice_size`.\n        \"\"\"\n        if slice_size == \"auto\":\n            # half the attention head size is usually a good trade-off between", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "imagic_stable_diffusion.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6758620689655173}, {"context": "        r\"\"\"\n        Enable sliced attention computation.\n\n        When this option is enabled, the attention module will split the input tensor in slices, to compute attention\n        in several steps. This is useful to save some memory in exchange for a small speed decrease.\n\n        Args:\n            slice_size (`str` or `int`, *optional*, defaults to `\"auto\"`):\n                When `\"auto\"`, halves the input to the attention heads, so attention will be computed in two steps. If\n                a number is provided, uses as many slices as `attention_head_dim // slice_size`. In this case,\n                `attention_head_dim` must be a multiple of `slice_size`.\n        \"\"\"\n        if slice_size == \"auto\":\n            # half the attention head size is usually a good trade-off between\n            # speed and memory\n            slice_size = self.unet.config.attention_head_dim // 2\n        self.unet.set_attention_slice(slice_size)\n\n    def disable_attention_slicing(self):\n        r\"\"\"", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "seed_resize_stable_diffusion.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.4966887417218543}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#                 raise RuntimeError(\"self._env._env.task._random does not exist\")\n#             self._env.task._random = random_state\n#         self.reset()\n#         return _seed\n# \n#     def _output_transform(\n#         self, timestep_tuple: Tuple[\"TimeStep\"]  # noqa: F821\n#     ) -> Tuple[np.ndarray, float, bool]:\n#         if type(timestep_tuple) is not tuple:\n#             timestep_tuple = (timestep_tuple,)\n#         reward = timestep_tuple[0].reward\n# \n#         done = False  # dm_control envs are non-terminating\n#         observation = timestep_tuple[0].observation\n#         return observation, reward, done\n# \n#     @property\n#     def input_spec(self) -> TensorSpec:\n#         if self._input_spec is None:\n#             self.__dict__[\"_input_spec\"] = CompositeSpec(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/replay_buffers.py\n# --------------------------------------------------\n#         Transforms are executed in order when `sample` is called.\n# \n#         Args:\n#             index (int): Position to insert the transform.\n#             transform (Transform): The transform to be appended\n#         \"\"\"\n#         transform.eval()\n#         self._transform.insert(index, transform)\n# \n# \n# class PrioritizedReplayBuffer(ReplayBuffer):\n#     \"\"\"Prioritized replay buffer.\n# \n#     Presented in\n#         \"Schaul, T.; Quan, J.; Antonoglou, I.; and Silver, D. 2015.\n#         Prioritized experience replay.\"\n#         (https://arxiv.org/abs/1511.05952)\n# \n#     Args:\n#         alpha (float): exponent \u03b1 determines how much prioritization is used,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_libs.py\n# --------------------------------------------------\n# \n# @implement_for(\"gym\", \"0.26\", None)\n# def _make_gym_environment(env_name):  # noqa: F811\n#     return gym.make(env_name, render_mode=\"rgb_array\")\n# \n# \n# @pytest.mark.skipif(not _has_dmc, reason=\"no dm_control library found\")\n# @pytest.mark.parametrize(\"env_name,task\", [[\"cheetah\", \"run\"]])\n# @pytest.mark.parametrize(\"frame_skip\", [1, 3])\n# @pytest.mark.parametrize(\n#     \"from_pixels,pixels_only\",\n#     [\n#         [True, True],\n#         [True, False],\n#         [False, False],\n#     ],\n# )\n# class TestDMControl:\n#     def test_dmcontrol(self, env_name, task, frame_skip, from_pixels, pixels_only):\n#         if from_pixels and (not torch.has_cuda or not torch.cuda.device_count()):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#         # specs are defined when first called\n#         return\n# \n#     def _check_kwargs(self, kwargs: Dict):\n#         if \"env\" not in kwargs:\n#             raise TypeError(\"Could not find environment key 'env' in kwargs.\")\n#         env = kwargs[\"env\"]\n#         if not isinstance(env, (dm_control.rl.control.Environment, pixels.Wrapper)):\n#             raise TypeError(\n#                 \"env is not of type 'dm_control.rl.control.Environment' or `dm_control.suite.wrappers.pixels.Wrapper`.\"\n#             )\n# \n#     def _set_egl_device(self, device: DEVICE_TYPING):\n#         # Deprecated as lead to unreliable rendering\n#         # egl device needs to be set before importing mujoco bindings: in\n#         # distributed settings, it'll be easy to tell which cuda device to use.\n#         # In mp settings, we'll need to use mp.Pool with a specific init function\n#         # that defines the EGL device before importing libraries. For now, we'll\n#         # just use a common EGL_DEVICE_ID environment variable for all processes.\n#         return\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#             if render_kwargs is not None:\n#                 self.render_kwargs.update(render_kwargs)\n#             env = pixels.Wrapper(\n#                 env,\n#                 pixels_only=self.pixels_only,\n#                 render_kwargs=self.render_kwargs,\n#             )\n#         return env\n# \n#     def _make_specs(self, env: \"gym.Env\") -> None:  # noqa: F821\n#         # specs are defined when first called\n#         return\n# \n#     def _check_kwargs(self, kwargs: Dict):\n#         if \"env\" not in kwargs:\n#             raise TypeError(\"Could not find environment key 'env' in kwargs.\")\n#         env = kwargs[\"env\"]\n#         if not isinstance(env, (dm_control.rl.control.Environment, pixels.Wrapper)):\n#             raise TypeError(\n#                 \"env is not of type 'dm_control.rl.control.Environment' or `dm_control.suite.wrappers.pixels.Wrapper`.\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_libs.py\n# --------------------------------------------------\n#             from_pixels=from_pixels,\n#             pixels_only=pixels_only,\n#         )\n#         check_env_specs(env)\n# \n# \n# @implement_for(\"gym\", None, \"0.26\")\n# def _make_gym_environment(env_name):  # noqa: F811\n#     return gym.make(env_name)\n# \n# \n# @implement_for(\"gym\", \"0.26\", None)\n# def _make_gym_environment(env_name):  # noqa: F811\n#     return gym.make(env_name, render_mode=\"rgb_array\")\n# \n# \n# @pytest.mark.skipif(not _has_dmc, reason=\"no dm_control library found\")\n# @pytest.mark.parametrize(\"env_name,task\", [[\"cheetah\", \"run\"]])\n# @pytest.mark.parametrize(\"frame_skip\", [1, 3])\n# @pytest.mark.parametrize(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\naction_encoding\n            else torch.long\n        )\n        return (\n            MultiDiscreteTensorSpec(spec.nvec, device=device, dtype=dtype)\n            if categorical_action_encoding\n            else MultiOneHotDiscreteTensorSpec(spec.nvec, device=device, dtype=dtype)\n        )\n    elif isinstance(spec, gym.spaces.Box):\n        shape = spec.shape\n        if not len(shape):\n            shape = torch.Size([1])\n        if dtype is None:\n            dtype = numpy_to_torch_dtype_dict[spec.dtype]\n        low = torch.tensor(spec.low, device=device, dtype=dtype)\n        high = torch.tensor(spec.high, device=device, dtype=dtype)\n        is_unbounded = low.isinf().all() and high.isinf().all()\n        return (\n            UnboundedContinuousTensorSpec(shape, device=device, dtype=dtype)\n            if is_unbounded\n            else BoundedTensorSpec(\n                low,\n                high,\n                shape,\n                dtype=dtype,\n                device=device,\n            )\n        )\n    elif isinstance(spec, (Dict,)):\n        spec_out = {}\n        for k in spec.keys():\n            spec_out[k] = _gym_to_torchrl_spec_transform(\n                spec[k],\n                device=device,\n                categorical_action_encoding=categorical_action_encoding,\n            )\n        return CompositeSpec(**spec_out)\n    elif isinstance(spec, gym.spaces.dict.Dict):\n        return _gym_to_torchrl_spec_transform(\n            spec.spaces,\n            device=device,\n            categorical_action_encoding=categorical_action_encoding,\n        )\n    else:\n        raise NotImplementedError(\n            f\"spec of type {type(spec).__name__} is currently unaccounted for\"\n        )\n\n\ndef _get_envs(to_dict=False) -> List:\n    envs = _get_gym_envs()\n    envs = list(envs)\n    envs = sorted(envs)\n    return envs\n\n\n@implement_for(\"gym\", None, \"0.26.0\")\ndef _get_gym_envs():  # noqa: F811\n    return gym.envs.registration.registry.env_specs.keys()\n\n\n@implement_for(\"gym\", \"0.26.0\", None)\ndef _get_gym_envs():  # noqa: F811\n    return gym.envs.registration.registry.keys()\n\n\ndef _get_gym():\n    if _has_gym:\n        return gym\n    else:\n        return None\n\n\ndef _is_from_pixels(env):\n    observation_spec = env.observation_space\n    if isinstance(observation_spec, (Dict,)):\n        if \"pixels\" in set(observation_spec.keys()):\n            return True\n    if isinstance(observation_spec, (gym.spaces.dict.Dict,)):\n        if \"pixels\" in set(observation_spec.spaces.keys()):\n            return True\n    elif (\n        isinstance(observation_spec, gym.spaces.Box)\n        and (observation_spec.low == 0).all()\n        and (observation_spec.high == 255).all()\n        and observation_spec.low.shape[-1] == 3\n        and observation_spec.low.ndim == 3\n    ):\n        return True\n    elif isinstance(env, PixelObservationWrapper):\n        return True\n    return False\n\n\nclass GymWrapper(GymLikeEnv):\n    \"\"\"OpenAI Gym environment wrapper.\n\n    Examples:\n        >>> env = gym.make(\"Pendulum-v0\")\n        >>> env = GymWrapper(env)\n        >>> td = env.rand_step()\n        >>> print(td)\n        >>> print(env.available_envs)\n\n    \"\"\"\n\n    git_url = \"https://github.com/openai/gym\"\n    libname = \"gym\"\n\n    def __init__(self, env=None, categorical_action_encoding=False, **kwargs):\n        if env is not None:\n            kwargs[\"env\"] = env\n        self._seed_calls_reset = None\n        self._categorical_action_encoding = categorical_action_encoding\n        super().__init__(**kwargs)\n\n    def _check_kwargs(self, kwargs: Dict):\n        if \"env\" not in kwargs:\n            raise TypeError(\"Could not find environment key 'env' in kwargs.\")\n        env = kwargs[\"env\"]\n        if not (hasattr(env, \"action_space\") and hasattr(env, \"observation_space\")):\n            raise TypeError(\"env is not of type 'gym.Env'.\")\n\n    def _build_env(\n        self,\n        env,\n        from_pixels: bool = False,\n        pixels_only: bool = False,\n    ) -> \"gym.core.Env\":\n        env_from_pixels = _is_from_pixels(env)\n        from_pixels = from_pixels or env_from_pixels\n        self.from_pixels = from_pixels\n        self.pixels_only = pixels_only\n        if from_pixels and not env_from_pixels:\n            if isinstance(env, PixelObservationWrapper):\n                raise TypeError(\n                    \"PixelObservationWrapper cannot be used to wrap an environment\"\n                    \"that is already a PixelObservationWrapper instance.\"\n                )\n            env = self._build_gym_env(env, pixels_only)\n        return env\n\n    @implement_for(\"gym\", None, \"0.26.0\")\n    def _build_gym_env(self, env, pixels_only):  # noqa: F811\n        return PixelObservationWrapper(env, pixels_only=pixels_only)\n\n    @implement_for(\"gym\", \"0.26.0\", None)\n    def _build_gym_env(self, env, pixels_only):  # noqa: F811\n        from gym.wrappers.compatibility import EnvCompatibility\n\n        if env.render_mode:\n            return PixelObservationWrapper(env, pixels_only=pixels_only)\n\n        warnings.warn(\n            \"Environments provided to GymWrapper that need to be wrapped in PixelObservationWrapper \"\n            \"should be created with `gym.make(env_name, render_mode=mode)` where possible,\"\n            'where mode is either \"rgb_array\" or any other supported mode.'\n        )\n        # resetting as 0.26 comes with a very 'nice' OrderEnforcing wrapper\n        env = EnvCompatibility(env)\n        env.reset()\n        return LegacyPixelObservationWrapper(env, pixels_only=pixels_only)\n\n    @_classproperty\n    def available_envs(cls) -> List[str]:\n        return _get_envs()\n\n    @property\n    def lib(self) -> ModuleType:\n        return gym\n\n    def _set_seed(self, seed: int) -> int:  # noqa: F811\n        if self._seed_calls_reset is None:\n            # Determine basing on gym version whether `reset` is called when setting seed.\n            self._set_seed_initial(seed)\n        elif self._seed_calls_reset:\n            self.reset(seed=seed)\n        else:\n            self._env.seed(seed=seed)\n\n        return seed\n\n    @implement_for(\"gym\", None, \"0.19.0\")\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        self._seed_calls_reset = False\n        self._env.seed(seed=seed)\n\n    @implement_for(\"gym\", \"0.19.0\", None)", "choices": [{"text": "def _set_seed_initial(self, seed: int) -> None:"}], "metadata": {"task_id": "pytorch_rl/131", "ground_truth": "    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "context_start_lineno": 80, "line_no": 268, "query_window": {"context": "    def lib(self) -> ModuleType:\n        return gym\n\n    def _set_seed(self, seed: int) -> int:  # noqa: F811\n        if self._seed_calls_reset is None:\n            # Determine basing on gym version whether `reset` is called when setting seed.\n            self._set_seed_initial(seed)\n        elif self._seed_calls_reset:\n            self.reset(seed=seed)\n        else:\n            self._env.seed(seed=seed)\n\n        return seed\n\n    @implement_for(\"gym\", None, \"0.19.0\")\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        self._seed_calls_reset = False\n        self._env.seed(seed=seed)\n\n    @implement_for(\"gym\", \"0.19.0\", None)", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 268, "task_id": "pytorch_rl/131", "start_line_no": 248, "end_line_no": 268, "window_size": 20, "context_start_lineno": 80, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        elif (\n            env_name != PONG_VERSIONED\n            and from_pixels\n            and (not torch.has_cuda or not torch.cuda.device_count())\n        ):\n            raise pytest.skip(\"no cuda device\")\n\n        env = GymEnv(\n            env_name,\n            frame_skip=frame_skip,\n            from_pixels=from_pixels,\n            pixels_only=pixels_only,\n        )\n        check_env_specs(env)\n\n\n@implement_for(\"gym\", None, \"0.26\")\ndef _make_gym_environment(env_name):  # noqa: F811\n    return gym.make(env_name)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_libs.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3220338983050847}, {"context": "        pixels_only: bool = False,\n        camera_id: Union[int, str] = 0,\n        **kwargs,\n    ):\n        self.from_pixels = from_pixels\n        self.pixels_only = pixels_only\n\n        if from_pixels:\n            self._set_egl_device(self.device)\n            self.render_kwargs = {\"camera_id\": camera_id}\n            if render_kwargs is not None:\n                self.render_kwargs.update(render_kwargs)\n            env = pixels.Wrapper(\n                env,\n                pixels_only=self.pixels_only,\n                render_kwargs=self.render_kwargs,\n            )\n        return env\n\n    def _make_specs(self, env: \"gym.Env\") -> None:  # noqa: F821", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3125}, {"context": "            if render_kwargs is not None:\n                self.render_kwargs.update(render_kwargs)\n            env = pixels.Wrapper(\n                env,\n                pixels_only=self.pixels_only,\n                render_kwargs=self.render_kwargs,\n            )\n        return env\n\n    def _make_specs(self, env: \"gym.Env\") -> None:  # noqa: F821\n        # specs are defined when first called\n        return\n\n    def _check_kwargs(self, kwargs: Dict):\n        if \"env\" not in kwargs:\n            raise TypeError(\"Could not find environment key 'env' in kwargs.\")\n        env = kwargs[\"env\"]\n        if not isinstance(env, (dm_control.rl.control.Environment, pixels.Wrapper)):\n            raise TypeError(\n                \"env is not of type 'dm_control.rl.control.Environment' or `dm_control.suite.wrappers.pixels.Wrapper`.\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2923076923076923}, {"context": "            from_pixels=from_pixels,\n            pixels_only=pixels_only,\n        )\n        check_env_specs(env)\n\n\n@implement_for(\"gym\", None, \"0.26\")\ndef _make_gym_environment(env_name):  # noqa: F811\n    return gym.make(env_name)\n\n\n@implement_for(\"gym\", \"0.26\", None)\ndef _make_gym_environment(env_name):  # noqa: F811\n    return gym.make(env_name, render_mode=\"rgb_array\")\n\n\n@pytest.mark.skipif(not _has_dmc, reason=\"no dm_control library found\")\n@pytest.mark.parametrize(\"env_name,task\", [[\"cheetah\", \"run\"]])\n@pytest.mark.parametrize(\"frame_skip\", [1, 3])\n@pytest.mark.parametrize(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_libs.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2845528455284553}, {"context": "\n        Args:\n            transform (Transform): The transform to be appended\n        \"\"\"\n        transform.eval()\n        self._transform.append(transform)\n\n    def insert_transform(self, index: int, transform: \"Transform\") -> None:  # noqa-F821\n        \"\"\"Inserts transform.\n\n        Transforms are executed in order when `sample` is called.\n\n        Args:\n            index (int): Position to insert the transform.\n            transform (Transform): The transform to be appended\n        \"\"\"\n        transform.eval()\n        self._transform.insert(index, transform)\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "replay_buffers.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2830188679245283}, {"context": "    def _set_seed(self, _seed: Optional[int]) -> Optional[int]:\n        if _seed is None:\n            return None\n        random_state = np.random.RandomState(_seed)\n        if isinstance(self._env, pixels.Wrapper):\n            if not hasattr(self._env._env.task, \"_random\"):\n                raise RuntimeError(\"self._env._env.task._random does not exist\")\n            self._env._env.task._random = random_state\n        else:\n            if not hasattr(self._env.task, \"_random\"):\n                raise RuntimeError(\"self._env._env.task._random does not exist\")\n            self._env.task._random = random_state\n        self.reset()\n        return _seed\n\n    def _output_transform(\n        self, timestep_tuple: Tuple[\"TimeStep\"]  # noqa: F821\n    ) -> Tuple[np.ndarray, float, bool]:\n        if type(timestep_tuple) is not tuple:\n            timestep_tuple = (timestep_tuple,)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/sd_text2img_k_diffusion.py\n# examples/community/seed_resize_stable_diffusion.py\n# --------------------------------------------------\n#                 Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n#                 `guidance_scale` is defined as `w` of equation 2. of [Imagen\n#                 Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n#                 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n#                 usually at the expense of lower image quality.\n#             negative_prompt (`str` or `List[str]`, *optional*):\n#                 The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n#                 if `guidance_scale` is less than `1`).\n#             num_images_per_prompt (`int`, *optional*, defaults to 1):\n#                 The number of images to generate per prompt.\n#             eta (`float`, *optional*, defaults to 0.0):\n#                 Corresponds to parameter eta (\u03b7) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n#                 [`schedulers.DDIMScheduler`], will be ignored for others.\n#             generator (`torch.Generator`, *optional*):\n#                 A [torch generator](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make generation\n#                 deterministic.\n#             latents (`torch.FloatTensor`, *optional*):\n#                 Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image\n#                 generation. Can be used to tweak the same generation with different prompts. If not provided, a latents\n#                 tensor will ge generated by sampling using the supplied random `generator`.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/lpw_stable_diffusion_onnx.py\n# --------------------------------------------------\n#                 The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n#                 expense of slower inference.\n#             guidance_scale (`float`, *optional*, defaults to 7.5):\n#                 Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n#                 `guidance_scale` is defined as `w` of equation 2. of [Imagen\n#                 Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n#                 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n#                 usually at the expense of lower image quality.\n#             num_images_per_prompt (`int`, *optional*, defaults to 1):\n#                 The number of images to generate per prompt.\n#             eta (`float`, *optional*, defaults to 0.0):\n#                 Corresponds to parameter eta (\u03b7) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n#                 [`schedulers.DDIMScheduler`], will be ignored for others.\n#             generator (`torch.Generator`, *optional*):\n#                 A [torch generator](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make generation\n#                 deterministic.\n#             latents (`np.ndarray`, *optional*):\n#                 Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image\n#                 generation. Can be used to tweak the same generation with different prompts. If not provided, a latents\n#                 tensor will ge generated by sampling using the supplied random `generator`.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/lpw_stable_diffusion.py\n# --------------------------------------------------\n#             num_inference_steps (`int`, *optional*, defaults to 50):\n#                 The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n#                 expense of slower inference.\n#             guidance_scale (`float`, *optional*, defaults to 7.5):\n#                 Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n#                 `guidance_scale` is defined as `w` of equation 2. of [Imagen\n#                 Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n#                 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n#                 usually at the expense of lower image quality.\n#             num_images_per_prompt (`int`, *optional*, defaults to 1):\n#                 The number of images to generate per prompt.\n#             eta (`float`, *optional*, defaults to 0.0):\n#                 Corresponds to parameter eta (\u03b7) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n#                 [`schedulers.DDIMScheduler`], will be ignored for others.\n#             generator (`torch.Generator`, *optional*):\n#                 A [torch generator](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make generation\n#                 deterministic.\n#             latents (`torch.FloatTensor`, *optional*):\n#                 Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image\n#                 generation. Can be used to tweak the same generation with different prompts. If not provided, a latents\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/wildcard_stable_diffusion.py\n# --------------------------------------------------\n#                 expense of slower inference.\n#             guidance_scale (`float`, *optional*, defaults to 7.5):\n#                 Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n#                 `guidance_scale` is defined as `w` of equation 2. of [Imagen\n#                 Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n#                 1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n#                 usually at the expense of lower image quality.\n#             negative_prompt (`str` or `List[str]`, *optional*):\n#                 The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n#                 if `guidance_scale` is less than `1`).\n#             num_images_per_prompt (`int`, *optional*, defaults to 1):\n#                 The number of images to generate per prompt.\n#             eta (`float`, *optional*, defaults to 0.0):\n#                 Corresponds to parameter eta (\u03b7) in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n#                 [`schedulers.DDIMScheduler`], will be ignored for others.\n#             generator (`torch.Generator`, *optional*):\n#                 A [torch generator](https://pytorch.org/docs/stable/generated/torch.Generator.html) to make generation\n#                 deterministic.\n#             latents (`torch.FloatTensor`, *optional*):\n#                 Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nembeddings = text_embeddings.repeat(1, num_images_per_prompt, 1)\n        text_embeddings = text_embeddings.view(bs_embed * num_images_per_prompt, seq_len, -1)\n\n        # get unconditional embeddings for classifier free guidance\n        if do_classifier_free_guidance:\n            uncond_tokens: List[str]\n            if negative_prompt is None:\n                uncond_tokens = [\"\"] * batch_size\n            elif type(prompt) is not type(negative_prompt):\n                raise TypeError(\n                    f\"`negative_prompt` should be the same type to `prompt`, but got {type(negative_prompt)} !=\"\n                    f\" {type(prompt)}.\"\n                )\n            elif isinstance(negative_prompt, str):\n                uncond_tokens = [negative_prompt]\n            elif batch_size != len(negative_prompt):\n                raise ValueError(\n                    f\"`negative_prompt`: {negative_prompt} has batch size {len(negative_prompt)}, but `prompt`:\"\n                    f\" {prompt} has batch size {batch_size}. Please make sure that passed `negative_prompt` matches\"\n                    \" the batch size of `prompt`.\"\n                )\n            else:\n                uncond_tokens = negative_prompt\n\n            max_length = text_input_ids.shape[-1]\n            uncond_input = self.tokenizer(\n                uncond_tokens,\n                padding=\"max_length\",\n                max_length=max_length,\n                truncation=True,\n                return_tensors=\"pt\",\n            )\n\n            if hasattr(self.text_encoder.config, \"use_attention_mask\") and self.text_encoder.config.use_attention_mask:\n                attention_mask = uncond_input.attention_mask.to(device)\n            else:\n                attention_mask = None\n\n            uncond_embeddings = self.text_encoder(\n                uncond_input.input_ids.to(device),\n                attention_mask=attention_mask,\n            )\n            uncond_embeddings = uncond_embeddings[0]\n\n            # duplicate unconditional embeddings for each generation per prompt, using mps friendly method\n            seq_len = uncond_embeddings.shape[1]\n            uncond_embeddings = uncond_embeddings.repeat(1, num_images_per_prompt, 1)\n            uncond_embeddings = uncond_embeddings.view(batch_size * num_images_per_prompt, seq_len, -1)\n\n            # For classifier free guidance, we need to do two forward passes.\n            # Here we concatenate the unconditional and text embeddings into a single batch\n            # to avoid doing two forward passes\n            text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n\n        return text_embeddings\n\n    def run_safety_checker(self, image, device, dtype):\n        if self.safety_checker is not None:\n            safety_checker_input = self.feature_extractor(self.numpy_to_pil(image), return_tensors=\"pt\").to(device)\n            image, has_nsfw_concept = self.safety_checker(\n                images=image, clip_input=safety_checker_input.pixel_values.to(dtype)\n            )\n        else:\n            has_nsfw_concept = None\n        return image, has_nsfw_concept\n\n    def decode_latents(self, latents):\n        latents = 1 / 0.18215 * latents\n        image = self.vae.decode(latents).sample\n        image = (image / 2 + 0.5).clamp(0, 1)\n        # we always cast to float32 as this does not cause significant overhead and is compatible with bfloa16\n        image = image.cpu().permute(0, 2, 3, 1).float().numpy()\n        return image\n\n    def check_inputs(self, prompt, height, width, callback_steps):\n        if not isinstance(prompt, str) and not isinstance(prompt, list):\n            raise ValueError(f\"`prompt` has to be of type `str` or `list` but is {type(prompt)}\")\n\n        if height % 8 != 0 or width % 8 != 0:\n            raise ValueError(f\"`height` and `width` have to be divisible by 8 but are {height} and {width}.\")\n\n        if (callback_steps is None) or (\n            callback_steps is not None and (not isinstance(callback_steps, int) or callback_steps <= 0)\n        ):\n            raise ValueError(\n                f\"`callback_steps` has to be a positive integer but is {callback_steps} of type\"\n                f\" {type(callback_steps)}.\"\n            )\n\n    def prepare_latents(self, batch_size, num_channels_latents, height, width, dtype, device, generator, latents=None):\n        shape = (batch_size, num_channels_latents, height // 8, width // 8)\n        if latents is None:\n            if device.type == \"mps\":\n                # randn does not work reproducibly on mps\n                latents = torch.randn(shape, generator=generator, device=\"cpu\", dtype=dtype).to(device)\n            else:\n                latents = torch.randn(shape, generator=generator, device=device, dtype=dtype)\n        else:\n            if latents.shape != shape:\n                raise ValueError(f\"Unexpected latents shape, got {latents.shape}, expected {shape}\")\n            latents = latents.to(device)\n\n        # scale the initial noise by the standard deviation required by the scheduler\n        return latents\n\n    @torch.no_grad()\n    def __call__(\n        self,\n        prompt: Union[str, List[str]],\n        height: int = 512,\n        width: int = 512,\n        num_inference_steps: int = 50,\n        guidance_scale: float = 7.5,\n        negative_prompt: Optional[Union[str, List[str]]] = None,\n        num_images_per_prompt: Optional[int] = 1,\n        eta: float = 0.0,\n        generator: Optional[torch.Generator] = None,\n        latents: Optional[torch.FloatTensor] = None,\n        output_type: Optional[str] = \"pil\",\n        return_dict: bool = True,\n        callback: Optional[Callable[[int, int, torch.FloatTensor], None]] = None,\n        callback_steps: Optional[int] = 1,\n        **kwargs,\n    ):\n        r\"\"\"\n        Function invoked when calling the pipeline for generation.\n\n        Args:\n            prompt (`str` or `List[str]`):\n                The prompt or prompts to guide the image generation.\n            height (`int`, *optional*, defaults to 512):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to 512):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.\n            negative_prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n                if `guidance_scale` is less than `1`).", "choices": [{"text": "int"}], "metadata": {"task_id": "huggingface_diffusers/174", "ground_truth": "            num_images_per_prompt (`int`, *optional*, defaults to 1):", "fpath_tuple": ["huggingface_diffusers", "examples", "community", "sd_text2img_k_diffusion.py"], "context_start_lineno": 232, "line_no": 378, "query_window": {"context": "\n        Args:\n            prompt (`str` or `List[str]`):\n                The prompt or prompts to guide the image generation.\n            height (`int`, *optional*, defaults to 512):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to 512):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.\n            negative_prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n                if `guidance_scale` is less than `1`).", "metadata": {"fpath_tuple": ["huggingface_diffusers", "examples", "community", "sd_text2img_k_diffusion.py"], "line_no": 378, "task_id": "huggingface_diffusers/174", "start_line_no": 358, "end_line_no": 378, "window_size": 20, "context_start_lineno": 232, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "\n        Args:\n            prompt (`str` or `List[str]`):\n                The prompt or prompts to guide the image generation.\n            height (`int`, *optional*, defaults to 512):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to 512):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.\n            negative_prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n                if `guidance_scale` is less than `1`).", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "wildcard_stable_diffusion.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 1.0}, {"context": "        Args:\n            prompt (`str` or `List[str]`):\n                The prompt or prompts to guide the image generation.\n            negative_prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n                if `guidance_scale` is less than `1`).\n            height (`int`, *optional*, defaults to 512):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to 512):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.\n            num_images_per_prompt (`int`, *optional*, defaults to 1):", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "lpw_stable_diffusion.py"], "line_no": 900, "start_line_no": 890, "end_line_no": 910, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.9854014598540146}, {"context": "            prompt (`str` or `List[str]`):\n                The prompt or prompts to guide the image generation.\n            negative_prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n                if `guidance_scale` is less than `1`).\n            height (`int`, *optional*, defaults to 512):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to 512):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.\n            num_images_per_prompt (`int`, *optional*, defaults to 1):\n                The number of images to generate per prompt.", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "lpw_stable_diffusion_onnx.py"], "line_no": 900, "start_line_no": 890, "end_line_no": 910, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.9492753623188406}, {"context": "            prompt (`str` or `List[str]`):\n                The prompt or prompts to guide the image generation.\n            height (`int`, *optional*, defaults to 512):\n                The height in pixels of the generated image.\n            width (`int`, *optional*, defaults to 512):\n                The width in pixels of the generated image.\n            num_inference_steps (`int`, *optional*, defaults to 50):\n                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n                expense of slower inference.\n            guidance_scale (`float`, *optional*, defaults to 7.5):\n                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n                usually at the expense of lower image quality.\n            negative_prompt (`str` or `List[str]`, *optional*):\n                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored\n                if `guidance_scale` is less than `1`).\n            num_images_per_prompt (`int`, *optional*, defaults to 1):\n                The number of images to generate per prompt.", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "sd_text2img_k_diffusion.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "community", "seed_resize_stable_diffusion.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.9492753623188406}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/value/__init__.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# from .advantages import GAE, TDEstimate, TDLambdaEstimate\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/dreamer.py\n# --------------------------------------------------\n# from torchrl.envs.utils import set_exploration_mode, step_mdp\n# from torchrl.modules import SafeModule\n# from torchrl.objectives.common import LossModule\n# from torchrl.objectives.utils import distance_loss, hold_out_net\n# from torchrl.objectives.value.functional import vec_td_lambda_return_estimate\n# \n# \n# class DreamerModelLoss(LossModule):\n#     \"\"\"Dreamer Model Loss.\n# \n#     Computes the loss of the dreamer world model. The loss is composed of the kl divergence between the prior and posterior of the RSSM,\n#     the reconstruction loss over the reconstructed observation and the reward loss over the predicted reward.\n# \n#     Reference: https://arxiv.org/abs/1912.01603.\n# \n#     Args:\n#         world_model (SafeModule): the world model.\n#         lambda_kl (float, optional): the weight of the kl divergence loss. Default: 1.0.\n#         lambda_reco (float, optional): the weight of the reconstruction loss. Default: 1.0.\n#         lambda_reward (float, optional): the weight of the reward loss. Default: 1.0.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_modules.py\n# --------------------------------------------------\n#     DreamerActor,\n#     ObsDecoder,\n#     ObsEncoder,\n#     RSSMPosterior,\n#     RSSMPrior,\n#     RSSMRollout,\n# )\n# from torchrl.modules.models.utils import SquashDims\n# from torchrl.modules.planners.mppi import MPPIPlanner\n# from torchrl.objectives.value import TDLambdaEstimate\n# \n# \n# @pytest.fixture\n# def double_prec_fixture():\n#     dtype = torch.get_default_dtype()\n#     torch.set_default_dtype(torch.double)\n#     yield\n#     torch.set_default_dtype(dtype)\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/__init__.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# from .a2c import A2CLoss\n# from .common import LossModule\n# from .ddpg import DDPGLoss\n# from .dqn import DistributionalDQNLoss, DQNLoss\n# from .dreamer import DreamerActorLoss, DreamerModelLoss, DreamerValueLoss\n# from .ppo import ClipPPOLoss, KLPENPPOLoss, PPOLoss\n# from .redq import REDQLoss\n# from .reinforce import ReinforceLoss\n# from .sac import SACLoss\n# from .td3 import TD3Loss\n# from .utils import (\n#     distance_loss,\n#     HardUpdate,\n#     hold_out_net,\n#     hold_out_params,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/losses.py\n# --------------------------------------------------\n#     A2CLoss,\n#     ClipPPOLoss,\n#     DDPGLoss,\n#     DistributionalDQNLoss,\n#     DQNLoss,\n#     HardUpdate,\n#     KLPENPPOLoss,\n#     PPOLoss,\n#     SACLoss,\n#     SoftUpdate,\n# )\n# from torchrl.objectives.common import LossModule\n# from torchrl.objectives.deprecated import REDQLoss_deprecated\n# \n# # from torchrl.objectives.redq import REDQLoss\n# \n# from torchrl.objectives.utils import TargetNetUpdater\n# \n# \n# def make_target_updater(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/__init__.py\n# --------------------------------------------------\n# from .a2c import A2CLoss\n# from .common import LossModule\n# from .ddpg import DDPGLoss\n# from .dqn import DistributionalDQNLoss, DQNLoss\n# from .dreamer import DreamerActorLoss, DreamerModelLoss, DreamerValueLoss\n# from .ppo import ClipPPOLoss, KLPENPPOLoss, PPOLoss\n# from .redq import REDQLoss\n# from .reinforce import ReinforceLoss\n# from .sac import SACLoss\n# from .td3 import TD3Loss\n# from .utils import (\n#     distance_loss,\n#     HardUpdate,\n#     hold_out_net,\n#     hold_out_params,\n#     next_state_value,\n#     SoftUpdate,\n# )\n# \n# # from .value import bellman_max, c_val, dv_val, vtrace, GAE, TDLambdaEstimate, TDEstimate\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/__init__.py\n# --------------------------------------------------\n# from .a2c import A2CLoss\n# from .common import LossModule\n# from .ddpg import DDPGLoss\n# from .dqn import DistributionalDQNLoss, DQNLoss\n# from .dreamer import DreamerActorLoss, DreamerModelLoss, DreamerValueLoss\n# from .ppo import ClipPPOLoss, KLPENPPOLoss, PPOLoss\n# from .redq import REDQLoss\n# from .reinforce import ReinforceLoss\n# from .sac import SACLoss\n# from .td3 import TD3Loss\n# from .utils import (\n#     distance_loss,\n#     HardUpdate,\n#     hold_out_net,\n#     hold_out_params,\n#     next_state_value,\n#     SoftUpdate,\n# )\n# \n# # from .value import bellman_max, c_val, dv_val, vtrace, GAE, TDLambdaEstimate, TDEstimate\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/losses.py\n# --------------------------------------------------\n# )\n# from torchrl.objectives.common import LossModule\n# from torchrl.objectives.deprecated import REDQLoss_deprecated\n# \n# # from torchrl.objectives.redq import REDQLoss\n# \n# from torchrl.objectives.utils import TargetNetUpdater\n# \n# \n# def make_target_updater(\n#     cfg: \"DictConfig\", loss_module: LossModule  # noqa: F821\n# ) -> Optional[TargetNetUpdater]:\n#     \"\"\"Builds a target network weight update object.\"\"\"\n#     if cfg.loss == \"double\":\n#         if not cfg.hard_update:\n#             target_net_updater = SoftUpdate(\n#                 loss_module, 1 - 1 / cfg.value_network_update_interval\n#             )\n#         else:\n#             target_net_updater = HardUpdate(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport argparse\nimport re\nfrom copy import deepcopy\n\nfrom packaging import version as pack_version\n\n_has_functorch = True\ntry:\n    import functorch as ft  # noqa\n\n    make_functional_with_buffers = ft.make_functional_with_buffers\n    FUNCTORCH_ERR = \"\"\nexcept ImportError as err:\n    _has_functorch = False\n    FUNCTORCH_ERR = str(err)\n\nimport numpy as np\nimport pytest\nimport torch\nfrom _utils_internal import dtype_fixture, get_available_devices  # noqa\nfrom mocking_classes import ContinuousActionConvMockEnv\nfrom tensordict.nn import get_functional, TensorDictModule\n\n# from torchrl.data.postprocs.utils import expand_as_right\nfrom tensordict.tensordict import assert_allclose_td, TensorDict\nfrom torch import autograd, nn\nfrom torchrl.data import (\n    BoundedTensorSpec,\n    CompositeSpec,\n    DiscreteTensorSpec,\n    MultiOneHotDiscreteTensorSpec,\n    OneHotDiscreteTensorSpec,\n    UnboundedContinuousTensorSpec,\n)\nfrom torchrl.data.postprocs.postprocs import MultiStep\nfrom torchrl.envs.model_based.dreamer import DreamerEnv\nfrom torchrl.envs.transforms import TensorDictPrimer, TransformedEnv\nfrom torchrl.modules import (\n    DistributionalQValueActor,\n    QValueActor,\n    SafeModule,\n    SafeProbabilisticModule,\n    SafeProbabilisticSequential,\n    SafeSequential,\n    WorldModelWrapper,\n)\nfrom torchrl.modules.distributions.continuous import NormalParamWrapper, TanhNormal\nfrom torchrl.modules.models.model_based import (\n    DreamerActor,\n    ObsDecoder,\n    ObsEncoder,\n    RSSMPosterior,\n    RSSMPrior,\n    RSSMRollout,\n)\nfrom torchrl.modules.models.models import MLP\nfrom torchrl.modules.tensordict_module.actors import (\n    Actor,\n    ActorCriticOperator,\n    ActorValueOperator,\n    ProbabilisticActor,\n    ValueOperator,\n)\nfrom torchrl.modules.utils import Buffer\nfrom torchrl.objectives import (\n    A2CLoss,\n    ClipPPOLoss,\n    DDPGLoss,\n    DistributionalDQNLoss,\n    DQNLoss,\n    DreamerActorLoss,\n    DreamerModelLoss,\n    DreamerValueLoss,\n    KLPENPPOLoss,\n    PPOLoss,\n    SACLoss,\n    TD3Loss,\n)\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.objectives.deprecated import DoubleREDQLoss_deprecated, REDQLoss_deprecated\nfrom torchrl.objectives.redq import REDQLoss\nfrom torchrl.objectives.reinforce import ReinforceLoss\nfrom torchrl.objectives.utils import HardUpdate, hold_out_net, SoftUpdate\nfrom torchrl.objectives.value.advantages import GAE, TDEstimate, TDLambdaEstimate\nfrom torchrl.objectives.value.functional import (", "choices": [{"text": "bellman_max, c_val, dv_val, vtrace"}], "metadata": {"task_id": "pytorch_rl/16", "ground_truth": "    generalized_advantage_estimate,", "fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "context_start_lineno": 0, "line_no": 90, "query_window": {"context": "    A2CLoss,\n    ClipPPOLoss,\n    DDPGLoss,\n    DistributionalDQNLoss,\n    DQNLoss,\n    DreamerActorLoss,\n    DreamerModelLoss,\n    DreamerValueLoss,\n    KLPENPPOLoss,\n    PPOLoss,\n    SACLoss,\n    TD3Loss,\n)\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.objectives.deprecated import DoubleREDQLoss_deprecated, REDQLoss_deprecated\nfrom torchrl.objectives.redq import REDQLoss\nfrom torchrl.objectives.reinforce import ReinforceLoss\nfrom torchrl.objectives.utils import HardUpdate, hold_out_net, SoftUpdate\nfrom torchrl.objectives.value.advantages import GAE, TDEstimate, TDLambdaEstimate\nfrom torchrl.objectives.value.functional import (", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 90, "task_id": "pytorch_rl/16", "start_line_no": 70, "end_line_no": 90, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    A2CLoss,\n    ClipPPOLoss,\n    DDPGLoss,\n    DistributionalDQNLoss,\n    DQNLoss,\n    HardUpdate,\n    KLPENPPOLoss,\n    PPOLoss,\n    SACLoss,\n    SoftUpdate,\n)\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.objectives.deprecated import REDQLoss_deprecated\n\n# from torchrl.objectives.redq import REDQLoss\n\nfrom torchrl.objectives.utils import TargetNetUpdater\n\n\ndef make_target_updater(", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "losses.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5222222222222223}, {"context": "from .ppo import ClipPPOLoss, KLPENPPOLoss, PPOLoss\nfrom .redq import REDQLoss\nfrom .reinforce import ReinforceLoss\nfrom .sac import SACLoss\nfrom .td3 import TD3Loss\nfrom .utils import (\n    distance_loss,\n    HardUpdate,\n    hold_out_net,\n    hold_out_params,\n    next_state_value,\n    SoftUpdate,\n)\n\n# from .value import bellman_max, c_val, dv_val, vtrace, GAE, TDLambdaEstimate, TDEstimate", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "__init__.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 25, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4742268041237113}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom .a2c import A2CLoss\nfrom .common import LossModule\nfrom .ddpg import DDPGLoss\nfrom .dqn import DistributionalDQNLoss, DQNLoss\nfrom .dreamer import DreamerActorLoss, DreamerModelLoss, DreamerValueLoss\nfrom .ppo import ClipPPOLoss, KLPENPPOLoss, PPOLoss\nfrom .redq import REDQLoss\nfrom .reinforce import ReinforceLoss\nfrom .sac import SACLoss\nfrom .td3 import TD3Loss\nfrom .utils import (\n    distance_loss,\n    HardUpdate,\n    hold_out_net,\n    hold_out_params,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "__init__.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4661016949152542}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom dataclasses import dataclass\nfrom typing import Any, Optional, Tuple\n\nfrom torchrl.modules import ActorCriticOperator, ActorValueOperator\nfrom torchrl.objectives import (\n    A2CLoss,\n    ClipPPOLoss,\n    DDPGLoss,\n    DistributionalDQNLoss,\n    DQNLoss,\n    HardUpdate,\n    KLPENPPOLoss,\n    PPOLoss,\n    SACLoss,\n    SoftUpdate,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "losses.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3277310924369748}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom .a2c import A2CLoss\nfrom .common import LossModule\nfrom .ddpg import DDPGLoss\nfrom .dqn import DistributionalDQNLoss, DQNLoss\nfrom .dreamer import DreamerActorLoss, DreamerModelLoss, DreamerValueLoss", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.25}, {"context": "    ActorValueOperator,\n    CEMPlanner,\n    LSTMNet,\n    ProbabilisticActor,\n    QValueActor,\n    SafeModule,\n    ValueOperator,\n)\nfrom torchrl.modules.models import ConvNet, MLP, NoisyLazyLinear, NoisyLinear\nfrom torchrl.modules.models.model_based import (\n    DreamerActor,\n    ObsDecoder,\n    ObsEncoder,\n    RSSMPosterior,\n    RSSMPrior,\n    RSSMRollout,\n)\nfrom torchrl.modules.models.utils import SquashDims\nfrom torchrl.modules.planners.mppi import MPPIPlanner\nfrom torchrl.objectives.value import TDLambdaEstimate", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_modules.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2204724409448819}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nfrom typing import Optional, Tuple\n\nimport torch\nfrom tensordict import TensorDict\n\nfrom torchrl.envs.model_based.dreamer import DreamerEnv\nfrom torchrl.envs.utils import set_exploration_mode, step_mdp\nfrom torchrl.modules import SafeModule\nfrom torchrl.objectives.common import LossModule\nfrom torchrl.objectives.utils import distance_loss, hold_out_net\nfrom torchrl.objectives.value.functional import vec_td_lambda_return_estimate\n\n\nclass DreamerModelLoss(LossModule):\n    \"\"\"Dreamer Model Loss.\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "dreamer.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2097902097902098}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom .advantages import GAE, TDEstimate, TDLambdaEstimate", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "__init__.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 6, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.18867924528301888}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                 \"action_value\": action_value.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#             },\n#         )\n#         return td\n# \n#     @pytest.mark.parametrize(\"delay_value\", (False, True))\n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     @pytest.mark.parametrize(\n#         \"action_spec_type\", (\"nd_bounded\", \"one_hot\", \"categorical\")\n#     )\n#     def test_dqn(self, delay_value, device, action_spec_type):\n#         torch.manual_seed(self.seed)\n#         actor = self._create_mock_actor(\n#             action_spec_type=action_spec_type, device=device\n#         )\n#         td = self._create_mock_data_dqn(\n#             action_spec_type=action_spec_type, device=device\n#         )\n#         loss_fn = DQNLoss(actor, gamma=0.9, loss_function=\"l2\", delay_value=delay_value)\n#         with _check_td_steady(td):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                 \"action\": action,\n#                 \"action_value\": action_value,\n#             },\n#             device=device,\n#         )\n#         return td\n# \n#     def _create_seq_mock_data_dqn(\n#         self,\n#         action_spec_type,\n#         batch=2,\n#         T=4,\n#         obs_dim=3,\n#         action_dim=4,\n#         atoms=None,\n#         device=\"cpu\",\n#     ):\n#         # create a tensordict\n#         total_obs = torch.randn(batch, T + 1, obs_dim, device=device)\n#         obs = total_obs[:, :T]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#         reward = torch.randn(batch, T, 1, device=device)\n#         done = torch.zeros(batch, T, 1, dtype=torch.bool, device=device)\n#         mask = ~torch.zeros(batch, T, dtype=torch.bool, device=device)\n#         td = TensorDict(\n#             batch_size=(batch, T),\n#             source={\n#                 \"observation\": obs.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#                 \"next\": {\n#                     \"observation\": next_obs.masked_fill_(~mask.unsqueeze(-1), 0.0)\n#                 },\n#                 \"done\": done,\n#                 \"collector\": {\"mask\": mask},\n#                 \"reward\": reward.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#                 \"action\": action.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#             },\n#             device=device,\n#         )\n#         return td\n# \n#     @pytest.mark.skipif(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                 \"reward\": reward * mask.to(obs.dtype),\n#                 \"action\": action * mask.to(obs.dtype),\n#             },\n#             device=device,\n#         )\n#         return td\n# \n#     @pytest.mark.skipif(not _has_functorch, reason=\"functorch not installed\")\n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     @pytest.mark.parametrize(\n#         \"delay_actor, delay_qvalue\", [(False, False), (True, True)]\n#     )\n#     @pytest.mark.parametrize(\"policy_noise\", [0.1, 1.0])\n#     @pytest.mark.parametrize(\"noise_clip\", [0.1, 1.0])\n#     def test_td3(\n#         self,\n#         delay_actor,\n#         delay_qvalue,\n#         device,\n#         policy_noise,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#             batch_size=(batch, T),\n#             source={\n#                 \"observation\": obs.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#                 \"next\": {\n#                     \"observation\": next_obs.masked_fill_(~mask.unsqueeze(-1), 0.0)\n#                 },\n#                 \"done\": done,\n#                 \"collector\": {\"mask\": mask},\n#                 \"reward\": reward.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#                 \"action\": action.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#                 \"action_value\": action_value.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#             },\n#         )\n#         return td\n# \n#     @pytest.mark.parametrize(\"delay_value\", (False, True))\n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     @pytest.mark.parametrize(\n#         \"action_spec_type\", (\"nd_bounded\", \"one_hot\", \"categorical\")\n#     )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                 \"done\": done,\n#                 \"collector\": {\"mask\": mask},\n#                 \"reward\": reward.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#                 \"action\": action.masked_fill_(~mask.unsqueeze(-1), 0.0),\n#             },\n#             device=device,\n#         )\n#         return td\n# \n#     @pytest.mark.skipif(\n#         not _has_functorch, reason=f\"functorch not installed: {FUNCTORCH_ERR}\"\n#     )\n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     @pytest.mark.parametrize(\"delay_actor,delay_value\", [(False, False), (True, True)])\n#     def test_ddpg(self, delay_actor, delay_value, device):\n#         torch.manual_seed(self.seed)\n#         actor = self._create_mock_actor(device=device)\n#         value = self._create_mock_value(device=device)\n#         td = self._create_mock_data_ddpg(device=device)\n#         loss_fn = DDPGLoss(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n            np.random.seed(0)\n            loss = loss_fn(td)\n        if n == 0:\n            assert_allclose_td(td, ms_td.select(*list(td.keys())))\n            _loss = sum([item for _, item in loss.items()])\n            _loss_ms = sum([item for _, item in loss_ms.items()])\n            assert (\n                abs(_loss - _loss_ms) < 1e-3\n            ), f\"found abs(loss-loss_ms) = {abs(loss - loss_ms):4.5f} for n=0\"\n        else:\n            with pytest.raises(AssertionError):\n                assert_allclose_td(loss, loss_ms)\n\n        sum([item for _, item in loss_ms.items()]).backward()\n        named_parameters = loss_fn.named_parameters()\n        for name, p in named_parameters:\n            assert p.grad.norm() > 0.0, f\"parameter {name} has null gradient\"\n\n        # Check param update effect on targets\n        target_actor = loss_fn.target_actor_network_params.clone().values(\n            include_nested=True, leaves_only=True\n        )\n        target_qvalue = loss_fn.target_qvalue_network_params.clone().values(\n            include_nested=True, leaves_only=True\n        )\n        for p in loss_fn.parameters():\n            p.data += torch.randn_like(p)\n        target_actor2 = loss_fn.target_actor_network_params.clone().values(\n            include_nested=True, leaves_only=True\n        )\n        target_qvalue2 = loss_fn.target_qvalue_network_params.clone().values(\n            include_nested=True, leaves_only=True\n        )\n        if loss_fn.delay_actor:\n            assert all((p1 == p2).all() for p1, p2 in zip(target_actor, target_actor2))\n        else:\n            assert not any(\n                (p1 == p2).any() for p1, p2 in zip(target_actor, target_actor2)\n            )\n        if loss_fn.delay_qvalue:\n            assert all(\n                (p1 == p2).all() for p1, p2 in zip(target_qvalue, target_qvalue2)\n            )\n        else:\n            assert not any(\n                (p1 == p2).any() for p1, p2 in zip(target_qvalue, target_qvalue2)\n            )\n\n        # check that policy is updated after parameter update\n        actorp_set = set(actor.parameters())\n        loss_fnp_set = set(loss_fn.parameters())\n        assert len(actorp_set.intersection(loss_fnp_set)) == len(actorp_set)\n        parameters = [p.clone() for p in actor.parameters()]\n        for p in loss_fn.parameters():\n            p.data += torch.randn_like(p)\n        assert all((p1 != p2).all() for p1, p2 in zip(parameters, actor.parameters()))\n\n\n@pytest.mark.parametrize(\"version\", [1, 2])\nclass TestSAC:\n    seed = 0\n\n    def _create_mock_actor(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        # Actor\n        action_spec = BoundedTensorSpec(\n            -torch.ones(action_dim), torch.ones(action_dim), (action_dim,)\n        )\n        net = NormalParamWrapper(nn.Linear(obs_dim, 2 * action_dim))\n        module = SafeModule(net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"])\n        actor = ProbabilisticActor(\n            module=module,\n            in_keys=[\"loc\", \"scale\"],\n            spec=action_spec,\n            distribution_class=TanhNormal,\n        )\n        return actor.to(device)\n\n    def _create_mock_qvalue(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n\n        module = ValueClass()\n        qvalue = ValueOperator(\n            module=module,\n            in_keys=[\"observation\", \"action\"],\n        )\n        return qvalue.to(device)\n\n    def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        module = nn.Linear(obs_dim, 1)\n        value = ValueOperator(\n            module=module,\n            in_keys=[\"observation\"],\n        )\n        return value.to(device)\n\n    def _create_mock_distributional_actor(\n        self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n    ):\n        raise NotImplementedError\n\n    def _create_mock_data_sac(\n        self, batch=16, obs_dim=3, action_dim=4, atoms=None, device=\"cpu\"\n    ):\n        # create a tensordict\n        obs = torch.randn(batch, obs_dim, device=device)\n        next_obs = torch.randn(batch, obs_dim, device=device)\n        if atoms:\n            raise NotImplementedError\n        else:\n            action = torch.randn(batch, action_dim, device=device).clamp(-1, 1)\n        reward = torch.randn(batch, 1, device=device)\n        done = torch.zeros(batch, 1, dtype=torch.bool, device=device)\n        td = TensorDict(\n            batch_size=(batch,),\n            source={\n                \"observation\": obs,\n                \"next\": {\"observation\": next_obs},\n                \"done\": done,\n                \"reward\": reward,\n                \"action\": action,\n            },\n            device=device,\n        )\n        return td\n\n    def _create_seq_mock_data_sac(\n        self, batch=8, T=4, obs_dim=3, action_dim=4, atoms=None, device=\"cpu\"\n    ):\n        # create a tensordict\n        total_obs = torch.randn(batch, T + 1, obs_dim, device=device)\n        obs = total_obs[:, :T]\n        next_obs = total_obs[:, 1:]\n        if atoms:\n            action = torch.randn(batch, T, atoms, action_dim, device=device).clamp(\n                -1, 1\n            )\n        else:\n            action = torch.randn(batch, T, action_dim, device=device).clamp(-1, 1)\n        reward = torch.randn(batch, T, 1, device=device)\n        done = torch.zeros(batch, T, 1, dtype=torch.bool, device=device)\n        mask = torch.ones(batch, T, dtype=torch.bool, device=device)\n        td = TensorDict(\n            batch_size=(batch, T),\n            source={\n                \"observation\": obs.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"next\": {\n                    \"observation\": next_obs.masked_fill_(~mask.unsqueeze(-1), 0.0)\n                },\n                \"done\": done,\n                \"collector\": {\"mask\": mask},\n                \"reward\": reward.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"action\": action.masked_fill_(~mask.unsqueeze(-1), 0.0),\n            },\n            device=device,\n        )\n        return td\n\n    @pytest.mark.skipif(", "choices": [{"text": "not _has_functorch, reason=\"functorch not installed\")"}], "metadata": {"task_id": "pytorch_rl/68", "ground_truth": "        not _has_functorch, reason=f\"functorch not installed: {FUNCTORCH_ERR}\"", "fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "context_start_lineno": 861, "line_no": 1025, "query_window": {"context": "        reward = torch.randn(batch, T, 1, device=device)\n        done = torch.zeros(batch, T, 1, dtype=torch.bool, device=device)\n        mask = torch.ones(batch, T, dtype=torch.bool, device=device)\n        td = TensorDict(\n            batch_size=(batch, T),\n            source={\n                \"observation\": obs.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"next\": {\n                    \"observation\": next_obs.masked_fill_(~mask.unsqueeze(-1), 0.0)\n                },\n                \"done\": done,\n                \"collector\": {\"mask\": mask},\n                \"reward\": reward.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"action\": action.masked_fill_(~mask.unsqueeze(-1), 0.0),\n            },\n            device=device,\n        )\n        return td\n\n    @pytest.mark.skipif(", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 1025, "task_id": "pytorch_rl/68", "start_line_no": 1005, "end_line_no": 1025, "window_size": 20, "context_start_lineno": 861, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        reward = torch.randn(batch, T, 1, device=device)\n        done = torch.zeros(batch, T, 1, dtype=torch.bool, device=device)\n        mask = ~torch.zeros(batch, T, dtype=torch.bool, device=device)\n        td = TensorDict(\n            batch_size=(batch, T),\n            source={\n                \"observation\": obs.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"next\": {\n                    \"observation\": next_obs.masked_fill_(~mask.unsqueeze(-1), 0.0)\n                },\n                \"done\": done,\n                \"collector\": {\"mask\": mask},\n                \"reward\": reward.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"action\": action.masked_fill_(~mask.unsqueeze(-1), 0.0),\n            },\n            device=device,\n        )\n        return td\n\n    @pytest.mark.skipif(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.9764705882352941}, {"context": "            action = (action_value == action_value.max(-1, True)[0]).to(torch.long)\n\n        if action_spec_type == \"categorical\":\n            action_value = torch.max(action_value, -1, keepdim=True)[0]\n            action = torch.argmax(action, -1, keepdim=True)\n        # action_value = action_value.unsqueeze(-1)\n        reward = torch.randn(batch, T, 1, device=device)\n        done = torch.zeros(batch, T, 1, dtype=torch.bool, device=device)\n        mask = ~torch.zeros(batch, T, dtype=torch.bool, device=device)\n        td = TensorDict(\n            batch_size=(batch, T),\n            source={\n                \"observation\": obs.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"next\": {\n                    \"observation\": next_obs.masked_fill_(~mask.unsqueeze(-1), 0.0)\n                },\n                \"done\": done,\n                \"collector\": {\"mask\": mask},\n                \"reward\": reward.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"action\": action.masked_fill_(~mask.unsqueeze(-1), 0.0),", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6981132075471698}, {"context": "        reward = torch.randn(batch, T, 1, device=device)\n        done = torch.zeros(batch, T, 1, dtype=torch.bool, device=device)\n        mask = ~torch.zeros(batch, T, 1, dtype=torch.bool, device=device)\n        td = TensorDict(\n            batch_size=(batch, T),\n            source={\n                \"observation\": obs * mask.to(obs.dtype),\n                \"next\": {\"observation\": next_obs * mask.to(obs.dtype)},\n                \"done\": done,\n                \"collector\": {\"mask\": mask},\n                \"reward\": reward * mask.to(obs.dtype),\n                \"action\": action * mask.to(obs.dtype),\n            },\n            device=device,\n        )\n        return td\n\n    @pytest.mark.skipif(not _has_functorch, reason=\"functorch not installed\")\n    @pytest.mark.parametrize(\"device\", get_available_devices())\n    @pytest.mark.parametrize(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6542056074766355}, {"context": "        # create a tensordict\n        total_obs = torch.randn(batch, T + 1, obs_dim, device=device)\n        obs = total_obs[:, :T]\n        next_obs = total_obs[:, 1:]\n        if atoms:\n            action = torch.randn(batch, T, atoms, action_dim, device=device).clamp(\n                -1, 1\n            )\n        else:\n            action = torch.randn(batch, T, action_dim, device=device).clamp(-1, 1)\n        reward = torch.randn(batch, T, 1, device=device)\n        done = torch.zeros(batch, T, 1, dtype=torch.bool, device=device)\n        mask = ~torch.zeros(batch, T, dtype=torch.bool, device=device)\n        td = TensorDict(\n            batch_size=(batch, T),\n            source={\n                \"observation\": obs.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"next\": {\n                    \"observation\": next_obs.masked_fill_(~mask.unsqueeze(-1), 0.0)\n                },", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.616822429906542}, {"context": "            action = torch.argmax(action, -1, keepdim=True)\n        reward = torch.randn(batch, 1)\n        done = torch.zeros(batch, 1, dtype=torch.bool)\n        td = TensorDict(\n            batch_size=(batch,),\n            source={\n                \"observation\": obs,\n                \"next\": {\"observation\": next_obs},\n                \"done\": done,\n                \"reward\": reward,\n                \"action\": action,\n                \"action_value\": action_value,\n            },\n            device=device,\n        )\n        return td\n\n    def _create_seq_mock_data_dqn(\n        self,\n        action_spec_type,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.594059405940594}, {"context": "            batch_size=(batch, T),\n            source={\n                \"observation\": obs.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"next\": {\n                    \"observation\": next_obs.masked_fill_(~mask.unsqueeze(-1), 0.0)\n                },\n                \"done\": done,\n                \"collector\": {\"mask\": mask},\n                \"reward\": reward.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"action\": action.masked_fill_(~mask.unsqueeze(-1), 0.0),\n                \"action_value\": action_value.masked_fill_(~mask.unsqueeze(-1), 0.0),\n            },\n        )\n        return td\n\n    @pytest.mark.parametrize(\"delay_value\", (False, True))\n    @pytest.mark.parametrize(\"device\", get_available_devices())\n    @pytest.mark.parametrize(\n        \"action_spec_type\", (\"nd_bounded\", \"one_hot\", \"categorical\")\n    )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5909090909090909}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#             spec = UnboundedContinuousTensorSpec(4)\n#         else:\n#             raise NotImplementedError\n# \n#         kwargs = {\"distribution_class\": TanhNormal}\n#         if out_keys == [\"loc\", \"scale\"]:\n#             dist_in_keys = [\"loc\", \"scale\"]\n#         elif out_keys == [\"loc_1\", \"scale_1\"]:\n#             dist_in_keys = {\"loc\": \"loc_1\", \"scale\": \"scale_1\"}\n#         else:\n#             raise NotImplementedError\n# \n#         if safe and spec is None:\n#             with pytest.raises(\n#                 RuntimeError,\n#                 match=\"is not a valid configuration as the tensor specs are not \"\n#                 \"specified\",\n#             ):\n#                 prob_module = SafeProbabilisticModule(\n#                     in_keys=dist_in_keys,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#             },\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n# \n#     def _step(\n#         self,\n#         tensordict: TensorDictBase,\n#     ) -> TensorDictBase:\n#         action = tensordict.get(\"action\")\n#         self.count += action.to(torch.int)\n#         return TensorDict(\n#             source={\n#                 \"observation\": self.count,\n#                 \"done\": self.count > self.max_steps,\n#                 \"reward\": torch.zeros_like(self.count, dtype=torch.float),\n#             },\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/vmas.py\n# --------------------------------------------------\n# \n#     def _init_env(self) -> Optional[int]:\n#         pass\n# \n#     def _set_seed(self, seed: Optional[int]):\n#         self._env.seed(seed)\n# \n#     def _reset(\n#         self, tensordict: Optional[TensorDictBase] = None, **kwargs\n#     ) -> TensorDictBase:\n#         if tensordict is not None and \"_reset\" in tensordict.keys():\n#             _reset = tensordict.get(\"_reset\")\n#             envs_to_reset = _reset.any(dim=0)\n#             for env_index, to_reset in enumerate(envs_to_reset):\n#                 if to_reset:\n#                     self._env.reset_at(env_index)\n#             done = _selective_unsqueeze(self._env.done(), batch_size=(self.num_envs,))\n#             obs = []\n#             infos = []\n#             dones = []\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#                 self._storage.load_state_dict(_storage)\n#             elif self._storage is None:\n#                 batch_size = _storage.pop(\"__batch_size\")\n#                 device = _storage.pop(\"__device\")\n#                 self._storage = TensorDict(\n#                     _storage, batch_size=batch_size, device=device\n#                 )\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         else:\n#             raise TypeError(\n#                 f\"Objects of type {type(_storage)} are not supported by ListStorage.load_state_dict\"\n#             )\n#         self.initialized = state_dict[\"initialized\"]\n#         self._len = state_dict[\"_len\"]\n# \n#     def _init(self, data: Union[TensorDictBase, torch.Tensor]) -> None:\n#         print(\"Creating a TensorStorage...\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#             )\n#         return {\n#             \"_storage\": _storage,\n#             \"initialized\": self.initialized,\n#             \"_len\": self._len,\n#         }\n# \n#     def load_state_dict(self, state_dict):\n#         _storage = copy(state_dict[\"_storage\"])\n#         if isinstance(_storage, torch.Tensor):\n#             if isinstance(self._storage, torch.Tensor):\n#                 self._storage.copy_(_storage)\n#             elif self._storage is None:\n#                 self._storage = _storage\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         elif isinstance(_storage, (dict, OrderedDict)):\n#             if isinstance(self._storage, TensorDictBase):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/collectors/collectors.py\n# --------------------------------------------------\n#             if self._td_env is None:\n#                 self._td_env = td.to(env_device)\n#             else:\n#                 self._td_env.update(td, inplace=True)\n#             return self._td_env\n#         else:\n#             return dest.update(td, inplace=True)\n# \n#     def _reset_if_necessary(self) -> None:\n#         done = self._tensordict.get(\"done\")\n#         if not self.reset_when_done:\n#             done = torch.zeros_like(done)\n#         steps = self._tensordict.get((\"collector\", \"step_count\"))\n#         done_or_terminated = done.squeeze(-1) | (steps == self.max_frames_per_traj)\n#         if self._has_been_done is None:\n#             self._has_been_done = done_or_terminated\n#         else:\n#             self._has_been_done = self._has_been_done | done_or_terminated\n#         if not self._has_been_done.all() and self.init_with_lag:\n#             _reset = torch.zeros_like(done_or_terminated).bernoulli_(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#             if isinstance(self._storage, torch.Tensor):\n#                 self._storage.copy_(_storage)\n#             elif self._storage is None:\n#                 self._storage = _storage\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         elif isinstance(_storage, (dict, OrderedDict)):\n#             if isinstance(self._storage, TensorDictBase):\n#                 self._storage.load_state_dict(_storage)\n#             elif self._storage is None:\n#                 batch_size = _storage.pop(\"__batch_size\")\n#                 device = _storage.pop(\"__device\")\n#                 self._storage = TensorDict(\n#                     _storage, batch_size=batch_size, device=device\n#                 )\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nsteps_ops = []\n        self._post_steps_log_ops = []\n        self._pre_steps_log_ops = []\n        self._post_optim_log_ops = []\n        self._pre_optim_ops = []\n        self._post_loss_ops = []\n        self._optimizer_ops = []\n        self._process_optim_batch_ops = []\n        self._post_optim_ops = []\n        self._modules = {}\n\n        if self.optimizer is not None:\n            optimizer_hook = OptimizerHook(self.optimizer)\n            optimizer_hook.register(self)\n\n    def register_module(self, module_name: str, module: Any) -> None:\n        if module_name in self._modules:\n            raise RuntimeError(\n                f\"{module_name} is already registered, choose a different name.\"\n            )\n        self._modules[module_name] = module\n\n    def _get_state(self):\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            state = StateDict(\n                collected_frames=self.collected_frames,\n                _last_log=self._last_log,\n                _last_save=self._last_save,\n                _optim_count=self._optim_count,\n            )\n        else:\n            state = OrderedDict(\n                collected_frames=self.collected_frames,\n                _last_log=self._last_log,\n                _last_save=self._last_save,\n                _optim_count=self._optim_count,\n            )\n        return state\n\n    @property\n    def app_state(self):\n        self._app_state = {\n            \"state\": StateDict(**self._get_state()),\n            \"collector\": self.collector,\n            \"loss_module\": self.loss_module,\n            **{k: item for k, item in self._modules.items()},\n        }\n        return self._app_state\n\n    def state_dict(self) -> Dict:\n        state = self._get_state()\n        state_dict = OrderedDict(\n            collector=self.collector.state_dict(),\n            loss_module=self.loss_module.state_dict(),\n            state=state,\n            **{k: item.state_dict() for k, item in self._modules.items()},\n        )\n        return state_dict\n\n    def load_state_dict(self, state_dict: Dict) -> None:\n        model_state_dict = state_dict[\"loss_module\"]\n        collector_state_dict = state_dict[\"collector\"]\n\n        self.loss_module.load_state_dict(model_state_dict)\n        self.collector.load_state_dict(collector_state_dict)\n        for key, item in self._modules.items():\n            item.load_state_dict(state_dict[key])\n\n        self.collected_frames = state_dict[\"state\"][\"collected_frames\"]\n        self._last_log = state_dict[\"state\"][\"_last_log\"]\n        self._last_save = state_dict[\"state\"][\"_last_save\"]\n        self._optim_count = state_dict[\"state\"][\"_optim_count\"]\n\n    def _save_trainer(self) -> None:\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            if not _has_ts:\n                raise ImportError(\n                    \"torchsnapshot not found. Consider installing torchsnapshot or \"\n                    \"using the torch checkpointing backend (`CKPT_BACKEND=torch`)\"\n                )\n            Snapshot.take(app_state=self.app_state, path=self.save_trainer_file)\n        elif _CKPT_BACKEND == \"torch\":\n            torch.save(self.state_dict(), self.save_trainer_file)\n        else:\n            raise NotImplementedError(\n                f\"CKPT_BACKEND should be one of {_CKPT_BACKEND.backends}, got {_CKPT_BACKEND}.\"\n            )\n\n    def save_trainer(self, force_save: bool = False) -> None:\n        _save = force_save\n        if self.save_trainer_file is not None:\n            if (self.collected_frames - self._last_save) > self.save_trainer_interval:\n                self._last_save = self.collected_frames\n                _save = True\n        if _save and self.save_trainer_file:\n            self._save_trainer()\n\n    def load_from_file(self, file: Union[str, pathlib.Path]) -> Trainer:\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            snapshot = Snapshot(path=file)\n            snapshot.restore(app_state=self.app_state)\n        elif _CKPT_BACKEND == \"torch\":\n            loaded_dict: OrderedDict = torch.load(file)\n            self.load_state_dict(loaded_dict)\n        return self\n\n    def set_seed(self):\n        seed = self.collector.set_seed(self.seed, static_seed=False)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n\n    @property\n    def collector(self) -> _DataCollector:\n        return self._collector\n\n    @collector.setter\n    def collector(self, collector: _DataCollector) -> None:\n        self._collector = collector\n\n    def register_op(self, dest: str, op: Callable, **kwargs) -> None:\n        if dest == \"batch_process\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._batch_process_ops.append((op, kwargs))\n\n        elif dest == \"pre_optim_steps\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._pre_optim_ops.append((op, kwargs))\n\n        elif dest == \"process_optim_batch\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._process_optim_batch_ops.append((op, kwargs))\n\n        elif dest == \"post_loss\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._post_loss_ops.append((op, kwargs))\n\n        elif dest == \"optimizer\":\n            _check_input_output_typehint(\n                op, input=[TensorDictBase, bool, float, int], output=TensorDictBase\n            )\n            self._optimizer_ops.append((op, kwargs))\n\n        elif dest == \"post_steps\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._post_steps_ops.append((op, kwargs))\n\n        elif dest == \"post_optim\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._post_optim_ops.append((op, kwargs))\n\n        elif dest == \"pre_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._pre_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_optim_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_optim_log_ops.append((op, kwargs))\n\n        else:\n            raise RuntimeError(", "choices": [{"text": "f\"Invalid op destination '{dest}'. Please choose one of the following: \""}], "metadata": {"task_id": "pytorch_rl/163", "ground_truth": "                f\"The hook collection {dest} is not recognised. Choose from:\"", "fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "context_start_lineno": 175, "line_no": 351, "query_window": {"context": "        elif dest == \"pre_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._pre_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_optim_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_optim_log_ops.append((op, kwargs))\n\n        else:\n            raise RuntimeError(", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "line_no": 351, "task_id": "pytorch_rl/163", "start_line_no": 331, "end_line_no": 351, "window_size": 20, "context_start_lineno": 175, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            )\n        return {\n            \"_storage\": _storage,\n            \"initialized\": self.initialized,\n            \"_len\": self._len,\n        }\n\n    def load_state_dict(self, state_dict):\n        _storage = copy(state_dict[\"_storage\"])\n        if isinstance(_storage, torch.Tensor):\n            if isinstance(self._storage, torch.Tensor):\n                self._storage.copy_(_storage)\n            elif self._storage is None:\n                self._storage = _storage\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n                )\n        elif isinstance(_storage, (dict, OrderedDict)):\n            if isinstance(self._storage, TensorDictBase):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.27722772277227725}, {"context": "            if td.device == torch.device(\"cpu\") and self.pin_memory:\n                td.pin_memory()\n            self._td_policy.update(td, inplace=True)\n        return self._td_policy\n\n    def _cast_to_env(\n        self, td: TensorDictBase, dest: Optional[TensorDictBase] = None\n    ) -> TensorDictBase:\n        env_device = self.env_device\n        if dest is None:\n            if self._td_env is None:\n                self._td_env = td.to(env_device)\n            else:\n                self._td_env.update(td, inplace=True)\n            return self._td_env\n        else:\n            return dest.update(td, inplace=True)\n\n    def _reset_if_necessary(self) -> None:\n        done = self._tensordict.get(\"done\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "collectors", "collectors.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26804123711340205}, {"context": "        _storage = self._storage\n        if isinstance(_storage, torch.Tensor):\n            pass\n        elif isinstance(_storage, TensorDictBase):\n            _storage = _storage.state_dict()\n        elif _storage is None:\n            _storage = {}\n        else:\n            raise TypeError(\n                f\"Objects of type {type(_storage)} are not supported by LazyTensorStorage.state_dict\"\n            )\n        return {\n            \"_storage\": _storage,\n            \"initialized\": self.initialized,\n            \"_len\": self._len,\n        }\n\n    def load_state_dict(self, state_dict):\n        _storage = copy(state_dict[\"_storage\"])\n        if isinstance(_storage, torch.Tensor):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2647058823529412}, {"context": "            if isinstance(self._storage, torch.Tensor):\n                self._storage.copy_(_storage)\n            elif self._storage is None:\n                self._storage = _storage\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n                )\n        elif isinstance(_storage, (dict, OrderedDict)):\n            if isinstance(self._storage, TensorDictBase):\n                self._storage.load_state_dict(_storage)\n            elif self._storage is None:\n                batch_size = _storage.pop(\"__batch_size\")\n                device = _storage.pop(\"__device\")\n                self._storage = TensorDict(\n                    _storage, batch_size=batch_size, device=device\n                )\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26}, {"context": "        ).expand(self.batch_size)\n\n    def _check_kwargs(self, kwargs: Dict):\n        if \"env\" not in kwargs:\n            raise TypeError(\"Could not find environment key 'env' in kwargs.\")\n        env = kwargs[\"env\"]\n        if not isinstance(env, vmas.simulator.environment.Environment):\n            raise TypeError(\n                \"env is not of type 'vmas.simulator.environment.Environment'.\"\n            )\n\n    def _init_env(self) -> Optional[int]:\n        pass\n\n    def _set_seed(self, seed: Optional[int]):\n        self._env.seed(seed)\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "vmas.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.25663716814159293}, {"context": "            self.count[_reset] = 0\n        else:\n            self.count[:] = 0\n        return TensorDict(\n            source={\n                \"observation\": self.count.clone(),\n                \"done\": self.count > self.max_steps,\n            },\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,\n    ) -> TensorDictBase:\n        action = tensordict.get(\"action\")\n        self.count += action.to(torch.int)\n        return TensorDict(\n            source={", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 890, "start_line_no": 880, "end_line_no": 900, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.25510204081632654}, {"context": "            spec=None,\n            in_keys=in_keys,\n            out_keys=out_keys,\n        )\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n        else:\n            raise NotImplementedError\n\n        kwargs = {\"distribution_class\": TanhNormal}\n        if out_keys == [\"loc\", \"scale\"]:\n            dist_in_keys = [\"loc\", \"scale\"]\n        elif out_keys == [\"loc_1\", \"scale_1\"]:\n            dist_in_keys = {\"loc\": \"loc_1\", \"scale\": \"scale_1\"}\n        else:", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2524271844660194}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# measurements/honest/honest.py\n# --------------------------------------------------\n# # Source: https://github.com/MilaNLProc/honest\n# \n# \"\"\" HONEST score \"\"\"\n# \n# from collections import defaultdict\n# \n# import datasets\n# import numpy as np\n# import pandas as pd\n# import unidecode\n# \n# import evaluate\n# \n# \n# logger = evaluate.logging.get_logger(__name__)\n# \n# \n# _CITATION = \"\"\"\n# @inproceedings{nozza-etal-2021-honest,\n#     title = {\"{HONEST}: Measuring Hurtful Sentence Completion in Language Models\"},\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/seqeval/seqeval.py\n# --------------------------------------------------\n# IOB1\n# IOB2\n# IOE1\n# IOE2\n# IOBES\n# \n# See the [README.md] file at https://github.com/chakki-works/seqeval for more information.\n# \"\"\"\n# \n# _KWARGS_DESCRIPTION = \"\"\"\n# Produces labelling scores along with its sufficient statistics\n# from a source against one or more references.\n# \n# Args:\n#     predictions: List of List of predicted labels (Estimated targets as returned by a tagger)\n#     references: List of List of reference labels (Ground truth (correct) target values)\n#     suffix: True if the IOB prefix is after type, False otherwise. default: False\n#     scheme: Specify target tagging scheme. Should be one of [\"IOB1\", \"IOB2\", \"IOE1\", \"IOE2\", \"IOBES\", \"BILOU\"].\n#         default: None\n#     mode: Whether to count correct entity labels with incorrect I/B tags as true positives or not.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/super_glue/record_evaluation.py\n# --------------------------------------------------\n# \"\"\"\n# Official evaluation script for ReCoRD v1.0.\n# (Some functions are adopted from the SQuAD evaluation script.)\n# \"\"\"\n# \n# \n# import argparse\n# import json\n# import re\n# import string\n# import sys\n# from collections import Counter\n# \n# \n# def normalize_answer(s):\n#     \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n# \n#     def remove_articles(text):\n#         return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/cuad/compute_score.py\n# --------------------------------------------------\n# \"\"\" Official evaluation script for CUAD dataset. \"\"\"\n# \n# import argparse\n# import json\n# import re\n# import string\n# import sys\n# \n# import numpy as np\n# \n# \n# IOU_THRESH = 0.5\n# \n# \n# def get_jaccard(prediction, ground_truth):\n#     remove_tokens = [\".\", \",\", \";\", \":\"]\n# \n#     for token in remove_tokens:\n#         ground_truth = ground_truth.replace(token, \"\")\n#         prediction = prediction.replace(token, \"\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/code_eval/execute.py\n# --------------------------------------------------\n# import multiprocessing\n# import os\n# import platform\n# import signal\n# import tempfile\n# \n# \n# def check_correctness(check_program, timeout, task_id, completion_id):\n#     \"\"\"\n#     Evaluates the functional correctness of a completion by running the test\n#     suite provided in the problem.\n# \n#     :param completion_id: an optional completion ID so we can match\n#         the results later even if execution finishes asynchronously.\n#     \"\"\"\n#     manager = multiprocessing.Manager()\n#     result = manager.list()\n# \n#     p = multiprocessing.Process(target=unsafe_execute, args=(check_program, result, timeout))\n#     p.start()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/squad/compute_score.py\n# --------------------------------------------------\n# \"\"\" Official evaluation script for v1.1 of the SQuAD dataset. \"\"\"\n# \n# import argparse\n# import json\n# import re\n# import string\n# import sys\n# from collections import Counter\n# \n# \n# def normalize_answer(s):\n#     \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n# \n#     def remove_articles(text):\n#         return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n# \n#     def white_space_fix(text):\n#         return \" \".join(text.split())\n# \n#     def remove_punc(text):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# metrics/code_eval/execute.py\n# --------------------------------------------------\n# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# # See the License for the specific language governing permissions and\n# # limitations under the License.\n# \n# # This code is adapted from OpenAI's release\n# # https://github.com/openai/human-eval/blob/master/human_eval/execution.py\n# \n# import contextlib\n# import faulthandler\n# import io\n# import multiprocessing\n# import os\n# import platform\n# import signal\n# import tempfile\n# \n# \n# def check_correctness(check_program, timeout, task_id, completion_id):\n#     \"\"\"\n#     Evaluates the functional correctness of a completion by running the test\n# --------------------------------------------------\n# the below code fragment can be found in:\n# setup.py\n# --------------------------------------------------\n# To create the package for pypi.\n# \n# 0. Prerequisites:\n#    - Dependencies:\n#      - twine: \"pip install twine\"\n#    - Create an account in (and join the 'evaluate' project):\n#      - PyPI: https://pypi.org/\n#      - Test PyPI: https://test.pypi.org/\n# \n# 1. Change the version in:\n#    - __init__.py\n#    - setup.py\n# \n# 2. Commit these changes: \"git commit -m 'Release: VERSION'\"\n# \n# 3. Add a tag in git to mark the release: \"git tag VERSION -m 'Add tag VERSION for pypi'\"\n#    Push the tag to remote: git push --tags origin main\n# \n# 4. Build both the sources and the wheel. Do not change anything in setup.py between\n#    creating the wheel and the source distribution (obviously).\n# --------------------------------------------------\n# the below code fragment can be found in:\n# setup.py\n# --------------------------------------------------\n# # Lint as: python3\n# \"\"\" HuggingFace/Evaluate is an open library for evaluation.\n# \n# Note:\n# \n#    VERSION needs to be formatted following the MAJOR.MINOR.PATCH convention\n#    (we need to follow this convention to be able to retrieve versioned scripts)\n# \n# Simple check list for release from AllenNLP repo: https://github.com/allenai/allennlp/blob/master/setup.py\n# \n# To create the package for pypi.\n# \n# 0. Prerequisites:\n#    - Dependencies:\n#      - twine: \"pip install twine\"\n#    - Create an account in (and join the 'evaluate' project):\n#      - PyPI: https://pypi.org/\n#      - Test PyPI: https://test.pypi.org/\n# \n# 1. Change the version in:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\"\"\"\nUtilities for working with the local dataset cache.\nThis file is adapted from the AllenNLP library at https://github.com/allenai/allennlp\nCopyright by the AllenNLP authors.\n\"\"\"\n\nimport copy\nimport io\nimport json", "choices": [{"text": "import os"}], "metadata": {"task_id": "huggingface_evaluate/14", "ground_truth": "import os", "fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "context_start_lineno": 0, "line_no": 9, "query_window": {"context": "\"\"\"\nUtilities for working with the local dataset cache.\nThis file is adapted from the AllenNLP library at https://github.com/allenai/allennlp\nCopyright by the AllenNLP authors.\n\"\"\"\n\nimport copy\nimport io\nimport json", "metadata": {"fpath_tuple": ["huggingface_evaluate", "src", "evaluate", "utils", "file_utils.py"], "line_no": 9, "task_id": "huggingface_evaluate/14", "start_line_no": 0, "end_line_no": 9, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "# Lint as: python3\n\"\"\" HuggingFace/Evaluate is an open library for evaluation.\n\nNote:\n\n   VERSION needs to be formatted following the MAJOR.MINOR.PATCH convention\n   (we need to follow this convention to be able to retrieve versioned scripts)\n\nSimple check list for release from AllenNLP repo: https://github.com/allenai/allennlp/blob/master/setup.py\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "setup.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.22580645161290322}, {"context": "# Lint as: python3\n\"\"\" HuggingFace/Evaluate is an open library for evaluation.\n\nNote:\n\n   VERSION needs to be formatted following the MAJOR.MINOR.PATCH convention\n   (we need to follow this convention to be able to retrieve versioned scripts)\n\nSimple check list for release from AllenNLP repo: https://github.com/allenai/allennlp/blob/master/setup.py\n\nTo create the package for pypi.\n\n0. Prerequisites:\n   - Dependencies:\n     - twine: \"pip install twine\"\n   - Create an account in (and join the 'evaluate' project):\n     - PyPI: https://pypi.org/\n     - Test PyPI: https://test.pypi.org/\n\n1. Change the version in:", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "setup.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.16153846153846155}, {"context": "# Copyright 2020 The HuggingFace Datasets Authors and the current dataset script contributor.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This code is adapted from OpenAI's release\n# https://github.com/openai/human-eval/blob/master/human_eval/execution.py\n\nimport contextlib\nimport faulthandler\nimport io", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "execute.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1390728476821192}, {"context": "\"\"\" Official evaluation script for v1.1 of the SQuAD dataset. \"\"\"\n\nimport argparse\nimport json\nimport re\nimport string\nimport sys\nfrom collections import Counter\n\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "squad", "compute_score.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.13559322033898305}, {"context": "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# This code is adapted from OpenAI's release\n# https://github.com/openai/human-eval/blob/master/human_eval/execution.py\n\nimport contextlib\nimport faulthandler\nimport io\nimport multiprocessing\nimport os\nimport platform\nimport signal\nimport tempfile\n\n\ndef check_correctness(check_program, timeout, task_id, completion_id):\n    \"\"\"\n    Evaluates the functional correctness of a completion by running the test", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "code_eval", "execute.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1322314049586777}, {"context": "\"\"\" Official evaluation script for CUAD dataset. \"\"\"\n\nimport argparse\nimport json\nimport re\nimport string\nimport sys\n\nimport numpy as np\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "cuad", "compute_score.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.12962962962962962}, {"context": "\"\"\"\nOfficial evaluation script for ReCoRD v1.0.\n(Some functions are adopted from the SQuAD evaluation script.)\n\"\"\"\n\n\nimport argparse\nimport json\nimport re\nimport string", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "super_glue", "record_evaluation.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.12903225806451613}, {"context": "\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nseqeval is a Python framework for sequence labeling evaluation.\nseqeval can evaluate the performance of chunking tasks such as named-entity recognition, part-of-speech tagging, semantic role labeling and so on.\n\nThis is well-tested by using the Perl script conlleval, which can be used for\nmeasuring the performance of a system that has processed the CoNLL-2000 shared task data.\n\nseqeval supports following formats:\nIOB1\nIOB2\nIOE1\nIOE2\nIOBES\n\nSee the [README.md] file at https://github.com/chakki-works/seqeval for more information.\n\"\"\"\n\n_KWARGS_DESCRIPTION = \"\"\"", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "metrics", "seqeval", "seqeval.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.128}, {"context": "# Source: https://github.com/MilaNLProc/honest\n\n\"\"\" HONEST score \"\"\"\n\nfrom collections import defaultdict\n\nimport datasets\nimport numpy as np\nimport pandas as pd\nimport unidecode", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "measurements", "honest", "honest.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.1267605633802817}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#             tokenizer=tokenizer,\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"accuracy\"], 1.0)\n# \n#     def test_class_init(self):\n#         evaluator = TextClassificationEvaluator()\n#         self.assertEqual(evaluator.task, \"text-classification\")\n#         self.assertIsNone(evaluator.default_metric_name)\n# \n#         results = evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"f1\",\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"f1\"], 1.0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#         evaluator = Text2TextGenerationEvaluator()\n#         self.assertEqual(evaluator.task, \"text2text-generation\")\n#         self.assertIsNone(evaluator.default_metric_name)\n# \n#         results = evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"bleu\",\n#         )\n#         self.assertEqual(results[\"bleu\"], 0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(data=self.data)\n#         self.assertEqual(results[\"bleu\"], 0)\n# \n#     def test_overwrite_default_metric(self):\n#         rouge = load(\"rouge\")\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#         evaluator = AutomaticSpeechRecognitionEvaluator()\n#         self.assertEqual(evaluator.task, \"automatic-speech-recognition\")\n#         self.assertIsNone(evaluator.default_metric_name)\n# \n#         results = evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"wer\",\n#         )\n#         self.assertEqual(results[\"wer\"], 1.0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(data=self.data)\n#         self.assertGreater(results[\"wer\"], 1.0)\n# \n#     def test_overwrite_default_metric(self):\n#         cer = load(\"cer\")\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_metric.py\n# --------------------------------------------------\n#         metric.info.features = Features(\n#             {\"predictions\": Sequence(Value(\"string\")), \"references\": Sequence(Value(\"string\"))}\n#         )\n#         metric.compute(predictions=[[\"a\"]], references=[[\"a\"]])\n#         with self.assertRaises(ValueError):\n#             metric.compute(predictions=[\"a\"], references=[\"a\"])\n# \n#     def test_string_casting_tested_once(self):\n# \n#         self.counter = 0\n# \n#         def checked_fct(fct):  # wrapper function that increases a counter on each call\n#             def wrapped(*args, **kwargs):\n#                 self.counter += 1\n#                 return fct(*args, **kwargs)\n# \n#             return wrapped\n# \n#         with mock.patch(\n#             \"evaluate.EvaluationModule._enforce_nested_string_type\",\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#         results = evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=\"f1\",\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"f1\"], 1.0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(\n#             data=self.data,\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"accuracy\"], 1.0)\n# \n#     def test_data_loading(self):\n# \n#         # Test passing in dataset by name with split\n#         data = self.evaluator.load_data(\"evaluate/imdb-ci\", split=\"test[:1]\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#             data=self.data,\n#             metric=\"accuracy\",\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"accuracy\"], 0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(\n#             data=self.data,\n#             label_mapping=self.label_mapping,\n#         )\n#         self.assertEqual(results[\"accuracy\"], 0)\n# \n#     def test_overwrite_default_metric(self):\n#         accuracy = load(\"accuracy\")\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=accuracy,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_evaluator.py\n# --------------------------------------------------\n#             metric=\"seqeval\",\n#         )\n#         self.assertEqual(results[\"overall_accuracy\"], 1.0)\n# \n#     @slow\n#     def test_default_pipe_init(self):\n#         results = self.evaluator.compute(\n#             data=self.data,\n#         )\n#         self.assertEqual(results[\"overall_accuracy\"], 2 / 3)\n# \n#     def test_overwrite_default_metric(self):\n#         accuracy = load(\"seqeval\")\n#         results = self.evaluator.compute(\n#             model_or_pipeline=self.pipe,\n#             data=self.data,\n#             metric=accuracy,\n#         )\n#         self.assertEqual(results[\"overall_accuracy\"], 1.0)\n#         results = self.evaluator.compute(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport glob\nfrom unittest import TestCase\nfrom unittest.mock import patch\n\nimport pytest\nimport requests\nimport yaml\n\nfrom evaluate.hub import push_to_hub\nfrom tests.test_metric import DummyMetric\n\n\nminimum_metadata = {\n    \"model-index\": [\n        {\n            \"results\": [\n                {\n                    \"task\": {\"type\": \"dummy-task\"},\n                    \"dataset\": {\"type\": \"dataset_type\", \"name\": \"dataset_name\"},\n                    \"metrics\": [\n                        {\"type\": \"dummy_metric\", \"value\": 1.0, \"name\": \"Pretty Metric Name\"},\n                    ],\n                }\n            ]\n        }\n    ]\n}\n\nextras_metadata = {\n    \"model-index\": [\n        {\n            \"results\": [\n                {\n                    \"task\": {\"type\": \"dummy-task\", \"name\": \"task_name\"},\n                    \"dataset\": {\n                        \"type\": \"dataset_type\",\n                        \"name\": \"dataset_name\",\n                        \"config\": \"fr\",\n                        \"split\": \"test\",\n                        \"revision\": \"abc\",\n                        \"args\": {\"a\": 1, \"b\": 2},\n                    },\n                    \"metrics\": [\n                        {\n                            \"type\": \"dummy_metric\",\n                            \"value\": 1.0,\n                            \"name\": \"Pretty Metric Name\",\n                            \"config\": \"default\",\n                            \"args\": {\"hello\": 1, \"world\": 2},\n                        },\n                    ],\n                }\n            ]\n        }\n    ]\n}\n\n\n@patch(\"evaluate.hub.HF_HUB_ALLOWED_TASKS\", [\"dummy-task\"])\n@patch(\"evaluate.hub.dataset_info\", lambda x: True)\n@patch(\"evaluate.hub.model_info\", lambda x: True)\n@patch(\"evaluate.hub.metadata_update\")\nclass TestHub(TestCase):\n    @pytest.fixture(autouse=True)\n    def inject_fixtures(self, caplog):\n        self._caplog = caplog\n\n    def setUp(self):\n        self.metric = DummyMetric()\n        self.metric.add()\n        self.args = {\"hello\": 1, \"world\": 2}\n        self.result = self.metric.compute()\n\n    def test_push_metric_required_arguments(self, metadata_update):\n        push_to_hub(\n            model_id=\"username/repo\",\n            metric_value=self.result[\"accuracy\"],\n            metric_name=\"Pretty Metric Name\",\n            metric_type=self.metric.name,\n            dataset_name=\"dataset_name\",\n            dataset_type=\"dataset_type\",\n            task_type=\"dummy-task\",\n        )\n\n        metadata_update.assert_called_once_with(repo_id=\"username/repo\", metadata=minimum_metadata, overwrite=False)\n\n    def test_push_metric_missing_arguments(self, metadata_update):\n        with pytest.raises(TypeError):\n            push_to_hub(", "choices": [{"text": "model_id=\"username/repo\","}], "metadata": {"task_id": "huggingface_evaluate/34", "ground_truth": "                model_id=\"username/repo\",", "fpath_tuple": ["huggingface_evaluate", "tests", "test_hub.py"], "context_start_lineno": 0, "line_no": 89, "query_window": {"context": "        self.metric.add()\n        self.args = {\"hello\": 1, \"world\": 2}\n        self.result = self.metric.compute()\n\n    def test_push_metric_required_arguments(self, metadata_update):\n        push_to_hub(\n            model_id=\"username/repo\",\n            metric_value=self.result[\"accuracy\"],\n            metric_name=\"Pretty Metric Name\",\n            metric_type=self.metric.name,\n            dataset_name=\"dataset_name\",\n            dataset_type=\"dataset_type\",\n            task_type=\"dummy-task\",\n        )\n\n        metadata_update.assert_called_once_with(repo_id=\"username/repo\", metadata=minimum_metadata, overwrite=False)\n\n    def test_push_metric_missing_arguments(self, metadata_update):\n        with pytest.raises(TypeError):\n            push_to_hub(", "metadata": {"fpath_tuple": ["huggingface_evaluate", "tests", "test_hub.py"], "line_no": 89, "task_id": "huggingface_evaluate/34", "start_line_no": 69, "end_line_no": 89, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_evaluate"}}, "top_k_context": [{"context": "        self.assertEqual(results[\"overall_accuracy\"], 0.5)\n\n    def test_class_init(self):\n        evaluator = TokenClassificationEvaluator()\n        self.assertEqual(evaluator.task, \"token-classification\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"seqeval\",\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 1.0)\n\n    @slow\n    def test_default_pipe_init(self):\n        results = self.evaluator.compute(\n            data=self.data,\n        )\n        self.assertEqual(results[\"overall_accuracy\"], 2 / 3)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 720, "start_line_no": 710, "end_line_no": 730, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3089430894308943}, {"context": "        )\n        self.assertEqual(results[\"accuracy\"], 0)\n\n    def test_class_init(self):\n        evaluator = ImageClassificationEvaluator()\n        self.assertEqual(evaluator.task, \"image-classification\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"accuracy\",\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 0)\n\n    @slow\n    def test_default_pipe_init(self):\n        results = self.evaluator.compute(\n            data=self.data,", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 500, "start_line_no": 490, "end_line_no": 510, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.3}, {"context": "            tokenizer=tokenizer,\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    def test_class_init(self):\n        evaluator = TextClassificationEvaluator()\n        self.assertEqual(evaluator.task, \"text-classification\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"f1\",\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"f1\"], 1.0)\n\n    @slow\n    def test_default_pipe_init(self):", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.296}, {"context": "        del metric\n\n    def test_string_casting(self):\n        metric = DummyMetric(experiment_id=\"test_string_casting\")\n        metric.info.features = Features({\"predictions\": Value(\"string\"), \"references\": Value(\"string\")})\n        metric.compute(predictions=[\"a\"], references=[\"a\"])\n        with self.assertRaises(ValueError):\n            metric.compute(predictions=[1], references=[1])\n\n        metric = DummyMetric(experiment_id=\"test_string_casting_2\")\n        metric.info.features = Features(\n            {\"predictions\": Sequence(Value(\"string\")), \"references\": Sequence(Value(\"string\"))}\n        )\n        metric.compute(predictions=[[\"a\"]], references=[[\"a\"]])\n        with self.assertRaises(ValueError):\n            metric.compute(predictions=[\"a\"], references=[\"a\"])\n\n    def test_string_casting_tested_once(self):\n\n        self.counter = 0", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_metric.py"], "line_no": 510, "start_line_no": 500, "end_line_no": 520, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2926829268292683}, {"context": "    def test_pipe_init(self):\n        print(self.evaluator)\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n        )\n        print(results)\n        self.assertEqual(results[\"wer\"], 1.0)\n\n    def test_class_init(self):\n        evaluator = AutomaticSpeechRecognitionEvaluator()\n        self.assertEqual(evaluator.task, \"automatic-speech-recognition\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"wer\",\n        )\n        self.assertEqual(results[\"wer\"], 1.0)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 1000, "start_line_no": 990, "end_line_no": 1010, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2892561983471074}, {"context": "        self.evaluator = evaluator(\"text2text-generation\")\n\n    def test_pipe_init(self):\n        results = self.evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n        )\n        self.assertEqual(results[\"bleu\"], 0)\n\n    def test_class_init(self):\n        evaluator = Text2TextGenerationEvaluator()\n        self.assertEqual(evaluator.task, \"text2text-generation\")\n        self.assertIsNone(evaluator.default_metric_name)\n\n        results = evaluator.compute(\n            model_or_pipeline=self.pipe,\n            data=self.data,\n            metric=\"bleu\",\n        )\n        self.assertEqual(results[\"bleu\"], 0)", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 920, "start_line_no": 910, "end_line_no": 930, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2857142857142857}, {"context": "        )\n\n        model = AutoModelForSequenceClassification.from_pretrained(self.default_model)\n        tokenizer = AutoTokenizer.from_pretrained(self.default_model)\n\n        self.assertEqual(results[\"accuracy\"], 1.0)\n        results = self.evaluator.compute(\n            model_or_pipeline=model,\n            data=self.data,\n            metric=\"accuracy\",\n            tokenizer=tokenizer,\n            label_mapping=self.label_mapping,\n        )\n        self.assertEqual(results[\"accuracy\"], 1.0)\n\n    def test_class_init(self):\n        evaluator = TextClassificationEvaluator()\n        self.assertEqual(evaluator.task, \"text-classification\")\n        self.assertIsNone(evaluator.default_metric_name)\n", "metadata": [{"fpath_tuple": ["huggingface_evaluate", "tests", "test_evaluator.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "huggingface_evaluate", "slice_size": 2}], "sim_score": 0.2846153846153846}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_specs.py\n# --------------------------------------------------\n#                 RuntimeError, match=\"All devices of CompositeSpec must match\"\n#             ):\n#                 ts[\"bad\"] = UnboundedContinuousTensorSpec(device=dest, dtype=dtype)\n# \n#     def test_del(self, is_complete, device, dtype):\n#         ts = self._composite_spec(is_complete, device, dtype)\n#         assert \"obs\" in ts.keys()\n#         assert \"act\" in ts.keys()\n#         del ts[\"obs\"]\n#         assert \"obs\" not in ts.keys()\n#         assert \"act\" in ts.keys()\n# \n#     def test_encode(self, is_complete, device, dtype):\n#         ts = self._composite_spec(is_complete, device, dtype)\n#         if dtype is None:\n#             dtype = torch.get_default_dtype()\n# \n#         for _ in range(100):\n#             r = ts.rand()\n#             raw_vals = {\"obs\": r[\"obs\"].cpu().numpy()}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n#     def __repr__(self) -> str:\n#         return (\n#             f\"{self.__class__.__name__}(\"\n#             f\"loc={self.loc.item():4.4f}, scale={self.scale.item():4.4f}, \"\n#             f\"keys={self.in_keys})\"\n#         )\n# \n# \n# class FiniteTensorDictCheck(Transform):\n#     \"\"\"This transform will check that all the items of the tensordict are finite, and raise an exception if they are not.\"\"\"\n# \n#     def __init__(self):\n#         super().__init__(in_keys=[])\n# \n#     def _call(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         tensordict.apply(check_finite)\n#         return tensordict\n# \n# \n# class DoubleToFloat(Transform):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n#             return BoundedTensorSpec(\n#                 self.clamp_min,\n#                 self.clamp_max,\n#                 shape=reward_spec.shape,\n#                 device=reward_spec.device,\n#                 dtype=reward_spec.dtype,\n#             )\n#         else:\n#             raise NotImplementedError(\n#                 f\"{self.__class__.__name__}.transform_reward_spec not \"\n#                 f\"implemented for tensor spec of type\"\n#                 f\" {type(reward_spec).__name__}\"\n#             )\n# \n#     def __repr__(self) -> str:\n#         return (\n#             f\"{self.__class__.__name__}(\"\n#             f\"clamp_min={float(self.clamp_min):4.4f}, clamp_max\"\n#             f\"={float(self.clamp_max):4.4f}, keys={self.in_keys})\"\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n#     def transform_reward_spec(self, reward_spec: TensorSpec) -> TensorSpec:\n#         if isinstance(reward_spec, UnboundedContinuousTensorSpec):\n#             return reward_spec\n#         else:\n#             raise NotImplementedError(\n#                 f\"{self.__class__.__name__}.transform_reward_spec not \"\n#                 f\"implemented for tensor spec of type\"\n#                 f\" {type(reward_spec).__name__}\"\n#             )\n# \n#     def __repr__(self) -> str:\n#         return (\n#             f\"{self.__class__.__name__}(\"\n#             f\"loc={self.loc.item():4.4f}, scale={self.scale.item():4.4f}, \"\n#             f\"keys={self.in_keys})\"\n#         )\n# \n# \n# class FiniteTensorDictCheck(Transform):\n#     \"\"\"This transform will check that all the items of the tensordict are finite, and raise an exception if they are not.\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/modules/tensordict_module/probabilistic.py\n# --------------------------------------------------\n#                 and all(_spec is None for _spec in spec.values())\n#             ):\n#                 raise RuntimeError(\n#                     \"`SafeProbabilisticModule(spec=None, safe=True)` is not a valid configuration as the tensor \"\n#                     \"specs are not specified\"\n#                 )\n#             self.register_forward_hook(_forward_hook_safe_action)\n# \n#     @property\n#     def spec(self) -> CompositeSpec:\n#         return self._spec\n# \n#     @spec.setter\n#     def spec(self, spec: CompositeSpec) -> None:\n#         if not isinstance(spec, CompositeSpec):\n#             raise RuntimeError(\n#                 f\"Trying to set an object of type {type(spec)} as a tensorspec but expected a CompositeSpec instance.\"\n#             )\n#         self._spec = spec\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#         dist_in_keys = [\"logits\"]\n#     else:\n#         raise NotImplementedError(\n#             f\"actions with domain {action_spec.domain} are not supported\"\n#         )\n# \n#     if cfg.shared_mapping:\n#         hidden_features = 300\n#         if proof_environment.from_pixels:\n#             if in_keys_actor is None:\n#                 in_keys_actor = [\"pixels\"]\n#             common_module = ConvNet(\n#                 bias_last_layer=True,\n#                 depth=None,\n#                 num_cells=[32, 64, 64],\n#                 kernel_sizes=[8, 4, 3],\n#                 strides=[4, 2, 1],\n#             )\n#         else:\n#             if cfg.lstm:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#             policy_distribution_class = TruncatedNormal\n#     elif action_spec.domain == \"discrete\":\n#         out_features = action_spec.shape[-1]\n#         policy_distribution_kwargs = {}\n#         policy_distribution_class = OneHotCategorical\n#         dist_in_keys = [\"logits\"]\n#     else:\n#         raise NotImplementedError(\n#             f\"actions with domain {action_spec.domain} are not supported\"\n#         )\n# \n#     if cfg.shared_mapping:\n#         hidden_features = 300\n#         if proof_environment.from_pixels:\n#             if in_keys_actor is None:\n#                 in_keys_actor = [\"pixels\"]\n#             common_module = ConvNet(\n#                 bias_last_layer=True,\n#                 depth=None,\n#                 num_cells=[32, 64, 64],\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\ntensordict_module.common import (\n    ensure_tensordict_compatible,\n    is_tensordict_compatible,\n)\nfrom torchrl.modules.tensordict_module.probabilistic import (\n    SafeProbabilisticModule,\n    SafeProbabilisticSequential,\n)\nfrom torchrl.modules.tensordict_module.sequence import SafeSequential\n\n_has_functorch = False\ntry:\n    from functorch import vmap\n\n    _has_functorch = True\nexcept ImportError:\n    pass\n\n\nclass TestTDModule:\n    def test_multiple_output(self):\n        class MultiHeadLinear(nn.Module):\n            def __init__(self, in_1, out_1, out_2, out_3):\n                super().__init__()\n                self.linear_1 = nn.Linear(in_1, out_1)\n                self.linear_2 = nn.Linear(in_1, out_2)\n                self.linear_3 = nn.Linear(in_1, out_3)\n\n            def forward(self, x):\n                return self.linear_1(x), self.linear_2(x), self.linear_3(x)\n\n        tensordict_module = SafeModule(\n            MultiHeadLinear(5, 4, 3, 2),\n            in_keys=[\"input\"],\n            out_keys=[\"out_1\", \"out_2\", \"out_3\"],\n        )\n        td = TensorDict({\"input\": torch.randn(3, 5)}, batch_size=[3])\n        td = tensordict_module(td)\n        assert td.shape == torch.Size([3])\n        assert \"input\" in td.keys()\n        assert \"out_1\" in td.keys()\n        assert \"out_2\" in td.keys()\n        assert \"out_3\" in td.keys()\n        assert td.get(\"out_3\").shape == torch.Size([3, 2])\n\n        # Using \"_\" key to ignore some output\n        tensordict_module = SafeModule(\n            MultiHeadLinear(5, 4, 3, 2),\n            in_keys=[\"input\"],\n            out_keys=[\"_\", \"_\", \"out_3\"],\n        )\n        td = TensorDict({\"input\": torch.randn(3, 5)}, batch_size=[3])\n        td = tensordict_module(td)\n        assert td.shape == torch.Size([3])\n        assert \"input\" in td.keys()\n        assert \"out_3\" in td.keys()\n        assert \"_\" not in td.keys()\n        assert td.get(\"out_3\").shape == torch.Size([3, 2])\n\n    def test_spec_key_warning(self):\n        class MultiHeadLinear(nn.Module):\n            def __init__(self, in_1, out_1, out_2):\n                super().__init__()\n                self.linear_1 = nn.Linear(in_1, out_1)\n                self.linear_2 = nn.Linear(in_1, out_2)\n\n            def forward(self, x):\n                return self.linear_1(x), self.linear_2(x)\n\n        spec_dict = {\n            \"_\": UnboundedContinuousTensorSpec((4,)),\n            \"out_2\": UnboundedContinuousTensorSpec((3,)),\n        }\n\n        # warning due to \"_\" in spec keys\n        with pytest.warns(UserWarning, match='got a spec with key \"_\"'):\n            tensordict_module = SafeModule(\n                MultiHeadLinear(5, 4, 3),\n                in_keys=[\"input\"],\n                out_keys=[\"_\", \"out_2\"],\n                spec=CompositeSpec(**spec_dict),\n            )\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    @pytest.mark.parametrize(\"lazy\", [True, False])\n    def test_stateful(self, safe, spec_type, lazy):\n        torch.manual_seed(0)\n        param_multiplier = 1\n        if lazy:\n            net = nn.LazyLinear(4 * param_multiplier)\n        else:\n            net = nn.Linear(3, 4 * param_multiplier)\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n\n        if safe and spec is None:\n            with pytest.raises(\n                RuntimeError,\n                match=\"is not a valid configuration as the tensor specs are not \"\n                \"specified\",\n            ):\n                tensordict_module = SafeModule(\n                    module=net,\n                    spec=spec,\n                    in_keys=[\"in\"],\n                    out_keys=[\"out\"],\n                    safe=safe,\n                )\n            return\n        else:\n            tensordict_module = SafeModule(\n                module=net,\n                spec=spec,\n                in_keys=[\"in\"],\n                out_keys=[\"out\"],\n                safe=safe,\n            )\n\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        tensordict_module(td)\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 4])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"safe\", [True, False])\n    @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n    @pytest.mark.parametrize(\"out_keys\", [[\"loc\", \"scale\"], [\"loc_1\", \"scale_1\"]])\n    @pytest.mark.parametrize(\"lazy\", [True, False])\n    @pytest.mark.parametrize(\"exp_mode\", [\"mode\", \"random\", None])\n    def test_stateful_probabilistic(self, safe, spec_type, lazy, exp_mode, out_keys):\n        torch.manual_seed(0)\n        param_multiplier = 2\n        if lazy:\n            net = nn.LazyLinear(4 * param_multiplier)\n        else:\n            net = nn.Linear(3, 4 * param_multiplier)\n\n        in_keys = [\"in\"]\n        net = SafeModule(\n            module=NormalParamWrapper(net),\n            spec=None,\n            in_keys=in_keys,\n            out_keys=out_keys,\n        )\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n        else:\n            raise NotImplementedError\n\n        kwargs = {\"distribution_class\": TanhNormal}\n        if out_keys == [\"loc\", \"scale\"]:\n            dist_in_keys = [\"loc\", \"scale\"]\n        elif out_keys == [\"loc_1\", \"scale_1\"]:\n            dist_in_keys = {\"loc\": \"loc_1\", \"scale\": \"scale_1\"}\n        else:\n            raise NotImplementedError\n\n        if safe and spec is None:\n            with pytest.raises(\n                RuntimeError,\n                match=\"is not a valid configuration as the tensor specs are not \"\n                \"specified\",\n            ):\n                prob_module = SafeProbabilisticModule(", "choices": [{"text": "SafeProbabilisticModule("}], "metadata": {"task_id": "pytorch_rl/67", "ground_truth": "                    in_keys=dist_in_keys,", "fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "context_start_lineno": 19, "line_no": 199, "query_window": {"context": "        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n        else:\n            raise NotImplementedError\n\n        kwargs = {\"distribution_class\": TanhNormal}\n        if out_keys == [\"loc\", \"scale\"]:\n            dist_in_keys = [\"loc\", \"scale\"]\n        elif out_keys == [\"loc_1\", \"scale_1\"]:\n            dist_in_keys = {\"loc\": \"loc_1\", \"scale\": \"scale_1\"}\n        else:\n            raise NotImplementedError\n\n        if safe and spec is None:\n            with pytest.raises(\n                RuntimeError,\n                match=\"is not a valid configuration as the tensor specs are not \"\n                \"specified\",\n            ):\n                prob_module = SafeProbabilisticModule(", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 199, "task_id": "pytorch_rl/67", "start_line_no": 179, "end_line_no": 199, "window_size": 20, "context_start_lineno": 19, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "                \"max\": action_spec.space.maximum,\n                \"tanh_loc\": cfg.tanh_loc,\n            }\n            policy_distribution_class = TanhNormal\n        elif cfg.distribution == \"truncated_normal\":\n            policy_distribution_kwargs = {\n                \"min\": action_spec.space.minimum,\n                \"max\": action_spec.space.maximum,\n                \"tanh_loc\": cfg.tanh_loc,\n            }\n            policy_distribution_class = TruncatedNormal\n    elif action_spec.domain == \"discrete\":\n        out_features = action_spec.shape[-1]\n        policy_distribution_kwargs = {}\n        policy_distribution_class = OneHotCategorical\n        dist_in_keys = [\"logits\"]\n    else:\n        raise NotImplementedError(\n            f\"actions with domain {action_spec.domain} are not supported\"\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3111111111111111}, {"context": "            policy_distribution_kwargs = {\n                \"min\": action_spec.space.minimum,\n                \"max\": action_spec.space.maximum,\n                \"tanh_loc\": cfg.tanh_loc,\n            }\n            policy_distribution_class = TruncatedNormal\n    elif action_spec.domain == \"discrete\":\n        out_features = action_spec.shape[-1]\n        policy_distribution_kwargs = {}\n        policy_distribution_class = OneHotCategorical\n        dist_in_keys = [\"logits\"]\n    else:\n        raise NotImplementedError(\n            f\"actions with domain {action_spec.domain} are not supported\"\n        )\n\n    if cfg.shared_mapping:\n        hidden_features = 300\n        if proof_environment.from_pixels:\n            if in_keys_actor is None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 820, "start_line_no": 810, "end_line_no": 830, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3103448275862069}, {"context": "        if set(spec.keys()) != set(self.out_keys):\n            raise RuntimeError(\n                f\"spec keys and out_keys do not match, got: {set(spec.keys())} and {set(self.out_keys)} respectively\"\n            )\n\n        self._spec = spec\n        self.safe = safe\n        if safe:\n            if spec is None or (\n                isinstance(spec, CompositeSpec)\n                and all(_spec is None for _spec in spec.values())\n            ):\n                raise RuntimeError(\n                    \"`SafeProbabilisticModule(spec=None, safe=True)` is not a valid configuration as the tensor \"\n                    \"specs are not specified\"\n                )\n            self.register_forward_hook(_forward_hook_safe_action)\n\n    @property\n    def spec(self) -> CompositeSpec:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "modules", "tensordict_module", "probabilistic.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30714285714285716}, {"context": "            loc = self.loc\n            scale = self.scale\n            reward = (reward - loc) / scale\n            return reward\n        else:\n            scale = self.scale\n            loc = self.loc\n            reward = reward * scale + loc\n            return reward\n\n    def transform_reward_spec(self, reward_spec: TensorSpec) -> TensorSpec:\n        if isinstance(reward_spec, UnboundedContinuousTensorSpec):\n            return reward_spec\n        else:\n            raise NotImplementedError(\n                f\"{self.__class__.__name__}.transform_reward_spec not \"\n                f\"implemented for tensor spec of type\"\n                f\" {type(reward_spec).__name__}\"\n            )\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 1670, "start_line_no": 1660, "end_line_no": 1680, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3046875}, {"context": "        if self.clamp_max is not None and self.clamp_min is not None:\n            reward = reward.clamp(self.clamp_min, self.clamp_max)\n        elif self.clamp_min is not None:\n            reward = reward.clamp_min(self.clamp_min)\n        elif self.clamp_max is not None:\n            reward = reward.clamp_max(self.clamp_max)\n        return reward\n\n    def transform_reward_spec(self, reward_spec: TensorSpec) -> TensorSpec:\n        if isinstance(reward_spec, UnboundedContinuousTensorSpec):\n            return BoundedTensorSpec(\n                self.clamp_min,\n                self.clamp_max,\n                shape=reward_spec.shape,\n                device=reward_spec.device,\n                dtype=reward_spec.dtype,\n            )\n        else:\n            raise NotImplementedError(\n                f\"{self.__class__.__name__}.transform_reward_spec not \"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 850, "start_line_no": 840, "end_line_no": 860, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30158730158730157}, {"context": "    def transform_reward_spec(self, reward_spec: TensorSpec) -> TensorSpec:\n        if isinstance(reward_spec, UnboundedContinuousTensorSpec):\n            return reward_spec\n        else:\n            raise NotImplementedError(\n                f\"{self.__class__.__name__}.transform_reward_spec not \"\n                f\"implemented for tensor spec of type\"\n                f\" {type(reward_spec).__name__}\"\n            )\n\n    def __repr__(self) -> str:\n        return (\n            f\"{self.__class__.__name__}(\"\n            f\"loc={self.loc.item():4.4f}, scale={self.scale.item():4.4f}, \"\n            f\"keys={self.in_keys})\"\n        )\n\n\nclass FiniteTensorDictCheck(Transform):\n    \"\"\"This transform will check that all the items of the tensordict are finite, and raise an exception if they are not.\"\"\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 1680, "start_line_no": 1670, "end_line_no": 1690, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.29605263157894735}, {"context": "\n    @pytest.mark.parametrize(\"dest\", get_available_devices())\n    def test_setitem_matches_device(self, is_complete, device, dtype, dest):\n        ts = self._composite_spec(is_complete, device, dtype)\n\n        if dest == device:\n            ts[\"good\"] = UnboundedContinuousTensorSpec(device=dest, dtype=dtype)\n            assert ts[\"good\"].device == dest\n        else:\n            with pytest.raises(\n                RuntimeError, match=\"All devices of CompositeSpec must match\"\n            ):\n                ts[\"bad\"] = UnboundedContinuousTensorSpec(device=dest, dtype=dtype)\n\n    def test_del(self, is_complete, device, dtype):\n        ts = self._composite_spec(is_complete, device, dtype)\n        assert \"obs\" in ts.keys()\n        assert \"act\" in ts.keys()\n        del ts[\"obs\"]\n        assert \"obs\" not in ts.keys()", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_specs.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2896551724137931}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n# \n#   @property\n#   def feasible_values(self) -> Union[List[int], List[float], List[str]]:\n#     if self.type in (ParameterType.DISCRETE, ParameterType.CATEGORICAL):\n#       if not self._feasible_values:\n#         return []\n#       return copy.copy(self._feasible_values)\n#     elif self.type == ParameterType.INTEGER:\n#       return list(range(self.bounds[0], self.bounds[1] + 1))\n#     raise ValueError('feasible_values is invalid for type: %s' % self.type)\n# \n#   @property\n#   def default_value(self) -> Optional[Union[int, float, str]]:\n#     \"\"\"Returns the default value, or None if not set.\"\"\"\n#     return self._default_value\n# \n#   # TODO: TO BE DEPRECATED. Used by factory() only.\n#   def _add_children(\n#       self, new_children: Sequence[Tuple[MonotypeParameterSequence,\n#                                          'ParameterConfig']]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyglove/converters.py\n# --------------------------------------------------\n#     return float(val)\n#   else:\n#     return val\n# \n# \n# def _make_decision_point(\n#     parameter_config: vz.ParameterConfig) -> pg.geno.DecisionPoint:\n#   \"\"\"Make a decision point (DNASpec) out from a parameter config.\"\"\"\n# \n#   # NOTE(daiyip): We set the name of each decision point instead of its\n#   # location with parameter name.\n#   #\n#   # Why? For conditional space, the ID of a decision point is a\n#   # path of locations from the root to the leaf node. For example, if there\n#   # are two parameters - a parent with location 'a' and a child with location\n#   # 'b', the ID for the child will be 'a.b'. However, for external (\n#   # non-PyGlove created) study, the parameter name for the child does not\n#   # follow this pattern. The solution is to use the ``name`` property of\n#   # `DNASpec`, which allows the user to access hierarchical decision\n#   # points by name, also DNA supports to_dict/from_dict based on the decision\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n# \n#   @property\n#   def default_value(self) -> Optional[Union[int, float, str]]:\n#     \"\"\"Returns the default value, or None if not set.\"\"\"\n#     return self._default_value\n# \n#   # TODO: TO BE DEPRECATED. Used by factory() only.\n#   def _add_children(\n#       self, new_children: Sequence[Tuple[MonotypeParameterSequence,\n#                                          'ParameterConfig']]\n#   ) -> 'ParameterConfig':\n#     \"\"\"Clones the ParameterConfig and adds new children to it.\n# \n#     Args:\n#       new_children: A sequence of tuples formatted as: (matching_parent_values,\n#         ParameterConfig). If the child ParameterConfig have pre-existing parent\n#         values, they will be overridden.\n# \n#     Returns:\n#       A parent parameter config, with children set.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/base_study_config.py\n# --------------------------------------------------\n#     return self == self.MAXIMIZE\n# \n#   @property\n#   def is_minimize(self) -> bool:\n#     return self == self.MINIMIZE\n# \n# \n# class MetricType(enum.Enum):\n#   \"\"\"Type of the metric.\n# \n#   OBJECTIVE: Objective to be maximized / minimized.\n#   SAFETY: Objective to be kept above / below a certain threshold.\n#   \"\"\"\n#   OBJECTIVE = 'OBJECTIVE'\n#   SAFETY = 'SAFETY'  # Soft constraint\n# \n#   # pylint: disable=comparison-with-callable\n#   @property\n#   def is_safety(self) -> bool:\n#     return self == MetricType.SAFETY\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyglove/converters.py\n# --------------------------------------------------\n#     val: vz.ParameterValueTypes,\n#     external_type: vz.ExternalType) -> vz.ParameterValueTypes:\n#   \"\"\"Converts a parameter value to proper external type.\"\"\"\n#   if external_type == vz.ExternalType.BOOLEAN:\n#     # We output strings 'True' or 'False', not booleans themselves.\n#     # because BOOLEAN is interally CATEGORICAL.\n#     return val\n#   elif external_type == vz.ExternalType.INTEGER:\n#     return int(val)\n#   elif external_type == vz.ExternalType.FLOAT:\n#     return float(val)\n#   else:\n#     return val\n# \n# \n# def _make_decision_point(\n#     parameter_config: vz.ParameterConfig) -> pg.geno.DecisionPoint:\n#   \"\"\"Make a decision point (DNASpec) out from a parameter config.\"\"\"\n# \n#   # NOTE(daiyip): We set the name of each decision point instead of its\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#       if not math.isclose(default_value, default_int_value):\n#         raise ValueError('default_value for an INTEGER parameter should be an '\n#                          'integer, got float: [{}]'.format(default_value))\n#       return default_int_value\n#   elif (param_type == ParameterType.CATEGORICAL and\n#         isinstance(default_value, str)):\n#     return default_value\n#   raise ValueError(\n#       'default_value has an incorrect type. ParameterType has type {}, '\n#       'but default_value has type {}'.format(param_type.name,\n#                                              type(default_value)))\n# \n# \n# #######################\n# # Experimental features\n# #######################\n# class FidelityMode(enum.Enum):\n#   \"\"\"Decides how the fidelity config should be interpreated.\n# \n#   SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#                                              type(default_value)))\n# \n# \n# #######################\n# # Experimental features\n# #######################\n# class FidelityMode(enum.Enum):\n#   \"\"\"Decides how the fidelity config should be interpreated.\n# \n#   SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower\n#     fidelity measurement. Currently, no algorithms can take advatange of it, and\n#     Vizier behaves exactly like NON_SEQUENTIAL case. This is for tracking\n#     purposes only.\n# \n#   NOT_SEQUENTIAL: Each fidelity is separately measured. Example: Fidelity\n#     is the fraction of dataset to train on.\n# \n#   STEPS: Fidelity determines the maximum value for Measurement.steps reported\n#     to Vizier. There is one-to-one correspondence between steps and fidelity.\n#     A high fideltiy Trial's measurements contain lower fidelity evaluations.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"Wrapper classes for Trial protos and other messages in them.\"\"\"\n\nimport collections\nfrom collections import abc\nimport copy\nimport dataclasses\nimport datetime\nimport enum\nfrom typing import Any, Dict, List, Mapping, MutableMapping, Optional, Union, FrozenSet\n\nfrom absl import logging\nimport attr\nimport numpy as np\n\nfrom vizier._src.pyvizier.shared import common\n\nParameterValueTypes = Union[str, int, float, bool]\n\n# TODO: These constants should be deleted.\nTRUE_VALUE = 'True'\nFALSE_VALUE = 'False'\n\n\nclass ParameterType(enum.Enum):\n  \"\"\"Valid Values for ParameterConfig.type.\"\"\"\n  DOUBLE = 'DOUBLE'\n  INTEGER = 'INTEGER'\n  CATEGORICAL = 'CATEGORICAL'\n  DISCRETE = 'DISCRETE'\n\n  def is_numeric(self) -> bool:\n    return self in [self.DOUBLE, self.INTEGER, self.DISCRETE]\n\n  def is_continuous(self) -> bool:\n    return self == self.DOUBLE\n\n  def _raise_type_error(self, value: ParameterValueTypes) -> None:\n    raise TypeError(f'Type {self} is not compatible with value: {value}')\n\n  def assert_correct_type(self, value: ParameterValueTypes) -> None:\n    if self.is_numeric() and float(value) != value:\n      self._raise_type_error(value)\n\n  # TODO: Accepting boolean into categorical is unintuitive.\n    elif (self\n          == ParameterType.CATEGORICAL) and (not isinstance(value,\n                                                            (str, bool))):\n      self._raise_type_error(value)\n\n    if self == self.INTEGER and int(value) != value:\n      self._raise_type_error(value)\n\n\n# TODO: Trial class should not depend on these.\nclass ExternalType(enum.Enum):\n  \"\"\"Valid Values for ParameterConfig.external_type.\"\"\"\n  INTERNAL = 'INTERNAL'\n  BOOLEAN = 'BOOLEAN'\n  INTEGER = 'INTEGER'\n  FLOAT = 'FLOAT'\n\n\n# Values should NEVER be removed from the enums below, only added.\nclass TrialStatus(enum.Enum):\n  \"\"\"Values for Trial.Status.\"\"\"", "choices": [{"text": "class TrialStatus(enum.Enum):"}], "metadata": {"task_id": "google_vizier/4", "ground_truth": "  UNKNOWN = 'UNKNOWN'", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "context_start_lineno": 0, "line_no": 81, "query_window": {"context": "          == ParameterType.CATEGORICAL) and (not isinstance(value,\n                                                            (str, bool))):\n      self._raise_type_error(value)\n\n    if self == self.INTEGER and int(value) != value:\n      self._raise_type_error(value)\n\n\n# TODO: Trial class should not depend on these.\nclass ExternalType(enum.Enum):\n  \"\"\"Valid Values for ParameterConfig.external_type.\"\"\"\n  INTERNAL = 'INTERNAL'\n  BOOLEAN = 'BOOLEAN'\n  INTEGER = 'INTEGER'\n  FLOAT = 'FLOAT'\n\n\n# Values should NEVER be removed from the enums below, only added.\nclass TrialStatus(enum.Enum):\n  \"\"\"Values for Trial.Status.\"\"\"", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 81, "task_id": "google_vizier/4", "start_line_no": 61, "end_line_no": 81, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "      if not math.isclose(default_value, default_int_value):\n        raise ValueError('default_value for an INTEGER parameter should be an '\n                         'integer, got float: [{}]'.format(default_value))\n      return default_int_value\n  elif (param_type == ParameterType.CATEGORICAL and\n        isinstance(default_value, str)):\n    return default_value\n  raise ValueError(\n      'default_value has an incorrect type. ParameterType has type {}, '\n      'but default_value has type {}'.format(param_type.name,\n                                             type(default_value)))\n\n\n#######################\n# Experimental features\n#######################\nclass FidelityMode(enum.Enum):\n  \"\"\"Decides how the fidelity config should be interpreated.\n\n  SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2787878787878788}, {"context": "  if (param_type in (ParameterType.DOUBLE, ParameterType.DISCRETE) and\n      (isinstance(default_value, float) or isinstance(default_value, int))):\n    return float(default_value)\n  elif (param_type == ParameterType.INTEGER and\n        (isinstance(default_value, float) or isinstance(default_value, int))):\n    if isinstance(default_value, int):\n      return default_value\n    else:\n      # Check if the float rounds nicely.\n      default_int_value = round(default_value)\n      if not math.isclose(default_value, default_int_value):\n        raise ValueError('default_value for an INTEGER parameter should be an '\n                         'integer, got float: [{}]'.format(default_value))\n      return default_int_value\n  elif (param_type == ParameterType.CATEGORICAL and\n        isinstance(default_value, str)):\n    return default_value\n  raise ValueError(\n      'default_value has an incorrect type. ParameterType has type {}, '\n      'but default_value has type {}'.format(param_type.name,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2702702702702703}, {"context": "\n\ndef _to_json_str_compressed(value: Any) -> str:\n  \"\"\"Serialize (maybe) symbolic object to compressed JSON value.\"\"\"\n  return base64.b64encode(\n      lzma.compress(json.dumps(\n          pg.to_json(value)).encode('utf-8'))).decode('ascii')\n\n\ndef _parameter_with_external_type(\n    val: vz.ParameterValueTypes,\n    external_type: vz.ExternalType) -> vz.ParameterValueTypes:\n  \"\"\"Converts a parameter value to proper external type.\"\"\"\n  if external_type == vz.ExternalType.BOOLEAN:\n    # We output strings 'True' or 'False', not booleans themselves.\n    # because BOOLEAN is interally CATEGORICAL.\n    return val\n  elif external_type == vz.ExternalType.INTEGER:\n    return int(val)\n  elif external_type == vz.ExternalType.FLOAT:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "converters.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2658959537572254}, {"context": "\n# Values should NEVER be removed from ObjectiveMetricGoal, only added.\nclass ObjectiveMetricGoal(enum.IntEnum):\n  \"\"\"Valid Values for MetricInformation.Goal.\"\"\"\n  MAXIMIZE = 1\n  MINIMIZE = 2\n\n  # pylint: disable=comparison-with-callable\n  @property\n  def is_maximize(self) -> bool:\n    return self == self.MAXIMIZE\n\n  @property\n  def is_minimize(self) -> bool:\n    return self == self.MINIMIZE\n\n\nclass MetricType(enum.Enum):\n  \"\"\"Type of the metric.\n", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "base_study_config.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2647058823529412}, {"context": "\n  @property\n  def feasible_values(self) -> Union[List[int], List[float], List[str]]:\n    if self.type in (ParameterType.DISCRETE, ParameterType.CATEGORICAL):\n      if not self._feasible_values:\n        return []\n      return copy.copy(self._feasible_values)\n    elif self.type == ParameterType.INTEGER:\n      return list(range(self.bounds[0], self.bounds[1] + 1))\n    raise ValueError('feasible_values is invalid for type: %s' % self.type)\n\n  @property\n  def default_value(self) -> Optional[Union[int, float, str]]:\n    \"\"\"Returns the default value, or None if not set.\"\"\"\n    return self._default_value\n\n  # TODO: TO BE DEPRECATED. Used by factory() only.\n  def _add_children(\n      self, new_children: Sequence[Tuple[MonotypeParameterSequence,\n                                         'ParameterConfig']]", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2640449438202247}, {"context": "    val: vz.ParameterValueTypes,\n    external_type: vz.ExternalType) -> vz.ParameterValueTypes:\n  \"\"\"Converts a parameter value to proper external type.\"\"\"\n  if external_type == vz.ExternalType.BOOLEAN:\n    # We output strings 'True' or 'False', not booleans themselves.\n    # because BOOLEAN is interally CATEGORICAL.\n    return val\n  elif external_type == vz.ExternalType.INTEGER:\n    return int(val)\n  elif external_type == vz.ExternalType.FLOAT:\n    return float(val)\n  else:\n    return val\n\n\ndef _make_decision_point(\n    parameter_config: vz.ParameterConfig) -> pg.geno.DecisionPoint:\n  \"\"\"Make a decision point (DNASpec) out from a parameter config.\"\"\"\n\n  # NOTE(daiyip): We set the name of each decision point instead of its", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyglove", "converters.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2606060606060606}, {"context": "  # TODO: Equivalent code should look like:\n  # copied = copy.deepcopy(config)\n  # for feasible_value in copied.feasible_values():\n  #   copied.subspace(feasible_value).clear()\n  @property\n  def clone_without_children(self) -> 'ParameterConfig':\n    \"\"\"Returns the clone of self, without child_parameter_configs.\"\"\"\n    clone = copy.deepcopy(self)\n    clone._del_child_parameter_configs()  # pylint: disable='protected-access'\n    return clone\n\n  @property\n  def feasible_values(self) -> Union[List[int], List[float], List[str]]:\n    if self.type in (ParameterType.DISCRETE, ParameterType.CATEGORICAL):\n      if not self._feasible_values:\n        return []\n      return copy.copy(self._feasible_values)\n    elif self.type == ParameterType.INTEGER:\n      return list(range(self.bounds[0], self.bounds[1] + 1))\n    raise ValueError('feasible_values is invalid for type: %s' % self.type)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.25842696629213485}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmark/FedHPOBench/fedhpobench/utils/draw.py\n# --------------------------------------------------\n#             val_loss = result['val_avg_loss']\n#             try:\n#                 best_round = np.argmin(val_loss)\n#             except:\n#                 continue\n#             results.append(result[key][best_round])\n#             config.append(row)\n#         best_index = np.argmax(results)\n#         return config[best_index], results[best_index]\n# \n#     # config, _ = get_best_config(benchmark)\n#     config = {'wd': 0.0, 'dropout': 0.5, 'step': 1.0}\n#     config_space = benchmark.get_configuration_space()\n#     X, Y = sorted(list(config_space['batch'])), sorted(list(\n#         config_space['lr']))\n#     print(X, Y)\n#     for lr in Y:\n#         y = []\n#         for batch in X:\n#             xy = {'lr': lr, 'batch': batch}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/aggregators/asyn_clients_avg_aggregator.py\n# --------------------------------------------------\n# \n#         sample_size, avg_model = models[0]\n#         for key in avg_model:\n#             for i in range(len(models)):\n#                 local_sample_size, local_model = models[i]\n# \n#                 if self.cfg.federate.ignore_weight:\n#                     weight = 1.0 / len(models)\n#                 else:\n#                     weight = local_sample_size / training_set_size\n# \n#                 assert staleness is not None\n#                 weight *= self.discount_func(staleness[i])\n#                 if isinstance(local_model[key], torch.Tensor):\n#                     local_model[key] = local_model[key].float()\n#                 else:\n#                     local_model[key] = torch.FloatTensor(local_model[key])\n# \n#                 if i == 0:\n#                     avg_model[key] = local_model[key] * weight\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/autotune/smac.py\n# --------------------------------------------------\n#         from federatedscope.autotune.utils import summarize_hpo_results\n#         results = summarize_hpo_results(init_configs,\n#                                         perfs,\n#                                         white_list=set(config_space.keys()),\n#                                         desc=cfg.hpo.larger_better,\n#                                         use_wandb=cfg.wandb.use)\n#         logger.info(\n#             \"========================== HPO Final ==========================\")\n#         logger.info(\"\\n{}\".format(results))\n#         logger.info(\"====================================================\")\n# \n#         return perfs\n# \n#     config_space = scheduler._search_space\n#     if cfg.hpo.scheduler.startswith('wrap_'):\n#         ss = CS.ConfigurationSpace()\n#         ss.add_hyperparameter(config_space['hpo.table.idx'])\n#         config_space = ss\n# \n#     if cfg.hpo.sha.iter != 0:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/autotune/utils.py\n# --------------------------------------------------\n#             cur_level = cur_level[ln]\n#         cur_level[names[-1]] = v\n# \n#     return results\n# \n# \n# def summarize_hpo_results(configs,\n#                           perfs,\n#                           white_list=None,\n#                           desc=False,\n#                           use_wandb=False):\n#     if white_list is not None:\n#         cols = list(white_list) + ['performance']\n#     else:\n#         cols = [k for k in configs[0]] + ['performance']\n# \n#     d = []\n#     for trial_cfg, result in zip(configs, perfs):\n#         if white_list is not None:\n#             d.append([\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/autotune/hpbandster.py\n# --------------------------------------------------\n#                     f'{config}, and get performance {res}')\n#         if self.cfg.wandb.use:\n#             log2wandb(len(self._perfs) - 1, config, results, self.cfg)\n#         return {'loss': float(res), 'info': res}\n# \n#     def summarize(self):\n#         from federatedscope.autotune.utils import summarize_hpo_results\n#         results = summarize_hpo_results(self._init_configs,\n#                                         self._perfs,\n#                                         white_list=set(self._ss.keys()),\n#                                         desc=self.cfg.hpo.larger_better,\n#                                         use_wandb=self.cfg.wandb.use)\n#         logger.info(\n#             \"========================== HPO Final ==========================\")\n#         logger.info(\"\\n{}\".format(results))\n#         logger.info(\"====================================================\")\n# \n#         return results\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/autotune/utils.py\n# --------------------------------------------------\n#                           use_wandb=False):\n#     if white_list is not None:\n#         cols = list(white_list) + ['performance']\n#     else:\n#         cols = [k for k in configs[0]] + ['performance']\n# \n#     d = []\n#     for trial_cfg, result in zip(configs, perfs):\n#         if white_list is not None:\n#             d.append([\n#                 trial_cfg[k] if k in trial_cfg.keys() else None\n#                 for k in white_list\n#             ] + [result])\n#         else:\n#             d.append([trial_cfg[k] for k in trial_cfg] + [result])\n#     d = sorted(d, key=lambda ele: ele[-1], reverse=desc)\n#     df = pd.DataFrame(d, columns=cols)\n#     pd.set_option('display.max_colwidth', None)\n#     pd.set_option('display.max_columns', None)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/autotune/smac.py\n# --------------------------------------------------\n#         config['federate.total_round_num'] = budget\n#         init_configs.append(config)\n#         perfs.append(res)\n#         logger.info(f'Evaluate the {len(perfs)-1}-th config '\n#                     f'{config}, and get performance {res}')\n#         if cfg.wandb.use:\n#             log2wandb(len(perfs) - 1, config, results, cfg)\n#         return res\n# \n#     def summarize():\n#         from federatedscope.autotune.utils import summarize_hpo_results\n#         results = summarize_hpo_results(init_configs,\n#                                         perfs,\n#                                         white_list=set(config_space.keys()),\n#                                         desc=cfg.hpo.larger_better,\n#                                         use_wandb=cfg.wandb.use)\n#         logger.info(\n#             \"========================== HPO Final ==========================\")\n#         logger.info(\"\\n{}\".format(results))\n#         logger.info(\"====================================================\")\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nworkers:\n            # execute FL in parallel by multi-threading\n            flags = [\n                threading.Event() for _ in range(self._cfg.hpo.num_workers)\n            ]\n            for i in range(len(flags)):\n                flags[i].set()\n            threads = [None for _ in range(len(flags))]\n            thread_results = [dict() for _ in range(len(flags))]\n\n            perfs = [None for _ in range(len(configs))]\n            for i, config in enumerate(configs):\n                available_worker = 0\n                while not flags[available_worker].is_set():\n                    available_worker = (available_worker + 1) % len(threads)\n                if thread_results[available_worker]:\n                    completed_trial_results = thread_results[available_worker]\n                    cfg_idx = completed_trial_results['cfg_idx']\n                    perfs[cfg_idx] = completed_trial_results['perf']\n                    logger.info(\n                        \"Evaluate the {}-th config {} and get performance {}\".\n                        format(cfg_idx, configs[cfg_idx], perfs[cfg_idx]))\n                    thread_results[available_worker].clear()\n\n                trial_cfg = self._cfg.clone()\n                trial_cfg.merge_from_list(config2cmdargs(config))\n                flags[available_worker].clear()\n                trial = TrialExecutor(i, flags[available_worker],\n                                      thread_results[available_worker],\n                                      trial_cfg, self._client_cfgs)\n                trial.start()\n                threads[available_worker] = trial\n\n            for i in range(len(flags)):\n                if not flags[i].is_set():\n                    threads[i].join()\n            for i in range(len(thread_results)):\n                if thread_results[i]:\n                    completed_trial_results = thread_results[i]\n                    cfg_idx = completed_trial_results['cfg_idx']\n                    perfs[cfg_idx] = completed_trial_results['perf']\n                    # TODO: Support num_worker in WandB\n                    logger.info(\n                        \"Evaluate the {}-th config {} and get performance {}\".\n                        format(cfg_idx, configs[cfg_idx], perfs[cfg_idx]))\n                    thread_results[i].clear()\n\n        else:\n            perfs = [None] * len(configs)\n            for i, config in enumerate(configs):\n                trial_cfg = self._cfg.clone()\n                trial_cfg.merge_from_list(config2cmdargs(config))\n                results = make_trial(trial_cfg, self._client_cfgs)\n                key1, key2 = trial_cfg.hpo.metric.split('.')\n                perfs[i] = results[key1][key2]\n                logger.info(\n                    \"Evaluate the {}-th config {} and get performance {}\".\n                    format(i, config, perfs[i]))\n                if self._cfg.wandb.use:\n                    log2wandb(i, config, results, trial_cfg)\n        return perfs\n\n    def optimize(self):\n        perfs = self._evaluate(self._init_configs)\n        results = summarize_hpo_results(self._init_configs,\n                                        perfs,\n                                        white_list=set(\n                                            self._search_space.keys()),\n                                        desc=self._cfg.hpo.larger_better,\n                                        use_wandb=self._cfg.wandb.use)\n        logger.info(\n            \"========================== HPO Final ==========================\")\n        logger.info(\"\\n{}\".format(results))\n        logger.info(\"====================================================\")\n\n        return results\n\n\nclass IterativeScheduler(ModelFreeBase):\n    \"\"\"The base class for HPO algorithms that divide the whole optimization\n    procedure into iterations.\n    \"\"\"\n    def _setup(self):\n        self._stage = 0\n        return super(IterativeScheduler, self)._setup()\n\n    def _stop_criterion(self, configs, last_results):\n        \"\"\"To determine whether the algorithm should be terminated.\n\n        Arguments:\n            configs (list): each element is a trial configuration.\n            last_results (DataFrame): each row corresponds to a specific\n            configuration as well as its latest performance.\n        :returns: whether to terminate.\n        :rtype: bool\n        \"\"\"\n        raise NotImplementedError\n\n    def _iteration(self, configs):\n        \"\"\"To evaluate the given collection of configurations at this stage.\n\n        Arguments:\n            configs (list): each element is a trial configuration.\n        :returns: the performances of the given configurations.\n        :rtype: list\n        \"\"\"\n\n        perfs = self._evaluate(configs)\n        return perfs\n\n    def _generate_next_population(self, configs, perfs):\n        \"\"\"To generate the configurations for the next stage.\n\n        Arguments:\n            configs (list): the configurations of last stage.\n            perfs (list): their corresponding performances.\n        :returns: configuration for the next stage.\n        :rtype: list\n        \"\"\"\n\n        raise NotImplementedError\n\n    def optimize(self):\n        current_configs = deepcopy(self._init_configs)\n        last_results = None\n        while not self._stop_criterion(current_configs, last_results):\n            current_perfs = self._iteration(current_configs)\n            last_results = summarize_hpo_results(\n                current_configs,\n                current_perfs,\n                white_list=set(self._search_space.keys()),\n                desc=self._cfg.hpo.larger_better,\n                use_wandb=self._cfg.wandb.use)\n            self._stage += 1\n            logger.info(\n                \"========================== Stage{} ==========================\"\n                .format(self._stage))\n            logger.info(\"\\n{}\".format(last_results))\n            logger.info(\"====================================================\")\n            current_configs = self._generate_next_population(\n                current_configs, current_perfs)\n\n        return current_configs\n\n\nclass SuccessiveHalvingAlgo(IterativeScheduler):\n    \"\"\"Successive Halving Algorithm (SHA) tailored to FL setting, where,\n    in each iteration, just a limited number of communication rounds are\n    allowed for each trial.\n    \"\"\"\n    def _setup(self):\n        init_configs = super(SuccessiveHalvingAlgo, self)._setup()\n\n        for trial_cfg in init_configs:\n            trial_cfg['federate.save_to'] = os.path.join(\n                self._cfg.hpo.working_folder,\n                \"{}.pth\".format(config2str(trial_cfg)))\n\n        if self._cfg.hpo.sha.budgets:\n            for trial_cfg in init_configs:\n                trial_cfg[\n                    'federate.total_round_num'] = self._cfg.hpo.sha.budgets[\n                        self._stage]\n                trial_cfg['eval.freq'] = self._cfg.hpo.sha.budgets[self._stage]\n\n        return init_configs\n\n    def _stop_criterion(self, configs, last_results):\n        return len(configs) <= 1\n\n    def _generate_next_population(self, configs, perfs):\n        indices = [(i, val) for i, val in enumerate(perfs)]\n        indices.sort(key=lambda x: x[1], reverse=self._cfg.hpo.larger_better)\n        next_population = [\n            configs[tp[0]] for tp in\n            indices[:math.\n                    ceil(float(len(indices)) / self._cfg.hpo.sha.elim_rate)]\n        ]\n\n        for trial_cfg in next_population:\n            if 'federate.restore_from' not in trial_cfg:\n                trial_cfg['federate.restore_from'] = trial_cfg[\n                    'federate.save_to']\n            if self._cfg.hpo.sha.budgets and self._stage < len(", "choices": [{"text": "elif self.cfg.hpo.scheduler == 'naive':"}], "metadata": {"task_id": "alibaba_FederatedScope/130", "ground_truth": "                    self._cfg.hpo.sha.budgets):", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "autotune", "algos.py"], "context_start_lineno": 136, "line_no": 320, "query_window": {"context": "\n        return init_configs\n\n    def _stop_criterion(self, configs, last_results):\n        return len(configs) <= 1\n\n    def _generate_next_population(self, configs, perfs):\n        indices = [(i, val) for i, val in enumerate(perfs)]\n        indices.sort(key=lambda x: x[1], reverse=self._cfg.hpo.larger_better)\n        next_population = [\n            configs[tp[0]] for tp in\n            indices[:math.\n                    ceil(float(len(indices)) / self._cfg.hpo.sha.elim_rate)]\n        ]\n\n        for trial_cfg in next_population:\n            if 'federate.restore_from' not in trial_cfg:\n                trial_cfg['federate.restore_from'] = trial_cfg[\n                    'federate.save_to']\n            if self._cfg.hpo.sha.budgets and self._stage < len(", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "autotune", "algos.py"], "line_no": 320, "task_id": "alibaba_FederatedScope/130", "start_line_no": 300, "end_line_no": 320, "window_size": 20, "context_start_lineno": 136, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "            config: configurations of FS run.\n\n        Returns:\n            Best results of server of specific FS run.\n        \"\"\"\n        budget = cfg.hpo.sha.budgets[-1]\n        results = eval_in_fs(cfg, config, budget, client_cfgs)\n        key1, key2 = cfg.hpo.metric.split('.')\n        res = results[key1][key2]\n        config = dict(config)\n        config['federate.total_round_num'] = budget\n        init_configs.append(config)\n        perfs.append(res)\n        logger.info(f'Evaluate the {len(perfs)-1}-th config '\n                    f'{config}, and get performance {res}')\n        if cfg.wandb.use:\n            log2wandb(len(perfs) - 1, config, results, cfg)\n        return res\n\n    def summarize():", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "autotune", "smac.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.26380368098159507}, {"context": "            cur_level = cur_level[ln]\n        cur_level[names[-1]] = v\n\n    return results\n\n\ndef summarize_hpo_results(configs,\n                          perfs,\n                          white_list=None,\n                          desc=False,\n                          use_wandb=False):\n    if white_list is not None:\n        cols = list(white_list) + ['performance']\n    else:\n        cols = [k for k in configs[0]] + ['performance']\n\n    d = []\n    for trial_cfg, result in zip(configs, perfs):\n        if white_list is not None:\n            d.append([", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "autotune", "utils.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2553191489361702}, {"context": "    def compute(self, config, budget, **kwargs):\n        results = eval_in_fs(self.cfg, config, int(budget), self.client_cfgs)\n        key1, key2 = self.cfg.hpo.metric.split('.')\n        res = results[key1][key2]\n        config = dict(config)\n        config['federate.total_round_num'] = budget\n        self._init_configs.append(config)\n        self._perfs.append(float(res))\n        time.sleep(self.sleep_interval)\n        logger.info(f'Evaluate the {len(self._perfs)-1}-th config '\n                    f'{config}, and get performance {res}')\n        if self.cfg.wandb.use:\n            log2wandb(len(self._perfs) - 1, config, results, self.cfg)\n        return {'loss': float(res), 'info': res}\n\n    def summarize(self):\n        from federatedscope.autotune.utils import summarize_hpo_results\n        results = summarize_hpo_results(self._init_configs,\n                                        self._perfs,\n                                        white_list=set(self._ss.keys()),", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "autotune", "hpbandster.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.25274725274725274}, {"context": "\n    results = dict()\n\n    for k, v in kvs.items():\n        names = k.split('.')\n        cur_level = results\n        for i in range(len(names) - 1):\n            ln = names[i]\n            if ln not in cur_level:\n                cur_level[ln] = dict()\n            cur_level = cur_level[ln]\n        cur_level[names[-1]] = v\n\n    return results\n\n\ndef summarize_hpo_results(configs,\n                          perfs,\n                          white_list=None,\n                          desc=False,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "autotune", "utils.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2518518518518518}, {"context": "        config['federate.total_round_num'] = budget\n        init_configs.append(config)\n        perfs.append(res)\n        logger.info(f'Evaluate the {len(perfs)-1}-th config '\n                    f'{config}, and get performance {res}')\n        if cfg.wandb.use:\n            log2wandb(len(perfs) - 1, config, results, cfg)\n        return res\n\n    def summarize():\n        from federatedscope.autotune.utils import summarize_hpo_results\n        results = summarize_hpo_results(init_configs,\n                                        perfs,\n                                        white_list=set(config_space.keys()),\n                                        desc=cfg.hpo.larger_better,\n                                        use_wandb=cfg.wandb.use)\n        logger.info(\n            \"========================== HPO Final ==========================\")\n        logger.info(\"\\n{}\".format(results))\n        logger.info(\"====================================================\")", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "autotune", "smac.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.24719101123595505}, {"context": "                ((1.0 + staleness)**self.cfg.asyn.staleness_discount_factor))\n\n    def _para_weighted_avg(self, models, recover_fun=None, staleness=None):\n        \"\"\"\n        Calculates the weighted average of models.\n        \"\"\"\n        training_set_size = 0\n        for i in range(len(models)):\n            sample_size, _ = models[i]\n            training_set_size += sample_size\n\n        sample_size, avg_model = models[0]\n        for key in avg_model:\n            for i in range(len(models)):\n                local_sample_size, local_model = models[i]\n\n                if self.cfg.federate.ignore_weight:\n                    weight = 1.0 / len(models)\n                else:\n                    weight = local_sample_size / training_set_size", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "aggregators", "asyn_clients_avg_aggregator.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.24666666666666667}, {"context": "    benchmark = TabularBenchmark(model, dname, algo, device=-1)\n\n    def get_best_config(benchmark):\n        results, config = [], []\n        for idx in tqdm(range(len(benchmark.table))):\n            row = benchmark.table.iloc[idx]\n            if sample_client is not None and row[\n                    'sample_client'] != sample_client:\n                continue\n            result = eval(row['result'])\n            val_loss = result['val_avg_loss']\n            try:\n                best_round = np.argmin(val_loss)\n            except:\n                continue\n            results.append(result[key][best_round])\n            config.append(row)\n        best_index = np.argmax(results)\n        return config[best_index], results[best_index]\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "benchmark", "FedHPOBench", "fedhpobench", "utils", "draw.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.24528301886792453}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_trainer.py\n# --------------------------------------------------\n# \n# from fortuna.prob_model.joint.state import JointState\n# from fortuna.training.train_state import TrainState\n# from fortuna.training.trainer import TrainerABC\n# \n# \n# class FakeTrainState:\n#     apply_fn = lambda *x: x[-1]\n#     tx = None\n#     params = {}\n#     mutable = None\n#     unravel = None\n#     step = 0\n#     predict_fn = lambda *x: x[-1]\n# \n# \n# class FakeTrainer(TrainerABC):\n#     def init_state(\n#         self,\n#         prob_model_state: JointState,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/output_calibrator/output_calib_manager/base.py\n# --------------------------------------------------\n# from fortuna.utils.random import WithRNG\n# \n# \n# class OutputCalibManager(WithRNG):\n#     def __init__(self, output_calibrator: Optional[nn.Module] = None):\n#         self.output_calibrator = output_calibrator\n# \n#     def apply(\n#         self,\n#         params: CalibParams,\n#         outputs: Array,\n#         mutable: Optional[CalibMutable] = None,\n#         calib: bool = False,\n#         rng: Optional[PRNGKeyArray] = None,\n#     ) -> Union[jnp.ndarray, Tuple[jnp.ndarray, PyTree]]:\n#         \"\"\"\n#         Apply the output calibrator forward pass.\n# \n#         Parameters\n#         ----------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/model_manager/base.py\n# --------------------------------------------------\n# import abc\n# from typing import Dict, Optional, Tuple, Union\n# \n# import jax.numpy as jnp\n# from flax.core import FrozenDict\n# from flax.training.checkpoints import PyTree\n# from jax._src.prng import PRNGKeyArray\n# \n# from fortuna.typing import Array, Mutable, Params\n# from fortuna.utils.random import WithRNG\n# \n# \n# class ModelManager(WithRNG, abc.ABC):\n#     \"\"\"\n#     Abstract model manager class.\n#     It orchestrates the forward pass of the models in the probabilistic model.\n#     \"\"\"\n# \n#     @abc.abstractmethod\n#     def apply(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/map/map_trainer.py\n# --------------------------------------------------\n# from __future__ import annotations\n# \n# from typing import Any, Callable, Dict, Optional, Tuple, Union\n# \n# import jax.numpy as jnp\n# from flax.core import FrozenDict\n# from jax._src.prng import PRNGKeyArray\n# from optax._src.base import PyTree\n# \n# from fortuna.prob_model.posterior.map import *\n# from fortuna.prob_model.posterior.map.map_state import MAPState\n# from fortuna.prob_model.posterior.posterior_trainer import PosteriorTrainerABC\n# from fortuna.training.trainer import JittedMixin, MultiDeviceMixin\n# from fortuna.typing import (Array, Batch, CalibMutable, CalibParams, Mutable,\n#                             Params)\n# \n# \n# class MAPTrainer(PosteriorTrainerABC):\n#     def training_loss_step(\n#         self,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/posterior/normalizing_flow/normalizing_flow_trainer.py\n# --------------------------------------------------\n# from __future__ import annotations\n# \n# import abc\n# from typing import Any, Callable, Dict, Optional, Tuple, Union\n# \n# import jax.numpy as jnp\n# import numpy as np\n# from flax.core import FrozenDict\n# from jax import random, vmap\n# from jax._src.prng import PRNGKeyArray\n# from jax.tree_util import tree_map\n# from optax._src.base import PyTree\n# \n# from fortuna.distribution.base import Distribution\n# from fortuna.prob_model.posterior.posterior_trainer import PosteriorTrainerABC\n# from fortuna.prob_model.posterior.state import PosteriorState\n# from fortuna.typing import Array, Batch, CalibMutable, CalibParams, Params\n# \n# \n# class NormalizingFlowTrainer(PosteriorTrainerABC):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/model_manager/classification.py\n# fortuna/model/model_manager/regression.py\n# --------------------------------------------------\n# from typing import Dict, Optional, Tuple, Union\n# \n# import flax.linen as nn\n# import jax.numpy as jnp\n# from flax.core import FrozenDict\n# from flax.training.checkpoints import PyTree\n# from jax import random\n# from jax._src.prng import PRNGKeyArray\n# \n# from fortuna.model.model_manager.base import ModelManager\n# from fortuna.typing import Array, Mutable, Params\n# \n# \n# class ClassificationModelManager(ModelManager):\n#     def __init__(self, model: nn.Module):\n#         r\"\"\"\n#         Classification model manager class. It orchestrates the forward pass of the model in the probabilistic model.\n# \n#         Parameters\n#         ----------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/output_calibrator/output_calib_manager/base.py\n# --------------------------------------------------\n# from typing import Optional, Tuple, Union\n# \n# import flax.linen as nn\n# import jax.numpy as jnp\n# from flax.core import FrozenDict\n# from flax.training.checkpoints import PyTree\n# from jax import random\n# from jax._src.prng import PRNGKeyArray\n# \n# from fortuna.typing import Array, CalibMutable, CalibParams\n# from fortuna.utils.random import WithRNG\n# \n# \n# class OutputCalibManager(WithRNG):\n#     def __init__(self, output_calibrator: Optional[nn.Module] = None):\n#         self.output_calibrator = output_calibrator\n# \n#     def apply(\n#         self,\n#         params: CalibParams,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_trainer.py\n# --------------------------------------------------\n# import unittest\n# import unittest.mock as mock\n# from typing import Any, Callable, Dict, Optional, Tuple, Union\n# \n# import jax.random\n# import numpy as np\n# from flax.core import FrozenDict\n# from jax import numpy as jnp\n# from jax._src.prng import PRNGKeyArray\n# from optax._src.base import GradientTransformation, PyTree\n# \n# from fortuna.prob_model.joint.state import JointState\n# from fortuna.training.train_state import TrainState\n# from fortuna.training.trainer import TrainerABC\n# \n# \n# class FakeTrainState:\n#     apply_fn = lambda *x: x[-1]\n#     tx = None\n#     params = {}\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport pathlib\nfrom typing import Dict, Tuple, Union\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom flax.core import FrozenDict\nfrom optax._src.base import GradientTransformation, PyTree\n\nParams = FrozenDict[str, FrozenDict[str, PyTree]]\nMutable = FrozenDict[str, FrozenDict[str, PyTree]]\nCalibParams = FrozenDict[str, PyTree]\nCalibMutable = FrozenDict[str, PyTree]", "choices": [{"text": "TrainState"}], "metadata": {"task_id": "awslabs_fortuna/161", "ground_truth": "OptaxOptimizer = GradientTransformation", "fpath_tuple": ["awslabs_fortuna", "fortuna", "typing.py"], "context_start_lineno": 0, "line_no": 12, "query_window": {"context": "import pathlib\nfrom typing import Dict, Tuple, Union\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom flax.core import FrozenDict\nfrom optax._src.base import GradientTransformation, PyTree\n\nParams = FrozenDict[str, FrozenDict[str, PyTree]]\nMutable = FrozenDict[str, FrozenDict[str, PyTree]]\nCalibParams = FrozenDict[str, PyTree]\nCalibMutable = FrozenDict[str, PyTree]", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "typing.py"], "line_no": 12, "task_id": "awslabs_fortuna/161", "start_line_no": 0, "end_line_no": 12, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "import unittest\nimport unittest.mock as mock\nfrom typing import Any, Callable, Dict, Optional, Tuple, Union\n\nimport jax.random\nimport numpy as np\nfrom flax.core import FrozenDict\nfrom jax import numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\nfrom optax._src.base import GradientTransformation, PyTree", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.515625}, {"context": "from typing import Optional, Tuple, Union\n\nimport flax.linen as nn\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom flax.training.checkpoints import PyTree\nfrom jax import random\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.typing import Array, CalibMutable, CalibParams", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "output_calibrator", "output_calib_manager", "base.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4696969696969697}, {"context": "from typing import Dict, Optional, Tuple, Union\n\nimport flax.linen as nn\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom flax.training.checkpoints import PyTree\nfrom jax import random\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.model.model_manager.base import ModelManager", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "model_manager", "classification.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}, {"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "model_manager", "regression.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.417910447761194}, {"context": "from __future__ import annotations\n\nimport abc\nfrom typing import Any, Callable, Dict, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom flax.core import FrozenDict\nfrom jax import random, vmap\nfrom jax._src.prng import PRNGKeyArray", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "normalizing_flow", "normalizing_flow_trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3939393939393939}, {"context": "from __future__ import annotations\n\nfrom typing import Any, Callable, Dict, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom jax._src.prng import PRNGKeyArray\nfrom optax._src.base import PyTree\n\nfrom fortuna.prob_model.posterior.map import *", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "posterior", "map", "map_trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3888888888888889}, {"context": "import abc\nfrom typing import Dict, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom flax.training.checkpoints import PyTree\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.typing import Array, Mutable, Params\nfrom fortuna.utils.random import WithRNG", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "model_manager", "base.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.38028169014084506}, {"context": "from typing import Optional, Tuple, Union\n\nimport flax.linen as nn\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom flax.training.checkpoints import PyTree\nfrom jax import random\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.typing import Array, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass OutputCalibManager(WithRNG):\n    def __init__(self, output_calibrator: Optional[nn.Module] = None):\n        self.output_calibrator = output_calibrator\n\n    def apply(\n        self,\n        params: CalibParams,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "output_calibrator", "output_calib_manager", "base.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.36082474226804123}, {"context": "import unittest\nimport unittest.mock as mock\nfrom typing import Any, Callable, Dict, Optional, Tuple, Union\n\nimport jax.random\nimport numpy as np\nfrom flax.core import FrozenDict\nfrom jax import numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\nfrom optax._src.base import GradientTransformation, PyTree\n\nfrom fortuna.prob_model.joint.state import JointState\nfrom fortuna.training.train_state import TrainState\nfrom fortuna.training.trainer import TrainerABC\n\n\nclass FakeTrainState:\n    apply_fn = lambda *x: x[-1]\n    tx = None\n    params = {}", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_trainer.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.36}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/dataset/imdb.py\n# --------------------------------------------------\n#                                    truncation=True,\n#                                    max_length=max_seq_len,\n#                                    return_tensors='pt')\n#         num_non_padding = (encoded_inputs.input_ids !=\n#                            tokenizer.pad_token_id).sum(dim=-1)\n#         for i, pad_idx in enumerate(num_non_padding):\n#             encoded_inputs.input_ids[i, 0] = tokenizer.bos_token_id\n#             encoded_inputs.input_ids[i, pad_idx - 1] = tokenizer.eos_token_id\n# \n#         if cache_dir:\n#             logger.info('Saving cache file to \\'{}\\''.format(cache_file))\n#             os.makedirs(save_dir, exist_ok=True)\n#             torch.save({\n#                 'examples': examples,\n#                 'encoded_inputs': encoded_inputs\n#             }, cache_file)\n# \n#     example_indices = torch.arange(encoded_inputs.input_ids.size(0),\n#                                    dtype=torch.long)\n#     dataset = DatasetDict({\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/dataset/msqg.py\n# --------------------------------------------------\n# \n#         if raw_cache_dir:\n#             logger.info('Saving cache file to \\'{}\\''.format(cache_dir))\n#             os.makedirs(cache_dir, exist_ok=True)\n#             token_ids = np.memmap(filename=osp.join(cache_dir,\n#                                                     'token_ids.memmap'),\n#                                   shape=(len(src_examples), max_src_len),\n#                                   mode='w+',\n#                                   dtype=np.int64)\n#             attention_mask = np.memmap(filename=osp.join(\n#                 cache_dir, 'attention_mask.memmap'),\n#                                        shape=(len(src_examples), max_src_len),\n#                                        mode='w+',\n#                                        dtype=np.int64)\n# \n#             for i in range(len(src_examples)):\n#                 token_ids[i] = src_encoded.input_ids[i]\n#                 attention_mask[i] = src_encoded.attention_mask[i]\n# \n#             token_ids = torch.from_numpy(token_ids)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/dataset/msqg.py\n# --------------------------------------------------\n#         token_type_ids = torch.from_numpy(token_type_ids)\n#         attention_mask = torch.from_numpy(attention_mask)\n#         labels = torch.from_numpy(labels)\n#     else:\n#         src_encoded = tokenizer(src_examples,\n#                                 padding='max_length',\n#                                 truncation=True,\n#                                 max_length=max_src_len,\n#                                 return_tensors='pt')\n#         tgt_examples = split_sent(tgt_examples,\n#                                   eoq=tokenizer.eoq_token,\n#                                   tokenize=False)\n#         tgt_encoded = tokenizer(tgt_examples,\n#                                 padding='max_length',\n#                                 truncation=True,\n#                                 max_length=max_tgt_len,\n#                                 return_tensors='pt')\n#         num_non_padding = (tgt_encoded.input_ids !=\n#                            tokenizer.pad_token_id).sum(dim=-1)\n#         for i, pad_idx in enumerate(num_non_padding):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/dataset/msqg.py\n# --------------------------------------------------\n#         src_encoded = tokenizer(src_examples,\n#                                 padding='max_length',\n#                                 truncation=True,\n#                                 max_length=max_src_len,\n#                                 return_tensors='pt')\n#         num_non_padding = (src_encoded.input_ids !=\n#                            tokenizer.pad_token_id).sum(dim=-1)\n#         for i, pad_idx in enumerate(num_non_padding):\n#             src_encoded.input_ids[i, 0] = tokenizer.bos_token_id\n#             src_encoded.input_ids[i, pad_idx - 1] = tokenizer.eos_token_id\n# \n#         if raw_cache_dir:\n#             logger.info('Saving cache file to \\'{}\\''.format(cache_dir))\n#             os.makedirs(cache_dir, exist_ok=True)\n#             token_ids = np.memmap(filename=osp.join(cache_dir,\n#                                                     'token_ids.memmap'),\n#                                   shape=(len(src_examples), max_src_len),\n#                                   mode='w+',\n#                                   dtype=np.int64)\n#             attention_mask = np.memmap(filename=osp.join(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/nlp/hetero_tasks/dataset/msqg.py\n# --------------------------------------------------\n#                                   eoq=tokenizer.eoq_token,\n#                                   tokenize=False)\n#         tgt_encoded = tokenizer(tgt_examples,\n#                                 padding='max_length',\n#                                 truncation=True,\n#                                 max_length=max_tgt_len,\n#                                 return_tensors='pt')\n#         num_non_padding = (tgt_encoded.input_ids !=\n#                            tokenizer.pad_token_id).sum(dim=-1)\n#         for i, pad_idx in enumerate(num_non_padding):\n#             tgt_encoded.input_ids[i, 0] = tokenizer.bos_token_id\n#             tgt_encoded.input_ids[i, pad_idx - 1] = tokenizer.eos_token_id\n# \n#         if raw_cache_dir:\n#             logger.info('Saving cache file to \\'{}\\''.format(cache_dir))\n#             os.makedirs(cache_dir, exist_ok=True)\n#             token_ids = np.memmap(filename=osp.join(cache_dir,\n#                                                     'token_ids.memmap'),\n#                                   shape=(len(src_examples), max_src_len),\n#                                   mode='w+',\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport os\nimport os.path as osp\nimport logging\nimport torch\nimport numpy as np\nfrom federatedscope.nlp.hetero_tasks.dataset.utils import split_sent, \\\n    DatasetDict, NUM_DEBUG\n\nlogger = logging.getLogger(__name__)\n\n\ndef get_cnndm_examples(data, is_debug=False):\n    if is_debug:\n        data = data[:NUM_DEBUG]\n    src_examples, tgt_examples = [], []\n    for ex in data:\n        src_examples.append(ex['src'])\n        tgt_examples.append(ex['tgt'])\n    return src_examples, tgt_examples\n\n\ndef process_cnndm_dataset(data,\n                          split,\n                          tokenizer,\n                          max_src_len,\n                          max_tgt_len,\n                          raw_cache_dir='',\n                          client_id=None,\n                          pretrain=False,\n                          is_debug=False,\n                          **kwargs):\n    if pretrain:\n        return process_cnndm_dataset_for_pretrain(data, split, tokenizer,\n                                                  max_src_len, raw_cache_dir,\n                                                  client_id, is_debug)\n\n    cache_dir = osp.join(raw_cache_dir, 'train', str(client_id), split)\n    src_examples, tgt_examples = get_cnndm_examples(data, is_debug)\n    if osp.exists(cache_dir):\n        logger.info('Loading cache file from \\'{}\\''.format(cache_dir))\n        token_ids = np.memmap(filename=osp.join(cache_dir, 'token_ids.memmap'),\n                              shape=(len(src_examples), max_src_len),\n                              mode='r',\n                              dtype=np.int64)\n        token_type_ids = np.memmap(filename=osp.join(cache_dir,\n                                                     'token_type_ids.memmap'),\n                                   shape=(len(src_examples), max_src_len),\n                                   mode='r',\n                                   dtype=np.int64)\n        attention_mask = np.memmap(filename=osp.join(cache_dir,\n                                                     'attention_mask.memmap'),\n                                   shape=(len(src_examples), max_src_len),\n                                   mode='r',\n                                   dtype=np.int64)\n        labels = np.memmap(filename=osp.join(cache_dir, 'labels.memmap'),\n                           shape=(len(src_examples), max_tgt_len),\n                           mode='r',\n                           dtype=np.int64)\n\n        token_ids = torch.from_numpy(token_ids)\n        token_type_ids = torch.from_numpy(token_type_ids)\n        attention_mask = torch.from_numpy(attention_mask)\n        labels = torch.from_numpy(labels)\n    else:\n        src_encoded = tokenizer(src_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_src_len,\n                                return_tensors='pt')\n        tgt_examples = split_sent(tgt_examples, eoq=tokenizer.eoq_token)\n        tgt_encoded = tokenizer(tgt_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_tgt_len,\n                                return_tensors='pt')\n        num_non_padding = (tgt_encoded.input_ids !=\n                           tokenizer.pad_token_id).sum(dim=-1)", "choices": [{"text": "tgt_encoded.input_ids[i, pad_idx - 1] = tokenizer.eos_token_id"}], "metadata": {"task_id": "alibaba_FederatedScope/180", "ground_truth": "        for i, pad_idx in enumerate(num_non_padding):", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "cnndm.py"], "context_start_lineno": 0, "line_no": 77, "query_window": {"context": "                           dtype=np.int64)\n\n        token_ids = torch.from_numpy(token_ids)\n        token_type_ids = torch.from_numpy(token_type_ids)\n        attention_mask = torch.from_numpy(attention_mask)\n        labels = torch.from_numpy(labels)\n    else:\n        src_encoded = tokenizer(src_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_src_len,\n                                return_tensors='pt')\n        tgt_examples = split_sent(tgt_examples, eoq=tokenizer.eoq_token)\n        tgt_encoded = tokenizer(tgt_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_tgt_len,\n                                return_tensors='pt')\n        num_non_padding = (tgt_encoded.input_ids !=\n                           tokenizer.pad_token_id).sum(dim=-1)", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "cnndm.py"], "line_no": 77, "task_id": "alibaba_FederatedScope/180", "start_line_no": 57, "end_line_no": 77, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "        token_type_ids = torch.from_numpy(token_type_ids)\n        attention_mask = torch.from_numpy(attention_mask)\n        labels = torch.from_numpy(labels)\n    else:\n        src_encoded = tokenizer(src_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_src_len,\n                                return_tensors='pt')\n        tgt_examples = split_sent(tgt_examples,\n                                  eoq=tokenizer.eoq_token,\n                                  tokenize=False)\n        tgt_encoded = tokenizer(tgt_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_tgt_len,\n                                return_tensors='pt')\n        num_non_padding = (tgt_encoded.input_ids !=\n                           tokenizer.pad_token_id).sum(dim=-1)\n        for i, pad_idx in enumerate(num_non_padding):", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "msqg.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.8131868131868132}, {"context": "                                                     'attention_mask.memmap'),\n                                   shape=(len(src_examples), max_src_len),\n                                   mode='r',\n                                   dtype=np.int64)\n        token_ids = torch.from_numpy(token_ids)\n        attention_mask = torch.from_numpy(attention_mask)\n    else:\n        src_examples = split_sent(src_examples,\n                                  eoq=tokenizer.eoq_token,\n                                  tokenize=False)\n        src_encoded = tokenizer(src_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_src_len,\n                                return_tensors='pt')\n        num_non_padding = (src_encoded.input_ids !=\n                           tokenizer.pad_token_id).sum(dim=-1)\n        for i, pad_idx in enumerate(num_non_padding):\n            src_encoded.input_ids[i, 0] = tokenizer.bos_token_id\n            src_encoded.input_ids[i, pad_idx - 1] = tokenizer.eos_token_id", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "msqg.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.6576576576576577}, {"context": "                                                     'attention_mask.memmap'),\n                                   shape=(len(src_examples), max_src_len),\n                                   mode='r',\n                                   dtype=np.int64)\n        labels = np.memmap(filename=osp.join(cache_dir, 'labels.memmap'),\n                           shape=(len(src_examples), max_tgt_len),\n                           mode='r',\n                           dtype=np.int64)\n\n        token_ids = torch.from_numpy(token_ids)\n        token_type_ids = torch.from_numpy(token_type_ids)\n        attention_mask = torch.from_numpy(attention_mask)\n        labels = torch.from_numpy(labels)\n    else:\n        src_encoded = tokenizer(src_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_src_len,\n                                return_tensors='pt')\n        tgt_examples = split_sent(tgt_examples,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "msqg.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.6458333333333334}, {"context": "        src_encoded = tokenizer(src_examples,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=max_src_len,\n                                return_tensors='pt')\n        num_non_padding = (src_encoded.input_ids !=\n                           tokenizer.pad_token_id).sum(dim=-1)\n        for i, pad_idx in enumerate(num_non_padding):\n            src_encoded.input_ids[i, 0] = tokenizer.bos_token_id\n            src_encoded.input_ids[i, pad_idx - 1] = tokenizer.eos_token_id\n\n        if raw_cache_dir:\n            logger.info('Saving cache file to \\'{}\\''.format(cache_dir))\n            os.makedirs(cache_dir, exist_ok=True)\n            token_ids = np.memmap(filename=osp.join(cache_dir,\n                                                    'token_ids.memmap'),\n                                  shape=(len(src_examples), max_src_len),\n                                  mode='w+',\n                                  dtype=np.int64)\n            attention_mask = np.memmap(filename=osp.join(", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "msqg.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.44525547445255476}, {"context": "        logger.info('Loading cache file from \\'{}\\''.format(cache_file))\n        cache_data = torch.load(cache_file)\n        examples = cache_data['examples']\n        encoded_inputs = cache_data['encoded_inputs']\n    else:\n        examples = get_imdb_examples(data, is_debug)\n        texts = [ex[0] for ex in examples]\n        texts = split_sent(texts, eoq=tokenizer.eoq_token)\n        encoded_inputs = tokenizer(texts,\n                                   padding='max_length',\n                                   truncation=True,\n                                   max_length=max_seq_len,\n                                   return_tensors='pt')\n        num_non_padding = (encoded_inputs.input_ids !=\n                           tokenizer.pad_token_id).sum(dim=-1)\n        for i, pad_idx in enumerate(num_non_padding):\n            encoded_inputs.input_ids[i, 0] = tokenizer.bos_token_id\n            encoded_inputs.input_ids[i, pad_idx - 1] = tokenizer.eos_token_id\n\n        if cache_dir:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "nlp", "hetero_tasks", "dataset", "imdb.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.44360902255639095}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_transforms.py\n# --------------------------------------------------\n# \n#         _ = cat_frames._call(tdc)\n#         assert (buffer != 0).all()\n# \n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     def test_finitetensordictcheck(self, device):\n#         ftd = FiniteTensorDictCheck()\n#         td = TensorDict(\n#             {key: torch.randn(1, 3, 3, device=device) for key in [\"a\", \"b\", \"c\"]}, [1]\n#         )\n#         ftd(td)\n#         td.set(\"inf\", torch.zeros(1, 3).fill_(float(\"inf\")))\n#         with pytest.raises(ValueError, match=\"Encountered a non-finite tensor\"):\n#             ftd(td)\n# \n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     @pytest.mark.parametrize(\n#         \"keys\",\n#         [\n#             [\"observation\", \"some_other_key\"],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n#         \"backend\",\n#         [\n#             \"torchsnapshot\",\n#             \"torch\",\n#         ],\n#     )\n#     def test_countframes_load(self, backend):\n#         if not _has_ts and backend == \"torchsnapshot\":\n#             pytest.skip(\"torchsnapshot not found\")\n# \n#         os.environ[\"CKPT_BACKEND\"] = backend\n#         state_dict_has_been_called = [False]\n#         load_state_dict_has_been_called = [False]\n#         CountFramesLog.state_dict, CountFramesLog_state_dict = _fun_checker(\n#             CountFramesLog.state_dict, state_dict_has_been_called\n#         )\n#         (\n#             CountFramesLog.load_state_dict,\n#             CountFramesLog_load_state_dict,\n#         ) = _fun_checker(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n#     assert td_out.shape[0] == td.get((\"collector\", \"mask\")).sum()\n#     assert (td[\"tensor\"][td[(\"collector\", \"mask\")]] == td_out[\"tensor\"]).all()\n# \n# \n# class TestSubSampler:\n#     def test_subsampler(self):\n#         torch.manual_seed(0)\n#         trainer = mocking_trainer()\n# \n#         batch_size = 10\n#         sub_traj_len = 5\n# \n#         key1 = \"key1\"\n#         key2 = \"key2\"\n# \n#         subsampler = BatchSubSampler(batch_size=batch_size, sub_traj_len=sub_traj_len)\n#         subsampler.register(trainer)\n# \n#         td = TensorDict(\n#             {\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#         env.set_seed(1)\n#         action = env.action_spec.rand()\n#         action[:] = 1\n#         for i in range(max_steps):\n#             td = env.step(\n#                 TensorDict(\n#                     {\"action\": action}, batch_size=env.batch_size, device=env.device\n#                 )\n#             )\n#             assert (td[\"done\"] == 0).all()\n#             assert (td[\"next\"][\"observation\"] == i + 1).all()\n# \n#         td = env.step(\n#             TensorDict({\"action\": action}, batch_size=env.batch_size, device=env.device)\n#         )\n#         assert (td[\"done\"] == 1).all()\n#         assert (td[\"next\"][\"observation\"] == max_steps + 1).all()\n# \n#         _reset = torch.randint(low=0, high=2, size=env.batch_size, dtype=torch.bool)\n#         while not _reset.any():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n#         td = TensorDict(\n#             {(\"collector\", \"mask\"): torch.zeros(batch, dtype=torch.bool).bernoulli_()},\n#             [batch],\n#         )\n#         trainer._pre_steps_log_hook(td)\n#         assert (\n#             count_frames.frame_count == td.get((\"collector\", \"mask\")).sum() * frame_skip\n#         )\n# \n#     @pytest.mark.parametrize(\n#         \"backend\",\n#         [\n#             \"torchsnapshot\",\n#             \"torch\",\n#         ],\n#     )\n#     def test_countframes_load(self, backend):\n#         if not _has_ts and backend == \"torchsnapshot\":\n#             pytest.skip(\"torchsnapshot not found\")\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_transforms.py\n# --------------------------------------------------\n#         [[\"done\", \"reward\"]],\n#     )\n#     @pytest.mark.parametrize(\"device\", get_available_devices())\n#     def test_sum_reward(self, keys, device):\n#         torch.manual_seed(0)\n#         batch = 4\n#         rs = RewardSum()\n#         td = TensorDict(\n#             {\n#                 \"done\": torch.zeros((batch, 1), dtype=torch.bool),\n#                 \"reward\": torch.rand((batch, 1)),\n#             },\n#             device=device,\n#             batch_size=[batch],\n#         )\n# \n#         # apply one time, episode_reward should be equal to reward again\n#         td = rs(td)\n#         assert \"episode_reward\" in td.keys()\n#         assert (td.get(\"episode_reward\") == td.get(\"reward\")).all()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_transforms.py\n# --------------------------------------------------\n#                 \"reward\": torch.rand((batch, 1)),\n#             },\n#             device=device,\n#             batch_size=[batch],\n#         )\n# \n#         # apply one time, episode_reward should be equal to reward again\n#         td = rs(td)\n#         assert \"episode_reward\" in td.keys()\n#         assert (td.get(\"episode_reward\") == td.get(\"reward\")).all()\n# \n#         # apply a second time, episode_reward should twice the reward\n#         td = rs(td)\n#         assert (td.get(\"episode_reward\") == 2 * td.get(\"reward\")).all()\n# \n#         # reset environments\n#         td.set(\"_reset\", torch.ones(batch, dtype=torch.bool, device=device))\n#         rs.reset(td)\n# \n#         # apply a third time, episode_reward should be equal to reward again\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport argparse\nimport time\nimport warnings\n\nimport pytest\nimport torch\nfrom tensordict import TensorDict\nfrom torch import multiprocessing as mp\n\n\nclass TestShared:\n    @staticmethod\n    def remote_process(command_pipe_child, command_pipe_parent, tensordict):\n        command_pipe_parent.close()\n        assert tensordict.is_shared()\n        t0 = time.time()\n        tensordict.zero_()\n        print(f\"zeroing time: {time.time() - t0}\")\n        command_pipe_child.send(\"done\")\n        command_pipe_child.close()\n        del command_pipe_child, command_pipe_parent, tensordict\n\n    @staticmethod\n    def driver_func(subtd, td):\n        assert subtd.is_shared()\n        command_pipe_parent, command_pipe_child = mp.Pipe()\n        proc = mp.Process(\n            target=TestShared.remote_process,\n            args=(command_pipe_child, command_pipe_parent, subtd),\n        )\n        proc.start()\n        command_pipe_child.close()\n        command_pipe_parent.recv()\n        for item in subtd.values():\n            assert (item == 0).all()\n\n        for item in td[0].values():\n            assert (item == 0).all()\n        command_pipe_parent.close()\n        proc.join()\n        del command_pipe_child, command_pipe_parent, proc\n\n    @pytest.mark.parametrize(\"indexing_method\", range(3))\n    def test_shared(self, indexing_method):\n        torch.manual_seed(0)\n        tensordict = TensorDict(\n            source={\n                \"a\": torch.randn(1000, 200),\n                \"b\": torch.randn(1000, 100),\n                \"done\": torch.zeros(1000, 100, dtype=torch.bool).bernoulli_(),\n            },\n            batch_size=[1000],\n        )\n\n        td = tensordict.clone().share_memory_()\n        if indexing_method == 0:\n            subtd = TensorDict(\n                source={key: item[0] for key, item in td.items()},\n                batch_size=[],\n                _is_shared=True,\n            )\n        elif indexing_method == 1:\n            subtd = td.get_sub_tensordict(0)\n        elif indexing_method == 2:\n            subtd = td[0]\n        else:\n            raise NotImplementedError\n\n        assert subtd.is_shared()\n\n        self.driver_func(subtd, td)\n\n\nclass TestStack:\n    @staticmethod\n    def remote_process(command_pipe_child, command_pipe_parent, tensordict):\n        command_pipe_parent.close()\n        assert isinstance(tensordict, TensorDict), f\"td is of type {type(tensordict)}\"\n        assert tensordict.is_shared() or tensordict.is_memmap()\n        new_tensordict = torch.stack(\n            [\n                tensordict[i].contiguous().clone().zero_()\n                for i in range(tensordict.shape[0])\n            ],\n            0,\n        )\n        cmd = command_pipe_child.recv()\n        t0 = time.time()\n        if cmd == \"stack\":\n            tensordict.copy_(new_tensordict)\n        elif cmd == \"serial\":\n            for i, td in enumerate(new_tensordict.tensordicts):\n                tensordict.update_at_(td, i)\n        time_spent = time.time() - t0\n        command_pipe_child.send(time_spent)\n        command_pipe_child.close()\n        del command_pipe_child, command_pipe_parent\n\n    @staticmethod\n    def driver_func(td, stack):\n\n        command_pipe_parent, command_pipe_child = mp.Pipe()\n        proc = mp.Process(\n            target=TestStack.remote_process,\n            args=(command_pipe_child, command_pipe_parent, td),\n        )\n        proc.start()\n        command_pipe_child.close()\n        command_pipe_parent.send(\"stack\" if stack else \"serial\")\n        time_spent = command_pipe_parent.recv()\n        print(f\"stack {stack}: time={time_spent}\")\n        for item in td.values():\n            assert (item == 0).all()\n        proc.join()\n        command_pipe_parent.close()\n        return time_spent\n\n    @pytest.mark.parametrize(\"shared\", [\"shared\", \"memmap\"])\n    def test_shared(self, shared):\n        print(f\"test_shared: shared={shared}\")\n        torch.manual_seed(0)\n        tensordict = TensorDict(\n            source={\n                \"a\": torch.randn(100, 2),\n                \"b\": torch.randn(100, 1),\n                \"done\": torch.zeros(100, 1, dtype=torch.bool).bernoulli_(),", "choices": [{"text": "\"test_shared: shared=memmap\""}], "metadata": {"task_id": "pytorch_rl/70", "ground_truth": "            },", "fpath_tuple": ["pytorch_rl", "test", "test_shared.py"], "context_start_lineno": 0, "line_no": 130, "query_window": {"context": "        proc.start()\n        command_pipe_child.close()\n        command_pipe_parent.send(\"stack\" if stack else \"serial\")\n        time_spent = command_pipe_parent.recv()\n        print(f\"stack {stack}: time={time_spent}\")\n        for item in td.values():\n            assert (item == 0).all()\n        proc.join()\n        command_pipe_parent.close()\n        return time_spent\n\n    @pytest.mark.parametrize(\"shared\", [\"shared\", \"memmap\"])\n    def test_shared(self, shared):\n        print(f\"test_shared: shared={shared}\")\n        torch.manual_seed(0)\n        tensordict = TensorDict(\n            source={\n                \"a\": torch.randn(100, 2),\n                \"b\": torch.randn(100, 1),\n                \"done\": torch.zeros(100, 1, dtype=torch.bool).bernoulli_(),", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_shared.py"], "line_no": 130, "task_id": "pytorch_rl/70", "start_line_no": 110, "end_line_no": 130, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        [[\"done\", \"reward\"]],\n    )\n    @pytest.mark.parametrize(\"device\", get_available_devices())\n    def test_sum_reward(self, keys, device):\n        torch.manual_seed(0)\n        batch = 4\n        rs = RewardSum()\n        td = TensorDict(\n            {\n                \"done\": torch.zeros((batch, 1), dtype=torch.bool),\n                \"reward\": torch.rand((batch, 1)),\n            },\n            device=device,\n            batch_size=[batch],\n        )\n\n        # apply one time, episode_reward should be equal to reward again\n        td = rs(td)\n        assert \"episode_reward\" in td.keys()\n        assert (td.get(\"episode_reward\") == td.get(\"reward\")).all()", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_transforms.py"], "line_no": 820, "start_line_no": 810, "end_line_no": 830, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.41333333333333333}, {"context": "        else:\n            observation_spec = CompositeSpec(\n                {key: BoundedTensorSpec(-1, 1, (nchannels, 16, 16)) for key in keys}\n            )\n            observation_spec = gs.transform_observation_spec(observation_spec)\n            for key in keys:\n                assert observation_spec[key].shape == torch.Size([1, 16, 16])\n\n    @pytest.mark.parametrize(\n        \"keys\",\n        [[\"done\", \"reward\"]],\n    )\n    @pytest.mark.parametrize(\"device\", get_available_devices())\n    def test_sum_reward(self, keys, device):\n        torch.manual_seed(0)\n        batch = 4\n        rs = RewardSum()\n        td = TensorDict(\n            {\n                \"done\": torch.zeros((batch, 1), dtype=torch.bool),", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_transforms.py"], "line_no": 810, "start_line_no": 800, "end_line_no": 820, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3836477987421384}, {"context": "\nclass TestCountFrames:\n    def test_countframes(self):\n        torch.manual_seed(0)\n        trainer = mocking_trainer()\n\n        frame_skip = 3\n        batch = 10\n        count_frames = CountFramesLog(frame_skip=frame_skip)\n        count_frames.register(trainer)\n        td = TensorDict(\n            {(\"collector\", \"mask\"): torch.zeros(batch, dtype=torch.bool).bernoulli_()},\n            [batch],\n        )\n        trainer._pre_steps_log_hook(td)\n        assert (\n            count_frames.frame_count == td.get((\"collector\", \"mask\")).sum() * frame_skip\n        )\n\n    @pytest.mark.parametrize(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 990, "start_line_no": 980, "end_line_no": 1000, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3783783783783784}, {"context": "        env1.close()\n        env2.close()\n\n    @pytest.mark.parametrize(\"batch_size\", [(), (1,), (4,), (32, 5)])\n    @pytest.mark.parametrize(\"n_workers\", [1, 2])\n    def test_parallel_env_reset_flag(self, batch_size, n_workers, max_steps=3):\n        torch.manual_seed(1)\n        env = ParallelEnv(\n            n_workers, lambda: CountingEnv(max_steps=max_steps, batch_size=batch_size)\n        )\n        env.set_seed(1)\n        action = env.action_spec.rand()\n        action[:] = 1\n        for i in range(max_steps):\n            td = env.step(\n                TensorDict(\n                    {\"action\": action}, batch_size=env.batch_size, device=env.device\n                )\n            )\n            assert (td[\"done\"] == 0).all()", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 910, "start_line_no": 900, "end_line_no": 920, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.36774193548387096}, {"context": "    trainer.register_op(\"batch_process\", mask_batch)\n    batch = 10\n    td = TensorDict(\n        {\n            (\"collector\", \"mask\"): torch.zeros(batch, dtype=torch.bool).bernoulli_(),\n            \"tensor\": torch.randn(batch, 51),\n        },\n        [batch],\n    )\n    td_out = trainer._process_batch_hook(td)\n    assert td_out.shape[0] == td.get((\"collector\", \"mask\")).sum()\n    assert (td[\"tensor\"][td[(\"collector\", \"mask\")]] == td_out[\"tensor\"]).all()\n\n\nclass TestSubSampler:\n    def test_subsampler(self):\n        torch.manual_seed(0)\n        trainer = mocking_trainer()\n\n        batch_size = 10", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 770, "start_line_no": 760, "end_line_no": 780, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3618421052631579}, {"context": "        td = TensorDict(\n            {(\"collector\", \"mask\"): torch.zeros(batch, dtype=torch.bool).bernoulli_()},\n            [batch],\n        )\n        trainer._pre_steps_log_hook(td)\n        assert (\n            count_frames.frame_count == td.get((\"collector\", \"mask\")).sum() * frame_skip\n        )\n\n    @pytest.mark.parametrize(\n        \"backend\",\n        [\n            \"torchsnapshot\",\n            \"torch\",\n        ],\n    )\n    def test_countframes_load(self, backend):\n        if not _has_ts and backend == \"torchsnapshot\":\n            pytest.skip(\"torchsnapshot not found\")\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 1000, "start_line_no": 990, "end_line_no": 1010, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.35570469798657717}, {"context": "\n        cat_frames(td.clone())\n        buffer = getattr(cat_frames, f\"_cat_buffers_{key1}\")\n\n        tdc = td.clone()\n        passed_back_td = cat_frames.reset(tdc)\n        assert \"_reset\" in tdc.keys()\n\n        assert tdc is passed_back_td\n        assert (buffer == 0).all()\n\n        _ = cat_frames._call(tdc)\n        assert (buffer != 0).all()\n\n    @pytest.mark.parametrize(\"device\", get_available_devices())\n    def test_finitetensordictcheck(self, device):\n        ftd = FiniteTensorDictCheck()\n        td = TensorDict(\n            {key: torch.randn(1, 3, 3, device=device) for key in [\"a\", \"b\", \"c\"]}, [1]\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_transforms.py"], "line_no": 1370, "start_line_no": 1360, "end_line_no": 1380, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3503184713375796}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/r2d2.py\n# --------------------------------------------------\n#             'obs': obs,\n#             'action': model_output['action'],\n#             'prev_state': model_output['prev_state'],\n#             'reward': timestep.reward,\n#             'done': timestep.done,\n#         }\n#         return transition\n# \n#     def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n#         r\"\"\"\n#         Overview:\n#             Get the trajectory and the n step return data, then sample from the n_step return data\n# \n#         Arguments:\n#             - data (:obj:`list`): The trajectory's cache\n# \n#         Returns:\n#             - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/cql.py\n# --------------------------------------------------\n#         }\n#         return transition\n# \n#     def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def _init_eval(self) -> None:\n#         r\"\"\"\n#         Overview:\n#             Evaluate mode init method. Called by ``self.__init__``.\n#             Init eval model. Unlike learn and collect model, eval model does not need noise.\n#         \"\"\"\n#         self._eval_model = model_wrap(self._model, wrapper_name='base')\n#         self._eval_model.reset()\n# \n#     def _forward_eval(self, data: dict) -> dict:\n#         r\"\"\"\n#         Overview:\n#             Forward function for eval mode, similar to ``self._forward_collect``.\n#         Arguments:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/dqn.py\n# --------------------------------------------------\n#             'next_obs': timestep.obs,\n#             'action': policy_output['action'],\n#             'reward': timestep.reward,\n#             'done': timestep.done,\n#         }\n#         return transition\n# \n#     def _init_eval(self) -> None:\n#         r\"\"\"\n#         Overview:\n#             Evaluate mode init method. Called by ``self.__init__``, initialize eval_model.\n#         \"\"\"\n#         self._eval_model = model_wrap(self._model, wrapper_name='argmax_sample')\n#         self._eval_model.reset()\n# \n#     def _forward_eval(self, data: Dict[int, Any]) -> Dict[int, Any]:\n#         \"\"\"\n#         Overview:\n#             Forward computation graph of eval mode(evaluate policy performance), at most cases, it is similar to \\\n#             ``self._forward_collect``.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/sql.py\n# --------------------------------------------------\n#         }\n#         return EasyDict(transition)\n# \n#     def _init_eval(self) -> None:\n#         r\"\"\"\n#         Overview:\n#             Evaluate mode init method. Called by ``self.__init__``.\n#             Init eval model with argmax strategy.\n#         \"\"\"\n#         self._eval_model = model_wrap(self._model, wrapper_name='argmax_sample')\n#         self._eval_model.reset()\n# \n#     def _forward_eval(self, data: dict) -> dict:\n#         r\"\"\"\n#         Overview:\n#             Forward function for eval mode, similar to ``self._forward_collect``.\n#         Arguments:\n#             - data (:obj:`dict`): Dict type data, including at least ['obs'].\n#         Returns:\n#             - data (:obj:`dict`): Dict type data, including at least inferred action according to input obs.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/coma.py\n# --------------------------------------------------\n#             'next_obs': timestep.obs,\n#             'prev_state': model_output['prev_state'],\n#             'action': model_output['action'],\n#             'reward': timestep.reward,\n#             'done': timestep.done,\n#         }\n#         return transition\n# \n#     def _init_eval(self) -> None:\n#         r\"\"\"\n#         Overview:\n#             Evaluate mode init method. Called by ``self.__init__``.\n#             Init eval model with argmax strategy and hidden_state plugin.\n#         \"\"\"\n#         self._eval_model = model_wrap(\n#             self._model,\n#             wrapper_name='hidden_state',\n#             state_num=self._cfg.eval.env_num,\n#             save_prev_state=True,\n#             init_fn=lambda: [None for _ in range(self._cfg.model.agent_num)]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/acer.py\n# --------------------------------------------------\n#             'logit': policy_output['logit'],\n#             'action': policy_output['action'],\n#             'reward': timestep.reward,\n#             'done': timestep.done,\n#         }\n#         return transition\n# \n#     def _init_eval(self) -> None:\n#         r\"\"\"\n#         Overview:\n#             Evaluate mode init method. Called by ``self.__init__``, initialize eval_model,\n#             and use argmax_sample to choose action.\n#         \"\"\"\n#         self._eval_model = model_wrap(self._model, wrapper_name='argmax_sample')\n#         self._eval_model.reset()\n# \n#     def _forward_eval(self, data: Dict[int, Any]) -> Dict[int, Any]:\n#         r\"\"\"\n#         Overview:\n#             Forward computation graph of eval mode(evaluate policy performance), at most cases, it is similar to \\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/qtran.py\n# --------------------------------------------------\n#             'action': model_output['action'],\n#             'reward': timestep.reward,\n#             'done': timestep.done,\n#         }\n#         return transition\n# \n#     def _init_eval(self) -> None:\n#         r\"\"\"\n#         Overview:\n#             Evaluate mode init method. Called by ``self.__init__``.\n#             Init eval model with argmax strategy and the hidden_state plugin.\n#         \"\"\"\n#         self._eval_model = model_wrap(\n#             self._model,\n#             wrapper_name='hidden_state',\n#             state_num=self._cfg.eval.env_num,\n#             save_prev_state=True,\n#             init_fn=lambda: [None for _ in range(self._cfg.model.agent_num)]\n#         )\n#         self._eval_model = model_wrap(self._eval_model, wrapper_name='argmax_sample')\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nstate'][0])\n        inputs = {'obs': data['obs'], 'action': data['action']}\n        total_q = self._learn_model.forward(inputs, single_step=False)['total_q']\n\n        if self._cfg.learn.double_q:\n            next_inputs = {'obs': data['next_obs']}\n            self._learn_model.reset(state=data['prev_state'][1])\n            logit_detach = self._learn_model.forward(next_inputs, single_step=False)['logit'].clone().detach()\n            next_inputs = {'obs': data['next_obs'], 'action': logit_detach.argmax(dim=-1)}\n        else:\n            next_inputs = {'obs': data['next_obs']}\n        with torch.no_grad():\n            target_total_q = self._target_model.forward(next_inputs, single_step=False)['total_q']\n\n        with torch.no_grad():\n            if data['done'] is not None:\n                target_v = self._gamma * (1 - data['done']) * target_total_q + data['reward']\n            else:\n                target_v = self._gamma * target_total_q + data['reward']\n\n        data = v_1step_td_data(total_q, target_total_q, data['reward'], data['done'], data['weight'])\n        loss, td_error_per_sample = v_1step_td_error(data, self._gamma)\n        # ====================\n        # Q-mix update\n        # ====================\n        self._optimizer.zero_grad()\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(self._model.parameters(), self._cfg.learn.clip_value)\n        self._optimizer.step()\n        # =============\n        # after update\n        # =============\n        self._target_model.update(self._learn_model.state_dict())\n        return {\n            'cur_lr': self._optimizer.defaults['lr'],\n            'total_loss': loss.item(),\n            'total_q': total_q.mean().item() / self._cfg.model.agent_num,\n            'target_reward_total_q': target_v.mean().item() / self._cfg.model.agent_num,\n            'target_total_q': target_total_q.mean().item() / self._cfg.model.agent_num,\n            'grad_norm': grad_norm,\n        }\n\n    def _reset_learn(self, data_id: Optional[List[int]] = None) -> None:\n        r\"\"\"\n        Overview:\n            Reset learn model to the state indicated by data_id\n        Arguments:\n            - data_id (:obj:`Optional[List[int]]`): The id that store the state and we will reset\\\n                the model state to the state indicated by data_id\n        \"\"\"\n        self._learn_model.reset(data_id=data_id)\n\n    def _state_dict_learn(self) -> Dict[str, Any]:\n        r\"\"\"\n        Overview:\n            Return the state_dict of learn mode, usually including model and optimizer.\n        Returns:\n            - state_dict (:obj:`Dict[str, Any]`): the dict of current policy learn state, for saving and restoring.\n        \"\"\"\n        return {\n            'model': self._learn_model.state_dict(),\n            'optimizer': self._optimizer.state_dict(),\n        }\n\n    def _load_state_dict_learn(self, state_dict: Dict[str, Any]) -> None:\n        r\"\"\"\n        Overview:\n            Load the state_dict variable into policy learn mode.\n        Arguments:\n            - state_dict (:obj:`Dict[str, Any]`): the dict of policy learn state saved before.\n        .. tip::\n            If you want to only load some parts of model, you can simply set the ``strict`` argument in \\\n            load_state_dict to ``False``, or refer to ``ding.torch_utils.checkpoint_helper`` for more \\\n            complicated operation.\n        \"\"\"\n        self._learn_model.load_state_dict(state_dict['model'])\n        self._optimizer.load_state_dict(state_dict['optimizer'])\n\n    def _init_collect(self) -> None:\n        r\"\"\"\n        Overview:\n            Collect mode init method. Called by ``self.__init__``.\n            Init traj and unroll length, collect model.\n            Enable the eps_greedy_sample and the hidden_state plugin.\n        \"\"\"\n        self._unroll_len = self._cfg.collect.unroll_len\n        self._collect_model = model_wrap(\n            self._model,\n            wrapper_name='hidden_state',\n            state_num=self._cfg.collect.env_num,\n            save_prev_state=True,\n            init_fn=lambda: [None for _ in range(self._cfg.model.agent_num)]\n        )\n        self._collect_model = model_wrap(self._collect_model, wrapper_name='eps_greedy_sample')\n        self._collect_model.reset()\n\n    def _forward_collect(self, data: dict, eps: float) -> dict:\n        r\"\"\"\n        Overview:\n            Forward function for collect mode with eps_greedy\n        Arguments:\n            - data (:obj:`dict`): Dict type data, including at least ['obs'].\n            - eps (:obj:`float`): epsilon value for exploration, which is decayed by collected env step.\n        Returns:\n            - data (:obj:`dict`): The collected data\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        data = {'obs': data}\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps, data_id=data_id)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _reset_collect(self, data_id: Optional[List[int]] = None) -> None:\n        r\"\"\"\n        Overview:\n            Reset collect model to the state indicated by data_id\n        Arguments:\n            - data_id (:obj:`Optional[List[int]]`): The id that store the state and we will reset\\\n                the model state to the state indicated by data_id\n        \"\"\"\n        self._collect_model.reset(data_id=data_id)\n\n    def _process_transition(self, obs: Any, model_output: dict, timestep: namedtuple) -> dict:\n        r\"\"\"\n        Overview:\n            Generate dict type transition data from inputs.\n        Arguments:\n            - obs (:obj:`Any`): Env observation\n            - model_output (:obj:`dict`): Output of collect model, including at least ['action', 'prev_state']\n            - timestep (:obj:`namedtuple`): Output after env step, including at least ['obs', 'reward', 'done']\\\n                (here 'obs' indicates obs after env step).\n        Returns:\n            - transition (:obj:`dict`): Dict type transition data, including 'obs', 'next_obs', 'prev_state',\\\n                'action', 'reward', 'done'\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'prev_state': model_output['prev_state'],\n            'action': model_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _init_eval(self) -> None:\n        r\"\"\"\n        Overview:\n            Evaluate mode init method. Called by ``self.__init__``.", "choices": [{"text": "Init eval model with argmax strategy and hidden_state plugin."}], "metadata": {"task_id": "opendilab_ACE/123", "ground_truth": "            Init eval model with argmax strategy and the hidden_state plugin.", "fpath_tuple": ["opendilab_ACE", "ding", "policy", "qmix.py"], "context_start_lineno": 193, "line_no": 349, "query_window": {"context": "            - timestep (:obj:`namedtuple`): Output after env step, including at least ['obs', 'reward', 'done']\\\n                (here 'obs' indicates obs after env step).\n        Returns:\n            - transition (:obj:`dict`): Dict type transition data, including 'obs', 'next_obs', 'prev_state',\\\n                'action', 'reward', 'done'\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'prev_state': model_output['prev_state'],\n            'action': model_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _init_eval(self) -> None:\n        r\"\"\"\n        Overview:\n            Evaluate mode init method. Called by ``self.__init__``.", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "qmix.py"], "line_no": 349, "task_id": "opendilab_ACE/123", "start_line_no": 329, "end_line_no": 349, "window_size": 20, "context_start_lineno": 193, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "            - timestep (:obj:`namedtuple`): Output after env step, including at least ['obs', 'reward', 'done']\\\n                (here 'obs' indicates obs after env step).\n        Returns:\n            - transition (:obj:`dict`): Dict type transition data, including 'obs', 'next_obs', 'prev_state',\\\n                'action', 'reward', 'done'\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'prev_state': model_output['prev_state'],\n            'action': model_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _init_eval(self) -> None:\n        r\"\"\"\n        Overview:\n            Evaluate mode init method. Called by ``self.__init__``.", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "qtran.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 1.0}, {"context": "                - model_output (:obj:`dict`): Output of collect model, including ['logit','action']\n                - timestep (:obj:`namedtuple`): Output after env step, including at least ['obs', 'reward', 'done']\\\n                       (here 'obs' indicates obs after env step).\n        Returns:\n               - transition (:obj:`dict`): Dict type transition data, including at least ['obs','next_obs', 'logit',\\\n               'action','reward', 'done']\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'logit': policy_output['logit'],\n            'action': policy_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _init_eval(self) -> None:\n        r\"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "acer.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.7849462365591398}, {"context": "        Arguments:\n            - obs (:obj:`Any`): Env observation\n            - model_output (:obj:`dict`): Output of collect model, including at least ['action', 'prev_state']\n            - timestep (:obj:`namedtuple`): Output after env step, including at least ['obs', 'reward', 'done'] \\\n                (here 'obs' indicates obs after env step).\n        Returns:\n            - transition (:obj:`dict`): Dict type transition data.\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'prev_state': model_output['prev_state'],\n            'action': model_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _init_eval(self) -> None:\n        r\"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "coma.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.776595744680851}, {"context": "                (here 'obs' indicates obs after env step).\n        Returns:\n            - transition (:obj:`dict`): Dict type transition data.\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'action': model_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return EasyDict(transition)\n\n    def _init_eval(self) -> None:\n        r\"\"\"\n        Overview:\n            Evaluate mode init method. Called by ``self.__init__``.\n            Init eval model with argmax strategy.\n        \"\"\"\n        self._eval_model = model_wrap(self._model, wrapper_name='argmax_sample')", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "sql.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6857142857142857}, {"context": "            - obs (:obj:`Any`): Env observation.\n            - policy_output (:obj:`Dict[str, Any]`): The output of policy collect mode(``self._forward_collect``),\\\n                including at least ``action``.\n            - timestep (:obj:`namedtuple`): The output after env step(execute policy output action), including at \\\n                least ``obs``, ``reward``, ``done``, (here obs indicates obs after env step).\n        Returns:\n            - transition (:obj:`dict`): Dict type transition data.\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'action': policy_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _init_eval(self) -> None:\n        r\"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "dqn.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6698113207547169}, {"context": "                (here 'obs' indicates obs after env step, i.e. next_obs).\n        Return:\n            - transition (:obj:`Dict[str, Any]`): Dict type transition data.\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'action': model_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        return get_train_sample(data, self._unroll_len)\n\n    def _init_eval(self) -> None:\n        r\"\"\"\n        Overview:\n            Evaluate mode init method. Called by ``self.__init__``.", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "cql.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6363636363636364}, {"context": "            Generate dict type transition data from inputs.\n        Arguments:\n            - obs (:obj:`Any`): Env observation\n            - model_output (:obj:`dict`): Output of collect model, including at least ['action', 'prev_state']\n            - timestep (:obj:`namedtuple`): Output after env step, including at least ['reward', 'done'] \\\n                (here 'obs' indicates obs after env step).\n        Returns:\n            - transition (:obj:`dict`): Dict type transition data.\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'action': model_output['action'],\n            'prev_state': model_output['prev_state'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "r2d2.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6330275229357798}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_inpaint_legacy.py\n# --------------------------------------------------\n#         gc.collect()\n#         torch.cuda.empty_cache()\n# \n#     def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n#         generator = torch.Generator(device=generator_device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_image.png\"\n#         )\n#         mask_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_mask.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"A red cat sitting on a park bench\",\n#             \"image\": init_image,\n#             \"mask_image\": mask_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 50,\n#             \"strength\": 0.75,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_inpaint_legacy.py\n# --------------------------------------------------\n# \n#     def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n#         generator = torch.Generator(device=generator_device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_image.png\"\n#         )\n#         mask_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_mask.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"A red cat sitting on a park bench\",\n#             \"image\": init_image,\n#             \"mask_image\": mask_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 3,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_img2img.py\n# --------------------------------------------------\n#     def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n#         generator = torch.Generator(device=generator_device).manual_seed(seed)\n#         init_image = load_image(\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_img2img/sketch-mountains-input.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"a fantasy landscape, concept art, high resolution\",\n#             \"image\": init_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 50,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n#         }\n#         return inputs\n# \n#     def test_img2img_pndm(self):\n#         sd_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n#         sd_pipe.to(torch_device)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_img2img.py\n# --------------------------------------------------\n#         inputs = {\n#             \"prompt\": \"a fantasy landscape, concept art, high resolution\",\n#             \"image\": init_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 3,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n#         }\n#         return inputs\n# \n#     def test_stable_diffusion_img2img_default(self):\n#         pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", safety_checker=None)\n#         pipe.to(torch_device)\n#         pipe.set_progress_bar_config(disable=None)\n#         pipe.enable_attention_slicing()\n# \n#         inputs = self.get_inputs(torch_device)\n#         image = pipe(**inputs).images\n#         image_slice = image[0, -3:, -3:, -1].flatten()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_inpaint_legacy.py\n# --------------------------------------------------\n#         )\n#         inputs = {\n#             \"prompt\": \"A red cat sitting on a park bench\",\n#             \"image\": init_image,\n#             \"mask_image\": mask_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 3,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n#         }\n#         return inputs\n# \n#     def test_stable_diffusion_inpaint_legacy_pndm(self):\n#         pipe = StableDiffusionInpaintPipelineLegacy.from_pretrained(\n#             \"CompVis/stable-diffusion-v1-4\", safety_checker=None\n#         )\n#         pipe.to(torch_device)\n#         pipe.set_progress_bar_config(disable=None)\n#         pipe.enable_attention_slicing()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/pipelines/stable_diffusion/test_stable_diffusion_inpaint_legacy.py\n# --------------------------------------------------\n#             \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n#             \"/stable_diffusion_inpaint/input_bench_mask.png\"\n#         )\n#         inputs = {\n#             \"prompt\": \"A red cat sitting on a park bench\",\n#             \"image\": init_image,\n#             \"mask_image\": mask_image,\n#             \"generator\": generator,\n#             \"num_inference_steps\": 50,\n#             \"strength\": 0.75,\n#             \"guidance_scale\": 7.5,\n#             \"output_type\": \"numpy\",\n#         }\n#         return inputs\n# \n#     def test_inpaint_pndm(self):\n#         sd_pipe = StableDiffusionInpaintPipelineLegacy.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n#         sd_pipe.to(torch_device)\n#         sd_pipe.set_progress_bar_config(disable=None)\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nnumpy, nightly, slow, torch_device\nfrom diffusers.utils.testing_utils import require_torch_gpu\nfrom PIL import Image\nfrom transformers import CLIPTextConfig, CLIPTextModel, CLIPTokenizer\n\nfrom ...test_pipelines_common import PipelineTesterMixin\n\n\ntorch.backends.cuda.matmul.allow_tf32 = False\n\n\nclass StableDiffusionInpaintPipelineFastTests(PipelineTesterMixin, unittest.TestCase):\n    pipeline_class = StableDiffusionInpaintPipeline\n\n    def get_dummy_components(self):\n        torch.manual_seed(0)\n        unet = UNet2DConditionModel(\n            block_out_channels=(32, 64),\n            layers_per_block=2,\n            sample_size=32,\n            in_channels=9,\n            out_channels=4,\n            down_block_types=(\"DownBlock2D\", \"CrossAttnDownBlock2D\"),\n            up_block_types=(\"CrossAttnUpBlock2D\", \"UpBlock2D\"),\n            cross_attention_dim=32,\n        )\n        scheduler = PNDMScheduler(skip_prk_steps=True)\n        torch.manual_seed(0)\n        vae = AutoencoderKL(\n            block_out_channels=[32, 64],\n            in_channels=3,\n            out_channels=3,\n            down_block_types=[\"DownEncoderBlock2D\", \"DownEncoderBlock2D\"],\n            up_block_types=[\"UpDecoderBlock2D\", \"UpDecoderBlock2D\"],\n            latent_channels=4,\n        )\n        torch.manual_seed(0)\n        text_encoder_config = CLIPTextConfig(\n            bos_token_id=0,\n            eos_token_id=2,\n            hidden_size=32,\n            intermediate_size=37,\n            layer_norm_eps=1e-05,\n            num_attention_heads=4,\n            num_hidden_layers=5,\n            pad_token_id=1,\n            vocab_size=1000,\n        )\n        text_encoder = CLIPTextModel(text_encoder_config)\n        tokenizer = CLIPTokenizer.from_pretrained(\"hf-internal-testing/tiny-random-clip\")\n\n        components = {\n            \"unet\": unet,\n            \"scheduler\": scheduler,\n            \"vae\": vae,\n            \"text_encoder\": text_encoder,\n            \"tokenizer\": tokenizer,\n            \"safety_checker\": None,\n            \"feature_extractor\": None,\n        }\n        return components\n\n    def get_dummy_inputs(self, device, seed=0):\n        # TODO: use tensor inputs instead of PIL, this is here just to leave the old expected_slices untouched\n        image = floats_tensor((1, 3, 32, 32), rng=random.Random(seed)).to(device)\n        image = image.cpu().permute(0, 2, 3, 1)[0]\n        init_image = Image.fromarray(np.uint8(image)).convert(\"RGB\").resize((64, 64))\n        mask_image = Image.fromarray(np.uint8(image + 4)).convert(\"RGB\").resize((64, 64))\n        if str(device).startswith(\"mps\"):\n            generator = torch.manual_seed(seed)\n        else:\n            generator = torch.Generator(device=device).manual_seed(seed)\n        inputs = {\n            \"prompt\": \"A painting of a squirrel eating a burger\",\n            \"image\": init_image,\n            \"mask_image\": mask_image,\n            \"generator\": generator,\n            \"num_inference_steps\": 2,\n            \"guidance_scale\": 6.0,\n            \"output_type\": \"numpy\",\n        }\n        return inputs\n\n    def test_stable_diffusion_inpaint(self):\n        device = \"cpu\"  # ensure determinism for the device-dependent torch.Generator\n        components = self.get_dummy_components()\n        sd_pipe = StableDiffusionInpaintPipeline(**components)\n        sd_pipe = sd_pipe.to(device)\n        sd_pipe.set_progress_bar_config(disable=None)\n\n        inputs = self.get_dummy_inputs(device)\n        image = sd_pipe(**inputs).images\n        image_slice = image[0, -3:, -3:, -1]\n\n        assert image.shape == (1, 64, 64, 3)\n        expected_slice = np.array([0.4723, 0.5731, 0.3939, 0.5441, 0.5922, 0.4392, 0.5059, 0.4651, 0.4474])\n\n        assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2\n\n    def test_stable_diffusion_inpaint_image_tensor(self):\n        device = \"cpu\"  # ensure determinism for the device-dependent torch.Generator\n        components = self.get_dummy_components()\n        sd_pipe = StableDiffusionInpaintPipeline(**components)\n        sd_pipe = sd_pipe.to(device)\n        sd_pipe.set_progress_bar_config(disable=None)\n\n        inputs = self.get_dummy_inputs(device)\n        output = sd_pipe(**inputs)\n        out_pil = output.images\n\n        inputs = self.get_dummy_inputs(device)\n        inputs[\"image\"] = torch.tensor(np.array(inputs[\"image\"]) / 127.5 - 1).permute(2, 0, 1).unsqueeze(0)\n        inputs[\"mask_image\"] = torch.tensor(np.array(inputs[\"mask_image\"]) / 255).permute(2, 0, 1)[:1].unsqueeze(0)\n        output = sd_pipe(**inputs)\n        out_tensor = output.images\n\n        assert out_pil.shape == (1, 64, 64, 3)\n        assert np.abs(out_pil.flatten() - out_tensor.flatten()).max() < 5e-2\n\n    def test_stable_diffusion_inpaint_with_num_images_per_prompt(self):\n        device = \"cpu\"\n        components = self.get_dummy_components()\n        sd_pipe = StableDiffusionInpaintPipeline(**components)\n        sd_pipe = sd_pipe.to(device)\n        sd_pipe.set_progress_bar_config(disable=None)\n\n        inputs = self.get_dummy_inputs(device)\n        images = sd_pipe(**inputs, num_images_per_prompt=2).images\n\n        # check if the output is a list of 2 images\n        assert len(images) == 2\n\n\n@slow\n@require_torch_gpu\nclass StableDiffusionInpaintPipelineSlowTests(unittest.TestCase):\n    def setUp(self):\n        super().setUp()\n\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_mask.png\"\n        )\n        inputs = {\n            \"prompt\": \"Face of a yellow cat, high resolution, sitting on a park bench\",", "choices": [{"text": "\"image\": init_image,"}], "metadata": {"task_id": "huggingface_diffusers/81", "ground_truth": "            \"image\": init_image,", "fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint.py"], "context_start_lineno": 31, "line_no": 187, "query_window": {"context": "    def setUp(self):\n        super().setUp()\n\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_mask.png\"\n        )\n        inputs = {\n            \"prompt\": \"Face of a yellow cat, high resolution, sitting on a park bench\",", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint.py"], "line_no": 187, "task_id": "huggingface_diffusers/81", "start_line_no": 167, "end_line_no": 187, "window_size": 20, "context_start_lineno": 31, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_mask.png\"\n        )\n        inputs = {\n            \"prompt\": \"A red cat sitting on a park bench\",\n            \"image\": init_image,\n            \"mask_image\": mask_image,\n            \"generator\": generator,\n            \"num_inference_steps\": 50,\n            \"strength\": 0.75,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint_legacy.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.8034188034188035}, {"context": "\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_mask.png\"\n        )\n        inputs = {\n            \"prompt\": \"A red cat sitting on a park bench\",\n            \"image\": init_image,\n            \"mask_image\": mask_image,\n            \"generator\": generator,\n            \"num_inference_steps\": 3,\n            \"strength\": 0.75,\n            \"guidance_scale\": 7.5,\n            \"output_type\": \"numpy\",", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint_legacy.py"], "line_no": 360, "start_line_no": 350, "end_line_no": 370, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6825396825396826}, {"context": "        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_img2img/sketch-mountains-input.png\"\n        )\n        inputs = {\n            \"prompt\": \"a fantasy landscape, concept art, high resolution\",\n            \"image\": init_image,\n            \"generator\": generator,\n            \"num_inference_steps\": 3,\n            \"strength\": 0.75,\n            \"guidance_scale\": 7.5,\n            \"output_type\": \"numpy\",\n        }\n        return inputs", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_img2img.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6617647058823529}, {"context": "\n\n@nightly\n@require_torch_gpu\nclass StableDiffusionImg2ImgPipelineNightlyTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_img2img/sketch-mountains-input.png\"\n        )\n        inputs = {\n            \"prompt\": \"a fantasy landscape, concept art, high resolution\",\n            \"image\": init_image,\n            \"generator\": generator,", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_img2img.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6428571428571429}, {"context": "        assert images.shape == (batch_size * num_images_per_prompt, 32, 32, 3)\n\n\n@slow\n@require_torch_gpu\nclass StableDiffusionInpaintLegacyPipelineSlowTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_mask.png\"", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint_legacy.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6363636363636364}, {"context": "        pipe(**inputs, callback=callback_fn, callback_steps=1)\n        assert callback_fn.has_been_called\n        assert number_of_steps == 2\n\n\n@nightly\n@require_torch_gpu\nclass StableDiffusionInpaintLegacyPipelineNightlyTests(unittest.TestCase):\n    def tearDown(self):\n        super().tearDown()\n        gc.collect()\n        torch.cuda.empty_cache()\n\n    def get_inputs(self, device, generator_device=\"cpu\", dtype=torch.float32, seed=0):\n        generator = torch.Generator(device=generator_device).manual_seed(seed)\n        init_image = load_image(\n            \"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main\"\n            \"/stable_diffusion_inpaint/input_bench_image.png\"\n        )\n        mask_image = load_image(", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "pipelines", "stable_diffusion", "test_stable_diffusion_inpaint_legacy.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.6027397260273972}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#                 safe=safe,\n#             )\n# \n#         params = make_functional(tdmodule)\n# \n#         # vmap = True\n#         params = params.expand(10)\n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n#         if safe and spec_type == \"bounded\":\n#             with pytest.raises(\n#                 RuntimeError, match=\"vmap cannot be used with safe=True\"\n#             ):\n#                 td_out = vmap(tdmodule, (None, 0))(td, params)\n#             return\n#         else:\n#             td_out = vmap(tdmodule, (None, 0))(td, params)\n#         assert td_out is not td\n#         assert td_out.shape == torch.Size([10, 3])\n#         assert td_out.get(\"out\").shape == torch.Size([10, 3, 4])\n#         # test bounds\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#         tdmodule(td, params=params)\n#         assert td.shape == torch.Size([3])\n#         assert td.get(\"out\").shape == torch.Size([3, 32])\n# \n#         # test bounds\n#         if not safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n#         elif safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n# \n#     @pytest.mark.parametrize(\"safe\", [True, False])\n#     @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n#     def test_functional_with_buffer_probabilistic(self, safe, spec_type):\n#         torch.manual_seed(0)\n#         param_multiplier = 2\n# \n#         tdnet = SafeModule(\n#             module=NormalParamWrapper(nn.BatchNorm1d(32 * param_multiplier)),\n#             spec=None,\n#             in_keys=[\"in\"],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#                 out_keys=[\"out\"],\n#                 spec=spec,\n#                 safe=safe,\n#                 **kwargs,\n#             )\n# \n#         tensordict_module = SafeProbabilisticSequential(tdnet, prob_module)\n#         params = make_functional(tensordict_module)\n# \n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n#         tensordict_module(td, params=params)\n#         assert td.shape == torch.Size([3])\n#         assert td.get(\"out\").shape == torch.Size([3, 4])\n# \n#         # test bounds\n#         if not safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n#         elif safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n# \n#         assert hasattr(tdmodule, \"__getitem__\")\n#         assert tdmodule[0] is tdmodule1\n#         assert tdmodule[1] is tdmodule2\n# \n#         td = TensorDict({\"in\": torch.randn(3, 7)}, [3])\n#         tdmodule(td, params=params)\n# \n#         assert td.shape == torch.Size([3])\n#         assert td.get(\"out\").shape == torch.Size([3, 7])\n# \n#         # test bounds\n#         if not safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n#         elif safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n# \n#     @pytest.mark.parametrize(\"safe\", [True, False])\n#     @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n#     def test_functional_with_buffer_probabilistic(self, safe, spec_type):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#                 safe=safe,\n#             )\n# \n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n#         tensordict_module(td)\n#         assert td.shape == torch.Size([3])\n#         assert td.get(\"out\").shape == torch.Size([3, 4])\n# \n#         # test bounds\n#         if not safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n#         elif safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n# \n#     @pytest.mark.parametrize(\"safe\", [True, False])\n#     @pytest.mark.parametrize(\"spec_type\", [None, \"bounded\", \"unbounded\"])\n#     @pytest.mark.parametrize(\"out_keys\", [[\"loc\", \"scale\"], [\"loc_1\", \"scale_1\"]])\n#     @pytest.mark.parametrize(\"lazy\", [True, False])\n#     @pytest.mark.parametrize(\"exp_mode\", [\"mode\", \"random\", None])\n#     def test_stateful_probabilistic(self, safe, spec_type, lazy, exp_mode, out_keys):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#             tensordict_module = SafeModule(\n#                 spec=spec,\n#                 module=net,\n#                 in_keys=[\"in\"],\n#                 out_keys=[\"out\"],\n#                 safe=safe,\n#             )\n# \n#         td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n#         tensordict_module(td, params=params)\n#         assert td.shape == torch.Size([3])\n#         assert td.get(\"out\").shape == torch.Size([3, 4])\n# \n#         # test bounds\n#         if not safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n#         elif safe and spec_type == \"bounded\":\n#             assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n# \n#     @pytest.mark.parametrize(\"safe\", [True, False])\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n:\n            raise NotImplementedError\n\n        kwargs = {\"distribution_class\": TanhNormal}\n\n        if safe and spec is None:\n            pytest.skip(\"safe and spec is None is checked elsewhere\")\n        else:\n            tdmodule1 = SafeModule(\n                net1,\n                spec=None,\n                in_keys=[\"in\"],\n                out_keys=[\"hidden\"],\n                safe=False,\n            )\n            tdmodule2 = SafeModule(net2, in_keys=[\"hidden\"], out_keys=[\"loc\", \"scale\"])\n            prob_module = SafeProbabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=safe,\n                **kwargs,\n            )\n            tdmodule = SafeProbabilisticSequential(tdmodule1, tdmodule2, prob_module)\n\n        params = make_functional(tdmodule)\n\n        # vmap = True\n        params = params.expand(10)\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        if safe and spec_type == \"bounded\":\n            with pytest.raises(\n                RuntimeError, match=\"vmap cannot be used with safe=True\"\n            ):\n                td_out = vmap(tdmodule, (None, 0))(td, params)\n            return\n        else:\n            td_out = vmap(tdmodule, (None, 0))(td, params)\n        assert td_out is not td\n        assert td_out.shape == torch.Size([10, 3])\n        assert td_out.get(\"out\").shape == torch.Size([10, 3, 4])\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td_out.get(\"out\") > 0.1) | (td_out.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td_out.get(\"out\") < 0.1) | (td_out.get(\"out\") > -0.1)).all()\n\n        # vmap = (0, 0)\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        td_repeat = td.expand(10, *td.batch_size)\n        td_out = vmap(tdmodule, (0, 0))(td_repeat, params)\n        assert td_out is not td_repeat\n        assert td_out.shape == torch.Size([10, 3])\n        assert td_out.get(\"out\").shape == torch.Size([10, 3, 4])\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td_out.get(\"out\") > 0.1) | (td_out.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td_out.get(\"out\") < 0.1) | (td_out.get(\"out\") > -0.1)).all()\n\n    @pytest.mark.parametrize(\"functional\", [True, False])\n    def test_submodule_sequence(self, functional):\n        td_module_1 = SafeModule(\n            nn.Linear(3, 2),\n            in_keys=[\"in\"],\n            out_keys=[\"hidden\"],\n        )\n        td_module_2 = SafeModule(\n            nn.Linear(2, 4),\n            in_keys=[\"hidden\"],\n            out_keys=[\"out\"],\n        )\n        td_module = SafeSequential(td_module_1, td_module_2)\n\n        if functional:\n            td_1 = TensorDict({\"in\": torch.randn(5, 3)}, [5])\n            sub_seq_1 = td_module.select_subsequence(out_keys=[\"hidden\"])\n            params = make_functional(sub_seq_1)\n            sub_seq_1(td_1, params=params)\n            assert \"hidden\" in td_1.keys()\n            assert \"out\" not in td_1.keys()\n            td_2 = TensorDict({\"hidden\": torch.randn(5, 2)}, [5])\n            sub_seq_2 = td_module.select_subsequence(in_keys=[\"hidden\"])\n            params = make_functional(sub_seq_2)\n            sub_seq_2(td_2, params=params)\n            assert \"out\" in td_2.keys()\n            assert td_2.get(\"out\").shape == torch.Size([5, 4])\n        else:\n            td_1 = TensorDict({\"in\": torch.randn(5, 3)}, [5])\n            sub_seq_1 = td_module.select_subsequence(out_keys=[\"hidden\"])\n            sub_seq_1(td_1)\n            assert \"hidden\" in td_1.keys()\n            assert \"out\" not in td_1.keys()\n            td_2 = TensorDict({\"hidden\": torch.randn(5, 2)}, [5])\n            sub_seq_2 = td_module.select_subsequence(in_keys=[\"hidden\"])\n            sub_seq_2(td_2)\n            assert \"out\" in td_2.keys()\n            assert td_2.get(\"out\").shape == torch.Size([5, 4])\n\n    @pytest.mark.parametrize(\"stack\", [True, False])\n    @pytest.mark.parametrize(\"functional\", [True, False])\n    def test_sequential_partial(self, stack, functional):\n        torch.manual_seed(0)\n        param_multiplier = 2\n\n        net1 = nn.Linear(3, 4)\n\n        net2 = nn.Linear(4, 4 * param_multiplier)\n        net2 = NormalParamWrapper(net2)\n        net2 = SafeModule(net2, in_keys=[\"b\"], out_keys=[\"loc\", \"scale\"])\n\n        net3 = nn.Linear(4, 4 * param_multiplier)\n        net3 = NormalParamWrapper(net3)\n        net3 = SafeModule(net3, in_keys=[\"c\"], out_keys=[\"loc\", \"scale\"])\n\n        spec = BoundedTensorSpec(-0.1, 0.1, 4)\n\n        kwargs = {\"distribution_class\": TanhNormal}\n\n        tdmodule1 = SafeModule(\n            net1,\n            in_keys=[\"a\"],\n            out_keys=[\"hidden\"],\n            spec=None,\n            safe=False,\n        )\n        tdmodule2 = SafeProbabilisticSequential(\n            net2,\n            SafeProbabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=True,\n                **kwargs,\n            ),\n        )\n        tdmodule3 = SafeProbabilisticSequential(\n            net3,\n            SafeProbabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=True,\n                **kwargs,\n            ),\n        )\n        tdmodule = SafeSequential(\n            tdmodule1, tdmodule2, tdmodule3, partial_tolerant=True\n        )\n\n        if functional:\n            params = make_functional(tdmodule)\n        else:\n            params = None\n\n        if stack:\n            td = torch.stack(\n                [\n                    TensorDict({\"a\": torch.randn(3), \"b\": torch.randn(4)}, []),\n                    TensorDict({\"a\": torch.randn(3), \"c\": torch.randn(4)}, []),\n                ],\n                0,\n            )\n            if functional:\n                tdmodule(td, params=params)\n            else:\n                tdmodule(td)\n            assert \"loc\" in td.keys()\n            assert \"scale\" in td.keys()\n            assert \"out\" in td.keys()\n            assert td[\"out\"].shape[0] == 2\n            assert td[\"loc\"].shape[0] == 2\n            assert td[\"scale\"].shape[0] == 2", "choices": [{"text": "if not safe:"}], "metadata": {"task_id": "pytorch_rl/3", "ground_truth": "            assert \"b\" not in td.keys()", "fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "context_start_lineno": 1227, "line_no": 1400, "query_window": {"context": "            params = None\n\n        if stack:\n            td = torch.stack(\n                [\n                    TensorDict({\"a\": torch.randn(3), \"b\": torch.randn(4)}, []),\n                    TensorDict({\"a\": torch.randn(3), \"c\": torch.randn(4)}, []),\n                ],\n                0,\n            )\n            if functional:\n                tdmodule(td, params=params)\n            else:\n                tdmodule(td)\n            assert \"loc\" in td.keys()\n            assert \"scale\" in td.keys()\n            assert \"out\" in td.keys()\n            assert td[\"out\"].shape[0] == 2\n            assert td[\"loc\"].shape[0] == 2\n            assert td[\"scale\"].shape[0] == 2", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 1400, "task_id": "pytorch_rl/3", "start_line_no": 1380, "end_line_no": 1400, "window_size": 20, "context_start_lineno": 1227, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            ):\n                tensordict_module = SafeModule(\n                    spec=spec,\n                    module=net,\n                    in_keys=[\"in\"],\n                    out_keys=[\"out\"],\n                    safe=safe,\n                )\n            return\n        else:\n            tensordict_module = SafeModule(\n                spec=spec,\n                module=net,\n                in_keys=[\"in\"],\n                out_keys=[\"out\"],\n                safe=safe,\n            )\n\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        tensordict_module(td, params=params)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45}, {"context": "                    out_keys=[\"out\"],\n                    safe=safe,\n                )\n            return\n        else:\n            tensordict_module = SafeModule(\n                module=net,\n                spec=spec,\n                in_keys=[\"in\"],\n                out_keys=[\"out\"],\n                safe=safe,\n            )\n\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        tensordict_module(td)\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 4])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.43478260869565216}, {"context": "        assert len(tdmodule) == 3\n        tdmodule[1] = tdmodule2\n        params[\"module\", \"1\"] = params[\"module\", \"2\"]\n        assert len(tdmodule) == 3\n\n        assert hasattr(tdmodule, \"__delitem__\")\n        assert len(tdmodule) == 3\n        del tdmodule[2]\n        del params[\"module\", \"2\"]\n        assert len(tdmodule) == 2\n\n        assert hasattr(tdmodule, \"__getitem__\")\n        assert tdmodule[0] is tdmodule1\n        assert tdmodule[1] is tdmodule2\n\n        td = TensorDict({\"in\": torch.randn(3, 7)}, [3])\n        tdmodule(td, params=params)\n\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 7])", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 1000, "start_line_no": 990, "end_line_no": 1010, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.42857142857142855}, {"context": "                    in_keys=[\"loc\", \"scale\"],\n                    out_keys=[\"out\"],\n                    spec=spec,\n                    safe=safe,\n                    **kwargs,\n                )\n            return\n        else:\n            prob_module = SafeProbabilisticModule(\n                in_keys=[\"loc\", \"scale\"],\n                out_keys=[\"out\"],\n                spec=spec,\n                safe=safe,\n                **kwargs,\n            )\n\n        tensordict_module = SafeProbabilisticSequential(tdnet, prob_module)\n        params = make_functional(tensordict_module)\n\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.42391304347826086}, {"context": "        else:\n            tdmodule = SafeModule(\n                spec=spec,\n                module=net,\n                in_keys=[\"in\"],\n                out_keys=[\"out\"],\n                safe=safe,\n            )\n\n        td = TensorDict({\"in\": torch.randn(3, 32 * param_multiplier)}, [3])\n        tdmodule(td, params=params)\n        assert td.shape == torch.Size([3])\n        assert td.get(\"out\").shape == torch.Size([3, 32])\n\n        # test bounds\n        if not safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") > 0.1) | (td.get(\"out\") < -0.1)).any()\n        elif safe and spec_type == \"bounded\":\n            assert ((td.get(\"out\") < 0.1) | (td.get(\"out\") > -0.1)).all()\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.41904761904761906}, {"context": "                    out_keys=[\"out\"],\n                    safe=safe,\n                )\n            return\n        else:\n            tdmodule = SafeModule(\n                spec=spec,\n                module=net,\n                in_keys=[\"in\"],\n                out_keys=[\"out\"],\n                safe=safe,\n            )\n\n        params = make_functional(tdmodule)\n\n        # vmap = True\n        params = params.expand(10)\n        td = TensorDict({\"in\": torch.randn(3, 3)}, [3])\n        if safe and spec_type == \"bounded\":\n            with pytest.raises(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4148936170212766}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/gfl/fedsageplus/worker.py\n# --------------------------------------------------\n#                     state=self.state,\n#                     content=(sample_size, clf_para)))\n# \n#     def callback_funcs_for_model_para(self, message: Message):\n#         round, sender, content = message.state, message.sender, message.content\n#         self.trainer_clf.update(content)\n#         self.state = round\n#         sample_size, clf_para, results = self.trainer_clf.train()\n#         if self._cfg.federate.share_local_model and not \\\n#                 self._cfg.federate.online_aggr:\n#             clf_para = copy.deepcopy(clf_para)\n#         logger.info(\n#             self._monitor.format_eval_res(results,\n#                                           rnd=self.state,\n#                                           role='Client #{}'.format(self.ID)))\n#         self.comm_manager.send(\n#             Message(msg_type='clf_para',\n#                     sender=self.ID,\n#                     receiver=[sender],\n#                     state=self.state,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/preprocess/instance_norm.py\n# --------------------------------------------------\n#                         receiver=[self.server_id],\n#                         content=content))\n# \n#     def callback_func_for_instance_mean(self, message: Message):\n#         \"\"\"\n#         The handling function for calculate instance_norm after receiving \\\n#         var and mean.\n#         \"\"\"\n#         sender = message.sender\n#         feat_mean = message.content\n#         self.global_mean = feat_mean\n# \n#         self.msg_buffer['ss_instance_sum_norm_square'] = {}  # For variance\n#         content = {}\n#         # Send norm_square\n#         for split in ['train_data', 'val_data', 'test_data']:\n#             if hasattr(self.data, split):\n#                 split_data = getattr(self.data, split)\n#                 if split_data is not None and 'x' in split_data:\n#                     content[split] = self.ss_manager.secret_split({\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/autotune/fedex/client.py\n# --------------------------------------------------\n#         sender = message.sender\n#         self.state = message.state\n#         if message.content is not None:\n#             model_params = message.content[\"model_param\"]\n#             self.trainer.update(model_params)\n#         if self._cfg.finetune.before_eval:\n#             self.trainer.finetune()\n#         metrics = {}\n#         for split in self._cfg.eval.split:\n#             eval_metrics = self.trainer.evaluate(target_data_split_name=split)\n#             for key in eval_metrics:\n# \n#                 if self._cfg.federate.mode == 'distributed':\n#                     logger.info('Client #{:d}: (Evaluation ({:s} set) at '\n#                                 'Round #{:d}) {:s} is {:.6f}'.format(\n#                                     self.ID, split, self.state, key,\n#                                     eval_metrics[key]))\n#                 metrics.update(**eval_metrics)\n#         self.comm_manager.send(\n#             Message(msg_type='metrics',\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/cl/fedgc/client.py\n# --------------------------------------------------\n# \n#     def callback_funcs_for_pred_embedding(self, message: Message):\n#         round, sender, content = message.state, message.sender, message.content\n#         self.trainer.update(content)\n#         sample_size, model_para, results = self.trainer.train()\n#         self.state = round\n#         pred_embedding = self.trainer.get_train_pred_embedding()\n# \n#         train_log_res = self._monitor.format_eval_res(results,\n#                                                       rnd=self.state,\n#                                                       role='Client #{}'.format(\n#                                                           self.ID),\n#                                                       return_raw=True)\n#         logger.info(train_log_res)\n# \n#         self.comm_manager.send(\n#             Message(msg_type='pred_embedding',\n#                     sender=self.ID,\n#                     receiver=[sender],\n#                     state=self.state,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/server.py\n# --------------------------------------------------\n# \n#         self.trigger_for_start()\n# \n#     def callback_funcs_for_metrics(self, message: Message):\n#         \"\"\"\n#         The handling function for receiving the evaluation results, \\\n#         which triggers ``check_and_move_on`` (perform aggregation when \\\n#         enough feedback has been received).\n# \n#         Arguments:\n#             message: The received message\n#         \"\"\"\n# \n#         rnd = message.state\n#         sender = message.sender\n#         content = message.content\n# \n#         if rnd not in self.msg_buffer['eval'].keys():\n#             self.msg_buffer['eval'][rnd] = dict()\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/base_client.py\n# --------------------------------------------------\n# \n#         Arguments:\n#             message: The received message\n#         \"\"\"\n#         raise NotImplementedError\n# \n#     @abc.abstractmethod\n#     def callback_funcs_for_join_in_info(self, message):\n#         \"\"\"\n#         The handling function for receiving the request of join in \\\n#         information (such as ``batch_size``, ``num_of_samples``) during \\\n#         the joining process.\n# \n#         Arguments:\n#             message: The received message\n#         \"\"\"\n#         raise NotImplementedError\n# \n#     @abc.abstractmethod\n#     def callback_funcs_for_address(self, message):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/base_client.py\n# --------------------------------------------------\n#             message: The received message\n#         \"\"\"\n#         raise NotImplementedError\n# \n#     @abc.abstractmethod\n#     def callback_funcs_for_assign_id(self, message):\n#         \"\"\"\n#         The handling function for receiving the client_ID assigned by the \\\n#         server (during the joining process), which is used in the \\\n#         distributed mode.\n# \n#         Arguments:\n#             message: The received message\n#         \"\"\"\n#         raise NotImplementedError\n# \n#     @abc.abstractmethod\n#     def callback_funcs_for_join_in_info(self, message):\n#         \"\"\"\n#         The handling function for receiving the request of join in \\\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n self.msg_buffer['train'][state]\n                sample_size, first_aggregate_model_para = model_list[0]\n                single_model_case = True\n                if isinstance(first_aggregate_model_para, list):\n                    assert isinstance(first_aggregate_model_para[0], dict), \\\n                        \"aggregate_model_para should a list of multiple \" \\\n                        \"state_dict for multiple models\"\n                    single_model_case = False\n                else:\n                    assert isinstance(first_aggregate_model_para, dict), \\\n                        \"aggregate_model_para should \" \\\n                        \"a state_dict for single model case\"\n                    first_aggregate_model_para = [first_aggregate_model_para]\n                    model_list = [[model] for model in model_list]\n\n                for sub_model_idx, aggregate_single_model_para in enumerate(\n                        first_aggregate_model_para):\n                    for key in aggregate_single_model_para:\n                        for i in range(1, len(model_list)):\n                            aggregate_single_model_para[key] += model_list[i][\n                                sub_model_idx][key]\n\n                self.comm_manager.send(\n                    Message(msg_type='model_para',\n                            sender=self.ID,\n                            receiver=[self.server_id],\n                            state=self.state,\n                            timestamp=timestamp,\n                            content=(sample_size, first_aggregate_model_para[0]\n                                     if single_model_case else\n                                     first_aggregate_model_para)))\n\n        else:\n            round = message.state\n            sender = message.sender\n            timestamp = message.timestamp\n            content = message.content\n            # When clients share the local model, we must set strict=True to\n            # ensure all the model params (which might be updated by other\n            # clients in the previous local training process) are overwritten\n            # and synchronized with the received model\n            self.trainer.update(content,\n                                strict=self._cfg.federate.share_local_model)\n            self.state = round\n            skip_train_isolated_or_global_mode = \\\n                self.early_stopper.early_stopped and \\\n                self._cfg.federate.method in [\"local\", \"global\"]\n            if self.is_unseen_client or skip_train_isolated_or_global_mode:\n                # for these cases (1) unseen client (2) isolated_global_mode,\n                # we do not local train and upload local model\n                sample_size, model_para_all, results = \\\n                    0, self.trainer.get_model_para(), {}\n                if skip_train_isolated_or_global_mode:\n                    logger.info(\n                        f\"[Local/Global mode] Client #{self.ID} has been \"\n                        f\"early stopped, we will skip the local training\")\n                    self._monitor.local_converged()\n            else:\n                if self.early_stopper.early_stopped and \\\n                        self._monitor.local_convergence_round == 0:\n                    logger.info(\n                        f\"[Normal FL Mode] Client #{self.ID} has been locally \"\n                        f\"early stopped. \"\n                        f\"The next FL update may result in negative effect\")\n                    self._monitor.local_converged()\n                sample_size, model_para_all, results = self.trainer.train()\n                if self._cfg.federate.share_local_model and not \\\n                        self._cfg.federate.online_aggr:\n                    model_para_all = copy.deepcopy(model_para_all)\n                train_log_res = self._monitor.format_eval_res(\n                    results,\n                    rnd=self.state,\n                    role='Client #{}'.format(self.ID),\n                    return_raw=True)\n                logger.info(train_log_res)\n                if self._cfg.wandb.use and self._cfg.wandb.client_train_info:\n                    self._monitor.save_formatted_results(train_log_res,\n                                                         save_file_name=\"\")\n\n            # Return the feedbacks to the server after local update\n            if self._cfg.federate.use_ss:\n                assert not self.is_unseen_client, \\\n                    \"Un-support using secret sharing for unseen clients.\" \\\n                    \"i.e., you set cfg.federate.use_ss=True and \" \\\n                    \"cfg.federate.unseen_clients_rate in (0, 1)\"\n                single_model_case = True\n                if isinstance(model_para_all, list):\n                    assert isinstance(model_para_all[0], dict), \\\n                        \"model_para should a list of \" \\\n                        \"multiple state_dict for multiple models\"\n                    single_model_case = False\n                else:\n                    assert isinstance(model_para_all, dict), \\\n                        \"model_para should a state_dict for single model case\"\n                    model_para_all = [model_para_all]\n                model_para_list_all = []\n                for model_para in model_para_all:\n                    for key in model_para:\n                        model_para[key] = model_para[key] * sample_size\n                    model_para_list = self.ss_manager.secret_split(model_para)\n                    model_para_list_all.append(model_para_list)\n                    # print(model_para)\n                    # print(self.ss_manager.secret_reconstruct(\n                    # model_para_list))\n                frame_idx = 0\n                for neighbor in self.comm_manager.neighbors:\n                    if neighbor != self.server_id:\n                        content_frame = model_para_list_all[0][frame_idx] if \\\n                            single_model_case else \\\n                            [model_para_list[frame_idx] for model_para_list\n                             in model_para_list_all]\n                        self.comm_manager.send(\n                            Message(msg_type='ss_model_para',\n                                    sender=self.ID,\n                                    receiver=[neighbor],\n                                    state=self.state,\n                                    timestamp=self._gen_timestamp(\n                                        init_timestamp=timestamp,\n                                        instance_number=sample_size),\n                                    content=content_frame))\n                        frame_idx += 1\n                content_frame = model_para_list_all[0][frame_idx] if \\\n                    single_model_case else \\\n                    [model_para_list[frame_idx] for model_para_list in\n                     model_para_list_all]\n                self.msg_buffer['train'][self.state] = [(sample_size,\n                                                         content_frame)]\n            else:\n                if self._cfg.asyn.use:\n                    # Return the model delta when using asynchronous training\n                    # protocol, because the staled updated might be discounted\n                    # and cause that the sum of the aggregated weights might\n                    # not be equal to 1\n                    shared_model_para = self._calculate_model_delta(\n                        init_model=content, updated_model=model_para_all)\n                else:\n                    shared_model_para = model_para_all\n\n                self.comm_manager.send(\n                    Message(msg_type='model_para',\n                            sender=self.ID,\n                            receiver=[sender],\n                            state=self.state,\n                            timestamp=self._gen_timestamp(\n                                init_timestamp=timestamp,\n                                instance_number=sample_size),\n                            content=(sample_size, shared_model_para)))\n\n    def callback_funcs_for_assign_id(self, message: Message):\n        \"\"\"\n        The handling function for receiving the client_ID assigned by the \\\n        server (during the joining process), which is used in the \\\n        distributed mode.\n\n        Arguments:\n            message: The received message\n        \"\"\"", "choices": [{"text": "self.ID = message.content"}], "metadata": {"task_id": "alibaba_FederatedScope/146", "ground_truth": "        content = message.content", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "client.py"], "context_start_lineno": 231, "line_no": 388, "query_window": {"context": "\n                self.comm_manager.send(\n                    Message(msg_type='model_para',\n                            sender=self.ID,\n                            receiver=[sender],\n                            state=self.state,\n                            timestamp=self._gen_timestamp(\n                                init_timestamp=timestamp,\n                                instance_number=sample_size),\n                            content=(sample_size, shared_model_para)))\n\n    def callback_funcs_for_assign_id(self, message: Message):\n        \"\"\"\n        The handling function for receiving the client_ID assigned by the \\\n        server (during the joining process), which is used in the \\\n        distributed mode.\n\n        Arguments:\n            message: The received message\n        \"\"\"", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "client.py"], "line_no": 388, "task_id": "alibaba_FederatedScope/146", "start_line_no": 368, "end_line_no": 388, "window_size": 20, "context_start_lineno": 231, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "        raise NotImplementedError\n\n    @abc.abstractmethod\n    def callback_funcs_for_model_para(self, message):\n        \"\"\"\n        The handling function for receiving model parameters, \\\n        which triggers the local training process. \\\n        This handling function is widely used in various FL courses.\n\n        Arguments:\n            message: The received message\n        \"\"\"\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def callback_funcs_for_assign_id(self, message):\n        \"\"\"\n        The handling function for receiving the client_ID assigned by the \\\n        server (during the joining process), which is used in the \\\n        distributed mode.", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "base_client.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4766355140186916}, {"context": "            message: The received message\n        \"\"\"\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def callback_funcs_for_assign_id(self, message):\n        \"\"\"\n        The handling function for receiving the client_ID assigned by the \\\n        server (during the joining process), which is used in the \\\n        distributed mode.\n\n        Arguments:\n            message: The received message\n        \"\"\"\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def callback_funcs_for_join_in_info(self, message):\n        \"\"\"\n        The handling function for receiving the request of join in \\", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "base_client.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.46601941747572817}, {"context": "                                                address=address)\n\n            if len(self._cfg.federate.join_in_info) != 0:\n                self.comm_manager.send(\n                    Message(msg_type='ask_for_join_in_info',\n                            sender=self.ID,\n                            receiver=[sender],\n                            state=self.state,\n                            timestamp=self.cur_timestamp,\n                            content=self._cfg.federate.join_in_info.copy()))\n\n        self.trigger_for_start()\n\n    def callback_funcs_for_metrics(self, message: Message):\n        \"\"\"\n        The handling function for receiving the evaluation results, \\\n        which triggers ``check_and_move_on`` (perform aggregation when \\\n        enough feedback has been received).\n\n        Arguments:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "server.py"], "line_no": 980, "start_line_no": 970, "end_line_no": 990, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4566929133858268}, {"context": "        self.state = round\n        sample_size = self.trainer.num_samples\n        model_para = self.trainer.get_model_para()\n\n        self.comm_manager.send(\n            Message(msg_type='model_para',\n                    sender=self.ID,\n                    receiver=[sender],\n                    state=self.state,\n                    content=(sample_size, model_para)))\n\n    def callback_funcs_for_pred_embedding(self, message: Message):\n        round, sender, content = message.state, message.sender, message.content\n        self.trainer.update(content)\n        sample_size, model_para, results = self.trainer.train()\n        self.state = round\n        pred_embedding = self.trainer.get_train_pred_embedding()\n\n        train_log_res = self._monitor.format_eval_res(results,\n                                                      rnd=self.state,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "cl", "fedgc", "client.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.41739130434782606}, {"context": "        results['client_id'] = self.ID - 1\n        content = (sample_size, model_para_all, results)\n        self.comm_manager.send(\n            Message(msg_type='model_para',\n                    sender=self.ID,\n                    receiver=[sender],\n                    state=self.state,\n                    content=content))\n\n    def callback_funcs_for_evaluate(self, message: Message):\n        sender = message.sender\n        self.state = message.state\n        if message.content is not None:\n            model_params = message.content[\"model_param\"]\n            self.trainer.update(model_params)\n        if self._cfg.finetune.before_eval:\n            self.trainer.finetune()\n        metrics = {}\n        for split in self._cfg.eval.split:\n            eval_metrics = self.trainer.evaluate(target_data_split_name=split)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "autotune", "fedex", "client.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3968253968253968}, {"context": "                    if key not in content:\n                        content[key] = value\n                    else:\n                        for sub_key in content[key].keys():\n                            content[key][sub_key] += content_frame[key][\n                                sub_key]\n\n            self.comm_manager.send(\n                Message(msg_type='ss_instance_sum',\n                        sender=self.ID,\n                        receiver=[self.server_id],\n                        content=content))\n\n    def callback_func_for_instance_mean(self, message: Message):\n        \"\"\"\n        The handling function for calculate instance_norm after receiving \\\n        var and mean.\n        \"\"\"\n        sender = message.sender\n        feat_mean = message.content", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "preprocess", "instance_norm.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3949579831932773}, {"context": "        sample_size, clf_para, results = self.trainer_clf.train()\n        self.state = round\n        logger.info(\n            self._monitor.format_eval_res(results,\n                                          rnd=self.state,\n                                          role='Client #{}'.format(self.ID)))\n        self.comm_manager.send(\n            Message(msg_type='clf_para',\n                    sender=self.ID,\n                    receiver=[sender],\n                    state=self.state,\n                    content=(sample_size, clf_para)))\n\n    def callback_funcs_for_model_para(self, message: Message):\n        round, sender, content = message.state, message.sender, message.content\n        self.trainer_clf.update(content)\n        self.state = round\n        sample_size, clf_para, results = self.trainer_clf.train()\n        if self._cfg.federate.share_local_model and not \\\n                self._cfg.federate.online_aggr:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "gfl", "fedsageplus", "worker.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3937007874015748}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/tests/test_data_helper.py\n# --------------------------------------------------\n#         model.cuda()\n#         timer = EasyTimer()\n#         dataloader = iter(self.get_dataloader())\n#         dataloader = CudaFetcher(dataloader, device='cuda', sleep=0.1)\n#         dataloader.run()\n# \n#         count = 0\n#         while True:\n#             with timer:\n#                 data = next(dataloader)\n#                 model(data)\n#             print('count {}, run_time: {}'.format(count, timer.value))\n#             count += 1\n#             if count == 10:\n#                 break\n# \n#         dataloader.close()\n# \n# \n# @pytest.mark.cudatest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/tests/test_data_helper.py\n# --------------------------------------------------\n#                 model(data)\n#             print('count {}, run_time: {}'.format(count, timer.value))\n#             count += 1\n#             if count == 10:\n#                 break\n# \n#         dataloader.close()\n# \n# \n# @pytest.mark.cudatest\n# def test_to_device_cuda(setup_data_dict):\n#     setup_data_dict['module'] = nn.Linear(3, 5)\n#     device = 'cuda'\n#     cuda_d = to_device(setup_data_dict, device, ignore_keys=['module'])\n#     assert cuda_d['module'].weight.device == torch.device('cpu')\n#     other = EasyTimer()\n#     with pytest.raises(TypeError):\n#         to_device(other)\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/learner/base_learner.py\n# --------------------------------------------------\n#         batch_size = self._policy.get_attribute('batch_size')\n#         device = self._policy.get_attribute('device')\n#         chunk_size = cfg.chunk_size if 'chunk_size' in cfg else batch_size\n#         self._dataloader = AsyncDataLoader(\n#             self.get_data, batch_size, device, chunk_size, collate_fn=lambda x: x, num_workers=cfg.num_workers\n#         )\n#         self._next_data = self._time_wrapper(self._next_data, 'scalar', 'data_time')\n# \n#     def _next_data(self) -> Any:\n#         \"\"\"\n#         Overview:\n#             [Only Used In Parallel Mode] Call ``_dataloader``'s ``__next__`` method to return next training data.\n#         Returns:\n#             - data (:obj:`Any`): Next training data from dataloader.\n#         \"\"\"\n#         return next(self._dataloader)\n# \n#     def close(self) -> None:\n#         \"\"\"\n#         Overview:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/learner/base_learner.py\n# --------------------------------------------------\n#         Overview:\n#             [Only Used In Parallel Mode] Call ``_dataloader``'s ``__next__`` method to return next training data.\n#         Returns:\n#             - data (:obj:`Any`): Next training data from dataloader.\n#         \"\"\"\n#         return next(self._dataloader)\n# \n#     def close(self) -> None:\n#         \"\"\"\n#         Overview:\n#             [Only Used In Parallel Mode] Close the related resources, e.g. dataloader, tensorboard logger, etc.\n#         \"\"\"\n#         if self._end_flag:\n#             return\n#         self._end_flag = True\n#         if hasattr(self, '_dataloader'):\n#             self._dataloader.close()\n#         if self._tb_logger:\n#             self._tb_logger.flush()\n#             self._tb_logger.close()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/data/tests/test_dataloader.py\n# --------------------------------------------------\n#                 total_data_time += data_time\n#             with timer:\n#                 with torch.no_grad():\n#                     _, idx = model(data)\n#                 if use_cuda:\n#                     idx = idx.cpu()\n#                 sorted_idx = torch.sort(idx)[0]\n#                 assert sorted_idx.eq(torch.arange(batch_size)).sum() == batch_size, idx\n#             model_time = timer.value\n#             print('count {}, data_time: {}, model_time: {}'.format(count, data_time, model_time))\n#             count += 1\n#             if count == 10:\n#                 break\n#         if num_workers < 1:\n#             assert total_data_time <= 7 * batch_size * 0.5 + 7 * 0.01 - 7 * 1\n#         else:\n#             assert total_data_time <= 7 * 0.008\n#         dataloader.__del__()\n#         time.sleep(0.5)\n#         assert len(threading.enumerate()) <= 2, threading.enumerate()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/data/tests/test_dataloader.py\n# --------------------------------------------------\n#         model = self.get_model()\n#         if use_cuda:\n#             model.cuda()\n#         timer = EasyTimer()\n#         data_source = self.get_data_source()\n#         device = 'cuda' if use_cuda else 'cpu'\n#         dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n#         count = 0\n#         total_data_time = 0.\n#         while True:\n#             with timer:\n#                 data = next(dataloader)\n#             data_time = timer.value\n#             if count > 2:  # ignore start-3 time\n#                 total_data_time += data_time\n#             with timer:\n#                 with torch.no_grad():\n#                     _, idx = model(data)\n#                 if use_cuda:\n#                     idx = idx.cpu()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/data/tests/test_dataloader.py\n# --------------------------------------------------\n#             with timer:\n#                 data = next(dataloader)\n#             data_time = timer.value\n#             if count > 2:  # ignore start-3 time\n#                 total_data_time += data_time\n#             with timer:\n#                 with torch.no_grad():\n#                     _, idx = model(data)\n#                 if use_cuda:\n#                     idx = idx.cpu()\n#                 sorted_idx = torch.sort(idx)[0]\n#                 assert sorted_idx.eq(torch.arange(batch_size)).sum() == batch_size, idx\n#             model_time = timer.value\n#             print('count {}, data_time: {}, model_time: {}'.format(count, data_time, model_time))\n#             count += 1\n#             if count == 10:\n#                 break\n#         if num_workers < 1:\n#             assert total_data_time <= 7 * batch_size * 0.5 + 7 * 0.01 - 7 * 1\n#         else:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport time\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom functools import partial\nfrom itertools import product\nimport os.path as osp\nimport os\nimport random\n\nfrom ding.utils import EasyTimer, read_file\nfrom ding.utils.data import AsyncDataLoader\n\nexp_times = 10\nmax_iter = 50\nnum_workers = 8\nuse_cuda = True\n\n# read_file_time, process_time, batch_size, chunk_size, env_name\nenv_args = [\n    (0.0008, 0.005, 128, 32, \"small\"),\n    (0.0008, 0.05, 64, 16, \"middle\"),\n    (0.6, 0.2, 4, 1, \"big16\"),\n    (2, 0.25, 4, 1, \"big64\"),\n]\ndata_infer_ratio_args = [1, 2, 4]\n\nargs = [item for item in product(*[env_args, data_infer_ratio_args])]\n\nout_str_list = []\n\n\nclass MyDataset(Dataset):\n\n    def __init__(self, file_time, process_time, batch_size, name):\n        self.data = torch.randn(256, 256)\n        self.file_time = file_time\n        self.process_time = process_time\n        self.batch_size = batch_size\n        self.path = osp.join(osp.dirname(__file__), \"../traj_files/{}/data\".format(name))\n        self.file_list = os.listdir(self.path)\n        self.file_sequence = random.sample(range(0, len(self.file_list)), len(self.file_list))\n        self.i = 0\n\n    def __len__(self):\n        return self.batch_size * max_iter * 2\n\n    def __getitem__(self, idx):\n        try:\n            s = read_file(osp.join(self.path, self.file_list[self.file_sequence[self.i]]))\n        except:\n            print(\"file read meets an error\")\n            time.sleep(self.file_time)\n        self.i = (self.i + 1) % len(self.file_list)\n        time.sleep(self.process_time)\n        return [self.data, idx]\n\n\nclass MyModel(nn.Module):\n\n    def __init__(self, infer_time):\n        super().__init__()\n        self.main = [nn.Linear(256, 256) for _ in range(10)]\n        self.main = nn.Sequential(*self.main)\n        self.infer_time = infer_time\n\n    def forward(self, x):\n        idx = x[1]\n        # No real infer here.\n        time.sleep(self.infer_time)\n        return [x, idx]\n\n\ndef get_data_source(dataset):\n\n    def data_source_fn(batch_size):\n        return [partial(dataset.__getitem__, idx=i) for i in range(batch_size)]\n\n    return data_source_fn\n\n\ndef entry(env, read_infer_ratio, use_cuda):\n    file_time, process_time, batch_size, chunk_size, data_name = env[0], env[1], env[2], env[3], env[4]\n    data_time = file_time + process_time\n    infer_time = data_time * (batch_size / num_workers) * 1.05 / read_infer_ratio\n    out_str = '\\n===== each_data: {:.4f}({}), infer: {:.4f}, read/infer: {:.4f}, \\\n        batch_size: {}, chunk_size: {} ====='.format(\n        data_time, data_name, infer_time, read_infer_ratio, batch_size, chunk_size\n    )\n    out_str_list.append(out_str)\n    print(out_str)\n\n    model = MyModel(infer_time)\n    if use_cuda:\n        model.cuda()\n    timer = EasyTimer()\n\n    # ### Our DataLoader ####\n    total_sum_time_list = []\n    total_data_time_list = []\n    total_infer_time_list = []\n    for _ in range(exp_times):\n        print('\\t----- Our DataLoader -----')\n        dataset = MyDataset(file_time, process_time, batch_size, data_name)\n        data_source = get_data_source(dataset)\n        device = 'cuda' if use_cuda else 'cpu'\n        our_dataloader = AsyncDataLoader(\n            data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size\n        )\n        iter = 0\n        total_data_time = 0.\n        total_infer_time = 0.\n        total_sum_time = 0.\n        while True:\n            with timer:\n                data = next(our_dataloader)\n            data_time = timer.value\n            with timer:\n                with torch.no_grad():", "choices": [{"text": "_, idx = model(data)"}], "metadata": {"task_id": "opendilab_ACE/184", "ground_truth": "                    _, idx = model(data)", "fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "tests", "dataloader_speed", "experiment_dataloader_speed.py"], "context_start_lineno": 0, "line_no": 119, "query_window": {"context": "    total_data_time_list = []\n    total_infer_time_list = []\n    for _ in range(exp_times):\n        print('\\t----- Our DataLoader -----')\n        dataset = MyDataset(file_time, process_time, batch_size, data_name)\n        data_source = get_data_source(dataset)\n        device = 'cuda' if use_cuda else 'cpu'\n        our_dataloader = AsyncDataLoader(\n            data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size\n        )\n        iter = 0\n        total_data_time = 0.\n        total_infer_time = 0.\n        total_sum_time = 0.\n        while True:\n            with timer:\n                data = next(our_dataloader)\n            data_time = timer.value\n            with timer:\n                with torch.no_grad():", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "tests", "dataloader_speed", "experiment_dataloader_speed.py"], "line_no": 119, "task_id": "opendilab_ACE/184", "start_line_no": 99, "end_line_no": 119, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "        model = self.get_model()\n        if use_cuda:\n            model.cuda()\n        timer = EasyTimer()\n        data_source = self.get_data_source()\n        device = 'cuda' if use_cuda else 'cpu'\n        dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n        count = 0\n        total_data_time = 0.\n        while True:\n            with timer:\n                data = next(dataloader)\n            data_time = timer.value\n            if count > 2:  # ignore start-3 time\n                total_data_time += data_time\n            with timer:\n                with torch.no_grad():\n                    _, idx = model(data)\n                if use_cuda:\n                    idx = idx.cpu()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "tests", "test_dataloader.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.48214285714285715}, {"context": "    def test_cpu(self, batch_size, num_workers, chunk_size):\n        self.entry(batch_size, num_workers, chunk_size, use_cuda=False)\n\n    @pytest.mark.cudatest\n    @pytest.mark.parametrize('batch_size, num_workers, chunk_size', args)\n    def test_gpu(self, batch_size, num_workers, chunk_size):\n        self.entry(batch_size, num_workers, chunk_size, use_cuda=True)\n        torch.cuda.empty_cache()\n\n    def entry(self, batch_size, num_workers, chunk_size, use_cuda):\n        model = self.get_model()\n        if use_cuda:\n            model.cuda()\n        timer = EasyTimer()\n        data_source = self.get_data_source()\n        device = 'cuda' if use_cuda else 'cpu'\n        dataloader = AsyncDataLoader(data_source, batch_size, device, num_workers=num_workers, chunk_size=chunk_size)\n        count = 0\n        total_data_time = 0.\n        while True:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "tests", "test_dataloader.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3902439024390244}, {"context": "            with timer:\n                data = next(dataloader)\n            data_time = timer.value\n            if count > 2:  # ignore start-3 time\n                total_data_time += data_time\n            with timer:\n                with torch.no_grad():\n                    _, idx = model(data)\n                if use_cuda:\n                    idx = idx.cpu()\n                sorted_idx = torch.sort(idx)[0]\n                assert sorted_idx.eq(torch.arange(batch_size)).sum() == batch_size, idx\n            model_time = timer.value\n            print('count {}, data_time: {}, model_time: {}'.format(count, data_time, model_time))\n            count += 1\n            if count == 10:\n                break\n        if num_workers < 1:\n            assert total_data_time <= 7 * batch_size * 0.5 + 7 * 0.01 - 7 * 1\n        else:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "tests", "test_dataloader.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.31386861313868614}, {"context": "        batch_size = self._policy.get_attribute('batch_size')\n        device = self._policy.get_attribute('device')\n        chunk_size = cfg.chunk_size if 'chunk_size' in cfg else batch_size\n        self._dataloader = AsyncDataLoader(\n            self.get_data, batch_size, device, chunk_size, collate_fn=lambda x: x, num_workers=cfg.num_workers\n        )\n        self._next_data = self._time_wrapper(self._next_data, 'scalar', 'data_time')\n\n    def _next_data(self) -> Any:\n        \"\"\"\n        Overview:\n            [Only Used In Parallel Mode] Call ``_dataloader``'s ``__next__`` method to return next training data.\n        Returns:\n            - data (:obj:`Any`): Next training data from dataloader.\n        \"\"\"\n        return next(self._dataloader)\n\n    def close(self) -> None:\n        \"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "learner", "base_learner.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2986111111111111}, {"context": "\n        .. note::\n\n            Only in parallel mode will we use attributes ``get_data`` and ``_dataloader`` to get data from file system;\n            Instead, in serial version, we can fetch data from memory directly.\n\n            In parallel mode, ``get_data`` is set by ``LearnerCommHelper``, and should be callable.\n            Users don't need to know the related details if not necessary.\n        \"\"\"\n        cfg = self._cfg.dataloader\n        batch_size = self._policy.get_attribute('batch_size')\n        device = self._policy.get_attribute('device')\n        chunk_size = cfg.chunk_size if 'chunk_size' in cfg else batch_size\n        self._dataloader = AsyncDataLoader(\n            self.get_data, batch_size, device, chunk_size, collate_fn=lambda x: x, num_workers=cfg.num_workers\n        )\n        self._next_data = self._time_wrapper(self._next_data, 'scalar', 'data_time')\n\n    def _next_data(self) -> Any:\n        \"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "learner", "base_learner.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2654320987654321}, {"context": "        model.cuda()\n        timer = EasyTimer()\n        dataloader = iter(self.get_dataloader())\n        dataloader = CudaFetcher(dataloader, device='cuda', sleep=0.1)\n        dataloader.run()\n\n        count = 0\n        while True:\n            with timer:\n                data = next(dataloader)\n                model(data)\n            print('count {}, run_time: {}'.format(count, timer.value))\n            count += 1\n            if count == 10:\n                break\n\n        dataloader.close()\n\n\n@pytest.mark.cudatest", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "tests", "test_data_helper.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.26153846153846155}, {"context": "                self.main = nn.Sequential(*self.main)\n\n            def forward(self, x):\n                x = self.main(x)\n                return x\n\n        return Model()\n\n    def test_naive(self):\n        model = self.get_model()\n        model.cuda()\n        timer = EasyTimer()\n        dataloader = iter(self.get_dataloader())\n        dataloader = CudaFetcher(dataloader, device='cuda', sleep=0.1)\n        dataloader.run()\n\n        count = 0\n        while True:\n            with timer:\n                data = next(dataloader)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "tests", "test_data_helper.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.23809523809523808}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/d4pg.py\n# --------------------------------------------------\n#             Arguments:\n#                 - traj (:obj:`list`): The trajectory's buffer list\n#             Returns:\n#                 - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         data = get_nstep_return_data(traj, self._nstep, gamma=self._gamma)\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n#         return 'qac_dist', ['ding.model.template.qac_dist']\n# \n#     def _monitor_vars_learn(self) -> List[str]:\n#         r\"\"\"\n#         Overview:\n#             Return variables' name if variables are to used in monitor.\n#         Returns:\n#             - vars (:obj:`List[str]`): Variables' name list.\n#         \"\"\"\n#         ret = ['cur_lr_actor', 'cur_lr_critic', 'critic_loss', 'actor_loss', 'total_loss', 'q_value', 'action']\n#         return ret\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/rainbow.py\n# --------------------------------------------------\n#         Returns:\n#             - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         data = get_nstep_return_data(traj, self._nstep, gamma=self._gamma)\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n#         return 'rainbowdqn', ['ding.model.template.q_learning']\n# \n#     def _reset_noise(self, model: torch.nn.Module):\n#         r\"\"\"\n#         Overview:\n#             Reset the noise of model\n# \n#         Arguments:\n#             - model (:obj:`torch.nn.Module`): the model to reset, must contain reset_noise method\n#         \"\"\"\n#         for m in model.modules():\n#             if hasattr(m, 'reset_noise'):\n#                 m.reset_noise()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/iqn.py\n# --------------------------------------------------\n#             output = self._collect_model.forward(data, eps=eps)\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n#         r\"\"\"\n#         Overview:\n#             Get the trajectory and the n step return data, then sample from the n_step return data\n#         Arguments:\n#             - data (:obj:`list`): The trajectory's cache\n#         Returns:\n#             - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n#         return 'iqn', ['ding.model.template.q_learning']\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/collaq.py\n# --------------------------------------------------\n#     def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n#         r\"\"\"\n#         Overview:\n#             Get the train sample from trajectory.\n#         Arguments:\n#             - data (:obj:`list`): The trajectory's cache\n#         Returns:\n#             - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n#         \"\"\"\n#         Overview:\n#             Return this algorithm default model setting for demonstration.\n#         Returns:\n#             - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names\n#         .. note::\n#             The user can define and use customized network model but must obey the same inferface definition indicated \\\n#             by import_names path. For collaq, ``ding.model.qmix.qmix``\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/collaq.py\n# --------------------------------------------------\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n#         \"\"\"\n#         Overview:\n#             Return this algorithm default model setting for demonstration.\n#         Returns:\n#             - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names\n#         .. note::\n#             The user can define and use customized network model but must obey the same inferface definition indicated \\\n#             by import_names path. For collaq, ``ding.model.qmix.qmix``\n#         \"\"\"\n#         return 'collaq', ['ding.model.template.qmix']\n# \n#     def _monitor_vars_learn(self) -> List[str]:\n#         r\"\"\"\n#         Overview:\n#             Return variables' name if variables are to used in monitor.\n#         Returns:\n#             - vars (:obj:`List[str]`): Variables' name list.\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/coma.py\n# --------------------------------------------------\n#             - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n#         \"\"\"\n#         Overview:\n#             Return this algorithm default model setting for demonstration.\n#         Returns:\n#             - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names\n#         .. note::\n#             The user can define and use customized network model but must obey the same inferface definition indicated \\\n#             by import_names path. For coma, ``ding.model.coma.coma``\n#         \"\"\"\n#         return 'coma', ['ding.model.template.coma']\n# \n#     def _monitor_vars_learn(self) -> List[str]:\n#         r\"\"\"\n#         Overview:\n#             Return variables' name if variables are to used in monitor.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/qmix.py\n# --------------------------------------------------\n#             - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n#         \"\"\"\n#         Overview:\n#             Return this algorithm default model setting for demonstration.\n#         Returns:\n#             - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names\n#         .. note::\n#             The user can define and use customized network model but must obey the same inferface definition indicated \\\n#             by import_names path. For QMIX, ``ding.model.qmix.qmix``\n#         \"\"\"\n#         return 'qmix', ['ding.model.template.qmix']\n# \n#     def _monitor_vars_learn(self) -> List[str]:\n#         r\"\"\"\n#         Overview:\n#             Return variables' name if variables are to used in monitor.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nOptional[List[int]]`): The id that store the state and we will reset\\\n                the model state to the state indicated by data_id\n        \"\"\"\n        self._learn_model.reset(data_id=data_id)\n\n    def _state_dict_learn(self) -> Dict[str, Any]:\n        r\"\"\"\n        Overview:\n            Return the state_dict of learn mode, usually including model and optimizer.\n        Returns:\n            - state_dict (:obj:`Dict[str, Any]`): the dict of current policy learn state, for saving and restoring.\n        \"\"\"\n        return {\n            'model': self._learn_model.state_dict(),\n            'optimizer': self._optimizer.state_dict(),\n        }\n\n    def _load_state_dict_learn(self, state_dict: Dict[str, Any]) -> None:\n        r\"\"\"\n        Overview:\n            Load the state_dict variable into policy learn mode.\n        Arguments:\n            - state_dict (:obj:`Dict[str, Any]`): the dict of policy learn state saved before.\n        .. tip::\n            If you want to only load some parts of model, you can simply set the ``strict`` argument in \\\n            load_state_dict to ``False``, or refer to ``ding.torch_utils.checkpoint_helper`` for more \\\n            complicated operation.\n        \"\"\"\n        self._learn_model.load_state_dict(state_dict['model'])\n        self._optimizer.load_state_dict(state_dict['optimizer'])\n\n    def _init_collect(self) -> None:\n        r\"\"\"\n        Overview:\n            Collect mode init method. Called by ``self.__init__``.\n            Init traj and unroll length, collect model.\n            Enable the eps_greedy_sample and the hidden_state plugin.\n        \"\"\"\n        self._unroll_len = self._cfg.collect.unroll_len\n        self._collect_model = model_wrap(\n            self._model,\n            wrapper_name='hidden_state',\n            state_num=self._cfg.collect.env_num,\n            save_prev_state=True,\n            init_fn=lambda: [None for _ in range(self._cfg.model.agent_num)]\n        )\n        self._collect_model = model_wrap(self._collect_model, wrapper_name='eps_greedy_sample')\n        self._collect_model.reset()\n\n    def _forward_collect(self, data: dict, eps: float) -> dict:\n        r\"\"\"\n        Overview:\n            Forward function for collect mode with eps_greedy\n        Arguments:\n            - data (:obj:`dict`): Dict type data, including at least ['obs'].\n            - eps (:obj:`float`): epsilon value for exploration, which is decayed by collected env step.\n        Returns:\n            - data (:obj:`dict`): The collected data\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        data = {'obs': data}\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps, data_id=data_id)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _reset_collect(self, data_id: Optional[List[int]] = None) -> None:\n        r\"\"\"\n        Overview:\n            Reset collect model to the state indicated by data_id\n        Arguments:\n            - data_id (:obj:`Optional[List[int]]`): The id that store the state and we will reset\\\n                the model state to the state indicated by data_id\n        \"\"\"\n        self._collect_model.reset(data_id=data_id)\n\n    def _process_transition(self, obs: Any, model_output: dict, timestep: namedtuple) -> dict:\n        r\"\"\"\n        Overview:\n            Generate dict type transition data from inputs.\n        Arguments:\n            - obs (:obj:`Any`): Env observation\n            - model_output (:obj:`dict`): Output of collect model, including at least ['action', 'prev_state']\n            - timestep (:obj:`namedtuple`): Output after env step, including at least ['obs', 'reward', 'done']\\\n                (here 'obs' indicates obs after env step).\n        Returns:\n            - transition (:obj:`dict`): Dict type transition data, including 'obs', 'next_obs', 'prev_state',\\\n                'action', 'reward', 'done'\n        \"\"\"\n        transition = {\n            'obs': obs,\n            'next_obs': timestep.obs,\n            'prev_state': model_output['prev_state'],\n            'action': model_output['action'],\n            'reward': timestep.reward,\n            'done': timestep.done,\n        }\n        return transition\n\n    def _init_eval(self) -> None:\n        r\"\"\"\n        Overview:\n            Evaluate mode init method. Called by ``self.__init__``.\n            Init eval model with argmax strategy and the hidden_state plugin.\n        \"\"\"\n        self._eval_model = model_wrap(\n            self._model,\n            wrapper_name='hidden_state',\n            state_num=self._cfg.eval.env_num,\n            save_prev_state=True,\n            init_fn=lambda: [None for _ in range(self._cfg.model.agent_num)]\n        )\n        self._eval_model = model_wrap(self._eval_model, wrapper_name='argmax_sample')\n        self._eval_model.reset()\n\n    def _forward_eval(self, data: dict) -> dict:\n        r\"\"\"\n        Overview:\n            Forward function for evaluation mode, similar to ``self._forward_collect``.\n        Arguments:\n            - data (:obj:`dict`): Dict type data, including at least ['obs'].\n        Returns:\n            - output (:obj:`dict`): Dict type data, including at least inferred action according to input obs.\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        data = {'obs': data}\n        self._eval_model.eval()\n        with torch.no_grad():\n            output = self._eval_model.forward(data, data_id=data_id)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _reset_eval(self, data_id: Optional[List[int]] = None) -> None:\n        r\"\"\"\n        Overview:\n            Reset eval model to the state indicated by data_id\n        Arguments:\n            - data_id (:obj:`Optional[List[int]]`): The id that store the state and we will reset\\\n                the model state to the state indicated by data_id\n        \"\"\"\n        self._eval_model.reset(data_id=data_id)\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:\n            Get the train sample from trajectory.\n        Arguments:\n            - data (:obj:`list`): The trajectory's cache\n        Returns:\n            - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        \"\"\"\n        Overview:\n            Return this algorithm default model setting for demonstration.\n        Returns:\n            - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names\n        .. note::", "choices": [{"text": "The above code completes the implementation of a reinforcement learning policy class. It includes methods for training, collecting data, and evaluating the model. The code also includes functions for resetting the model state, processing transitions, and generating training samples. The implementation supports different types of models, including D4PG, Rainbow DQN, IQN, CollaQ, COMA, and QMIX."}], "metadata": {"task_id": "opendilab_ACE/18", "ground_truth": "            The user can define and use customized network model but must obey the same inferface definition indicated \\", "fpath_tuple": ["opendilab_ACE", "ding", "policy", "qtran.py"], "context_start_lineno": 271, "line_no": 442, "query_window": {"context": "        self._eval_model.reset(data_id=data_id)\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:\n            Get the train sample from trajectory.\n        Arguments:\n            - data (:obj:`list`): The trajectory's cache\n        Returns:\n            - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        \"\"\"\n        Overview:\n            Return this algorithm default model setting for demonstration.\n        Returns:\n            - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names\n        .. note::", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "qtran.py"], "line_no": 442, "task_id": "opendilab_ACE/18", "start_line_no": 422, "end_line_no": 442, "window_size": 20, "context_start_lineno": 271, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "        \"\"\"\n        self._eval_model.reset(data_id=data_id)\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:\n            Get the train sample from trajectory.\n        Arguments:\n            - data (:obj:`list`): The trajectory's cache\n        Returns:\n            - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        \"\"\"\n        Overview:\n            Return this algorithm default model setting for demonstration.\n        Returns:\n            - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "qmix.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.9659090909090909}, {"context": "\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:\n            Get the train sample from trajectory\n\n        Arguments:\n            - data (:obj:`list`): The trajectory's cache\n\n        Returns:\n            - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        \"\"\"\n        Overview:\n            Return this algorithm default model setting for demonstration.\n        Returns:\n            - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "coma.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.9204545454545454}, {"context": "    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:\n            Get the train sample from trajectory.\n        Arguments:\n            - data (:obj:`list`): The trajectory's cache\n        Returns:\n            - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        \"\"\"\n        Overview:\n            Return this algorithm default model setting for demonstration.\n        Returns:\n            - model_info (:obj:`Tuple[str, List[str]]`): model name and mode import_names\n        .. note::\n            The user can define and use customized network model but must obey the same inferface definition indicated \\\n            by import_names path. For collaq, ``ding.model.qmix.qmix``", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "collaq.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.7433628318584071}, {"context": "    def _reset_eval(self, data_id: Optional[List[int]] = None) -> None:\n        r\"\"\"\n        Overview:\n            Reset eval model to the state indicated by data_id\n        Arguments:\n            - data_id (:obj:`Optional[List[int]]`): The id that store the state and we will reset\\\n                the model state to the state indicated by data_id\n        \"\"\"\n        self._eval_model.reset(data_id=data_id)\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:\n            Get the train sample from trajectory.\n        Arguments:\n            - data (:obj:`list`): The trajectory's cache\n        Returns:\n            - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        return get_train_sample(data, self._unroll_len)", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "collaq.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6388888888888888}, {"context": "    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:\n            Get the trajectory and the n step return data, then sample from the n_step return data\n        Arguments:\n            - data (:obj:`list`): The trajectory's cache\n        Returns:\n            - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        return 'iqn', ['ding.model.template.q_learning']", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "iqn.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 244, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6261682242990654}, {"context": "        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, traj: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:\n            Get the trajectory and the n step return data, then sample from the n_step return data\n\n        Arguments:\n            - traj (:obj:`list`): The trajactory's buffer list\n\n        Returns:\n            - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        data = get_nstep_return_data(traj, self._nstep, gamma=self._gamma)\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        return 'rainbowdqn', ['ding.model.template.q_learning']\n\n    def _reset_noise(self, model: torch.nn.Module):", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "rainbow.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5511811023622047}, {"context": "            **loss_dict,\n            **q_value_dict,\n        }\n\n    def _get_train_sample(self, traj: list) -> Union[None, List[Any]]:\n        r\"\"\"\n            Overview:\n                Get the trajectory and the n step return data, then sample from the n_step return data\n            Arguments:\n                - traj (:obj:`list`): The trajectory's buffer list\n            Returns:\n                - samples (:obj:`dict`): The training samples generated\n        \"\"\"\n        data = get_nstep_return_data(traj, self._nstep, gamma=self._gamma)\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        return 'qac_dist', ['ding.model.template.qac_dist']\n\n    def _monitor_vars_learn(self) -> List[str]:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "d4pg.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.55}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_modules.py\n# --------------------------------------------------\n# \n#         state = torch.randn(*batch_size, temporal_size, deter_size, device=device)\n#         belief = torch.randn(*batch_size, temporal_size, stoch_size, device=device)\n#         action = torch.randn(*batch_size, temporal_size, action_size, device=device)\n#         obs_emb = torch.randn(*batch_size, temporal_size, 1024, device=device)\n# \n#         tensordict = TensorDict(\n#             {\n#                 \"state\": state.clone(),\n#                 \"action\": action.clone(),\n#                 \"next\": {\n#                     \"encoded_latents\": obs_emb.clone(),\n#                     \"belief\": belief.clone(),\n#                 },\n#             },\n#             device=device,\n#             batch_size=torch.Size([*batch_size, temporal_size]),\n#         )\n#         ## Init of lazy linears\n#         _ = rssm_rollout(tensordict.clone())\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_modules.py\n# --------------------------------------------------\n#             SafeModule(\n#                 rssm_prior,\n#                 in_keys=[\"state\", \"belief\", \"action\"],\n#                 out_keys=[\n#                     (\"next\", \"prior_mean\"),\n#                     (\"next\", \"prior_std\"),\n#                     \"_\",\n#                     (\"next\", \"belief\"),\n#                 ],\n#             ),\n#             SafeModule(\n#                 rssm_posterior,\n#                 in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n#                 out_keys=[\n#                     (\"next\", \"posterior_mean\"),\n#                     (\"next\", \"posterior_std\"),\n#                     (\"next\", \"state\"),\n#                 ],\n#             ),\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#         # World Model and reward model\n#         rssm_rollout = RSSMRollout(\n#             SafeModule(\n#                 rssm_prior,\n#                 in_keys=[\"state\", \"belief\", \"action\"],\n#                 out_keys=[\n#                     (\"next\", \"prior_mean\"),\n#                     (\"next\", \"prior_std\"),\n#                     \"_\",\n#                     (\"next\", \"belief\"),\n#                 ],\n#             ),\n#             SafeModule(\n#                 rssm_posterior,\n#                 in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n#                 out_keys=[\n#                     (\"next\", \"posterior_mean\"),\n#                     (\"next\", \"posterior_std\"),\n#                     (\"next\", \"state\"),\n#                 ],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                     \"state\",\n#                     \"belief\",\n#                 ],\n#             ),\n#         )\n#         reward_model = SafeModule(\n#             reward_module,\n#             in_keys=[\"state\", \"belief\"],\n#             out_keys=[\"reward\"],\n#         )\n#         model_based_env = DreamerEnv(\n#             world_model=WorldModelWrapper(\n#                 transition_model,\n#                 reward_model,\n#             ),\n#             prior_shape=torch.Size([state_dim]),\n#             belief_shape=torch.Size([rssm_hidden_dim]),\n#         )\n#         model_based_env.set_specs_from_env(mock_env)\n#         with torch.no_grad():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                 out_keys=[(\"next\", \"encoded_latents\")],\n#             ),\n#             rssm_rollout,\n#             SafeModule(\n#                 obs_decoder,\n#                 in_keys=[(\"next\", \"state\"), (\"next\", \"belief\")],\n#                 out_keys=[(\"next\", \"reco_pixels\")],\n#             ),\n#         )\n#         reward_module = SafeModule(\n#             reward_module,\n#             in_keys=[(\"next\", \"state\"), (\"next\", \"belief\")],\n#             out_keys=[\"reward\"],\n#         )\n#         world_model = WorldModelWrapper(world_modeler, reward_module)\n# \n#         with torch.no_grad():\n#             td = mock_env.rollout(10)\n#             td = td.unsqueeze(0).to_tensordict()\n#             td[\"state\"] = torch.zeros((1, 10, state_dim))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#             ),\n#         )\n#         reward_module = MLP(\n#             out_features=1, depth=2, num_cells=mlp_num_units, activation_class=nn.ELU\n#         )\n#         # World Model and reward model\n#         world_modeler = SafeSequential(\n#             SafeModule(\n#                 obs_encoder,\n#                 in_keys=[(\"next\", \"pixels\")],\n#                 out_keys=[(\"next\", \"encoded_latents\")],\n#             ),\n#             rssm_rollout,\n#             SafeModule(\n#                 obs_decoder,\n#                 in_keys=[(\"next\", \"state\"), (\"next\", \"belief\")],\n#                 out_keys=[(\"next\", \"reco_pixels\")],\n#             ),\n#         )\n#         reward_module = SafeModule(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_modules.py\n# --------------------------------------------------\n#             SafeModule(\n#                 rssm_posterior,\n#                 in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n#                 out_keys=[\n#                     (\"next\", \"posterior_mean\"),\n#                     (\"next\", \"posterior_std\"),\n#                     (\"next\", \"state\"),\n#                 ],\n#             ),\n#         )\n# \n#         state = torch.randn(*batch_size, temporal_size, deter_size, device=device)\n#         belief = torch.randn(*batch_size, temporal_size, stoch_size, device=device)\n#         action = torch.randn(*batch_size, temporal_size, action_size, device=device)\n#         obs_emb = torch.randn(*batch_size, temporal_size, 1024, device=device)\n# \n#         tensordict = TensorDict(\n#             {\n#                 \"state\": state.clone(),\n#                 \"action\": action.clone(),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                 ],\n#             ),\n#             SafeModule(\n#                 rssm_posterior,\n#                 in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n#                 out_keys=[\n#                     (\"next\", \"posterior_mean\"),\n#                     (\"next\", \"posterior_std\"),\n#                     (\"next\", \"state\"),\n#                 ],\n#             ),\n#         )\n#         reward_module = MLP(\n#             out_features=1, depth=2, num_cells=mlp_num_units, activation_class=nn.ELU\n#         )\n#         # World Model and reward model\n#         world_modeler = SafeSequential(\n#             SafeModule(\n#                 obs_encoder,\n#                 in_keys=[(\"next\", \"pixels\")],\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\n        nn.TensorDictModel: Dreamer Model based environnement.\n        nn.TensorDictModel: Dreamer Actor the world model space.\n        nn.TensorDictModel: Dreamer Value model.\n        nn.TensorDictModel: Dreamer Actor for the real world space.\n\n    \"\"\"\n    proof_env_is_none = proof_environment is None\n    if proof_env_is_none:\n        proof_environment = transformed_env_constructor(\n            cfg=cfg, use_env_creator=False, obs_norm_state_dict=obs_norm_state_dict\n        )()\n\n    # Modules\n    obs_encoder = ObsEncoder()\n    obs_decoder = ObsDecoder()\n\n    rssm_prior = RSSMPrior(\n        hidden_dim=cfg.rssm_hidden_dim,\n        rnn_hidden_dim=cfg.rssm_hidden_dim,\n        state_dim=cfg.state_dim,\n        action_spec=proof_environment.action_spec,\n    )\n    rssm_posterior = RSSMPosterior(\n        hidden_dim=cfg.rssm_hidden_dim, state_dim=cfg.state_dim\n    )\n    reward_module = MLP(\n        out_features=1, depth=2, num_cells=cfg.mlp_num_units, activation_class=nn.ELU\n    )\n\n    world_model = _dreamer_make_world_model(\n        obs_encoder, obs_decoder, rssm_prior, rssm_posterior, reward_module\n    ).to(device)\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        tensordict = proof_environment.rollout(4)\n        tensordict = tensordict.to_tensordict().to(device)\n        tensordict = tensordict.to(device)\n        world_model(tensordict)\n\n    model_based_env = _dreamer_make_mbenv(\n        reward_module,\n        rssm_prior,\n        obs_decoder,\n        proof_environment,\n        use_decoder_in_env,\n        cfg.state_dim,\n        cfg.rssm_hidden_dim,\n    )\n    model_based_env = model_based_env.to(device)\n\n    actor_simulator, actor_realworld = _dreamer_make_actors(\n        obs_encoder,\n        rssm_prior,\n        rssm_posterior,\n        cfg.mlp_num_units,\n        action_key,\n        proof_environment,\n    )\n    actor_simulator = actor_simulator.to(device)\n\n    value_model = _dreamer_make_value_model(cfg.mlp_num_units, value_key)\n    value_model = value_model.to(device)\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        tensordict = model_based_env.rollout(4)\n        tensordict = tensordict.to(device)\n        tensordict = actor_simulator(tensordict)\n        value_model(tensordict)\n\n    actor_realworld = actor_realworld.to(device)\n    if proof_env_is_none:\n        proof_environment.close()\n        torch.cuda.empty_cache()\n        del proof_environment\n\n    del tensordict\n    return world_model, model_based_env, actor_simulator, value_model, actor_realworld\n\n\ndef _dreamer_make_world_model(\n    obs_encoder, obs_decoder, rssm_prior, rssm_posterior, reward_module\n):\n    # World Model and reward model\n    rssm_rollout = RSSMRollout(\n        SafeModule(\n            rssm_prior,\n            in_keys=[\"state\", \"belief\", \"action\"],\n            out_keys=[\n                (\"next\", \"prior_mean\"),\n                (\"next\", \"prior_std\"),\n                \"_\",\n                (\"next\", \"belief\"),\n            ],\n        ),\n        SafeModule(\n            rssm_posterior,\n            in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n            out_keys=[\n                (\"next\", \"posterior_mean\"),\n                (\"next\", \"posterior_std\"),\n                (\"next\", \"state\"),\n            ],\n        ),\n    )\n\n    transition_model = SafeSequential(\n        SafeModule(\n            obs_encoder,\n            in_keys=[(\"next\", \"pixels\")],\n            out_keys=[(\"next\", \"encoded_latents\")],\n        ),\n        rssm_rollout,\n        SafeModule(\n            obs_decoder,\n            in_keys=[(\"next\", \"state\"), (\"next\", \"belief\")],\n            out_keys=[(\"next\", \"reco_pixels\")],\n        ),\n    )\n    reward_model = SafeModule(\n        reward_module,\n        in_keys=[(\"next\", \"state\"), (\"next\", \"belief\")],\n        out_keys=[\"reward\"],\n    )\n    world_model = WorldModelWrapper(\n        transition_model,\n        reward_model,\n    )\n    return world_model\n\n\ndef _dreamer_make_actors(\n    obs_encoder,\n    rssm_prior,\n    rssm_posterior,\n    mlp_num_units,\n    action_key,\n    proof_environment,\n):\n    actor_module = DreamerActor(\n        out_features=proof_environment.action_spec.shape[0],\n        depth=3,\n        num_cells=mlp_num_units,\n        activation_class=nn.ELU,\n    )\n    actor_simulator = _dreamer_make_actor_sim(\n        action_key, proof_environment, actor_module\n    )\n    actor_realworld = _dreamer_make_actor_real(\n        obs_encoder,\n        rssm_prior,\n        rssm_posterior,\n        actor_module,\n        action_key,\n        proof_environment,\n    )\n    return actor_simulator, actor_realworld\n\n\ndef _dreamer_make_actor_sim(action_key, proof_environment, actor_module):\n    actor_simulator = SafeProbabilisticSequential(\n        SafeModule(\n            actor_module,\n            in_keys=[\"state\", \"belief\"],\n            out_keys=[\"loc\", \"scale\"],\n            spec=CompositeSpec(\n                **{\n                    \"loc\": UnboundedContinuousTensorSpec(\n                        proof_environment.action_spec.shape,\n                        device=proof_environment.action_spec.device,\n                    ),\n                    \"scale\": UnboundedContinuousTensorSpec(\n                        proof_environment.action_spec.shape,\n                        device=proof_environment.action_spec.device,\n                    ),\n                }\n            ),\n        ),\n        SafeProbabilisticModule(\n            in_keys=[\"loc\", \"scale\"],\n            out_keys=[action_key],\n            default_interaction_mode=\"random\",\n            distribution_class=TanhNormal,\n            spec=CompositeSpec(**{action_key: proof_environment.action_spec}),\n        ),\n    )\n    return actor_simulator\n\n\ndef _dreamer_make_actor_real(\n    obs_encoder, rssm_prior, rssm_posterior, actor_module, action_key, proof_environment\n):\n    # actor for real world: interacts with states ~ posterior\n    # Out actor differs from the original paper where first they compute prior and posterior and then act on it\n    # but we found that this approach worked better.\n    actor_realworld = SafeSequential(\n        SafeModule(\n            obs_encoder,\n            in_keys=[\"pixels\"],\n            out_keys=[\"encoded_latents\"],\n        ),\n        SafeModule(\n            rssm_posterior,\n            in_keys=[\"belief\", \"encoded_latents\"],\n            out_keys=[\n                \"_\",\n                \"_\",\n                \"state\",\n            ],\n        ),", "choices": [{"text": "SafeProbabilisticModule("}], "metadata": {"task_id": "pytorch_rl/159", "ground_truth": "        SafeProbabilisticSequential(", "fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "context_start_lineno": 1488, "line_no": 1696, "query_window": {"context": "    obs_encoder, rssm_prior, rssm_posterior, actor_module, action_key, proof_environment\n):\n    # actor for real world: interacts with states ~ posterior\n    # Out actor differs from the original paper where first they compute prior and posterior and then act on it\n    # but we found that this approach worked better.\n    actor_realworld = SafeSequential(\n        SafeModule(\n            obs_encoder,\n            in_keys=[\"pixels\"],\n            out_keys=[\"encoded_latents\"],\n        ),\n        SafeModule(\n            rssm_posterior,\n            in_keys=[\"belief\", \"encoded_latents\"],\n            out_keys=[\n                \"_\",\n                \"_\",\n                \"state\",\n            ],\n        ),", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1696, "task_id": "pytorch_rl/159", "start_line_no": 1676, "end_line_no": 1696, "window_size": 20, "context_start_lineno": 1488, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        # World Model and reward model\n        rssm_rollout = RSSMRollout(\n            SafeModule(\n                rssm_prior,\n                in_keys=[\"state\", \"belief\", \"action\"],\n                out_keys=[\n                    (\"next\", \"prior_mean\"),\n                    (\"next\", \"prior_std\"),\n                    \"_\",\n                    (\"next\", \"belief\"),\n                ],\n            ),\n            SafeModule(\n                rssm_posterior,\n                in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n                out_keys=[\n                    (\"next\", \"posterior_mean\"),\n                    (\"next\", \"posterior_std\"),\n                    (\"next\", \"state\"),\n                ],", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 2480, "start_line_no": 2470, "end_line_no": 2490, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.36792452830188677}, {"context": "            SafeModule(\n                rssm_prior,\n                in_keys=[\"state\", \"belief\", \"action\"],\n                out_keys=[\n                    (\"next\", \"prior_mean\"),\n                    (\"next\", \"prior_std\"),\n                    \"_\",\n                    (\"next\", \"belief\"),\n                ],\n            ),\n            SafeModule(\n                rssm_posterior,\n                in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n                out_keys=[\n                    (\"next\", \"posterior_mean\"),\n                    (\"next\", \"posterior_std\"),\n                    (\"next\", \"state\"),\n                ],\n            ),\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_modules.py"], "line_no": 630, "start_line_no": 620, "end_line_no": 640, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3673469387755102}, {"context": "                ],\n            ),\n            SafeModule(\n                rssm_posterior,\n                in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n                out_keys=[\n                    (\"next\", \"posterior_mean\"),\n                    (\"next\", \"posterior_std\"),\n                    (\"next\", \"state\"),\n                ],\n            ),\n        )\n        reward_module = MLP(\n            out_features=1, depth=2, num_cells=mlp_num_units, activation_class=nn.ELU\n        )\n        # World Model and reward model\n        world_modeler = SafeSequential(\n            SafeModule(\n                obs_encoder,\n                in_keys=[(\"next\", \"pixels\")],", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 2490, "start_line_no": 2480, "end_line_no": 2500, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.35294117647058826}, {"context": "            ),\n        )\n        reward_module = MLP(\n            out_features=1, depth=2, num_cells=mlp_num_units, activation_class=nn.ELU\n        )\n        # World Model and reward model\n        world_modeler = SafeSequential(\n            SafeModule(\n                obs_encoder,\n                in_keys=[(\"next\", \"pixels\")],\n                out_keys=[(\"next\", \"encoded_latents\")],\n            ),\n            rssm_rollout,\n            SafeModule(\n                obs_decoder,\n                in_keys=[(\"next\", \"state\"), (\"next\", \"belief\")],\n                out_keys=[(\"next\", \"reco_pixels\")],\n            ),\n        )\n        reward_module = SafeModule(", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 2500, "start_line_no": 2490, "end_line_no": 2510, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.32231404958677684}, {"context": "        reward_module = MLP(\n            out_features=1, depth=2, num_cells=mlp_num_units, activation_class=nn.ELU\n        )\n        transition_model = SafeSequential(\n            SafeModule(\n                rssm_prior,\n                in_keys=[\"state\", \"belief\", \"action\"],\n                out_keys=[\n                    \"_\",\n                    \"_\",\n                    \"state\",\n                    \"belief\",\n                ],\n            ),\n        )\n        reward_model = SafeModule(\n            reward_module,\n            in_keys=[\"state\", \"belief\"],\n            out_keys=[\"reward\"],\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 2550, "start_line_no": 2540, "end_line_no": 2560, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3153153153153153}, {"context": "        obs_decoder = ObsDecoder()\n\n        rssm_prior = RSSMPrior(\n            hidden_dim=rssm_hidden_dim,\n            rnn_hidden_dim=rssm_hidden_dim,\n            state_dim=state_dim,\n            action_spec=mock_env.action_spec,\n        )\n        rssm_posterior = RSSMPosterior(hidden_dim=rssm_hidden_dim, state_dim=state_dim)\n\n        # World Model and reward model\n        rssm_rollout = RSSMRollout(\n            SafeModule(\n                rssm_prior,\n                in_keys=[\"state\", \"belief\", \"action\"],\n                out_keys=[\n                    (\"next\", \"prior_mean\"),\n                    (\"next\", \"prior_std\"),\n                    \"_\",\n                    (\"next\", \"belief\"),", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 2470, "start_line_no": 2460, "end_line_no": 2480, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30578512396694213}, {"context": "            hidden_dim=stoch_size,\n            rnn_hidden_dim=stoch_size,\n            state_dim=deter_size,\n        ).to(device)\n        rssm_posterior = RSSMPosterior(\n            hidden_dim=stoch_size,\n            state_dim=deter_size,\n        ).to(device)\n\n        rssm_rollout = RSSMRollout(\n            SafeModule(\n                rssm_prior,\n                in_keys=[\"state\", \"belief\", \"action\"],\n                out_keys=[\n                    (\"next\", \"prior_mean\"),\n                    (\"next\", \"prior_std\"),\n                    \"_\",\n                    (\"next\", \"belief\"),\n                ],\n            ),", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_modules.py"], "line_no": 620, "start_line_no": 610, "end_line_no": 630, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28695652173913044}, {"context": "            SafeModule(\n                rssm_posterior,\n                in_keys=[(\"next\", \"belief\"), (\"next\", \"encoded_latents\")],\n                out_keys=[\n                    (\"next\", \"posterior_mean\"),\n                    (\"next\", \"posterior_std\"),\n                    (\"next\", \"state\"),\n                ],\n            ),\n        )\n\n        state = torch.randn(*batch_size, temporal_size, deter_size, device=device)\n        belief = torch.randn(*batch_size, temporal_size, stoch_size, device=device)\n        action = torch.randn(*batch_size, temporal_size, action_size, device=device)\n        obs_emb = torch.randn(*batch_size, temporal_size, 1024, device=device)\n\n        tensordict = TensorDict(\n            {\n                \"state\": state.clone(),\n                \"action\": action.clone(),", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_modules.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2777777777777778}], "window_size": 20, "slice_size": 2}}
