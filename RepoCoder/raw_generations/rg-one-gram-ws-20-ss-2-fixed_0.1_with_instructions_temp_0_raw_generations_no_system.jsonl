{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/_utils.py\n# --------------------------------------------------\n#             )\n#             print(\" -- \".join(strings))\n# \n#     @staticmethod\n#     def erase():\n#         for k in timeit._REG:\n#             timeit._REG[k] = [0.0, 0.0, 0]\n# \n# \n# def _check_for_faulty_process(processes):\n#     terminate = False\n#     for p in processes:\n#         if not p.is_alive():\n#             terminate = True\n#             for _p in processes:\n#                 if _p.is_alive():\n#                     _p.terminate()\n#         if terminate:\n#             break\n#     if terminate:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#             state_dict[f\"worker{idx}\"] = _state_dict\n# \n#         return state_dict\n# \n#     @_check_start\n#     def load_state_dict(self, state_dict: OrderedDict) -> None:\n#         if \"worker0\" not in state_dict:\n#             state_dict = OrderedDict(\n#                 **{f\"worker{idx}\": state_dict for idx in range(self.num_workers)}\n#             )\n#         for i, channel in enumerate(self.parent_channels):\n#             channel.send((\"load_state_dict\", state_dict[f\"worker{i}\"]))\n#         for channel in self.parent_channels:\n#             msg, _ = channel.recv()\n#             if msg != \"loaded\":\n#                 raise RuntimeError(f\"Expected 'loaded' but received {msg}\")\n# \n#     @_check_start\n#     def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         self._assert_tensordict_shape(tensordict)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/_utils_internal.py\n# --------------------------------------------------\n#     return devices\n# \n# \n# def generate_seeds(seed, repeat):\n#     seeds = [seed]\n#     for _ in range(repeat - 1):\n#         seed = seed_generator(seed)\n#         seeds.append(seed)\n#     return seeds\n# \n# \n# # Decorator to retry upon certain Exceptions.\n# def retry(ExceptionToCheck, tries=3, delay=3, skip_after_retries=False):\n#     def deco_retry(f):\n#         @wraps(f)\n#         def f_retry(*args, **kwargs):\n#             mtries, mdelay = tries, delay\n#             while mtries > 1:\n#                 try:\n#                     return f(*args, **kwargs)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n# \n#         elif cmd == \"state_dict\":\n#             state_dict = _recursively_strip_locks_from_state_dict(env.state_dict())\n#             msg = \"state_dict\"\n#             child_pipe.send((msg, state_dict))\n# \n#         else:\n#             err_msg = f\"{cmd} from env\"\n#             try:\n#                 attr = getattr(env, cmd)\n#                 if callable(attr):\n#                     args, kwargs = data\n#                     args_replace = []\n#                     for _arg in args:\n#                         if isinstance(_arg, str) and _arg == \"_self\":\n#                             continue\n#                         else:\n#                             args_replace.append(_arg)\n#                     result = attr(*args_replace, **kwargs)\n#                 else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# build_tools/setup_helpers/extension.py\n# --------------------------------------------------\n#                 [\"cmake\", str(_ROOT_DIR)] + cmake_args,\n#                 cwd=self.build_temp,\n#                 stderr=STDOUT,\n#             )\n#         except CalledProcessError as exc:\n#             print(exc.output)\n# \n#         try:\n#             check_output(\n#                 [\"cmake\", \"--build\", \".\"] + build_args,\n#                 cwd=self.build_temp,\n#                 stderr=STDOUT,\n#             )\n#         except CalledProcessError as exc:\n#             print(exc.output)\n# \n#     def get_ext_filename(self, fullname):\n#         ext_filename = super().get_ext_filename(fullname)\n#         ext_filename_parts = ext_filename.split(\".\")\n#         without_abi = ext_filename_parts[:-2] + ext_filename_parts[-1:]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# build_tools/setup_helpers/extension.py\n# --------------------------------------------------\n#     ]\n# \n# \n# # Based off of\n# # https://github.com/pybind/cmake_example/blob/580c5fd29d4651db99d8874714b07c0c49a53f8a/setup.py\n# class CMakeBuild(build_ext):\n#     def run(self):\n#         try:\n#             subprocess.check_output([\"cmake\", \"--version\"])\n#         except OSError:\n#             raise RuntimeError(\"CMake is not available.\") from None\n#         super().run()\n# \n#     def build_extension(self, ext):\n#         # Since two library files (libtorchrl and _torchrl) need to be\n#         # recognized by setuptools, we instantiate `Extension` twice. (see `get_ext_modules`)\n#         # This leads to the situation where this `build_extension` method is called twice.\n#         # However, the following `cmake` command will build all of them at the same time,\n#         # so, we do not need to perform `cmake` twice.\n#         # Therefore we call `cmake` only for `torchrl._torchrl`.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# build_tools/setup_helpers/extension.py\n# --------------------------------------------------\n#                 stderr=STDOUT,\n#             )\n#         except CalledProcessError as exc:\n#             print(exc.output)\n# \n#         try:\n#             check_output(\n#                 [\"cmake\", \"--build\", \".\"] + build_args,\n#                 cwd=self.build_temp,\n#                 stderr=STDOUT,\n#             )\n#         except CalledProcessError as exc:\n#             print(exc.output)\n# \n#     def get_ext_filename(self, fullname):\n#         ext_filename = super().get_ext_filename(fullname)\n#         ext_filename_parts = ext_filename.split(\".\")\n#         without_abi = ext_filename_parts[:-2] + ext_filename_parts[-1:]\n#         ext_filename = \".\".join(without_abi)\n#         return ext_filename\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport argparse\nimport distutils.command.clean\nimport glob\nimport os\nimport shutil\nimport subprocess\nimport sys\nfrom datetime import date\nfrom pathlib import Path\nfrom typing import List\n\nfrom setuptools import find_packages, setup\nfrom torch.utils.cpp_extension import BuildExtension, CppExtension\n\ncwd = os.path.dirname(os.path.abspath(__file__))\ntry:\n    sha = (\n        subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=cwd)\n        .decode(\"ascii\")\n        .strip()\n    )\nexcept Exception:\n    sha = \"Unknown\"\n\n\ndef get_version():\n    version_txt = os.path.join(cwd, \"version.txt\")\n    with open(version_txt, \"r\") as f:\n        version = f.readline().strip()\n    if os.getenv(\"BUILD_VERSION\"):\n        version = os.getenv(\"BUILD_VERSION\")\n    elif sha != \"Unknown\":\n        version += \"+\" + sha[:7]\n    return version\n\n\nROOT_DIR = Path(__file__).parent.resolve()\n\n\npackage_name = \"torchrl\"\n\n\ndef get_nightly_version():\n    today = date.today()\n    return f\"{today.year}.{today.month}.{today.day}\"\n\n\ndef parse_args(argv: List[str]) -> argparse.Namespace:\n    parser = argparse.ArgumentParser(description=\"torchrl setup\")\n    parser.add_argument(\n        \"--package_name\",\n        type=str,\n        default=\"torchrl\",\n        help=\"the name of this output wheel\",\n    )\n    return parser.parse_known_args(argv)\n\n\ndef write_version_file(version):\n    version_path = os.path.join(cwd, \"torchrl\", \"version.py\")\n    with open(version_path, \"w\") as f:\n        f.write(\"__version__ = '{}'\\n\".format(version))\n        f.write(\"git_version = {}\\n\".format(repr(sha)))\n\n\ndef _get_pytorch_version():\n    # if \"PYTORCH_VERSION\" in os.environ:\n    #     return f\"torch=={os.environ['PYTORCH_VERSION']}\"\n    return \"torch\"\n\n\ndef _get_packages():\n    exclude = [\n        \"build*\",\n        \"test*\",\n        \"torchrl.csrc*\",\n        \"third_party*\",\n        \"tools*\",\n    ]\n    return find_packages(exclude=exclude)\n\n\nROOT_DIR = Path(__file__).parent.resolve()\n\n\nclass clean(distutils.command.clean.clean):\n    def run(self):\n        # Run default behavior first\n        distutils.command.clean.clean.run(self)\n\n        # Remove torchrl extension\n        for path in (ROOT_DIR / \"torchrl\").glob(\"**/*.so\"):\n            print(f\"removing '{path}'\")\n            path.unlink()\n        # Remove build directory\n        build_dirs = [\n            ROOT_DIR / \"build\",\n        ]\n        for path in build_dirs:\n            if path.exists():\n                print(f\"removing '{path}' (and everything under it)\")\n                shutil.rmtree(str(path), ignore_errors=True)\n\n\n# def _run_cmd(cmd):\n#     try:\n#         return subprocess.check_output(cmd, cwd=ROOT_DIR).decode(\"ascii\").strip()\n#     except Exception:\n#         return None\n\n\ndef get_extensions():\n    extension = CppExtension\n\n    extra_link_args = []\n    extra_compile_args = {\n        \"cxx\": [\n            \"-O3\",\n            \"-std=c++14\",\n            \"-fdiagnostics-color=always\",", "completion": "# \"-Wno-deprecated-declarations\",\n#             \"-Wno-unused-function\",\n#             \"-Wno-write-strings\",\n#             \"-Wno-unknown-pragmas\",\n#             \"-Wno-unused-variable\",\n#             \"-Wno-unused-result\",\n#             \"-Wno-unused-but-set-variable\",\n#             \"-Wno-strict-overflow\",\n#             \"-Wno-format\",\n#             \"-Wno-format-security\",\n#             \"-Wno-format-extra-args\",\n#             \"-Wno-sign-compare\",\n#             \"-Wno-enum-compare\",\n#             \"-Wno-maybe-uninitialized\",\n#             \"-Wno-strict-aliasing\",\n#             \"-Wno-ignored-qualifiers\",\n#             \"-Wno-unused-local-typedefs\",\n#             \"-Wno-unused-function\",\n#             \"-Wno-unused-parameter\",\n#             \"-Wno-unused-variable\",\n#             \"-Wno-unused-but-set-variable\",\n#             \"-Wno-unused-result\",\n#             \"-Wno-unused-label\",\n#             \"-Wno-unused-value\",\n#             \"-Wno-unused-const-variable\",\n#             \"-Wno-unused-local-typedef\",\n#             \"-Wno-unused-private-field\",\n#", "metadata": {"task_id": "pytorch_rl/156", "ground_truth": "        ]", "fpath_tuple": ["pytorch_rl", "setup.py"], "context_start_lineno": 0, "line_no": 124, "query_window": {"context": "                print(f\"removing '{path}' (and everything under it)\")\n                shutil.rmtree(str(path), ignore_errors=True)\n\n\n# def _run_cmd(cmd):\n#     try:\n#         return subprocess.check_output(cmd, cwd=ROOT_DIR).decode(\"ascii\").strip()\n#     except Exception:\n#         return None\n\n\ndef get_extensions():\n    extension = CppExtension\n\n    extra_link_args = []\n    extra_compile_args = {\n        \"cxx\": [\n            \"-O3\",\n            \"-std=c++14\",\n            \"-fdiagnostics-color=always\",", "metadata": {"fpath_tuple": ["pytorch_rl", "setup.py"], "line_no": 124, "task_id": "pytorch_rl/156", "start_line_no": 104, "end_line_no": 124, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "                [\"cmake\", str(_ROOT_DIR)] + cmake_args,\n                cwd=self.build_temp,\n                stderr=STDOUT,\n            )\n        except CalledProcessError as exc:\n            print(exc.output)\n\n        try:\n            check_output(\n                [\"cmake\", \"--build\", \".\"] + build_args,\n                cwd=self.build_temp,\n                stderr=STDOUT,\n            )\n        except CalledProcessError as exc:\n            print(exc.output)\n\n    def get_ext_filename(self, fullname):\n        ext_filename = super().get_ext_filename(fullname)\n        ext_filename_parts = ext_filename.split(\".\")\n        without_abi = ext_filename_parts[:-2] + ext_filename_parts[-1:]", "metadata": [{"fpath_tuple": ["pytorch_rl", "build_tools", "setup_helpers", "extension.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.22}, {"context": "_USE_OPENMP = (\n    _get_build(\"USE_OPENMP\", True)\n    and \"ATen parallel backend: OpenMP\" in torch.__config__.parallel_info()\n)\n_TORCH_CUDA_ARCH_LIST = os.environ.get(\"TORCH_CUDA_ARCH_LIST\", None)\n\n\ndef get_ext_modules():\n    return [\n        Extension(name=\"torchrl._torchrl\", sources=[]),\n    ]\n\n\n# Based off of\n# https://github.com/pybind/cmake_example/blob/580c5fd29d4651db99d8874714b07c0c49a53f8a/setup.py\nclass CMakeBuild(build_ext):\n    def run(self):\n        try:\n            subprocess.check_output([\"cmake\", \"--version\"])\n        except OSError:", "metadata": [{"fpath_tuple": ["pytorch_rl", "build_tools", "setup_helpers", "extension.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21465968586387435}, {"context": "            if hasattr(self, \"parallel\") and self.parallel:\n                # CMake 3.12+ only.\n                build_args += [\"-j{}\".format(self.parallel)]\n\n        if not os.path.exists(self.build_temp):\n            os.makedirs(self.build_temp)\n\n        print(\" \".join([\"cmake\", str(_ROOT_DIR)] + cmake_args))\n        try:\n            check_output(\n                [\"cmake\", str(_ROOT_DIR)] + cmake_args,\n                cwd=self.build_temp,\n                stderr=STDOUT,\n            )\n        except CalledProcessError as exc:\n            print(exc.output)\n\n        try:\n            check_output(\n                [\"cmake\", \"--build\", \".\"] + build_args,", "metadata": [{"fpath_tuple": ["pytorch_rl", "build_tools", "setup_helpers", "extension.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20625}, {"context": "            child_pipe.send((\"closing\", None))\n            child_pipe.close()\n            if verbose:\n                print(f\"{pid} closed\")\n            break\n\n        elif cmd == \"load_state_dict\":\n            env.load_state_dict(data)\n            msg = \"loaded\"\n            child_pipe.send((msg, None))\n\n        elif cmd == \"state_dict\":\n            state_dict = _recursively_strip_locks_from_state_dict(env.state_dict())\n            msg = \"state_dict\"\n            child_pipe.send((msg, state_dict))\n\n        else:\n            err_msg = f\"{cmd} from env\"\n            try:\n                attr = getattr(env, cmd)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 1050, "start_line_no": 1040, "end_line_no": 1060, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2054794520547945}, {"context": "def get_relative_path(curr_file, *path_components):\n    return os.path.join(os.path.dirname(curr_file), *path_components)\n\n\ndef get_available_devices():\n    devices = [torch.device(\"cpu\")]\n    n_cuda = torch.cuda.device_count()\n    if n_cuda > 0:\n        for i in range(n_cuda):\n            devices += [torch.device(f\"cuda:{i}\")]\n    return devices\n\n\ndef generate_seeds(seed, repeat):\n    seeds = [seed]\n    for _ in range(repeat - 1):\n        seed = seed_generator(seed)\n        seeds.append(seed)\n    return seeds\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "_utils_internal.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2052980132450331}, {"context": "\n    @_check_start\n    def state_dict(self) -> OrderedDict:\n        state_dict = OrderedDict()\n        for channel in self.parent_channels:\n            channel.send((\"state_dict\", None))\n        for idx, channel in enumerate(self.parent_channels):\n            msg, _state_dict = channel.recv()\n            if msg != \"state_dict\":\n                raise RuntimeError(f\"Expected 'state_dict' but received {msg}\")\n            state_dict[f\"worker{idx}\"] = _state_dict\n\n        return state_dict\n\n    @_check_start\n    def load_state_dict(self, state_dict: OrderedDict) -> None:\n        if \"worker0\" not in state_dict:\n            state_dict = OrderedDict(\n                **{f\"worker{idx}\": state_dict for idx in range(self.num_workers)}\n            )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20512820512820512}, {"context": "    @staticmethod\n    def print(prefix=None):\n        keys = list(timeit._REG)\n        keys.sort()\n        for name in keys:\n            strings = []\n            if prefix:\n                strings.append(prefix)\n            strings.append(\n                f\"{name} took {timeit._REG[name][0] * 1000:4.4} msec (total = {timeit._REG[name][1]} sec)\"\n            )\n            print(\" -- \".join(strings))\n\n    @staticmethod\n    def erase():\n        for k in timeit._REG:\n            timeit._REG[k] = [0.0, 0.0, 0]\n\n\ndef _check_for_faulty_process(processes):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.20512820512820512}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/textual_inversion/textual_inversion.py\n# --------------------------------------------------\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--allow_tf32\",\n#         action=\"store_true\",\n#         help=(\n#             \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n#             \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--report_to\",\n#         type=str,\n#         default=\"tensorboard\",\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/text_to_image/train_text_to_image_flax.py\n# --------------------------------------------------\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--mixed_precision\",\n#         type=str,\n#         default=\"no\",\n#         choices=[\"no\", \"fp16\", \"bf16\"],\n#         help=(\n#             \"Whether to use mixed precision. Choose\"\n#             \"between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.\"\n#             \"and an Nvidia Ampere GPU.\"\n#         ),\n#     )\n#     parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n# \n#     args = parser.parse_args()\n#     env_local_rank = int(os.environ.get(\"LOCAL_RANK\", -1))\n#     if env_local_rank != -1 and env_local_rank != args.local_rank:\n#         args.local_rank = env_local_rank\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/text_to_image/train_text_to_image_flax.py\n# --------------------------------------------------\n#             \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--report_to\",\n#         type=str,\n#         default=\"tensorboard\",\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--mixed_precision\",\n#         type=str,\n#         default=\"no\",\n#         choices=[\"no\", \"fp16\", \"bf16\"],\n#         help=(\n#             \"Whether to use mixed precision. Choose\"\n#             \"between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/dreambooth/train_dreambooth_lora.py\n# examples/dreambooth/train_dreambooth.py\n# examples/research_projects/multi_subject_dreambooth/train_multi_subject_dreambooth.py\n# --------------------------------------------------\n#         action=\"store_true\",\n#         help=(\n#             \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n#             \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--report_to\",\n#         type=str,\n#         default=\"tensorboard\",\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--mixed_precision\",\n#         type=str,\n#         default=None,\n#         choices=[\"no\", \"fp16\", \"bf16\"],\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/dreambooth/train_dreambooth_lora.py\n# examples/dreambooth/train_dreambooth.py\n# examples/research_projects/multi_subject_dreambooth/train_multi_subject_dreambooth.py\n# --------------------------------------------------\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--mixed_precision\",\n#         type=str,\n#         default=None,\n#         choices=[\"no\", \"fp16\", \"bf16\"],\n#         help=(\n#             \"Whether to use mixed precision. Choose between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >=\"\n#             \" 1.10.and an Nvidia Ampere GPU.  Default to the value of accelerate config of the current system or the\"\n#             \" flag passed with the `accelerate.launch` command. Use this argument to override the accelerate config.\"\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--prior_generation_precision\",\n#         type=str,\n#         default=None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/textual_inversion/textual_inversion.py\n# --------------------------------------------------\n#     parser.add_argument(\n#         \"--report_to\",\n#         type=str,\n#         default=\"tensorboard\",\n#         help=(\n#             'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n#             ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n#         ),\n#     )\n#     parser.add_argument(\n#         \"--validation_prompt\",\n#         type=str,\n#         default=None,\n#         help=\"A prompt that is used during validation to verify that the model is learning.\",\n#     )\n#     parser.add_argument(\n#         \"--num_validation_images\",\n#         type=int,\n#         default=4,\n#         help=\"Number of images that should be generated during validation with `validation_prompt`.\",\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n,\n        default=None,\n        required=False,\n        help=\"A folder containing the training data of class images.\",\n    )\n    parser.add_argument(\n        \"--instance_prompt\",\n        type=str,\n        default=None,\n        required=True,\n        help=\"The prompt with identifier specifying the instance\",\n    )\n    parser.add_argument(\n        \"--class_prompt\",\n        type=str,\n        default=None,\n        help=\"The prompt to specify images in the same class as provided instance images.\",\n    )\n    parser.add_argument(\n        \"--with_prior_preservation\",\n        default=False,\n        action=\"store_true\",\n        help=\"Flag to add prior preservation loss.\",\n    )\n    parser.add_argument(\"--prior_loss_weight\", type=float, default=1.0, help=\"The weight of prior preservation loss.\")\n    parser.add_argument(\n        \"--num_class_images\",\n        type=int,\n        default=100,\n        help=(\n            \"Minimal class images for prior preservation loss. If there are not enough images already present in\"\n            \" class_data_dir, additional images will be sampled with class_prompt.\"\n        ),\n    )\n    parser.add_argument(\n        \"--output_dir\",\n        type=str,\n        default=\"text-inversion-model\",\n        help=\"The output directory where the model predictions and checkpoints will be written.\",\n    )\n    parser.add_argument(\"--seed\", type=int, default=None, help=\"A seed for reproducible training.\")\n    parser.add_argument(\n        \"--resolution\",\n        type=int,\n        default=512,\n        help=(\n            \"The resolution for input images, all the images in the train/validation dataset will be resized to this\"\n            \" resolution\"\n        ),\n    )\n    parser.add_argument(\n        \"--center_crop\",\n        default=False,\n        action=\"store_true\",\n        help=(\n            \"Whether to center crop the input images to the resolution. If not set, the images will be randomly\"\n            \" cropped. The images will be resized to the resolution first before cropping.\"\n        ),\n    )\n    parser.add_argument(\"--train_text_encoder\", action=\"store_true\", help=\"Whether to train the text encoder\")\n    parser.add_argument(\n        \"--train_batch_size\", type=int, default=4, help=\"Batch size (per device) for the training dataloader.\"\n    )\n    parser.add_argument(\n        \"--sample_batch_size\", type=int, default=4, help=\"Batch size (per device) for sampling images.\"\n    )\n    parser.add_argument(\"--num_train_epochs\", type=int, default=1)\n    parser.add_argument(\n        \"--max_train_steps\",\n        type=int,\n        default=None,\n        help=\"Total number of training steps to perform.  If provided, overrides num_train_epochs.\",\n    )\n    parser.add_argument(\n        \"--checkpointing_steps\",\n        type=int,\n        default=500,\n        help=(\n            \"Save a checkpoint of the training state every X updates. These checkpoints can be used both as final\"\n            \" checkpoints in case they are better than the last checkpoint, and are also suitable for resuming\"\n            \" training using `--resume_from_checkpoint`.\"\n        ),\n    )\n    parser.add_argument(\n        \"--resume_from_checkpoint\",\n        type=str,\n        default=None,\n        help=(\n            \"Whether training should be resumed from a previous checkpoint. Use a path saved by\"\n            ' `--checkpointing_steps`, or `\"latest\"` to automatically select the last available checkpoint.'\n        ),\n    )\n    parser.add_argument(\n        \"--gradient_accumulation_steps\",\n        type=int,\n        default=1,\n        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n    )\n    parser.add_argument(\n        \"--gradient_checkpointing\",\n        action=\"store_true\",\n        help=\"Whether or not to use gradient checkpointing to save memory at the expense of slower backward pass.\",\n    )\n    parser.add_argument(\n        \"--learning_rate\",\n        type=float,\n        default=5e-6,\n        help=\"Initial learning rate (after the potential warmup period) to use.\",\n    )\n    parser.add_argument(\n        \"--scale_lr\",\n        action=\"store_true\",\n        default=False,\n        help=\"Scale the learning rate by the number of GPUs, gradient accumulation steps, and batch size.\",\n    )\n    parser.add_argument(\n        \"--lr_scheduler\",\n        type=str,\n        default=\"constant\",\n        help=(\n            'The scheduler type to use. Choose between [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\",'\n            ' \"constant\", \"constant_with_warmup\"]'\n        ),\n    )\n    parser.add_argument(\n        \"--lr_warmup_steps\", type=int, default=500, help=\"Number of steps for the warmup in the lr scheduler.\"\n    )\n    parser.add_argument(\n        \"--lr_num_cycles\",\n        type=int,\n        default=1,\n        help=\"Number of hard resets of the lr in cosine_with_restarts scheduler.\",\n    )\n    parser.add_argument(\"--lr_power\", type=float, default=1.0, help=\"Power factor of the polynomial scheduler.\")\n    parser.add_argument(\n        \"--use_8bit_adam\", action=\"store_true\", help=\"Whether or not to use 8-bit Adam from bitsandbytes.\"\n    )\n    parser.add_argument(\"--adam_beta1\", type=float, default=0.9, help=\"The beta1 parameter for the Adam optimizer.\")\n    parser.add_argument(\"--adam_beta2\", type=float, default=0.999, help=\"The beta2 parameter for the Adam optimizer.\")\n    parser.add_argument(\"--adam_weight_decay\", type=float, default=1e-2, help=\"Weight decay to use.\")\n    parser.add_argument(\"--adam_epsilon\", type=float, default=1e-08, help=\"Epsilon value for the Adam optimizer\")\n    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n    parser.add_argument(\"--push_to_hub\", action=\"store_true\", help=\"Whether or not to push the model to the Hub.\")\n    parser.add_argument(\"--hub_token\", type=str, default=None, help=\"The token to use to push to the Model Hub.\")\n    parser.add_argument(\n        \"--hub_model_id\",\n        type=str,\n        default=None,\n        help=\"The name of the repository to keep in sync with the local `output_dir`.\",\n    )\n    parser.add_argument(\n        \"--logging_dir\",\n        type=str,\n        default=\"logs\",\n        help=(\n            \"[TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to\"\n            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )", "completion": "import argparse\nimport os\n\nparser = argparse.ArgumentParser()\n\n# Add arguments\nparser.add_argument(\n    \"--class_data_dir\",\n    type=str,\n    default=None,\n    required=False,\n    help=\"A folder containing the training data of class images.\",\n)\nparser.add_argument(\n    \"--instance_prompt\",\n    type=str,\n    default=None,\n    required=True,\n    help=\"The prompt with identifier specifying the instance\",\n)\nparser.add_argument(\n    \"--class_prompt\",\n    type=str,\n    default=None,\n    help=\"The prompt to specify images in the same class as provided instance images.\",\n)\nparser.add_argument(\n    \"--with_prior_preservation\",\n    default=False,\n    action=\"store_true\",\n    help=\"Flag to add prior preservation loss.\",\n)\nparser.add_argument(\"--prior_loss_weight\", type=float, default=1.0, help=\"The weight of prior preservation loss.\")\nparser.add_argument(\n    \"--num_class_images\",\n    type=int,\n    default=100,\n    help=(\n        \"Minimal class images for prior preservation loss. If there are not enough images already present in\"\n        \" class_data_dir, additional images will be sampled with class_prompt.\"\n    ),\n)\nparser.add_argument(\n    \"--output_dir\",\n    type=str,\n", "metadata": {"task_id": "huggingface_diffusers/75", "ground_truth": "    parser.add_argument(", "fpath_tuple": ["huggingface_diffusers", "examples", "research_projects", "multi_subject_dreambooth", "train_multi_subject_dreambooth.py"], "context_start_lineno": 89, "line_no": 265, "query_window": {"context": "            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )", "metadata": {"fpath_tuple": ["huggingface_diffusers", "examples", "research_projects", "multi_subject_dreambooth", "train_multi_subject_dreambooth.py"], "line_no": 265, "task_id": "huggingface_diffusers/75", "start_line_no": 245, "end_line_no": 265, "window_size": 20, "context_start_lineno": 89, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )\n    parser.add_argument(", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "textual_inversion", "textual_inversion.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.8677685950413223}, {"context": "        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )\n    parser.add_argument(\n        \"--mixed_precision\",\n        type=str,\n        default=None,\n        choices=[\"no\", \"fp16\", \"bf16\"],", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "dreambooth", "train_dreambooth_lora.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "dreambooth", "train_dreambooth.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "research_projects", "multi_subject_dreambooth", "train_multi_subject_dreambooth.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.7819548872180451}, {"context": "        \"--logging_dir\",\n        type=str,\n        default=\"logs\",\n        help=(\n            \"[TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to\"\n            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "dreambooth", "train_dreambooth_lora.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "dreambooth", "train_dreambooth.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}, {"fpath_tuple": ["huggingface_diffusers", "examples", "research_projects", "multi_subject_dreambooth", "train_multi_subject_dreambooth.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.674074074074074}, {"context": "        type=str,\n        default=None,\n        help=\"The name of the repository to keep in sync with the local `output_dir`.\",\n    )\n    parser.add_argument(\n        \"--logging_dir\",\n        type=str,\n        default=\"logs\",\n        help=(\n            \"[TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to\"\n            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "text_to_image", "train_text_to_image_flax.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5448275862068965}, {"context": "            \" *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.\"\n        ),\n    )\n    parser.add_argument(\n        \"--report_to\",\n        type=str,\n        default=\"tensorboard\",\n        help=(\n            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n        ),\n    )\n    parser.add_argument(\n        \"--mixed_precision\",\n        type=str,\n        default=\"no\",\n        choices=[\"no\", \"fp16\", \"bf16\"],\n        help=(\n            \"Whether to use mixed precision. Choose\"\n            \"between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.\"", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "text_to_image", "train_text_to_image_flax.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.5369127516778524}, {"context": "    )\n    parser.add_argument(\n        \"--mixed_precision\",\n        type=str,\n        default=\"no\",\n        choices=[\"no\", \"fp16\", \"bf16\"],\n        help=(\n            \"Whether to use mixed precision. Choose\"\n            \"between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.\"\n            \"and an Nvidia Ampere GPU.\"\n        ),\n    )\n    parser.add_argument(\n        \"--allow_tf32\",\n        action=\"store_true\",\n        help=(\n            \"Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see\"\n            \" https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\"\n        ),\n    )", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "textual_inversion", "textual_inversion.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.506578947368421}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n# \n#     def empty_cache(self):\n#         self.__dict__[\"_parent\"] = None\n# \n# \n# class TransformedEnv(EnvBase):\n#     \"\"\"A transformed_in environment.\n# \n#     Args:\n#         env (EnvBase): original environment to be transformed_in.\n#         transform (Transform, optional): transform to apply to the tensordict resulting\n#             from :obj:`env.step(td)`. If none is provided, an empty Compose\n#             placeholder in an eval mode is used.\n#         cache_specs (bool, optional): if True, the specs will be cached once\n#             and for all after the first call (i.e. the specs will be\n#             transformed_in only once). If the transform changes during\n#             training, the original spec transform may not be valid anymore,\n#             in which case this value should be set  to `False`. Default is\n#             `True`.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#                 self._env.reward_spec(), device=self.device\n#             )\n#             if len(reward_spec.shape) == 0:\n#                 reward_spec.shape = torch.Size([1])\n#             self.__dict__[\"_reward_spec\"] = reward_spec\n#         return self._reward_spec\n# \n#     @reward_spec.setter\n#     def reward_spec(self, value: TensorSpec) -> None:\n#         if not hasattr(value, \"shape\"):\n#             raise TypeError(\n#                 f\"reward_spec of type {type(value)} do not have a shape \" f\"attribute.\"\n#             )\n#         if len(value.shape) == 0:\n#             raise RuntimeError(\n#                 \"the reward_spec shape cannot be empty (this error\"\n#                 \" usually comes from trying to set a reward_spec\"\n#                 \" with a null number of dimensions. Try using a multidimensional\"\n#                 \" spec instead, for instance with a singleton dimension at the tail).\"\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#         if self._observation_spec is None:\n#             self._set_properties()\n#         return self._observation_spec\n# \n#     @observation_spec.setter\n#     def observation_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec) and value is not None:\n#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n#         self.__dict__[\"_observation_spec\"] = value\n# \n#     @property\n#     def input_spec(self) -> TensorSpec:\n#         if self._input_spec is None:\n#             self._set_properties()\n#         return self._input_spec\n# \n#     @input_spec.setter\n#     def input_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec) and value is not None:\n#             raise TypeError(\"The type of an input_spec must be Composite.\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#         self.__dict__[\"_input_spec\"] = value\n# \n#     @property\n#     def observation_spec(self) -> TensorSpec:\n#         if self._observation_spec is None:\n#             self.__dict__[\"_observation_spec\"] = _dmcontrol_to_torchrl_spec_transform(\n#                 self._env.observation_spec(), device=self.device\n#             )\n#         return self._observation_spec\n# \n#     @observation_spec.setter\n#     def observation_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec):\n#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n#         self.__dict__[\"_observation_spec\"] = value\n# \n#     @property\n#     def reward_spec(self) -> TensorSpec:\n#         if self._reward_spec is None:\n#             reward_spec = _dmcontrol_to_torchrl_spec_transform(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#         self.__dict__[\"_input_spec\"] = value\n# \n#     @property\n#     def reward_spec(self) -> TensorSpec:\n#         if self._reward_spec is None:\n#             self._set_properties()\n#         return self._reward_spec\n# \n#     @reward_spec.setter\n#     def reward_spec(self, value: TensorSpec) -> None:\n#         if not hasattr(value, \"shape\") and value is not None:\n#             raise TypeError(\n#                 f\"reward_spec of type {type(value)} do not have a shape \" f\"attribute.\"\n#             )\n#         if value is not None and len(value.shape) == 0:\n#             raise RuntimeError(\n#                 \"the reward_spec shape cannot be empty (this error\"\n#                 \" usually comes from trying to set a reward_spec\"\n#                 \" with a null number of dimensions. Try using a multidimensional\"\n#                 \" spec instead, for instance with a singleton dimension at the tail).\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#     @property\n#     def input_spec(self) -> TensorSpec:\n#         if self._input_spec is None:\n#             self._set_properties()\n#         return self._input_spec\n# \n#     @input_spec.setter\n#     def input_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec) and value is not None:\n#             raise TypeError(\"The type of an input_spec must be Composite.\")\n#         self.__dict__[\"_input_spec\"] = value\n# \n#     @property\n#     def reward_spec(self) -> TensorSpec:\n#         if self._reward_spec is None:\n#             self._set_properties()\n#         return self._reward_spec\n# \n#     @reward_spec.setter\n#     def reward_spec(self, value: TensorSpec) -> None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n#     @observation_spec.setter\n#     def observation_spec(self, value: TensorSpec) -> None:\n#         if not isinstance(value, CompositeSpec):\n#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n#         self.__dict__[\"_observation_spec\"] = value\n# \n#     @property\n#     def reward_spec(self) -> TensorSpec:\n#         if self._reward_spec is None:\n#             reward_spec = _dmcontrol_to_torchrl_spec_transform(\n#                 self._env.reward_spec(), device=self.device\n#             )\n#             if len(reward_spec.shape) == 0:\n#                 reward_spec.shape = torch.Size([1])\n#             self.__dict__[\"_reward_spec\"] = reward_spec\n#         return self._reward_spec\n# \n#     @reward_spec.setter\n#     def reward_spec(self, value: TensorSpec) -> None:\n#         if not hasattr(value, \"shape\"):\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nose but with other features that we don't want to loose.\n                transform = [transform]\n            else:\n                for t in transform:\n                    t.reset_parent()\n            env_transform = env.transform\n            if type(env_transform) is not Compose:\n                env_transform.reset_parent()\n                env_transform = [env_transform]\n            else:\n                for t in env_transform:\n                    t.reset_parent()\n            transform = Compose(*env_transform, *transform).to(device)\n        else:\n            self._set_env(env, device)\n            if transform is None:\n                transform = Compose()\n            else:\n                transform = transform.to(device)\n        self.transform = transform\n\n        self._last_obs = None\n        self.cache_specs = cache_specs\n        self.__dict__[\"_reward_spec\"] = None\n        self.__dict__[\"_input_spec\"] = None\n        self.__dict__[\"_observation_spec\"] = None\n        self.batch_size = self.base_env.batch_size\n\n    def _set_env(self, env: EnvBase, device) -> None:\n        if device != env.device:\n            env = env.to(device)\n        self.base_env = env\n        # updates need not be inplace, as transforms may modify values out-place\n        self.base_env._inplace_update = False\n\n    @property\n    def transform(self) -> Transform:\n        return self._transform\n\n    @transform.setter\n    def transform(self, transform: Transform):\n        if not isinstance(transform, Transform):\n            raise ValueError(\n                f\"\"\"Expected a transform of type torchrl.envs.transforms.Transform,\nbut got an object of type {type(transform)}.\"\"\"\n            )\n        prev_transform = self.transform\n        if prev_transform is not None:\n            prev_transform.empty_cache()\n            prev_transform.__dict__[\"_container\"] = None\n        transform.set_container(self)\n        transform.eval()\n        self._transform = transform\n\n    @property\n    def device(self) -> bool:\n        return self.base_env.device\n\n    @device.setter\n    def device(self, value):\n        raise RuntimeError(\"device is a read-only property\")\n\n    @property\n    def batch_locked(self) -> bool:\n        return self.base_env.batch_locked\n\n    @batch_locked.setter\n    def batch_locked(self, value):\n        raise RuntimeError(\"batch_locked is a read-only property\")\n\n    @property\n    def run_type_checks(self) -> bool:\n        return self.base_env.run_type_checks\n\n    @run_type_checks.setter\n    def run_type_checks(self, value):\n        raise RuntimeError(\n            \"run_type_checks is a read-only property for TransformedEnvs\"\n        )\n\n    @property\n    def _inplace_update(self):\n        return self.base_env._inplace_update\n\n    @property\n    def observation_spec(self) -> TensorSpec:\n        \"\"\"Observation spec of the transformed environment.\"\"\"\n        if self._observation_spec is None or not self.cache_specs:\n            observation_spec = self.transform.transform_observation_spec(\n                self.base_env.observation_spec.clone()\n            )\n            if self.cache_specs:\n                self.__dict__[\"_observation_spec\"] = observation_spec\n        else:\n            observation_spec = self._observation_spec\n        return observation_spec\n\n    @property\n    def action_spec(self) -> TensorSpec:\n        \"\"\"Action spec of the transformed environment.\"\"\"\n        return self.input_spec[\"action\"]\n\n    @property\n    def input_spec(self) -> TensorSpec:\n        \"\"\"Action spec of the transformed environment.\"\"\"\n        if self._input_spec is None or not self.cache_specs:\n            input_spec = self.transform.transform_input_spec(\n                self.base_env.input_spec.clone()\n            )\n            if self.cache_specs:\n                self.__dict__[\"_input_spec\"] = input_spec\n        else:\n            input_spec = self._input_spec\n        return input_spec\n\n    @property\n    def reward_spec(self) -> TensorSpec:\n        \"\"\"Reward spec of the transformed environment.\"\"\"\n        if self._reward_spec is None or not self.cache_specs:\n            reward_spec = self.transform.transform_reward_spec(\n                self.base_env.reward_spec.clone()\n            )\n            if self.cache_specs:\n                self.__dict__[\"_reward_spec\"] = reward_spec\n        else:\n            reward_spec = self._reward_spec\n        return reward_spec\n\n    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n        tensordict = tensordict.clone(False)\n        tensordict_in = self.transform.inv(tensordict)\n        tensordict_out = self.base_env._step(tensordict_in)\n        tensordict_out = (\n            tensordict_out.update(  # update the output with the original tensordict\n                tensordict.exclude(\n                    *tensordict_out.keys()\n                )  # exclude the newly written keys\n            )\n        )\n        next_tensordict = self.transform._step(tensordict_out)\n        # tensordict_out.update(next_tensordict, inplace=False)\n\n        return next_tensordict\n\n    def set_seed(\n        self, seed: Optional[int] = None, static_seed: bool = False\n    ) -> Optional[int]:\n        \"\"\"Set the seeds of the environment.\"\"\"\n        return self.base_env.set_seed(seed, static_seed=static_seed)\n\n    def _set_seed(self, seed: Optional[int]):\n        \"\"\"This method is not used in transformed envs.\"\"\"\n        pass\n\n    def _reset(self, tensordict: Optional[TensorDictBase] = None, **kwargs):\n        if tensordict is not None:\n            tensordict = tensordict.clone(recurse=False)\n        out_tensordict = self.base_env.reset(tensordict=tensordict, **kwargs)\n        out_tensordict = self.transform.reset(out_tensordict)\n        out_tensordict = self.transform(out_tensordict)\n        return out_tensordict\n\n    def state_dict(self) -> OrderedDict:\n        state_dict = self.transform.state_dict()\n        return state_dict\n\n    def load_state_dict(self, state_dict: OrderedDict, **kwargs) -> None:\n        self.transform.load_state_dict(state_dict, **kwargs)\n\n    def eval(self) -> TransformedEnv:\n        if \"transform\" in self.__dir__():\n            # when calling __init__, eval() is called but transforms are not set\n            # yet.\n            self.transform.eval()\n        return self\n\n    def train(self, mode: bool = True) -> TransformedEnv:\n        self.transform.train(mode)\n        return self\n\n    @property\n    def is_closed(self) -> bool:\n        return self.base_env.is_closed\n\n    @is_closed.setter\n    def is_closed(self, value: bool):\n        self.base_env.is_closed = value\n\n    def close(self):\n        self.base_env.close()\n        self.is_closed = True\n\n    def empty_cache(self):\n        self.__dict__[\"_observation_spec\"] = None\n        self.__dict__[\"_input_spec\"] = None\n        self.__dict__[\"_reward_spec\"] = None\n\n    def append_transform(self, transform: Transform) -> None:\n        self._erase_metadata()\n        if not isinstance(transform, Transform):\n            raise ValueError(\n                \"TransformedEnv.append_transform expected a transform but received an object of \"", "completion": "type {type(transform)}.\"\n            )\n        self.transform.append(transform)\n\n    def reset_transform(self) -> None:\n        self._erase_metadata()\n        self.transform.reset()\n\n    def _erase_metadata(self) -> None:\n        self.empty_cache()\n        self.transform.empty_cache()", "metadata": {"task_id": "pytorch_rl/98", "ground_truth": "                f\"type {type(transform)} instead.\"", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "context_start_lineno": 316, "line_no": 518, "query_window": {"context": "        return self.base_env.is_closed\n\n    @is_closed.setter\n    def is_closed(self, value: bool):\n        self.base_env.is_closed = value\n\n    def close(self):\n        self.base_env.close()\n        self.is_closed = True\n\n    def empty_cache(self):\n        self.__dict__[\"_observation_spec\"] = None\n        self.__dict__[\"_input_spec\"] = None\n        self.__dict__[\"_reward_spec\"] = None\n\n    def append_transform(self, transform: Transform) -> None:\n        self._erase_metadata()\n        if not isinstance(transform, Transform):\n            raise ValueError(\n                \"TransformedEnv.append_transform expected a transform but received an object of \"", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 518, "task_id": "pytorch_rl/98", "start_line_no": 498, "end_line_no": 518, "window_size": 20, "context_start_lineno": 316, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        self.__dict__[\"_input_spec\"] = value\n\n    @property\n    def observation_spec(self) -> TensorSpec:\n        if self._observation_spec is None:\n            self.__dict__[\"_observation_spec\"] = _dmcontrol_to_torchrl_spec_transform(\n                self._env.observation_spec(), device=self.device\n            )\n        return self._observation_spec\n\n    @observation_spec.setter\n    def observation_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec):\n            raise TypeError(\"The type of an observation_spec must be Composite.\")\n        self.__dict__[\"_observation_spec\"] = value\n\n    @property\n    def reward_spec(self) -> TensorSpec:\n        if self._reward_spec is None:\n            reward_spec = _dmcontrol_to_torchrl_spec_transform(", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45544554455445546}, {"context": "        if self._observation_spec is None:\n            self._set_properties()\n        return self._observation_spec\n\n    @observation_spec.setter\n    def observation_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec) and value is not None:\n            raise TypeError(\"The type of an observation_spec must be Composite.\")\n        self.__dict__[\"_observation_spec\"] = value\n\n    @property\n    def input_spec(self) -> TensorSpec:\n        if self._input_spec is None:\n            self._set_properties()\n        return self._input_spec\n\n    @input_spec.setter\n    def input_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec) and value is not None:\n            raise TypeError(\"The type of an input_spec must be Composite.\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45054945054945056}, {"context": "    @property\n    def input_spec(self) -> TensorSpec:\n        if self._input_spec is None:\n            self._set_properties()\n        return self._input_spec\n\n    @input_spec.setter\n    def input_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec) and value is not None:\n            raise TypeError(\"The type of an input_spec must be Composite.\")\n        self.__dict__[\"_input_spec\"] = value\n\n    @property\n    def reward_spec(self) -> TensorSpec:\n        if self._reward_spec is None:\n            self._set_properties()\n        return self._reward_spec\n\n    @reward_spec.setter\n    def reward_spec(self, value: TensorSpec) -> None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.43956043956043955}, {"context": "                action=_dmcontrol_to_torchrl_spec_transform(\n                    self._env.action_spec(), device=self.device\n                )\n            )\n        return self._input_spec\n\n    @input_spec.setter\n    def input_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec):\n            raise TypeError(\"The type of an input_spec must be Composite.\")\n        self.__dict__[\"_input_spec\"] = value\n\n    @property\n    def observation_spec(self) -> TensorSpec:\n        if self._observation_spec is None:\n            self.__dict__[\"_observation_spec\"] = _dmcontrol_to_torchrl_spec_transform(\n                self._env.observation_spec(), device=self.device\n            )\n        return self._observation_spec\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4230769230769231}, {"context": "        if self._device is None:\n            self._set_properties()\n        return self._device\n\n    @device.setter\n    def device(self, value: DEVICE_TYPING) -> None:\n        self.to(value)\n\n    @property\n    def observation_spec(self) -> TensorSpec:\n        if self._observation_spec is None:\n            self._set_properties()\n        return self._observation_spec\n\n    @observation_spec.setter\n    def observation_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec) and value is not None:\n            raise TypeError(\"The type of an observation_spec must be Composite.\")\n        self.__dict__[\"_observation_spec\"] = value\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.40816326530612246}, {"context": "    @observation_spec.setter\n    def observation_spec(self, value: TensorSpec) -> None:\n        if not isinstance(value, CompositeSpec):\n            raise TypeError(\"The type of an observation_spec must be Composite.\")\n        self.__dict__[\"_observation_spec\"] = value\n\n    @property\n    def reward_spec(self) -> TensorSpec:\n        if self._reward_spec is None:\n            reward_spec = _dmcontrol_to_torchrl_spec_transform(\n                self._env.reward_spec(), device=self.device\n            )\n            if len(reward_spec.shape) == 0:\n                reward_spec.shape = torch.Size([1])\n            self.__dict__[\"_reward_spec\"] = reward_spec\n        return self._reward_spec\n\n    @reward_spec.setter\n    def reward_spec(self, value: TensorSpec) -> None:\n        if not hasattr(value, \"shape\"):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.40707964601769914}, {"context": "                            break\n                        transform = orig_trans.clone()\n                        transform.reset_parent()\n                        out.append_transform(transform)\n            elif isinstance(container, TransformedEnv):\n                out = TransformedEnv(container.base_env)\n            else:\n                raise ValueError(f\"container is of type {type(container)}\")\n            self.__dict__[\"_parent\"] = out\n        return self.__dict__[\"_parent\"]\n\n    def empty_cache(self):\n        self.__dict__[\"_parent\"] = None\n\n\nclass TransformedEnv(EnvBase):\n    \"\"\"A transformed_in environment.\n\n    Args:\n        env (EnvBase): original environment to be transformed_in.", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3669724770642202}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/league/player.py\n# --------------------------------------------------\n# from typing import Callable, Optional, List\n# from collections import namedtuple\n# import numpy as np\n# from easydict import EasyDict\n# \n# from ding.utils import import_module, PLAYER_REGISTRY\n# from .algorithm import pfsp\n# \n# \n# class Player:\n#     \"\"\"\n#     Overview:\n#         Base player class, player is the basic member of a league\n#     Interfaces:\n#         __init__\n#     Property:\n#         race, payoff, checkpoint_path, player_id, total_agent_step\n#     \"\"\"\n#     _name = \"BasePlayer\"  # override this variable for sub-class player\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/torch_utils/network/soft_argmax.py\n# --------------------------------------------------\n# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# \n# \n# class SoftArgmax(nn.Module):\n#     r\"\"\"\n#     Overview:\n#         An nn.Module that computes SoftArgmax\n#     Interface:\n#         __init__, forward\n# \n#     .. note:\n# \n#         For more softargmax info, you can refere to\n#         the wiki page <https://wikimili.com/en/Softmax_function> or\n#         the lecture <https://mc.ai/softmax-function-beyond-the-basics/>\n# \n#     \"\"\"\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/fake_linklink.py\n# --------------------------------------------------\n# from collections import namedtuple\n# \n# \n# class FakeClass:\n# \n#     def __init__(self, *args, **kwargs):\n#         pass\n# \n# \n# class FakeNN:\n#     SyncBatchNorm2d = FakeClass\n# \n# \n# class FakeLink:\n#     nn = FakeNN()\n#     syncbnVarMode_t = namedtuple(\"syncbnVarMode_t\", \"L2\")(L2=None)\n#     allreduceOp_t = namedtuple(\"allreduceOp_t\", ['Sum', 'Max'])\n# \n# \n# link = FakeLink()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/common/utils.py\n# --------------------------------------------------\n# import torch\n# from easydict import EasyDict\n# from ding.utils import import_module, MODEL_REGISTRY\n# \n# \n# def create_model(cfg: EasyDict) -> torch.nn.Module:\n#     r\"\"\"\n#     Overview:\n#         Creat model given config dictionary\n#     Arguments:\n#         - cfg: (:obj:`dict`):\n#             The trainning configuration, the key ``import_name`` is\n#             used to import module, and they key ``type`` is used to build model.\n#     Returns:\n#         - (:obj:`torch.nn.Module`) The corresponding model.\n#     \"\"\"\n#     import_module(cfg.pop('import_names', []))\n#     # must use pop\n#     return MODEL_REGISTRY.build(cfg.pop(\"type\"), **cfg)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/replay_buffer/base_buffer.py\n# --------------------------------------------------\n# from typing import Union, Dict, Any, List\n# from abc import ABC, abstractmethod\n# import copy\n# from easydict import EasyDict\n# \n# from ding.utils import import_module, BUFFER_REGISTRY\n# \n# \n# class IBuffer(ABC):\n#     r\"\"\"\n#     Overview:\n#         Buffer interface\n#     Interfaces:\n#         default_config, push, update, sample, clear, count, state_dict, load_state_dict\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls) -> EasyDict:\n#         r\"\"\"\n#         Overview:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/policy_factory.py\n# --------------------------------------------------\n# from typing import Dict, Any, Callable\n# from collections import namedtuple\n# import numpy as np\n# \n# from ding.torch_utils import to_device\n# \n# \n# class PolicyFactory:\n#     r\"\"\"\n#     Overview:\n#         Pure random policy. Only used for initial sample collecting if `cfg.policy.random_collect_size` > 0.\n#     \"\"\"\n# \n#     @staticmethod\n#     def get_random_policy(\n#             policy: 'BasePolicy',  # noqa\n#             action_space: 'EnvElementInfo' = None,  # noqa\n#             forward_fn: Callable = None,\n#     ) -> None:\n#         assert not (action_space is None and forward_fn is None)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/coordinator/base_parallel_commander.py\n# --------------------------------------------------\n#     Overview:\n#         Base parallel commander abstract class.\n#     Interface:\n#         get_collector_task\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls: type) -> EasyDict:\n#         cfg = EasyDict(copy.deepcopy(cls.config))\n#         cfg.cfg_type = cls.__name__ + 'Dict'\n#         return cfg\n# \n#     @abstractmethod\n#     def get_collector_task(self) -> dict:\n#         raise NotImplementedError\n# \n#     def judge_collector_finish(self, task_id: str, info: dict) -> bool:\n#         collector_done = info.get('collector_done', False)\n#         if collector_done:\n#             return True\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/reward_model/base_reward_model.py\n# --------------------------------------------------\n# from abc import ABC, abstractmethod\n# from easydict import EasyDict\n# import copy\n# from ding.utils import REWARD_MODEL_REGISTRY, import_module\n# \n# \n# class BaseRewardModel(ABC):\n#     \"\"\"\n#     Overview:\n#         the base class of reward model\n#     Interface:\n#         ``default_config``, ``estimate``, ``train``, ``clear_data``, ``collect_data``, ``load_expert_date``\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls: type) -> EasyDict:\n#         cfg = EasyDict(copy.deepcopy(cls.config))\n#         cfg.cfg_type = cls.__name__ + 'Dict'\n#         return cfg\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/coordinator/base_parallel_commander.py\n# --------------------------------------------------\n# from abc import ABC, abstractmethod\n# from collections import defaultdict\n# from easydict import EasyDict\n# import copy\n# \n# from ding.utils import import_module, COMMANDER_REGISTRY, LimitedSpaceContainer\n# \n# \n# class BaseCommander(ABC):\n#     r\"\"\"\n#     Overview:\n#         Base parallel commander abstract class.\n#     Interface:\n#         get_collector_task\n#     \"\"\"\n# \n#     @classmethod\n#     def default_config(cls: type) -> EasyDict:\n#         cfg = EasyDict(copy.deepcopy(cls.config))\n#         cfg.cfg_type = cls.__name__ + 'Dict'\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom collections import namedtuple\nfrom easydict import EasyDict\nimport copy\n\n\nclass BaseSerialCommander(object):\n    r\"\"\"\n    Overview:\n        Base serial commander class.\n    Interface:", "completion": "get_collector_task, judge_collector_finish", "metadata": {"task_id": "opendilab_ACE/164", "ground_truth": "        __init__, step", "fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "base_serial_commander.py"], "context_start_lineno": 0, "line_no": 10, "query_window": {"context": "from collections import namedtuple\nfrom easydict import EasyDict\nimport copy\n\n\nclass BaseSerialCommander(object):\n    r\"\"\"\n    Overview:\n        Base serial commander class.\n    Interface:", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "base_serial_commander.py"], "line_no": 10, "task_id": "opendilab_ACE/164", "start_line_no": 0, "end_line_no": 10, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "from abc import ABC, abstractmethod\nfrom collections import defaultdict\nfrom easydict import EasyDict\nimport copy\n\nfrom ding.utils import import_module, COMMANDER_REGISTRY, LimitedSpaceContainer\n\n\nclass BaseCommander(ABC):\n    r\"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "base_parallel_commander.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.4}, {"context": "from abc import ABC, abstractmethod\nfrom easydict import EasyDict\nimport copy\nfrom ding.utils import REWARD_MODEL_REGISTRY, import_module\n\n\nclass BaseRewardModel(ABC):\n    \"\"\"\n    Overview:\n        the base class of reward model", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "reward_model", "base_reward_model.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.35}, {"context": "from abc import ABC, abstractmethod\nfrom collections import defaultdict\nfrom easydict import EasyDict\nimport copy\n\nfrom ding.utils import import_module, COMMANDER_REGISTRY, LimitedSpaceContainer\n\n\nclass BaseCommander(ABC):\n    r\"\"\"\n    Overview:\n        Base parallel commander abstract class.\n    Interface:\n        get_collector_task\n    \"\"\"\n\n    @classmethod\n    def default_config(cls: type) -> EasyDict:\n        cfg = EasyDict(copy.deepcopy(cls.config))\n        cfg.cfg_type = cls.__name__ + 'Dict'", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "base_parallel_commander.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3373493975903614}, {"context": "from typing import Dict, Any, Callable\nfrom collections import namedtuple\nimport numpy as np\n\nfrom ding.torch_utils import to_device\n\n\nclass PolicyFactory:\n    r\"\"\"\n    Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "policy_factory.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.32075471698113206}, {"context": "from typing import Union, Dict, Any, List\nfrom abc import ABC, abstractmethod\nimport copy\nfrom easydict import EasyDict\n\nfrom ding.utils import import_module, BUFFER_REGISTRY\n\n\nclass IBuffer(ABC):\n    r\"\"\"", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "replay_buffer", "base_buffer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3157894736842105}, {"context": "import torch\nfrom easydict import EasyDict\nfrom ding.utils import import_module, MODEL_REGISTRY\n\n\ndef create_model(cfg: EasyDict) -> torch.nn.Module:\n    r\"\"\"\n    Overview:\n        Creat model given config dictionary\n    Arguments:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "common", "utils.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.3}, {"context": "from collections import namedtuple\n\n\nclass FakeClass:\n\n    def __init__(self, *args, **kwargs):\n        pass\n\n\nclass FakeNN:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "fake_linklink.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2916666666666667}, {"context": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass SoftArgmax(nn.Module):\n    r\"\"\"\n    Overview:\n        An nn.Module that computes SoftArgmax\n    Interface:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "torch_utils", "network", "soft_argmax.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2857142857142857}, {"context": "from typing import Callable, Optional, List\nfrom collections import namedtuple\nimport numpy as np\nfrom easydict import EasyDict\n\nfrom ding.utils import import_module, PLAYER_REGISTRY\nfrom .algorithm import pfsp\n\n\nclass Player:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "league", "player.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2833333333333333}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_joint.py\n# --------------------------------------------------\n#                 shape_inputs=self.shape_inputs,\n#                 output_dim=self.output_dim,\n#                 output_type=\"continuous\",\n#             )\n#         )\n# \n#         self.params = FrozenDict(\n#             dict(\n#                 model=self.joint.likelihood.model_manager.model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#                 lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#     def test_lik_log_batched_joint_prob(self):\n#         for batch in self.data_arr:\n#             log_joint_prob, aux = self.joint._batched_log_joint_prob(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_output_maker.py\n# --------------------------------------------------\n#         )\n# \n#     def test_regressor_model_manager_apply(self):\n#         regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n#         params = FrozenDict(\n#             dict(\n#                 model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n#                 lik_log_var=self.model.init(\n#                     self.rng, jnp.zeros((2,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#         inputs = make_array_random_inputs(\n#             n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n#         )\n#         assert regressor_model_manager.apply(params, inputs).shape == (\n#             self.n_inputs,\n#             2 * self.output_dim,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_joint.py\n# --------------------------------------------------\n#         )\n# \n#         self.params = FrozenDict(\n#             dict(\n#                 model=self.joint.likelihood.model_manager.model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#                 lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#     def test_lik_log_batched_joint_prob(self):\n#         for batch in self.data_arr:\n#             log_joint_prob, aux = self.joint._batched_log_joint_prob(\n#                 self.params, batch, n_data=batch[1].shape[0], return_aux=[\"outputs\"]\n#             )\n#             assert jnp.array([log_joint_prob]).shape == (1,)\n#             assert aux[\"outputs\"].shape == (self.n_inputs, 2 * self.output_dim)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_output_maker.py\n# --------------------------------------------------\n#             n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n#         )\n#         assert classifier_model_manager.apply(params, inputs).shape == (\n#             self.n_inputs,\n#             self.output_dim,\n#         )\n# \n#     def test_regressor_model_manager_apply(self):\n#         regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n#         params = FrozenDict(\n#             dict(\n#                 model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n#                 lik_log_var=self.model.init(\n#                     self.rng, jnp.zeros((2,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#         inputs = make_array_random_inputs(\n#             n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_joint.py\n# --------------------------------------------------\n#         )\n# \n#         self.params = FrozenDict(\n#             dict(\n#                 model=self.joint.likelihood.model_manager.model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#                 lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n#                     self.rng, jnp.zeros((1,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#     def test_lik_log_batched_joint_prob(self):\n#         for batch in self.data_arr:\n#             log_joint_prob, aux = self.joint._batched_log_joint_prob(\n#                 self.params, batch, n_data=batch[1].shape[0], return_aux=[\"outputs\"]\n#             )\n#             assert jnp.array([log_joint_prob]).shape == (1,)\n#             assert aux[\"outputs\"].shape == (self.n_inputs, 2 * self.output_dim)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/test_output_maker.py\n# --------------------------------------------------\n#         )\n# \n#     def test_regressor_model_manager_apply(self):\n#         regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n#         params = FrozenDict(\n#             dict(\n#                 model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n#                 lik_log_var=self.model.init(\n#                     self.rng, jnp.zeros((2,) + self.shape_inputs)\n#                 ),\n#             )\n#         )\n# \n#         inputs = make_array_random_inputs(\n#             n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n#         )\n#         assert regressor_model_manager.apply(params, inputs).shape == (\n#             self.n_inputs,\n#             2 * self.output_dim,\n#         )\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nsLoader\nfrom fortuna.model.mlp import MLP\nfrom fortuna.model.model_manager.classification import \\\n    ClassificationModelManager\nfrom fortuna.model.model_manager.regression import RegressionModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_model.likelihood.classification import \\\n    ClassificationLikelihood\nfrom fortuna.prob_model.likelihood.regression import RegressionLikelihood\nfrom fortuna.prob_output_layer.classification import \\\n    ClassificationProbOutputLayer\nfrom fortuna.prob_output_layer.regression import RegressionProbOutputLayer\nfrom fortuna.utils.random import RandomNumberGenerator\nfrom tests.make_data import (make_array_random_data,\n                             make_generator_fun_random_data)\n\n\nclass TestLikelihoods(unittest.TestCase):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.shape_inputs = (3,)\n        self.n_inputs = 10\n        self.output_dim = 2\n        self.n_batches = 2\n        self.batch_size = 3\n        self.rng = random.PRNGKey(0)\n        rng = RandomNumberGenerator(seed=0)\n        reg_prob_output_layer = RegressionProbOutputLayer()\n        reg_prob_output_layer.rng = rng\n        self.reg_lik = RegressionLikelihood(\n            model_manager=RegressionModelManager(\n                model=MLP(output_dim=self.output_dim),\n                likelihood_log_variance_model=MLP(output_dim=self.output_dim),\n            ),\n            output_calib_manager=OutputCalibManager(output_calibrator=None),\n            prob_output_layer=reg_prob_output_layer,\n        )\n        self.reg_lik.rng = rng\n        class_prob_output_layer = ClassificationProbOutputLayer()\n        class_prob_output_layer.rng = rng\n        self.class_lik = ClassificationLikelihood(\n            model_manager=ClassificationModelManager(\n                model=MLP(output_dim=self.output_dim)\n            ),\n            output_calib_manager=OutputCalibManager(output_calibrator=None),\n            prob_output_layer=class_prob_output_layer,\n        )\n        self.class_lik.rng = rng\n\n        self.reg_data_arr = DataLoader.from_array_data(\n            make_array_random_data(\n                n_data=self.n_inputs,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n        self.reg_inputs_arr = InputsLoader.from_data_loader(self.reg_data_arr)\n\n        self.reg_data_gen_fun = DataLoader.from_callable_iterable(\n            make_generator_fun_random_data(\n                n_batches=self.n_batches,\n                batch_size=self.batch_size,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n        self.reg_inputs_gen_fun = InputsLoader.from_data_loader(self.reg_data_gen_fun)\n\n        self.class_data_arr = DataLoader.from_array_data(\n            make_array_random_data(\n                n_data=self.n_inputs,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"discrete\",\n            )\n        )\n        self.class_inputs_arr = InputsLoader.from_data_loader(self.class_data_arr)\n\n        self.class_data_gen_fun = DataLoader.from_callable_iterable(\n            make_generator_fun_random_data(\n                n_batches=self.n_batches,\n                batch_size=self.batch_size,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"discrete\",\n            )\n        )\n        self.class_inputs_gen_fun = InputsLoader.from_data_loader(\n            self.class_data_gen_fun\n        )\n\n    def test_lik_batched_log_joint_prob(self):\n        params = FrozenDict(\n            dict(\n                model=self.reg_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.reg_lik.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        for batch_data in self.reg_data_arr:\n            batched_log_joint_prob1 = self.reg_lik._batched_log_joint_prob(\n                params, batch_data, n_data=batch_data[1].shape[0]\n            )\n            batched_log_joint_prob2 = self.reg_lik._batched_log_joint_prob(\n                params, batch_data, n_data=2 * batch_data[1].shape[0]\n            )\n            assert jnp.allclose(batched_log_joint_prob2, 2 * batched_log_joint_prob1)\n            assert jnp.array([batched_log_joint_prob1]).shape == (1,)\n\n            _, aux = self.reg_lik._batched_log_joint_prob(\n                params,\n                batch_data,\n                n_data=batch_data[1].shape[0],\n                return_aux=[\"outputs\"],\n            )\n            assert aux[\"outputs\"].shape == (self.n_inputs, 2 * self.output_dim)\n\n    def test_lik_log_joint_prob(self):\n        params = FrozenDict(\n            dict(\n                model=self.reg_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.reg_lik.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        log_probs = self.reg_lik.log_prob(params, self.reg_data_arr)\n        assert log_probs.shape == (self.n_inputs,)\n\n        log_probs = self.reg_lik.log_prob(params, self.reg_data_gen_fun)\n        assert log_probs.shape == (self.n_batches * self.batch_size,)\n\n    def test_sample(self):\n        params = FrozenDict(\n            dict(\n                model=self.reg_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.reg_lik.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        samples = self.reg_lik.sample(10, params, self.reg_inputs_arr)\n        assert samples.shape == (10, self.n_inputs, self.output_dim)\n\n        params = FrozenDict(\n            dict(\n                model=self.class_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)", "completion": "", "metadata": {"task_id": "awslabs_fortuna/29", "ground_truth": "                ),", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_likelihood.py"], "context_start_lineno": 6, "line_no": 167, "query_window": {"context": "\n    def test_sample(self):\n        params = FrozenDict(\n            dict(\n                model=self.reg_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.reg_lik.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        samples = self.reg_lik.sample(10, params, self.reg_inputs_arr)\n        assert samples.shape == (10, self.n_inputs, self.output_dim)\n\n        params = FrozenDict(\n            dict(\n                model=self.class_lik.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_likelihood.py"], "line_no": 167, "task_id": "awslabs_fortuna/29", "start_line_no": 147, "end_line_no": 167, "window_size": 20, "context_start_lineno": 6, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n        )\n        assert classifier_model_manager.apply(params, inputs).shape == (\n            self.n_inputs,\n            self.output_dim,\n        )\n\n    def test_regressor_model_manager_apply(self):\n        regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n        params = FrozenDict(\n            dict(\n                model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n                lik_log_var=self.model.init(\n                    self.rng, jnp.zeros((2,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        inputs = make_array_random_inputs(\n            n_inputs=self.n_inputs, shape_inputs=self.shape_inputs", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_output_maker.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6463414634146342}, {"context": "                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n\n        self.params = FrozenDict(\n            dict(\n                model=self.joint.likelihood.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n                lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n    def test_lik_log_batched_joint_prob(self):\n        for batch in self.data_arr:\n            log_joint_prob, aux = self.joint._batched_log_joint_prob(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_joint.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6235294117647059}, {"context": "        self.model = MLP(output_dim=self.output_dim)\n        self.lik_log_var = MLP(output_dim=self.output_dim)\n\n    def test_classifier_model_manager_apply(self):\n        classifier_model_manager = ClassificationModelManager(self.model)\n        params = FrozenDict(\n            dict(model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)))\n        )\n\n        inputs = make_array_random_inputs(\n            n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n        )\n        assert classifier_model_manager.apply(params, inputs).shape == (\n            self.n_inputs,\n            self.output_dim,\n        )\n\n    def test_regressor_model_manager_apply(self):\n        regressor_model_manager = RegressionModelManager(self.model, self.lik_log_var)\n        params = FrozenDict(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_output_maker.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5764705882352941}, {"context": "                ),\n                lik_log_var=self.joint.likelihood.model_manager.likelihood_log_variance_model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)\n                ),\n            )\n        )\n\n    def test_lik_log_batched_joint_prob(self):\n        for batch in self.data_arr:\n            log_joint_prob, aux = self.joint._batched_log_joint_prob(\n                self.params, batch, n_data=batch[1].shape[0], return_aux=[\"outputs\"]\n            )\n            assert jnp.array([log_joint_prob]).shape == (1,)\n            assert aux[\"outputs\"].shape == (self.n_inputs, 2 * self.output_dim)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_joint.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 64, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5531914893617021}, {"context": "            dict(\n                model=self.model.init(self.rng, jnp.zeros((2,) + self.shape_inputs)),\n                lik_log_var=self.model.init(\n                    self.rng, jnp.zeros((2,) + self.shape_inputs)\n                ),\n            )\n        )\n\n        inputs = make_array_random_inputs(\n            n_inputs=self.n_inputs, shape_inputs=self.shape_inputs\n        )\n        assert regressor_model_manager.apply(params, inputs).shape == (\n            self.n_inputs,\n            2 * self.output_dim,\n        )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "test_output_maker.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 55, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5512820512820513}, {"context": "                    likelihood_log_variance_model=MLP(output_dim=self.output_dim),\n                ),\n                prob_output_layer=RegressionProbOutputLayer(),\n                output_calib_manager=OutputCalibManager(output_calibrator=None),\n            ),\n        )\n\n        self.data_arr = DataLoader.from_array_data(\n            make_array_random_data(\n                n_data=self.n_inputs,\n                shape_inputs=self.shape_inputs,\n                output_dim=self.output_dim,\n                output_type=\"continuous\",\n            )\n        )\n\n        self.params = FrozenDict(\n            dict(\n                model=self.joint.likelihood.model_manager.model.init(\n                    self.rng, jnp.zeros((1,) + self.shape_inputs)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_joint.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.46534653465346537}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n# \n# \n# class DataLoader:\n#     def __init__(\n#         self,\n#         data_loader: Union[\n#             FromIterableToDataLoader,\n#             FromCallableIterableToDataLoader,\n#             FromArrayDataToDataLoader,\n#             FromTensorFlowDataLoaderToDataLoader,\n#             FromTorchDataLoaderToDataLoader,\n#             ChoppedDataLoader\n#         ],\n#     ):\n#         \"\"\"\n#         A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n#         are arrays, with different data points over the first dimension.\n# \n#         Parameters\n#         ----------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#     @classmethod\n#     def from_iterable(cls, iterable: Iterable[Batch],) -> DataLoader:\n#         \"\"\"\n#         Transform an iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n# \n#         Parameters\n#         ----------\n#         iterable: Iterable[Batch]\n#             An iterable of tuples of input and target arrays.\n# \n#         Returns\n#         -------\n#         DataLoader\n#             A data loader object.\n#         \"\"\"\n#         return cls(data_loader=FromIterableToDataLoader(iterable))\n# \n#     @classmethod\n#     def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         Transform a TensorFlow data loader into a :class:`~fortuna.data.loader.DataLoader` object.\n# \n#         Parameters\n#         ----------\n#         tf_data_loader\n#             A TensorFlow data loader where each batch is a tuple of input and target Tensors.\n# \n#         Returns\n#         -------\n#         DataLoader\n#             A data loader object.\n#         \"\"\"\n#         return cls(\n#             data_loader=FromTensorFlowDataLoaderToDataLoader(\n#                 tf_data_loader=tf_data_loader\n#             )\n#         )\n# \n#     @classmethod\n#     def from_torch_data_loader(cls, torch_data_loader) -> DataLoader:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/classification.py\n# --------------------------------------------------\n#     ) -> Status:\n#         \"\"\"\n#         Calibrate the probabilistic classifier.\n# \n#         Parameters\n#         ----------\n#         calib_data_loader : DataLoader\n#             A calibration data loader.\n#         val_data_loader : DataLoader\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/regression.py\n# --------------------------------------------------\n#         Parameters\n#         ----------\n#         calib_data_loader : DataLoader\n#             A calibration data loader.\n#         val_data_loader : DataLoader\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n#             self._check_output_dim(val_data_loader)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         Returns\n#         -------\n#         DataLoader\n#             A data loader object.\n#         \"\"\"\n#         return cls(data_loader=FromIterableToDataLoader(iterable))\n# \n#     @classmethod\n#     def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n#         \"\"\"\n#         Transform a TensorFlow data loader into a :class:`~fortuna.data.loader.DataLoader` object.\n# \n#         Parameters\n#         ----------\n#         tf_data_loader\n#             A TensorFlow data loader where each batch is a tuple of input and target Tensors.\n# \n#         Returns\n#         -------\n#         DataLoader\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#     def from_array_data(\n#         cls,\n#         data: Batch,\n#         batch_size: Optional[int] = None,\n#         shuffle: bool = False,\n#         prefetch: bool = False,\n#     ) -> DataLoader:\n#         \"\"\"\n#         Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n#         respectively.\n# \n#         Parameters\n#         ----------\n#         data: Batch\n#             Input and target arrays of data.\n#         batch_size: Optional[int]\n#             The batch size. If not given, the data will not be batched.\n#         shuffle: bool\n#             Whether the data loader should shuffle at every call.\n#         prefetch: bool\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#             FromTorchDataLoaderToDataLoader,\n#             ChoppedDataLoader\n#         ],\n#     ):\n#         \"\"\"\n#         A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n#         are arrays, with different data points over the first dimension.\n# \n#         Parameters\n#         ----------\n#         data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n#         FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n#             A data loader.\n#         \"\"\"\n#         self._data_loader = data_loader\n# \n#     def __iter__(self):\n#         yield from self._data_loader()\n# \n#     @classmethod\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n#         FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n#             A data loader.\n#         \"\"\"\n#         self._data_loader = data_loader\n# \n#     def __iter__(self):\n#         yield from self._data_loader()\n# \n#     @classmethod\n#     def from_array_data(\n#         cls,\n#         data: Batch,\n#         batch_size: Optional[int] = None,\n#         shuffle: bool = False,\n#         prefetch: bool = False,\n#     ) -> DataLoader:\n#         \"\"\"\n#         Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n#         respectively.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n where each batch is a tuple of input and target Tensors.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(\n            data_loader=FromTorchDataLoaderToDataLoader(\n                torch_data_loader=torch_data_loader\n            )\n        )\n\n    def to_array_data(self) -> Batch:\n        \"\"\"\n        Reduce a data loader to a tuple of input and target arrays.\n\n        Returns\n        -------\n        Batch\n            Tuple of input and target arrays.\n        \"\"\"\n        inputs, targets = [], []\n        for batch_inputs, batch_targets in self._data_loader():\n            inputs.append(batch_inputs)\n            targets.append(batch_targets)\n        return np.concatenate(inputs, 0), np.concatenate(targets, 0)\n\n    def to_array_inputs(self) -> Array:\n        \"\"\"\n        Reduce a data loader to an array of target data.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        inputs = []\n        for batch_inputs, batch_targets in self._data_loader():\n            inputs.append(batch_inputs)\n        return np.concatenate(inputs, 0)\n\n    def to_array_targets(self) -> Array:\n        \"\"\"\n        Reduce a data loader to an array of target data.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        targets = []\n        for batch_inputs, batch_targets in self._data_loader():\n            targets.append(batch_targets)\n        return np.concatenate(targets, 0)\n\n    def to_inputs_loader(self) -> InputsLoader:\n        \"\"\"\n        Reduce a data loader to an inputs loader.\n\n        Returns\n        -------\n        InputsLoader\n            The inputs loader derived from the data loader.\n        \"\"\"\n        return InputsLoader.from_data_loader(DataLoader(data_loader=self._data_loader))\n\n    def to_targets_loader(self) -> TargetsLoader:\n        \"\"\"\n        Reduce a data loader to a targets loader.\n\n        Returns\n        -------\n        TargetsLoader\n            The targets loader derived from the data loader.\n        \"\"\"\n        return TargetsLoader.from_data_loader(DataLoader(data_loader=self._data_loader))\n\n    @classmethod\n    def chop(cls, data_loader: DataLoader, divisor: int) -> DataLoader:\n        \"\"\"\n        Chop the last part of each batch of the data loader, to make sure the number od data points per batch divides\n        `divisor`.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader\n        divisor : int\n            Number of data points that each batched must divide.\n\n        Returns\n        -------\n        DataLoader\n            A data loader with chopped batches.\n        \"\"\"\n        return cls(data_loader=ChoppedDataLoader(data_loader=data_loader, divisor=divisor))\n\n\nclass InputsLoader:\n    def __init__(\n        self,\n        inputs_loader: Union[\n            FromArrayInputsToInputsLoader,\n            FromDataLoaderToInputsLoader,\n            FromCallableIterableToInputsLoader,\n            FromIterableToInputsLoader,\n            ChoppedInputsLoader\n        ],\n    ):\n        \"\"\"\n        An inputs loader class. Each batch is an array of inputs, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        inputs_loader : Union[FromArrayInputsToInputsLoader, FromDataLoaderToInputsLoader]\n            An inputs loader.\n        \"\"\"\n        self._inputs_loader = inputs_loader\n\n    def __iter__(self):\n        yield from self._inputs_loader()\n\n    @classmethod\n    def from_data_loader(cls, data_loader: DataLoader) -> InputsLoader:\n        \"\"\"\n        Reduce a data loader to an inputs loader.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader.\n        \"\"\"\n        return cls(inputs_loader=FromDataLoaderToInputsLoader(data_loader))\n\n    @classmethod\n    def from_array_inputs(\n        cls,\n        inputs: Array,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ) -> InputsLoader:\n        \"\"\"\n        Build a :class:`~fortuna.data.loader.InputsLoader` object from an array of input data.\n\n        Parameters\n        ----------\n        inputs: Array\n            Input array of data.\n        batch_size: Optional[int]\n            The batch size. If not given, the inputs will not be batched.\n        shuffle: bool\n            Whether the inputs loader should shuffle at every call.\n        prefetch: bool\n            Whether to prefetch the next batch.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader built out of the array of inputs.\n        \"\"\"\n        return cls(\n            inputs_loader=FromArrayInputsToInputsLoader(\n                inputs, batch_size=batch_size, shuffle=shuffle, prefetch=prefetch\n            )\n        )\n\n    def to_array_inputs(self) -> Array:\n        \"\"\"\n        Reduce an inputs loader to an array of inputs.\n\n        Returns\n        -------\n        Array\n            Array of input data.\n        \"\"\"\n        inputs = []\n        for batch_inputs in self._inputs_loader():\n            inputs.append(batch_inputs)\n        return np.concatenate(inputs, 0)\n\n    @classmethod\n    def from_callable_iterable(\n        cls, fun: Callable[[], Iterable[Array]],\n    ) -> InputsLoader:\n        \"\"\"\n        Transform a callable iterable into a :class:`~fortuna.data.loader.InputsLoader` object.\n\n        Parameters\n        ----------\n        fun: Callable[[], Iterable[Array]]\n            A callable iterable of input arrays.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader object.\n        \"\"\"\n        return cls(inputs_loader=FromCallableIterableToInputsLoader(fun))\n\n    @classmethod\n    def from_iterable(cls, iterable: Iterable[Array],) -> InputsLoader:\n        \"\"\"\n        Transform an iterable into a :class:`~fortuna.data.loader.InputsLoader` object.\n\n        Parameters\n        ----------\n        iterable: Iterable[Array]\n            An iterable of input arrays.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader object.\n        \"\"\"\n        return cls(inputs_loader=FromIterableToInputsLoader(iterable))\n\n    @classmethod\n    def chop(cls, inputs_loader: InputsLoader, divisor: int) -> InputsLoader:\n        \"\"\"\n        Chop the last part of each batch of the inputs loader, to make sure the number od data points per batch divides\n        `divisor`.\n\n        Parameters\n        ----------\n        inputs_loader : InputsLoader\n            An inputs loader.\n        divisor : int\n            Number of data points that each batched must divide.\n\n        Returns\n        -------\n        InputsLoader\n            An inputs loader with chopped batches.\n        \"\"\"\n        return cls(inputs_loader=ChoppedInputsLoader(inputs_loader=inputs_loader, divisor=divisor))\n\n\nclass TargetsLoader:\n    def __init__(\n        self,\n        targets_loader: Union[\n            FromArrayTargetsToTargetsLoader,\n            FromDataLoaderToTargetsLoader,\n            FromCallableIterableToTargetsLoader,\n            FromIterableToTargetsLoader,\n            ChoppedTargetsLoader\n        ],\n    ):\n        \"\"\"\n        A targets loader class. Each batch is an array of targets, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        targets_loader : Union[FromArrayTargetsToTargetsLoader, FromDataLoaderToTargetsLoader]\n            A targets loader.\n        \"\"\"\n        self._targets_loader = targets_loader\n\n    def __iter__(self):", "completion": "```\n    def __iter__(self):\n        yield from self._targets_loader()\n```\n\n```python\n    @classmethod\n    def from_data_loader(cls, data_loader: DataLoader) -> TargetsLoader:\n        \"\"\"\n        Reduce a data loader to a targets loader.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader.\n\n        Returns\n        -------\n        TargetsLoader\n            A targets loader.\n        \"\"\"\n        return cls(targets_loader=FromDataLoaderToTargetsLoader(data_loader))\n\n    @classmethod\n    def from_array_targets(\n        cls,\n        targets: Array,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ) -> TargetsLoader:\n        \"\"\"\n        Build a :class:`~fortuna.data.loader.TargetsLoader` object from an array of target data.\n\n        Parameters\n        ----------\n        targets: Array\n            Target array of data.\n        batch_size: Optional[int]\n            The batch size. If not given, the targets will not be batched.\n        shuffle: bool\n            Whether the targets loader should shuffle at every call.\n        prefetch: bool\n            Whether to prefetch the next batch.\n\n        Returns\n        -------\n        TargetsLoader", "metadata": {"task_id": "awslabs_fortuna/148", "ground_truth": "        yield from self._targets_loader()", "fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "context_start_lineno": 136, "line_no": 402, "query_window": {"context": "        self,\n        targets_loader: Union[\n            FromArrayTargetsToTargetsLoader,\n            FromDataLoaderToTargetsLoader,\n            FromCallableIterableToTargetsLoader,\n            FromIterableToTargetsLoader,\n            ChoppedTargetsLoader\n        ],\n    ):\n        \"\"\"\n        A targets loader class. Each batch is an array of targets, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        targets_loader : Union[FromArrayTargetsToTargetsLoader, FromDataLoaderToTargetsLoader]\n            A targets loader.\n        \"\"\"\n        self._targets_loader = targets_loader\n\n    def __iter__(self):", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 402, "task_id": "awslabs_fortuna/148", "start_line_no": 382, "end_line_no": 402, "window_size": 20, "context_start_lineno": 136, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "            FromTorchDataLoaderToDataLoader,\n            ChoppedDataLoader\n        ],\n    ):\n        \"\"\"\n        A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n        are arrays, with different data points over the first dimension.\n\n        Parameters\n        ----------\n        data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n        FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n            A data loader.\n        \"\"\"\n        self._data_loader = data_loader\n\n    def __iter__(self):\n        yield from self._data_loader()\n\n    @classmethod", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6705882352941176}, {"context": "\n\nclass DataLoader:\n    def __init__(\n        self,\n        data_loader: Union[\n            FromIterableToDataLoader,\n            FromCallableIterableToDataLoader,\n            FromArrayDataToDataLoader,\n            FromTensorFlowDataLoaderToDataLoader,\n            FromTorchDataLoaderToDataLoader,\n            ChoppedDataLoader\n        ],\n    ):\n        \"\"\"\n        A data loader class. Each batch is a tuple of input and target variables, respectively. Both inputs and targets\n        are arrays, with different data points over the first dimension.\n\n        Parameters\n        ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6172839506172839}, {"context": "        data_loader : Union[FromIterableToDataLoader, FromCallableIterableToDataLoader, FromArrayDataToDataLoader,\n        FromTensorFlowDataLoaderToDataLoader, FromTorchDataLoaderToDataLoader]\n            A data loader.\n        \"\"\"\n        self._data_loader = data_loader\n\n    def __iter__(self):\n        yield from self._data_loader()\n\n    @classmethod\n    def from_array_data(\n        cls,\n        data: Batch,\n        batch_size: Optional[int] = None,\n        shuffle: bool = False,\n        prefetch: bool = False,\n    ) -> DataLoader:\n        \"\"\"\n        Build a :class:`~fortuna.data.loader.DataLoader` object from a tuple of arrays of input and target variables,\n        respectively.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.37735849056603776}, {"context": "    @classmethod\n    def from_iterable(cls, iterable: Iterable[Batch],) -> DataLoader:\n        \"\"\"\n        Transform an iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        iterable: Iterable[Batch]\n            An iterable of tuples of input and target arrays.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromIterableToDataLoader(iterable))\n\n    @classmethod\n    def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n        \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3106796116504854}, {"context": "\n    def calibrate(\n        self,\n        calib_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_config: CalibConfig = CalibConfig(),\n    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "regression.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3076923076923077}, {"context": "            fit_config,\n            calib_config,\n            **fit_kwargs,\n        )\n\n    def calibrate(\n        self,\n        calib_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_config: CalibConfig = CalibConfig(),\n    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "classification.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3076923076923077}, {"context": "        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromIterableToDataLoader(iterable))\n\n    @classmethod\n    def from_tensorflow_data_loader(cls, tf_data_loader) -> DataLoader:\n        \"\"\"\n        Transform a TensorFlow data loader into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        tf_data_loader\n            A TensorFlow data loader where each batch is a tuple of input and target Tensors.\n\n        Returns\n        -------\n        DataLoader", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3069306930693069}, {"context": "        fun: Callable[[], Iterable[Batch]]\n            A callable iterable of tuples of input and target arrays.\n\n        Returns\n        -------\n        DataLoader\n            A data loader object.\n        \"\"\"\n        return cls(data_loader=FromCallableIterableToDataLoader(fun))\n\n    @classmethod\n    def from_iterable(cls, iterable: Iterable[Batch],) -> DataLoader:\n        \"\"\"\n        Transform an iterable into a :class:`~fortuna.data.loader.DataLoader` object.\n\n        Parameters\n        ----------\n        iterable: Iterable[Batch]\n            An iterable of tuples of input and target arrays.\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3018867924528302}, {"context": "from __future__ import annotations\n\nfrom typing import Callable, Iterable, Optional, Union\n\nimport jax\nimport numpy as np\nfrom flax import jax_utils\nfrom jax.tree_util import tree_map\n\nfrom fortuna.typing import Array, Batch\n\n\nclass DataLoader:\n    def __init__(\n        self,\n        data_loader: Union[\n            FromIterableToDataLoader,\n            FromCallableIterableToDataLoader,\n            FromArrayDataToDataLoader,\n            FromTensorFlowDataLoaderToDataLoader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.28125}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n# \n# \n# class RegressionPredictive(Predictive):\n#     def __init__(\n#         self,\n#         output_calib_manager: OutputCalibManager,\n#         prob_output_layer: RegressionProbOutputLayer,\n#     ):\n#         super().__init__(\n#             output_calib_manager=output_calib_manager,\n#             prob_output_layer=prob_output_layer,\n#         )\n# \n#     def quantile(\n#         self,\n#         q: Union[float, Array, List],\n#         outputs: Array,\n#         n_target_samples: Optional[int] = 30,\n#         rng: Optional[PRNGKeyArray] = None,\n#         calibrated: bool = True,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/predictive/base.py\n# --------------------------------------------------\n#     def __init__(self, posterior: Posterior):\n#         \"\"\"\n#         Predictive distribution abstract class.\n# \n#         Parameters\n#         ----------\n#         posterior : Posterior\n#              A posterior distribution object.\n#         \"\"\"\n#         self.likelihood = posterior.joint.likelihood\n#         self.posterior = posterior\n# \n#     def log_prob(\n#         self,\n#         data_loader: DataLoader,\n#         n_posterior_samples: int = 30,\n#         rng: Optional[PRNGKeyArray] = None,\n#         distribute: bool = True,\n#         **kwargs\n#     ) -> jnp.ndarray:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/predictive/base.py\n# --------------------------------------------------\n# from fortuna.data.loader import (DataLoader,\n#                                  DeviceDimensionAugmentedDataLoader,\n#                                  DeviceDimensionAugmentedInputsLoader,\n#                                  InputsLoader, TargetsLoader)\n# from fortuna.prob_model.posterior.base import Posterior\n# from fortuna.typing import Array, Batch, CalibMutable, CalibParams\n# from fortuna.utils.random import WithRNG\n# \n# \n# class Predictive(WithRNG):\n#     def __init__(self, posterior: Posterior):\n#         \"\"\"\n#         Predictive distribution abstract class.\n# \n#         Parameters\n#         ----------\n#         posterior : Posterior\n#              A posterior distribution object.\n#         \"\"\"\n#         self.likelihood = posterior.joint.likelihood\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/base.py\n# --------------------------------------------------\n# from fortuna.utils.random import WithRNG\n# \n# \n# class Predictive(WithRNG, abc.ABC):\n#     def __init__(\n#         self,\n#         output_calib_manager: OutputCalibManager,\n#         prob_output_layer: ProbOutputLayer,\n#     ):\n#         r\"\"\"\n#         Abstract predictive distribution. It characterizes the distribution of the target variable given the\n#         calibrated outputs. It can be see as :math:`p(y|\\omega)`, where :math:`y` is a target variable and\n#         :math:`\\omega` a calibrated output.\n#         \"\"\"\n#         self.output_calib_manager = output_calib_manager\n#         self.prob_output_layer = prob_output_layer\n#         self.state = None\n# \n#     def log_prob(\n#         self, outputs: Array, targets: Array, calibrated: bool = True, **kwargs\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/likelihood/classification.py\n# --------------------------------------------------\n#     OutputCalibManager\n# from fortuna.prob_model.likelihood.base import Likelihood\n# from fortuna.prob_output_layer.classification import \\\n#     ClassificationProbOutputLayer\n# from fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n# \n# \n# class ClassificationLikelihood(Likelihood):\n#     def __init__(\n#         self,\n#         model_manager: ClassificationModelManager,\n#         prob_output_layer: ClassificationProbOutputLayer,\n#         output_calib_manager: OutputCalibManager,\n#     ):\n#         \"\"\"\n#         A classification likelihood function class. In this class, the likelihood function is additionally assumed to\n#         be a probability density function, i.e. positive and integrating to 1. The likelihood is formed by three\n#         objects applied in sequence: the model manager, the output calibrator and the probabilistic output layer. The\n#         model manager maps parameters and inputs to outputs. The output calibration takes outputs and returns some\n#         calibrated version of them. The probabilistic output layer describes the probability distribution of the\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/joint/base.py\n# --------------------------------------------------\n# from fortuna.prob_model.joint.state import JointState\n# from fortuna.prob_model.likelihood.base import Likelihood\n# from fortuna.prob_model.prior.base import Prior\n# from fortuna.typing import Batch, CalibMutable, CalibParams, Mutable, Params\n# from fortuna.utils.random import WithRNG\n# \n# \n# class Joint(WithRNG):\n#     def __init__(self, prior: Prior, likelihood: Likelihood):\n#         r\"\"\"\n#         Joint distribution class. This is the joint distribution of target variables and random model parameters given\n#         input variables and calibration parameters. It is given by\n# \n#         .. math::\n#             p(y, w|x, \\phi),\n# \n#         where:\n#          - :math:`x` is an observed input variable;\n#          - :math:`y` is an observed target variable;\n#          - :math:`w` denotes the random model parameters;\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/likelihood/regression.py\n# --------------------------------------------------\n#     OutputCalibManager\n# from fortuna.prob_model.likelihood.base import Likelihood\n# from fortuna.prob_output_layer.regression import RegressionProbOutputLayer\n# from fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n# \n# \n# class RegressionLikelihood(Likelihood):\n#     def __init__(\n#         self,\n#         model_manager: RegressionModelManager,\n#         prob_output_layer: RegressionProbOutputLayer,\n#         output_calib_manager: OutputCalibManager,\n#     ):\n#         \"\"\"\n#         A classification likelihood function class. In this class, the likelihood function is additionally assumed to\n#         be a probability density function, i.e. positive and integrating to 1. The likelihood is formed by three\n#         objects applied in sequence: the model manager, the output calibrator and the probabilistic output layer. The\n#         model manager maps parameters and inputs to outputs. The output calibration takes outputs and returns some\n#         calibrated version of them. The probabilistic output layer describes the probability distribution of the\n#         calibrated outputs.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport abc\nfrom typing import Any, Callable, List, Optional, Tuple, Union\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import jit, pmap\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import (DataLoader,\n                                 DeviceDimensionAugmentedDataLoader,\n                                 DeviceDimensionAugmentedInputsLoader,\n                                 InputsLoader)\nfrom fortuna.model.model_manager.base import ModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import (Array, Batch, CalibMutable, CalibParams, Mutable,\n                            Params)\nfrom fortuna.utils.random import WithRNG\n\n\nclass Likelihood(WithRNG):\n    def __init__(\n        self,\n        model_manager: ModelManager,", "completion": "        prob_output_layer: ProbOutputLayer,\n        output_calib_manager: OutputCalibManager,\n    ):\n        \"\"\"\n        Likelihood function abstract class. In this class, the likelihood function is additionally assumed to be a\n        probability density function, i.e. positive and integrating to 1. The likelihood is formed by three objects\n        applied in sequence: the model manager, the output calibrator and the probabilistic output layer. The model\n        manager maps parameters and inputs to outputs. The output calibration takes outputs and returns some calibrated\n        version of them. The probabilistic output layer describes the probability distribution of the calibrated\n        outputs.\n\n        Parameters\n        ----------\n        model_manager : ModelManager\n            A model manager object.\n        prob_output_layer : ProbOutputLayer\n            A probabilistic output layer object.\n        output_calib_manager : OutputCalibManager\n            An output calibrator manager object.\n        \"\"\"\n        self.model_manager = model_manager\n        self.prob_output_layer = prob_output_layer\n        self.output_calib_manager = output_calib_manager\n\n    def log_prob(\n        self,\n        inputs: Array,\n        targets: Array,\n        calibrated: bool = True,\n        **kwargs\n    ) -> j", "metadata": {"task_id": "awslabs_fortuna/104", "ground_truth": "        prob_output_layer: ProbOutputLayer,", "fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "base.py"], "context_start_lineno": 0, "line_no": 25, "query_window": {"context": "from jax import jit, pmap\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import (DataLoader,\n                                 DeviceDimensionAugmentedDataLoader,\n                                 DeviceDimensionAugmentedInputsLoader,\n                                 InputsLoader)\nfrom fortuna.model.model_manager.base import ModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import (Array, Batch, CalibMutable, CalibParams, Mutable,\n                            Params)\nfrom fortuna.utils.random import WithRNG\n\n\nclass Likelihood(WithRNG):\n    def __init__(\n        self,\n        model_manager: ModelManager,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "base.py"], "line_no": 25, "task_id": "awslabs_fortuna/104", "start_line_no": 5, "end_line_no": 25, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "from typing import Optional, Union\n\nimport jax.numpy as jnp\nimport numpy as np\nfrom jax import vmap\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import InputsLoader\nfrom fortuna.model.model_manager.regression import RegressionModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_model.likelihood.base import Likelihood\nfrom fortuna.prob_output_layer.regression import RegressionProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n\n\nclass RegressionLikelihood(Likelihood):\n    def __init__(\n        self,\n        model_manager: RegressionModelManager,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "regression.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.616822429906542}, {"context": "from typing import List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom flax.core import FrozenDict\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.data.loader import DataLoader\nfrom fortuna.model.model_manager.state import ModelManagerState\nfrom fortuna.output_calibrator.output_calib_manager.state import \\\n    OutputCalibManagerState\nfrom fortuna.prob_model.joint.state import JointState\nfrom fortuna.prob_model.likelihood.base import Likelihood\nfrom fortuna.prob_model.prior.base import Prior\nfrom fortuna.typing import Batch, CalibMutable, CalibParams, Mutable, Params\nfrom fortuna.utils.random import WithRNG\n\n\nclass Joint(WithRNG):\n    def __init__(self, prior: Prior, likelihood: Likelihood):\n        r\"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "joint", "base.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5546218487394958}, {"context": "from typing import Optional\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import vmap\n\nfrom fortuna.data.loader import InputsLoader\nfrom fortuna.model.model_manager.classification import \\\n    ClassificationModelManager\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_model.likelihood.base import Likelihood\nfrom fortuna.prob_output_layer.classification import \\\n    ClassificationProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams, Mutable, Params\n\n\nclass ClassificationLikelihood(Likelihood):\n    def __init__(\n        self,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "likelihood", "classification.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5436893203883495}, {"context": "import abc\nfrom typing import Any, List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG, abc.ABC):\n    def __init__(\n        self,\n        output_calib_manager: OutputCalibManager,\n        prob_output_layer: ProbOutputLayer,\n    ):\n        r\"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "base.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5315315315315315}, {"context": "import abc\nfrom typing import Callable, Dict, List, Optional, Tuple, Union\n\nimport jax\nimport jax.numpy as jnp\nimport jax.scipy as jsp\nfrom jax import jit, lax, pmap, random\nfrom jax._src.prng import PRNGKeyArray\nfrom jax.tree_util import tree_map\n\nfrom fortuna.data.loader import (DataLoader,\n                                 DeviceDimensionAugmentedDataLoader,\n                                 DeviceDimensionAugmentedInputsLoader,\n                                 InputsLoader, TargetsLoader)\nfrom fortuna.prob_model.posterior.base import Posterior\nfrom fortuna.typing import Array, Batch, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG):", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "base.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4918032786885246}, {"context": "from fortuna.data.loader import (DataLoader,\n                                 DeviceDimensionAugmentedDataLoader,\n                                 DeviceDimensionAugmentedInputsLoader,\n                                 InputsLoader, TargetsLoader)\nfrom fortuna.prob_model.posterior.base import Posterior\nfrom fortuna.typing import Array, Batch, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG):\n    def __init__(self, posterior: Posterior):\n        \"\"\"\n        Predictive distribution abstract class.\n\n        Parameters\n        ----------\n        posterior : Posterior\n             A posterior distribution object.\n        \"\"\"\n        self.likelihood = posterior.joint.likelihood", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "predictive", "base.py"], "line_no": 20, "start_line_no": 10, "end_line_no": 30, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.49122807017543857}, {"context": "from typing import List, Optional, Union\n\nimport jax.numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.calib_model.predictive.base import Predictive\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.regression import RegressionProbOutputLayer\nfrom fortuna.typing import Array\n\n\nclass RegressionPredictive(Predictive):\n    def __init__(\n        self,\n        output_calib_manager: OutputCalibManager,\n        prob_output_layer: RegressionProbOutputLayer,\n    ):\n        super().__init__(\n            output_calib_manager=output_calib_manager,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.43859649122807015}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/vae.py\n# --------------------------------------------------\n#         sample = self.conv_in(sample)\n# \n#         # down\n#         for down_block in self.down_blocks:\n#             sample = down_block(sample)\n# \n#         # middle\n#         sample = self.mid_block(sample)\n# \n#         # post-process\n#         sample = self.conv_norm_out(sample)\n#         sample = self.conv_act(sample)\n#         sample = self.conv_out(sample)\n# \n#         return sample\n# \n# \n# class Decoder(nn.Module):\n#     def __init__(\n#         self,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/vae_flax.py\n# --------------------------------------------------\n#                 padding=\"VALID\",\n#                 dtype=self.dtype,\n#             )\n# \n#     def __call__(self, hidden_states, deterministic=True):\n#         residual = hidden_states\n#         hidden_states = self.norm1(hidden_states)\n#         hidden_states = nn.swish(hidden_states)\n#         hidden_states = self.conv1(hidden_states)\n# \n#         hidden_states = self.norm2(hidden_states)\n#         hidden_states = nn.swish(hidden_states)\n#         hidden_states = self.dropout_layer(hidden_states, deterministic)\n#         hidden_states = self.conv2(hidden_states)\n# \n#         if self.conv_shortcut is not None:\n#             residual = self.conv_shortcut(residual)\n# \n#         return hidden_states + residual\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_1d_blocks.py\n# --------------------------------------------------\n#         self.group_norm_1 = nn.GroupNorm(1, mid_channels)\n#         self.gelu_1 = nn.GELU()\n#         self.conv_2 = nn.Conv1d(mid_channels, out_channels, 5, padding=2)\n# \n#         if not self.is_last:\n#             self.group_norm_2 = nn.GroupNorm(1, out_channels)\n#             self.gelu_2 = nn.GELU()\n# \n#     def forward(self, hidden_states):\n#         residual = self.conv_skip(hidden_states) if self.has_conv_skip else hidden_states\n# \n#         hidden_states = self.conv_1(hidden_states)\n#         hidden_states = self.group_norm_1(hidden_states)\n#         hidden_states = self.gelu_1(hidden_states)\n#         hidden_states = self.conv_2(hidden_states)\n# \n#         if not self.is_last:\n#             hidden_states = self.group_norm_2(hidden_states)\n#             hidden_states = self.gelu_2(hidden_states)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_1d_blocks.py\n# --------------------------------------------------\n#     def __init__(self, num_groups_out, out_channels, embed_dim, act_fn):\n#         super().__init__()\n#         self.final_conv1d_1 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n#         self.final_conv1d_gn = nn.GroupNorm(num_groups_out, embed_dim)\n#         if act_fn == \"silu\":\n#             self.final_conv1d_act = nn.SiLU()\n#         if act_fn == \"mish\":\n#             self.final_conv1d_act = nn.Mish()\n#         self.final_conv1d_2 = nn.Conv1d(embed_dim, out_channels, 1)\n# \n#     def forward(self, hidden_states, temb=None):\n#         hidden_states = self.final_conv1d_1(hidden_states)\n#         hidden_states = rearrange_dims(hidden_states)\n#         hidden_states = self.final_conv1d_gn(hidden_states)\n#         hidden_states = rearrange_dims(hidden_states)\n#         hidden_states = self.final_conv1d_act(hidden_states)\n#         hidden_states = self.final_conv1d_2(hidden_states)\n#         return hidden_states\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_1d_blocks.py\n# --------------------------------------------------\n#     def forward(self, hidden_states, temb=None):\n#         hidden_states = self.final_conv1d_1(hidden_states)\n#         hidden_states = rearrange_dims(hidden_states)\n#         hidden_states = self.final_conv1d_gn(hidden_states)\n#         hidden_states = rearrange_dims(hidden_states)\n#         hidden_states = self.final_conv1d_act(hidden_states)\n#         hidden_states = self.final_conv1d_2(hidden_states)\n#         return hidden_states\n# \n# \n# class OutValueFunctionBlock(nn.Module):\n#     def __init__(self, fc_dim, embed_dim):\n#         super().__init__()\n#         self.final_block = nn.ModuleList(\n#             [\n#                 nn.Linear(fc_dim + embed_dim, fc_dim // 2),\n#                 nn.Mish(),\n#                 nn.Linear(fc_dim // 2, 1),\n#             ]\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/models/unet_1d_blocks.py\n# --------------------------------------------------\n# class ResConvBlock(nn.Module):\n#     def __init__(self, in_channels, mid_channels, out_channels, is_last=False):\n#         super().__init__()\n#         self.is_last = is_last\n#         self.has_conv_skip = in_channels != out_channels\n# \n#         if self.has_conv_skip:\n#             self.conv_skip = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n# \n#         self.conv_1 = nn.Conv1d(in_channels, mid_channels, 5, padding=2)\n#         self.group_norm_1 = nn.GroupNorm(1, mid_channels)\n#         self.gelu_1 = nn.GELU()\n#         self.conv_2 = nn.Conv1d(mid_channels, out_channels, 5, padding=2)\n# \n#         if not self.is_last:\n#             self.group_norm_2 = nn.GroupNorm(1, out_channels)\n#             self.gelu_2 = nn.GELU()\n# \n#     def forward(self, hidden_states):\n#         residual = self.conv_skip(hidden_states) if self.has_conv_skip else hidden_states\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom functools import partial\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Upsample1D(nn.Module):\n    \"\"\"\n    An upsampling layer with an optional convolution.\n\n    Parameters:\n            channels: channels in the inputs and outputs.\n            use_conv: a bool determining if a convolution is applied.\n            use_conv_transpose:\n            out_channels:\n    \"\"\"\n\n    def __init__(self, channels, use_conv=False, use_conv_transpose=False, out_channels=None, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.use_conv_transpose = use_conv_transpose\n        self.name = name\n\n        self.conv = None\n        if use_conv_transpose:\n            self.conv = nn.ConvTranspose1d(channels, self.out_channels, 4, 2, 1)\n        elif use_conv:\n            self.conv = nn.Conv1d(self.channels, self.out_channels, 3, padding=1)\n\n    def forward(self, x):\n        assert x.shape[1] == self.channels\n        if self.use_conv_transpose:\n            return self.conv(x)\n\n        x = F.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n\n        if self.use_conv:\n            x = self.conv(x)\n\n        return x\n\n\nclass Downsample1D(nn.Module):\n    \"\"\"\n    A downsampling layer with an optional convolution.\n\n    Parameters:\n        channels: channels in the inputs and outputs.\n        use_conv: a bool determining if a convolution is applied.\n        out_channels:\n        padding:\n    \"\"\"\n\n    def __init__(self, channels, use_conv=False, out_channels=None, padding=1, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.padding = padding\n        stride = 2\n        self.name = name\n\n        if use_conv:\n            self.conv = nn.Conv1d(self.channels, self.out_channels, 3, stride=stride, padding=padding)\n        else:\n            assert self.channels == self.out_channels\n            self.conv = nn.AvgPool1d(kernel_size=stride, stride=stride)\n\n    def forward(self, x):\n        assert x.shape[1] == self.channels\n        return self.conv(x)\n\n\nclass Upsample2D(nn.Module):\n    \"\"\"\n    An upsampling layer with an optional convolution.\n\n    Parameters:\n        channels: channels in the inputs and outputs.\n        use_conv: a bool determining if a convolution is applied.\n        use_conv_transpose:\n        out_channels:\n    \"\"\"\n\n    def __init__(self, channels, use_conv=False, use_conv_transpose=False, out_channels=None, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.use_conv_transpose = use_conv_transpose\n        self.name = name\n\n        conv = None\n        if use_conv_transpose:\n            conv = nn.ConvTranspose2d(channels, self.out_channels, 4, 2, 1)\n        elif use_conv:\n            conv = nn.Conv2d(self.channels, self.out_channels, 3, padding=1)\n\n        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n        if name == \"conv\":\n            self.conv = conv\n        else:\n            self.Conv2d_0 = conv\n\n    def forward(self, hidden_states, output_size=None):\n        assert hidden_states.shape[1] == self.channels\n\n        if self.use_conv_transpose:\n            return self.conv(hidden_states)\n\n        # Cast to float32 to as 'upsample_nearest2d_out_frame' op does not support bfloat16\n        # TODO(Suraj): Remove this cast once the issue is fixed in PyTorch\n        # https://github.com/pytorch/pytorch/issues/86679\n        dtype = hidden_states.dtype\n        if dtype == torch.bfloat16:\n            hidden_states = hidden_states.to(torch.float32)\n\n        # upsample_nearest_nhwc fails with large batch sizes. see https://github.com/huggingface/diffusers/issues/984\n        if hidden_states.shape[0] >= 64:\n            hidden_states = hidden_states.contiguous()\n\n        # if `output_size` is passed we force the interpolation output\n        # size and do not make use of `scale_factor=2`\n        if output_size is None:\n            hidden_states = F.interpolate(hidden_states, scale_factor=2.0, mode=\"nearest\")\n        else:\n            hidden_states = F.interpolate(hidden_states, size=output_size, mode=\"nearest\")\n\n        # If the input is bfloat16, we cast back to bfloat16\n        if dtype == torch.bfloat16:\n            hidden_states = hidden_states.to(dtype)\n\n        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n        if self.use_conv:\n            if self.name == \"conv\":\n                hidden_states = self.conv(hidden_states)\n            else:\n                hidden_states = self.Conv2d_0(hidden_states)\n\n        return hidden_states\n\n\nclass Downsample2D(nn.Module):\n    \"\"\"\n    A downsampling layer with an optional convolution.\n\n    Parameters:\n        channels: channels in the inputs and outputs.\n        use_conv: a bool determining if a convolution is applied.\n        out_channels:\n        padding:\n    \"\"\"\n\n    def __init__(self, channels, use_conv=False, out_channels=None, padding=1, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.padding = padding\n        stride = 2\n        self.name = name\n\n        if use_conv:\n            conv = nn.Conv2d(self.channels, self.out_channels, 3, stride=stride, padding=padding)\n        else:\n            assert self.channels == self.out_channels\n            conv = nn.AvgPool2d(kernel_size=stride, stride=stride)\n\n        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n        if name == \"conv\":\n            self.Conv2d_0 = conv", "completion": "```python\nclass Encoder(nn.Module):\n    def __init__(self, in_channels, out_channels, num_groups_in, num_groups_out, embed_dim, act_fn):\n        super().__init__()\n        self.conv1 = nn.Conv1d(in_channels, embed_dim, 5, padding=2)\n        self.group_norm1 = nn.GroupNorm(num_groups_in, embed_dim)\n        if act_fn == \"silu\":\n            self.act_fn = nn.SiLU()\n        elif act_fn == \"mish\":\n            self.act_fn = nn.Mish()\n        self.conv2 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n        self.group_norm2 = nn.GroupNorm(num_groups_in, embed_dim)\n        self.conv3 = nn.Conv1d(embed_dim, out_channels, 5, padding=2)\n        self.group_norm3 = nn.GroupNorm(num_groups_out, out_channels)\n\n    def forward(self, hidden_states):\n        hidden_states = self.conv1(hidden_states)\n        hidden_states = self.group_norm1(hidden_states)\n        hidden_states = self.act_fn(hidden_states)\n        hidden_states = self.conv2(hidden_states)\n        hidden_states = self.group_norm2(hidden_states", "metadata": {"task_id": "huggingface_diffusers/132", "ground_truth": "            self.conv = conv", "fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "resnet.py"], "context_start_lineno": 0, "line_no": 174, "query_window": {"context": "    \"\"\"\n\n    def __init__(self, channels, use_conv=False, out_channels=None, padding=1, name=\"conv\"):\n        super().__init__()\n        self.channels = channels\n        self.out_channels = out_channels or channels\n        self.use_conv = use_conv\n        self.padding = padding\n        stride = 2\n        self.name = name\n\n        if use_conv:\n            conv = nn.Conv2d(self.channels, self.out_channels, 3, stride=stride, padding=padding)\n        else:\n            assert self.channels == self.out_channels\n            conv = nn.AvgPool2d(kernel_size=stride, stride=stride)\n\n        # TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed\n        if name == \"conv\":\n            self.Conv2d_0 = conv", "metadata": {"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "resnet.py"], "line_no": 174, "task_id": "huggingface_diffusers/132", "start_line_no": 154, "end_line_no": 174, "window_size": 20, "context_start_lineno": 0, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        # compute next hidden_states\n        hidden_states = self.proj_attn(hidden_states)\n        hidden_states = hidden_states.transpose(1, 2)\n        hidden_states = self.dropout(hidden_states)\n\n        output = hidden_states + residual\n\n        return output\n\n\nclass ResConvBlock(nn.Module):\n    def __init__(self, in_channels, mid_channels, out_channels, is_last=False):\n        super().__init__()\n        self.is_last = is_last\n        self.has_conv_skip = in_channels != out_channels\n\n        if self.has_conv_skip:\n            self.conv_skip = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n\n        self.conv_1 = nn.Conv1d(in_channels, mid_channels, 5, padding=2)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_1d_blocks.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.35398230088495575}, {"context": "    def __init__(self, num_groups_out, out_channels, embed_dim, act_fn):\n        super().__init__()\n        self.final_conv1d_1 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n        self.final_conv1d_gn = nn.GroupNorm(num_groups_out, embed_dim)\n        if act_fn == \"silu\":\n            self.final_conv1d_act = nn.SiLU()\n        if act_fn == \"mish\":\n            self.final_conv1d_act = nn.Mish()\n        self.final_conv1d_2 = nn.Conv1d(embed_dim, out_channels, 1)\n\n    def forward(self, hidden_states, temb=None):\n        hidden_states = self.final_conv1d_1(hidden_states)\n        hidden_states = rearrange_dims(hidden_states)\n        hidden_states = self.final_conv1d_gn(hidden_states)\n        hidden_states = rearrange_dims(hidden_states)\n        hidden_states = self.final_conv1d_act(hidden_states)\n        hidden_states = self.final_conv1d_2(hidden_states)\n        return hidden_states\n\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_1d_blocks.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.35398230088495575}, {"context": "\n        if self.upsample:\n            hidden_states = self.upsample(hidden_states)\n        if self.downsample:\n            self.downsample = self.downsample(hidden_states)\n\n        return hidden_states\n\n\nclass OutConv1DBlock(nn.Module):\n    def __init__(self, num_groups_out, out_channels, embed_dim, act_fn):\n        super().__init__()\n        self.final_conv1d_1 = nn.Conv1d(embed_dim, embed_dim, 5, padding=2)\n        self.final_conv1d_gn = nn.GroupNorm(num_groups_out, embed_dim)\n        if act_fn == \"silu\":\n            self.final_conv1d_act = nn.SiLU()\n        if act_fn == \"mish\":\n            self.final_conv1d_act = nn.Mish()\n        self.final_conv1d_2 = nn.Conv1d(embed_dim, out_channels, 1)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_1d_blocks.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3448275862068966}, {"context": "class ResConvBlock(nn.Module):\n    def __init__(self, in_channels, mid_channels, out_channels, is_last=False):\n        super().__init__()\n        self.is_last = is_last\n        self.has_conv_skip = in_channels != out_channels\n\n        if self.has_conv_skip:\n            self.conv_skip = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n\n        self.conv_1 = nn.Conv1d(in_channels, mid_channels, 5, padding=2)\n        self.group_norm_1 = nn.GroupNorm(1, mid_channels)\n        self.gelu_1 = nn.GELU()\n        self.conv_2 = nn.Conv1d(mid_channels, out_channels, 5, padding=2)\n\n        if not self.is_last:\n            self.group_norm_2 = nn.GroupNorm(1, out_channels)\n            self.gelu_2 = nn.GELU()\n\n    def forward(self, hidden_states):\n        residual = self.conv_skip(hidden_states) if self.has_conv_skip else hidden_states", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "unet_1d_blocks.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "        )\n\n        use_nin_shortcut = self.in_channels != out_channels if self.use_nin_shortcut is None else self.use_nin_shortcut\n\n        self.conv_shortcut = None\n        if use_nin_shortcut:\n            self.conv_shortcut = nn.Conv(\n                out_channels,\n                kernel_size=(1, 1),\n                strides=(1, 1),\n                padding=\"VALID\",\n                dtype=self.dtype,\n            )\n\n    def __call__(self, hidden_states, deterministic=True):\n        residual = hidden_states\n        hidden_states = self.norm1(hidden_states)\n        hidden_states = nn.swish(hidden_states)\n        hidden_states = self.conv1(hidden_states)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "vae_flax.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.32432432432432434}, {"context": "\n        # out\n        self.conv_norm_out = nn.GroupNorm(num_channels=block_out_channels[-1], num_groups=norm_num_groups, eps=1e-6)\n        self.conv_act = nn.SiLU()\n\n        conv_out_channels = 2 * out_channels if double_z else out_channels\n        self.conv_out = nn.Conv2d(block_out_channels[-1], conv_out_channels, 3, padding=1)\n\n    def forward(self, x):\n        sample = x\n        sample = self.conv_in(sample)\n\n        # down\n        for down_block in self.down_blocks:\n            sample = down_block(sample)\n\n        # middle\n        sample = self.mid_block(sample)\n\n        # post-process", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "models", "vae.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3217391304347826}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/exception/base.py\n# --------------------------------------------------\n#         Returns:\n#             - status_code (:obj:`int`): Http status code\n#         \"\"\"\n#         return self.__status_code\n# \n#     @property\n#     def success(self) -> bool:\n#         return self.__success\n# \n#     @property\n#     def code(self) -> int:\n#         return self.__code\n# \n#     @property\n#     def message(self) -> str:\n#         return self.__message\n# \n#     @property\n#     def data(self) -> Mapping[str, Any]:\n#         return self.__data\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/loader/tests/loader/test_number.py\n# --------------------------------------------------\n#     def test_is_positive(self):\n#         _loader = is_positive()\n#         assert _loader(1) == 1\n#         with pytest.raises(ValueError):\n#             _loader(0)\n#         with pytest.raises(ValueError):\n#             _loader(-1)\n# \n#     def test_is_negative(self):\n#         _loader = is_negative()\n#         with pytest.raises(ValueError):\n#             _loader(1)\n#         with pytest.raises(ValueError):\n#             _loader(0)\n#         assert _loader(-1) == -1\n# \n#     def test_non_positive(self):\n#         _loader = non_positive()\n#         with pytest.raises(ValueError):\n#             _loader(1)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/base/test_network.py\n# --------------------------------------------------\n# \n#     @responses.activate\n#     def test_http_engine_with_path(self):\n#         with self.__yield_http_engine():\n#             engine = HttpEngine(host='example.com', port=7777, path='/this/is')\n#             response = engine.request('GET', '200')\n#             assert response.status_code == 200\n#             assert json.loads(response.content.decode()) == {\"success\": True}\n# \n#             with pytest.raises(HTTPError) as ei:\n#                 engine.request('GET', '404')\n# \n#             err = ei.value\n#             assert err.response.status_code == 404\n#             assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n# \n#     @responses.activate\n#     def test_get_http_engine_class(self):\n#         with self.__yield_http_engine():\n#             _token = '233'\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/tests/test_default_helper.py\n# --------------------------------------------------\n#         assert 'z' not in new3['b']\n# \n#     def test_flatten_dict(self):\n#         dict = {\n#             'a': 3,\n#             'b': {\n#                 'c': 3,\n#                 'd': {\n#                     'e': 6,\n#                     'f': 5,\n#                 },\n#                 'z': 4,\n#             }\n#         }\n#         flat = flatten_dict(dict)\n#         assert flat['a'] == 3\n#         assert flat['b/c'] == 3\n#         assert flat['b/d/e'] == 6\n#         assert flat['b/d/f'] == 5\n#         assert flat['b/z'] == 4\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/base/test_network.py\n# --------------------------------------------------\n# \n#             _http_engine_class = get_http_engine_class(\n#                 headers={'Token': lambda: _token},\n#                 data_processor=(lambda d: {\n#                     'data': json.dumps(d)\n#                 }),\n#                 http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n#             )()\n#             engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n# \n#             response = engine.request('GET', '200', {'a': 'skdjgflksdj'})\n#             assert response.status_code == 200\n#             assert json.loads(response.content.decode()) == {\"success\": True}\n#             assert response.request.headers['Token'] == '233'\n#             assert json.loads(response.request.body) == {'data': json.dumps({'a': 'skdjgflksdj'})}\n# \n#             with pytest.raises(RuntimeError) as ei:\n#                 engine.request('GET', '404', {'a': 'skdjgflksdj'})\n# \n#             err = ei.value\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/base/test_network.py\n# --------------------------------------------------\n#             _http_engine_class = get_http_engine_class(\n#                 headers={'Token': lambda: _token},\n#                 data_processor=(lambda d: {\n#                     'data': json.dumps(d)\n#                 }),\n#                 http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n#             )()\n#             engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n# \n#             response = engine.request('GET', '200', {'a': 'skdjgflksdj'})\n#             assert response.status_code == 200\n#             assert json.loads(response.content.decode()) == {\"success\": True}\n#             assert response.request.headers['Token'] == '233'\n#             assert json.loads(response.request.body) == {'data': json.dumps({'a': 'skdjgflksdj'})}\n# \n#             with pytest.raises(RuntimeError) as ei:\n#                 engine.request('GET', '404', {'a': 'skdjgflksdj'})\n# \n#             err = ei.value\n#             assert 'This is 404' in str(err)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/interaction/tests/base/test_network.py\n# --------------------------------------------------\n#                 engine.request('GET', '404')\n# \n#             err = ei.value\n#             assert err.response.status_code == 404\n#             assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n# \n#     @responses.activate\n#     def test_get_http_engine_class(self):\n#         with self.__yield_http_engine():\n#             _token = '233'\n# \n#             _http_engine_class = get_http_engine_class(\n#                 headers={'Token': lambda: _token},\n#                 data_processor=(lambda d: {\n#                     'data': json.dumps(d)\n#                 }),\n#                 http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n#             )()\n#             engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport json\n\nimport pytest\nfrom flask import Flask\n\nfrom ...base import success_response, failure_response, get_values_from_response, ResponsibleException, responsible\n\n\n@pytest.mark.unittest\nclass TestInteractionBaseApp:\n\n    def test_success_response(self):\n        app = Flask('_test_success_response')\n\n        @app.route('/success', methods=['GET'])\n        def success_method():\n            return success_response(\n                data={\n                    'a': 1,\n                    'b': 2,\n                    'sum': 3,\n                },\n                message='This is success message.',\n            )\n\n        client = app.test_client()\n\n        response = client.get('/success')\n        assert response.status_code == 200\n        assert json.loads(response.data.decode()) == {\n            'success': True,\n            'code': 0,\n            'data': {\n                'a': 1,\n                'b': 2,\n                'sum': 3,\n            },\n            'message': 'This is success message.',\n        }\n\n    # noinspection DuplicatedCode\n    def test_failure_response(self):\n        app = Flask('_test_failure_response')\n\n        @app.route('/fail', methods=['GET'])\n        def fail_method():\n            return failure_response(\n                code=233,\n                message='This is failure message.',\n                data={\n                    'a': 2,\n                    'b': 3,\n                    'sum': 5,\n                },\n            ), 404\n\n        client = app.test_client()\n\n        response = client.get('/fail')\n        assert response.status_code == 404\n        assert json.loads(response.data.decode()) == {\n            'success': False,\n            'code': 233,\n            'data': {\n                'a': 2,\n                'b': 3,\n                'sum': 5,\n            },\n            'message': 'This is failure message.',\n        }\n\n    def test_get_values_from_response(self):\n        app = Flask('_test_get_values_from_response')\n\n        @app.route('/success', methods=['GET'])\n        def success_method():\n            return success_response(\n                data={\n                    'a': 1,\n                    'b': 2,\n                    'sum': 3,\n                },\n                message='This is success message.',\n            )\n\n        @app.route('/fail', methods=['GET'])\n        def fail_method():\n            return failure_response(\n                code=233,\n                message='This is failure message.',\n                data={\n                    'a': 2,\n                    'b': 3,\n                    'sum': 5,\n                },\n            ), 404\n\n        client = app.test_client()\n\n        response = client.get('/success')\n        assert response.status_code == 200\n        assert get_values_from_response(response) == (\n            200,\n            True,\n            0,\n            'This is success message.',", "completion": "{\n                'a': 1,\n                'b': 2,\n                'sum': 3,\n            }\n        )\n\n        response = client.get('/fail')\n        assert response.status_code == 404\n        assert get_values_from_response(response) == (\n            404,\n            False,\n            233,\n            'This is failure message.',\n            {\n                'a': 2,\n                'b': 3,\n                'sum': 5,\n            }\n        )\n\n    def test_responsible_decorator(self):\n        app = Flask('_test_responsible_decorator')\n\n        @app.route('/success', methods=['GET'])\n        @responsible\n        def success_method():\n            return {\n                'a': 1,\n                'b': 2,\n                'sum': 3,\n            }\n\n        @app.route('/fail', methods=['GET'])\n        @responsible\n        def fail_method():\n            raise ResponsibleException(\n                code=233,\n                message='This is failure message.',\n                data={\n                    'a': 2,\n                    'b': 3,\n                    'sum': 5,\n                },\n            )\n\n        client = app.test_client()\n\n        response = client.get('/success')\n        assert response.status_code", "metadata": {"task_id": "opendilab_ACE/155", "ground_truth": "            {", "fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_app.py"], "context_start_lineno": 0, "line_no": 106, "query_window": {"context": "        def fail_method():\n            return failure_response(\n                code=233,\n                message='This is failure message.',\n                data={\n                    'a': 2,\n                    'b': 3,\n                    'sum': 5,\n                },\n            ), 404\n\n        client = app.test_client()\n\n        response = client.get('/success')\n        assert response.status_code == 200\n        assert get_values_from_response(response) == (\n            200,\n            True,\n            0,\n            'This is success message.',", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_app.py"], "line_no": 106, "task_id": "opendilab_ACE/155", "start_line_no": 86, "end_line_no": 106, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "\n    @responses.activate\n    def test_http_engine_with_path(self):\n        with self.__yield_http_engine():\n            engine = HttpEngine(host='example.com', port=7777, path='/this/is')\n            response = engine.request('GET', '200')\n            assert response.status_code == 200\n            assert json.loads(response.content.decode()) == {\"success\": True}\n\n            with pytest.raises(HTTPError) as ei:\n                engine.request('GET', '404')\n\n            err = ei.value\n            assert err.response.status_code == 404\n            assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n\n    @responses.activate\n    def test_get_http_engine_class(self):\n        with self.__yield_http_engine():\n            _token = '233'", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_network.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2619047619047619}, {"context": "\n            _http_engine_class = get_http_engine_class(\n                headers={'Token': lambda: _token},\n                data_processor=(lambda d: {\n                    'data': json.dumps(d)\n                }),\n                http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n            )()\n            engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n\n            response = engine.request('GET', '200', {'a': 'skdjgflksdj'})\n            assert response.status_code == 200\n            assert json.loads(response.content.decode()) == {\"success\": True}\n            assert response.request.headers['Token'] == '233'\n            assert json.loads(response.request.body) == {'data': json.dumps({'a': 'skdjgflksdj'})}\n\n            with pytest.raises(RuntimeError) as ei:\n                engine.request('GET', '404', {'a': 'skdjgflksdj'})\n\n            err = ei.value", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_network.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2608695652173913}, {"context": "                engine.request('GET', '404')\n\n            err = ei.value\n            assert err.response.status_code == 404\n            assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n\n    @responses.activate\n    def test_get_http_engine_class(self):\n        with self.__yield_http_engine():\n            _token = '233'\n\n            _http_engine_class = get_http_engine_class(\n                headers={'Token': lambda: _token},\n                data_processor=(lambda d: {\n                    'data': json.dumps(d)\n                }),\n                http_error_gene=lambda e: RuntimeError('This is {status}'.format(status=e.response.status_code))\n            )()\n            engine = _http_engine_class(host='example.com', port=7777, path='/this/is')\n", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_network.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.25735294117647056}, {"context": "            'b': {\n                'c': 3,\n                'd': {\n                    'e': 6,\n                    'f': 5,\n                },\n                'z': 4,\n            }\n        }\n        flat = flatten_dict(dict)\n        assert flat['a'] == 3\n        assert flat['b/c'] == 3\n        assert flat['b/d/e'] == 6\n        assert flat['b/d/f'] == 5\n        assert flat['b/z'] == 4", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "tests", "test_default_helper.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 215, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2564102564102564}, {"context": "            response = engine.request('GET', '/this/is/200')\n            assert response.status_code == 200\n            assert json.loads(response.content.decode()) == {\"success\": True}\n\n            with pytest.raises(HTTPError) as ei:\n                engine.request('GET', '/this/is/404')\n\n            err = ei.value\n            assert err.response.status_code == 404\n            assert json.loads(err.response.content.decode()) == {'exception': 'reason'}\n\n    @responses.activate\n    def test_http_engine_with_path(self):\n        with self.__yield_http_engine():\n            engine = HttpEngine(host='example.com', port=7777, path='/this/is')\n            response = engine.request('GET', '200')\n            assert response.status_code == 200\n            assert json.loads(response.content.decode()) == {\"success\": True}\n\n            with pytest.raises(HTTPError) as ei:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "tests", "base", "test_network.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.25}, {"context": "            _loader({'a': 0, 'b': -1})\n        with pytest.raises(ValueError):\n            _loader({'a': 1, 'b': 2})\n\n    def test_mcmp_invalid(self):\n        with pytest.raises(ValueError):\n            mcmp(1, '>', item('a'), '<=', item('b'), '==')\n        with pytest.raises(KeyError):\n            mcmp(1, '>', item('a'), '*=', item('b'))\n\n    def test_is_positive(self):\n        _loader = is_positive()\n        assert _loader(1) == 1\n        with pytest.raises(ValueError):\n            _loader(0)\n        with pytest.raises(ValueError):\n            _loader(-1)\n\n    def test_is_negative(self):\n        _loader = is_negative()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "loader", "tests", "loader", "test_number.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.25}, {"context": "        self.__status_code, self.__success, self.__code, self.__message, self.__data = \\\n            get_values_from_response(error.response)\n        Exception.__init__(self, self.__message)\n\n    @property\n    def status_code(self) -> int:\n        \"\"\"\n        Overview:\n            Get http status code of response\n        Returns:\n            - status_code (:obj:`int`): Http status code\n        \"\"\"\n        return self.__status_code\n\n    @property\n    def success(self) -> bool:\n        return self.__success\n\n    @property\n    def code(self) -> int:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "interaction", "exception", "base.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.24731182795698925}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_scheduler_flax.py\n# --------------------------------------------------\n# \n#         num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n# \n#         for scheduler_class in self.scheduler_classes:\n#             sample, key = self.dummy_sample\n#             residual = 0.1 * sample\n# \n#             scheduler_config = self.get_scheduler_config()\n#             scheduler = scheduler_class(**scheduler_config)\n#             state = scheduler.create_state()\n# \n#             with tempfile.TemporaryDirectory() as tmpdirname:\n#                 scheduler.save_config(tmpdirname)\n#                 new_scheduler, new_state = scheduler_class.from_pretrained(tmpdirname)\n# \n#             if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n#                 state = scheduler.set_timesteps(state, num_inference_steps)\n#                 new_state = new_scheduler.set_timesteps(new_state, num_inference_steps)\n#             elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n#                 kwargs[\"num_inference_steps\"] = num_inference_steps\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/test_pipelines_common.py\n# --------------------------------------------------\n#             if param == \"kwargs\":\n#                 # kwargs can be added if arguments of pipeline call function are deprecated\n#                 continue\n#             assert param in self.allowed_required_args\n# \n#         optional_parameters = set({k for k, v in parameters.items() if v.default != inspect._empty})\n# \n#         for param in self.required_optional_params:\n#             assert param in optional_parameters\n# \n#     def test_inference_batch_consistent(self):\n#         self._test_inference_batch_consistent()\n# \n#     def _test_inference_batch_consistent(self, batch_sizes=[2, 4, 13]):\n#         components = self.get_dummy_components()\n#         pipe = self.pipeline_class(**components)\n#         pipe.to(torch_device)\n#         pipe.set_progress_bar_config(disable=None)\n# \n#         inputs = self.get_dummy_inputs(torch_device)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/configuration_utils.py\n# --------------------------------------------------\n#     def _get_init_keys(cls):\n#         return set(dict(inspect.signature(cls.__init__).parameters).keys())\n# \n#     @classmethod\n#     def extract_init_dict(cls, config_dict, **kwargs):\n#         # 0. Copy origin config dict\n#         original_dict = {k: v for k, v in config_dict.items()}\n# \n#         # 1. Retrieve expected config attributes from __init__ signature\n#         expected_keys = cls._get_init_keys(cls)\n#         expected_keys.remove(\"self\")\n#         # remove general kwargs if present in dict\n#         if \"kwargs\" in expected_keys:\n#             expected_keys.remove(\"kwargs\")\n#         # remove flax internal keys\n#         if hasattr(cls, \"_flax_internal_args\"):\n#             for arg in cls._flax_internal_args:\n#                 expected_keys.remove(arg)\n# \n#         # 2. Remove attributes that cannot be expected from expected config attributes\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/configuration_utils.py\n# --------------------------------------------------\n#         orig_cls_name = config_dict.pop(\"_class_name\", cls.__name__)\n#         if orig_cls_name != cls.__name__ and hasattr(diffusers_library, orig_cls_name):\n#             orig_cls = getattr(diffusers_library, orig_cls_name)\n#             unexpected_keys_from_orig = cls._get_init_keys(orig_cls) - expected_keys\n#             config_dict = {k: v for k, v in config_dict.items() if k not in unexpected_keys_from_orig}\n# \n#         # remove private attributes\n#         config_dict = {k: v for k, v in config_dict.items() if not k.startswith(\"_\")}\n# \n#         # 3. Create keyword arguments that will be passed to __init__ from expected keyword arguments\n#         init_dict = {}\n#         for key in expected_keys:\n#             # if config param is passed to kwarg and is present in config dict\n#             # it should overwrite existing config dict key\n#             if key in kwargs and key in config_dict:\n#                 config_dict[key] = kwargs.pop(key)\n# \n#             if key in kwargs:\n#                 # overwrite key\n#                 init_dict[key] = kwargs.pop(key)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/configuration_utils.py\n# --------------------------------------------------\n#         expected_keys.remove(\"self\")\n#         # remove general kwargs if present in dict\n#         if \"kwargs\" in expected_keys:\n#             expected_keys.remove(\"kwargs\")\n#         # remove flax internal keys\n#         if hasattr(cls, \"_flax_internal_args\"):\n#             for arg in cls._flax_internal_args:\n#                 expected_keys.remove(arg)\n# \n#         # 2. Remove attributes that cannot be expected from expected config attributes\n#         # remove keys to be ignored\n#         if len(cls.ignore_for_config) > 0:\n#             expected_keys = expected_keys - set(cls.ignore_for_config)\n# \n#         # load diffusers library to import compatible and original scheduler\n#         diffusers_library = importlib.import_module(__name__.split(\".\")[0])\n# \n#         if cls.has_compatibles:\n#             compatible_classes = [c for c in cls._get_compatibles() if not isinstance(c, DummyObject)]\n#         else:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/pipeline_utils.py\n# --------------------------------------------------\n#             if name in self._optional_components and value[0] is None:\n#                 return False\n#             return True\n# \n#         model_index_dict = {k: v for k, v in model_index_dict.items() if is_saveable_module(k, v)}\n# \n#         for pipeline_component_name in model_index_dict.keys():\n#             sub_model = getattr(self, pipeline_component_name)\n#             model_cls = sub_model.__class__\n# \n#             save_method_name = None\n#             # search for the model's base class in LOADABLE_CLASSES\n#             for library_name, library_classes in LOADABLE_CLASSES.items():\n#                 library = importlib.import_module(library_name)\n#                 for base_class, save_load_methods in library_classes.items():\n#                     class_candidate = getattr(library, base_class, None)\n#                     if class_candidate is not None and issubclass(model_cls, class_candidate):\n#                         # if we found a suitable base class in LOADABLE_CLASSES then grab its save method\n#                         save_method_name = save_load_methods[0]\n#                         break\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n = 0.1 * sample\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n                new_scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            # Set the seed before step() as some schedulers are stochastic like EulerAncestralDiscreteScheduler, EulerDiscreteScheduler\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            output = scheduler.step(residual, time_step, sample, **kwargs).prev_sample\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            new_output = new_scheduler.step(residual, time_step, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def check_over_forward(self, time_step=0, **forward_kwargs):\n        kwargs = dict(self.forward_default_kwargs)\n        kwargs.update(forward_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            if scheduler_class in (EulerAncestralDiscreteScheduler, EulerDiscreteScheduler, LMSDiscreteScheduler):\n                time_step = float(time_step)\n\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            if scheduler_class == VQDiffusionScheduler:\n                num_vec_classes = scheduler_config[\"num_vec_classes\"]\n                sample = self.dummy_sample(num_vec_classes)\n                model = self.dummy_model(num_vec_classes)\n                residual = model(sample, time_step)\n            else:\n                sample = self.dummy_sample\n                residual = 0.1 * sample\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n                new_scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            output = scheduler.step(residual, time_step, sample, **kwargs).prev_sample\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            new_output = new_scheduler.step(residual, time_step, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def test_from_save_pretrained(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            timestep = 1\n            if scheduler_class in (EulerAncestralDiscreteScheduler, EulerDiscreteScheduler, LMSDiscreteScheduler):\n                timestep = float(timestep)\n\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            if scheduler_class == VQDiffusionScheduler:\n                num_vec_classes = scheduler_config[\"num_vec_classes\"]\n                sample = self.dummy_sample(num_vec_classes)\n                model = self.dummy_model(num_vec_classes)\n                residual = model(sample, timestep)\n            else:\n                sample = self.dummy_sample\n                residual = 0.1 * sample\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            if num_inference_steps is not None and hasattr(scheduler, \"set_timesteps\"):\n                scheduler.set_timesteps(num_inference_steps)\n                new_scheduler.set_timesteps(num_inference_steps)\n            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            output = scheduler.step(residual, timestep, sample, **kwargs).prev_sample\n\n            if \"generator\" in set(inspect.signature(scheduler.step).parameters.keys()):\n                kwargs[\"generator\"] = torch.manual_seed(0)\n            new_output = new_scheduler.step(residual, timestep, sample, **kwargs).prev_sample\n\n            assert torch.sum(torch.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def test_compatibles(self):\n        for scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n\n            scheduler = scheduler_class(**scheduler_config)\n\n            assert all(c is not None for c in scheduler.compatibles)\n\n            for comp_scheduler_cls in scheduler.compatibles:\n                comp_scheduler = comp_scheduler_cls.from_config(scheduler.config)\n                assert comp_scheduler is not None\n\n            new_scheduler = scheduler_class.from_config(comp_scheduler.config)\n\n            new_scheduler_config = {k: v for k, v in new_scheduler.config.items() if k in scheduler.config}\n            scheduler_diff = {k: v for k, v in new_scheduler.config.items() if k not in scheduler.config}\n\n            # make sure that configs are essentially identical\n            assert new_scheduler_config == dict(scheduler.config)\n\n            # make sure that only differences are for configs that are not in init\n            init_keys = inspect.signature(scheduler_class.__init__).parameters.keys()\n            assert set(scheduler_diff.keys()).intersection(set(init_keys)) == set()\n\n    def test_from_pretrained(self):\n        for scheduler_class in self.scheduler_classes:", "completion": "scheduler_class in self.scheduler_classes:\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n\n            with tempfile.TemporaryDirectory() as tmpdirname:\n                scheduler.save_config(tmpdirname)\n                new_scheduler = scheduler_class.from_pretrained(tmpdirname)\n\n            assert isinstance(new_scheduler, scheduler_class)\n\n            assert new_scheduler.config == scheduler.config\n            assert new_scheduler.state == scheduler.state", "metadata": {"task_id": "huggingface_diffusers/56", "ground_truth": "            scheduler_config = self.get_scheduler_config()", "fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "context_start_lineno": 276, "line_no": 409, "query_window": {"context": "            assert all(c is not None for c in scheduler.compatibles)\n\n            for comp_scheduler_cls in scheduler.compatibles:\n                comp_scheduler = comp_scheduler_cls.from_config(scheduler.config)\n                assert comp_scheduler is not None\n\n            new_scheduler = scheduler_class.from_config(comp_scheduler.config)\n\n            new_scheduler_config = {k: v for k, v in new_scheduler.config.items() if k in scheduler.config}\n            scheduler_diff = {k: v for k, v in new_scheduler.config.items() if k not in scheduler.config}\n\n            # make sure that configs are essentially identical\n            assert new_scheduler_config == dict(scheduler.config)\n\n            # make sure that only differences are for configs that are not in init\n            init_keys = inspect.signature(scheduler_class.__init__).parameters.keys()\n            assert set(scheduler_diff.keys()).intersection(set(init_keys)) == set()\n\n    def test_from_pretrained(self):\n        for scheduler_class in self.scheduler_classes:", "metadata": {"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler.py"], "line_no": 409, "task_id": "huggingface_diffusers/56", "start_line_no": 389, "end_line_no": 409, "window_size": 20, "context_start_lineno": 276, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "        model_index_dict = dict(self.config)\n        model_index_dict.pop(\"_class_name\")\n        model_index_dict.pop(\"_diffusers_version\")\n        model_index_dict.pop(\"_module\", None)\n\n        expected_modules, optional_kwargs = self._get_signature_keys(self)\n\n        def is_saveable_module(name, value):\n            if name not in expected_modules:\n                return False\n            if name in self._optional_components and value[0] is None:\n                return False\n            return True\n\n        model_index_dict = {k: v for k, v in model_index_dict.items() if is_saveable_module(k, v)}\n\n        for pipeline_component_name in model_index_dict.keys():\n            sub_model = getattr(self, pipeline_component_name)\n            model_cls = sub_model.__class__\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "pipeline_utils.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3277310924369748}, {"context": "    def _get_init_keys(cls):\n        return set(dict(inspect.signature(cls.__init__).parameters).keys())\n\n    @classmethod\n    def extract_init_dict(cls, config_dict, **kwargs):\n        # 0. Copy origin config dict\n        original_dict = {k: v for k, v in config_dict.items()}\n\n        # 1. Retrieve expected config attributes from __init__ signature\n        expected_keys = cls._get_init_keys(cls)\n        expected_keys.remove(\"self\")\n        # remove general kwargs if present in dict\n        if \"kwargs\" in expected_keys:\n            expected_keys.remove(\"kwargs\")\n        # remove flax internal keys\n        if hasattr(cls, \"_flax_internal_args\"):\n            for arg in cls._flax_internal_args:\n                expected_keys.remove(arg)\n\n        # 2. Remove attributes that cannot be expected from expected config attributes", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "configuration_utils.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.32061068702290074}, {"context": "            compatible_classes = []\n\n        expected_keys_comp_cls = set()\n        for c in compatible_classes:\n            expected_keys_c = cls._get_init_keys(c)\n            expected_keys_comp_cls = expected_keys_comp_cls.union(expected_keys_c)\n        expected_keys_comp_cls = expected_keys_comp_cls - cls._get_init_keys(cls)\n        config_dict = {k: v for k, v in config_dict.items() if k not in expected_keys_comp_cls}\n\n        # remove attributes from orig class that cannot be expected\n        orig_cls_name = config_dict.pop(\"_class_name\", cls.__name__)\n        if orig_cls_name != cls.__name__ and hasattr(diffusers_library, orig_cls_name):\n            orig_cls = getattr(diffusers_library, orig_cls_name)\n            unexpected_keys_from_orig = cls._get_init_keys(orig_cls) - expected_keys\n            config_dict = {k: v for k, v in config_dict.items() if k not in unexpected_keys_from_orig}\n\n        # remove private attributes\n        config_dict = {k: v for k, v in config_dict.items() if not k.startswith(\"_\")}\n\n        # 3. Create keyword arguments that will be passed to __init__ from expected keyword arguments", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "configuration_utils.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3170731707317073}, {"context": "            config_dict = cls._dict_from_json_file(config_file)\n        except (json.JSONDecodeError, UnicodeDecodeError):\n            raise EnvironmentError(f\"It looks like the config file at '{config_file}' is not a valid JSON file.\")\n\n        if return_unused_kwargs:\n            return config_dict, kwargs\n\n        return config_dict\n\n    @staticmethod\n    def _get_init_keys(cls):\n        return set(dict(inspect.signature(cls.__init__).parameters).keys())\n\n    @classmethod\n    def extract_init_dict(cls, config_dict, **kwargs):\n        # 0. Copy origin config dict\n        original_dict = {k: v for k, v in config_dict.items()}\n\n        # 1. Retrieve expected config attributes from __init__ signature\n        expected_keys = cls._get_init_keys(cls)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "configuration_utils.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.31386861313868614}, {"context": "\n    def test_pipeline_call_implements_required_args(self):\n        assert hasattr(self.pipeline_class, \"__call__\"), f\"{self.pipeline_class} should have a `__call__` method\"\n        parameters = inspect.signature(self.pipeline_class.__call__).parameters\n        required_parameters = {k: v for k, v in parameters.items() if v.default == inspect._empty}\n        required_parameters.pop(\"self\")\n        required_parameters = set(required_parameters)\n        optional_parameters = set({k for k, v in parameters.items() if v.default != inspect._empty})\n\n        for param in required_parameters:\n            if param == \"kwargs\":\n                # kwargs can be added if arguments of pipeline call function are deprecated\n                continue\n            assert param in self.allowed_required_args\n\n        optional_parameters = set({k for k, v in parameters.items() if v.default != inspect._empty})\n\n        for param in self.required_optional_params:\n            assert param in optional_parameters\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_pipelines_common.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.31297709923664124}, {"context": "            elif num_inference_steps is not None and not hasattr(scheduler, \"set_timesteps\"):\n                kwargs[\"num_inference_steps\"] = num_inference_steps\n\n            output = scheduler.step(state, residual, time_step, sample, key, **kwargs).prev_sample\n            new_output = new_scheduler.step(new_state, residual, time_step, sample, key, **kwargs).prev_sample\n\n            assert jnp.sum(jnp.abs(output - new_output)) < 1e-5, \"Scheduler outputs are not identical\"\n\n    def test_from_save_pretrained(self):\n        kwargs = dict(self.forward_default_kwargs)\n\n        num_inference_steps = kwargs.pop(\"num_inference_steps\", None)\n\n        for scheduler_class in self.scheduler_classes:\n            sample, key = self.dummy_sample\n            residual = 0.1 * sample\n\n            scheduler_config = self.get_scheduler_config()\n            scheduler = scheduler_class(**scheduler_config)\n            state = scheduler.create_state()", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "tests", "test_scheduler_flax.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3049645390070922}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# from __future__ import annotations\n# \n# import collections\n# import os\n# from typing import Any, Dict, Optional, Tuple, Union\n# \n# import numpy as np\n# import torch\n# \n# from torchrl.data import (\n#     BoundedTensorSpec,\n#     CompositeSpec,\n#     TensorSpec,\n#     UnboundedContinuousTensorSpec,\n#     UnboundedDiscreteTensorSpec,\n# )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# import argparse\n# import os\n# import tempfile\n# from argparse import Namespace\n# from collections import OrderedDict\n# from os import path, walk\n# from time import sleep\n# \n# import pytest\n# import torch\n# from torch import nn\n# \n# try:\n#     from tensorboard.backend.event_processing import event_accumulator\n#     from torchrl.record.loggers import TensorboardLogger\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# from __future__ import annotations\n# \n# import os\n# from collections import OrderedDict\n# from copy import deepcopy\n# from multiprocessing import connection\n# from multiprocessing.synchronize import Lock as MpLock\n# from time import sleep\n# from typing import Any, Callable, Dict, List, Optional, Sequence, Union\n# from warnings import warn\n# \n# import torch\n# from tensordict import TensorDict\n# from tensordict.tensordict import LazyStackedTensorDict, TensorDictBase\n# from torch import multiprocessing as mp\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import abc\n# import os\n# from collections import OrderedDict\n# from copy import copy\n# from typing import Any, Dict, Sequence, Union\n# \n# import torch\n# from tensordict.memmap import MemmapTensor\n# from tensordict.prototype import is_tensorclass\n# from tensordict.tensordict import TensorDict, TensorDictBase\n# \n# from torchrl._utils import _CKPT_BACKEND\n# from torchrl.data.replay_buffers.utils import INT_CLASSES\n# \n# try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import argparse\n# import os.path\n# from collections import defaultdict\n# \n# import numpy as np\n# import pytest\n# import torch\n# import yaml\n# from _utils_internal import (\n#     CARTPOLE_VERSIONED,\n#     get_available_devices,\n#     HALFCHEETAH_VERSIONED,\n#     PENDULUM_VERSIONED,\n#     PONG_VERSIONED,\n# )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/record/loggers/csv.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# import os\n# from collections import defaultdict\n# from pathlib import Path\n# from typing import Optional\n# \n# import torch\n# from torch import Tensor\n# \n# from .common import Logger\n# \n# \n# class CSVExperiment:\n#     \"\"\"A CSV logger experiment class.\"\"\"\n# \n#     def __init__(self, log_dir: str):\n#         self.scalars = defaultdict(lambda: [])\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/_utils_internal.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import time\n# from functools import wraps\n# \n# # Get relative file path\n# # this returns relative path from current file.\n# import pytest\n# import torch.cuda\n# from torchrl._utils import implement_for, seed_generator\n# from torchrl.envs.libs.gym import _has_gym\n# \n# # Specified for test_utils.py\n# __version__ = \"0.3\"\n# \n# # Default versions of the environments.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_td_distributed.py\n# examples/torchrl_features/memmap_speed_distributed.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import time\n# \n# import configargparse\n# import torch\n# import torch.distributed.rpc as rpc\n# from tensordict import TensorDict\n# from tensordict.memmap import set_transfer_ownership\n# \n# parser = configargparse.ArgumentParser()\n# parser.add_argument(\"--world_size\", default=2, type=int)\n# parser.add_argument(\"--rank\", default=-1, type=int)\n# parser.add_argument(\"--task\", default=1, type=int)\n# parser.add_argument(\"--rank_var\", default=\"SLURM_JOB_ID\", type=str)\n# parser.add_argument(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb_distributed.py\n# --------------------------------------------------\n# # Copyright (c) Meta Platforms, Inc. and affiliates.\n# #\n# # This source code is licensed under the MIT license found in the\n# # LICENSE file in the root directory of this source tree.\n# \n# import os\n# import sys\n# import time\n# \n# import pytest\n# import torch\n# import torch.distributed.rpc as rpc\n# import torch.multiprocessing as mp\n# from tensordict.tensordict import TensorDict\n# from torchrl.data.replay_buffers import RemoteTensorDictReplayBuffer\n# from torchrl.data.replay_buffers.samplers import RandomSampler\n# from torchrl.data.replay_buffers.storages import LazyMemmapStorage\n# from torchrl.data.replay_buffers.writers import RoundRobinWriter\n# \n# RETRY_COUNT = 3\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport collections\nimport math\nimport os\nimport time", "completion": "# the below code fragment can be found in:\n# torchrl/envs/libs/dm_control.py\n# --------------------------------------------------\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nfrom __future__ import annotations\n\nimport collections\nimport os\nfrom typing import Any, Dict, Optional, Tuple, Union\n\nimport numpy as np\nimport torch\n\nfrom torchrl.data import (\n    BoundedTensorSpec,\n    CompositeSpec,\n    TensorSpec,\n    UnboundedContinuousTensorSpec,\n    UnboundedDiscreteTensorSpec,\n)\n\n# the below code fragment can be found in:\n# test/test_trainer.py\n# --------------------------------------------------\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport argparse\nimport os\nimport tempfile\nfrom argparse import Namespace\nfrom collections import OrderedDict\nfrom os import path, walk\nfrom time import sleep\n\nimport pytest\nimport torch\nfrom torch import nn\n\ntry:\n    from tensorboard.backend.event_processing import event_accumulator\n", "metadata": {"task_id": "pytorch_rl/45", "ground_truth": "from functools import wraps", "fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "context_start_lineno": 0, "line_no": 4, "query_window": {"context": "import collections\nimport math\nimport os\nimport time", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "line_no": 4, "task_id": "pytorch_rl/45", "start_line_no": 0, "end_line_no": 4, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport sys\nimport time\n\nimport pytest", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.0975609756097561}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport time\n\nimport configargparse\nimport torch", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_td_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}, {"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_speed_distributed.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.09523809523809523}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport time\nfrom functools import wraps\n\n# Get relative file path", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "_utils_internal.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.0851063829787234}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport os\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import Optional\n\nimport torch", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "record", "loggers", "csv.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.08333333333333333}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport argparse\nimport os.path\nfrom collections import defaultdict\n\nimport numpy as np", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.08163265306122448}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport abc\nimport os\nfrom collections import OrderedDict\nfrom copy import copy\nfrom typing import Any, Dict, Sequence, Union", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.0784313725490196}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom __future__ import annotations\n\nimport os\nfrom collections import OrderedDict\nfrom copy import deepcopy", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.0784313725490196}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nimport argparse\nimport os\nimport tempfile\nfrom argparse import Namespace\nfrom collections import OrderedDict\nfrom os import path, walk", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_trainer.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.07692307692307693}, {"context": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nfrom __future__ import annotations\n\nimport collections\nimport os\nfrom typing import Any, Dict, Optional, Tuple, Union\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "dm_control.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.07692307692307693}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/c51.py\n# --------------------------------------------------\n#         with torch.no_grad():\n#             output = self._collect_model.forward(data, eps=eps)\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n#         r\"\"\"\n#         Overview:\n#             Get the trajectory and the n step return data, then sample from the n_step return data\n#         Arguments:\n#             - data (:obj:`list`): The trajectory's cache\n#         Returns:\n#             - samples (:obj:`dict`): The training samples generated\n#         \"\"\"\n#         data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/cql.py\n# --------------------------------------------------\n#         with torch.no_grad():\n#             output = self._collect_model.forward(data, eps=eps)\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n#         r\"\"\"\n#             Overview:\n#                 Get the trajectory and the n step return data, then sample from the n_step return data\n#             Arguments:\n#                 - data (:obj:`list`): The trajectory's cache\n#             Returns:\n#                 - samples (:obj:`dict`): The training samples generated\n#             \"\"\"\n#         data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def default_model(self) -> Tuple[str, List[str]]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/acer.py\n# --------------------------------------------------\n#             output = self._collect_model.forward(data, mode='compute_actor')\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         output = {i: d for i, d in zip(data_id, output)}\n#         return output\n# \n#     def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n#         r\"\"\"\n#         Overview:\n#             For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n#             can be used for training directly.\n#         Arguments:\n#             - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n#                 format as the return value of ``self._process_transition`` method.\n#         Returns:\n#             - samples (:obj:`dict`): List of training samples.\n#         .. note::\n#             We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n#             And the user can customize the this data processing procedure by overriding this two methods and collector \\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/impala.py\n# --------------------------------------------------\n#         return output\n# \n#     def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n#         r\"\"\"\n#         Overview:\n#             For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n#             can be used for training directly.\n#         Arguments:\n#             - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n#                 format as the return value of ``self._process_transition`` method.\n#         Returns:\n#             - samples (:obj:`dict`): List of training samples.\n#         .. note::\n#             We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n#             And the user can customize the this data processing procedure by overriding this two methods and collector \\\n#             itself.\n#         \"\"\"\n#         return get_train_sample(data, self._unroll_len)\n# \n#     def _process_transition(self, obs: Any, policy_output: Dict[str, Any], timestep: namedtuple) -> Dict[str, Any]:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/sql.py\n# --------------------------------------------------\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n#         \"\"\"\n#         Overview:\n#             For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n#             can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\\n#             or some continuous transitions(DRQN).\n#         Arguments:\n#             - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n#                 format as the return value of ``self._process_transition`` method.\n#         Returns:\n#             - samples (:obj:`dict`): The list of training samples.\n# \n#         .. note::\n#             We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n#             And the user can customize the this data processing procecure by overriding this two methods and collector \\\n#             itself.\n#         \"\"\"\n#         data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/dqn.py\n# --------------------------------------------------\n#         if self._cuda:\n#             output = to_device(output, 'cpu')\n#         output = default_decollate(output)\n#         return {i: d for i, d in zip(data_id, output)}\n# \n#     def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n#         \"\"\"\n#         Overview:\n#             For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n#             can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\\n#             or some continuous transitions(DRQN).\n#         Arguments:\n#             - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n#                 format as the return value of ``self._process_transition`` method.\n#         Returns:\n#             - samples (:obj:`dict`): The list of training samples.\n# \n#         .. note::\n#             We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n#             And the user can customize the this data processing procecure by overriding this two methods and collector \\\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n # [batch, agent, state_len - 25 - 1 - unit_type_bits]]\n            global_ally_label = (ally * local_label).sum(1) # [batch, state_len - 25 - 1 - unit_type_bits]\n            global_enemy_label = ((1 - ally) * local_label).sum(1) # [batch, state_len - 25 - 1 - unit_type_bits]\n            global_label = torch.cat([global_ally_label, global_enemy_label], dim=1)\n            if self._cfg.learn.get('aux_label_norm', False):\n                local_label = local_label/(local_label.abs().max(dim=1).values.unsqueeze(1)+1e-9)\n                global_label = global_label/(global_label.abs().max(dim=1).values.unsqueeze(1)+1e-9)\n            if self._cfg.learn.get('aux_class_balance', False):\n                local_loss = l2_balance(local_label, (local_label - local_pred).pow(2))\n            else:\n                local_loss = (local_label - local_pred).pow(2).mean()\n            global_loss = (global_label - global_pred).pow(2).mean()\n            aux_loss = local_loss + global_loss\n        elif self.cfg.learn.env == 'grf':\n            state, next_state = obs['states'][:, :, 4:11], next_obs['states'][:, :, 4:11]  # [batch, agent, state_len - 25]\n            local_pred, global_pred = aux_pred['local_pred'], aux_pred['global_pred']\n            ally = state[:, :, :1]  # [batch, agent, 1]\n            local_label = (next_state - state)  # [batch, agent, state_len - 25 - 1 - unit_type_bits]]\n            if self._cfg.learn.get('aux_label_norm', False):\n                local_label = local_label / (local_label.abs().max(dim=1).values.unsqueeze(1) + 1e-9)\n            if self._cfg.learn.get('aux_class_balance', False):\n                local_loss = l2_balance(local_label, (local_label - local_pred).pow(2))\n            else:\n                local_loss = (local_label - local_pred).pow(2).mean()\n            aux_loss = local_loss\n        # update\n        # cosine aux_loss_weight\n        tem = self._aux_loss_weight\n        cur = min(self._forward_learn_cnt/tem.T_max, 1)\n        aux_loss_weight = tem.end + 0.5*(tem.begin - tem.end) * (1 + math.cos(math.pi*cur))\n        loss = rl_loss + aux_loss_weight * aux_loss\n        self._optimizer.zero_grad()\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(self._model.parameters(), self._cfg.learn.clip_value)\n        self._optimizer.step()\n        if self._cfg.learn.learning_rate_type == 'cosine' and self._scheduler.last_epoch < self._scheduler.T_max:\n            self._scheduler.step()\n        # =============\n        # after update\n        # =============\n        self._forward_learn_cnt += 1\n        self._target_model.update(self._learn_model.state_dict())\n        ret = {\n            'lr': self._optimizer.param_groups[0]['lr'],\n            'loss': loss.item(),\n            'q': target_q.mean().item(),\n            'grad_norm': grad_norm,\n            'rl_loss': rl_loss.item(),\n            'aux_loss': aux_loss.item(),\n            'priority': td_error_per_sample.abs().tolist(),\n            'aux_loss_weight': aux_loss_weight,\n        }\n        return ret\n\n    def _state_dict_learn(self) -> Dict[str, Any]:\n        r\"\"\"\n        Overview:\n            Return the state_dict of learn mode, usually including model and optimizer.\n        Returns:\n            - state_dict (:obj:`Dict[str, Any]`): the dict of current policy learn state, for saving and restoring.\n        \"\"\"\n        return {\n            'model': self._learn_model.state_dict(),\n            'target_model': self._target_model.state_dict(),\n            'optimizer': self._optimizer.state_dict(),\n        }\n\n    def _load_state_dict_learn(self, state_dict: Dict[str, Any]) -> None:\n        \"\"\"\n        Overview:\n            Load the state_dict variable into policy learn mode.\n        Arguments:\n            - state_dict (:obj:`Dict[str, Any]`): the dict of policy learn state saved before.\n\n        .. tip::\n            If you want to only load some parts of model, you can simply set the ``strict`` argument in \\\n            load_state_dict to ``False``, or refer to ``ding.torch_utils.checkpoint_helper`` for more \\\n            complicated operation.\n        \"\"\"\n        self._learn_model.load_state_dict(state_dict['model'])\n        self._target_model.load_state_dict(state_dict['target_model'])\n        # self._optimizer.load_state_dict(state_dict['optimizer'])\n\n    def _init_collect(self) -> None:\n        r\"\"\"\n        Overview:\n            Collect mode init method. Called by ``self.__init__``.\n            Init traj and unroll length, collect model.\n            Enable the eps_greedy_sample and the hidden_state plugin.\n        \"\"\"\n        self._unroll_len = self._cfg.collect.unroll_len\n        # self._collect_model = model_wrap(self._model, wrapper_name='eps_greedy_sample')\n        self._collect_model = self._model\n        # self._collect_model.reset()\n\n    def _forward_collect(self, data: dict, eps: float) -> dict:\n        r\"\"\"\n        Overview:\n            Forward function for collect mode with eps_greedy\n        Arguments:\n            - data (:obj:`Dict[str, Any]`): Dict type data, stacked env data for predicting policy_output(action), \\\n                values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.\n            - eps (:obj:`float`): epsilon value for exploration, which is decayed by collected env step.\n        Returns:\n            - output (:obj:`Dict[int, Any]`): Dict type data, including at least inferred action according to input obs.\n        ReturnsKeys\n            - necessary: ``action``\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        if self._cfg.learn.shuffle:\n            action_ind_reverse, ally_ind_reverse = self._collect_shuffle_data(data)\n        self._collect_model.eval()\n        with torch.no_grad():\n            _, action = self._collect_model.forward(data, {'type': 'eps_greedy', 'eps': eps})\n            if self._cfg.learn.shuffle:\n                action = action_ind_reverse.gather(1, action.index_select(1, ally_ind_reverse))\n            output = {'action': action}\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\", "completion": "can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) or some continuous transitions(DRQN).\n        Arguments:\n            - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n                format as the return value of ``self._process_transition`` method.\n        Returns:\n            - samples (:obj:`dict`): The list of training samples.\n\n        .. note::\n            We will vectorize ``process_transition`` and ``get_train_sample`` method in the following release version. \\\n            And the user can customize the this data processing procedure by overriding this two methods and collector \\\n            itself.\n        \"\"\"\n        data = get_nstep_return_data(data, self._nstep, gamma=self._gamma)\n        return get_train_sample(data, self._unroll_len)\n\n    def default_model(self) -> Tuple[str, List[str]]:\n        r\"\"\"\n        Overview:\n            Return the default model name and default hyper-parameters of the model.\n        Returns:\n            - model_name (:obj:`str`): The default model name.\n            - hyper_params (:obj:`List[str]`): The default hyper-parameters of the", "metadata": {"task_id": "opendilab_ACE/162", "ground_truth": "            can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\", "fpath_tuple": ["opendilab_ACE", "ding", "policy", "ace_dqn.py"], "context_start_lineno": 281, "line_no": 410, "query_window": {"context": "        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        if self._cfg.learn.shuffle:\n            action_ind_reverse, ally_ind_reverse = self._collect_shuffle_data(data)\n        self._collect_model.eval()\n        with torch.no_grad():\n            _, action = self._collect_model.forward(data, {'type': 'eps_greedy', 'eps': eps})\n            if self._cfg.learn.shuffle:\n                action = action_ind_reverse.gather(1, action.index_select(1, ally_ind_reverse))\n            output = {'action': action}\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "ace_dqn.py"], "line_no": 410, "task_id": "opendilab_ACE/162", "start_line_no": 390, "end_line_no": 410, "window_size": 20, "context_start_lineno": 281, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "        ReturnsKeys\n            - necessary: ``logit``, ``action``\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n            can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "dqn.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6642335766423357}, {"context": "        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps, alpha=self._cfg.learn.alpha)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        \"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n            can be used for training directly. A train sample can be a processed transition(DQN with nstep TD) \\\n            or some continuous transitions(DRQN).\n        Arguments:\n            - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "sql.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6013071895424836}, {"context": "        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, mode='compute_actor')\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        output = {i: d for i, d in zip(data_id, output)}\n        return output\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        r\"\"\"\n        Overview:\n            For a given trajectory(transitions, a list of transition) data, process it into a list of sample that \\\n            can be used for training directly.\n        Arguments:\n            - data (:obj:`List[Dict[str, Any]`): The trajectory data(a list of transition), each element is the same \\\n                format as the return value of ``self._process_transition`` method.", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "impala.py"], "line_no": 320, "start_line_no": 310, "end_line_no": 330, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5838926174496645}, {"context": "            - output (:obj:`Dict[int, Dict[str,Any]]`): Dict of predicting policy_output(logit, action) for each env.\n        ReturnsKeys\n            - necessary: ``logit``, ``action``\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, mode='compute_actor')\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        output = {i: d for i, d in zip(data_id, output)}\n        return output\n\n    def _get_train_sample(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        r\"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "acer.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5390070921985816}, {"context": "            Arguments:\n                - data (:obj:`dict`): Dict type data, including at least ['obs'].\n            Returns:\n                - data (:obj:`dict`): The collected data\n            \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n            Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "cql.py"], "line_no": 900, "start_line_no": 890, "end_line_no": 910, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5285714285714286}, {"context": "        Arguments:\n            - data (:obj:`dict`): Dict type data, including at least ['obs'].\n        Returns:\n            - data (:obj:`dict`): The collected data\n        \"\"\"\n        data_id = list(data.keys())\n        data = default_collate(list(data.values()))\n        if self._cuda:\n            data = to_device(data, self._device)\n        self._collect_model.eval()\n        with torch.no_grad():\n            output = self._collect_model.forward(data, eps=eps)\n        if self._cuda:\n            output = to_device(output, 'cpu')\n        output = default_decollate(output)\n        return {i: d for i, d in zip(data_id, output)}\n\n    def _get_train_sample(self, data: list) -> Union[None, List[Any]]:\n        r\"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "c51.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5214285714285715}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/backdoor_trainer.py\n# --------------------------------------------------\n#                                             insert_pos=0)\n# \n#     return base_trainer\n# \n# \n# def hook_on_fit_start_init_local_opt(ctx):\n# \n#     ctx.original_epoch = ctx[\"num_train_epoch\"]\n#     ctx[\"num_train_epoch\"] = ctx.self_epoch\n# \n# \n# def hook_on_fit_end_reset_opt(ctx):\n# \n#     ctx[\"num_train_epoch\"] = ctx.original_epoch\n# \n# \n# def hook_on_fit_start_init_local_model(ctx):\n# \n#     # the original global model\n#     ctx.original_model = copy.deepcopy(ctx.model)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/backdoor_trainer.py\n# --------------------------------------------------\n#     if scale_poisoning or pgd_poisoning:\n# \n#         base_trainer.register_hook_in_train(\n#             new_hook=hook_on_fit_start_init_local_model,\n#             trigger='on_fit_start',\n#             insert_pos=-1)\n# \n#     if base_trainer.cfg.attack.scale_poisoning:\n# \n#         base_trainer.ctx.scale_para = base_trainer.cfg.attack.scale_para\n# \n#         base_trainer.register_hook_in_train(\n#             new_hook=hook_on_fit_end_scale_poisoning,\n#             trigger=\"on_fit_end\",\n#             insert_pos=-1)\n# \n#     if base_trainer.cfg.attack.pgd_poisoning:\n# \n#         base_trainer.ctx.self_epoch = base_trainer.cfg.attack.self_epoch\n#         base_trainer.ctx.pgd_lr = base_trainer.cfg.attack.pgd_lr\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/GAN_trainer.py\n# --------------------------------------------------\n#         new_hook=hook_on_data_injection_sav_data,\n#         trigger='on_fit_end',\n#         insert_mode=-1)\n# \n#     return base_trainer\n# \n# \n# def hood_on_fit_start_generator(ctx):\n#     '''\n#     count the FL training round before fitting\n#     Args:\n#         ctx ():\n# \n#     Returns:\n# \n#     '''\n#     ctx.gan_cra.round_num += 1\n#     logger.info('----- Round {}: GAN training ............'.format(\n#         ctx.gan_cra.round_num))\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/trainers/trainer_fedprox.py\n# --------------------------------------------------\n#                                         insert_pos=-1)\n# \n#     base_trainer.register_hook_in_eval(new_hook=_hook_del_initialization,\n#                                        trigger='on_fit_end',\n#                                        insert_pos=-1)\n# \n#     return base_trainer\n# \n# \n# def init_fedprox_ctx(base_trainer):\n#     \"\"\"Set proximal regularizer and the factor of regularizer\n# \n#     \"\"\"\n#     ctx = base_trainer.ctx\n#     cfg = base_trainer.cfg\n# \n#     cfg.defrost()\n#     cfg.regularizer.type = 'proximal_regularizer'\n#     cfg.regularizer.mu = cfg.fedprox.mu\n#     cfg.freeze()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/backdoor_trainer.py\n# --------------------------------------------------\n#             trigger='on_batch_end',\n#             insert_pos=-1)\n# \n#         base_trainer.register_hook_in_train(\n#             new_hook=hook_on_epoch_end_project_grad,\n#             trigger='on_epoch_end',\n#             insert_pos=-1)\n# \n#         base_trainer.register_hook_in_train(new_hook=hook_on_fit_end_reset_opt,\n#                                             trigger='on_fit_end',\n#                                             insert_pos=0)\n# \n#     return base_trainer\n# \n# \n# def hook_on_fit_start_init_local_opt(ctx):\n# \n#     ctx.original_epoch = ctx[\"num_train_epoch\"]\n#     ctx[\"num_train_epoch\"] = ctx.self_epoch\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/GAN_trainer.py\n# --------------------------------------------------\n#                                       sav_pth=base_trainer.cfg.outdir)\n# \n#     # ---- action-level plug-in -------\n# \n#     base_trainer.register_hook_in_train(new_hook=hood_on_fit_start_generator,\n#                                         trigger='on_fit_start',\n#                                         insert_mode=-1)\n#     base_trainer.register_hook_in_train(new_hook=hook_on_gan_cra_train,\n#                                         trigger='on_batch_start',\n#                                         insert_mode=-1)\n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_batch_injected_data_generation,\n#         trigger='on_batch_start',\n#         insert_mode=-1)\n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_batch_forward_injected_data,\n#         trigger='on_batch_forward',\n#         insert_mode=-1)\n# \n#     base_trainer.register_hook_in_train(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/attack/trainer/GAN_trainer.py\n# --------------------------------------------------\n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_batch_injected_data_generation,\n#         trigger='on_batch_start',\n#         insert_mode=-1)\n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_batch_forward_injected_data,\n#         trigger='on_batch_forward',\n#         insert_mode=-1)\n# \n#     base_trainer.register_hook_in_train(\n#         new_hook=hook_on_data_injection_sav_data,\n#         trigger='on_fit_end',\n#         insert_mode=-1)\n# \n#     return base_trainer\n# \n# \n# def hood_on_fit_start_generator(ctx):\n#     '''\n#     count the FL training round before fitting\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport logging\nfrom typing import Type\n\nimport torch\n\nfrom federatedscope.core.trainers import GeneralTorchTrainer\nfrom federatedscope.core.data.wrap_dataset import WrapDataset\nfrom federatedscope.attack.auxiliary.MIA_get_target_data import get_target_data\n\nlogger = logging.getLogger(__name__)\n\n\ndef wrap_GradientAscentTrainer(\n        base_trainer: Type[GeneralTorchTrainer]) -> Type[GeneralTorchTrainer]:\n    '''\n    wrap the gradient_invert trainer\n\n    Args:\n        base_trainer: Type: core.trainers.GeneralTorchTrainer\n\n    :returns:\n        The wrapped trainer; Type: core.trainers.GeneralTorchTrainer\n\n    '''\n\n    # base_trainer.ctx.target_data = get_target_data()\n    base_trainer.ctx.target_data_dataloader = WrapDataset(\n        get_target_data(base_trainer.cfg.data.type))\n    base_trainer.ctx.target_data = get_target_data(base_trainer.cfg.data.type)\n\n    base_trainer.ctx.is_target_batch = False\n    base_trainer.ctx.finish_injected = False\n\n    base_trainer.ctx.target_data_loss = []\n\n    base_trainer.ctx.outdir = base_trainer.cfg.outdir\n    base_trainer.ctx.round = -1\n    base_trainer.ctx.inject_round = base_trainer.cfg.attack.inject_round\n    base_trainer.ctx.mia_is_simulate_in = \\\n        base_trainer.cfg.attack.mia_is_simulate_in\n    base_trainer.ctx.mia_simulate_in_round = \\\n        base_trainer.cfg.attack.mia_simulate_in_round\n\n    base_trainer.register_hook_in_train(new_hook=hook_on_fit_start_count_round,\n                                        trigger='on_fit_start',\n                                        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(", "completion": "new_hook=hook_on_batch_start_inject_data,\n                                        trigger='on_batch_start',\n                                        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_forward_inject_data,\n        trigger='on_batch_forward',\n        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_fit_end_save_data,\n        trigger='on_fit_end',\n        insert_mode=-1)\n\n    return base_trainer\n\n\ndef hook_on_fit_start_count_round(ctx):\n    '''\n    count the FL training round before fitting\n    Args:\n        ctx ():\n\n    Returns:\n\n    '''\n    ctx.round += 1\n    logger.info('----- Round {}: Gradient Ascent training ............'.format(\n        ctx.round))\n\n\ndef hook_on_batch_start_inject_data(ctx):\n    '''\n    inject target data into the training data\n    Args:\n        ctx ():\n\n    Returns:\n\n    '''\n    if ctx.round >= ctx.inject_round and not ctx.finish_injected:\n        ctx.is_target_batch = True\n        ctx.finish_injected = True\n\n\ndef hook_on_batch_forward_inject_data(ctx):\n    '''\n    inject target data into the training data\n    Args:\n        ctx ():\n\n    Returns", "metadata": {"task_id": "alibaba_FederatedScope/163", "ground_truth": "        new_hook=hook_on_batch_start_replace_data_batch,", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "MIA_invert_gradient_trainer.py"], "context_start_lineno": 0, "line_no": 48, "query_window": {"context": "    base_trainer.ctx.target_data = get_target_data(base_trainer.cfg.data.type)\n\n    base_trainer.ctx.is_target_batch = False\n    base_trainer.ctx.finish_injected = False\n\n    base_trainer.ctx.target_data_loss = []\n\n    base_trainer.ctx.outdir = base_trainer.cfg.outdir\n    base_trainer.ctx.round = -1\n    base_trainer.ctx.inject_round = base_trainer.cfg.attack.inject_round\n    base_trainer.ctx.mia_is_simulate_in = \\\n        base_trainer.cfg.attack.mia_is_simulate_in\n    base_trainer.ctx.mia_simulate_in_round = \\\n        base_trainer.cfg.attack.mia_simulate_in_round\n\n    base_trainer.register_hook_in_train(new_hook=hook_on_fit_start_count_round,\n                                        trigger='on_fit_start',\n                                        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "MIA_invert_gradient_trainer.py"], "line_no": 48, "task_id": "alibaba_FederatedScope/163", "start_line_no": 28, "end_line_no": 48, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "                                      sav_pth=base_trainer.cfg.outdir)\n\n    # ---- action-level plug-in -------\n\n    base_trainer.register_hook_in_train(new_hook=hood_on_fit_start_generator,\n                                        trigger='on_fit_start',\n                                        insert_mode=-1)\n    base_trainer.register_hook_in_train(new_hook=hook_on_gan_cra_train,\n                                        trigger='on_batch_start',\n                                        insert_mode=-1)\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_injected_data_generation,\n        trigger='on_batch_start',\n        insert_mode=-1)\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_forward_injected_data,\n        trigger='on_batch_forward',\n        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "GAN_trainer.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4805194805194805}, {"context": "    '''\n\n    # ---------------- attribute-level plug-in -----------------------\n\n    base_trainer.ctx.target_label_ind = \\\n        base_trainer.cfg.attack.target_label_ind\n    base_trainer.ctx.gan_cra = GANCRA(base_trainer.cfg.attack.target_label_ind,\n                                      base_trainer.ctx.model,\n                                      dataset_name=base_trainer.cfg.data.type,\n                                      device=base_trainer.ctx.device,\n                                      sav_pth=base_trainer.cfg.outdir)\n\n    # ---- action-level plug-in -------\n\n    base_trainer.register_hook_in_train(new_hook=hood_on_fit_start_generator,\n                                        trigger='on_fit_start',\n                                        insert_mode=-1)\n    base_trainer.register_hook_in_train(new_hook=hook_on_gan_cra_train,\n                                        trigger='on_batch_start',\n                                        insert_mode=-1)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "GAN_trainer.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4666666666666667}, {"context": "        base_trainer.ctx.pgd_eps = base_trainer.cfg.attack.pgd_eps\n        base_trainer.ctx.batch_index = 0\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_fit_start_init_local_pgd,\n            trigger='on_fit_start',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_batch_end_project_grad,\n            trigger='on_batch_end',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_epoch_end_project_grad,\n            trigger='on_epoch_end',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(new_hook=hook_on_fit_end_reset_opt,\n                                            trigger='on_fit_end',", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "backdoor_trainer.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.43243243243243246}, {"context": "    base_trainer.register_hook_in_train(new_hook=_hook_record_initialization,\n                                        trigger='on_fit_start',\n                                        insert_pos=-1)\n\n    base_trainer.register_hook_in_eval(new_hook=_hook_record_initialization,\n                                       trigger='on_fit_start',\n                                       insert_pos=-1)\n\n    base_trainer.register_hook_in_train(new_hook=_hook_del_initialization,\n                                        trigger='on_fit_end',\n                                        insert_pos=-1)\n\n    base_trainer.register_hook_in_eval(new_hook=_hook_del_initialization,\n                                       trigger='on_fit_end',\n                                       insert_pos=-1)\n\n    return base_trainer\n\n\ndef init_fedprox_ctx(base_trainer):", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "trainers", "trainer_fedprox.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4166666666666667}, {"context": "    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_injected_data_generation,\n        trigger='on_batch_start',\n        insert_mode=-1)\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_batch_forward_injected_data,\n        trigger='on_batch_forward',\n        insert_mode=-1)\n\n    base_trainer.register_hook_in_train(\n        new_hook=hook_on_data_injection_sav_data,\n        trigger='on_fit_end',\n        insert_mode=-1)\n\n    return base_trainer\n\n\ndef hood_on_fit_start_generator(ctx):\n    '''\n    count the FL training round before fitting", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "GAN_trainer.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3974358974358974}, {"context": "            trigger='on_fit_start',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(new_hook=hook_on_fit_end_reset_opt,\n                                            trigger='on_fit_end',\n                                            insert_pos=0)\n\n    scale_poisoning = base_trainer.cfg.attack.scale_poisoning\n    pgd_poisoning = base_trainer.cfg.attack.pgd_poisoning\n\n    if scale_poisoning or pgd_poisoning:\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_fit_start_init_local_model,\n            trigger='on_fit_start',\n            insert_pos=-1)\n\n    if base_trainer.cfg.attack.scale_poisoning:\n\n        base_trainer.ctx.scale_para = base_trainer.cfg.attack.scale_para", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "backdoor_trainer.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3950617283950617}, {"context": "            trigger='on_batch_end',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(\n            new_hook=hook_on_epoch_end_project_grad,\n            trigger='on_epoch_end',\n            insert_pos=-1)\n\n        base_trainer.register_hook_in_train(new_hook=hook_on_fit_end_reset_opt,\n                                            trigger='on_fit_end',\n                                            insert_pos=0)\n\n    return base_trainer\n\n\ndef hook_on_fit_start_init_local_opt(ctx):\n\n    ctx.original_epoch = ctx[\"num_train_epoch\"]\n    ctx[\"num_train_epoch\"] = ctx.self_epoch\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "attack", "trainer", "backdoor_trainer.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.38271604938271603}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_collector.py\n# --------------------------------------------------\n# class UnwrappablePolicy(nn.Module):\n#     def __init__(self, out_features: int):\n#         super().__init__()\n#         self.linear = nn.LazyLinear(out_features)\n# \n#     def forward(self, observation, other_stuff):\n#         return self.linear(observation), other_stuff.sum()\n# \n# \n# class ParametricPolicyNet(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.param = torch.nn.Parameter(torch.randn(1, requires_grad=True))\n# \n#     def forward(self, obs):\n#         max_obs = (obs == obs.max(dim=-1, keepdim=True)[0]).cumsum(-1).argmax(-1)\n#         k = obs.shape[-1]\n#         max_obs = (max_obs + 1) % k\n#         action = torch.nn.functional.one_hot(max_obs, k)\n#         return action\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#                 self.linear = nn.Linear(hidden_dim + action_dim, 1)\n# \n#             def forward(self, hidden, act):\n#                 return self.linear(torch.cat([hidden, act], -1))\n# \n#         common = SafeModule(CommonClass(), in_keys=[\"observation\"], out_keys=[\"hidden\"])\n#         actor_subnet = ProbabilisticActor(\n#             SafeModule(ActorClass(), in_keys=[\"hidden\"], out_keys=[\"loc\", \"scale\"]),\n#             in_keys=[\"loc\", \"scale\"],\n#             distribution_class=TanhNormal,\n#             return_log_prob=True,\n#         )\n#         qvalue_subnet = ValueOperator(ValueClass(), in_keys=[\"hidden\", \"action\"])\n#         model = ActorCriticOperator(common, actor_subnet, qvalue_subnet)\n#         return model.to(device)\n# \n#     def _create_mock_data_redq(\n#         self, batch=16, obs_dim=3, action_dim=4, atoms=None, device=\"cpu\"\n#     ):\n#         # create a tensordict\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_collector.py\n# --------------------------------------------------\n#         self.out_keys = [\"action\"]\n#         self.linear = nn.LazyLinear(out_features)\n# \n#     def forward(self, tensordict):\n#         return TensorDict(\n#             {self.out_keys[0]: self.linear(tensordict.get(self.in_keys[0]))},\n#             [],\n#         )\n# \n# \n# class UnwrappablePolicy(nn.Module):\n#     def __init__(self, out_features: int):\n#         super().__init__()\n#         self.linear = nn.LazyLinear(out_features)\n# \n#     def forward(self, observation, other_stuff):\n#         return self.linear(observation), other_stuff.sum()\n# \n# \n# class ParametricPolicyNet(nn.Module):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# test/test_cost.py\n# --------------------------------------------------\n#     def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n#         # Actor\n#         class ValueClass(nn.Module):\n#             def __init__(self):\n#                 super().__init__()\n#                 self.linear = nn.Linear(obs_dim + action_dim, 1)\n# \n#             def forward(self, obs, act):\n#                 return self.linear(torch.cat([obs, act], -1))\n# \n#         module = ValueClass()\n#         value = ValueOperator(\n#             module=module,\n#             in_keys=[\"observation\", \"action\"],\n#         )\n#         return value.to(device)\n# \n#     def _create_mock_distributional_actor(\n#         self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n#     ):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# test/test_cost.py\n# --------------------------------------------------\n#         module = ValueClass()\n#         value = ValueOperator(\n#             module=module,\n#             in_keys=[\"observation\", \"action\"],\n#         )\n#         return value.to(device)\n# \n#     def _create_mock_distributional_actor(\n#         self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n#     ):\n#         raise NotImplementedError\n# \n#     def _create_mock_data_ddpg(\n#         self, batch=8, obs_dim=3, action_dim=4, atoms=None, device=\"cpu\"\n#     ):\n#         # create a tensordict\n#         obs = torch.randn(batch, obs_dim, device=device)\n#         next_obs = torch.randn(batch, obs_dim, device=device)\n#         if atoms:\n#             raise NotImplementedError\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n# \n#         module = ValueClass()\n#         qvalue = ValueOperator(\n#             module=module,\n#             in_keys=[\"observation\", \"action\"],\n#         )\n#         return qvalue.to(device)\n# \n#     def _create_shared_mock_actor_qvalue(\n#         self, batch=2, obs_dim=3, action_dim=4, hidden_dim=5, device=\"cpu\"\n#     ):\n#         class CommonClass(nn.Module):\n#             def __init__(self):\n#                 super().__init__()\n#                 self.linear = nn.Linear(obs_dim, hidden_dim)\n# \n#             def forward(self, obs):\n#                 return self.linear(obs)\n# \n#         class ActorClass(nn.Module):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_cost.py\n# --------------------------------------------------\n#             in_keys=[\"observation\", \"action\"],\n#         )\n#         return qvalue.to(device)\n# \n#     def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n#         module = nn.Linear(obs_dim, 1)\n#         value = ValueOperator(\n#             module=module,\n#             in_keys=[\"observation\"],\n#         )\n#         return value.to(device)\n# \n#     def _create_mock_distributional_actor(\n#         self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n#     ):\n#         raise NotImplementedError\n# \n#     def _create_mock_data_sac(\n#         self, batch=16, obs_dim=3, action_dim=4, atoms=None, device=\"cpu\"\n#     ):\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n                shape=batch_size,\n            )\n\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            categorical_action_encoding=categorical_action_encoding,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1).unsqueeze(-1)\n        obs = obs.expand(*obs.shape[:-1], 3)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -2, -3)[..., 0, :]\n\n    def _obs_step(self, obs, a):\n        return obs + a.unsqueeze(-1) / self.maxstep\n\n\nclass ContinuousActionConvMockEnv(ContinuousActionVecMockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=True,\n        pixel_shape=None,\n        **kwargs,\n    ):\n        batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n        if pixel_shape is None:\n            pixel_shape = [1, 7, 7]\n        if observation_spec is None:\n            cls.out_key = \"pixels\"\n            observation_spec = CompositeSpec(\n                pixels=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, *pixel_shape])\n                ),\n                pixels_orig=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, *pixel_shape])\n                ),\n                shape=batch_size,\n            )\n\n        if action_spec is None:\n            action_spec = BoundedTensorSpec(-1, 1, [*batch_size, pixel_shape[-1]])\n\n        if reward_spec is None:\n            reward_spec = UnboundedContinuousTensorSpec(shape=(*batch_size, 1))\n        if input_spec is None:\n            cls._out_key = \"pixels_orig\"\n            input_spec = CompositeSpec(\n                **{cls._out_key: observation_spec[\"pixels\"], \"action\": action_spec},\n                shape=batch_size,\n            )\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -1, -2).squeeze()\n\n\nclass ContinuousActionConvMockEnvNumpy(ContinuousActionConvMockEnv):\n    @classmethod\n    def __new__(\n        cls,\n        *args,\n        observation_spec=None,\n        action_spec=None,\n        input_spec=None,\n        reward_spec=None,\n        from_pixels=True,\n        **kwargs,\n    ):\n        batch_size = kwargs.setdefault(\"batch_size\", torch.Size([]))\n        if observation_spec is None:\n            cls.out_key = \"pixels\"\n            observation_spec = CompositeSpec(\n                pixels=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, 7, 7, 3])\n                ),\n                pixels_orig=UnboundedContinuousTensorSpec(\n                    shape=torch.Size([*batch_size, 7, 7, 3])\n                ),\n            )\n        return super().__new__(\n            *args,\n            observation_spec=observation_spec,\n            action_spec=action_spec,\n            reward_spec=reward_spec,\n            input_spec=input_spec,\n            from_pixels=from_pixels,\n            **kwargs,\n        )\n\n    def _get_out_obs(self, obs):\n        obs = torch.diag_embed(obs, 0, -2, -1).unsqueeze(-1)\n        obs = obs.expand(*obs.shape[:-1], 3)\n        return obs\n\n    def _get_in_obs(self, obs):\n        return obs.diagonal(0, -2, -3)[..., 0, :]\n\n    def _obs_step(self, obs, a):\n        return obs + a / self.maxstep\n\n\nclass DiscreteActionConvPolicy(DiscreteActionVecPolicy):\n    in_keys = [\"pixels\"]\n    out_keys = [\"action\"]\n\n    def _get_in_obs(self, tensordict):\n        obs = tensordict.get(*self.in_keys).diagonal(0, -1, -2).squeeze()\n        return obs\n\n\nclass DummyModelBasedEnvBase(ModelBasedEnvBase):\n    \"\"\"Dummy environnement for Model Based RL algorithms.\n\n    This class is meant to be used to test the model based environnement.\n\n    Args:\n        world_model (WorldModel): the world model to use for the environnement.\n        device (str or torch.device, optional): the device to use for the environnement.\n        dtype (torch.dtype, optional): the dtype to use for the environnement.\n        batch_size (sequence of int, optional): the batch size to use for the environnement.\n    \"\"\"\n\n    def __init__(\n        self,\n        world_model,\n        device=\"cpu\",\n        dtype=None,\n        batch_size=None,\n    ):\n        super().__init__(\n            world_model,\n            device=device,\n            dtype=dtype,\n            batch_size=batch_size,\n        )\n        self.observation_spec = CompositeSpec(\n            hidden_observation=UnboundedContinuousTensorSpec(\n                (\n                    *self.batch_size,\n                    4,\n                )\n            ),\n            shape=self.batch_size,\n        )\n        self.input_spec = CompositeSpec(\n            hidden_observation=UnboundedContinuousTensorSpec(\n                (\n                    *self.batch_size,\n                    4,\n                )\n            ),\n            action=UnboundedContinuousTensorSpec(\n                (\n                    *self.batch_size,\n                    1,\n                )\n            ),\n            shape=self.batch_size,\n        )\n        self.reward_spec = UnboundedContinuousTensorSpec(\n            (\n                *self.batch_size,\n                1,\n            )\n        )\n\n    def _reset(self, tensordict: TensorDict, **kwargs) -> TensorDict:\n        td = TensorDict(\n            {\n                \"hidden_observation\": self.input_spec[\"hidden_observation\"].rand(),\n            },\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n        return td\n\n\nclass ActionObsMergeLinear(nn.Module):\n    def __init__(self, in_size, out_size):\n        super().__init__()\n        self.linear = nn.Linear(in_size, out_size)\n\n    def forward(self, observation, action):\n        return self.linear(torch.cat([observation, action], dim=-1))\n\n\nclass CountingEnv(EnvBase):\n    def __init__(self, max_steps: int = 5, **kwargs):\n        super().__init__(**kwargs)\n        self.max_steps = max_steps\n\n        self.observation_spec = CompositeSpec(", "completion": "count=UnboundedContinuousTensorSpec(shape=(1,))\n        self.action_spec = BoundedTensorSpec(0, 1, shape=(1,))\n        self.reward_spec = UnboundedContinuousTensorSpec(shape=(1,))\n\n    def _reset(self, **kwargs):\n        self.count = 0\n        return TensorDict(count=torch.tensor([self.count]))\n\n    def _step(self, action):\n        self.count += 1\n        done = self.count >= self.max_steps\n        reward = 1 if done else 0\n        return TensorDict(count=torch.tensor([self.count])), reward, done, {}\n\n    def _render(self, mode=\"human\"):\n        pass\n\n\nclass DummyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(1, 1)\n\n    def forward(self, observation, action):\n        return self.linear(torch.cat([observation[\"count\"], action], dim=-1))\n\n\nclass DummyWorldModel(WorldModel):\n    def __init__(self):\n        super().__init__(observation_spec=CompositeSpec(count=UnboundedContinuousTensorSpec(shape=(1,))),\n                         action_spec=BoundedTensorSpec(0, 1, shape=(1,)),\n                         reward_spec", "metadata": {"task_id": "pytorch_rl/13", "ground_truth": "            observation=UnboundedContinuousTensorSpec(", "fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "context_start_lineno": 632, "line_no": 851, "query_window": {"context": "            device=self.device,\n        )\n        return td\n\n\nclass ActionObsMergeLinear(nn.Module):\n    def __init__(self, in_size, out_size):\n        super().__init__()\n        self.linear = nn.Linear(in_size, out_size)\n\n    def forward(self, observation, action):\n        return self.linear(torch.cat([observation, action], dim=-1))\n\n\nclass CountingEnv(EnvBase):\n    def __init__(self, max_steps: int = 5, **kwargs):\n        super().__init__(**kwargs)\n        self.max_steps = max_steps\n\n        self.observation_spec = CompositeSpec(", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 851, "task_id": "pytorch_rl/13", "start_line_no": 831, "end_line_no": 851, "window_size": 20, "context_start_lineno": 632, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n\n        module = ValueClass()\n        qvalue = ValueOperator(\n            module=module,\n            in_keys=[\"observation\", \"action\"],\n        )\n        return qvalue.to(device)\n\n    def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        module = nn.Linear(obs_dim, 1)\n        value = ValueOperator(\n            module=module,\n            in_keys=[\"observation\"],\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 950, "start_line_no": 940, "end_line_no": 960, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3963963963963964}, {"context": "        return actor.to(device)\n\n    def _create_mock_qvalue(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n\n        module = ValueClass()\n        qvalue = ValueOperator(\n            module=module,\n            in_keys=[\"observation\", \"action\"],\n        )\n        return qvalue.to(device)\n\n    def _create_shared_mock_actor_qvalue(\n        self, batch=2, obs_dim=3, action_dim=4, hidden_dim=5, device=\"cpu\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 1350, "start_line_no": 1340, "end_line_no": 1360, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.39316239316239315}, {"context": "    def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        # Actor\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n\n        module = ValueClass()\n        value = ValueOperator(\n            module=module,\n            in_keys=[\"observation\", \"action\"],\n        )\n        return value.to(device)\n\n    def _create_mock_distributional_actor(\n        self, batch=2, obs_dim=3, action_dim=4, atoms=5, vmin=1, vmax=5\n    ):", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}, {"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 680, "start_line_no": 670, "end_line_no": 690, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38524590163934425}, {"context": "        action_spec = BoundedTensorSpec(\n            -torch.ones(action_dim), torch.ones(action_dim), (action_dim,)\n        )\n        module = nn.Linear(obs_dim, action_dim)\n        actor = Actor(\n            spec=action_spec,\n            module=module,\n        )\n        return actor.to(device)\n\n    def _create_mock_value(self, batch=2, obs_dim=3, action_dim=4, device=\"cpu\"):\n        # Actor\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(obs_dim + action_dim, 1)\n\n            def forward(self, obs, act):\n                return self.linear(torch.cat([obs, act], -1))\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}, {"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 670, "start_line_no": 660, "end_line_no": 680, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3793103448275862}, {"context": "        output = self.linear(observation)\n        if self.multiple_outputs:\n            return output, output.sum(), output.min(), output.max()\n        return self.linear(observation)\n\n\nclass TensorDictCompatiblePolicy(nn.Module):\n    def __init__(self, out_features: int):\n        super().__init__()\n        self.in_keys = [\"observation\"]\n        self.out_keys = [\"action\"]\n        self.linear = nn.LazyLinear(out_features)\n\n    def forward(self, tensordict):\n        return TensorDict(\n            {self.out_keys[0]: self.linear(tensordict.get(self.in_keys[0]))},\n            [],\n        )\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_collector.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3783783783783784}, {"context": "            def __init__(self):\n                super().__init__()\n                self.linear = NormalParamWrapper(nn.Linear(hidden_dim, 2 * action_dim))\n\n            def forward(self, hidden):\n                return self.linear(hidden)\n\n        class ValueClass(nn.Module):\n            def __init__(self):\n                super().__init__()\n                self.linear = nn.Linear(hidden_dim + action_dim, 1)\n\n            def forward(self, hidden, act):\n                return self.linear(torch.cat([hidden, act], -1))\n\n        common = SafeModule(CommonClass(), in_keys=[\"observation\"], out_keys=[\"hidden\"])\n        actor_subnet = ProbabilisticActor(\n            SafeModule(ActorClass(), in_keys=[\"hidden\"], out_keys=[\"loc\", \"scale\"]),\n            in_keys=[\"loc\", \"scale\"],\n            distribution_class=TanhNormal,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_cost.py"], "line_no": 1380, "start_line_no": 1370, "end_line_no": 1390, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.37606837606837606}, {"context": "        self.out_keys = [\"action\"]\n        self.linear = nn.LazyLinear(out_features)\n\n    def forward(self, tensordict):\n        return TensorDict(\n            {self.out_keys[0]: self.linear(tensordict.get(self.in_keys[0]))},\n            [],\n        )\n\n\nclass UnwrappablePolicy(nn.Module):\n    def __init__(self, out_features: int):\n        super().__init__()\n        self.linear = nn.LazyLinear(out_features)\n\n    def forward(self, observation, other_stuff):\n        return self.linear(observation), other_stuff.sum()\n\n\nclass ParametricPolicyNet(nn.Module):", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_collector.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.375}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n#         tensordict_out = tensordict_out.exclude(*obs_keys, inplace=True)\n#         tensordict_out.set(\"next\", tensordict_out_select)\n# \n#         reward = tensordict_out.get(\"reward\")\n#         # unsqueeze rewards if needed\n#         # the input tensordict may have more leading dimensions than the batch_size\n#         # e.g. in model-based contexts.\n#         batch_size = self.batch_size\n#         dims = len(batch_size)\n#         leading_batch_size = (\n#             tensordict_out.batch_size[:-dims] if dims else tensordict_out.shape\n#         )\n#         expected_reward_shape = torch.Size(\n#             [*leading_batch_size, *self.reward_spec.shape]\n#         )\n#         actual_reward_shape = reward.shape\n#         if actual_reward_shape != expected_reward_shape:\n#             reward = reward.view(expected_reward_shape)\n#             tensordict_out.set(\"reward\", reward)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/postprocs/postprocs.py\n# --------------------------------------------------\n#         done = tensordict.get(\"done\")\n#         if (\"collector\", \"mask\") in tensordict.keys(True):\n#             mask = tensordict.get((\"collector\", \"mask\")).view_as(done)\n#         else:\n#             mask = done.clone().flip(1).cumsum(1).flip(1).to(torch.bool)\n#         reward = tensordict.get(\"reward\")\n# \n#         b, T, *_ = mask.shape\n# \n#         terminal, post_terminal = _get_terminal(done, self.n_steps_max)\n# \n#         # Compute gamma for n-step value function\n#         gamma_masked = _get_gamma(self.gamma, reward, mask, self.n_steps_max)\n# \n#         # Discounted summed reward\n#         partial_return = _conv1d_reward(reward, self.gammas, self.n_steps_max)\n# \n#         # step_to_next_state\n#         nonterminal = ~post_terminal[:, :T]\n#         steps_to_next_obs = _get_steps_to_next_obs(nonterminal, self.n_steps_max)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n#                 obs = tensordict_out.get(key)\n#                 self.observation_spec.type_check(obs, key)\n# \n#             if tensordict_out.get(\"reward\").dtype is not self.reward_spec.dtype:\n#                 raise TypeError(\n#                     f\"expected reward.dtype to be {self.reward_spec.dtype} \"\n#                     f\"but got {tensordict_out.get('reward').dtype}\"\n#                 )\n# \n#             if tensordict_out.get(\"done\").dtype is not torch.bool:\n#                 raise TypeError(\n#                     f\"expected done.dtype to be torch.bool but got {tensordict_out.get('done').dtype}\"\n#                 )\n#         tensordict.update(tensordict_out, inplace=self._inplace_update)\n# \n#         return tensordict\n# \n#     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         raise NotImplementedError(\"EnvBase.forward is not implemented\")\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/value/advantages.py\n# --------------------------------------------------\n#             ... )\n#             >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n#             >>> reward = torch.randn(1, 10, 1)\n#             >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n#             >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n# \n#         \"\"\"\n#         if tensordict.batch_dims < 1:\n#             raise RuntimeError(\n#                 \"Expected input tensordict to have at least one dimensions, got\"\n#                 f\"tensordict.batch_size = {tensordict.batch_size}\"\n#             )\n#         reward = tensordict.get(\"reward\")\n#         if self.average_rewards:\n#             reward = reward - reward.mean()\n#             reward = reward / reward.std().clamp_min(1e-4)\n#             tensordict.set(\n#                 \"reward\", reward\n#             )  # we must update the rewards if they are used later in the code\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/value/advantages.py\n# --------------------------------------------------\n#         gamma = self.gamma\n#         kwargs = {}\n#         if self.is_functional and params is None:\n#             raise RuntimeError(\n#                 \"Expected params to be passed to advantage module but got none.\"\n#             )\n#         if params is not None:\n#             kwargs[\"params\"] = params.detach()\n#         with hold_out_net(self.value_network):\n#             self.value_network(tensordict, **kwargs)\n#             value = tensordict.get(self.value_key)\n# \n#         # we may still need to pass gradient, but we don't want to assign grads to\n#         # value net params\n#         step_td = step_mdp(tensordict)\n#         if target_params is not None:\n#             # we assume that target parameters are not differentiable\n#             kwargs[\"params\"] = target_params\n#         elif \"params\" in kwargs:\n#             kwargs[\"params\"] = kwargs[\"params\"].detach()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/value/advantages.py\n# --------------------------------------------------\n#                 f\"tensordict.batch_size = {tensordict.batch_size}\"\n#             )\n#         reward = tensordict.get(\"reward\")\n#         if self.average_rewards:\n#             reward = reward - reward.mean()\n#             reward = reward / reward.std().clamp_min(1e-4)\n#             tensordict.set(\n#                 \"reward\", reward\n#             )  # we must update the rewards if they are used later in the code\n# \n#         gamma = self.gamma\n#         kwargs = {}\n#         if self.is_functional and params is None:\n#             raise RuntimeError(\n#                 \"Expected params to be passed to advantage module but got none.\"\n#             )\n#         if params is not None:\n#             kwargs[\"params\"] = params.detach()\n#         with hold_out_net(self.value_network):\n#             self.value_network(tensordict, **kwargs)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n, but we don't want to assign grads to\n        # value net params\n        step_td = step_mdp(tensordict)\n        if target_params is not None:\n            # we assume that target parameters are not differentiable\n            kwargs[\"params\"] = target_params\n        elif \"params\" in kwargs:\n            kwargs[\"params\"] = kwargs[\"params\"].detach()\n        with hold_out_net(self.value_network):\n            self.value_network(step_td, **kwargs)\n            next_value = step_td.get(self.value_key)\n\n        done = tensordict.get(\"done\")\n        adv = td_advantage_estimate(gamma, value, next_value, reward, done)\n        tensordict.set(\"advantage\", adv)\n        tensordict.set(\"value_target\", adv + value)\n        return tensordict\n\n\nclass TDLambdaEstimate(nn.Module):\n    \"\"\"TD-Lambda estimate of advantage function.\n\n    Args:\n        gamma (scalar): exponential mean discount.\n        lmbda (scalar): trajectory discount.\n        value_network (SafeModule): value operator used to retrieve the value estimates.\n        average_rewards (bool, optional): if True, rewards will be standardized\n            before the TD is computed.\n        differentiable (bool, optional): if True, gradients are propagated throught\n            the computation of the value function. Default is :obj:`False`.\n        vectorized (bool, optional): whether to use the vectorized version of the\n            lambda return. Default is `True`.\n        advantage_key (str or tuple of str, optional): the key of the advantage entry.\n            Defaults to \"advantage\".\n        value_target_key (str or tuple of str, optional): the key of the advantage entry.\n            Defaults to \"value_target\".\n        value_key (str or tuple of str, optional): the value key to read from the input tensordict.\n            Defaults to \"state_value\".\n\n    \"\"\"\n\n    def __init__(\n        self,\n        gamma: Union[float, torch.Tensor],\n        lmbda: Union[float, torch.Tensor],\n        value_network: SafeModule,\n        average_rewards: bool = False,\n        differentiable: bool = False,\n        vectorized: bool = True,\n        advantage_key: Union[str, Tuple] = \"advantage\",\n        value_target_key: Union[str, Tuple] = \"value_target\",\n        value_key: Union[str, Tuple] = \"state_value\",\n    ):\n        super().__init__()\n        try:\n            device = next(value_network.parameters()).device\n        except StopIteration:\n            device = torch.device(\"cpu\")\n        self.register_buffer(\"gamma\", torch.tensor(gamma, device=device))\n        self.register_buffer(\"lmbda\", torch.tensor(lmbda, device=device))\n        self.value_network = value_network\n        self.vectorized = vectorized\n\n        self.average_rewards = average_rewards\n        self.differentiable = differentiable\n        self.value_key = value_key\n        if value_key not in value_network.out_keys:\n            raise KeyError(\n                f\"value key '{value_key}' not found in value network out_keys.\"\n            )\n\n        self.advantage_key = advantage_key\n        self.value_target_key = value_target_key\n\n        self.in_keys = (\n            value_network.in_keys\n            + [\"reward\", \"done\"]\n            + [(\"next\", in_key) for in_key in value_network.in_keys]\n        )\n        self.out_keys = [self.advantage_key, self.value_target_key]\n\n    @property\n    def is_functional(self):\n        return (\n            \"_is_stateless\" in self.value_network.__dict__\n            and self.value_network.__dict__[\"_is_stateless\"]\n        )\n\n    @_self_set_grad_enabled\n    @dispatch_kwargs\n    def forward(\n        self,\n        tensordict: TensorDictBase,\n        params: Optional[List[Tensor]] = None,\n        target_params: Optional[List[Tensor]] = None,\n    ) -> TensorDictBase:\n        \"\"\"Computes the TDLambdaEstimate given the data in tensordict.\n\n        If a functional module is provided, a nested TensorDict containing the parameters\n        (and if relevant the target parameters) can be passed to the module.\n\n        Args:\n            tensordict (TensorDictBase): A TensorDict containing the data\n                (an observation key, \"action\", \"reward\", \"done\" and \"next\" tensordict state\n                as returned by the environment) necessary to compute the value estimates and the TDLambdaEstimate.\n                The data passed to this module should be structured as :obj:`[*B, T, F]` where :obj:`B` are\n                the batch size, :obj:`T` the time dimension and :obj:`F` the feature dimension(s).\n            params (TensorDictBase, optional): A nested TensorDict containing the params\n                to be passed to the functional value network module.\n            target_params (TensorDictBase, optional): A nested TensorDict containing the\n                target params to be passed to the functional value network module.\n\n        Returns:\n            An updated TensorDict with an advantage and a value_error keys as defined in the constructor.\n\n        Examples:\n            >>> from tensordict import TensorDict\n            >>> value_net = SafeModule(\n            ...     nn.Linear(3, 1), in_keys=[\"obs\"], out_keys=[\"state_value\"]\n            ... )\n            >>> module = TDLambdaEstimate(\n            ...     gamma=0.98,\n            ...     lmbda=0.94,\n            ...     value_network=value_net,\n            ...     differentiable=False,\n            ... )\n            >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n            >>> reward = torch.randn(1, 10, 1)\n            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n            >>> tensordict = TensorDict({\"obs\": obs, \"next\": {\"obs\": next_obs}, \"done\": done, \"reward\": reward}, [1, 10])\n            >>> _ = module(tensordict)\n            >>> assert \"advantage\" in tensordict.keys()\n\n        The module supports non-tensordict (i.e. unpacked tensordict) inputs too:\n\n        Examples:\n            >>> value_net = SafeModule(\n            ...     nn.Linear(3, 1), in_keys=[\"obs\"], out_keys=[\"state_value\"]\n            ... )\n            >>> module = TDLambdaEstimate(\n            ...     gamma=0.98,\n            ...     lmbda=0.94,\n            ...     value_network=value_net,\n            ...     differentiable=False,\n            ... )\n            >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n            >>> reward = torch.randn(1, 10, 1)\n            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n\n        \"\"\"\n        if tensordict.batch_dims < 1:\n            raise RuntimeError(\n                \"Expected input tensordict to have at least one dimensions, got\"\n                f\"tensordict.batch_size = {tensordict.batch_size}\"\n            )\n        reward = tensordict.get(\"reward\")\n        if self.average_rewards:\n            reward = reward - reward.mean()\n            reward = reward / reward.std().clamp_min(1e-4)\n            tensordict.set(\n                \"reward\", reward\n            )  # we must update the rewards if they are used later in the code\n\n        gamma = self.gamma\n        lmbda = self.lmbda\n\n        kwargs = {}", "completion": "```python\n        if self.is_functional and params is None:\n            raise RuntimeError(\n                \"Expected params to be passed to advantage module but got none.\"\n            )\n        if params is not None:\n            kwargs[\"params\"] = params.detach()\n        with hold_out_net(self.value_network):\n            self.value_network(tensordict, **kwargs)\n            value = tensordict.get(self.value_key)\n```\n\n```python\n        # we may still need to pass gradient, but we don't want to assign grads to\n        # value net params\n        step_td = step_mdp(tensordict)\n        if target_params is not None:\n            # we assume that target parameters are not differentiable\n            kwargs[\"params\"] = target_params\n        elif \"params\" in kwargs:\n            kwargs[\"params\"] = kwargs[\"params\"].detach()\n        with hold_out_net(self.value_network):\n            self.value_network(step_td, **kwargs)\n            next_value = step_td.get(self.value_key)\n```\n\n```python\n        done = tensordict.get(\"done\")\n        adv = td_advantage_estimate(gamma, value, next_value, reward, done)\n        tensordict.set(\"advantage\", adv)\n       ", "metadata": {"task_id": "pytorch_rl/56", "ground_truth": "        if self.is_functional and params is None:", "fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "context_start_lineno": 182, "line_no": 350, "query_window": {"context": "            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n\n        \"\"\"\n        if tensordict.batch_dims < 1:\n            raise RuntimeError(\n                \"Expected input tensordict to have at least one dimensions, got\"\n                f\"tensordict.batch_size = {tensordict.batch_size}\"\n            )\n        reward = tensordict.get(\"reward\")\n        if self.average_rewards:\n            reward = reward - reward.mean()\n            reward = reward / reward.std().clamp_min(1e-4)\n            tensordict.set(\n                \"reward\", reward\n            )  # we must update the rewards if they are used later in the code\n\n        gamma = self.gamma\n        lmbda = self.lmbda\n\n        kwargs = {}", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 350, "task_id": "pytorch_rl/56", "start_line_no": 330, "end_line_no": 350, "window_size": 20, "context_start_lineno": 182, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            ... )\n            >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n            >>> reward = torch.randn(1, 10, 1)\n            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n\n        \"\"\"\n        if tensordict.batch_dims < 1:\n            raise RuntimeError(\n                \"Expected input tensordict to have at least one dimensions, got\"\n                f\"tensordict.batch_size = {tensordict.batch_size}\"\n            )\n        reward = tensordict.get(\"reward\")\n        if self.average_rewards:\n            reward = reward - reward.mean()\n            reward = reward / reward.std().clamp_min(1e-4)\n            tensordict.set(\n                \"reward\", reward\n            )  # we must update the rewards if they are used later in the code\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.7796610169491526}, {"context": "                f\"tensordict.batch_size = {tensordict.batch_size}\"\n            )\n        reward = tensordict.get(\"reward\")\n        if self.average_rewards:\n            reward = reward - reward.mean()\n            reward = reward / reward.std().clamp_min(1e-4)\n            tensordict.set(\n                \"reward\", reward\n            )  # we must update the rewards if they are used later in the code\n\n        gamma = self.gamma\n        kwargs = {}\n        if self.is_functional and params is None:\n            raise RuntimeError(\n                \"Expected params to be passed to advantage module but got none.\"\n            )\n        if params is not None:\n            kwargs[\"params\"] = params.detach()\n        with hold_out_net(self.value_network):\n            self.value_network(tensordict, **kwargs)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6076923076923076}, {"context": "        The module supports non-tensordict (i.e. unpacked tensordict) inputs too:\n\n        Examples:\n            >>> value_net = SafeModule(\n            ...     nn.Linear(3, 1), in_keys=[\"obs\"], out_keys=[\"state_value\"]\n            ... )\n            >>> module = TDEstimate(\n            ...     gamma=0.98,\n            ...     value_network=value_net,\n            ...     differentiable=False,\n            ... )\n            >>> obs, next_obs = torch.randn(2, 1, 10, 3)\n            >>> reward = torch.randn(1, 10, 1)\n            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)\n            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)\n\n        \"\"\"\n        if tensordict.batch_dims < 1:\n            raise RuntimeError(\n                \"Expected input tensordict to have at least one dimensions, got\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "value", "advantages.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38311688311688313}, {"context": "        done = tensordict_out.get(\"done\")\n        # unsqueeze done if needed\n        expected_done_shape = torch.Size([*leading_batch_size, *batch_size, 1])\n        actual_done_shape = done.shape\n        if actual_done_shape != expected_done_shape:\n            done = done.view(expected_done_shape)\n            tensordict_out.set(\"done\", done)\n\n        if self.run_type_checks:\n            for key in self._select_observation_keys(tensordict_out):\n                obs = tensordict_out.get(key)\n                self.observation_spec.type_check(obs, key)\n\n            if tensordict_out.get(\"reward\").dtype is not self.reward_spec.dtype:\n                raise TypeError(\n                    f\"expected reward.dtype to be {self.reward_spec.dtype} \"\n                    f\"but got {tensordict_out.get('reward').dtype}\"\n                )\n\n            if tensordict_out.get(\"done\").dtype is not torch.bool:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.30666666666666664}, {"context": "                rewards.\n\n\n        Returns:\n            in-place transformation of the input tensordict.\n\n        \"\"\"\n        if tensordict.batch_dims != 2:\n            raise RuntimeError(\"Expected a tensordict with B x T x ... dimensions\")\n\n        done = tensordict.get(\"done\")\n        if (\"collector\", \"mask\") in tensordict.keys(True):\n            mask = tensordict.get((\"collector\", \"mask\")).view_as(done)\n        else:\n            mask = done.clone().flip(1).cumsum(1).flip(1).to(torch.bool)\n        reward = tensordict.get(\"reward\")\n\n        b, T, *_ = mask.shape\n\n        terminal, post_terminal = _get_terminal(done, self.n_steps_max)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "postprocs", "postprocs.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2972972972972973}, {"context": "        if tensordict_out is tensordict:\n            raise RuntimeError(\n                \"EnvBase._step should return outplace changes to the input \"\n                \"tensordict. Consider emptying the TensorDict first (e.g. tensordict.empty() or \"\n                \"tensordict.select()) inside _step before writing new tensors onto this new instance.\"\n            )\n        tensordict.unlock()\n\n        obs_keys = set(self.observation_spec.keys())\n        tensordict_out_select = tensordict_out.select(*obs_keys)\n        tensordict_out = tensordict_out.exclude(*obs_keys, inplace=True)\n        tensordict_out.set(\"next\", tensordict_out_select)\n\n        reward = tensordict_out.get(\"reward\")\n        # unsqueeze rewards if needed\n        # the input tensordict may have more leading dimensions than the batch_size\n        # e.g. in model-based contexts.\n        batch_size = self.batch_size\n        dims = len(batch_size)\n        leading_batch_size = (", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.28402366863905326}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n# \n#   assigned_worker: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   stopping_reason: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   _infeasibility_reason: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/context.py\n# --------------------------------------------------\n#       factory=dict,\n#       validator=attr.validators.deep_mapping(\n#           key_validator=attr.validators.instance_of(str),\n#           value_validator=attr.validators.instance_of(ParameterValue),\n#           mapping_validator=attr.validators.instance_of(dict)),\n#       on_setattr=attr.setters.validate)  # pytype: disable=wrong-arg-types\n# \n#   metadata: Metadata = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=Metadata(),\n#       validator=attr.validators.instance_of(Metadata),\n#       on_setattr=attr.setters.validate)\n# \n#   related_links: Dict[str, str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       factory=dict,\n#       validator=attr.validators.deep_mapping(\n#           key_validator=attr.validators.instance_of(str),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   _infeasibility_reason: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   description: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   related_links: Dict[str, str] = attr.ib(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/base_study_config.py\n# --------------------------------------------------\n#       # FYI: Converter is applied before validator.\n#       converter=lambda x: float(x) if x is not None else -np.inf,\n#       validator=[attr.validators.instance_of(float), _min_leq_max],\n#       kw_only=True)\n# \n#   # Maximum value of this metric can be optionally specified.\n#   max_value: float = attr.field(\n#       init=True,\n#       default=None,\n#       # FYI: Converter is applied before validator.\n#       converter=lambda x: float(x) if x is not None else np.inf,\n#       validator=[attr.validators.instance_of(float), _max_geq_min],\n#       on_setattr=attr.setters.validate,\n#       kw_only=True)\n# \n#   def min_value_or(self, default_value_fn: Callable[[], float]) -> float:\n#     \"\"\"Returns the minimum value if finite, or default_value_fn().\n# \n#     Avoids the common pitfalls of using\n#       `metric.min_value or default_value`\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#   )\n# \n#   description: Optional[str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       validator=attr.validators.optional(attr.validators.instance_of(str)),\n#   )\n# \n#   related_links: Dict[str, str] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       factory=dict,\n#       validator=attr.validators.deep_mapping(\n#           key_validator=attr.validators.instance_of(str),\n#           value_validator=attr.validators.instance_of(str),\n#           mapping_validator=attr.validators.instance_of(dict)),\n#   )  # pytype: disable=wrong-arg-types\n# \n#   final_measurement: Optional[Measurement] = attr.ib(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#       factory=list,\n#       validator=attr.validators.deep_iterable(\n#           member_validator=attr.validators.instance_of(Measurement),\n#           iterable_validator=attr.validators.instance_of(list)),\n#   )\n# \n#   creation_time: Optional[datetime.datetime] = attr.ib(\n#       init=True,\n#       default=datetime.datetime.now(),\n#       converter=_to_local_time,\n#       kw_only=True,\n#       repr=lambda v: v.strftime('%x %X') if v is not None else 'None',\n#       validator=attr.validators.optional(\n#           attr.validators.instance_of(datetime.datetime)),\n#   )\n# \n#   completion_time: Optional[datetime.datetime] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/trial.py\n# --------------------------------------------------\n#       kw_only=True,\n#       repr=lambda v: v.strftime('%x %X') if v is not None else 'None',\n#       validator=attr.validators.optional(\n#           attr.validators.instance_of(datetime.datetime)),\n#   )\n# \n#   completion_time: Optional[datetime.datetime] = attr.ib(\n#       init=True,\n#       kw_only=True,\n#       default=None,\n#       repr=lambda v: v.strftime('%x %X') if v is not None else 'None',\n#       converter=_to_local_time,\n#       validator=attr.validators.optional(\n#           attr.validators.instance_of(datetime.datetime)),\n#   )\n# \n#   @property\n#   def duration(self) -> Optional[datetime.timedelta]:\n#     \"\"\"Returns the duration of this Trial if it is completed, or None.\"\"\"\n#     if self.completion_time:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"ParameterConfig wraps ParameterConfig and ParameterSpec protos.\"\"\"\n\nimport collections\nfrom typing import Sized, Collection, Set as AbstractSet\nimport copy\nimport enum\nimport json\nimport math\nimport re\nfrom typing import Generator, Iterator, List, Optional, Sequence, Tuple, Union, overload\n\nfrom absl import logging\nimport attr\nfrom vizier._src.pyvizier.shared import trial\n\nExternalType = trial.ExternalType\nParameterType = trial.ParameterType\n\n\nclass ScaleType(enum.Enum):\n  \"\"\"Valid Values for ParameterConfig.scale_type.\"\"\"\n  LINEAR = 'LINEAR'\n  LOG = 'LOG'\n  REVERSE_LOG = 'REVERSE_LOG'\n  UNIFORM_DISCRETE = 'UNIFORM_DISCRETE'\n\n  def is_nonlinear(self) -> bool:\n    return self in [self.LOG, self.REVERSE_LOG]\n\n\n# A sequence of possible internal parameter values.\nParameterValueTypes = Union[str, int, float, bool]\nMonotypeParameterSequence = Union[Sequence[Union[int, float]], Sequence[str]]\nMonotypeParameterList = Union[List[Union[int, float]], List[str]]\n\n\ndef _validate_bounds(bounds: Union[Tuple[int, int], Tuple[float, float]]):\n  \"\"\"Validates the bounds.\"\"\"\n  if len(bounds) != 2:\n    raise ValueError('Bounds must have length 2. Given: {}'.format(bounds))\n  lower = bounds[0]\n  upper = bounds[1]\n  if not all([math.isfinite(v) for v in (lower, upper)]):\n    raise ValueError(\n        'Both \"lower\" and \"upper\" must be finite. Given: (%f, %f)' %\n        (lower, upper))\n  if lower > upper:\n    raise ValueError(\n        'Lower cannot be greater than upper: given lower={} upper={}'.format(\n            lower, upper))\n\n\ndef _get_feasible_points_and_bounds(\n    feasible_values: Sequence[float]\n) -> Tuple[List[float], Union[Tuple[int, int], Tuple[float, float]]]:\n  \"\"\"Validates and converts feasible values to floats.\"\"\"\n  if not all([math.isfinite(p) for p in feasible_values]):\n    raise ValueError('Feasible values must all be finite. Given: {}' %\n                     feasible_values)\n\n  feasible_points = list(sorted(feasible_values))\n  bounds = (feasible_points[0], feasible_points[-1])\n  return feasible_points, bounds\n\n\ndef _get_categories(categories: Sequence[str]) -> List[str]:\n  \"\"\"Returns the categories.\"\"\"\n  return sorted(list(categories))\n\n\ndef _get_default_value(\n    param_type: ParameterType,\n    default_value: Union[float, int, str]) -> Union[float, int, str]:\n  \"\"\"Validates and converts the default_value to the right type.\"\"\"\n  if (param_type in (ParameterType.DOUBLE, ParameterType.DISCRETE) and\n      (isinstance(default_value, float) or isinstance(default_value, int))):\n    return float(default_value)\n  elif (param_type == ParameterType.INTEGER and\n        (isinstance(default_value, float) or isinstance(default_value, int))):\n    if isinstance(default_value, int):\n      return default_value\n    else:\n      # Check if the float rounds nicely.\n      default_int_value = round(default_value)\n      if not math.isclose(default_value, default_int_value):\n        raise ValueError('default_value for an INTEGER parameter should be an '\n                         'integer, got float: [{}]'.format(default_value))\n      return default_int_value\n  elif (param_type == ParameterType.CATEGORICAL and\n        isinstance(default_value, str)):\n    return default_value\n  raise ValueError(\n      'default_value has an incorrect type. ParameterType has type {}, '\n      'but default_value has type {}'.format(param_type.name,\n                                             type(default_value)))\n\n\n#######################\n# Experimental features\n#######################\nclass FidelityMode(enum.Enum):\n  \"\"\"Decides how the fidelity config should be interpreated.\n\n  SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower\n    fidelity measurement. Currently, no algorithms can take advatange of it, and\n    Vizier behaves exactly like NON_SEQUENTIAL case. This is for tracking\n    purposes only.\n\n  NOT_SEQUENTIAL: Each fidelity is separately measured. Example: Fidelity\n    is the fraction of dataset to train on.\n\n  STEPS: Fidelity determines the maximum value for Measurement.steps reported\n    to Vizier. There is one-to-one correspondence between steps and fidelity.\n    A high fideltiy Trial's measurements contain lower fidelity evaluations.\n    When this is enabled, suggestion models do not use\n    Trials' final_measurement. Instead, it reads the measurements whose\n    \"steps\" exactly match one of the fidelities, and treats them as if they\n    were separate Trials. Example: Fidelity is the number of total epochs\n    to train on.\n  \"\"\"\n  SEQUENTIAL = 'SEQUENTIAL'\n  NOT_SEQUENTIAL = 'NOT_SEQUENTIAL'\n  STEPS = 'STEPS'\n\n\n@attr.define\nclass FidelityConfig:\n  mode: FidelityMode = attr.field(converter=FidelityMode)\n  cost_ratio: Sequence[float] = attr.field(\n      converter=tuple, default=tuple(), kw_only=True)\n\n\n########################\n# Experimental features end here\n########################\n\n\n@attr.s(auto_attribs=True, frozen=False, init=True, slots=True, eq=True)\nclass ParameterConfig:\n  \"\"\"A Vizier ParameterConfig.\n\n  Use ParameterConfig.factory to create a valid instance.\n  \"\"\"\n  _name: str = attr.ib(\n      init=True, validator=attr.validators.instance_of(str), kw_only=True)\n  _type: ParameterType = attr.ib(\n      init=True,\n      validator=attr.validators.instance_of(ParameterType),\n      repr=lambda v: v.name if v is not None else 'None',\n      kw_only=True)\n  # Only one of _feasible_values, _bounds will be set at any given time.\n  _bounds: Optional[Union[Tuple[int, int], Tuple[float, float]]] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float)),\n              iterable_validator=attr.validators.instance_of(tuple))),\n      kw_only=True)\n  _feasible_values: Optional[MonotypeParameterList] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float, str)),\n              iterable_validator=attr.validators.instance_of((list, tuple)))),", "completion": "@attr.s(auto_attribs=True, frozen=False, init=True, slots=True, eq=True)\nclass ParameterConfig:\n  \"\"\"A Vizier ParameterConfig.\n\n  Use ParameterConfig.factory to create a valid instance.\n  \"\"\"\n  _name: str = attr.ib(\n      init=True, validator=attr.validators.instance_of(str), kw_only=True)\n  _type: ParameterType = attr.ib(\n      init=True,\n      validator=attr.validators.instance_of(ParameterType),\n      repr=lambda v: v.name if v is not None else 'None',\n      kw_only=True)\n  # Only one of _feasible_values, _bounds will be set at any given time.\n  _bounds: Optional[Union[Tuple[int, int], Tuple[float, float]]] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float)),\n              iterable_validator=attr.validators.instance_of(tuple))),\n      kw_only=True)\n  _feasible_values: Optional[MonotypeParameterList] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int", "metadata": {"task_id": "google_vizier/111", "ground_truth": "      kw_only=True)", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "context_start_lineno": 0, "line_no": 180, "query_window": {"context": "      init=True, validator=attr.validators.instance_of(str), kw_only=True)\n  _type: ParameterType = attr.ib(\n      init=True,\n      validator=attr.validators.instance_of(ParameterType),\n      repr=lambda v: v.name if v is not None else 'None',\n      kw_only=True)\n  # Only one of _feasible_values, _bounds will be set at any given time.\n  _bounds: Optional[Union[Tuple[int, int], Tuple[float, float]]] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float)),\n              iterable_validator=attr.validators.instance_of(tuple))),\n      kw_only=True)\n  _feasible_values: Optional[MonotypeParameterList] = attr.ib(\n      init=True,\n      validator=attr.validators.optional(\n          attr.validators.deep_iterable(\n              member_validator=attr.validators.instance_of((int, float, str)),\n              iterable_validator=attr.validators.instance_of((list, tuple)))),", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 180, "task_id": "google_vizier/111", "start_line_no": 160, "end_line_no": 180, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "      factory=list,\n      validator=attr.validators.deep_iterable(\n          member_validator=attr.validators.instance_of(Measurement),\n          iterable_validator=attr.validators.instance_of(list)),\n  )\n\n  creation_time: Optional[datetime.datetime] = attr.ib(\n      init=True,\n      default=datetime.datetime.now(),\n      converter=_to_local_time,\n      kw_only=True,\n      repr=lambda v: v.strftime('%x %X') if v is not None else 'None',\n      validator=attr.validators.optional(\n          attr.validators.instance_of(datetime.datetime)),\n  )\n\n  completion_time: Optional[datetime.datetime] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 480, "start_line_no": 470, "end_line_no": 490, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.423728813559322}, {"context": "      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(\n          attr.validators.instance_of(Measurement)),\n  )\n\n  measurements: List[Measurement] = attr.ib(\n      init=True,\n      kw_only=True,\n      factory=list,\n      validator=attr.validators.deep_iterable(\n          member_validator=attr.validators.instance_of(Measurement),\n          iterable_validator=attr.validators.instance_of(list)),\n  )\n\n  creation_time: Optional[datetime.datetime] = attr.ib(\n      init=True,\n      default=datetime.datetime.now(),\n      converter=_to_local_time,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3482142857142857}, {"context": "      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  _infeasibility_reason: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  description: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  related_links: Dict[str, str] = attr.ib(", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.33962264150943394}, {"context": "          attr.validators.optional(attr.validators.instance_of(float)),\n          attr.validators.optional(attr.validators.le(1.0)),\n          attr.validators.optional(attr.validators.ge(0.0))\n      ],\n      kw_only=True)\n\n  # Minimum value of this metric can be optionally specified.\n  min_value: float = attr.field(\n      init=True,\n      default=None,\n      # FYI: Converter is applied before validator.\n      converter=lambda x: float(x) if x is not None else -np.inf,\n      validator=[attr.validators.instance_of(float), _min_leq_max],\n      kw_only=True)\n\n  # Maximum value of this metric can be optionally specified.\n  max_value: float = attr.field(\n      init=True,\n      default=None,\n      # FYI: Converter is applied before validator.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "base_study_config.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3384615384615385}, {"context": "\n  assigned_worker: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  stopping_reason: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  _infeasibility_reason: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.33653846153846156}, {"context": "  description: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n      on_setattr=attr.setters.validate)\n\n  parameters: Dict[str, ParameterValue] = attr.ib(\n      init=True,\n      kw_only=True,\n      factory=dict,\n      validator=attr.validators.deep_mapping(\n          key_validator=attr.validators.instance_of(str),\n          value_validator=attr.validators.instance_of(ParameterValue),\n          mapping_validator=attr.validators.instance_of(dict)),\n      on_setattr=attr.setters.validate)  # pytype: disable=wrong-arg-types\n\n  metadata: Metadata = attr.ib(\n      init=True,\n      kw_only=True,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "context.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3360655737704918}, {"context": "      kw_only=True,\n      default=0,\n      validator=attr.validators.instance_of(int),\n  )\n\n  is_requested: bool = attr.ib(\n      init=True,\n      kw_only=True,\n      default=False,\n      validator=attr.validators.instance_of(bool))\n\n  assigned_worker: Optional[str] = attr.ib(\n      init=True,\n      kw_only=True,\n      default=None,\n      validator=attr.validators.optional(attr.validators.instance_of(str)),\n  )\n\n  stopping_reason: Optional[str] = attr.ib(\n      init=True,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "trial.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.3333333333333333}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_speed_distributed.py\n# --------------------------------------------------\n#     if rank == 0:\n#         rpc.init_rpc(\n#             AGENT_NAME,\n#             rank=rank,\n#             world_size=world_size,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n#         )\n#         # create tensor\n#         tensor = torch.zeros(10000, 10000)\n#         if tensortype == \"memmap\":\n#             tensor = MemmapTensor(tensor)\n#         elif tensortype == \"tensor\":\n#             pass\n#         else:\n#             raise NotImplementedError\n# \n#         # \u00a0send tensor\n#         w = 1\n#         fut0 = rpc.remote(f\"worker{w}\", send_tensor, args=(tensor,))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb_distributed.py\n# --------------------------------------------------\n#         pool.apply_async(shutdown)\n# \n# \n# def init_rpc(rank, name, world_size):\n#     os.environ[\"MASTER_ADDR\"] = \"localhost\"\n#     os.environ[\"MASTER_PORT\"] = \"29500\"\n#     str_init_method = \"tcp://localhost:10030\"\n#     options = rpc.TensorPipeRpcBackendOptions(\n#         num_worker_threads=16, init_method=str_init_method\n#     )\n#     rpc.init_rpc(\n#         name,\n#         rank=rank,\n#         backend=rpc.BackendType.TENSORPIPE,\n#         rpc_backend_options=options,\n#         world_size=world_size,\n#     )\n# \n# \n# def shutdown():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_td_distributed.py\n# --------------------------------------------------\n#             AGENT_NAME,\n#             rank=rank,\n#             world_size=world_size,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n#         )\n# \n#         if args.task == 0:\n#             time.sleep(1)\n#             t0 = time.time()\n#             for w in range(1, args.world_size):\n#                 fut0 = rpc.rpc_async(f\"worker{w}\", get_tensordict, args=())\n#                 fut0.wait()\n#                 fut1 = rpc.rpc_async(f\"worker{w}\", tensordict_add, args=())\n#                 tensordict2 = fut1.wait()\n#                 tensordict2.clone()\n#             print(\"time: \", time.time() - t0)\n#         elif args.task == 1:\n#             time.sleep(1)\n#             t0 = time.time()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_rb_distributed.py\n# --------------------------------------------------\n#     rpc.init_rpc(\n#         name,\n#         rank=rank,\n#         backend=rpc.BackendType.TENSORPIPE,\n#         rpc_backend_options=options,\n#         world_size=world_size,\n#     )\n# \n# \n# def shutdown():\n#     rpc.shutdown()\n# \n# \n# def _construct_buffer(target):\n#     for _ in range(RETRY_COUNT):\n#         try:\n#             buffer_rref = rpc.remote(target, ReplayBufferNode, args=(1000,))\n#             return buffer_rref\n#         except Exception as e:\n#             print(f\"Failed to connect: {e}\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmarks/storage/benchmark_sample_latency_over_rpc.py\n# --------------------------------------------------\n# if __name__ == \"__main__\":\n#     args = parser.parse_args()\n#     rank = args.rank\n#     storage_type = args.storage\n# \n#     print(f\"Rank: {rank}; Storage: {storage_type}\")\n# \n#     os.environ[\"MASTER_ADDR\"] = \"localhost\"\n#     os.environ[\"MASTER_PORT\"] = \"29500\"\n#     os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n#     options = rpc.TensorPipeRpcBackendOptions(\n#         num_worker_threads=16, init_method=\"tcp://localhost:10002\", rpc_timeout=120\n#     )\n#     if rank == 0:\n#         # rank 0 is the trainer\n#         rpc.init_rpc(\n#             TRAINER_NODE,\n#             rank=rank,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/torchrl_features/memmap_td_distributed.py\n# --------------------------------------------------\n#     os.environ[\"MASTER_PORT\"] = \"29500\"\n# \n#     str_init_method = \"tcp://localhost:10000\"\n#     options = rpc.TensorPipeRpcBackendOptions(\n#         _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n#     )\n# \n#     if rank == 0:\n#         # rank0 is the trainer\n#         rpc.init_rpc(\n#             AGENT_NAME,\n#             rank=rank,\n#             world_size=world_size,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n#         )\n# \n#         if args.task == 0:\n#             time.sleep(1)\n#             t0 = time.time()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# benchmarks/storage/benchmark_sample_latency_over_rpc.py\n# --------------------------------------------------\n#     options = rpc.TensorPipeRpcBackendOptions(\n#         num_worker_threads=16, init_method=\"tcp://localhost:10002\", rpc_timeout=120\n#     )\n#     if rank == 0:\n#         # rank 0 is the trainer\n#         rpc.init_rpc(\n#             TRAINER_NODE,\n#             rank=rank,\n#             backend=rpc.BackendType.TENSORPIPE,\n#             rpc_backend_options=options,\n#         )\n#         trainer = DummyTrainerNode()\n#         results = []\n#         for i in range(REPEATS):\n#             result = trainer.train(batch_size=BATCH_SIZE)\n#             if i == 0:\n#                 continue\n#             results.append(result)\n#             print(i, results[-1])\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\"\"\"\nExample use of a distributed replay buffer\n===========================\n\nThis example illustrates how a skeleton reinforcement learning algorithm can be implemented in a distributed fashion with communication between nodes/workers handled using `torch.rpc`.\nIt focusses on how to set up a replay buffer worker that accepts remote operation requests efficiently, and so omits any learning component such as parameter updates that may be required for a complete distributed reinforcement learning algorithm implementation.\nIn this model, >= 1 data collectors workers are responsible for collecting experiences in an environment, the replay buffer worker receives all of these experiences and exposes them to a trainer that is responsible for making parameter updates to any required models.\n\"\"\"\n\nimport argparse\nimport os\nimport random\nimport sys\nimport time\n\nimport torch\nimport torch.distributed.rpc as rpc\nfrom tensordict import TensorDict\nfrom torchrl.data.replay_buffers import RemoteTensorDictReplayBuffer\nfrom torchrl.data.replay_buffers.samplers import RandomSampler\nfrom torchrl.data.replay_buffers.storages import LazyMemmapStorage\nfrom torchrl.data.replay_buffers.utils import accept_remote_rref_invocation\nfrom torchrl.data.replay_buffers.writers import RoundRobinWriter\n\nRETRY_LIMIT = 2\nRETRY_DELAY_SECS = 3\nREPLAY_BUFFER_NODE = \"ReplayBuffer\"\nTRAINER_NODE = \"Trainer\"\n\nparser = argparse.ArgumentParser(\n    description=\"RPC Replay Buffer Example\",\n    formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n)\n\nparser.add_argument(\n    \"--rank\",\n    type=int,\n    default=-1,\n    help=\"Node Rank [0 = Replay Buffer, 1 = Dummy Trainer, 2+ = Dummy Data Collector]\",\n)\n\n\nclass DummyDataCollectorNode:\n    \"\"\"Data collector node responsible for collecting experiences used for learning.\n\n    Args:\n        replay_buffer (rpc.RRef): the RRef associated with the construction of the replay buffer\n    \"\"\"\n\n    def __init__(self, replay_buffer: rpc.RRef) -> None:\n        self.id = rpc.get_worker_info().id\n        self.replay_buffer = replay_buffer\n        print(\"Data Collector Node constructed\")\n\n    def _submit_random_item_async(self) -> rpc.RRef:\n        td = TensorDict({\"a\": torch.randint(100, (1,))}, [])\n        return rpc.remote(\n            self.replay_buffer.owner(),\n            ReplayBufferNode.add,\n            args=(\n                self.replay_buffer,\n                td,\n            ),\n        )\n\n    @accept_remote_rref_invocation\n    def collect(self):\n        \"\"\"Method that begins experience collection (we just generate random TensorDicts in this example). `accept_remote_rref_invocation` enables this method to be invoked remotely provided the class instantiation `rpc.RRef` is provided in place of the object reference.\"\"\"\n        for elem in range(50):\n            time.sleep(random.randint(1, 4))\n            print(\n                f\"Collector [{self.id}] submission {elem}: {self._submit_random_item_async().to_here()}\"\n            )\n\n\nclass DummyTrainerNode:\n    \"\"\"Trainer node responsible for learning from experiences sampled from an experience replay buffer.\"\"\"\n\n    def __init__(self) -> None:\n        print(\"DummyTrainerNode\")\n        self.id = rpc.get_worker_info().id\n        self.replay_buffer = self._create_replay_buffer()\n        self._create_and_launch_data_collectors()\n\n    def train(self, iterations: int) -> None:\n        for iteration in range(iterations):\n            print(f\"[{self.id}] Training Iteration: {iteration}\")\n            time.sleep(3)\n            batch = rpc.rpc_sync(\n                self.replay_buffer.owner(),\n                ReplayBufferNode.sample,\n                args=(self.replay_buffer, 16),\n            )\n            print(f\"[{self.id}] Sample Obtained Iteration: {iteration}\")\n            print(f\"{batch}\")\n\n    def _create_replay_buffer(self) -> rpc.RRef:\n        while True:\n            try:\n                replay_buffer_info = rpc.get_worker_info(REPLAY_BUFFER_NODE)\n                buffer_rref = rpc.remote(\n                    replay_buffer_info, ReplayBufferNode, args=(10000,)\n                )\n                print(f\"Connected to replay buffer {replay_buffer_info}\")\n                return buffer_rref\n            except Exception as e:\n                print(f\"Failed to connect to replay buffer: {e}\")\n                time.sleep(RETRY_DELAY_SECS)\n\n    def _create_and_launch_data_collectors(self) -> None:\n        data_collector_number = 2\n        retries = 0\n        data_collectors = []\n        data_collector_infos = []\n        # discover launched data collector nodes (with retry to allow collectors to dynamically join)\n        while True:\n            try:\n                data_collector_info = rpc.get_worker_info(\n                    f\"DataCollector{data_collector_number}\"\n                )\n                print(f\"Data collector info: {data_collector_info}\")\n                dc_ref = rpc.remote(\n                    data_collector_info,\n                    DummyDataCollectorNode,\n                    args=(self.replay_buffer,),\n                )\n                data_collectors.append(dc_ref)\n                data_collector_infos.append(data_collector_info)\n                data_collector_number += 1\n                retries = 0\n            except Exception:\n                retries += 1\n                print(\n                    f\"Failed to connect to DataCollector{data_collector_number} with {retries} retries\"\n                )\n                if retries >= RETRY_LIMIT:\n                    print(f\"{len(data_collectors)} data collectors\")\n                    for data_collector_info, data_collector in zip(\n                        data_collector_infos, data_collectors\n                    ):\n                        rpc.remote(\n                            data_collector_info,\n                            DummyDataCollectorNode.collect,\n                            args=(data_collector,),\n                        )\n                    break\n                else:\n                    time.sleep(RETRY_DELAY_SECS)\n\n\nclass ReplayBufferNode(RemoteTensorDictReplayBuffer):\n    \"\"\"Experience replay buffer node that is capable of accepting remote connections. Being a `RemoteTensorDictReplayBuffer` means all of it's public methods are remotely invokable using `torch.rpc`.\n    Using a LazyMemmapStorage is highly advised in distributed settings with shared storage due to the lower serialisation cost of MemmapTensors as well as the ability to specify file storage locations which can improve ability to recover from node failures.\n\n    Args:\n        capacity (int): the maximum number of elements that can be stored in the replay buffer.\n    \"\"\"\n\n    def __init__(self, capacity: int):\n        super().__init__(\n            storage=LazyMemmapStorage(\n                max_size=capacity, scratch_dir=\"/tmp/\", device=torch.device(\"cpu\")\n            ),\n            sampler=RandomSampler(),\n            writer=RoundRobinWriter(),\n            collate_fn=lambda x: x,\n        )\n\n\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    print(f\"Rank: {rank}\")\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n    str_init_method = \"tcp://localhost:10000\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=str_init_method\n    )", "completion": "if rank == 0:\n        # rank 0 is the replay buffer\n        rpc.init_rpc(\n            REPLAY_BUFFER_NODE,\n            rank=rank,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,\n        )\n        replay_buffer = ReplayBufferNode(10000)\n        rpc.shutdown()\n    elif rank == 1:\n        # rank 1 is the trainer\n        rpc.init_rpc(\n            TRAINER_NODE,\n            rank=rank,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,\n        )\n        trainer = DummyTrainerNode()\n        trainer.train(10)\n        rpc.shutdown()\n    else:\n        # ranks 2+ are the data collectors\n        rpc.init_rpc(\n            f\"DataCollector{rank}\",\n            rank=rank,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,\n        )\n        rpc.shutdown()", "metadata": {"task_id": "pytorch_rl/112", "ground_truth": "    if rank == 0:", "fpath_tuple": ["pytorch_rl", "examples", "distributed", "distributed_replay_buffer.py"], "context_start_lineno": 0, "line_no": 181, "query_window": {"context": "                max_size=capacity, scratch_dir=\"/tmp/\", device=torch.device(\"cpu\")\n            ),\n            sampler=RandomSampler(),\n            writer=RoundRobinWriter(),\n            collate_fn=lambda x: x,\n        )\n\n\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    print(f\"Rank: {rank}\")\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n    str_init_method = \"tcp://localhost:10000\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=str_init_method\n    )", "metadata": {"fpath_tuple": ["pytorch_rl", "examples", "distributed", "distributed_replay_buffer.py"], "line_no": 181, "task_id": "pytorch_rl/112", "start_line_no": 161, "end_line_no": 181, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "if __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    storage_type = args.storage\n\n    print(f\"Rank: {rank}; Storage: {storage_type}\")\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=\"tcp://localhost:10002\", rpc_timeout=120\n    )\n    if rank == 0:\n        # rank 0 is the trainer\n        rpc.init_rpc(\n            TRAINER_NODE,\n            rank=rank,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,", "metadata": [{"fpath_tuple": ["pytorch_rl", "benchmarks", "storage", "benchmark_sample_latency_over_rpc.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5655172413793104}, {"context": "\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    if rank < 0:\n        rank = int(os.environ[args.rank_var])\n    print(\"rank: \", rank)\n    world_size = args.world_size\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n\n    str_init_method = \"tcp://localhost:10000\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n    )\n\n    if rank == 0:\n        # rank0 is the trainer\n        rpc.init_rpc(", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_td_distributed.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5}, {"context": "                \"next_observation\": torch.randn(\n                    BUFFER_SIZE,\n                    TENSOR_SIZE,\n                ),\n            },\n            batch_size=[BUFFER_SIZE],\n        )\n        self.extend(tds)\n\n\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    storage_type = args.storage\n\n    print(f\"Rank: {rank}; Storage: {storage_type}\")\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "benchmarks", "storage", "benchmark_sample_latency_over_rpc.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4405594405594406}, {"context": "        pool.apply_async(shutdown)\n\n\ndef init_rpc(rank, name, world_size):\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    str_init_method = \"tcp://localhost:10030\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=str_init_method\n    )\n    rpc.init_rpc(\n        name,\n        rank=rank,\n        backend=rpc.BackendType.TENSORPIPE,\n        rpc_backend_options=options,\n        world_size=world_size,\n    )\n\n\ndef shutdown():", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb_distributed.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38571428571428573}, {"context": "    os.environ[\"MASTER_PORT\"] = \"29500\"\n\n    str_init_method = \"tcp://localhost:10000\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        _transports=[\"uv\"], num_worker_threads=16, init_method=str_init_method\n    )\n\n    if rank == 0:\n        # rank0 is the trainer\n        rpc.init_rpc(\n            AGENT_NAME,\n            rank=rank,\n            world_size=world_size,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,\n        )\n\n        if args.task == 0:\n            time.sleep(1)\n            t0 = time.time()", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_td_distributed.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.38513513513513514}, {"context": ")\ndef test_funcs(names, func):\n    world_size = len(names)\n    with mp.Pool(world_size) as pool:\n        pool.starmap(\n            init_rpc, ((rank, name, world_size) for rank, name in enumerate(names))\n        )\n        pool.starmap(\n            func, ((rank, name, world_size) for rank, name in enumerate(names))\n        )\n        pool.apply_async(shutdown)\n\n\ndef init_rpc(rank, name, world_size):\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n    str_init_method = \"tcp://localhost:10030\"\n    options = rpc.TensorPipeRpcBackendOptions(\n        num_worker_threads=16, init_method=str_init_method\n    )", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_rb_distributed.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3783783783783784}, {"context": "\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    rank = args.rank\n    world_size = args.world_size\n    tensortype = args.tensortype\n\n    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n    os.environ[\"MASTER_PORT\"] = \"29500\"\n\n    if rank == 0:\n        rpc.init_rpc(\n            AGENT_NAME,\n            rank=rank,\n            world_size=world_size,\n            backend=rpc.BackendType.TENSORPIPE,\n            rpc_backend_options=options,\n        )\n        # create tensor\n        tensor = torch.zeros(10000, 10000)", "metadata": [{"fpath_tuple": ["pytorch_rl", "examples", "torchrl_features", "memmap_speed_distributed.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.36363636363636365}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/coding_ddpg.py\n# --------------------------------------------------\n# \n#     # init: since we have lazy layers, we should run the network\n#     # once to initialize them\n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.rollout(max_steps=4)\n#         td = td.to(device)\n#         actor(td)\n#         qnet(td)\n# \n#     return actor, qnet\n# \n# \n# ###############################################################################\n# # Evaluator: building your recorder object\n# # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n# # As the training data is obtained using some exploration strategy, the true\n# # performance of our algorithm needs to be assessed in deterministic mode. We\n# # do this using a dedicated class, ``Recorder``, which executes the policy in\n# # the environment at a given frequency and returns some statistics obtained\n# # from these simulations. The following helper function builds this object:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#         )\n#         actor_value = ActorCriticWrapper(policy_po, value_po).to(device)\n# \n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.rollout(max_steps=1000)\n#         td_device = td.to(device)\n#         td_device = actor_value(td_device)  # for init\n#     return actor_value\n# \n# \n# def make_ppo_model(\n#     proof_environment: EnvBase,\n#     cfg: \"DictConfig\",  # noqa: F821\n#     device: DEVICE_TYPING,\n#     in_keys_actor: Optional[Sequence[str]] = None,\n#     observation_key=None,\n#     **kwargs,\n# ) -> ActorValueOperator:\n#     \"\"\"Actor-value model constructor helper function.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n# \n# \n# def make_dreamer(\n#     cfg: \"DictConfig\",  # noqa: F821\n#     proof_environment: EnvBase = None,\n#     device: DEVICE_TYPING = \"cpu\",\n#     action_key: str = \"action\",\n#     value_key: str = \"state_value\",\n#     use_decoder_in_env: bool = False,\n#     obs_norm_state_dict=None,\n# ) -> nn.ModuleList:\n#     \"\"\"Create Dreamer components.\n# \n#     Args:\n#         cfg (DictConfig): Config object.\n#         proof_environment (EnvBase): Environment to initialize the model.\n#         device (DEVICE_TYPING, optional): Device to use.\n#             Defaults to \"cpu\".\n#         action_key (str, optional): Key to use for the action.\n#             Defaults to \"action\".\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#         module=q_net,\n#     )\n# \n#     module = torch.nn.ModuleList([actor, value]).to(device)\n# \n#     # init\n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.rollout(max_steps=1000)\n#         td = td.to(device)\n#         module[0](td)\n#         module[1](td)\n# \n#     return module\n# \n# \n# def make_a2c_model(\n#     proof_environment: EnvBase,\n#     cfg: \"DictConfig\",  # noqa: F821\n#     device: DEVICE_TYPING,\n#     in_keys_actor: Optional[Sequence[str]] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#     del td\n# \n#     return model\n# \n# \n# def make_redq_model(\n#     proof_environment: EnvBase,\n#     cfg: \"DictConfig\",  # noqa: F821\n#     device: DEVICE_TYPING = \"cpu\",\n#     in_keys: Optional[Sequence[str]] = None,\n#     actor_net_kwargs=None,\n#     qvalue_net_kwargs=None,\n#     observation_key=None,\n#     **kwargs,\n# ) -> nn.ModuleList:\n#     \"\"\"Actor and Q-value model constructor helper function for REDQ.\n# \n#     Follows default parameters proposed in REDQ original paper: https://openreview.net/pdf?id=AY8zfZm0tDd.\n#     Other configurations can easily be implemented by modifying this function at will.\n#     A single instance of the Q-value model is returned. It will be multiplicated by the loss function.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#     model = nn.ModuleList([actor, qvalue]).to(device)\n# \n#     # init nets\n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.rollout(1000)\n#         td = td.to(device)\n#         for net in model:\n#             net(td)\n#     del td\n#     return model\n# \n# \n# def make_dreamer(\n#     cfg: \"DictConfig\",  # noqa: F821\n#     proof_environment: EnvBase = None,\n#     device: DEVICE_TYPING = \"cpu\",\n#     action_key: str = \"action\",\n#     value_key: str = \"state_value\",\n#     use_decoder_in_env: bool = False,\n#     obs_norm_state_dict=None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/trainers/helpers/models.py\n# --------------------------------------------------\n#         module=value_net,\n#     )\n#     model = nn.ModuleList([actor, qvalue, value]).to(device)\n# \n#     # init nets\n#     with torch.no_grad(), set_exploration_mode(\"random\"):\n#         td = proof_environment.reset()\n#         td = td.to(device)\n#         for net in model:\n#             net(td)\n#     del td\n# \n#     return model\n# \n# \n# def make_redq_model(\n#     proof_environment: EnvBase,\n#     cfg: \"DictConfig\",  # noqa: F821\n#     device: DEVICE_TYPING = \"cpu\",\n#     in_keys: Optional[Sequence[str]] = None,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\nimport hydra\n\nimport numpy as np\nimport torch\nimport torch.cuda\nimport tqdm\n\nfrom torch import nn, optim\nfrom torchrl.collectors import MultiSyncDataCollector\nfrom torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer\n\nfrom torchrl.data.replay_buffers.storages import LazyMemmapStorage\nfrom torchrl.envs import (\n    Compose,\n    DoubleToFloat,\n    EnvCreator,\n    ObservationNorm,\n    ParallelEnv,\n    TransformedEnv,\n)\nfrom torchrl.envs.libs.gym import GymEnv\nfrom torchrl.envs.transforms import RewardScaling\nfrom torchrl.envs.utils import set_exploration_mode\nfrom torchrl.modules import (\n    AdditiveGaussianWrapper,\n    MLP,\n    ProbabilisticActor,\n    SafeModule,\n    ValueOperator,\n)\nfrom torchrl.modules.distributions import TanhDelta\n\nfrom torchrl.objectives import SoftUpdate\nfrom torchrl.objectives.td3 import TD3Loss\nfrom torchrl.record.loggers import generate_exp_name, get_logger\n\n\ndef env_maker(task, frame_skip=1, device=\"cpu\", from_pixels=False):\n    return GymEnv(\n        task, \"run\", device=device, frame_skip=frame_skip, from_pixels=from_pixels\n    )\n\n\ndef apply_env_transforms(env, reward_scaling=1.0):\n    transformed_env = TransformedEnv(\n        env,\n        Compose(\n            RewardScaling(loc=0.0, scale=reward_scaling),\n            ObservationNorm(in_keys=[\"observation\"]),\n            DoubleToFloat(in_keys=[\"observation\"], in_keys_inv=[]),\n        ),\n    )\n    return transformed_env\n\n\ndef make_replay_buffer(\n    prb=False,\n    buffer_size=1000000,\n    buffer_scratch_dir=\"/tmp/\",\n    device=\"cpu\",\n    make_replay_buffer=3,\n):\n    if prb:\n        replay_buffer = TensorDictPrioritizedReplayBuffer(\n            buffer_size,\n            alpha=0.7,\n            beta=0.5,\n            pin_memory=False,\n            prefetch=make_replay_buffer,\n            storage=LazyMemmapStorage(\n                buffer_size,\n                scratch_dir=buffer_scratch_dir,\n                device=device,\n            ),\n        )\n    else:\n        replay_buffer = TensorDictReplayBuffer(\n            buffer_size,\n            pin_memory=False,\n            prefetch=make_replay_buffer,\n            storage=LazyMemmapStorage(\n                buffer_size,\n                scratch_dir=buffer_scratch_dir,\n                device=device,\n            ),\n        )\n    return replay_buffer\n\n\n@hydra.main(version_base=None, config_path=\".\", config_name=\"config\")\ndef main(cfg: \"DictConfig\"):  # noqa: F821\n\n    device = (\n        torch.device(\"cuda:0\")\n        if torch.cuda.is_available()\n        and torch.cuda.device_count() > 0\n        and cfg.device == \"cuda:0\"\n        else torch.device(\"cpu\")\n    )\n\n    exp_name = generate_exp_name(\"TD3\", cfg.exp_name)\n    logger = get_logger(\n        logger_type=cfg.logger, logger_name=\"td3_logging\", experiment_name=exp_name\n    )\n\n    torch.manual_seed(cfg.seed)\n    np.random.seed(cfg.seed)\n\n    parallel_env = ParallelEnv(\n        cfg.env_per_collector, EnvCreator(lambda: env_maker(task=cfg.env_name))\n    )\n    parallel_env.set_seed(cfg.seed)\n\n    train_env = apply_env_transforms(parallel_env)\n\n    train_env.transform[1].init_stats(\n        num_iter=cfg.init_env_steps, reduce_dim=(0, 1), cat_dim=0\n    )\n    # check the shape of our summary stats\n    print(\"normalization constant shape:\", train_env.transform[1].loc.shape)\n\n    eval_env = TransformedEnv(\n        ParallelEnv(\n            cfg.env_per_collector, EnvCreator(lambda: env_maker(task=cfg.env_name))\n        ),\n        train_env.transform.clone(),\n    )\n    assert (eval_env.transform[1].loc == train_env.transform[1].loc).all()\n\n    # Create Agent\n\n    # Define Actor Network\n    in_keys = [\"observation\"]\n    action_spec = train_env.action_spec\n    actor_net_kwargs = {\n        \"num_cells\": [256, 256],\n        \"out_features\": action_spec.shape[-1],\n        \"activation_class\": nn.ReLU,\n    }\n\n    actor_net = MLP(**actor_net_kwargs)\n\n    dist_class = TanhDelta\n    dist_kwargs = {\n        \"min\": action_spec.space.minimum,\n        \"max\": action_spec.space.maximum,\n        \"tanh_loc\": False,\n    }\n\n    in_keys_actor = in_keys\n    actor_module = SafeModule(\n        actor_net,\n        in_keys=in_keys_actor,\n        out_keys=[\n            \"param\",\n        ],\n    )\n    actor = ProbabilisticActor(\n        spec=action_spec,\n        in_keys=[\"param\"],\n        module=actor_module,\n        distribution_class=dist_class,\n        distribution_kwargs=dist_kwargs,\n        default_interaction_mode=\"random\",\n        return_log_prob=False,\n    )\n\n    # Define Critic Network\n    qvalue_net_kwargs = {\n        \"num_cells\": [256, 256],\n        \"out_features\": 1,\n        \"activation_class\": nn.ReLU,\n    }\n\n    qvalue_net = MLP(\n        **qvalue_net_kwargs,\n    )\n\n    qvalue = ValueOperator(\n        in_keys=[\"action\"] + in_keys,\n        module=qvalue_net,\n    )\n\n    model = nn.ModuleList([actor, qvalue]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = eval_env.reset()\n        td = td.to(device)\n        for net in model:\n            net(td)", "completion": "The given code is an implementation of the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. \n\nThe code initializes the environment, creates an actor network and a critic network, and then initializes the networks with random exploration. The actor network is responsible for selecting actions based on the current state, while the critic network evaluates the quality of the selected actions. The TD3 algorithm uses two critic networks to reduce overestimation bias.\n\nThe code also sets up a replay buffer to store and sample experiences for training the networks. The replay buffer can be either a prioritized replay buffer or a regular replay buffer, depending on the configuration.\n\nThe main function of the code runs the TD3 algorithm, including the training loop and evaluation of the agent's performance. The agent interacts with the environment, collects experiences, and updates the networks using the TD3 loss function. The SoftUpdate class is used to update the target networks with a fraction of the main networks' parameters.\n\nThe code uses the Hydra library for configuration management and logging. The configuration file specifies the hyperparameters and settings for the TD3 algorithm.\n\nOverall, the code provides a complete implementation of the TD3 algorithm for training an agent to solve continuous control tasks.", "metadata": {"task_id": "pytorch_rl/108", "ground_truth": "    del td", "fpath_tuple": ["pytorch_rl", "examples", "td3", "td3.py"], "context_start_lineno": 0, "line_no": 197, "query_window": {"context": "        \"activation_class\": nn.ReLU,\n    }\n\n    qvalue_net = MLP(\n        **qvalue_net_kwargs,\n    )\n\n    qvalue = ValueOperator(\n        in_keys=[\"action\"] + in_keys,\n        module=qvalue_net,\n    )\n\n    model = nn.ModuleList([actor, qvalue]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = eval_env.reset()\n        td = td.to(device)\n        for net in model:\n            net(td)", "metadata": {"fpath_tuple": ["pytorch_rl", "examples", "td3", "td3.py"], "line_no": 197, "task_id": "pytorch_rl/108", "start_line_no": 177, "end_line_no": 197, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        default_interaction_mode=\"random\",\n        return_log_prob=False,\n    )\n\n    qvalue = ValueOperator(\n        in_keys=[\"action\"] + in_keys,\n        module=qvalue_net,\n    )\n    value = ValueOperator(\n        in_keys=in_keys,\n        module=value_net,\n    )\n    model = nn.ModuleList([actor, qvalue, value]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.reset()\n        td = td.to(device)\n        for net in model:\n            net(td)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1210, "start_line_no": 1200, "end_line_no": 1220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6896551724137931}, {"context": "        module=actor_module,\n        distribution_class=dist_class,\n        distribution_kwargs=dist_kwargs,\n        default_interaction_mode=\"random\",\n        return_log_prob=True,\n    )\n    qvalue = ValueOperator(\n        in_keys=in_keys_qvalue,\n        module=qvalue_net,\n    )\n    model = nn.ModuleList([actor, qvalue]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(1000)\n        td = td.to(device)\n        for net in model:\n            net(td)\n    del td\n    return model", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1450, "start_line_no": 1440, "end_line_no": 1460, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.6236559139784946}, {"context": "        module=value_net,\n    )\n    model = nn.ModuleList([actor, qvalue, value]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.reset()\n        td = td.to(device)\n        for net in model:\n            net(td)\n    del td\n\n    return model\n\n\ndef make_redq_model(\n    proof_environment: EnvBase,\n    cfg: \"DictConfig\",  # noqa: F821\n    device: DEVICE_TYPING = \"cpu\",\n    in_keys: Optional[Sequence[str]] = None,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1220, "start_line_no": 1210, "end_line_no": 1230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4954954954954955}, {"context": "        in_keys = [\"observation_vector\", \"action\"]\n        out_keys = [\"state_action_value\"]\n        q_net = DdpgMlpQNet(\n            mlp_net_kwargs_net1=value_net_default_kwargs1,\n            mlp_net_kwargs_net2=value_net_default_kwargs2,\n        )\n\n    value = state_class(\n        in_keys=in_keys,\n        out_keys=out_keys,\n        module=q_net,\n    )\n\n    module = torch.nn.ModuleList([actor, value]).to(device)\n\n    # init\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(max_steps=1000)\n        td = td.to(device)\n        module[0](td)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.46296296296296297}, {"context": "    model = nn.ModuleList([actor, qvalue]).to(device)\n\n    # init nets\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(1000)\n        td = td.to(device)\n        for net in model:\n            net(td)\n    del td\n    return model\n\n\ndef make_dreamer(\n    cfg: \"DictConfig\",  # noqa: F821\n    proof_environment: EnvBase = None,\n    device: DEVICE_TYPING = \"cpu\",\n    action_key: str = \"action\",\n    value_key: str = \"state_value\",\n    use_decoder_in_env: bool = False,\n    obs_norm_state_dict=None,", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 1460, "start_line_no": 1450, "end_line_no": 1470, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4098360655737705}, {"context": "            default_interaction_mode=\"random\",\n        )\n\n        value_net = MLP(\n            num_cells=[64, 64],\n            out_features=1,\n        )\n        value_po = ValueOperator(\n            value_net,\n            in_keys=in_keys_critic,\n        )\n        actor_value = ActorCriticWrapper(policy_po, value_po).to(device)\n\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(max_steps=1000)\n        td_device = td.to(device)\n        td_device = actor_value(td_device)  # for init\n    return actor_value\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "helpers", "models.py"], "line_no": 700, "start_line_no": 690, "end_line_no": 710, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.39814814814814814}, {"context": "        num_cells=[num_cells] * num_layers,\n        activation_class=nn.Tanh,\n        out_features=1,\n    )\n\n    in_keys = in_keys + [\"action\"]\n    qnet = ValueOperator(\n        in_keys=in_keys,\n        module=q_net,\n    ).to(device)\n\n    # init: since we have lazy layers, we should run the network\n    # once to initialize them\n    with torch.no_grad(), set_exploration_mode(\"random\"):\n        td = proof_environment.rollout(max_steps=4)\n        td = td.to(device)\n        actor(td)\n        qnet(td)\n\n    return actor, qnet", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "coding_ddpg.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.39473684210526316}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_transforms.py\n# --------------------------------------------------\n#         obs = obs.view(-1, obs.shape[-1])\n#         mean = obs.mean(0)\n#         assert (abs(mean) < thr).all()\n#         std = obs.std(0)\n#         assert (abs(std - 1) < thr).all()\n#         if not env_t.is_closed:\n#             env_t.close()\n#         self.SEED = 0\n# \n# \n# def test_added_transforms_are_in_eval_mode_trivial():\n#     base_env = ContinuousActionVecMockEnv()\n#     t = TransformedEnv(base_env)\n#     assert not t.transform.training\n# \n#     t.train()\n#     assert t.transform.training\n# \n# \n# def test_added_transforms_are_in_eval_mode():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#         td_device = env_serial.rollout(max_steps=10)\n#         assert td_device.device == torch.device(device), env_serial\n# \n#         if open_before:\n#             td_cpu = env_parallel.rollout(max_steps=10)\n#             assert td_cpu.device == torch.device(\"cpu\")\n#         env_parallel = env_parallel.to(device)\n#         assert env_parallel.observation_spec.device == torch.device(device)\n#         assert env_parallel.action_spec.device == torch.device(device)\n#         assert env_parallel.reward_spec.device == torch.device(device)\n#         assert env_parallel.device == torch.device(device)\n#         td_device = env_parallel.reset()\n#         assert td_device.device == torch.device(device), env_parallel\n#         td_device = env_parallel.rand_step()\n#         assert td_device.device == torch.device(device), env_parallel\n#         td_device = env_parallel.rollout(max_steps=10)\n#         assert td_device.device == torch.device(device), env_parallel\n# \n#         env_parallel.close()\n#         env_serial.close()\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#             assert td_cpu.device == torch.device(\"cpu\")\n#         env_serial = env_serial.to(device)\n#         assert env_serial.observation_spec.device == torch.device(device)\n#         assert env_serial.action_spec.device == torch.device(device)\n#         assert env_serial.reward_spec.device == torch.device(device)\n#         assert env_serial.device == torch.device(device)\n#         td_device = env_serial.reset()\n#         assert td_device.device == torch.device(device), env_serial\n#         td_device = env_serial.rand_step()\n#         assert td_device.device == torch.device(device), env_serial\n#         td_device = env_serial.rollout(max_steps=10)\n#         assert td_device.device == torch.device(device), env_serial\n# \n#         if open_before:\n#             td_cpu = env_parallel.rollout(max_steps=10)\n#             assert td_cpu.device == torch.device(\"cpu\")\n#         env_parallel = env_parallel.to(device)\n#         assert env_parallel.observation_spec.device == torch.device(device)\n#         assert env_parallel.action_spec.device == torch.device(device)\n#         assert env_parallel.reward_spec.device == torch.device(device)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/objectives/utils.py\n# --------------------------------------------------\n#     if \"steps_to_next_obs\" in tensordict.keys():\n#         steps_to_next_obs = tensordict.get(\"steps_to_next_obs\").squeeze(-1)\n#     else:\n#         steps_to_next_obs = 1\n# \n#     rewards = tensordict.get(\"reward\").squeeze(-1)\n#     done = tensordict.get(\"done\").squeeze(-1)\n# \n#     if pred_next_val is None:\n#         next_td = step_mdp(tensordict)  # next_observation -> observation\n#         next_td = next_td.select(*operator.in_keys)\n#         operator(next_td, **kwargs)\n#         pred_next_val_detach = next_td.get(next_val_key).squeeze(-1)\n#     else:\n#         pred_next_val_detach = pred_next_val.squeeze(-1)\n#     done = done.to(torch.float)\n#     target_value = (1 - done) * pred_next_val_detach\n#     rewards = rewards.to(torch.float)\n#     target_value = rewards + (gamma**steps_to_next_obs) * target_value\n#     return target_value\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_env.py\n# --------------------------------------------------\n#     )\n#     assert (td[\"done\"] == 1).all()\n#     assert (td[\"next\"][\"observation\"] == max_steps + 1).all()\n# \n#     _reset = torch.randint(low=0, high=2, size=env.batch_size, dtype=torch.bool)\n#     td_reset = env.reset(\n#         TensorDict({\"_reset\": _reset}, batch_size=env.batch_size, device=env.device)\n#     )\n# \n#     assert (td_reset[\"done\"][_reset] == 0).all()\n#     assert (td_reset[\"observation\"][_reset] == 0).all()\n#     assert (td_reset[\"done\"][~_reset] == 1).all()\n#     assert (td_reset[\"observation\"][~_reset] == max_steps + 1).all()\n# \n# \n# @pytest.mark.skipif(not _has_gym, reason=\"no gym\")\n# def test_seed():\n#     torch.manual_seed(0)\n#     env1 = GymEnv(PENDULUM_VERSIONED)\n#     env1.set_seed(0)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tutorials/sphinx-tutorials/torchrl_demo.py\n# --------------------------------------------------\n#     if tensordict[\"done\"].any():\n#         break\n#     tensordict = step_mdp(tensordict)  # roughly equivalent to obs = next_obs\n# tensordicts_stack = torch.stack(tensordicts, 0)\n# print(\"total steps:\", i)\n# print(tensordicts_stack)\n# \n# ###############################################################################\n# \n# (tensordicts_stack == tensordicts_prealloc).all()\n# \n# ###############################################################################\n# \n# # helper\n# torch.manual_seed(0)\n# env.set_seed(0)\n# tensordict_rollout = env.rollout(policy=actor, max_steps=max_steps)\n# tensordict_rollout\n# \n# ###############################################################################\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport pkg_resources\nimport torch\nfrom tensordict.nn.probabilistic import (  # noqa\n    interaction_mode as exploration_mode,\n    set_interaction_mode as set_exploration_mode,\n)\nfrom tensordict.tensordict import TensorDictBase\n\nAVAILABLE_LIBRARIES = {pkg.key for pkg in pkg_resources.working_set}\n\n\nclass _classproperty(property):\n    def __get__(self, cls, owner):\n        return classmethod(self.fget).__get__(None, owner)()\n\n\ndef step_mdp(\n    tensordict: TensorDictBase,\n    next_tensordict: TensorDictBase = None,\n    keep_other: bool = True,\n    exclude_reward: bool = True,\n    exclude_done: bool = True,\n    exclude_action: bool = True,\n    _run_check: bool = True,\n) -> TensorDictBase:\n    \"\"\"Creates a new tensordict that reflects a step in time of the input tensordict.\n\n    Given a tensordict retrieved after a step, returns the :obj:`\"next\"` indexed-tensordict.\n\n    Args:\n        tensordict (TensorDictBase): tensordict with keys to be renamed\n        next_tensordict (TensorDictBase, optional): destination tensordict\n        keep_other (bool, optional): if True, all keys that do not start with :obj:`'next_'` will be kept.\n            Default is True.\n        exclude_reward (bool, optional): if True, the :obj:`\"reward\"` key will be discarded\n            from the resulting tensordict.\n            Default is True.\n        exclude_done (bool, optional): if True, the :obj:`\"done\"` key will be discarded\n            from the resulting tensordict.\n            Default is True.\n        exclude_action (bool, optional): if True, the :obj:`\"action\"` key will be discarded\n            from the resulting tensordict.\n            Default is True.\n\n    Returns:\n         A new tensordict (or next_tensordict) containing the tensors of the t+1 step.\n\n    Examples:\n    This funtion allows for this kind of loop to be used:\n        >>> td_out = []\n        >>> env = make_env()\n        >>> policy = make_policy()\n        >>> td = env.reset()\n        >>> for i in range(max_steps):\n        >>>     td = env.step(td)\n        >>>     next_td = step_mdp(td)\n        >>>     assert next_td is not td # make sure that keys are not overwritten\n        >>>     td_out.append(td)\n        >>>     td = next_td\n        >>> td_out = torch.stack(td_out, 0)\n        >>> print(td_out) # should contain keys 'observation', 'next_observation', 'action', 'reward', 'done' or similar\n\n    \"\"\"\n    other_keys = []\n    prohibited = set()\n    if exclude_done:", "completion": "prohibited.add(\"done\")\n    if exclude_reward:\n        prohibited.add(\"reward\")\n    if exclude_action:\n        prohibited.add(\"action\")\n\n    if next_tensordict is None:\n        next_tensordict = TensorDictBase()\n\n    for key, value in tensordict.items():\n        if key.startswith(\"next_\"):\n            next_key = key[5:]\n            if next_key not in prohibited:\n                next_tensordict[next_key] = value\n        elif keep_other:\n            other_keys.append(key)\n\n    for key in other_keys:\n        next_tensordict[key] = tensordict[key]\n\n    if _run_check:\n        _check_step_mdp(tensordict, next_tensordict)\n\n    return next_tensordict\n\n\ndef _check_step_mdp(tensordict, next_tensordict):\n    assert isinstance(tensordict, TensorDictBase)\n    assert isinstance(next_tensordict, TensorDictBase)\n\n    for key in tensordict.keys():\n        if key.startswith(\"next_\"):\n            assert key[5:] not in tensordict.keys()\n\n    for key in next_tensordict.keys():\n        assert key.startswith(\"next_\")\n", "metadata": {"task_id": "pytorch_rl/28", "ground_truth": "        prohibited.add(\"done\")", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "utils.py"], "context_start_lineno": 0, "line_no": 71, "query_window": {"context": "\n    Examples:\n    This funtion allows for this kind of loop to be used:\n        >>> td_out = []\n        >>> env = make_env()\n        >>> policy = make_policy()\n        >>> td = env.reset()\n        >>> for i in range(max_steps):\n        >>>     td = env.step(td)\n        >>>     next_td = step_mdp(td)\n        >>>     assert next_td is not td # make sure that keys are not overwritten\n        >>>     td_out.append(td)\n        >>>     td = next_td\n        >>> td_out = torch.stack(td_out, 0)\n        >>> print(td_out) # should contain keys 'observation', 'next_observation', 'action', 'reward', 'done' or similar\n\n    \"\"\"\n    other_keys = []\n    prohibited = set()\n    if exclude_done:", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "utils.py"], "line_no": 71, "task_id": "pytorch_rl/28", "start_line_no": 51, "end_line_no": 71, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "# equivalent\ntorch.manual_seed(0)\nenv.set_seed(0)\n\nmax_steps = 100\ntensordict = env.reset()\ntensordicts = []\nfor _ in range(max_steps):\n    actor(tensordict)\n    tensordicts.append(env.step(tensordict))\n    if tensordict[\"done\"].any():\n        break\n    tensordict = step_mdp(tensordict)  # roughly equivalent to obs = next_obs\ntensordicts_stack = torch.stack(tensordicts, 0)\nprint(\"total steps:\", i)\nprint(tensordicts_stack)\n\n###############################################################################\n\n(tensordicts_stack == tensordicts_prealloc).all()", "metadata": [{"fpath_tuple": ["pytorch_rl", "tutorials", "sphinx-tutorials", "torchrl_demo.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26356589147286824}, {"context": "\n    for i in range(max_steps):\n        td = env.step(\n            TensorDict({\"action\": action}, batch_size=env.batch_size, device=env.device)\n        )\n        assert (td[\"done\"] == 0).all()\n        assert (td[\"next\"][\"observation\"] == i + 1).all()\n\n    td = env.step(\n        TensorDict({\"action\": action}, batch_size=env.batch_size, device=env.device)\n    )\n    assert (td[\"done\"] == 1).all()\n    assert (td[\"next\"][\"observation\"] == max_steps + 1).all()\n\n    _reset = torch.randint(low=0, high=2, size=env.batch_size, dtype=torch.bool)\n    td_reset = env.reset(\n        TensorDict({\"_reset\": _reset}, batch_size=env.batch_size, device=env.device)\n    )\n\n    assert (td_reset[\"done\"][_reset] == 0).all()", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 960, "start_line_no": 950, "end_line_no": 970, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2619047619047619}, {"context": "            Default: 'state_action_value'\n        gamma (float, optional): return discount rate.\n            default: 0.99\n        pred_next_val (Tensor, optional): the next state value can be provided if it is not computed with the operator.\n\n    Returns:\n        a Tensor of the size of the input tensordict containing the predicted value state.\n\n    \"\"\"\n    if \"steps_to_next_obs\" in tensordict.keys():\n        steps_to_next_obs = tensordict.get(\"steps_to_next_obs\").squeeze(-1)\n    else:\n        steps_to_next_obs = 1\n\n    rewards = tensordict.get(\"reward\").squeeze(-1)\n    done = tensordict.get(\"done\").squeeze(-1)\n\n    if pred_next_val is None:\n        next_td = step_mdp(tensordict)  # next_observation -> observation\n        next_td = next_td.select(*operator.in_keys)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "objectives", "utils.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2550335570469799}, {"context": "        assert env0.device == torch.device(device)\n        td_device = env0.reset()\n        assert td_device.device == torch.device(device), env0\n        td_device = env0.rand_step()\n        assert td_device.device == torch.device(device), env0\n        td_device = env0.rollout(max_steps=10)\n        assert td_device.device == torch.device(device), env0\n\n        if open_before:\n            td_cpu = env_serial.rollout(max_steps=10)\n            assert td_cpu.device == torch.device(\"cpu\")\n        env_serial = env_serial.to(device)\n        assert env_serial.observation_spec.device == torch.device(device)\n        assert env_serial.action_spec.device == torch.device(device)\n        assert env_serial.reward_spec.device == torch.device(device)\n        assert env_serial.device == torch.device(device)\n        td_device = env_serial.reset()\n        assert td_device.device == torch.device(device), env_serial\n        td_device = env_serial.rand_step()\n        assert td_device.device == torch.device(device), env_serial", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 740, "start_line_no": 730, "end_line_no": 750, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2549019607843137}, {"context": "            assert td_cpu.device == torch.device(\"cpu\")\n        env_serial = env_serial.to(device)\n        assert env_serial.observation_spec.device == torch.device(device)\n        assert env_serial.action_spec.device == torch.device(device)\n        assert env_serial.reward_spec.device == torch.device(device)\n        assert env_serial.device == torch.device(device)\n        td_device = env_serial.reset()\n        assert td_device.device == torch.device(device), env_serial\n        td_device = env_serial.rand_step()\n        assert td_device.device == torch.device(device), env_serial\n        td_device = env_serial.rollout(max_steps=10)\n        assert td_device.device == torch.device(device), env_serial\n\n        if open_before:\n            td_cpu = env_parallel.rollout(max_steps=10)\n            assert td_cpu.device == torch.device(\"cpu\")\n        env_parallel = env_parallel.to(device)\n        assert env_parallel.observation_spec.device == torch.device(device)\n        assert env_parallel.action_spec.device == torch.device(device)\n        assert env_parallel.reward_spec.device == torch.device(device)", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_env.py"], "line_no": 750, "start_line_no": 740, "end_line_no": 760, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2524271844660194}, {"context": "        env_t = TransformedEnv(env, t)\n        td = env_t.reset()\n        tds = []\n        for _ in range(N):\n            td = env_t.rand_step(td)\n            tds.append(td.clone())\n            if td.get(\"done\").any():\n                td = env_t.reset()\n        tds = torch.stack(tds, 0)\n        obs = tds.get((\"next\", \"observation\"))\n        obs = obs.view(-1, obs.shape[-1])\n        mean = obs.mean(0)\n        assert (abs(mean) < thr).all()\n        std = obs.std(0)\n        assert (abs(std - 1) < thr).all()\n        if not env_t.is_closed:\n            env_t.close()\n        self.SEED = 0\n\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_transforms.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2518518518518518}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/data/loader.py\n# --------------------------------------------------\n#         ----------\n#         data_loader : DataLoader\n#             A data loader.\n# \n#         Returns\n#         -------\n#         TargetsLoader\n#             A targets loader.\n#         \"\"\"\n#         return cls(targets_loader=FromDataLoaderToTargetsLoader(data_loader))\n# \n#     @classmethod\n#     def from_array_targets(\n#         cls,\n#         targets: Array,\n#         batch_size: Optional[int] = None,\n#         shuffle: bool = False,\n#         prefetch: bool = False,\n#     ) -> TargetsLoader:\n#         \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/classification.py\n# --------------------------------------------------\n#         val_targets: Optional[Array]\n#             Validation target variables.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_outputs, calib_targets)\n#         if val_outputs is not None:\n#             self._check_output_dim(val_outputs, val_targets)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.mean,\n#             calib_outputs=calib_outputs,\n#             calib_targets=calib_targets,\n#             val_outputs=val_outputs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/regression.py\n# --------------------------------------------------\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_outputs, calib_targets)\n#         if val_outputs is not None:\n#             self._check_output_dim(val_outputs, val_targets)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.variance,\n#             calib_outputs=calib_outputs,\n#             calib_targets=calib_targets,\n#             val_outputs=val_outputs,\n#             val_targets=val_targets,\n#             calib_config=calib_config,\n#         )\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/classification.py\n# --------------------------------------------------\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n#             self._check_output_dim(val_data_loader)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.mean,\n#             calib_data_loader=calib_data_loader,\n#             val_data_loader=val_data_loader,\n#             calib_config=calib_config,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/classification.py\n# --------------------------------------------------\n#         self._check_output_dim(calib_outputs, calib_targets)\n#         if val_outputs is not None:\n#             self._check_output_dim(val_outputs, val_targets)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.mean,\n#             calib_outputs=calib_outputs,\n#             calib_targets=calib_targets,\n#             val_outputs=val_outputs,\n#             val_targets=val_targets,\n#             calib_config=calib_config,\n#         )\n# \n#     def _check_output_dim(self, outputs: jnp.ndarray, targets: jnp.array):\n#         n_classes = len(np.unique(targets))\n#         if outputs.shape[1] != n_classes:\n#             raise ValueError(\n#                 f\"\"\"`outputs.shape[1]` must be the same as the dimension of the number of classes in `targets`. \n#                 However, `outputs.shape[1]={outputs.shape[1]}` and `len(np.unique(targets))={n_classes}`.\"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/regression.py\n# --------------------------------------------------\n#         if val_outputs is not None:\n#             self._check_output_dim(val_outputs, val_targets)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.variance,\n#             calib_outputs=calib_outputs,\n#             calib_targets=calib_targets,\n#             val_outputs=val_outputs,\n#             val_targets=val_targets,\n#             calib_config=calib_config,\n#         )\n# \n#     def _check_output_dim(self, outputs: jnp.ndarray, targets: jnp.array):\n#         if outputs.shape[1] != 2 * targets.shape[1]:\n#             raise ValueError(\n#                 f\"\"\"`outputs.shape[1]` must be twice the dimension of the target variables in `targets`, with \n#                 first and second halves corresponding to the mean and log-variance of the likelihood, respectively. \n#                 However, `outputs.shape[1]={outputs.shape[1]}` and `targets.shape[1]={targets.shape[1]}`.\"\"\"\n#             )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/prob_model/classification.py\n# --------------------------------------------------\n#             A validation data loader.\n#         calib_config : CalibConfig\n#             An object to configure the calibration.\n# \n#         Returns\n#         -------\n#         Status\n#             A calibration status object. It provides information about the calibration.\n#         \"\"\"\n#         self._check_output_dim(calib_data_loader)\n#         if val_data_loader is not None:\n#             self._check_output_dim(val_data_loader)\n#         return super()._calibrate(\n#             uncertainty_fn=calib_config.monitor.uncertainty_fn\n#             if calib_config.monitor.uncertainty_fn is not None\n#             else self.prob_output_layer.mean,\n#             calib_data_loader=calib_data_loader,\n#             val_data_loader=val_data_loader,\n#             calib_config=calib_config,\n#         )\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n nn.Module,\n        likelihood_log_variance_model: nn.Module,\n        prior: Prior = IsotropicGaussianPrior(),\n        posterior_approximator: PosteriorApproximator = SWAGPosteriorApproximator(),\n        output_calibrator: Optional[nn.Module] = RegressionTemperatureScaler(),\n        seed: int = 0,\n    ):\n        r\"\"\"\n        A probabilistic regressor class.\n\n        Parameters\n        ----------\n        model : nn.Module\n            A model describing the deterministic relation between inputs and outputs. It characterizes the mean model\n            of the likelihood function. The outputs must belong to the same space as the target variables.\n            Let :math:`x` be input variables and :math:`w` the random model parameters. Then the model is described by\n            a function :math:`\\mu(w, x)`.\n        likelihood_log_variance_model: nn.Module\n            A model characterizing the log-variance of a Gaussian likelihood function. The outputs must belong to the\n            same space as the target variables. Let :math:`x` be input variables and :math:`w` the random model\n            parameters. Then the model is described by a function :math:`\\log\\sigma^2(w, x)`.\n        prior : Prior\n            A prior distribution object. The default is an isotropic standard Gaussian. Let :math:`w` be the random\n            model parameters. Then the prior is defined by a distribution :math:`p(w)`.\n        posterior_approximator : PosteriorApproximator\n            A posterior approximation method. The default method is SWAG.\n        output_calibrator : Optional[nn.Module]\n            An output calibrator object. The default is temperature scaling for regression, which inflates the variance\n            of the likelihood with a scalar temperature parameter. Given outputs :math:`o` of the model manager, the\n            output calibrator is described by a function :math:`g(\\phi, o)`, where `phi` are deterministic\n            calibration parameters.\n        seed: int\n            A random seed.\n\n        Attributes\n        ----------\n        model : nn.Module\n            See `model` in `Parameters`.\n        model_manager : RegressionModelManager\n            This object orchestrates the model's forward pass. Given a mean model :math:`\\mu(w, x)` and a log-variance\n            model :math:`\\log\\sigma^2`, the model manager concatenates the two into\n            :math:`f(w, x)=[\\mu(w, x), \\log\\sigma^2(w, x)]`.\n        output_calibrator : nn.Module\n            See `output_calibrator` in `Parameters`.\n        prob_output_layer : RegressionProbOutputLayer\n            This object characterizes the distribution of the target variable given the calibrated outputs. It is\n            defined by :math:`p(y|\\omega)=\\text{Categorical}(p=softmax(\\omega))`, where :math:`\\omega` denote the\n            calibrated outputs and :math:`y` denotes a target variable.\n        likelihood : RegressionLikelihood\n            The likelihood function. This is defined by\n            :math:`p(y|w, \\phi, x) = \\text{Categorical}(p=\\text{softmax}(g(\\phi, f(w, x)))`.\n        prior : Prior\n            See `prior` in `Parameters`.\n        joint : Joint\n            This object describes the joint distribution of the target variables and the random parameters\n            given the input variables and the calibration parameters, that is :math:`p(y, w|x, \\phi)`.\n        posterior_approximator : PosteriorApproximator\n            See `posterior_approximator` in `Parameters`.\n        posterior : Posterior\n            This is the posterior approximation of the random parameters given the training data and the\n            calibration parameters, that is :math:`p(w|\\mathcal{D}, \\phi)`, where :math:`\\mathcal{D}` denotes the\n            training data set and :math:`\\phi` the calibration parameters.\n        predictive : RegressionPredictive\n            This denotes the predictive distribution, that is :math:`p(y|\\phi, x, \\mathcal{D})`. Its statistics are\n            approximated via a Monte Carlo approach by sampling from the posterior approximation.\n        \"\"\"\n        self.model = model\n        self.lik_log_var = likelihood_log_variance_model\n        self.prior = prior\n        self.output_calibrator = output_calibrator\n\n        self.model_manager = RegressionModelManager(\n            model, likelihood_log_variance_model\n        )\n        self.output_calib_manager = OutputCalibManager(\n            output_calibrator=output_calibrator\n        )\n        self.prob_output_layer = RegressionProbOutputLayer()\n\n        self.likelihood = RegressionLikelihood(\n            self.model_manager, self.prob_output_layer, self.output_calib_manager\n        )\n        self.joint = Joint(self.prior, self.likelihood)\n\n        self.posterior = getattr(\n            PosteriorApproximations, posterior_approximator.__str__()\n        ).value(joint=self.joint, posterior_approximator=posterior_approximator)\n        self.predictive = RegressionPredictive(self.posterior)\n\n        super().__init__(seed=seed)\n\n    def _check_output_dim(self, data_loader: DataLoader):\n        output_dim = 0\n        for x, y in data_loader:\n            input_shape = x.shape[1:]\n            output_dim = y.shape[1]\n            break\n        if output_dim == 0:\n            raise ValueError(\n                \"\"\"`_data_loader` is either empty or incorrectly constructed.\"\"\"\n            )\n        s = self.joint.init(input_shape)\n        outputs = self.model_manager.apply(\n            params=s.params, inputs=np.zeros((1,) + input_shape), mutable=s.mutable\n        )\n        if outputs.shape[1] != 2 * output_dim:\n            raise ValueError(\n                f\"\"\"The outputs dimension of both `model` and `likelihood_log_variance_model` must be the same as\n                the dimension of the target variables in `_data_loader`. However, {outputs.shape[1] // 2} and \n                {output_dim} were found, respectively.\"\"\"\n            )\n\n    def train(\n        self,\n        train_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_data_loader: Optional[DataLoader] = None,\n        fit_config: FitConfig = FitConfig(),\n        calib_config: CalibConfig = CalibConfig(),\n        **fit_kwargs,\n    ) -> Dict[str, Status]:\n        self._check_output_dim(train_data_loader)\n        return super().train(\n            train_data_loader,\n            val_data_loader,\n            calib_data_loader,\n            fit_config,\n            calib_config,\n            **fit_kwargs,\n        )\n\n    def calibrate(\n        self,\n        calib_data_loader: DataLoader,\n        val_data_loader: Optional[DataLoader] = None,\n        calib_config: CalibConfig = CalibConfig(),\n    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_data_loader)\n        if val_data_loader is not None:\n            self._check_output_dim(val_data_loader)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.variance,", "completion": "calib_data_loader=calib_data_loader,\n            val_data_loader=val_data_loader,\n            calib_config=calib_config,\n        )", "metadata": {"task_id": "awslabs_fortuna/94", "ground_truth": "            calib_data_loader=calib_data_loader,", "fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "regression.py"], "context_start_lineno": 30, "line_no": 191, "query_window": {"context": "        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_data_loader)\n        if val_data_loader is not None:\n            self._check_output_dim(val_data_loader)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.variance,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "regression.py"], "line_no": 191, "task_id": "awslabs_fortuna/94", "start_line_no": 171, "end_line_no": 191, "window_size": 20, "context_start_lineno": 30, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_data_loader)\n        if val_data_loader is not None:\n            self._check_output_dim(val_data_loader)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.mean,\n            calib_data_loader=calib_data_loader,\n            val_data_loader=val_data_loader,\n            calib_config=calib_config,\n        )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "classification.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 189, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.8493150684931506}, {"context": "\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_outputs, calib_targets)\n        if val_outputs is not None:\n            self._check_output_dim(val_outputs, val_targets)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.variance,\n            calib_outputs=calib_outputs,\n            calib_targets=calib_targets,\n            val_outputs=val_outputs,\n            val_targets=val_targets,\n            calib_config=calib_config,\n        )\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "regression.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7236842105263158}, {"context": "        val_targets: Optional[Array]\n            Validation target variables.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_outputs, calib_targets)\n        if val_outputs is not None:\n            self._check_output_dim(val_outputs, val_targets)\n        return super()._calibrate(\n            uncertainty_fn=calib_config.monitor.uncertainty_fn\n            if calib_config.monitor.uncertainty_fn is not None\n            else self.prob_output_layer.mean,\n            calib_outputs=calib_outputs,\n            calib_targets=calib_targets,\n            val_outputs=val_outputs,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "classification.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7142857142857143}, {"context": "    ) -> Status:\n        \"\"\"\n        Calibrate the probabilistic classifier.\n\n        Parameters\n        ----------\n        calib_data_loader : DataLoader\n            A calibration data loader.\n        val_data_loader : DataLoader\n            A validation data loader.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_data_loader)\n        if val_data_loader is not None:", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "prob_model", "classification.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6625}, {"context": "        calib_outputs: Array\n            Calibration model outputs.\n        calib_targets: Array\n            Calibration target variables.\n        val_outputs: Optional[Array]\n            Validation model outputs.\n        val_targets: Optional[Array]\n            Validation target variables.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"\n        self._check_output_dim(calib_outputs, calib_targets)\n        if val_outputs is not None:\n            self._check_output_dim(val_outputs, val_targets)\n        return super()._calibrate(", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "regression.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5632183908045977}, {"context": "        Calibrate the model outputs.\n\n        Parameters\n        ----------\n        calib_outputs: Array\n            Calibration model outputs.\n        calib_targets: Array\n            Calibration target variables.\n        val_outputs: Optional[Array]\n            Validation model outputs.\n        val_targets: Optional[Array]\n            Validation target variables.\n        calib_config : CalibConfig\n            An object to configure the calibration.\n\n        Returns\n        -------\n        Status\n            A calibration status object. It provides information about the calibration.\n        \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "classification.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3977272727272727}, {"context": "\n    def __iter__(self):\n        yield from self._targets_loader()\n\n    @classmethod\n    def from_data_loader(cls, data_loader: DataLoader) -> TargetsLoader:\n        \"\"\"\n        Reduce a data loader to a targets loader.\n\n        Parameters\n        ----------\n        data_loader : DataLoader\n            A data loader.\n\n        Returns\n        -------\n        TargetsLoader\n            A targets loader.\n        \"\"\"\n        return cls(targets_loader=FromDataLoaderToTargetsLoader(data_loader))", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "data", "loader.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.27722772277227725}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#                 metrics=metrics,\n#             )\n#             # keep track of training losses and metrics [granularity=batch]\n#             training_losses_and_metrics_epoch_all_steps.append(\n#                 training_losses_and_metrics_current_batch\n#             )\n#             # logging\n#             if verbose:\n#                 training_batch_metrics_str = \" | \".join(\n#                     [\n#                         f\"{m}: {round(float(v), 5)}\"\n#                         for m, v in training_losses_and_metrics_current_batch.items()\n#                     ]\n#                 )\n#                 progress_bar.set_description(\n#                     f\"Epoch: {current_epoch + 1} | \" + training_batch_metrics_str,\n#                     refresh=True,\n#                 )\n# \n#         # compute training losses and metrics avg for the current epoch + other ops (if needed)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#                 # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n#                 for k in val_losses_and_metrics_current_epoch.keys():\n#                     val_losses_and_metrics[k].append(\n#                         val_losses_and_metrics_current_epoch[k]\n#                     )\n#                 # check for early stopping\n#                 if self.is_early_stopping_active and self._early_stopping.should_stop:\n#                     logging.info(\"[Early Stopping] Stopping training...\")\n#                     break\n# \n#         # aggregate\n#         training_status = {\n#             k: jnp.array(v) for k, v in training_losses_and_metrics.items()\n#         }\n#         val_status = {k: jnp.array(v) for k, v in val_losses_and_metrics.items()}\n#         status = dict(**training_status, **val_status)\n# \n#         state = self.on_train_end(state)\n#         return state, status\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#                     metrics=metrics,\n#                     rng=rng,\n#                     state=state,\n#                     val_data_loader=val_data_loader,\n#                     val_outputs_loader=val_outputs_loader,\n#                     val_dataset_size=val_dataset_size,\n#                     verbose=verbose,\n#                 )\n#                 if verbose:\n#                     logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)\n#                 # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n#                 for k in val_losses_and_metrics_current_epoch.keys():\n#                     val_losses_and_metrics[k].append(\n#                         val_losses_and_metrics_current_epoch[k]\n#                     )\n#                 # check for early stopping\n#                 if self.is_early_stopping_active and self._early_stopping.should_stop:\n#                     logging.info(\"[Early Stopping] Stopping training...\")\n#                     break\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n#                 calib_outputs_loader,\n#                 training_dataset_size,\n#                 verbose,\n#                 progress_bar,\n#             )\n#             # keep track of training losses and metrics [granularity=epoch]\n#             for k in training_losses_and_metrics_current_epoch.keys():\n#                 training_losses_and_metrics[k].append(\n#                     training_losses_and_metrics_current_epoch[k]\n#                 )\n# \n#             # validation loop\n#             if self.should_perform_validation(val_data_loader, epoch):\n#                 # performance evaluation on the whole validation dataset\n#                 state = self.on_val_start(state)\n#                 (\n#                     val_losses_and_metrics_current_epoch,\n#                     val_epoch_metrics_str,\n#                 ) = self._val_loop(\n#                     fun=fun,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/training/trainer.py\n# --------------------------------------------------\n#             )\n#             # keep track of training losses and metrics [granularity=epoch]\n#             for k in training_losses_and_metrics_current_epoch.keys():\n#                 training_losses_and_metrics[k].append(\n#                     training_losses_and_metrics_current_epoch[k]\n#                 )\n# \n#             # validation loop\n#             if self.should_perform_validation(validation_dataloader, epoch):\n#                 # performance evaluation on the whole validation dataset\n#                 state = self.on_validation_start(state)\n#                 (\n#                     validation_losses_and_metrics_current_epoch,\n#                     validation_epoch_metrics_str,\n#                 ) = self._validation_loop(\n#                     fun=fun,\n#                     metrics=metrics,\n#                     rng=rng,\n#                     state=state,\n#                     training_kwargs=training_kwargs,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/training/trainer.py\n# --------------------------------------------------\n#                 state = self.on_validation_start(state)\n#                 (\n#                     validation_losses_and_metrics_current_epoch,\n#                     validation_epoch_metrics_str,\n#                 ) = self._validation_loop(\n#                     fun=fun,\n#                     metrics=metrics,\n#                     rng=rng,\n#                     state=state,\n#                     training_kwargs=training_kwargs,\n#                     validation_dataloader=validation_dataloader,\n#                     validation_dataset_size=validation_dataset_size,\n#                     verbose=verbose,\n#                     unravel=unravel,\n#                 )\n#                 if verbose:\n#                     logging.info(\n#                         f\"Epoch: {epoch + 1} | \" + validation_epoch_metrics_str\n#                     )\n#                 # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calibration/calibrator.py\n# --------------------------------------------------\n# \n#             # validation loop\n#             if self.should_perform_validation(val_data_loader, epoch):\n#                 # performance evaluation on the whole validation dataset\n#                 state = self.on_val_start(state)\n#                 (\n#                     val_losses_and_metrics_current_epoch,\n#                     val_epoch_metrics_str,\n#                 ) = self._val_loop(\n#                     fun=fun,\n#                     metrics=metrics,\n#                     rng=rng,\n#                     state=state,\n#                     val_data_loader=val_data_loader,\n#                     val_outputs_loader=val_outputs_loader,\n#                     val_dataset_size=val_dataset_size,\n#                     verbose=verbose,\n#                 )\n#                 if verbose:\n#                     logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport abc\nimport collections\nimport logging\nfrom functools import partial\nfrom typing import Any, Callable, Dict, List, Optional, Tuple, Union\n\nimport jax\nimport jax.numpy as jnp\nfrom flax import jax_utils\nfrom flax.training.common_utils import stack_forest\nfrom jax import lax, random, value_and_grad\nfrom jax._src.prng import PRNGKeyArray\nfrom jax.tree_util import tree_map\nfrom tqdm import trange\nfrom tqdm.std import tqdm as TqdmDecorator\n\nfrom fortuna.calibration.state import CalibState\nfrom fortuna.data.loader import DataLoader, TargetsLoader\nfrom fortuna.training.mixin import (InputValidatorMixin,\n                                    WithCheckpointingMixin,\n                                    WithEarlyStoppingMixin)\nfrom fortuna.typing import Array, CalibMutable, CalibParams, Path, Status\nfrom fortuna.utils.builtins import HashableMixin\n\n\nclass CalibModelCalibrator(\n    HashableMixin,\n    WithCheckpointingMixin,\n    WithEarlyStoppingMixin,\n    InputValidatorMixin,\n    metaclass=abc.ABCMeta,\n):\n    def __init__(\n        self,\n        *args,\n        calib_outputs: Array,\n        calib_targets: Array,\n        predict_fn: Callable[[jnp.ndarray], jnp.ndarray],\n        uncertainty_fn: Callable[[jnp.ndarray], jnp.ndarray],\n        val_outputs: Array,\n        val_targets: Array,\n        save_checkpoint_dir: Optional[Path] = None,\n        save_every_n_steps: Optional[int] = None,\n        keep_top_n_checkpoints: int = 2,\n        disable_training_metrics_computation: bool = False,\n        eval_every_n_epochs: int = 1,\n        **kwargs,\n    ):\n        super(CalibModelCalibrator, self).__init__(*args, **kwargs)\n        self._calib_outputs = calib_outputs\n        self._calib_targets = calib_targets\n        self._val_outputs = val_outputs\n        self._val_targets = val_targets\n        self.predict_fn = predict_fn\n        self.uncertainty_fn = uncertainty_fn\n        self.save_checkpoint_dir = save_checkpoint_dir\n        self.save_every_n_steps = save_every_n_steps\n        self.keep_top_n_checkpoints = keep_top_n_checkpoints\n        self.disable_training_metrics_computation = disable_training_metrics_computation\n        self.eval_every_n_epochs = eval_every_n_epochs\n        self.multi_device = False\n\n    def train(\n        self,\n        rng: PRNGKeyArray,\n        state: CalibState,\n        fun: Callable,\n        n_epochs: int = 1,\n        metrics: Optional[\n            Tuple[Callable[[jnp.ndarray, jnp.ndarray, Array], Array], ...]\n        ] = None,\n        verbose: bool = True,\n    ) -> Tuple[CalibState, Status]:\n        training_losses_and_metrics = collections.defaultdict(list)\n        val_losses_and_metrics = collections.defaultdict(list)\n\n        state, targets, outputs, rng = self.on_train_start(\n            state,\n            [self._calib_targets, self._val_targets],\n            [self._calib_outputs, self._val_outputs],\n            rng,\n        )\n        calib_targets, val_targets = targets\n        calib_outputs, val_outputs = outputs\n\n        progress_bar = trange(n_epochs, desc=\"Epoch\")\n        for epoch in progress_bar:\n            # training loop\n            (\n                state,\n                training_losses_and_metrics_current_epoch,\n                training_batch_metrics_str,\n            ) = self._training_loop(\n                epoch,\n                fun,\n                metrics,\n                rng,\n                state,\n                calib_targets,\n                calib_outputs,\n                verbose,\n                progress_bar,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(val_targets, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_val_start(state)", "completion": "(\n                    val_losses_and_metrics_current_epoch,\n                    val_epoch_metrics_str,\n                ) = self._val_loop(\n                    fun=fun,\n                    metrics=metrics,\n                    rng=rng,\n                    state=state,\n                    val_targets=val_targets,\n                    val_outputs=val_outputs,\n                    verbose=verbose,\n                )\n                if verbose:\n                    logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)\n                # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n                for k in val_losses_and_metrics_current_epoch.keys():\n                    val_losses_and_metrics[k].append(\n                        val_losses_and_metrics_current_epoch[k]\n                    )\n                # check for early stopping\n                if self.is_early_stopping_active and self._early_stopping.should_stop:\n                    logging.info(\"[Early Stopping] Stopping training...\")\n                    break\n\n        # aggregate\n        training_status = {\n            k: jnp.array(v) for k, v in training_losses_and_metrics.items()\n        }\n        val_status = {k: jnp.array(v) for k, v in val_losses_and_metrics.items()}\n        status = dict(**training_status, **val_status)\n\n        state = self.on", "metadata": {"task_id": "awslabs_fortuna/123", "ground_truth": "                (", "fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "context_start_lineno": 0, "line_no": 113, "query_window": {"context": "                epoch,\n                fun,\n                metrics,\n                rng,\n                state,\n                calib_targets,\n                calib_outputs,\n                verbose,\n                progress_bar,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(val_targets, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_val_start(state)", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "calib_model_calibrator.py"], "line_no": 113, "task_id": "awslabs_fortuna/123", "start_line_no": 93, "end_line_no": 113, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "                calib_outputs_loader,\n                training_dataset_size,\n                verbose,\n                progress_bar,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(val_data_loader, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_val_start(state)\n                (\n                    val_losses_and_metrics_current_epoch,\n                    val_epoch_metrics_str,\n                ) = self._val_loop(\n                    fun=fun,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.8089887640449438}, {"context": "            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(validation_dataloader, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_validation_start(state)\n                (\n                    validation_losses_and_metrics_current_epoch,\n                    validation_epoch_metrics_str,\n                ) = self._validation_loop(\n                    fun=fun,\n                    metrics=metrics,\n                    rng=rng,\n                    state=state,\n                    training_kwargs=training_kwargs,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "training", "trainer.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7333333333333333}, {"context": "                fun,\n                metrics,\n                rng,\n                state,\n                training_dataloader,\n                training_dataset_size,\n                training_kwargs,\n                verbose,\n                progress_bar,\n                unravel=unravel,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )\n\n            # validation loop\n            if self.should_perform_validation(validation_dataloader, epoch):\n                # performance evaluation on the whole validation dataset", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "training", "trainer.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7222222222222222}, {"context": "                state,\n                training_losses_and_metrics_current_epoch,\n                training_batch_metrics_str,\n            ) = self._training_loop(\n                epoch,\n                fun,\n                metrics,\n                rng,\n                state,\n                training_data_loader,\n                calib_outputs_loader,\n                training_dataset_size,\n                verbose,\n                progress_bar,\n            )\n            # keep track of training losses and metrics [granularity=epoch]\n            for k in training_losses_and_metrics_current_epoch.keys():\n                training_losses_and_metrics[k].append(\n                    training_losses_and_metrics_current_epoch[k]\n                )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6022727272727273}, {"context": "\n            # validation loop\n            if self.should_perform_validation(val_data_loader, epoch):\n                # performance evaluation on the whole validation dataset\n                state = self.on_val_start(state)\n                (\n                    val_losses_and_metrics_current_epoch,\n                    val_epoch_metrics_str,\n                ) = self._val_loop(\n                    fun=fun,\n                    metrics=metrics,\n                    rng=rng,\n                    state=state,\n                    val_data_loader=val_data_loader,\n                    val_outputs_loader=val_outputs_loader,\n                    val_dataset_size=val_dataset_size,\n                    verbose=verbose,\n                )\n                if verbose:\n                    logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.49514563106796117}, {"context": "                    metrics=metrics,\n                    rng=rng,\n                    state=state,\n                    val_data_loader=val_data_loader,\n                    val_outputs_loader=val_outputs_loader,\n                    val_dataset_size=val_dataset_size,\n                    verbose=verbose,\n                )\n                if verbose:\n                    logging.info(f\"Epoch: {epoch + 1} | \" + val_epoch_metrics_str)\n                # keep track of training losses and metrics [granularity=epoch] and check for early stopping\n                for k in val_losses_and_metrics_current_epoch.keys():\n                    val_losses_and_metrics[k].append(\n                        val_losses_and_metrics_current_epoch[k]\n                    )\n                # check for early stopping\n                if self.is_early_stopping_active and self._early_stopping.should_stop:\n                    logging.info(\"[Early Stopping] Stopping training...\")\n                    break\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 130, "start_line_no": 120, "end_line_no": 140, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4396551724137931}, {"context": "            # forward and backward pass\n            state, aux = self.training_step(\n                state, batch, outputs, fun, rng, training_dataset_size\n            )\n            # compute training losses and metrics for the current batch\n            training_losses_and_metrics_current_batch = self.training_step_end(\n                current_epoch=current_epoch,\n                state=state,\n                aux=aux,\n                batch=batch,\n                metrics=metrics,\n            )\n            # keep track of training losses and metrics [granularity=batch]\n            training_losses_and_metrics_epoch_all_steps.append(\n                training_losses_and_metrics_current_batch\n            )\n            # logging\n            if verbose:\n                training_batch_metrics_str = \" | \".join(\n                    [", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calibration", "calibrator.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4174757281553398}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/server.py\n# --------------------------------------------------\n#         # [ICLR'22, What Do We Mean by Generalization in Federated Learning?]\n#         self.unseen_clients_id = [] if unseen_clients_id is None \\\n#             else unseen_clients_id\n# \n#         # Server state\n#         self.is_finish = False\n# \n#         # Sampler\n#         if self._cfg.federate.sampler in ['uniform']:\n#             self.sampler = get_sampler(\n#                 sample_strategy=self._cfg.federate.sampler,\n#                 client_num=self.client_num,\n#                 client_info=None)\n#         else:\n#             # Some type of sampler would be instantiated in trigger_for_start,\n#             # since they need more information\n#             self.sampler = None\n# \n#         # Current Timestamp\n#         self.cur_timestamp = 0\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/client.py\n# --------------------------------------------------\n#         # Otherwise, we set patience=0 to deactivate the local early-stopper\n#         patience = self._cfg.early_stop.patience if \\\n#             self._cfg.federate.method in [\n#                 \"local\", \"global\"\n#             ] else 0\n#         self.early_stopper = EarlyStopper(\n#             patience, self._cfg.early_stop.delta,\n#             self._cfg.early_stop.improve_indicator_mode,\n#             self._monitor.the_larger_the_better)\n# \n#         # Secret Sharing Manager and message buffer\n#         self.ss_manager = AdditiveSecretSharing(\n#             shared_party_num=int(self._cfg.federate.sample_client_num\n#                                  )) if self._cfg.federate.use_ss else None\n#         self.msg_buffer = {'train': dict(), 'eval': dict()}\n# \n#         # Communication and communication ability\n#         if 'resource_info' in kwargs and kwargs['resource_info'] is not None:\n#             self.comp_speed = float(\n#                 kwargs['resource_info']['computation']) / 1000.  # (s/sample)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/data/base_data.py\n# --------------------------------------------------\n#                         and len(datadict[0]) != 0, \\\n#                         \"You specified cfg.data.server_holds_all=True \" \\\n#                         \"but data[0] is None. Please check whether you \" \\\n#                         \"pre-process the data[0] correctly\"\n#                     datadict[1] = datadict[0]\n#                 else:\n#                     logger.info(f\"Will merge data from clients whose ids in \"\n#                                 f\"[1, {self.global_cfg.federate.client_num}]\")\n#                     merged_data = merge_data(\n#                         all_data=datadict,\n#                         merged_max_data_id=self.global_cfg.federate.client_num)\n#                     datadict[1] = ClientData(self.global_cfg, **merged_data)\n#         datadict = self.attack(datadict)\n#         return datadict\n# \n#     def attack(self, datadict):\n#         \"\"\"\n#         Apply attack to ``StandaloneDataDict``.\n#         \"\"\"\n#         if 'backdoor' in self.global_cfg.attack.attack_method and 'edge' in \\\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/fed_runner.py\n# --------------------------------------------------\n#             self.cfg.defrost()\n#             self.cfg.federate.client_num = 1\n#             self.cfg.federate.sample_client_num = 1\n#             self.cfg.freeze()\n# \n#         # sample resource information\n#         if self.resource_info is not None:\n#             if len(self.resource_info) < self.cfg.federate.client_num + 1:\n#                 replace = True\n#                 logger.warning(\n#                     f\"Because the provided the number of resource information \"\n#                     f\"{len(self.resource_info)} is less than the number of \"\n#                     f\"participants {self.cfg.federate.client_num + 1}, one \"\n#                     f\"candidate might be selected multiple times.\")\n#             else:\n#                 replace = False\n#             sampled_index = np.random.choice(\n#                 list(self.resource_info.keys()),\n#                 size=self.cfg.federate.client_num + 1,\n#                 replace=replace)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/configs/cfg_asyn.py\n# --------------------------------------------------\n#        \"but {} is got\".format(\n#         type(cfg.asyn.time_budget))\n# \n#     # min received num pre-process\n#     min_received_num_valid = (0 < cfg.asyn.min_received_num <=\n#                               cfg.federate.sample_client_num)\n#     min_received_rate_valid = (0 < cfg.asyn.min_received_rate <= 1)\n#     # (a) sampling case\n#     if min_received_rate_valid:\n#         # (a.1) use min_received_rate\n#         old_min_received_num = cfg.asyn.min_received_num\n#         cfg.asyn.min_received_num = max(\n#             1,\n#             int(cfg.asyn.min_received_rate * cfg.federate.sample_client_num))\n#         if min_received_num_valid:\n#             logging.warning(\n#                 f\"Users specify both valid min_received_rate as\"\n#                 f\" {cfg.asyn.min_received_rate} \"\n#                 f\"and min_received_num as {old_min_received_num}.\\n\"\n#                 f\"\\t\\tWe will use the min_received_rate value to calculate \"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/configs/cfg_asyn.py\n# --------------------------------------------------\n#         old_min_received_num = cfg.asyn.min_received_num\n#         cfg.asyn.min_received_num = max(\n#             1,\n#             int(cfg.asyn.min_received_rate * cfg.federate.sample_client_num))\n#         if min_received_num_valid:\n#             logging.warning(\n#                 f\"Users specify both valid min_received_rate as\"\n#                 f\" {cfg.asyn.min_received_rate} \"\n#                 f\"and min_received_num as {old_min_received_num}.\\n\"\n#                 f\"\\t\\tWe will use the min_received_rate value to calculate \"\n#                 f\"the actual number of participated clients as\"\n#                 f\" {cfg.asyn.min_received_num}.\")\n#     # (a.2) use min_received_num, commented since the below two lines do not\n#     # change anything elif min_received_rate:\n#     #     cfg.asyn.min_received_num = cfg.asyn.min_received_num\n#     if not (min_received_num_valid or min_received_rate_valid):\n#         # (b) non-sampling case, use all clients\n#         cfg.asyn.min_received_num = cfg.federate.sample_client_num\n# \n#     # to ensure a valid staleness toleation\n# --------------------------------------------------\n\nimport logging\n\nfrom federatedscope.core.configs.config import CN\nfrom federatedscope.register import register_config\n\nlogger = logging.getLogger(__name__)\n\n\ndef extend_fl_setting_cfg(cfg):\n    # ---------------------------------------------------------------------- #\n    # Federate learning related options\n    # ---------------------------------------------------------------------- #\n    cfg.federate = CN()\n\n    cfg.federate.client_num = 0\n    cfg.federate.sample_client_num = -1\n    cfg.federate.sample_client_rate = -1.0\n    cfg.federate.unseen_clients_rate = 0.0\n    cfg.federate.total_round_num = 50\n    cfg.federate.mode = 'standalone'\n    cfg.federate.share_local_model = False\n    cfg.federate.data_weighted_aggr = False  # If True, the weight of aggr is\n    # the number of training samples in dataset.\n    cfg.federate.online_aggr = False\n    cfg.federate.make_global_eval = False\n    cfg.federate.use_diff = False\n    cfg.federate.merge_test_data = False  # For efficient simulation, users\n    # can choose to merge the test data and perform global evaluation,\n    # instead of perform test at each client\n\n    # the method name is used to internally determine composition of\n    # different aggregators, messages, handlers, etc.,\n    cfg.federate.method = \"FedAvg\"\n    cfg.federate.ignore_weight = False\n    cfg.federate.use_ss = False  # Whether to apply Secret Sharing\n    cfg.federate.restore_from = ''\n    cfg.federate.save_to = ''\n    cfg.federate.join_in_info = [\n    ]  # The information requirements (from server) for join_in\n    cfg.federate.sampler = 'uniform'  # the strategy for sampling client\n    # in each training round, ['uniform', 'group']\n    cfg.federate.resource_info_file = \"\"  # the device information file to\n    # record computation and communication ability\n\n    # atc (TODO: merge later)\n    cfg.federate.atc_vanilla = False\n    cfg.federate.atc_load_from = ''\n\n    # ---------------------------------------------------------------------- #\n    # Distribute training related options\n    # ---------------------------------------------------------------------- #\n    cfg.distribute = CN()\n\n    cfg.distribute.use = False\n    cfg.distribute.server_host = '0.0.0.0'\n    cfg.distribute.server_port = 50050\n    cfg.distribute.client_host = '0.0.0.0'\n    cfg.distribute.client_port = 50050\n    cfg.distribute.role = 'client'\n    cfg.distribute.data_file = 'data'\n    cfg.distribute.data_idx = -1  # data_idx is used to specify the data\n    # index in distributed mode when adopting a centralized dataset for\n    # simulation (formatted as {data_idx: data/dataloader}).\n    # data_idx = -1 means that the whole dataset is owned by the participant.\n    # when data_idx is other invalid values excepted for -1, we randomly\n    # sample the data_idx for simulation\n    cfg.distribute.grpc_max_send_message_length = 100 * 1024 * 1024\n    cfg.distribute.grpc_max_receive_message_length = 100 * 1024 * 1024\n    cfg.distribute.grpc_enable_http_proxy = False\n\n    # ---------------------------------------------------------------------- #\n    # Vertical FL related options (for demo)\n    # --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"-------------------- #\n    cfg.vertical = CN()\n    cfg.vertical.use = False\n    cfg.vertical.dims = [5, 10]  # TODO: we need to explain dims\n    cfg.vertical.encryption = 'paillier'\n    cfg.vertical.key_size = 3072\n    cfg.vertical.algo = 'lr'  # ['lr', 'xgb']\n    cfg.vertical.xgb_use_bin = False\n\n    # --------------- register corresponding check function ----------\n    cfg.register_cfg_check_fun(assert_fl_setting_cfg)\n\n\ndef assert_fl_setting_cfg(cfg):\n    assert cfg.federate.mode in [\"standalone\", \"distributed\"], \\\n        f\"Please specify the cfg.federate.mode as the string standalone or \" \\\n        f\"distributed. But got {cfg.federate.mode}.\"\n\n    # =============  client num related  ==============\n    assert not (cfg.federate.client_num == 0\n                and cfg.federate.mode == 'distributed'\n                ), \"Please configure the cfg.federate. in distributed mode. \"\n\n    assert 0 <= cfg.federate.unseen_clients_rate < 1, \\\n        \"You specified in-valid cfg.federate.unseen_clients_rate\"\n    if 0 < cfg.federate.unseen_clients_rate < 1 and cfg.federate.method in [\n            \"local\", \"global\"\n    ]:\n        logger.warning(\n            \"In local/global training mode, the unseen_clients_rate is \"\n            \"in-valid, plz check your config\")\n        unseen_clients_rate = 0.0\n        cfg.federate.unseen_clients_rate = unseen_clients_rate\n    else:\n        unseen_clients_rate = cfg.federate.unseen_clients_rate\n    participated_client_num = max(\n        1, int((1 - unseen_clients_rate) * cfg.federate.client_num))\n\n    # sample client num pre-process\n    sample_client_num_valid = (\n        0 < cfg.federate.sample_client_num <=\n        cfg.federate.client_num) and cfg.federate.client_num != 0\n    sample_client_rate_valid = (0 < cfg.federate.sample_client_rate <= 1)\n\n    sample_cfg_valid = sample_client_rate_valid or sample_client_num_valid", "completion": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/server.py\n# --------------------------------------------------\n#         # [ICLR'22, What Do We Mean by Generalization in Federated Learning?]\n#         self.unseen_clients_id = [] if unseen_clients_id is None \\\n#             else unseen_clients_id\n# \n#         # Server state\n#         self.is_finish = False\n# \n#         # Sampler\n#         if self._cfg.federate.sampler in ['uniform']:\n#             self.sampler = get_sampler(\n#                 sample_strategy=self._cfg.federate.sampler,\n#                 client_num=self.client_num,\n#                 client_info=None)\n#         else:\n#             # Some type of sampler would be instantiated in trigger_for_start,\n#             # since they need more information\n#             self.sampler = None\n# \n#         # Current Timestamp\n#         self.cur_timestamp = 0\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/workers/client.py\n# --------------------------------------------------\n#         # Otherwise, we set patience=0 to deactivate", "metadata": {"task_id": "alibaba_FederatedScope/81", "ground_truth": "    non_sample_case = cfg.federate.method in [\"local\", \"global\"]", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "configs", "cfg_fl_setting.py"], "context_start_lineno": 0, "line_no": 117, "query_window": {"context": "    if 0 < cfg.federate.unseen_clients_rate < 1 and cfg.federate.method in [\n            \"local\", \"global\"\n    ]:\n        logger.warning(\n            \"In local/global training mode, the unseen_clients_rate is \"\n            \"in-valid, plz check your config\")\n        unseen_clients_rate = 0.0\n        cfg.federate.unseen_clients_rate = unseen_clients_rate\n    else:\n        unseen_clients_rate = cfg.federate.unseen_clients_rate\n    participated_client_num = max(\n        1, int((1 - unseen_clients_rate) * cfg.federate.client_num))\n\n    # sample client num pre-process\n    sample_client_num_valid = (\n        0 < cfg.federate.sample_client_num <=\n        cfg.federate.client_num) and cfg.federate.client_num != 0\n    sample_client_rate_valid = (0 < cfg.federate.sample_client_rate <= 1)\n\n    sample_cfg_valid = sample_client_rate_valid or sample_client_num_valid", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "configs", "cfg_fl_setting.py"], "line_no": 117, "task_id": "alibaba_FederatedScope/81", "start_line_no": 97, "end_line_no": 117, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "       \"but {} is got\".format(\n        type(cfg.asyn.time_budget))\n\n    # min received num pre-process\n    min_received_num_valid = (0 < cfg.asyn.min_received_num <=\n                              cfg.federate.sample_client_num)\n    min_received_rate_valid = (0 < cfg.asyn.min_received_rate <= 1)\n    # (a) sampling case\n    if min_received_rate_valid:\n        # (a.1) use min_received_rate\n        old_min_received_num = cfg.asyn.min_received_num\n        cfg.asyn.min_received_num = max(\n            1,\n            int(cfg.asyn.min_received_rate * cfg.federate.sample_client_num))\n        if min_received_num_valid:\n            logging.warning(\n                f\"Users specify both valid min_received_rate as\"\n                f\" {cfg.asyn.min_received_rate} \"\n                f\"and min_received_num as {old_min_received_num}.\\n\"\n                f\"\\t\\tWe will use the min_received_rate value to calculate \"", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "configs", "cfg_asyn.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.36065573770491804}, {"context": "    cfg.register_cfg_check_fun(assert_asyn_cfg)\n\n\ndef assert_asyn_cfg(cfg):\n    if not cfg.asyn.use:\n        return True\n    # to ensure a valid time budget\n    assert isinstance(cfg.asyn.time_budget, int) or isinstance(\n        cfg.asyn.time_budget, float\n    ), \"The time budget (seconds) must be an int or a float value, \" \\\n       \"but {} is got\".format(\n        type(cfg.asyn.time_budget))\n\n    # min received num pre-process\n    min_received_num_valid = (0 < cfg.asyn.min_received_num <=\n                              cfg.federate.sample_client_num)\n    min_received_rate_valid = (0 < cfg.asyn.min_received_rate <= 1)\n    # (a) sampling case\n    if min_received_rate_valid:\n        # (a.1) use min_received_rate", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "configs", "cfg_asyn.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.30708661417322836}, {"context": "            import torch\n            torch.set_num_threads(1)\n\n        assert self.cfg.federate.client_num != 0, \\\n            \"In standalone mode, self.cfg.federate.client_num should be \" \\\n            \"non-zero. \" \\\n            \"This is usually cased by using synthetic data and users not \" \\\n            \"specify a non-zero value for client_num\"\n\n        if self.cfg.federate.method == \"global\":\n            self.cfg.defrost()\n            self.cfg.federate.client_num = 1\n            self.cfg.federate.sample_client_num = 1\n            self.cfg.freeze()\n\n        # sample resource information\n        if self.resource_info is not None:\n            if len(self.resource_info) < self.cfg.federate.client_num + 1:\n                replace = True\n                logger.warning(", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "fed_runner.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 310, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.30158730158730157}, {"context": "                all_data=datadict,\n                merged_max_data_id=self.global_cfg.federate.client_num,\n                specified_dataset_name=['test'])\n            # `0` indicate Server\n            datadict[0] = ClientData(self.global_cfg, **server_data)\n\n        if self.global_cfg.federate.method == \"global\":\n            if self.global_cfg.federate.client_num != 1:\n                if self.global_cfg.data.server_holds_all:\n                    assert datadict[0] is not None \\\n                        and len(datadict[0]) != 0, \\\n                        \"You specified cfg.data.server_holds_all=True \" \\\n                        \"but data[0] is None. Please check whether you \" \\\n                        \"pre-process the data[0] correctly\"\n                    datadict[1] = datadict[0]\n                else:\n                    logger.info(f\"Will merge data from clients whose ids in \"\n                                f\"[1, {self.global_cfg.federate.client_num}]\")\n                    merged_data = merge_data(\n                        all_data=datadict,", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "data", "base_data.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2777777777777778}, {"context": "                                   data=data,\n                                   device=device,\n                                   config=self._cfg,\n                                   is_attacker=self.is_attacker,\n                                   monitor=self._monitor)\n\n        # For client-side evaluation\n        self.best_results = dict()\n        self.history_results = dict()\n        # in local or global training mode, we do use the early stopper.\n        # Otherwise, we set patience=0 to deactivate the local early-stopper\n        patience = self._cfg.early_stop.patience if \\\n            self._cfg.federate.method in [\n                \"local\", \"global\"\n            ] else 0\n        self.early_stopper = EarlyStopper(\n            patience, self._cfg.early_stop.delta,\n            self._cfg.early_stop.improve_indicator_mode,\n            self._monitor.the_larger_the_better)\n", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "client.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.2740740740740741}, {"context": "        # Initialize the number of joined-in clients\n        self._client_num = client_num\n        self._total_round_num = total_round_num\n        self.sample_client_num = int(self._cfg.federate.sample_client_num)\n        self.join_in_client_num = 0\n        self.join_in_info = dict()\n        # the unseen clients indicate the ones that do not contribute to FL\n        # process by training on their local data and uploading their local\n        # model update. The splitting is useful to check participation\n        # generalization gap in\n        # [ICLR'22, What Do We Mean by Generalization in Federated Learning?]\n        self.unseen_clients_id = [] if unseen_clients_id is None \\\n            else unseen_clients_id\n\n        # Server state\n        self.is_finish = False\n\n        # Sampler\n        if self._cfg.federate.sampler in ['uniform']:\n            self.sampler = get_sampler(", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "workers", "server.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.25675675675675674}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/_utils_internal.py\n# --------------------------------------------------\n#     CARTPOLE_VERSIONED = \"CartPole-v0\"\n#     HALFCHEETAH_VERSIONED = \"HalfCheetah-v2\"\n#     PENDULUM_VERSIONED = \"Pendulum-v0\"\n#     PONG_VERSIONED = \"Pong-v4\"\n# \n# \n# @implement_for(\"gym\", \"0.21.0\", None)\n# def _set_gym_environments():  # noqa: F811\n#     global CARTPOLE_VERSIONED, HALFCHEETAH_VERSIONED, PENDULUM_VERSIONED, PONG_VERSIONED\n# \n#     CARTPOLE_VERSIONED = \"CartPole-v1\"\n#     HALFCHEETAH_VERSIONED = \"HalfCheetah-v4\"\n#     PENDULUM_VERSIONED = \"Pendulum-v1\"\n#     PONG_VERSIONED = \"ALE/Pong-v5\"\n# \n# \n# if _has_gym:\n#     _set_gym_environments()\n# \n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/_utils.py\n# --------------------------------------------------\n#         try:\n#             module = import_module(self.module_name)\n#         except ModuleNotFoundError:\n#             return unsupported\n# \n#         func_name = f\"{fn.__module__}.{fn.__name__}\"\n#         implementations = implement_for._implementations\n# \n#         # Return fitting implementation if it was encountered before.\n#         if func_name in implementations:\n#             return implementations[func_name]\n# \n#         version = module.__version__\n# \n#         if (self.from_version is None or version >= self.from_version) and (\n#             self.to_version is None or version < self.to_version\n#         ):\n#             implementations[func_name] = fn\n#             return fn\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#         self, kwargs, disable_env_checker: bool = None\n#     ) -> None:\n#         if disable_env_checker is not None:\n#             raise RuntimeError(\n#                 \"disable_env_checker should only be set if gym version is > 0.24\"\n#             )\n# \n#     @implement_for(\"gym\", \"0.24.0\", None)\n#     def _set_gym_args(  # noqa: F811\n#         self, kwargs, disable_env_checker: bool = None\n#     ) -> None:\n#         kwargs[\"disable_env_checker\"] = (\n#             disable_env_checker if disable_env_checker is not None else True\n#         )\n# \n#     def _build_env(\n#         self,\n#         env_name: str,\n#         **kwargs,\n#     ) -> \"gym.core.Env\":\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#         return seed\n# \n#     @implement_for(\"gym\", None, \"0.19.0\")\n#     def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n#         self._seed_calls_reset = False\n#         self._env.seed(seed=seed)\n# \n#     @implement_for(\"gym\", \"0.19.0\", None)\n#     def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n#         try:\n#             self.reset(seed=seed)\n#             self._seed_calls_reset = True\n#         except TypeError as err:\n#             warnings.warn(\n#                 f\"reset with seed kwarg returned an exception: {err}.\\n\"\n#                 f\"Calling env.seed from now on.\"\n#             )\n#             self._seed_calls_reset = False\n#             self._env.seed(seed=seed)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n# \n# @implement_for(\"gym\", \"0.26.0\", None)\n# def _get_gym_envs():  # noqa: F811\n#     return gym.envs.registration.registry.keys()\n# \n# \n# def _get_gym():\n#     if _has_gym:\n#         return gym\n#     else:\n#         return None\n# \n# \n# def _is_from_pixels(env):\n#     observation_spec = env.observation_space\n#     if isinstance(observation_spec, (Dict,)):\n#         if \"pixels\" in set(observation_spec.keys()):\n#             return True\n#     if isinstance(observation_spec, (gym.spaces.dict.Dict,)):\n#         if \"pixels\" in set(observation_spec.spaces.keys()):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#         return env\n# \n#     @implement_for(\"gym\", None, \"0.26.0\")\n#     def _build_gym_env(self, env, pixels_only):  # noqa: F811\n#         return PixelObservationWrapper(env, pixels_only=pixels_only)\n# \n#     @implement_for(\"gym\", \"0.26.0\", None)\n#     def _build_gym_env(self, env, pixels_only):  # noqa: F811\n#         from gym.wrappers.compatibility import EnvCompatibility\n# \n#         if env.render_mode:\n#             return PixelObservationWrapper(env, pixels_only=pixels_only)\n# \n#         warnings.warn(\n#             \"Environments provided to GymWrapper that need to be wrapped in PixelObservationWrapper \"\n#             \"should be created with `gym.make(env_name, render_mode=mode)` where possible,\"\n#             'where mode is either \"rgb_array\" or any other supported mode.'\n#         )\n#         # resetting as 0.26 comes with a very 'nice' OrderEnforcing wrapper\n#         env = EnvCompatibility(env)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/gym.py\n# --------------------------------------------------\n#             self.reset(seed=seed)\n#             self._seed_calls_reset = True\n#         except TypeError as err:\n#             warnings.warn(\n#                 f\"reset with seed kwarg returned an exception: {err}.\\n\"\n#                 f\"Calling env.seed from now on.\"\n#             )\n#             self._seed_calls_reset = False\n#             self._env.seed(seed=seed)\n# \n#     def _make_specs(self, env: \"gym.Env\") -> None:\n#         self.action_spec = _gym_to_torchrl_spec_transform(\n#             env.action_space,\n#             device=self.device,\n#             categorical_action_encoding=self._categorical_action_encoding,\n#         )\n#         observation_spec = _gym_to_torchrl_spec_transform(\n#             env.observation_space,\n#             device=self.device,\n#             categorical_action_encoding=self._categorical_action_encoding,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\n\nimport pytest\nfrom torchrl._utils import get_binary_env_var, implement_for\n\n\n@pytest.mark.parametrize(\"value\", [\"True\", \"1\", \"true\"])\ndef test_get_binary_env_var_positive(value):\n    try:\n        key = \"SOME_ENVIRONMENT_VARIABLE_UNLIKELY_TO_BE_IN_ENVIRONMENT\"\n\n        assert key not in os.environ\n\n        os.environ[key] = value\n        assert get_binary_env_var(key)\n\n    finally:\n        if key in os.environ:\n            del os.environ[key]\n\n\n@pytest.mark.parametrize(\"value\", [\"False\", \"0\", \"false\"])\ndef test_get_binary_env_var_negative(value):\n    try:\n        key = \"SOME_ENVIRONMENT_VARIABLE_UNLIKELY_TO_BE_IN_ENVIRONMENT\"\n\n        assert key not in os.environ\n\n        os.environ[key] = \"True\"\n        assert get_binary_env_var(key)\n        os.environ[key] = value\n        assert not get_binary_env_var(key)\n\n    finally:\n        if key in os.environ:\n            del os.environ[key]\n\n\ndef test_get_binary_env_var_missing():\n    try:\n        key = \"SOME_ENVIRONMENT_VARIABLE_UNLIKELY_TO_BE_IN_ENVIRONMENT\"\n\n        assert key not in os.environ\n        assert not get_binary_env_var(key)\n\n    finally:\n        if key in os.environ:\n            del os.environ[key]\n\n\ndef test_get_binary_env_var_wrong_value():\n    try:\n        key = \"SOME_ENVIRONMENT_VARIABLE_UNLIKELY_TO_BE_IN_ENVIRONMENT\"\n\n        assert key not in os.environ\n        os.environ[key] = \"smthwrong\"\n        with pytest.raises(ValueError):\n            get_binary_env_var(key)\n\n    finally:\n        if key in os.environ:\n            del os.environ[key]\n\n\nclass implement_for_test_functions:\n    \"\"\"\n    Groups functions that are used in tests for `implement_for` decorator.\n    \"\"\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.3\")\n    def select_correct_version():\n        \"\"\"To test from+ range and that this function is correctly selected as the implementation.\"\"\"\n        return \"0.3+\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.2\", \"0.3\")\n    def select_correct_version():  # noqa: F811\n        \"\"\"To test that right bound is not included.\"\"\"\n        return \"0.2-0.3\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.1\", \"0.2\")\n    def select_correct_version():  # noqa: F811\n        \"\"\"To test that function with missing from-to range is ignored.\"\"\"\n        return \"0.1-0.2\"\n\n    @staticmethod\n    @implement_for(\"missing_module\")\n    def missing_module():\n        \"\"\"To test that calling decorated function with missing module raises an exception.\"\"\"", "completion": "import gym\nfrom torchrl._utils import implement_for\n\n@implement_for(\"gym\", \"0.21.0\", None)\ndef _set_gym_environments():  # noqa: F811\n    global CARTPOLE_VERSIONED, HALFCHEETAH_VERSIONED, PENDULUM_VERSIONED, PONG_VERSIONED\n\n    CARTPOLE_VERSIONED = \"CartPole-v1\"\n    HALFCHEETAH_VERSIONED = \"HalfCheetah-v4\"\n    PENDULUM_VERSIONED = \"Pendulum-v1\"\n    PONG_VERSIONED = \"ALE/Pong-v5\"\n\n\nif _has_gym:\n    _set_gym_environments()\n\nclass GymWrapper:\n    def __init__(self, env_name: str, **kwargs):\n        self.env_name = env_name\n        self.kwargs = kwargs\n        self._build_env(env_name, **kwargs)\n\n    def _build_env(self, env_name: str, **kwargs):\n        env = gym.make(env_name, **kwargs)\n        self.env = self._build_gym_env(env, pixels_only=True)\n\n    @implement_for(\"gym\", \"0.26.0\", None)\n    def _", "metadata": {"task_id": "pytorch_rl/79", "ground_truth": "        return \"missing\"", "fpath_tuple": ["pytorch_rl", "test", "test_utils.py"], "context_start_lineno": 0, "line_no": 96, "query_window": {"context": "    def select_correct_version():\n        \"\"\"To test from+ range and that this function is correctly selected as the implementation.\"\"\"\n        return \"0.3+\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.2\", \"0.3\")\n    def select_correct_version():  # noqa: F811\n        \"\"\"To test that right bound is not included.\"\"\"\n        return \"0.2-0.3\"\n\n    @staticmethod\n    @implement_for(\"_utils_internal\", \"0.1\", \"0.2\")\n    def select_correct_version():  # noqa: F811\n        \"\"\"To test that function with missing from-to range is ignored.\"\"\"\n        return \"0.1-0.2\"\n\n    @staticmethod\n    @implement_for(\"missing_module\")\n    def missing_module():\n        \"\"\"To test that calling decorated function with missing module raises an exception.\"\"\"", "metadata": {"fpath_tuple": ["pytorch_rl", "test", "test_utils.py"], "line_no": 96, "task_id": "pytorch_rl/79", "start_line_no": 76, "end_line_no": 96, "window_size": 20, "context_start_lineno": 0, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "        return seed\n\n    @implement_for(\"gym\", None, \"0.19.0\")\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        self._seed_calls_reset = False\n        self._env.seed(seed=seed)\n\n    @implement_for(\"gym\", \"0.19.0\", None)\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        try:\n            self.reset(seed=seed)\n            self._seed_calls_reset = True\n        except TypeError as err:\n            warnings.warn(\n                f\"reset with seed kwarg returned an exception: {err}.\\n\"\n                f\"Calling env.seed from now on.\"\n            )\n            self._seed_calls_reset = False\n            self._env.seed(seed=seed)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2644628099173554}, {"context": "        from_pixels = from_pixels or env_from_pixels\n        self.from_pixels = from_pixels\n        self.pixels_only = pixels_only\n        if from_pixels and not env_from_pixels:\n            if isinstance(env, PixelObservationWrapper):\n                raise TypeError(\n                    \"PixelObservationWrapper cannot be used to wrap an environment\"\n                    \"that is already a PixelObservationWrapper instance.\"\n                )\n            env = self._build_gym_env(env, pixels_only)\n        return env\n\n    @implement_for(\"gym\", None, \"0.26.0\")\n    def _build_gym_env(self, env, pixels_only):  # noqa: F811\n        return PixelObservationWrapper(env, pixels_only=pixels_only)\n\n    @implement_for(\"gym\", \"0.26.0\", None)\n    def _build_gym_env(self, env, pixels_only):  # noqa: F811\n        from gym.wrappers.compatibility import EnvCompatibility\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.24806201550387597}, {"context": "    envs = _get_gym_envs()\n    envs = list(envs)\n    envs = sorted(envs)\n    return envs\n\n\n@implement_for(\"gym\", None, \"0.26.0\")\ndef _get_gym_envs():  # noqa: F811\n    return gym.envs.registration.registry.env_specs.keys()\n\n\n@implement_for(\"gym\", \"0.26.0\", None)\ndef _get_gym_envs():  # noqa: F811\n    return gym.envs.registration.registry.keys()\n\n\ndef _get_gym():\n    if _has_gym:\n        return gym\n    else:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2376237623762376}, {"context": "\n    def _set_seed(self, seed: int) -> int:  # noqa: F811\n        if self._seed_calls_reset is None:\n            # Determine basing on gym version whether `reset` is called when setting seed.\n            self._set_seed_initial(seed)\n        elif self._seed_calls_reset:\n            self.reset(seed=seed)\n        else:\n            self._env.seed(seed=seed)\n\n        return seed\n\n    @implement_for(\"gym\", None, \"0.19.0\")\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        self._seed_calls_reset = False\n        self._env.seed(seed=seed)\n\n    @implement_for(\"gym\", \"0.19.0\", None)\n    def _set_seed_initial(self, seed: int) -> None:  # noqa: F811\n        try:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.22608695652173913}, {"context": "\n    \"\"\"\n\n    def __init__(self, env_name, disable_env_checker=None, **kwargs):\n        kwargs[\"env_name\"] = env_name\n        self._set_gym_args(kwargs, disable_env_checker)\n        super().__init__(**kwargs)\n\n    @implement_for(\"gym\", None, \"0.24.0\")\n    def _set_gym_args(  # noqa: F811\n        self, kwargs, disable_env_checker: bool = None\n    ) -> None:\n        if disable_env_checker is not None:\n            raise RuntimeError(\n                \"disable_env_checker should only be set if gym version is > 0.24\"\n            )\n\n    @implement_for(\"gym\", \"0.24.0\", None)\n    def _set_gym_args(  # noqa: F811\n        self, kwargs, disable_env_checker: bool = None", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "gym.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.224}, {"context": "        self.to_version = to_version\n\n    def __call__(self, fn):\n        @wraps(fn)\n        def unsupported():\n            raise ModuleNotFoundError(\n                f\"Supported version of '{self.module_name}' has not been found.\"\n            )\n\n        # If the module is missing replace the function with the mock.\n        try:\n            module = import_module(self.module_name)\n        except ModuleNotFoundError:\n            return unsupported\n\n        func_name = f\"{fn.__module__}.{fn.__name__}\"\n        implementations = implement_for._implementations\n\n        # Return fitting implementation if it was encountered before.\n        if func_name in implementations:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "_utils.py"], "line_no": 220, "start_line_no": 210, "end_line_no": 230, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21705426356589147}, {"context": "CARTPOLE_VERSIONED = \"CartPole-v1\"\nHALFCHEETAH_VERSIONED = \"HalfCheetah-v4\"\nPENDULUM_VERSIONED = \"Pendulum-v1\"\nPONG_VERSIONED = \"ALE/Pong-v5\"\n\n\n@implement_for(\"gym\", None, \"0.21.0\")\ndef _set_gym_environments():  # noqa: F811\n    global CARTPOLE_VERSIONED, HALFCHEETAH_VERSIONED, PENDULUM_VERSIONED, PONG_VERSIONED\n\n    CARTPOLE_VERSIONED = \"CartPole-v0\"\n    HALFCHEETAH_VERSIONED = \"HalfCheetah-v2\"\n    PENDULUM_VERSIONED = \"Pendulum-v0\"\n    PONG_VERSIONED = \"Pong-v4\"\n\n\n@implement_for(\"gym\", \"0.21.0\", None)\ndef _set_gym_environments():  # noqa: F811\n    global CARTPOLE_VERSIONED, HALFCHEETAH_VERSIONED, PENDULUM_VERSIONED, PONG_VERSIONED\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "_utils_internal.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.21487603305785125}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/jumanji.py\n# --------------------------------------------------\n#         tensordict_out.set(\"done\", done)\n#         tensordict_out[\"state\"] = state_dict\n# \n#         return tensordict_out\n# \n# \n# class JumanjiEnv(JumanjiWrapper):\n#     \"\"\"Jumanji environment wrapper.\n# \n#     Examples:\n#         >>> env = JumanjiEnv(env_name=\"Snake-6x6-v0\", frame_skip=4)\n#         >>> td = env.rand_step()\n#         >>> print(td)\n#         >>> print(env.available_envs)\n#     \"\"\"\n# \n#     def __init__(self, env_name, **kwargs):\n#         kwargs[\"env_name\"] = env_name\n#         super().__init__(**kwargs)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n# \n#     def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n#         step_count = tensordict.get(\n#             \"step_count\",\n#             torch.zeros(\n#                 tensordict.batch_size,\n#                 dtype=torch.int64,\n#                 device=tensordict.device,\n#             ),\n#         )\n#         next_step_count = step_count + 1\n#         tensordict.set(\"step_count\", next_step_count)\n#         if self.max_steps is not None:\n#             done = tensordict.get(\"done\")\n#             done = done | (next_step_count >= self.max_steps).unsqueeze(-1)\n#             tensordict.set(\"done\", done)\n#         return tensordict\n# \n#     def transform_observation_spec(\n#         self, observation_spec: CompositeSpec\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#     ) -> TensorDictBase:\n#         tensordict = tensordict.to(self.device)\n#         a = tensordict.get(\"action\")\n# \n#         if not self.categorical_action_encoding:\n#             assert (a.sum(-1) == 1).all()\n# \n#         obs = self._get_in_obs(tensordict.get(self._out_key)) + a / self.maxstep\n#         tensordict = tensordict.select()  # empty tensordict\n# \n#         tensordict.set(self.out_key, self._get_out_obs(obs))\n#         tensordict.set(self._out_key, self._get_out_obs(obs))\n# \n#         done = torch.isclose(obs, torch.ones_like(obs) * (self.counter + 1))\n#         reward = done.any(-1).unsqueeze(-1)\n#         # set done to False\n#         done = torch.zeros_like(done).all(-1).unsqueeze(-1)\n#         tensordict.set(\"reward\", reward.to(torch.get_default_dtype()))\n#         tensordict.set(\"done\", done)\n#         return tensordict\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#         tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n#         return tensordict\n# \n#     def _step(\n#         self,\n#         tensordict: TensorDictBase,\n#     ) -> TensorDictBase:\n#         self.step_count += 1\n#         tensordict = tensordict.to(self.device)\n#         a = tensordict.get(\"action\")\n# \n#         obs = self._obs_step(self._get_in_obs(tensordict.get(self._out_key)), a)\n#         tensordict = tensordict.select()  # empty tensordict\n# \n#         tensordict.set(self.out_key, self._get_out_obs(obs))\n#         tensordict.set(self._out_key, self._get_out_obs(obs))\n# \n#         done = torch.isclose(obs, torch.ones_like(obs) * (self.counter + 1))\n#         while done.shape != tensordict.shape:\n#             done = done.any(-1)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/jumanji.py\n# --------------------------------------------------\n#         tensordict_out.set(\"done\", done)\n#         tensordict_out[\"state\"] = state_dict\n# \n#         return tensordict_out\n# \n#     def _reset(\n#         self, tensordict: Optional[TensorDictBase] = None, **kwargs\n#     ) -> TensorDictBase:\n# \n#         # generate random keys\n#         self.key, *keys = jax.random.split(self.key, self.numel() + 1)\n# \n#         # jax vectorizing map on env.reset\n#         state, timestep = jax.vmap(self._env.reset)(jnp.stack(keys))\n# \n#         # reshape batch size from vector\n#         state = _tree_reshape(state, self.batch_size)\n#         timestep = _tree_reshape(timestep, self.batch_size)\n# \n#         # collect outputs\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#         if tensordict is None:\n#             tensordict = TensorDict({}, self.batch_size, device=self.device)\n#         tensordict = tensordict.select().set(self.out_key, self._get_out_obs(state))\n#         tensordict = tensordict.set(self._out_key, self._get_out_obs(state))\n#         tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n#         return tensordict\n# \n#     def _step(\n#         self,\n#         tensordict: TensorDictBase,\n#     ) -> TensorDictBase:\n#         tensordict = tensordict.to(self.device)\n#         a = tensordict.get(\"action\")\n# \n#         if not self.categorical_action_encoding:\n#             assert (a.sum(-1) == 1).all()\n# \n#         obs = self._get_in_obs(tensordict.get(self._out_key)) + a / self.maxstep\n#         tensordict = tensordict.select()  # empty tensordict\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n        >>> reader = default_info_dict_reader([\"my_info_key\"])\n        >>> # assuming \"some_env-v0\" returns a dict with a key \"my_info_key\"\n        >>> env = GymWrapper(gym.make(\"some_env-v0\"))\n        >>> env.set_info_dict_reader(info_dict_reader=reader)\n        >>> tensordict = env.reset()\n        >>> tensordict = env.rand_step(tensordict)\n        >>> assert \"my_info_key\" in tensordict.keys()\n\n    \"\"\"\n\n    def __init__(\n        self,\n        keys: List[str] = None,\n        spec: Union[Sequence[TensorSpec], Dict[str, TensorSpec]] = None,\n    ):\n        if keys is None:\n            keys = []\n        self.keys = keys\n\n        if isinstance(spec, Sequence):\n            if len(spec) != len(self.keys):\n                raise ValueError(\n                    \"If specifying specs for info keys with a sequence, the \"\n                    \"length of the sequence must match the number of keys\"\n                )\n            self._info_spec = dict(zip(self.keys, spec))\n        else:\n            if spec is None:\n                spec = {}\n\n            self._info_spec = {\n                key: spec.get(key, UnboundedContinuousTensorSpec()) for key in self.keys\n            }\n\n    def __call__(\n        self, info_dict: Dict[str, Any], tensordict: TensorDictBase\n    ) -> TensorDictBase:\n        if not isinstance(info_dict, dict) and len(self.keys):\n            warnings.warn(\n                f\"Found an info_dict of type {type(info_dict)} \"\n                f\"but expected type or subtype `dict`.\"\n            )\n        for key in self.keys:\n            if key in info_dict:\n                tensordict[key] = info_dict[key]\n        return tensordict\n\n    @property\n    def info_spec(self) -> Dict[str, TensorSpec]:\n        return self._info_spec\n\n\nclass GymLikeEnv(_EnvWrapper):\n    \"\"\"A gym-like env is an environment.\n\n    Its behaviour is similar to gym environments in what common methods (specifically reset and step) are expected to do.\n\n    A :obj:`GymLikeEnv` has a :obj:`.step()` method with the following signature:\n\n        ``env.step(action: np.ndarray) -> Tuple[Union[np.ndarray, dict], double, bool, *info]``\n\n    where the outputs are the observation, reward and done state respectively.\n    In this implementation, the info output is discarded (but specific keys can be read\n    by updating info_dict_reader, see :obj:`set_info_dict_reader` class method).\n\n    By default, the first output is written at the \"observation\" key-value pair in the output tensordict, unless\n    the first output is a dictionary. In that case, each observation output will be put at the corresponding\n    :obj:`f\"{key}\"` location for each :obj:`f\"{key}\"` of the dictionary.\n\n    It is also expected that env.reset() returns an observation similar to the one observed after a step is completed.\n    \"\"\"\n\n    _info_dict_reader: BaseInfoDictReader\n\n    @classmethod\n    def __new__(cls, *args, **kwargs):\n        cls._info_dict_reader = None\n        return super().__new__(cls, *args, _batch_locked=True, **kwargs)\n\n    def read_action(self, action):\n        \"\"\"Reads the action obtained from the input TensorDict and transforms it in the format expected by the contained environment.\n\n        Args:\n            action (Tensor or TensorDict): an action to be taken in the environment\n\n        Returns: an action in a format compatible with the contained environment.\n\n        \"\"\"\n        return self.action_spec.to_numpy(action, safe=False)\n\n    def read_done(self, done):\n        \"\"\"Done state reader.\n\n        Reads a done state and returns a tuple containing:\n        - a done state to be set in the environment\n        - a boolean value indicating whether the frame_skip loop should be broken\n\n        Args:\n            done (np.ndarray, boolean or other format): done state obtained from the environment\n\n        \"\"\"\n        return done, done\n\n    def read_reward(self, total_reward, step_reward):\n        \"\"\"Reads a reward and the total reward so far (in the frame skip loop) and returns a sum of the two.\n\n        Args:\n            total_reward (torch.Tensor or TensorDict): total reward so far in the step\n            step_reward (reward in the format provided by the inner env): reward of this particular step\n\n        \"\"\"\n        return total_reward + self.reward_spec.encode(step_reward)\n\n    def read_obs(\n        self, observations: Union[Dict[str, Any], torch.Tensor, np.ndarray]\n    ) -> Dict[str, Any]:\n        \"\"\"Reads an observation from the environment and returns an observation compatible with the output TensorDict.\n\n        Args:\n            observations (observation under a format dictated by the inner env): observation to be read.\n\n        \"\"\"\n        if isinstance(observations, dict):\n            observations = {key: value for key, value in observations.items()}\n        if not isinstance(observations, (TensorDict, dict)):\n            (key,) = itertools.islice(self.observation_spec.keys(), 1)\n            observations = {key: observations}\n        observations = self.observation_spec.encode(observations)\n        return observations\n\n    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n        action = tensordict.get(\"action\")\n        action_np = self.read_action(action)\n\n        reward = self.reward_spec.zero()\n        for _ in range(self.wrapper_frame_skip):\n            obs, _reward, done, *info = self._output_transform(\n                self._env.step(action_np)\n            )\n            if isinstance(obs, list) and len(obs) == 1:\n                # Until gym 0.25.2 we had rendered frames returned in lists of length 1\n                obs = obs[0]\n            if len(info) == 2:\n                # gym 0.26\n                truncation, info = info\n            elif len(info) == 1:\n                info = info[0]\n            elif len(info) == 0:\n                info = None\n            else:\n                raise ValueError(\n                    \"the environment output is expected to be either\"\n                    \"obs, reward, done, truncation, info (gym >= 0.26) or \"\n                    f\"obs, reward, done, info. Got info with types = ({[type(x) for x in info]})\"\n                )\n\n            if _reward is None:\n                _reward = self.reward_spec.zero()\n\n            reward = self.read_reward(reward, _reward)\n\n            if isinstance(done, bool) or (\n                isinstance(done, np.ndarray) and not len(done)\n            ):\n                done = torch.tensor([done], device=self.device)\n\n            done, do_break = self.read_done(done)\n            if do_break:\n                break\n\n        obs_dict = self.read_obs(obs)\n\n        if reward is None:\n            reward = np.nan\n        reward = self._to_tensor(reward, dtype=self.reward_spec.dtype)\n        done = self._to_tensor(done, dtype=torch.bool)\n\n        tensordict_out = TensorDict(\n            obs_dict, batch_size=tensordict.batch_size, device=self.device\n        )\n\n        tensordict_out.set(\"reward\", reward)\n        tensordict_out.set(\"done\", done)\n        if self.info_dict_reader is not None and info is not None:\n            self.info_dict_reader(info, tensordict_out)\n\n        return tensordict_out\n\n    def _reset(", "completion": "self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:\n        obs = self._env.reset(**kwargs)\n        obs_dict = self.read_obs(obs)\n\n        tensordict_out = TensorDict(\n            obs_dict, batch_size=tensordict.batch_size, device=self.device\n        )\n\n        tensordict_out.set(\"reward\", self.reward_spec.zero())\n        tensordict_out.set(\"done\", torch.zeros(tensordict.batch_size, dtype=torch.bool))\n        if self.info_dict_reader is not None:\n            self.info_dict_reader({}, tensordict_out)\n\n        return tensordict_out\n\n    def set_info_dict_reader(self, info_dict_reader: BaseInfoDictReader):\n        \"\"\"Sets the info_dict_reader.\n\n        Args:\n            info_dict_reader (BaseInfoDictReader): an instance of a class that reads info_dict and updates the output TensorDict accordingly.\n\n        \"\"\"\n        self.info_dict_reader = info_dict_reader\n\n    @property\n    def info_spec(self) -> Dict[str, TensorSpec]:\n        \"\"\"Returns the info_spec.\n\n        Returns:\n            Dict[str, TensorSpec]: a dictionary containing the spec for each info key.\n\n        \"\"\"\n       ", "metadata": {"task_id": "pytorch_rl/101", "ground_truth": "        self, tensordict: Optional[TensorDictBase] = None, **kwargs", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "context_start_lineno": 45, "line_no": 234, "query_window": {"context": "\n        obs_dict = self.read_obs(obs)\n\n        if reward is None:\n            reward = np.nan\n        reward = self._to_tensor(reward, dtype=self.reward_spec.dtype)\n        done = self._to_tensor(done, dtype=torch.bool)\n\n        tensordict_out = TensorDict(\n            obs_dict, batch_size=tensordict.batch_size, device=self.device\n        )\n\n        tensordict_out.set(\"reward\", reward)\n        tensordict_out.set(\"done\", done)\n        if self.info_dict_reader is not None and info is not None:\n            self.info_dict_reader(info, tensordict_out)\n\n        return tensordict_out\n\n    def _reset(", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 234, "task_id": "pytorch_rl/101", "start_line_no": 214, "end_line_no": 234, "window_size": 20, "context_start_lineno": 45, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "\n    def _get_in_obs(self, obs):\n        return obs\n\n    def _get_out_obs(self, obs):\n        return obs\n\n    def _reset(self, tensordict: TensorDictBase = None) -> TensorDictBase:\n        self.counter += 1\n        state = torch.zeros(self.size) + self.counter\n        if tensordict is None:\n            tensordict = TensorDict({}, self.batch_size, device=self.device)\n        tensordict = tensordict.select().set(self.out_key, self._get_out_obs(state))\n        tensordict = tensordict.set(self._out_key, self._get_out_obs(state))\n        tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n        return tensordict\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5340909090909091}, {"context": "        done = timestep.step_type == self.lib.types.StepType.LAST\n        done = _ndarray_to_tensor(done).view(torch.bool).to(self.device)\n\n        # build results\n        tensordict_out = TensorDict(\n            source=obs_dict,\n            batch_size=tensordict.batch_size,\n            device=self.device,\n        )\n        tensordict_out.set(\"reward\", reward)\n        tensordict_out.set(\"done\", done)\n        tensordict_out[\"state\"] = state_dict\n\n        return tensordict_out\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:\n\n        # generate random keys", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "jumanji.py"], "line_no": 280, "start_line_no": 270, "end_line_no": 290, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5}, {"context": "    def _reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n        self.counter += 1\n        self.step_count = 0\n        # state = torch.zeros(self.size) + self.counter\n        if tensordict is None:\n            tensordict = TensorDict({}, self.batch_size, device=self.device)\n        tensordict = tensordict.select()\n        tensordict.update(self.observation_spec.rand())\n        # tensordict.set(\"next_\" + self.out_key, self._get_out_obs(state))\n        # tensordict.set(\"next_\" + self._out_key, self._get_out_obs(state))\n        tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n        return tensordict\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,\n    ) -> TensorDictBase:\n        self.step_count += 1\n        tensordict = tensordict.to(self.device)\n        a = tensordict.get(\"action\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 490, "start_line_no": 480, "end_line_no": 500, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.49}, {"context": "        if tensordict is None:\n            tensordict = TensorDict({}, self.batch_size, device=self.device)\n        tensordict = tensordict.select().set(self.out_key, self._get_out_obs(state))\n        tensordict = tensordict.set(self._out_key, self._get_out_obs(state))\n        tensordict.set(\"done\", torch.zeros(*tensordict.shape, 1, dtype=torch.bool))\n        return tensordict\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,\n    ) -> TensorDictBase:\n        tensordict = tensordict.to(self.device)\n        a = tensordict.get(\"action\")\n\n        if not self.categorical_action_encoding:\n            assert (a.sum(-1) == 1).all()\n\n        obs = self._get_in_obs(tensordict.get(self._out_key)) + a / self.maxstep\n        tensordict = tensordict.select()  # empty tensordict\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 400, "start_line_no": 390, "end_line_no": 410, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45794392523364486}, {"context": "                dtype=torch.int64,\n                device=tensordict.device,\n            ),\n        )\n        step_count[_reset] = 0\n        tensordict.set(\n            \"step_count\",\n            step_count,\n        )\n        return tensordict\n\n    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n        step_count = tensordict.get(\n            \"step_count\",\n            torch.zeros(\n                tensordict.batch_size,\n                dtype=torch.int64,\n                device=tensordict.device,\n            ),\n        )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 2710, "start_line_no": 2700, "end_line_no": 2720, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.45121951219512196}, {"context": "        state_dict = self.read_state(state)\n        obs_dict = self.read_obs(timestep.observation)\n        done = torch.zeros(self.batch_size, dtype=torch.bool)\n\n        # build results\n        tensordict_out = TensorDict(\n            source=obs_dict,\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n        tensordict_out.set(\"done\", done)\n        tensordict_out[\"state\"] = state_dict\n\n        return tensordict_out\n\n\nclass JumanjiEnv(JumanjiWrapper):\n    \"\"\"Jumanji environment wrapper.\n\n    Examples:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "jumanji.py"], "line_no": 310, "start_line_no": 300, "end_line_no": 320, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4479166666666667}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/preprocess/instance_norm.py\n# --------------------------------------------------\n#     worker.register_handlers(\n#         'ss_instance_sum_norm_square',\n#         worker.callback_func_for_ss_instance_sum_norm_square)\n#     return worker\n# \n# \n# def wrap_instance_norm_client(worker):\n#     \"\"\"\n#     This function is to perform instance norm vfl tabular data for client.\n#     Args:\n#         worker: ``federatedscope.core.workers.Worker`` to be wrapped\n# \n#     Returns:\n#         Wrap vfl client with instance norm.\n#     \"\"\"\n#     def callback_func_for_ask_for_instance_sum(self, message: Message):\n#         self.ss_manager = AdditiveSecretSharing(\n#             shared_party_num=int(self._cfg.federate.client_num))\n#         self.msg_buffer['ss_instance_sum'] = {}\n#         content = {}\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/selection/correlation_filter.py\n# --------------------------------------------------\n#         callback_funcs_for_encrypted_norm_feat, worker)\n#     worker.callbacks_funcs_for_feat_corrcoef = types.MethodType(\n#         callbacks_funcs_for_feat_corrcoef, worker)\n#     worker.callback_funcs_for_vertical_dims = types.MethodType(\n#         callback_funcs_for_vertical_dims, worker)\n# \n#     # Register handlers functions\n#     worker.register_handlers('feat_engr_public_keys',\n#                              worker.callback_funcs_for_feat_engr_public_keys)\n#     worker.register_handlers(\n#         'ask_for_encrypted_norm_feat',\n#         worker.callback_funcs_for_ask_for_encrypted_norm_feat)\n#     worker.register_handlers('encrypted_norm_feat',\n#                              worker.callback_funcs_for_encrypted_norm_feat)\n#     worker.register_handlers('feat_corrcoef',\n#                              worker.callbacks_funcs_for_feat_corrcoef)\n#     worker.register_handlers('vertical_dims',\n#                              worker.callback_funcs_for_vertical_dims)\n# \n#     return worker\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/xgb_base/worker/train_wrapper.py\n# --------------------------------------------------\n#     client.train = types.MethodType(train, client)\n#     client.callback_func_for_split = types.MethodType(callback_func_for_split,\n#                                                       client)\n#     client.callback_funcs_for_continue_training = types.MethodType(\n#         callback_funcs_for_continue_training, client)\n#     client._find_and_send_split = types.MethodType(_find_and_send_split,\n#                                                    client)\n#     client._check_eval_finish = types.MethodType(_check_eval_finish, client)\n# \n#     # Register handler functions\n#     client.register_handlers('split', client.callback_func_for_split)\n#     client.register_handlers('continue_training',\n#                              client.callback_funcs_for_continue_training)\n# \n#     return client\n# \n# \n# def wrap_server_for_train(server):\n# \n#     return server\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/selection/iv_filter.py\n# --------------------------------------------------\n#     worker.callback_funcs_for_binning = types.MethodType(\n#         callback_funcs_for_binning, worker)\n#     worker.callback_func_for_en_y = types.MethodType(callback_func_for_en_y,\n#                                                      worker)\n#     worker.callback_func_for_sum_en_y = types.MethodType(\n#         callback_func_for_sum_en_y, worker)\n#     worker.callback_func_for_iv_list = types.MethodType(\n#         callback_func_for_iv_list, worker)\n#     worker.callback_funcs_for_vertical_dims = types.MethodType(\n#         callback_funcs_for_vertical_dims, worker)\n# \n#     # Register handlers functions\n#     worker.register_handlers('binning', worker.callback_funcs_for_binning)\n#     worker.register_handlers('en_y', worker.callback_func_for_en_y)\n#     worker.register_handlers('sum_en_y', worker.callback_func_for_sum_en_y)\n#     worker.register_handlers('iv_list', worker.callback_func_for_iv_list)\n#     worker.register_handlers('vertical_dims',\n#                              worker.callback_funcs_for_vertical_dims)\n# \n#     return worker\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/core/feature/vfl/preprocess/instance_norm.py\n# --------------------------------------------------\n#     worker.callback_func_for_instance_mean = types.MethodType(\n#         callback_func_for_instance_mean, worker)\n#     worker.callback_func_for_ss_instance_sum_norm_square = types.MethodType(\n#         callback_func_for_ss_instance_sum_norm_square, worker)\n#     worker.callback_func_for_instance_var = types.MethodType(\n#         callback_func_for_instance_var, worker)\n# \n#     # Register handlers functions\n#     worker.register_handlers('ask_for_instance_sum',\n#                              worker.callback_func_for_ask_for_instance_sum)\n#     worker.register_handlers('ss_instance_sum',\n#                              worker.callback_func_ss_instance_sum)\n#     worker.register_handlers('instance_mean',\n#                              worker.callback_func_for_instance_mean)\n#     worker.register_handlers(\n#         'ss_instance_sum_norm_square',\n#         worker.callback_func_for_ss_instance_sum_norm_square)\n#     worker.register_handlers('instance_var',\n#                              worker.callback_func_for_instance_var)\n#     return worker\n# --------------------------------------------------\n# the below code fragment can be found in:\n# federatedscope/vertical_fl/xgb_base/worker/train_wrapper.py\n# --------------------------------------------------\n#     client.train = types.MethodType(train, client)\n#     client.callback_func_for_split = types.MethodType(callback_func_for_split,\n#                                                       client)\n#     client.callback_funcs_for_continue_training = types.MethodType(\n#         callback_funcs_for_continue_training, client)\n#     client._find_and_send_split = types.MethodType(_find_and_send_split,\n#                                                    client)\n#     client._check_eval_finish = types.MethodType(_check_eval_finish, client)\n# \n#     # Register handler functions\n#     client.register_handlers('split', client.callback_func_for_split)\n#     client.register_handlers('continue_training',\n#                              client.callback_funcs_for_continue_training)\n# \n#     return client\n# \n# \n# def wrap_server_for_train(server):\n# \n#     return server\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport types\nimport logging\nimport numpy as np\n\nfrom federatedscope.vertical_fl.loss.utils import get_vertical_loss\nfrom federatedscope.core.message import Message\n\nlogger = logging.getLogger(__name__)\n\n\ndef wrap_client_for_evaluation(client):\n    def eval(self, tree_num):\n        self.criterion = get_vertical_loss(self._cfg.criterion.type)\n        if self.test_x is None:\n            self.test_x, self.test_y = self._fetch_test_data()\n            self.test_result = np.zeros(self.test_x.shape[0])\n        self.model[tree_num][0].indicator = np.ones(self.test_x.shape[0])\n        self._test_for_node(tree_num, node_num=0)\n\n    def _fetch_test_data(self):\n        test_x = self.data['test']['x']\n        test_y = self.data['test']['y'] if 'y' in self.data['test'] else None\n\n        return test_x, test_y\n\n    def _feedback_eval_metrics(self):\n        test_loss = self.criterion.get_loss(self.test_y, self.test_result)\n        metrics = self.criterion.get_metric(self.test_y, self.test_result)\n        modified_metrics = dict()\n        for key in metrics.keys():\n            if 'test' not in key:\n                modified_metrics['test_' + key] = metrics[key]\n            else:\n                modified_metrics[key] = metrics[key]\n        modified_metrics.update({\n            'test_loss': test_loss,\n            'test_total': len(self.test_y)\n        })\n\n        self.comm_manager.send(\n            Message(msg_type='eval_metric',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[self.server_id],\n                    content=modified_metrics))\n        self.comm_manager.send(\n            Message(msg_type='feature_importance',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[self.server_id],\n                    content=self.feature_importance))\n        self.comm_manager.send(\n            Message(msg_type='ask_for_feature_importance',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[\n                        each\n                        for each in list(self.comm_manager.neighbors.keys())\n                        if each != self.server_id\n                    ],\n                    content='None'))\n\n    def _test_for_node(self, tree_num, node_num):\n        # All nodes have been traversed\n        if node_num >= 2**self.model.max_depth - 1:\n            if (\n                    tree_num + 1\n            ) % self._cfg.eval.freq == 0 or \\\n                    tree_num + 1 == self._cfg.model.num_of_trees:\n                self._feedback_eval_metrics()\n            self.eval_finish_flag = True\n            self._check_eval_finish(tree_num)\n        # The client owns the weight\n        elif self.model[tree_num][node_num].weight:\n            self.test_result += self.model[tree_num][\n                node_num].indicator * self.model[tree_num][\n                    node_num].weight * self._cfg.train.optimizer.eta\n            self._test_for_node(tree_num, node_num + 1)\n        # Other client owns the weight, need to communicate\n        elif self.model[tree_num][node_num].member:\n            self.comm_manager.send(\n                Message(msg_type='split_request',\n                        sender=self.ID,\n                        state=self.state,\n                        receiver=[self.model[tree_num][node_num].member],\n                        content=(tree_num, node_num)))\n        else:\n            self._test_for_node(tree_num, node_num + 1)\n\n    def callback_func_for_split_request(self, message: Message):\n        if self.test_x is None:\n            self.test_x, self.test_y = self._fetch_test_data()\n            self.test_result = np.zeros(self.test_x.shape[0])\n        tree_num, node_num = message.content\n        sender = message.sender\n        feature_idx = self.model[tree_num][node_num].feature_idx\n        feature_value = self.model[tree_num][node_num].feature_value\n        left_child, right_child = self.model[tree_num].split_childern(\n            self.test_x[:, feature_idx], feature_value)\n        self.comm_manager.send(\n            Message(msg_type='split_result',\n                    sender=self.ID,\n                    state=self.state,\n                    receiver=[sender],\n                    content=(tree_num, node_num, left_child, right_child)))\n\n    def callback_func_for_split_result(self, message: Message):\n        tree_num, node_num, left_child, right_child = message.content\n        self.model[tree_num][2 * node_num + 1].indicator = self.model[\n            tree_num][node_num].indicator * left_child\n        self.model[tree_num][2 * node_num + 2].indicator = self.model[\n            tree_num][node_num].indicator * right_child\n        self._test_for_node(tree_num, node_num + 1)\n\n    def callback_func_for_feature_importance(self, message: Message):\n        state = message.state\n        self.comm_manager.send(\n            Message(msg_type='feature_importance',\n                    sender=self.ID,\n                    state=state,\n                    receiver=[self.server_id],\n                    content=self.feature_importance))\n\n    # Bind method to instance\n    client.eval = types.MethodType(eval, client)\n    client._fetch_test_data = types.MethodType(_fetch_test_data, client)\n    client._test_for_node = types.MethodType(_test_for_node, client)\n    client._feedback_eval_metrics = types.MethodType(_feedback_eval_metrics,\n                                                     client)\n    client.callback_func_for_split_request = types.MethodType(\n        callback_func_for_split_request, client)\n    client.callback_func_for_split_result = types.MethodType(\n        callback_func_for_split_result, client)\n    client.callback_func_for_feature_importance = types.MethodType(\n        callback_func_for_feature_importance, client)\n\n    # Register handler functions\n    client.register_handlers('split_request',\n                             client.callback_func_for_split_request)\n    client.register_handlers('split_result',\n                             client.callback_func_for_split_result)\n    client.register_handlers('ask_for_feature_importance',\n                             client.callback_func_for_feature_importance)\n\n    return client\n\n\ndef wrap_server_for_evaluation(server):\n    def _check_and_save_result(self):\n\n        state = max(self.msg_buffer['eval'].keys())", "completion": "def wrap_server_for_evaluation(server):\n    def _check_and_save_result(self):\n        state = max(self.msg_buffer['eval'].keys())\n        if len(self.msg_buffer['eval'][state]) == self._cfg.federate.client_num:\n            eval_metrics = {}\n            feature_importance = {}\n            for client_id in self.msg_buffer['eval'][state]:\n                eval_metrics[client_id] = self.msg_buffer['eval'][state][client_id]['eval_metric']\n                feature_importance[client_id] = self.msg_buffer['eval'][state][client_id]['feature_importance']\n            self._save_eval_result(eval_metrics, feature_importance)\n            self.msg_buffer['eval'].pop(state)\n            self.msg_buffer['feature_importance'].pop(state)\n\n    def _save_eval_result(self, eval_metrics, feature_importance):\n        eval_result = {}\n        for client_id in eval_metrics:\n            for metric_name in eval_metrics[client_id]:\n                if metric_name not in eval_result:\n                    eval_result[metric_name] = []\n                eval_result[metric_name].append(eval_metrics[client_id][metric_name])\n        for metric_name in eval_result:\n            eval_result[metric_name] = np.mean(eval_result[metric", "metadata": {"task_id": "alibaba_FederatedScope/196", "ground_truth": "        buffer = self.msg_buffer['eval'][state]", "fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "evaluation_wrapper.py"], "context_start_lineno": 0, "line_no": 151, "query_window": {"context": "    client.callback_func_for_split_result = types.MethodType(\n        callback_func_for_split_result, client)\n    client.callback_func_for_feature_importance = types.MethodType(\n        callback_func_for_feature_importance, client)\n\n    # Register handler functions\n    client.register_handlers('split_request',\n                             client.callback_func_for_split_request)\n    client.register_handlers('split_result',\n                             client.callback_func_for_split_result)\n    client.register_handlers('ask_for_feature_importance',\n                             client.callback_func_for_feature_importance)\n\n    return client\n\n\ndef wrap_server_for_evaluation(server):\n    def _check_and_save_result(self):\n\n        state = max(self.msg_buffer['eval'].keys())", "metadata": {"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "evaluation_wrapper.py"], "line_no": 151, "task_id": "alibaba_FederatedScope/196", "start_line_no": 131, "end_line_no": 151, "window_size": 20, "context_start_lineno": 0, "repo": "alibaba_FederatedScope"}}, "top_k_context": [{"context": "    client.callback_func_for_split = types.MethodType(callback_func_for_split,\n                                                      client)\n    client.callback_funcs_for_continue_training = types.MethodType(\n        callback_funcs_for_continue_training, client)\n    client._find_and_send_split = types.MethodType(_find_and_send_split,\n                                                   client)\n    client._check_eval_finish = types.MethodType(_check_eval_finish, client)\n\n    # Register handler functions\n    client.register_handlers('split', client.callback_func_for_split)\n    client.register_handlers('continue_training',\n                             client.callback_funcs_for_continue_training)\n\n    return client\n\n\ndef wrap_server_for_train(server):\n\n    return server", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "train_wrapper.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 99, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.5277777777777778}, {"context": "        callback_func_for_ss_instance_sum_norm_square, worker)\n    worker.callback_func_for_instance_var = types.MethodType(\n        callback_func_for_instance_var, worker)\n\n    # Register handlers functions\n    worker.register_handlers('ask_for_instance_sum',\n                             worker.callback_func_for_ask_for_instance_sum)\n    worker.register_handlers('ss_instance_sum',\n                             worker.callback_func_ss_instance_sum)\n    worker.register_handlers('instance_mean',\n                             worker.callback_func_for_instance_mean)\n    worker.register_handlers(\n        'ss_instance_sum_norm_square',\n        worker.callback_func_for_ss_instance_sum_norm_square)\n    worker.register_handlers('instance_var',\n                             worker.callback_func_for_instance_var)\n    return worker", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "preprocess", "instance_norm.py"], "line_no": 300, "start_line_no": 290, "end_line_no": 307, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.4264705882352941}, {"context": "    worker.callback_func_for_iv_list = types.MethodType(\n        callback_func_for_iv_list, worker)\n    worker.callback_funcs_for_vertical_dims = types.MethodType(\n        callback_funcs_for_vertical_dims, worker)\n\n    # Register handlers functions\n    worker.register_handlers('binning', worker.callback_funcs_for_binning)\n    worker.register_handlers('en_y', worker.callback_func_for_en_y)\n    worker.register_handlers('sum_en_y', worker.callback_func_for_sum_en_y)\n    worker.register_handlers('iv_list', worker.callback_func_for_iv_list)\n    worker.register_handlers('vertical_dims',\n                             worker.callback_funcs_for_vertical_dims)\n\n    return worker", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "selection", "iv_filter.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 264, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3835616438356164}, {"context": "                    state=self.state,\n                    receiver=[sender],\n                    content=(tree_num, node_num)))\n\n    def callback_funcs_for_continue_training(self, message: Message):\n        tree_num, node_num = message.content\n        self.train(tree_num=tree_num, node_num=node_num + 1)\n\n    # Bind method to instance\n    client.train = types.MethodType(train, client)\n    client.callback_func_for_split = types.MethodType(callback_func_for_split,\n                                                      client)\n    client.callback_funcs_for_continue_training = types.MethodType(\n        callback_funcs_for_continue_training, client)\n    client._find_and_send_split = types.MethodType(_find_and_send_split,\n                                                   client)\n    client._check_eval_finish = types.MethodType(_check_eval_finish, client)\n\n    # Register handler functions\n    client.register_handlers('split', client.callback_func_for_split)", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "vertical_fl", "xgb_base", "worker", "train_wrapper.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3673469387755102}, {"context": "        callback_funcs_for_encrypted_norm_feat, worker)\n    worker.callbacks_funcs_for_feat_corrcoef = types.MethodType(\n        callbacks_funcs_for_feat_corrcoef, worker)\n    worker.callback_funcs_for_vertical_dims = types.MethodType(\n        callback_funcs_for_vertical_dims, worker)\n\n    # Register handlers functions\n    worker.register_handlers('feat_engr_public_keys',\n                             worker.callback_funcs_for_feat_engr_public_keys)\n    worker.register_handlers(\n        'ask_for_encrypted_norm_feat',\n        worker.callback_funcs_for_ask_for_encrypted_norm_feat)\n    worker.register_handlers('encrypted_norm_feat',\n                             worker.callback_funcs_for_encrypted_norm_feat)\n    worker.register_handlers('feat_corrcoef',\n                             worker.callbacks_funcs_for_feat_corrcoef)\n    worker.register_handlers('vertical_dims',\n                             worker.callback_funcs_for_vertical_dims)\n\n    return worker", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "selection", "correlation_filter.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.3670886075949367}, {"context": "    worker.trigger_for_feat_engr = types.MethodType(trigger_for_feat_engr,\n                                                    worker)\n    worker.callback_func_for_ss_instance_sum = types.MethodType(\n        callback_func_for_ss_instance_sum, worker)\n    worker.callback_func_for_ss_instance_sum_norm_square = types.MethodType(\n        callback_func_for_ss_instance_sum_norm_square, worker)\n\n    # Register handlers functions\n    worker.register_handlers('ss_instance_sum',\n                             worker.callback_func_for_ss_instance_sum)\n    worker.register_handlers(\n        'ss_instance_sum_norm_square',\n        worker.callback_func_for_ss_instance_sum_norm_square)\n    return worker\n\n\ndef wrap_instance_norm_client(worker):\n    \"\"\"\n    This function is to perform instance norm vfl tabular data for client.\n    Args:", "metadata": [{"fpath_tuple": ["alibaba_FederatedScope", "federatedscope", "core", "feature", "vfl", "preprocess", "instance_norm.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "alibaba_FederatedScope", "slice_size": 2}], "sim_score": 0.35555555555555557}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/lenet.py\n# --------------------------------------------------\n#     dtype: Any = jnp.float32\n# \n#     @nn.compact\n#     def __call__(self, x: jnp.ndarray):\n#         \"\"\"\n#         Forward pass.\n# \n#         Parameters\n#         ----------\n#         x: jnp.ndarray\n#             Outputs of the deep feature extractor sub-network.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Model outputs.\n#         \"\"\"\n#         x = nn.relu(x)\n#         x = nn.Dense(features=self.output_dim, dtype=self.dtype)(x)\n#         return x\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Deep feature extractor subnetwork forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             Deep feature extractor representation.\n#         \"\"\"\n#         conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n#         norm = partial(\n#             nn.BatchNorm,\n#             use_running_average=not train,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         self.dfe_subnet = DeepFeatureExtractorSubNet(\n#             stage_sizes=self.stage_sizes,\n#             block_cls=self.block_cls,\n#             num_filters=self.num_filters,\n#             dtype=self.dtype,\n#             activation=self.activation,\n#             conv=self.conv,\n#         )\n#         self.output_subnet = OutputSubNet(output_dim=self.output_dim, dtype=self.dtype)\n# \n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/cnn.py\n# --------------------------------------------------\n#     \"\"\"\n#     A CNN model.\n#     \n#     :param output_dim: int\n#         Output dimension.\n#     :param dropout_rate: Optional[float]\n#         Dropout rate.\n#     :param dtype: Any\n#         Data type. Default: `float32`.\n#     \"\"\"\n# \n#     def setup(self):\n#         self.hidden_layers = CNNHiddenLayers(\n#             dropout_rate=self.dropout_rate, dtype=self.dtype\n#         )\n#         self.last_layer = CNNLastLayer(output_dim=self.output_dim, dtype=self.dtype)\n# \n#     def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n#         x = self.hidden_layers(x, train)\n#         x = self.last_layer(x, train)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/cnn.py\n# --------------------------------------------------\n# from typing import Any\n# \n# import flax.linen as nn\n# import jax.numpy as jnp\n# \n# \n# class CNN(nn.Module):\n#     output_dim: int\n#     dropout_rate: float\n#     dtype: Any = jnp.float32\n#     \"\"\"\n#     A CNN model.\n#     \n#     :param output_dim: int\n#         Output dimension.\n#     :param dropout_rate: Optional[float]\n#         Dropout rate.\n#     :param dtype: Any\n#         Data type. Default: `float32`.\n#     \"\"\"\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#     block_cls: ModuleDef\n#         Block class.\n#     num_filters: int\n#         Number of filters.\n#     dtype: Any\n#         Layers' dtype.\n#     activation: Callable\n#         Activation function.\n#     conv: ModuleDef\n#         Convolution module.\n#     \"\"\"\n# \n#     stage_sizes: Sequence[int]\n#     block_cls: ModuleDef\n#     num_filters: int = 64\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     @nn.compact\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#         Output dimension.\n#     num_filters: int\n#         Number of filters.\n#     dtype: Any\n#         Layers' dtype.\n#     activation: Callable\n#         Activation function.\n#     conv: ModuleDef\n#         Convolution module.\n#     \"\"\"\n# \n#     stage_sizes: Sequence[int]\n#     block_cls: ModuleDef\n#     output_dim: int\n#     num_filters: int = 64\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     def setup(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n#     \"\"\"\n# \n#     stage_sizes: Sequence[int]\n#     block_cls: ModuleDef\n#     num_filters: int = 64\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     @nn.compact\n#     def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n#         \"\"\"\n#         Deep feature extractor subnetwork forward pass.\n# \n#         Parameters\n#         ----------\n#         x: Array\n#             Input data.\n#         train: bool\n#             Whether the call is performed during training.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/model/resnet.py\n# --------------------------------------------------\n# \n#     stage_sizes: Sequence[int]\n#     block_cls: ModuleDef\n#     output_dim: int\n#     num_filters: int = 64\n#     dtype: Any = jnp.float32\n#     activation: Callable = nn.relu\n#     conv: ModuleDef = nn.Conv\n# \n#     def setup(self):\n#         self.dfe_subnet = DeepFeatureExtractorSubNet(\n#             stage_sizes=self.stage_sizes,\n#             block_cls=self.block_cls,\n#             num_filters=self.num_filters,\n#             dtype=self.dtype,\n#             activation=self.activation,\n#             conv=self.conv,\n#         )\n#         self.output_subnet = OutputSubNet(output_dim=self.output_dim, dtype=self.dtype)\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n WideResnetBlock(nn.Module):\n    \"\"\"\n    A wide residual network block.\n\n    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    filters: int\n        Number of filters.\n    strides: Tuple[int, int]\n        Strides.\n    :param dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Block forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Block inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Block outputs.\n        \"\"\"\n        dropout = nn.Dropout(rate=self.dropout_rate)\n\n        y = self.norm(name=\"bn1\")(x)\n        y = nn.relu(y)\n        y = self.conv(self.filters, (3, 3), self.strides, name=\"conv1\")(y)\n        y = self.norm(name=\"bn2\")(y)\n        y = nn.relu(y)\n        if self.dropout_rate > 0.0:\n            y = dropout(y, deterministic=not train)\n        y = self.conv(self.filters, (3, 3), name=\"conv2\")(y)\n\n        # Apply an up projection in case of channel mismatch\n        if (x.shape[-1] != self.filters) or self.strides != (1, 1):\n            x = self.conv(self.filters, (3, 3), self.strides)(x)\n        return x + y\n\n\nclass WideResnetGroup(nn.Module):\n    \"\"\"\n    A wide residual network group.\n\n    Attributes\n    ----------\n    conv: ModuleDef\n        Convolution module.\n    norm: ModuleDef\n        Normalization module.\n    activation: Callable\n        Activation function.\n    blocks_per_group: int\n        Number of blocks per group.\n    strides: Tuple[int, int]\n        Strides.\n    dropout_rate: float\n        Dropout rate.\n    \"\"\"\n\n    conv: ModuleDef\n    norm: ModuleDef\n    activation: Callable\n    blocks_per_group: int\n    filters: int\n    strides: Tuple[int, int] = (1, 1)\n    dropout_rate: float = 0.0\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Group forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Group inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Group outputs.\n        \"\"\"\n        for i in range(self.blocks_per_group):\n            x = WideResnetBlock(\n                conv=self.conv,\n                norm=self.norm,\n                activation=self.activation,\n                filters=self.filters,\n                strides=self.strides if i == 0 else (1, 1),\n                dropout_rate=self.dropout_rate,\n            )(x, train=train)\n        return x\n\n\nclass DeepFeatureExtractorSubNet(nn.Module):\n    \"\"\"\n    Deep feature extractor subnetwork.\n\n    Attributes\n    ----------\n    depth: int\n        Depth of the subnetwork.\n    widen_factor: int\n        Widening factor.\n    dropout_rate: float\n        Dropout rate.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    depth: int = 28\n    widen_factor: int = 10\n    dropout_rate: float = 0.0\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    @nn.compact\n    def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Deep feature extractor subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: Array\n            Input data.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Deep feature extractor representation.\n        \"\"\"\n        blocks_per_group = (self.depth - 4) // 6\n\n        conv = partial(self.conv, use_bias=False, dtype=self.dtype)\n        norm = partial(\n            nn.BatchNorm,\n            use_running_average=not train,\n            momentum=0.9,\n            epsilon=1e-5,\n            dtype=self.dtype,\n        )\n\n        x = conv(16, (3, 3), name=\"init_conv\")(x)\n        x = WideResnetGroup(\n            conv=conv,\n            norm=norm,\n            activation=self.activation,\n            blocks_per_group=blocks_per_group,\n            filters=16 * self.widen_factor,\n            strides=(1, 1),\n            dropout_rate=self.dropout_rate,\n        )(x, train=train)\n        x = WideResnetGroup(\n            conv=conv,\n            norm=norm,\n            activation=self.activation,\n            blocks_per_group=blocks_per_group,\n            filters=32 * self.widen_factor,\n            strides=(2, 2),\n            dropout_rate=self.dropout_rate,\n        )(x, train=train)\n        x = WideResnetGroup(\n            conv=conv,\n            norm=norm,\n            activation=self.activation,\n            blocks_per_group=blocks_per_group,\n            filters=64 * self.widen_factor,\n            strides=(2, 2),\n            dropout_rate=self.dropout_rate,\n        )(x, train=train)\n        x = norm()(x)\n        x = nn.relu(x)\n        x = nn.avg_pool(x, (8, 8))\n        x = x.reshape((x.shape[0], -1))\n        return x\n\n\nclass OutputSubNet(nn.Module):\n    \"\"\"\n    Output subnetwork.\n\n    Parameters\n    ----------\n    output_dim: int\n        Output dimension.\n    dtype: Any\n        Layers' dtype.\n    \"\"\"\n\n    output_dim: int\n    dtype: Any = jnp.float32\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Output subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray\n            Subnetwork inputs.\n        train: bool\n            Whether the call is performed during training.\n\n        Returns\n        -------\n        jnp.ndarray\n            Outputs.\n        \"\"\"\n        x = nn.Dense(self.output_dim, dtype=self.dtype)(x)\n        return x\n\n\nclass WideResNet(nn.Module):\n    \"\"\"\n    Wide residual network class.\n\n    Attributes\n    ----------\n    output_dim: int\n        Output dimension.\n    depth: int\n        Depth of the subnetwork.\n    widen_factor: int\n        Widening factor.\n    dropout_rate: float\n        Dropout rate.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    output_dim: int\n    depth: int = 28\n    widen_factor: int = 10\n    dropout_rate: float = 0.0\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu", "completion": "conv: ModuleDef = nn.Conv\nnorm: ModuleDef = nn.BatchNorm\nfilters: int = 16\nstrides: Tuple[int, int] = (1, 1)\ndropout_rate: float = 0.0\n\nx = jnp.ndarray\ntrain: bool = True\n\ndropout = nn.Dropout(rate=dropout_rate)\n\ny = norm(name=\"bn1\")(x)\ny = nn.relu(y)\ny = conv(filters, (3, 3), strides, name=\"conv1\")(y)\ny = norm(name=\"bn2\")(y)\ny = nn.relu(y)\nif dropout_rate > 0.0:\n    y = dropout(y, deterministic=not train)\ny = conv(filters, (3, 3), name=\"conv2\")(y)\n\n# Apply an up projection in case of channel mismatch\nif (x.shape[-1] != filters) or strides != (1, 1):\n    x = conv(filters, (3, 3), strides)(x)\nx = x + y\n\nblocks_per_group = (depth - 4) // 6\n\nconv = partial(conv, use_bias=False, dtype=dtype)\nnorm = partial(\n    norm,\n    use_running_average=", "metadata": {"task_id": "awslabs_fortuna/54", "ground_truth": "    conv: ModuleDef = nn.Conv", "fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "context_start_lineno": 15, "line_no": 287, "query_window": {"context": "    depth: int\n        Depth of the subnetwork.\n    widen_factor: int\n        Widening factor.\n    dropout_rate: float\n        Dropout rate.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    output_dim: int\n    depth: int = 28\n    widen_factor: int = 10\n    dropout_rate: float = 0.0\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "wideresnet.py"], "line_no": 287, "task_id": "awslabs_fortuna/54", "start_line_no": 267, "end_line_no": 287, "window_size": 20, "context_start_lineno": 15, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        Output dimension.\n    num_filters: int\n        Number of filters.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    stage_sizes: Sequence[int]\n    block_cls: ModuleDef\n    output_dim: int\n    num_filters: int = 64\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    def setup(self):", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.46987951807228917}, {"context": "    block_cls: ModuleDef\n        Block class.\n    num_filters: int\n        Number of filters.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"\n\n    stage_sizes: Sequence[int]\n    block_cls: ModuleDef\n    num_filters: int = 64\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    @nn.compact", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.45121951219512196}, {"context": "    \"\"\"\n     Deep feature extractor subnetwork.\n\n    Attributes\n    ----------\n    stage_sizes: Sequence[int]\n        Sizes for each stage.\n    block_cls: ModuleDef\n        Block class.\n    output_dim: int\n        Output dimension.\n    num_filters: int\n        Number of filters.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.\n    \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.36363636363636365}, {"context": "\n\nclass DeepFeatureExtractorSubNet(nn.Module):\n    \"\"\"\n     Deep feature extractor subnetwork.\n\n    Attributes\n    ----------\n    stage_sizes: Sequence[int]\n        Sizes for each stage.\n    block_cls: ModuleDef\n        Block class.\n    num_filters: int\n        Number of filters.\n    dtype: Any\n        Layers' dtype.\n    activation: Callable\n        Activation function.\n    conv: ModuleDef\n        Convolution module.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 140, "start_line_no": 130, "end_line_no": 150, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3125}, {"context": "from typing import Any\n\nimport flax.linen as nn\nimport jax.numpy as jnp\n\n\nclass CNN(nn.Module):\n    output_dim: int\n    dropout_rate: float\n    dtype: Any = jnp.float32", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "cnn.py"], "line_no": 0, "start_line_no": 0, "end_line_no": 10, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.30666666666666664}, {"context": "from typing import Any\n\nimport flax.linen as nn\nimport jax.numpy as jnp\n\n\nclass CNN(nn.Module):\n    output_dim: int\n    dropout_rate: float\n    dtype: Any = jnp.float32\n    \"\"\"\n    A CNN model.\n    \n    :param output_dim: int\n        Output dimension.\n    :param dropout_rate: Optional[float]\n        Dropout rate.\n    :param dtype: Any\n        Data type. Default: `float32`.\n    \"\"\"", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "cnn.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.3}, {"context": "\n    stage_sizes: Sequence[int]\n    block_cls: ModuleDef\n    output_dim: int\n    num_filters: int = 64\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    def setup(self):\n        self.dfe_subnet = DeepFeatureExtractorSubNet(\n            stage_sizes=self.stage_sizes,\n            block_cls=self.block_cls,\n            num_filters=self.num_filters,\n            dtype=self.dtype,\n            activation=self.activation,\n            conv=self.conv,\n        )\n        self.output_subnet = OutputSubNet(output_dim=self.output_dim, dtype=self.dtype)\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 270, "start_line_no": 260, "end_line_no": 280, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.27450980392156865}, {"context": "    \"\"\"\n\n    stage_sizes: Sequence[int]\n    block_cls: ModuleDef\n    num_filters: int = 64\n    dtype: Any = jnp.float32\n    activation: Callable = nn.relu\n    conv: ModuleDef = nn.Conv\n\n    @nn.compact\n    def __call__(self, x: Array, train: bool = True) -> jnp.ndarray:\n        \"\"\"\n        Deep feature extractor subnetwork forward pass.\n\n        Parameters\n        ----------\n        x: Array\n            Input data.\n        train: bool\n            Whether the call is performed during training.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "resnet.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.26785714285714285}, {"context": "\n    Attributes\n    ----------\n    output_dim: int\n        The output model dimension.\n    dtype: Any\n        Layers' dtype.\n    \"\"\"\n\n    output_dim: int\n    dtype: Any = jnp.float32\n\n    @nn.compact\n    def __call__(self, x: jnp.ndarray):\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x: jnp.ndarray", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "model", "lenet.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.26506024096385544}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/coma.py\n# --------------------------------------------------\n# from .base_policy import Policy\n# \n# \n# @POLICY_REGISTRY.register('coma')\n# class COMAPolicy(Policy):\n#     r\"\"\"\n#     Overview:\n#         Policy class of COMA algorithm. COMA is a multi model reinforcement learning algorithm\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n#             _reset_eval, _get_train_sample, default_model, _monitor_vars_learn\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      coma           | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n#         2  ``cuda``             bool     False          | Whether to use cuda for network        | this arg can be diff-\n#                                                                                                  | erent from modes\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/ace_dqn.py\n# --------------------------------------------------\n# from ding.utils.data import timestep_collate, default_collate, default_decollate\n# from .base_policy import Policy\n# \n# @POLICY_REGISTRY.register('smac_ace_dqn')\n# class SMACACEDQNPolicy(Policy):\n#     \"\"\"\n#     Overview:\n#         Policy class of ACE algorithm. ACE is a multi agent reinforcement learning algorithm, \\\n#             you can view the paper in the following link https://arxiv.org/abs/2211.16068\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn \\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval \\\n#             _reset_eval, _get_train_sample, default_model\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      qmix           | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n#         2  ``cuda``             bool     True           | Whether to use cuda for network        | this arg can be diff-\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/collaq.py\n# --------------------------------------------------\n# from .base_policy import Policy\n# \n# \n# @POLICY_REGISTRY.register('collaq')\n# class CollaQPolicy(Policy):\n#     r\"\"\"\n#     Overview:\n#         Policy class of CollaQ algorithm. CollaQ is a multi-agent reinforcement learning algorithm\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n#             _reset_eval, _get_train_sample, default_model\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      collaq         | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n#         2  ``cuda``             bool     True           | Whether to use cuda for network        | this arg can be diff-\n#                                                                                                  | erent from modes\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/wqmix.py\n# --------------------------------------------------\n# from .base_policy import Policy\n# from ding.policy.qmix import QMIXPolicy\n# \n# \n# @POLICY_REGISTRY.register('wqmix')\n# class WQMIXPolicy(QMIXPolicy):\n#     r\"\"\"\n#     Overview:\n#         Policy class of WQMIX algorithm. WQMIX is a reinforcement learning algorithm modified from Qmix, \\\n#             you can view the paper in the following link https://arxiv.org/abs/2006.10800\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n#             _reset_eval, _get_train_sample, default_model\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      qmix           | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/policy/qmix.py\n# --------------------------------------------------\n# from .base_policy import Policy\n# \n# \n# @POLICY_REGISTRY.register('qmix')\n# class QMIXPolicy(Policy):\n#     r\"\"\"\n#     Overview:\n#         Policy class of QMIX algorithm. QMIX is a multi model reinforcement learning algorithm, \\\n#             you can view the paper in the following link https://arxiv.org/abs/1803.11485\n#     Interface:\n#         _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\\n#             _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n#             _reset_eval, _get_train_sample, default_model\n#     Config:\n#         == ==================== ======== ============== ======================================== =======================\n#         ID Symbol               Type     Default Value  Description                              Other(Shape)\n#         == ==================== ======== ============== ======================================== =======================\n#         1  ``type``             str      qmix           | RL policy register name, refer to      | this arg is optional,\n#                                                         | registry ``POLICY_REGISTRY``           | a placeholder\n#         2  ``cuda``             bool     True           | Whether to use cuda for network        | this arg can be diff-\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nfrom typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport torch.nn.functional as F\nimport copy\nfrom easydict import EasyDict\n\nfrom ding.torch_utils import Adam, RMSprop, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_epsilon_greedy_fn, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('qtran')\nclass QTRANPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of QTRAN algorithm. QTRAN is a multi model reinforcement learning algorithm, \\\n            you can view the paper in the following link https://arxiv.org/abs/1803.11485\n    Interface:\n        _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\", "completion": "_init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\\n            _reset_eval, _get_train_sample, default_model\n    Config:\n        == ==================== ======== ============== ======================================== =======================\n        ID Symbol               Type     Default Value  Description                              Other(Shape)\n        == ==================== ======== ============== ======================================== =======================\n        1  ``type``             str      qtran          | RL policy register name, refer to      | this arg is optional,\n                                                        | registry ``POLICY_REGISTRY``           | a placeholder\n        2  ``cuda``             bool     True           | Whether to use cuda for network        | this arg can be diff-\n                                                                                                 | erent from modes\n        3  ``gamma``            float    0.99           | Reward's future discount factor        | this arg is optional,\n                                                                                                 | a placeholder\n        4  ``nstep``            int      1              | N step reward                           | this arg is optional,\n                                                                                                 | a placeholder\n        5  ``rollout_num``      int      1              | Number of rollout workers               | this arg is optional,\n                                                                                                 | a", "metadata": {"task_id": "opendilab_ACE/112", "ground_truth": "            _init_collect, _forward_collect, _reset_collect, _process_transition, _init_eval, _forward_eval\\", "fpath_tuple": ["opendilab_ACE", "ding", "policy", "qtran.py"], "context_start_lineno": 0, "line_no": 23, "query_window": {"context": "import torch.nn.functional as F\nimport copy\nfrom easydict import EasyDict\n\nfrom ding.torch_utils import Adam, RMSprop, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_epsilon_greedy_fn, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('qtran')\nclass QTRANPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of QTRAN algorithm. QTRAN is a multi model reinforcement learning algorithm, \\\n            you can view the paper in the following link https://arxiv.org/abs/1803.11485\n    Interface:\n        _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "policy", "qtran.py"], "line_no": 23, "task_id": "opendilab_ACE/112", "start_line_no": 3, "end_line_no": 23, "window_size": 20, "context_start_lineno": 0, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\n\nfrom ding.torch_utils import RMSprop, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('qmix')\nclass QMIXPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of QMIX algorithm. QMIX is a multi model reinforcement learning algorithm, \\\n            you can view the paper in the following link https://arxiv.org/abs/1803.11485\n    Interface:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "qmix.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.6923076923076923}, {"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\n\nfrom ding.torch_utils import RMSprop, to_device\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\nfrom ding.policy.qmix import QMIXPolicy\n\n\n@POLICY_REGISTRY.register('wqmix')\nclass WQMIXPolicy(QMIXPolicy):\n    r\"\"\"\n    Overview:\n        Policy class of WQMIX algorithm. WQMIX is a reinforcement learning algorithm modified from Qmix, \\\n            you can view the paper in the following link https://arxiv.org/abs/2006.10800", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "wqmix.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.609271523178808}, {"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\n\nfrom ding.torch_utils import to_device, RMSprop\nfrom ding.rl_utils import v_1step_td_data, v_1step_td_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('collaq')\nclass CollaQPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of CollaQ algorithm. CollaQ is a multi-agent reinforcement learning algorithm\n    Interface:\n        _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "collaq.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5972222222222222}, {"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\nimport math\n\nfrom ding.torch_utils import Adam, RMSprop, to_device\nfrom ding.rl_utils import q_nstep_td_data, q_nstep_td_error, get_nstep_return_data, get_train_sample, l2_balance\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import timestep_collate, default_collate, default_decollate\nfrom .base_policy import Policy\n\n@POLICY_REGISTRY.register('smac_ace_dqn')\nclass SMACACEDQNPolicy(Policy):\n    \"\"\"\n    Overview:\n        Policy class of ACE algorithm. ACE is a multi agent reinforcement learning algorithm, \\\n            you can view the paper in the following link https://arxiv.org/abs/2211.16068\n    Interface:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "ace_dqn.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5590062111801242}, {"context": "from typing import List, Dict, Any, Tuple, Union, Optional\nfrom collections import namedtuple\nimport torch\nimport copy\n\nfrom ding.torch_utils import Adam, to_device\nfrom ding.rl_utils import coma_data, coma_error, get_train_sample\nfrom ding.model import model_wrap\nfrom ding.utils import POLICY_REGISTRY\nfrom ding.utils.data import default_collate, default_decollate, timestep_collate\nfrom .base_policy import Policy\n\n\n@POLICY_REGISTRY.register('coma')\nclass COMAPolicy(Policy):\n    r\"\"\"\n    Overview:\n        Policy class of COMA algorithm. COMA is a multi model reinforcement learning algorithm\n    Interface:\n        _init_learn, _data_preprocess_learn, _forward_learn, _reset_learn, _state_dict_learn, _load_state_dict_learn\\", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "policy", "coma.py"], "line_no": 10, "start_line_no": 0, "end_line_no": 20, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5517241379310345}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/test_tensordictmodules.py\n# --------------------------------------------------\n#             spec = UnboundedContinuousTensorSpec(4)\n#         else:\n#             raise NotImplementedError\n# \n#         kwargs = {\"distribution_class\": TanhNormal}\n#         if out_keys == [\"loc\", \"scale\"]:\n#             dist_in_keys = [\"loc\", \"scale\"]\n#         elif out_keys == [\"loc_1\", \"scale_1\"]:\n#             dist_in_keys = {\"loc\": \"loc_1\", \"scale\": \"scale_1\"}\n#         else:\n#             raise NotImplementedError\n# \n#         if safe and spec is None:\n#             with pytest.raises(\n#                 RuntimeError,\n#                 match=\"is not a valid configuration as the tensor specs are not \"\n#                 \"specified\",\n#             ):\n#                 prob_module = SafeProbabilisticModule(\n#                     in_keys=dist_in_keys,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# test/mocking_classes.py\n# --------------------------------------------------\n#             },\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n# \n#     def _step(\n#         self,\n#         tensordict: TensorDictBase,\n#     ) -> TensorDictBase:\n#         action = tensordict.get(\"action\")\n#         self.count += action.to(torch.int)\n#         return TensorDict(\n#             source={\n#                 \"observation\": self.count,\n#                 \"done\": self.count > self.max_steps,\n#                 \"reward\": torch.zeros_like(self.count, dtype=torch.float),\n#             },\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/libs/vmas.py\n# --------------------------------------------------\n# \n#     def _init_env(self) -> Optional[int]:\n#         pass\n# \n#     def _set_seed(self, seed: Optional[int]):\n#         self._env.seed(seed)\n# \n#     def _reset(\n#         self, tensordict: Optional[TensorDictBase] = None, **kwargs\n#     ) -> TensorDictBase:\n#         if tensordict is not None and \"_reset\" in tensordict.keys():\n#             _reset = tensordict.get(\"_reset\")\n#             envs_to_reset = _reset.any(dim=0)\n#             for env_index, to_reset in enumerate(envs_to_reset):\n#                 if to_reset:\n#                     self._env.reset_at(env_index)\n#             done = _selective_unsqueeze(self._env.done(), batch_size=(self.num_envs,))\n#             obs = []\n#             infos = []\n#             dones = []\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#                 self._storage.load_state_dict(_storage)\n#             elif self._storage is None:\n#                 batch_size = _storage.pop(\"__batch_size\")\n#                 device = _storage.pop(\"__device\")\n#                 self._storage = TensorDict(\n#                     _storage, batch_size=batch_size, device=device\n#                 )\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         else:\n#             raise TypeError(\n#                 f\"Objects of type {type(_storage)} are not supported by ListStorage.load_state_dict\"\n#             )\n#         self.initialized = state_dict[\"initialized\"]\n#         self._len = state_dict[\"_len\"]\n# \n#     def _init(self, data: Union[TensorDictBase, torch.Tensor]) -> None:\n#         print(\"Creating a TensorStorage...\")\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#             )\n#         return {\n#             \"_storage\": _storage,\n#             \"initialized\": self.initialized,\n#             \"_len\": self._len,\n#         }\n# \n#     def load_state_dict(self, state_dict):\n#         _storage = copy(state_dict[\"_storage\"])\n#         if isinstance(_storage, torch.Tensor):\n#             if isinstance(self._storage, torch.Tensor):\n#                 self._storage.copy_(_storage)\n#             elif self._storage is None:\n#                 self._storage = _storage\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         elif isinstance(_storage, (dict, OrderedDict)):\n#             if isinstance(self._storage, TensorDictBase):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/collectors/collectors.py\n# --------------------------------------------------\n#             if self._td_env is None:\n#                 self._td_env = td.to(env_device)\n#             else:\n#                 self._td_env.update(td, inplace=True)\n#             return self._td_env\n#         else:\n#             return dest.update(td, inplace=True)\n# \n#     def _reset_if_necessary(self) -> None:\n#         done = self._tensordict.get(\"done\")\n#         if not self.reset_when_done:\n#             done = torch.zeros_like(done)\n#         steps = self._tensordict.get((\"collector\", \"step_count\"))\n#         done_or_terminated = done.squeeze(-1) | (steps == self.max_frames_per_traj)\n#         if self._has_been_done is None:\n#             self._has_been_done = done_or_terminated\n#         else:\n#             self._has_been_done = self._has_been_done | done_or_terminated\n#         if not self._has_been_done.all() and self.init_with_lag:\n#             _reset = torch.zeros_like(done_or_terminated).bernoulli_(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/replay_buffers/storages.py\n# --------------------------------------------------\n#             if isinstance(self._storage, torch.Tensor):\n#                 self._storage.copy_(_storage)\n#             elif self._storage is None:\n#                 self._storage = _storage\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n#                 )\n#         elif isinstance(_storage, (dict, OrderedDict)):\n#             if isinstance(self._storage, TensorDictBase):\n#                 self._storage.load_state_dict(_storage)\n#             elif self._storage is None:\n#                 batch_size = _storage.pop(\"__batch_size\")\n#                 device = _storage.pop(\"__device\")\n#                 self._storage = TensorDict(\n#                     _storage, batch_size=batch_size, device=device\n#                 )\n#             else:\n#                 raise RuntimeError(\n#                     f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nsteps_ops = []\n        self._post_steps_log_ops = []\n        self._pre_steps_log_ops = []\n        self._post_optim_log_ops = []\n        self._pre_optim_ops = []\n        self._post_loss_ops = []\n        self._optimizer_ops = []\n        self._process_optim_batch_ops = []\n        self._post_optim_ops = []\n        self._modules = {}\n\n        if self.optimizer is not None:\n            optimizer_hook = OptimizerHook(self.optimizer)\n            optimizer_hook.register(self)\n\n    def register_module(self, module_name: str, module: Any) -> None:\n        if module_name in self._modules:\n            raise RuntimeError(\n                f\"{module_name} is already registered, choose a different name.\"\n            )\n        self._modules[module_name] = module\n\n    def _get_state(self):\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            state = StateDict(\n                collected_frames=self.collected_frames,\n                _last_log=self._last_log,\n                _last_save=self._last_save,\n                _optim_count=self._optim_count,\n            )\n        else:\n            state = OrderedDict(\n                collected_frames=self.collected_frames,\n                _last_log=self._last_log,\n                _last_save=self._last_save,\n                _optim_count=self._optim_count,\n            )\n        return state\n\n    @property\n    def app_state(self):\n        self._app_state = {\n            \"state\": StateDict(**self._get_state()),\n            \"collector\": self.collector,\n            \"loss_module\": self.loss_module,\n            **{k: item for k, item in self._modules.items()},\n        }\n        return self._app_state\n\n    def state_dict(self) -> Dict:\n        state = self._get_state()\n        state_dict = OrderedDict(\n            collector=self.collector.state_dict(),\n            loss_module=self.loss_module.state_dict(),\n            state=state,\n            **{k: item.state_dict() for k, item in self._modules.items()},\n        )\n        return state_dict\n\n    def load_state_dict(self, state_dict: Dict) -> None:\n        model_state_dict = state_dict[\"loss_module\"]\n        collector_state_dict = state_dict[\"collector\"]\n\n        self.loss_module.load_state_dict(model_state_dict)\n        self.collector.load_state_dict(collector_state_dict)\n        for key, item in self._modules.items():\n            item.load_state_dict(state_dict[key])\n\n        self.collected_frames = state_dict[\"state\"][\"collected_frames\"]\n        self._last_log = state_dict[\"state\"][\"_last_log\"]\n        self._last_save = state_dict[\"state\"][\"_last_save\"]\n        self._optim_count = state_dict[\"state\"][\"_optim_count\"]\n\n    def _save_trainer(self) -> None:\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            if not _has_ts:\n                raise ImportError(\n                    \"torchsnapshot not found. Consider installing torchsnapshot or \"\n                    \"using the torch checkpointing backend (`CKPT_BACKEND=torch`)\"\n                )\n            Snapshot.take(app_state=self.app_state, path=self.save_trainer_file)\n        elif _CKPT_BACKEND == \"torch\":\n            torch.save(self.state_dict(), self.save_trainer_file)\n        else:\n            raise NotImplementedError(\n                f\"CKPT_BACKEND should be one of {_CKPT_BACKEND.backends}, got {_CKPT_BACKEND}.\"\n            )\n\n    def save_trainer(self, force_save: bool = False) -> None:\n        _save = force_save\n        if self.save_trainer_file is not None:\n            if (self.collected_frames - self._last_save) > self.save_trainer_interval:\n                self._last_save = self.collected_frames\n                _save = True\n        if _save and self.save_trainer_file:\n            self._save_trainer()\n\n    def load_from_file(self, file: Union[str, pathlib.Path]) -> Trainer:\n        if _CKPT_BACKEND == \"torchsnapshot\":\n            snapshot = Snapshot(path=file)\n            snapshot.restore(app_state=self.app_state)\n        elif _CKPT_BACKEND == \"torch\":\n            loaded_dict: OrderedDict = torch.load(file)\n            self.load_state_dict(loaded_dict)\n        return self\n\n    def set_seed(self):\n        seed = self.collector.set_seed(self.seed, static_seed=False)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n\n    @property\n    def collector(self) -> _DataCollector:\n        return self._collector\n\n    @collector.setter\n    def collector(self, collector: _DataCollector) -> None:\n        self._collector = collector\n\n    def register_op(self, dest: str, op: Callable, **kwargs) -> None:\n        if dest == \"batch_process\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._batch_process_ops.append((op, kwargs))\n\n        elif dest == \"pre_optim_steps\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._pre_optim_ops.append((op, kwargs))\n\n        elif dest == \"process_optim_batch\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._process_optim_batch_ops.append((op, kwargs))\n\n        elif dest == \"post_loss\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=TensorDictBase\n            )\n            self._post_loss_ops.append((op, kwargs))\n\n        elif dest == \"optimizer\":\n            _check_input_output_typehint(\n                op, input=[TensorDictBase, bool, float, int], output=TensorDictBase\n            )\n            self._optimizer_ops.append((op, kwargs))\n\n        elif dest == \"post_steps\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._post_steps_ops.append((op, kwargs))\n\n        elif dest == \"post_optim\":\n            _check_input_output_typehint(op, input=None, output=None)\n            self._post_optim_ops.append((op, kwargs))\n\n        elif dest == \"pre_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._pre_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_optim_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_optim_log_ops.append((op, kwargs))\n\n        else:\n            raise RuntimeError(", "completion": "f\"Invalid destination '{dest}' for registering operation.\")\n\n    def _pre_steps(self) -> None:\n        for op, kwargs in self._pre_steps_log_ops:\n            op(self._tensordict, **kwargs)\n\n    def _post_steps(self) -> None:\n        for op, kwargs in self._post_steps_log_ops:\n            op(self._tensordict, **kwargs)\n\n    def _post_optim(self) -> None:\n        for op, kwargs in self._post_optim_log_ops:\n            op(self._tensordict, **kwargs)\n\n    def _pre_optim_steps(self) -> None:\n        for op, kwargs in self._pre_optim_ops:\n            op(**kwargs)\n\n    def _post_loss(self) -> None:\n        for op, kwargs in self._post_loss_ops:\n            op(self._tensordict, **kwargs)\n\n    def _optimizer(self) -> None:\n        for op, kwargs in self._optimizer_ops:\n            op(self._tensordict, **kwargs)\n\n    def _process_optim_batch(self) -> None:\n        for op, kwargs in self._process_optim_batch_ops:\n            op(self._tensordict, **", "metadata": {"task_id": "pytorch_rl/163", "ground_truth": "                f\"The hook collection {dest} is not recognised. Choose from:\"", "fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "context_start_lineno": 175, "line_no": 351, "query_window": {"context": "        elif dest == \"pre_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._pre_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_steps_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_steps_log_ops.append((op, kwargs))\n\n        elif dest == \"post_optim_log\":\n            _check_input_output_typehint(\n                op, input=TensorDictBase, output=Tuple[str, float]\n            )\n            self._post_optim_log_ops.append((op, kwargs))\n\n        else:\n            raise RuntimeError(", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "trainers", "trainers.py"], "line_no": 351, "task_id": "pytorch_rl/163", "start_line_no": 331, "end_line_no": 351, "window_size": 20, "context_start_lineno": 175, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "            )\n        return {\n            \"_storage\": _storage,\n            \"initialized\": self.initialized,\n            \"_len\": self._len,\n        }\n\n    def load_state_dict(self, state_dict):\n        _storage = copy(state_dict[\"_storage\"])\n        if isinstance(_storage, torch.Tensor):\n            if isinstance(self._storage, torch.Tensor):\n                self._storage.copy_(_storage)\n            elif self._storage is None:\n                self._storage = _storage\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n                )\n        elif isinstance(_storage, (dict, OrderedDict)):\n            if isinstance(self._storage, TensorDictBase):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.27722772277227725}, {"context": "            if td.device == torch.device(\"cpu\") and self.pin_memory:\n                td.pin_memory()\n            self._td_policy.update(td, inplace=True)\n        return self._td_policy\n\n    def _cast_to_env(\n        self, td: TensorDictBase, dest: Optional[TensorDictBase] = None\n    ) -> TensorDictBase:\n        env_device = self.env_device\n        if dest is None:\n            if self._td_env is None:\n                self._td_env = td.to(env_device)\n            else:\n                self._td_env.update(td, inplace=True)\n            return self._td_env\n        else:\n            return dest.update(td, inplace=True)\n\n    def _reset_if_necessary(self) -> None:\n        done = self._tensordict.get(\"done\")", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "collectors", "collectors.py"], "line_no": 590, "start_line_no": 580, "end_line_no": 600, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26804123711340205}, {"context": "        _storage = self._storage\n        if isinstance(_storage, torch.Tensor):\n            pass\n        elif isinstance(_storage, TensorDictBase):\n            _storage = _storage.state_dict()\n        elif _storage is None:\n            _storage = {}\n        else:\n            raise TypeError(\n                f\"Objects of type {type(_storage)} are not supported by LazyTensorStorage.state_dict\"\n            )\n        return {\n            \"_storage\": _storage,\n            \"initialized\": self.initialized,\n            \"_len\": self._len,\n        }\n\n    def load_state_dict(self, state_dict):\n        _storage = copy(state_dict[\"_storage\"])\n        if isinstance(_storage, torch.Tensor):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2647058823529412}, {"context": "            if isinstance(self._storage, torch.Tensor):\n                self._storage.copy_(_storage)\n            elif self._storage is None:\n                self._storage = _storage\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"\n                )\n        elif isinstance(_storage, (dict, OrderedDict)):\n            if isinstance(self._storage, TensorDictBase):\n                self._storage.load_state_dict(_storage)\n            elif self._storage is None:\n                batch_size = _storage.pop(\"__batch_size\")\n                device = _storage.pop(\"__device\")\n                self._storage = TensorDict(\n                    _storage, batch_size=batch_size, device=device\n                )\n            else:\n                raise RuntimeError(\n                    f\"Cannot copy a storage of type {type(_storage)} onto another of type {type(self._storage)}\"", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "storages.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.26}, {"context": "        ).expand(self.batch_size)\n\n    def _check_kwargs(self, kwargs: Dict):\n        if \"env\" not in kwargs:\n            raise TypeError(\"Could not find environment key 'env' in kwargs.\")\n        env = kwargs[\"env\"]\n        if not isinstance(env, vmas.simulator.environment.Environment):\n            raise TypeError(\n                \"env is not of type 'vmas.simulator.environment.Environment'.\"\n            )\n\n    def _init_env(self) -> Optional[int]:\n        pass\n\n    def _set_seed(self, seed: Optional[int]):\n        self._env.seed(seed)\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "libs", "vmas.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.25663716814159293}, {"context": "            self.count[_reset] = 0\n        else:\n            self.count[:] = 0\n        return TensorDict(\n            source={\n                \"observation\": self.count.clone(),\n                \"done\": self.count > self.max_steps,\n            },\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n\n    def _step(\n        self,\n        tensordict: TensorDictBase,\n    ) -> TensorDictBase:\n        action = tensordict.get(\"action\")\n        self.count += action.to(torch.int)\n        return TensorDict(\n            source={", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "mocking_classes.py"], "line_no": 890, "start_line_no": 880, "end_line_no": 900, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.25510204081632654}, {"context": "            spec=None,\n            in_keys=in_keys,\n            out_keys=out_keys,\n        )\n\n        if spec_type is None:\n            spec = None\n        elif spec_type == \"bounded\":\n            spec = BoundedTensorSpec(-0.1, 0.1, 4)\n        elif spec_type == \"unbounded\":\n            spec = UnboundedContinuousTensorSpec(4)\n        else:\n            raise NotImplementedError\n\n        kwargs = {\"distribution_class\": TanhNormal}\n        if out_keys == [\"loc\", \"scale\"]:\n            dist_in_keys = [\"loc\", \"scale\"]\n        elif out_keys == [\"loc_1\", \"scale_1\"]:\n            dist_in_keys = {\"loc\": \"loc_1\", \"scale\": \"scale_1\"}\n        else:", "metadata": [{"fpath_tuple": ["pytorch_rl", "test", "test_tensordictmodules.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.2524271844660194}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_qrdqn():\n#     config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_ppo():\n#     config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_a2c():\n#     config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_rainbow():\n#     config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_c51():\n#     config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_qrdqn():\n#     config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_rainbow():\n#     config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_iqn():\n#     config = [deepcopy(cartpole_iqn_config), deepcopy(cartpole_iqn_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_a2c_with_nstep_return():\n#     config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n#     config[0].policy.collect.discount_factor = 0.9\n#     config[0].policy.collect.nstep = 3\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n# def test_impala():\n#     config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_her_dqn():\n#     bitflip_her_dqn_config.policy.cuda = False\n#     try:\n#         bitflip_dqn_main(bitflip_her_dqn_config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_collaq():\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/entry/tests/test_serial_entry.py\n# --------------------------------------------------\n#     config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n#     config[0].policy.collect.discount_factor = 0.9\n#     config[0].policy.collect.nstep = 3\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# def test_impala():\n#     config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n#     config[0].policy.learn.update_per_collect = 1\n#     try:\n#         serial_pipeline(config, seed=0, max_iterations=1)\n#     except Exception:\n#         assert False, \"pipeline fail\"\n# \n# \n# @pytest.mark.unittest\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n_config, cooperative_navigation_wqmix_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_vdn_config, cooperative_navigation_vdn_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_coma_config, cooperative_navigation_coma_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_collaq_config, cooperative_navigation_collaq_create_config  # noqa\nfrom dizoo.multiagent_particle.config import cooperative_navigation_atoc_config, cooperative_navigation_atoc_create_config  # noqa\nfrom dizoo.league_demo.league_demo_ppo_config import league_demo_ppo_config\nfrom dizoo.league_demo.selfplay_demo_ppo_main import main as selfplay_main\nfrom dizoo.league_demo.league_demo_ppo_main import main as league_main\nfrom dizoo.classic_control.pendulum.config.pendulum_sac_data_generation_default_config import pendulum_sac_data_genearation_default_config, pendulum_sac_data_genearation_default_create_config  # noqa\nfrom dizoo.classic_control.pendulum.config.pendulum_cql_config import pendulum_cql_default_config, pendulum_cql_default_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_qrdqn_generation_data_config import cartpole_qrdqn_generation_data_config, cartpole_qrdqn_generation_data_create_config  # noqa\nfrom dizoo.classic_control.cartpole.config.cartpole_cql_config import cartpole_discrete_cql_config, cartpole_discrete_cql_create_config  # noqa\n\nwith open(\"./algo_record.log\", \"w+\") as f:\n    f.write(\"ALGO TEST STARTS\\n\")\n\n\n@pytest.mark.algotest\ndef test_dqn():\n    config = [deepcopy(cartpole_dqn_config), deepcopy(cartpole_dqn_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"1. dqn\\n\")\n\n\n@pytest.mark.algotest\ndef test_ddpg():\n    config = [deepcopy(pendulum_ddpg_config), deepcopy(pendulum_ddpg_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"2. ddpg\\n\")\n\n\n@pytest.mark.algotest\ndef test_td3():\n    config = [deepcopy(pendulum_td3_config), deepcopy(pendulum_td3_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"3. td3\\n\")\n\n\n@pytest.mark.algotest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"4. a2c\\n\")\n\n\n@pytest.mark.algotest\ndef test_rainbow():\n    config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"5. rainbow\\n\")\n\n\n@pytest.mark.algotest\ndef test_ppo():\n    config = [deepcopy(cartpole_ppo_config), deepcopy(cartpole_ppo_create_config)]\n    try:\n        ppo_main(config[0], seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"6. ppo\\n\")\n\n\n# @pytest.mark.algotest\ndef test_collaq():\n    config = [deepcopy(cooperative_navigation_collaq_config), deepcopy(cooperative_navigation_collaq_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"7. collaq\\n\")\n\n\n# @pytest.mark.algotest\ndef test_coma():\n    config = [deepcopy(cooperative_navigation_coma_config), deepcopy(cooperative_navigation_coma_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"8. coma\\n\")\n\n\n@pytest.mark.algotest\ndef test_sac():\n    config = [deepcopy(pendulum_sac_config), deepcopy(pendulum_sac_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"9. sac\\n\")\n\n\n@pytest.mark.algotest\ndef test_c51():\n    config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"10. c51\\n\")\n\n\n@pytest.mark.algotest\ndef test_r2d2():\n    config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"11. r2d2\\n\")\n\n\n@pytest.mark.algotest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"12. a2c with nstep return\\n\")\n\n\n# @pytest.mark.algotest", "completion": "def test_vdn():\n    config = [deepcopy(cooperative_navigation_vdn_config), deepcopy(cooperative_navigation_vdn_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"13. vdn\\n\")\n\n\n@pytest.mark.algotest\ndef test_atoc():\n    config = [deepcopy(cooperative_navigation_atoc_config), deepcopy(cooperative_navigation_atoc_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"14. atoc\\n\")\n\n\n@pytest.mark.algotest\ndef test_wqmix():\n    config = [deepcopy(cooperative_navigation_wqmix_config), deepcopy(cooperative_navigation_wqmix_create_config)]\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"15. wqmix\\n\")\n\n\n@pytest.mark.algotest\ndef test_com", "metadata": {"task_id": "opendilab_ACE/83", "ground_truth": "def test_atoc():", "fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "context_start_lineno": 32, "line_no": 185, "query_window": {"context": "        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"11. r2d2\\n\")\n\n\n@pytest.mark.algotest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0)\n    except Exception:\n        assert False, \"pipeline fail\"\n    with open(\"./algo_record.log\", \"a+\") as f:\n        f.write(\"12. a2c with nstep return\\n\")\n\n\n# @pytest.mark.algotest", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry_algo.py"], "line_no": 185, "task_id": "opendilab_ACE/83", "start_line_no": 165, "end_line_no": 185, "window_size": 20, "context_start_lineno": 32, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.64}, {"context": "    config[0].policy.learn.nstep_return = config[0].policy.collect.nstep_return = True\n    config[0].policy.collect.discount_factor = 0.9\n    config[0].policy.collect.nstep = 3\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_impala():\n    config = [deepcopy(cartpole_impala_config), deepcopy(cartpole_impala_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5882352941176471}, {"context": "    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_r2d2():\n    config = [deepcopy(cartpole_r2d2_config), deepcopy(cartpole_r2d2_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c_with_nstep_return():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5742574257425742}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_rainbow():\n    config = [deepcopy(cartpole_rainbow_config), deepcopy(cartpole_rainbow_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5196078431372549}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_iqn():\n    config = [deepcopy(cartpole_iqn_config), deepcopy(cartpole_iqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_c51():\n    config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5098039215686274}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_td3():\n    config = [deepcopy(pendulum_td3_config), deepcopy(pendulum_td3_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_a2c():\n    config = [deepcopy(cartpole_a2c_config), deepcopy(cartpole_a2c_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5096153846153846}, {"context": "        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_c51():\n    config = [deepcopy(cartpole_c51_config), deepcopy(cartpole_c51_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:\n        serial_pipeline(config, seed=0, max_iterations=1)\n    except Exception:\n        assert False, \"pipeline fail\"\n\n\n@pytest.mark.unittest\ndef test_qrdqn():\n    config = [deepcopy(cartpole_qrdqn_config), deepcopy(cartpole_qrdqn_create_config)]\n    config[0].policy.learn.update_per_collect = 1\n    try:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "entry", "tests", "test_serial_entry.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.5048543689320388}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#       with self._lock:\n#         trial_protos = (\n#             self._owners[resource.owner_id]\n#             .studies[resource.study_id]\n#             .trial_protos\n#         )\n#         if resource.trial_id not in trial_protos:\n#           raise custom_errors.NotFoundError(\n#               'Trial %s does not exist.' % trial.name\n#           )\n#         trial_protos[resource.trial_id] = copy.deepcopy(trial)\n#       return resource\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not update Trial with name:', resource.name\n#       ) from err\n# \n#   def list_trials(self, study_name: str) -> List[study_pb2.Trial]:\n#     resource = resources.StudyResource.from_name(study_name)\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#         trial_protos[resource.trial_id] = copy.deepcopy(trial)\n#       return resource\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not update Trial with name:', resource.name\n#       ) from err\n# \n#   def list_trials(self, study_name: str) -> List[study_pb2.Trial]:\n#     resource = resources.StudyResource.from_name(study_name)\n#     try:\n#       with self._lock:\n#         return copy.deepcopy(\n#             list(\n#                 self._owners[resource.owner_id]\n#                 .studies[resource.study_id]\n#                 .trial_protos.values()\n#             )\n#         )\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#             .trial_protos[resource.trial_id]\n#         )\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not get Trial with name:', resource.name\n#       ) from err\n# \n#   def update_trial(self, trial: study_pb2.Trial) -> resources.TrialResource:\n#     resource = resources.TrialResource.from_name(trial.name)\n#     try:\n#       with self._lock:\n#         trial_protos = (\n#             self._owners[resource.owner_id]\n#             .studies[resource.study_id]\n#             .trial_protos\n#         )\n#         if resource.trial_id not in trial_protos:\n#           raise custom_errors.NotFoundError(\n#               'Trial %s does not exist.' % trial.name\n#           )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#         trial_protos[resource.trial_id] = copy.deepcopy(trial)\n#     return resource\n# \n#   def get_trial(self, trial_name: str) -> study_pb2.Trial:\n#     resource = resources.TrialResource.from_name(trial_name)\n#     try:\n#       with self._lock:\n#         return copy.deepcopy(\n#             self._owners[resource.owner_id]\n#             .studies[resource.study_id]\n#             .trial_protos[resource.trial_id]\n#         )\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not get Trial with name:', resource.name\n#       ) from err\n# \n#   def update_trial(self, trial: study_pb2.Trial) -> resources.TrialResource:\n#     resource = resources.TrialResource.from_name(trial.name)\n#     try:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#       with self._lock:\n#         return copy.deepcopy(\n#             self._owners[resource.owner_id]\n#             .studies[resource.study_id]\n#             .study_proto\n#         )\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not get Study with name:', resource.name\n#       ) from err\n# \n#   def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n#     resource = resources.StudyResource.from_name(study.name)\n#     try:\n#       with self._lock:\n#         self._owners[resource.owner_id].studies[\n#             resource.study_id\n#         ].study_proto.CopyFrom(study)\n#       return resource\n#     except KeyError as err:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n# \n#   def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n#     resource = resources.StudyResource.from_name(study.name)\n#     try:\n#       with self._lock:\n#         self._owners[resource.owner_id].studies[\n#             resource.study_id\n#         ].study_proto.CopyFrom(study)\n#       return resource\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Could not update Study with name:', resource.name\n#       ) from err\n# \n#   def delete_study(self, study_name: str) -> None:\n#     resource = resources.StudyResource.from_name(study_name)\n#     try:\n#       with self._lock:\n#         del self._owners[resource.owner_id].studies[resource.study_id]\n#     except KeyError as err:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/service/datastore.py\n# --------------------------------------------------\n#       raise custom_errors.NotFoundError(\n#           'Could not update Study with name:', resource.name\n#       ) from err\n# \n#   def delete_study(self, study_name: str) -> None:\n#     resource = resources.StudyResource.from_name(study_name)\n#     try:\n#       with self._lock:\n#         del self._owners[resource.owner_id].studies[resource.study_id]\n#     except KeyError as err:\n#       raise custom_errors.NotFoundError(\n#           'Study does not exist:', study_name\n#       ) from err\n# \n#   def list_studies(self, owner_name: str) -> List[study_pb2.Study]:\n#     resource = resources.OwnerResource.from_name(owner_name)\n#     try:\n#       with self._lock:\n#         study_nodes = list(self._owners[resource.owner_id].studies.values())\n#         return copy.deepcopy(\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n# Copyright 2023 Google LLC.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import annotations\n\n\"\"\"Implementation of SQL Datastore.\"\"\"\nimport collections\nimport threading\nfrom typing import Callable, DefaultDict, Iterable, List, Optional\nfrom absl import logging\n\nimport sqlalchemy as sqla\n\nfrom vizier.service import custom_errors\nfrom vizier.service import datastore\nfrom vizier.service import key_value_pb2\nfrom vizier.service import resources\nfrom vizier.service import study_pb2\nfrom vizier.service import vizier_oss_pb2\nfrom google.longrunning import operations_pb2\n\n\n# TODO: Consider using ORM API (when fixed) to reduce code length.\nclass SQLDataStore(datastore.DataStore):\n  \"\"\"SQL Datastore.\"\"\"\n\n  def __init__(self, engine):\n    self._engine = engine\n    self._connection = self._engine.connect()\n    self._root_metadata = sqla.MetaData()\n    self._owners_table = sqla.Table(\n        'owners',\n        self._root_metadata,\n        sqla.Column('owner_name', sqla.String, primary_key=True),\n    )\n    self._studies_table = sqla.Table(\n        'studies',\n        self._root_metadata,\n        sqla.Column('study_name', sqla.String, primary_key=True),\n        sqla.Column('owner_id', sqla.String),\n        sqla.Column('study_id', sqla.String),\n        sqla.Column('serialized_study', sqla.String),\n    )\n    self._trials_table = sqla.Table(\n        'trials',\n        self._root_metadata,\n        sqla.Column('trial_name', sqla.String, primary_key=True),\n        sqla.Column('owner_id', sqla.String),\n        sqla.Column('study_id', sqla.String),\n        sqla.Column('trial_id', sqla.INTEGER),\n        sqla.Column('serialized_trial', sqla.String),\n    )\n    self._suggestion_operations_table = sqla.Table(\n        'suggestion_operations',\n        self._root_metadata,\n        sqla.Column('operation_name', sqla.String, primary_key=True),\n        sqla.Column('owner_id', sqla.String),\n        sqla.Column('study_id', sqla.String),\n        sqla.Column('client_id', sqla.String),\n        sqla.Column('operation_number', sqla.INTEGER),\n        sqla.Column('serialized_op', sqla.String),\n    )\n    self._early_stopping_operations_table = sqla.Table(\n        'early_stopping_operations',\n        self._root_metadata,\n        sqla.Column('operation_name', sqla.String, primary_key=True),\n        sqla.Column('owner_id', sqla.String),\n        sqla.Column('study_id', sqla.String),\n        sqla.Column('trial_id', sqla.INTEGER),\n        sqla.Column('serialized_op', sqla.String),\n    )\n    # This lock is meant to lock `execute()` calls for database types which\n    # don't support multi-threading, like SQLite.\n    self._lock = threading.Lock()\n    self._root_metadata.create_all(self._engine)\n\n  def create_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    study_resource = resources.StudyResource.from_name(study.name)\n    owner_name = study_resource.owner_resource.name\n    owner_query = self._owners_table.insert().values(owner_name=owner_name)\n    study_query = self._studies_table.insert().values(\n        study_name=study.name,\n        owner_id=study_resource.owner_id,\n        study_id=study_resource.study_id,\n        serialized_study=study.SerializeToString(),\n    )\n\n    with self._lock:\n      try:\n        self._connection.execute(owner_query)\n      except sqla.exc.IntegrityError:\n        logging.info('Owner with name %s currently exists.', owner_name)\n      try:\n        self._connection.execute(study_query)\n        return study_resource\n      except sqla.exc.IntegrityError as integrity_error:\n        raise custom_errors.AlreadyExistsError(\n            'Study with name %s already exists.' % study.name\n        ) from integrity_error\n\n  def load_study(self, study_name: str) -> study_pb2.Study:\n    query = sqla.select([self._studies_table])\n    query = query.where(self._studies_table.c.study_name == study_name)\n\n    with self._lock:\n      result = self._connection.execute(query)\n\n    row = result.fetchone()\n    if not row:\n      raise custom_errors.NotFoundError(\n          'Failed to find study name: %s' % study_name\n      )\n    return study_pb2.Study.FromString(row['serialized_study'])\n\n  def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    study_resource = resources.StudyResource.from_name(study.name)\n    exists_query = sqla.exists(\n        sqla.select([self._studies_table]).where(", "completion": "self._studies_table.c.study_name == study.name)\n    update_query = self._studies_table.update().where(\n        self._studies_table.c.study_name == study.name\n    ).values(serialized_study=study.SerializeToString())\n\n    with self._lock:\n      exists = self._connection.execute(exists_query).scalar()\n      if not exists:\n        raise custom_errors.NotFoundError(\n            'Could not update Study with name:', study.name\n        )\n      self._connection.execute(update_query)\n      return study_resource\n\n  def delete_study(self, study_name: str) -> None:\n    delete_query = self._studies_table.delete().where(\n        self._studies_table.c.study_name == study_name\n    )\n\n    with self._lock:\n      result = self._connection.execute(delete_query)\n      if result.rowcount == 0:\n        raise custom_errors.NotFoundError(\n            'Study does not exist:', study_name\n        )\n\n  def list_studies(self, owner_name: str) -> List[study_pb2.Study]:\n    query = sqla.select([self._studies_table])\n    query = query.where(self._studies_table.c.owner_id == owner_name)\n\n    with self._lock:\n", "metadata": {"task_id": "google_vizier/106", "ground_truth": "            self._studies_table.c.study_name == study.name", "fpath_tuple": ["google_vizier", "vizier", "service", "sql_datastore.py"], "context_start_lineno": 0, "line_no": 129, "query_window": {"context": "        ) from integrity_error\n\n  def load_study(self, study_name: str) -> study_pb2.Study:\n    query = sqla.select([self._studies_table])\n    query = query.where(self._studies_table.c.study_name == study_name)\n\n    with self._lock:\n      result = self._connection.execute(query)\n\n    row = result.fetchone()\n    if not row:\n      raise custom_errors.NotFoundError(\n          'Failed to find study name: %s' % study_name\n      )\n    return study_pb2.Study.FromString(row['serialized_study'])\n\n  def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    study_resource = resources.StudyResource.from_name(study.name)\n    exists_query = sqla.exists(\n        sqla.select([self._studies_table]).where(", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "service", "sql_datastore.py"], "line_no": 129, "task_id": "google_vizier/106", "start_line_no": 109, "end_line_no": 129, "window_size": 20, "context_start_lineno": 0, "repo": "google_vizier"}}, "top_k_context": [{"context": "\n  def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    resource = resources.StudyResource.from_name(study.name)\n    try:\n      with self._lock:\n        self._owners[resource.owner_id].studies[\n            resource.study_id\n        ].study_proto.CopyFrom(study)\n      return resource\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not update Study with name:', resource.name\n      ) from err\n\n  def delete_study(self, study_name: str) -> None:\n    resource = resources.StudyResource.from_name(study_name)\n    try:\n      with self._lock:\n        del self._owners[resource.owner_id].studies[resource.study_id]\n    except KeyError as err:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 390, "start_line_no": 380, "end_line_no": 400, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.43636363636363634}, {"context": "      with self._lock:\n        return copy.deepcopy(\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .study_proto\n        )\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not get Study with name:', resource.name\n      ) from err\n\n  def update_study(self, study: study_pb2.Study) -> resources.StudyResource:\n    resource = resources.StudyResource.from_name(study.name)\n    try:\n      with self._lock:\n        self._owners[resource.owner_id].studies[\n            resource.study_id\n        ].study_proto.CopyFrom(study)\n      return resource\n    except KeyError as err:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.41964285714285715}, {"context": "          study_dict.update(temp_dict)\n        else:\n          raise custom_errors.AlreadyExistsError(\n              'Study with that name already exists.', study.name\n          )\n    return resource\n\n  def load_study(self, study_name: str) -> study_pb2.Study:\n    resource = resources.StudyResource.from_name(study_name)\n    try:\n      with self._lock:\n        return copy.deepcopy(\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .study_proto\n        )\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not get Study with name:', resource.name\n      ) from err", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 380, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4117647058823529}, {"context": "      trial_protos = (\n          self._owners[resource.owner_id]\n          .studies[resource.study_id]\n          .trial_protos\n      )\n      if resource.trial_id in trial_protos:\n        raise custom_errors.AlreadyExistsError(\n            'Trial %s already exists' % trial.name\n        )\n      else:\n        trial_protos[resource.trial_id] = copy.deepcopy(trial)\n    return resource\n\n  def get_trial(self, trial_name: str) -> study_pb2.Trial:\n    resource = resources.TrialResource.from_name(trial_name)\n    try:\n      with self._lock:\n        return copy.deepcopy(\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4107142857142857}, {"context": "        trial_protos[resource.trial_id] = copy.deepcopy(trial)\n    return resource\n\n  def get_trial(self, trial_name: str) -> study_pb2.Trial:\n    resource = resources.TrialResource.from_name(trial_name)\n    try:\n      with self._lock:\n        return copy.deepcopy(\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .trial_protos[resource.trial_id]\n        )\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not get Trial with name:', resource.name\n      ) from err\n\n  def update_trial(self, trial: study_pb2.Trial) -> resources.TrialResource:\n    resource = resources.TrialResource.from_name(trial.name)\n    try:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 440, "start_line_no": 430, "end_line_no": 450, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.40707964601769914}, {"context": "      with self._lock:\n        trial_protos = (\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .trial_protos\n        )\n        if resource.trial_id not in trial_protos:\n          raise custom_errors.NotFoundError(\n              'Trial %s does not exist.' % trial.name\n          )\n        trial_protos[resource.trial_id] = copy.deepcopy(trial)\n      return resource\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not update Trial with name:', resource.name\n      ) from err\n\n  def list_trials(self, study_name: str) -> List[study_pb2.Trial]:\n    resource = resources.StudyResource.from_name(study_name)\n    try:", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 460, "start_line_no": 450, "end_line_no": 470, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4065040650406504}, {"context": "            .trial_protos[resource.trial_id]\n        )\n    except KeyError as err:\n      raise custom_errors.NotFoundError(\n          'Could not get Trial with name:', resource.name\n      ) from err\n\n  def update_trial(self, trial: study_pb2.Trial) -> resources.TrialResource:\n    resource = resources.TrialResource.from_name(trial.name)\n    try:\n      with self._lock:\n        trial_protos = (\n            self._owners[resource.owner_id]\n            .studies[resource.study_id]\n            .trial_protos\n        )\n        if resource.trial_id not in trial_protos:\n          raise custom_errors.NotFoundError(\n              'Trial %s does not exist.' % trial.name\n          )", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "service", "datastore.py"], "line_no": 450, "start_line_no": 440, "end_line_no": 460, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.4051724137931034}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         jnp.ndarray\n#             The estimated variance for each output.\n#         \"\"\"\n#         return super().variance(outputs, calibrated, **kwargs)\n# \n#     def std(\n#         self,\n#         outputs: jnp.ndarray,\n#         variances: Optional[jnp.ndarray] = None,\n#         calibrated: bool = True,\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the standard deviation of the one-hot encoded target variable given the output, with respect to the\n#         predictive distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         variances: Optional[jnp.ndarray]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n#         jnp.ndarray\n#             The estimated quantiles for each output.\n#         \"\"\"\n#         if calibrated:\n#             self._check_calibrated()\n#             state = self.state.get()\n#             outputs = self.output_calib_manager.apply(\n#                 params=state.params[\"output_calibrator\"],\n#                 outputs=outputs,\n#                 mutable=state.mutable[\"output_calibrator\"],\n#             )\n#         return self.prob_output_layer.quantile(q, outputs, n_target_samples, rng)\n# \n#     def credible_interval(\n#         self,\n#         outputs: Array,\n#         n_target_samples: int = 30,\n#         error: float = 0.05,\n#         interval_type: str = \"two-tailed\",\n#         rng: Optional[PRNGKeyArray] = None,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/regression.py\n# --------------------------------------------------\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated credible interval for each output.\n#         \"\"\"\n#         if calibrated:\n#             self._check_calibrated()\n#             state = self.state.get()\n#             outputs = self.output_calib_manager.apply(\n#                 params=state.params[\"output_calibrator\"],\n#                 outputs=outputs,\n#                 mutable=state.mutable[\"output_calibrator\"],\n#             )\n#         return self.prob_output_layer.credible_interval(\n#             outputs, n_target_samples, error, interval_type, rng\n#         )\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         \"\"\"\n#         return super().mean(outputs, calibrated, **kwargs)\n# \n#     def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mode for each output.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mode for each output.\n#         \"\"\"\n#         return super().mode(outputs, calibrated, **kwargs)\n# \n#     def variance(\n#         self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         \"\"\"\n#         return super().mode(outputs, calibrated, **kwargs)\n# \n#     def variance(\n#         self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n#     ) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         outputs : Array\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated mean for each output.\n#         \"\"\"\n#         return super().mean(outputs, calibrated, **kwargs)\n# \n#     def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n#         \"\"\"\n#         Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n#         distribution.\n# \n#         Parameters\n#         ----------\n# --------------------------------------------------\n# the below code fragment can be found in:\n# fortuna/calib_model/predictive/classification.py\n# --------------------------------------------------\n#         Parameters\n#         ----------\n#         outputs : jnp.ndarray\n#             Model outputs.\n#         calibrated : bool\n#             Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n#             model must have been calibrated beforehand.\n# \n#         Returns\n#         -------\n#         jnp.ndarray\n#             The estimated variance for each output.\n#         \"\"\"\n#         return super().variance(outputs, calibrated, **kwargs)\n# \n#     def std(\n#         self,\n#         outputs: jnp.ndarray,\n#         variances: Optional[jnp.ndarray] = None,\n#         calibrated: bool = True,\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\nimport abc\nfrom typing import Any, List, Optional, Tuple, Union\n\nimport jax.numpy as jnp\nfrom jax._src.prng import PRNGKeyArray\n\nfrom fortuna.output_calibrator.output_calib_manager.base import \\\n    OutputCalibManager\nfrom fortuna.prob_output_layer.base import ProbOutputLayer\nfrom fortuna.typing import Array, CalibMutable, CalibParams\nfrom fortuna.utils.random import WithRNG\n\n\nclass Predictive(WithRNG, abc.ABC):\n    def __init__(\n        self,\n        output_calib_manager: OutputCalibManager,\n        prob_output_layer: ProbOutputLayer,\n    ):\n        r\"\"\"\n        Abstract predictive distribution. It characterizes the distribution of the target variable given the\n        calibrated outputs. It can be see as :math:`p(y|\\omega)`, where :math:`y` is a target variable and\n        :math:`\\omega` a calibrated output.\n        \"\"\"\n        self.output_calib_manager = output_calib_manager\n        self.prob_output_layer = prob_output_layer\n        self.state = None\n\n    def log_prob(\n        self, outputs: Array, targets: Array, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Evaluate the log-probability density function (a.k.a. log-pdf) given the outputs and target data.\n\n        Parameters\n        ----------\n        outputs : Array\n            Calibrated outputs.\n        targets : Array\n            Target data points.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            An evaluation of the log-pdf for each data point.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.log_prob(outputs, targets, **kwargs)\n\n    def sample(\n        self,\n        n_target_samples: int,\n        outputs: Array,\n        rng: Optional[PRNGKeyArray] = None,\n        calibrated: bool = True,\n        **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Sample target variables for each outputs.\n\n        Parameters\n        ----------\n        n_target_samples: int\n            The number of target samples to draw for each of the outputs.\n        outputs : Array\n            Calibrated outputs.\n        rng : Optional[PRNGKeyArray]\n            A random number generator. If not passed, this will be taken from the attributes of this class.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            Samples of the target variable for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.sample(n_target_samples, outputs, rng, **kwargs)\n\n    def mean(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mean of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mean for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.mean(outputs, **kwargs)\n\n    def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mode of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mode for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.mode(outputs, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the", "completion": "model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated variance for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.variance(outputs, **kwargs)\n\n    def std(\n        self,\n        outputs: jnp.ndarray,\n        variances: Optional[jnp.ndarray] = None,\n        calibrated: bool = True,\n        **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the standard deviation of the target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        variances: Optional[jnp.ndarray]\n            The estimated variances for each output. If not provided, they will be computed using the `variance` method.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n", "metadata": {"task_id": "awslabs_fortuna/98", "ground_truth": "            model must have been calibrated beforehand.", "fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "base.py"], "context_start_lineno": 0, "line_no": 163, "query_window": {"context": "            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.mode(outputs, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the target variable given the output, with respect to the predictive distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the", "metadata": {"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "base.py"], "line_no": 163, "task_id": "awslabs_fortuna/98", "start_line_no": 143, "end_line_no": 163, "window_size": 20, "context_start_lineno": 0, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "        \"\"\"\n        return super().mode(outputs, calibrated, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 70, "start_line_no": 60, "end_line_no": 80, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.65}, {"context": "            prob_output_layer=prob_output_layer,\n        )\n\n    def mean(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mean of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mean for each output.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 30, "start_line_no": 20, "end_line_no": 40, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6132075471698113}, {"context": "        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mode for each output.\n        \"\"\"\n        return super().mode(outputs, calibrated, **kwargs)\n\n    def variance(\n        self, outputs: jnp.ndarray, calibrated: bool = True, **kwargs\n    ) -> jnp.ndarray:\n        \"\"\"\n        Estimate the variance of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 60, "start_line_no": 50, "end_line_no": 70, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5849056603773585}, {"context": "        \"\"\"\n        return super().mean(outputs, calibrated, **kwargs)\n\n    def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------\n        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mode for each output.", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5648148148148148}, {"context": "        outputs : Array\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated mean for each output.\n        \"\"\"\n        return super().mean(outputs, calibrated, **kwargs)\n\n    def mode(self, outputs: Array, calibrated: bool = True, **kwargs) -> jnp.ndarray:\n        \"\"\"\n        Estimate the mode of the one-hot encoded target variable given the output, with respect to the predictive\n        distribution.\n\n        Parameters\n        ----------", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 40, "start_line_no": 30, "end_line_no": 50, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.5596330275229358}, {"context": "            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated credible interval for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],\n            )\n        return self.prob_output_layer.credible_interval(\n            outputs, n_target_samples, error, interval_type, rng\n        )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 109, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.543859649122807}, {"context": "        n_target_samples: Optional[int]\n            Number of target samples to draw when computing quantiles.\n        rng: Optional[PRNGKeyArray]\n            A random number generator.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated quantiles for each output.\n        \"\"\"\n        if calibrated:\n            self._check_calibrated()\n            state = self.state.get()\n            outputs = self.output_calib_manager.apply(\n                params=state.params[\"output_calibrator\"],\n                outputs=outputs,\n                mutable=state.mutable[\"output_calibrator\"],", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "regression.py"], "line_no": 50, "start_line_no": 40, "end_line_no": 60, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4959349593495935}, {"context": "        Parameters\n        ----------\n        outputs : jnp.ndarray\n            Model outputs.\n        calibrated : bool\n            Whether the outputs should be calibrated when computing this method. If `calibrated` is set to True, the\n            model must have been calibrated beforehand.\n\n        Returns\n        -------\n        jnp.ndarray\n            The estimated variance for each output.\n        \"\"\"\n        return super().variance(outputs, calibrated, **kwargs)\n\n    def std(\n        self,\n        outputs: jnp.ndarray,\n        variances: Optional[jnp.ndarray] = None,\n        calibrated: bool = True,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "fortuna", "calib_model", "predictive", "classification.py"], "line_no": 80, "start_line_no": 70, "end_line_no": 90, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.4727272727272727}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#         Bounds and feasible_values, if provided, must consist of\n#         elements of the same type.\n#       TypeError: If children's matching_parent_values are not compatible with\n#         the ParameterConfig being created.\n#     \"\"\"\n#     if not name:\n#       raise ValueError('Parameter name cannot be empty.')\n# \n#     if bool(feasible_values) == bool(bounds):\n#       raise ValueError(\n#           'While creating Parameter with name={}: exactly one of '\n#           '\"feasible_values\" or \"bounds\" must be provided, but given '\n#           'feasible_values={} and bounds={}.'.format(name, feasible_values,\n#                                                      bounds))\n#     if feasible_values:\n#       if len(set(feasible_values)) != len(feasible_values):\n#         counter = collections.Counter(feasible_values)\n#         duplicate_dict = {k: v for k, v in counter.items() if v > 1}\n#         raise ValueError(\n#             'Feasible values cannot have duplicates: {}'.format(duplicate_dict))\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#       bounds: REQUIRED for INTEGER or DOUBLE type. Specifies (min, max). The\n#         type of (min, max) determines the created ParameterConfig's type.\n#       feasible_values: REQUIRED for DISCRETE or CATEGORICAL type. The elements'\n#         type determines the created ParameterConfig's type.\n#       children: sequence of tuples formatted as: (matching_parent_values,\n#         ParameterConfig). ONLY THE TYPES ARE VALIDATED. If the child\n#         ParameterConfig protos already have parent values set, they will be\n#         overridden by the provided matching_parent_values.\n#       fidelity_config: Fidelity config.  NOT VALIDATED.\n#       scale_type: Scaling to be applied. NOT VALIDATED.\n#       default_value: A default value for the Parameter.\n#       external_type: An annotation indicating the type this parameter should be\n#         cast to.\n# \n#     Returns:\n#       A ParameterConfig object which wraps a partially validated proto.\n# \n#     Raises:\n#       ValueError: Exactly one of feasible_values and bounds must be convertible\n#         to Boolean true. Bounds and numeric feasible_values must be finite.\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/oss/study_config.py\n# --------------------------------------------------\n#       raise ValueError('Invalid trial for this search space: failed to convert '\n#                        'all trial parameters: {}'.format(pytrial))\n# \n#     # Combine multi-dimensional parameter values to a list of values.\n#     trial_final_values: Dict[str, ParameterValueSequence] = {}\n#     # multi_dim_params: Dict[str, List[Tuple[int, ParameterValueSequence]]]\n#     multi_dim_params = collections.defaultdict(list)\n#     for name in trial_external_values:\n#       base_index = (\n#           vz.SearchSpaceSelector.parse_multi_dimensional_parameter_name(name)\n#       )\n#       if base_index is None:\n#         trial_final_values[name] = trial_external_values[name]\n#       else:\n#         base_name, index = base_index\n#         multi_dim_params[base_name].append((index, trial_external_values[name]))\n#     for name in multi_dim_params:\n#       multi_dim_params[name].sort(key=lambda x: x[0])\n#       trial_final_values[name] = [x[1] for x in multi_dim_params[name]]\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#       default_value: A default value for the Parameter.\n#       external_type: An annotation indicating the type this parameter should be\n#         cast to.\n# \n#     Returns:\n#       A ParameterConfig object which wraps a partially validated proto.\n# \n#     Raises:\n#       ValueError: Exactly one of feasible_values and bounds must be convertible\n#         to Boolean true. Bounds and numeric feasible_values must be finite.\n#         Bounds and feasible_values, if provided, must consist of\n#         elements of the same type.\n#       TypeError: If children's matching_parent_values are not compatible with\n#         the ParameterConfig being created.\n#     \"\"\"\n#     if not name:\n#       raise ValueError('Parameter name cannot be empty.')\n# \n#     if bool(feasible_values) == bool(bounds):\n#       raise ValueError(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#       if not math.isclose(default_value, default_int_value):\n#         raise ValueError('default_value for an INTEGER parameter should be an '\n#                          'integer, got float: [{}]'.format(default_value))\n#       return default_int_value\n#   elif (param_type == ParameterType.CATEGORICAL and\n#         isinstance(default_value, str)):\n#     return default_value\n#   raise ValueError(\n#       'default_value has an incorrect type. ParameterType has type {}, '\n#       'but default_value has type {}'.format(param_type.name,\n#                                              type(default_value)))\n# \n# \n# #######################\n# # Experimental features\n# #######################\n# class FidelityMode(enum.Enum):\n#   \"\"\"Decides how the fidelity config should be interpreated.\n# \n#   SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower\n# --------------------------------------------------\n# the below code fragment can be found in:\n# vizier/_src/pyvizier/shared/parameter_config.py\n# --------------------------------------------------\n#                                              type(default_value)))\n# \n# \n# #######################\n# # Experimental features\n# #######################\n# class FidelityMode(enum.Enum):\n#   \"\"\"Decides how the fidelity config should be interpreated.\n# \n#   SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower\n#     fidelity measurement. Currently, no algorithms can take advatange of it, and\n#     Vizier behaves exactly like NON_SEQUENTIAL case. This is for tracking\n#     purposes only.\n# \n#   NOT_SEQUENTIAL: Each fidelity is separately measured. Example: Fidelity\n#     is the fraction of dataset to train on.\n# \n#   STEPS: Fidelity determines the maximum value for Measurement.steps reported\n#     to Vizier. There is one-to-one correspondence between steps and fidelity.\n#     A high fideltiy Trial's measurements contain lower fidelity evaluations.\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n    try:\n      self.type.assert_correct_type(value)\n    except TypeError as e:\n      raise TypeError(\n          f'Parameter {self.name} is not compatible with value: {value}') from e\n\n    # TODO: We should be able to directly use \"value\" without\n    # casting to the internal type.\n    value = trial.ParameterValue(value)\n    if self.type == ParameterType.DOUBLE:\n      self._assert_bounds(value.as_float)\n    elif self.type == ParameterType.INTEGER:\n      self._assert_bounds(value.as_int)\n    elif self.type == ParameterType.DISCRETE:\n      self._assert_in_feasible_values(value.as_float)\n    elif self.type == ParameterType.CATEGORICAL:\n      self._assert_in_feasible_values(value.as_str)\n    else:\n      raise RuntimeError(\n          f'Parameter {self.name} has unknown parameter type: {self.type}')\n\n  def get_subspace_deepcopy(self, value: ParameterValueTypes) -> 'SearchSpace':\n    \"\"\"Get a deep copy of the subspace.\n\n    Validates the feasibility of value.\n\n    Args:\n      value: Must be a feasible value per this parameter config.\n\n    Returns:\n      Subspace conditioned on the value. Note that an empty search space is\n      returned if the parameter config is continuous and thus cannot have\n      a subspace.\n    \"\"\"\n    if not math.isfinite(self.num_feasible_values):\n      return SearchSpace()\n    value = trial.ParameterValue(value).cast_as_internal(self.type)\n    self._assert_feasible(value)\n    return copy.deepcopy(self._children.get(value, SearchSpace()))\n\n  def subspace(self, value: ParameterValueTypes) -> 'SearchSpace':\n    \"\"\"Selects the subspace for a specified parent value.\"\"\"\n    if not math.isfinite(self.num_feasible_values):\n      raise TypeError('DOUBLE type cannot have child parameters')\n\n    # TODO: We should be able to directly use \"value\".\n    value = trial.ParameterValue(value).cast_as_internal(self.type)\n    self._assert_feasible(value)\n    if value not in self._children:\n      self._children[value] = SearchSpace(parent_values=[value])\n    return self._children[value]\n\n\nParameterConfigOrConfigs = Union[ParameterConfig, Collection[ParameterConfig]]\n\n\n@attr.define(init=False)\nclass ParameterConfigSelector(Sized):\n  \"\"\"Holds a reference to ParameterConfigs.\"\"\"\n\n  # Selected configs.\n  _selected: tuple[ParameterConfig] = attr.field(init=True)\n\n  def __len__(self) -> int:\n    return len(self._selected)\n\n  def __init__(self, selected: ParameterConfigOrConfigs):\n    if isinstance(selected, Collection):\n      self.__attrs_init__(tuple(selected))\n    else:\n      self.__attrs_init__(tuple([selected]))\n\n  def select_values(self,\n                    values: MonotypeParameterSequence) -> 'SearchSpaceSelector':\n    \"\"\"Select values.\"\"\"\n    values = tuple(values)\n\n    for value in values:\n      for config in self._selected:\n        if not config.contains(value):\n          # Validate first so we don't create a lot of unnecessary empty\n          # search space upon failure.\n          raise ValueError(f'{value} is not feasible in {self}')\n\n    spaces = []\n    for value in values:\n      for config in self._selected:\n        spaces.append(config.subspace(value))\n    return SearchSpaceSelector(spaces)\n\n\nclass InvalidParameterError(Exception):\n  \"\"\"Error thrown when parameter values are invalid.\"\"\"\n\n\n################### Main Classes ###################\nSearchSpaceOrSpaces = Union['SearchSpace', Collection['SearchSpace']]\n\n\n@attr.define(init=False)\nclass SearchSpaceSelector:\n  \"\"\"Holds a reference to (sub) spaces.\"\"\"\n\n  # Selected (sub)-spaces.\n  # TODO: Consider switching the order of SearchSpaceSelector and\n  # SearchSpace.\n  _selected: tuple['SearchSpace'] = attr.field(init=True)\n\n  def __len__(self) -> int:\n    return len(self._selected)\n\n  def __init__(self, selected: SearchSpaceOrSpaces):\n    if isinstance(selected, Collection):\n      self.__attrs_init__(tuple(selected))\n    else:\n      self.__attrs_init__(tuple([selected]))\n\n  def add_float_param(self,\n                      name: str,\n                      min_value: float,\n                      max_value: float,\n                      *,\n                      default_value: Optional[float] = None,\n                      scale_type: Optional[ScaleType] = ScaleType.LINEAR,\n                      index: Optional[int] = None) -> 'ParameterConfigSelector':\n    \"\"\"Adds floating point parameter config(s) to the selected search space(s).\n\n    Args:\n      name: The parameter's name. Cannot be empty.\n      min_value: Inclusive lower bound for the parameter.\n      max_value: Inclusive upper bound for the parameter.\n      default_value: A default value for the Parameter.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      index: Specifies the multi-dimensional index for this parameter. E.g. if\n        name='rate' and index=0, then a single ParameterConfig with name\n        'rate[0]' is added. `index` should be >= 0.\n\n    Returns:\n      SearchSpaceSelector(s) for the newly added parameter(s):\n      One SearchSpaceSelector if one parameter was added, or a list of\n      SearchSpaceSelector if multiple parameters were added.\n\n    Raises:\n      ValueError: If `index` is invalid (e.g. negative).\n    \"\"\"\n    bounds = (float(min_value), float(max_value))\n    param_names = self._get_parameter_names_to_create(name=name, index=index)\n\n    new_params = []\n    for param_name in param_names:\n      new_pc = ParameterConfig.factory(\n          name=param_name,\n          bounds=bounds,\n          scale_type=scale_type,\n          default_value=default_value)\n      new_params.append(new_pc)\n    return self._add_parameters(new_params)\n\n  def add_int_param(\n      self,\n      name: str,\n      min_value: int,\n      max_value: int,\n      *,\n      default_value: Optional[int] = None,\n      scale_type: Optional[ScaleType] = None,\n      index: Optional[int] = None,\n      experimental_fidelity_config: Optional[FidelityConfig] = None,\n  ) -> 'ParameterConfigSelector':\n    \"\"\"Adds integer parameter config(s) to the selected search space(s).\n\n    Args:\n      name: The parameter's name. Cannot be empty.\n      min_value: Inclusive lower bound for the parameter.\n      max_value: Inclusive upper bound for the parameter.\n      default_value: A default value for the Parameter.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      index: Specifies the multi-dimensional index for this parameter. E.g. if\n        name='hidden_units' and index=0, then a single ParameterConfig with name\n        'hidden_units[0]' is added. `index` should be >= 0.\n      experimental_fidelity_config: EXPERIMENTAL. See FidelityConfig doc.\n\n    Returns:\n      ParameterConfigSelector for the newly added parameter(s).\n\n    Raises:\n      ValueError: If min_value or max_value are not integers.\n      ValueError: If `index` is invalid (e.g. negative).\n    \"\"\"\n    int_min_value = int(min_value)\n    if not math.isclose(min_value, int_min_value):\n      raise ValueError('min_value for an INTEGER parameter should be an integer'\n                       ', got: [{}]'.format(min_value))", "completion": "int_max_value = int(max_value)\n    if not math.isclose(max_value, int_max_value):\n      raise ValueError('max_value for an INTEGER parameter should be an integer'\n                       ', got: [{}]'.format(max_value))\n\n    bounds = (int_min_value, int_max_value)\n    param_names = self._get_parameter_names_to_create(name=name, index=index)\n\n    new_params = []\n    for param_name in param_names:\n      new_pc = ParameterConfig.factory(\n          name=param_name,\n          bounds=bounds,\n          scale_type=scale_type,\n          default_value=default_value,\n          fidelity_config=experimental_fidelity_config)\n      new_params.append(new_pc)\n    return self._add_parameters(new_params)\n\n  def add_discrete_param(\n      self,\n      name: str,\n      feasible_values: Sequence[Union[int, float]],\n      *,\n      default_value: Optional[Union[int, float]] = None,\n      index: Optional[int] = None,\n      experimental_fidelity_config: Optional[FidelityConfig] = None,\n  ) -> 'ParameterConfigSelector':\n    \"\"\"Adds discrete parameter config(s) to the selected search space(s).\n\n    Args:\n      name: The parameter's name. Cannot be empty.\n     ", "metadata": {"task_id": "google_vizier/165", "ground_truth": "    int_max_value = int(max_value)", "fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "context_start_lineno": 575, "line_no": 768, "query_window": {"context": "      min_value: Inclusive lower bound for the parameter.\n      max_value: Inclusive upper bound for the parameter.\n      default_value: A default value for the Parameter.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      index: Specifies the multi-dimensional index for this parameter. E.g. if\n        name='hidden_units' and index=0, then a single ParameterConfig with name\n        'hidden_units[0]' is added. `index` should be >= 0.\n      experimental_fidelity_config: EXPERIMENTAL. See FidelityConfig doc.\n\n    Returns:\n      ParameterConfigSelector for the newly added parameter(s).\n\n    Raises:\n      ValueError: If min_value or max_value are not integers.\n      ValueError: If `index` is invalid (e.g. negative).\n    \"\"\"\n    int_min_value = int(min_value)\n    if not math.isclose(min_value, int_min_value):\n      raise ValueError('min_value for an INTEGER parameter should be an integer'\n                       ', got: [{}]'.format(min_value))", "metadata": {"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 768, "task_id": "google_vizier/165", "start_line_no": 748, "end_line_no": 768, "window_size": 20, "context_start_lineno": 575, "repo": "google_vizier"}}, "top_k_context": [{"context": "      if not math.isclose(default_value, default_int_value):\n        raise ValueError('default_value for an INTEGER parameter should be an '\n                         'integer, got float: [{}]'.format(default_value))\n      return default_int_value\n  elif (param_type == ParameterType.CATEGORICAL and\n        isinstance(default_value, str)):\n    return default_value\n  raise ValueError(\n      'default_value has an incorrect type. ParameterType has type {}, '\n      'but default_value has type {}'.format(param_type.name,\n                                             type(default_value)))\n\n\n#######################\n# Experimental features\n#######################\nclass FidelityMode(enum.Enum):\n  \"\"\"Decides how the fidelity config should be interpreated.\n\n  SEQUENTIAL: A high fidelity measurement can be \"warm-started\" from a lower", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.29411764705882354}, {"context": "  if (param_type in (ParameterType.DOUBLE, ParameterType.DISCRETE) and\n      (isinstance(default_value, float) or isinstance(default_value, int))):\n    return float(default_value)\n  elif (param_type == ParameterType.INTEGER and\n        (isinstance(default_value, float) or isinstance(default_value, int))):\n    if isinstance(default_value, int):\n      return default_value\n    else:\n      # Check if the float rounds nicely.\n      default_int_value = round(default_value)\n      if not math.isclose(default_value, default_int_value):\n        raise ValueError('default_value for an INTEGER parameter should be an '\n                         'integer, got float: [{}]'.format(default_value))\n      return default_int_value\n  elif (param_type == ParameterType.CATEGORICAL and\n        isinstance(default_value, str)):\n    return default_value\n  raise ValueError(\n      'default_value has an incorrect type. ParameterType has type {}, '\n      'but default_value has type {}'.format(param_type.name,", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 100, "start_line_no": 90, "end_line_no": 110, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.28823529411764703}, {"context": "      bounds: REQUIRED for INTEGER or DOUBLE type. Specifies (min, max). The\n        type of (min, max) determines the created ParameterConfig's type.\n      feasible_values: REQUIRED for DISCRETE or CATEGORICAL type. The elements'\n        type determines the created ParameterConfig's type.\n      children: sequence of tuples formatted as: (matching_parent_values,\n        ParameterConfig). ONLY THE TYPES ARE VALIDATED. If the child\n        ParameterConfig protos already have parent values set, they will be\n        overridden by the provided matching_parent_values.\n      fidelity_config: Fidelity config.  NOT VALIDATED.\n      scale_type: Scaling to be applied. NOT VALIDATED.\n      default_value: A default value for the Parameter.\n      external_type: An annotation indicating the type this parameter should be\n        cast to.\n\n    Returns:\n      A ParameterConfig object which wraps a partially validated proto.\n\n    Raises:\n      ValueError: Exactly one of feasible_values and bounds must be convertible\n        to Boolean true. Bounds and numeric feasible_values must be finite.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 250, "start_line_no": 240, "end_line_no": 260, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.2669902912621359}, {"context": "      NOTE that the values in the dict may be a Sequence as opposed to a single\n      element.\n\n    Raises:\n      ValueError: If the trial parameters do not exist in this search space.\n      ValueError: If the trial contains duplicate parameters.\n    \"\"\"\n    trial_external_values: Dict[str, Union[float, int, str, bool]] = (\n        self._trial_to_external_values(pytrial))\n    if len(trial_external_values) != len(pytrial.parameters):\n      raise ValueError('Invalid trial for this search space: failed to convert '\n                       'all trial parameters: {}'.format(pytrial))\n\n    # Combine multi-dimensional parameter values to a list of values.\n    trial_final_values: Dict[str, ParameterValueSequence] = {}\n    # multi_dim_params: Dict[str, List[Tuple[int, ParameterValueSequence]]]\n    multi_dim_params = collections.defaultdict(list)\n    for name in trial_external_values:\n      base_index = (\n          vz.SearchSpaceSelector.parse_multi_dimensional_parameter_name(name)", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "oss", "study_config.py"], "line_no": 360, "start_line_no": 350, "end_line_no": 370, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.24873096446700507}, {"context": "                                        'ParameterConfig']]] = None,\n      fidelity_config: Optional[FidelityConfig] = None,\n      scale_type: Optional[ScaleType] = None,\n      default_value: Optional[Union[float, int, str]] = None,\n      external_type: Optional[ExternalType] = ExternalType.INTERNAL\n  ) -> 'ParameterConfig':\n    \"\"\"Factory method.\n\n    Args:\n      name: The parameter's name. Cannot be empty.\n      bounds: REQUIRED for INTEGER or DOUBLE type. Specifies (min, max). The\n        type of (min, max) determines the created ParameterConfig's type.\n      feasible_values: REQUIRED for DISCRETE or CATEGORICAL type. The elements'\n        type determines the created ParameterConfig's type.\n      children: sequence of tuples formatted as: (matching_parent_values,\n        ParameterConfig). ONLY THE TYPES ARE VALIDATED. If the child\n        ParameterConfig protos already have parent values set, they will be\n        overridden by the provided matching_parent_values.\n      fidelity_config: Fidelity config.  NOT VALIDATED.\n      scale_type: Scaling to be applied. NOT VALIDATED.", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.24644549763033174}, {"context": "      default_value: A default value for the Parameter.\n      external_type: An annotation indicating the type this parameter should be\n        cast to.\n\n    Returns:\n      A ParameterConfig object which wraps a partially validated proto.\n\n    Raises:\n      ValueError: Exactly one of feasible_values and bounds must be convertible\n        to Boolean true. Bounds and numeric feasible_values must be finite.\n        Bounds and feasible_values, if provided, must consist of\n        elements of the same type.\n      TypeError: If children's matching_parent_values are not compatible with\n        the ParameterConfig being created.\n    \"\"\"\n    if not name:\n      raise ValueError('Parameter name cannot be empty.')\n\n    if bool(feasible_values) == bool(bounds):\n      raise ValueError(", "metadata": [{"fpath_tuple": ["google_vizier", "vizier", "_src", "pyvizier", "shared", "parameter_config.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "google_vizier", "slice_size": 2}], "sim_score": 0.24431818181818182}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/vip.py\n# --------------------------------------------------\n#         else:\n#             self._device = dest\n#         return super().to(dest)\n# \n#     @property\n#     def device(self):\n#         return self._device\n# \n#     @property\n#     def dtype(self):\n#         return self._dtype\n# \n# \n# class VIPRewardTransform(VIPTransform):\n#     \"\"\"A VIP transform to compute rewards based on embedded similarity.\n# \n#     This class will update the reward computation\n#     \"\"\"\n# \n#     def reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/r3m.py\n# --------------------------------------------------\n# \n#         if self._device is not None:\n#             self.to(self._device)\n#         if self._dtype is not None:\n#             self.to(self._dtype)\n# \n#     def to(self, dest: Union[DEVICE_TYPING, torch.dtype]):\n#         if isinstance(dest, torch.dtype):\n#             self._dtype = dest\n#         else:\n#             self._device = dest\n#         return super().to(dest)\n# \n#     @property\n#     def device(self):\n#         return self._device\n# \n#     @property\n#     def dtype(self):\n#         return self._dtype\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#             minimum = torch.tensor(minimum, dtype=dtype, device=device)\n#         if not isinstance(maximum, torch.Tensor):\n#             maximum = torch.tensor(maximum, dtype=dtype, device=device)\n#         if maximum.device != device:\n#             maximum = maximum.to(device)\n#         if minimum.device != device:\n#             minimum = minimum.to(device)\n#         if dtype is not None and minimum.dtype is not dtype:\n#             minimum = minimum.to(dtype)\n#         if dtype is not None and maximum.dtype is not dtype:\n#             maximum = maximum.to(dtype)\n#         err_msg = (\n#             \"BoundedTensorSpec requires the shape to be explicitely (via \"\n#             \"the shape argument) or implicitely defined (via either the \"\n#             \"minimum or the maximum or both). If the maximum and/or the \"\n#             \"minimum have a non-singleton shape, they must match the \"\n#             \"provided shape if this one is set explicitely.\"\n#         )\n#         if shape is not None and not isinstance(shape, torch.Size):\n#             if isinstance(shape, int):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#         dtype: Optional[Union[str, torch.dtype]] = torch.long,\n#     ):\n#         if shape is None:\n#             shape = torch.Size([])\n#         dtype, device = _default_dtype_and_device(dtype, device)\n#         space = DiscreteBox(n)\n#         super().__init__(shape, space, device, dtype, domain=\"discrete\")\n# \n#     def rand(self, shape=None) -> torch.Tensor:\n#         if shape is None:\n#             shape = torch.Size([])\n#         return torch.randint(\n#             0,\n#             self.space.n,\n#             torch.Size([*shape, *self.shape]),\n#             device=self.device,\n#             dtype=self.dtype,\n#         )\n# \n#     def _project(self, val: torch.Tensor) -> torch.Tensor:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#         dtype: Optional[Union[str, torch.dtype]] = torch.long,\n#         use_register: bool = False,\n#     ):\n# \n#         dtype, device = _default_dtype_and_device(dtype, device)\n#         self.use_register = use_register\n#         space = DiscreteBox(\n#             n,\n#         )\n#         if shape is None:\n#             shape = torch.Size((space.n,))\n#         else:\n#             shape = torch.Size(shape)\n#             if not len(shape) or shape[-1] != space.n:\n#                 raise ValueError(\n#                     f\"The last value of the shape must match n for transform of type {self.__class__}. \"\n#                     f\"Got n={space.n} and shape={shape}.\"\n#                 )\n#         super().__init__(shape, space, device, dtype, \"discrete\")\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/data/tensor_specs.py\n# --------------------------------------------------\n#         device: Optional[DEVICE_TYPING] = None,\n#         dtype: Optional[Union[torch.dtype, str]] = None,\n#     ):\n#         dtype, device = _default_dtype_and_device(dtype, device)\n#         if dtype is None:\n#             dtype = torch.get_default_dtype()\n#         if device is None:\n#             device = torch._get_default_device()\n# \n#         if not isinstance(minimum, torch.Tensor):\n#             minimum = torch.tensor(minimum, dtype=dtype, device=device)\n#         if not isinstance(maximum, torch.Tensor):\n#             maximum = torch.tensor(maximum, dtype=dtype, device=device)\n#         if maximum.device != device:\n#             maximum = maximum.to(device)\n#         if minimum.device != device:\n#             minimum = minimum.to(device)\n#         if dtype is not None and minimum.dtype is not dtype:\n#             minimum = minimum.to(dtype)\n#         if dtype is not None and maximum.dtype is not dtype:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/model_based/common.py\n# --------------------------------------------------\n#         run_type_checks: bool = False,\n#     ):\n#         super(ModelBasedEnvBase, self).__init__(\n#             device=device,\n#             dtype=dtype,\n#             batch_size=batch_size,\n#             run_type_checks=run_type_checks,\n#         )\n#         self.world_model = world_model.to(self.device)\n#         self.world_model_params = params\n#         self.world_model_buffers = buffers\n# \n#     @classmethod\n#     def __new__(cls, *args, **kwargs):\n#         return super().__new__(\n#             cls, *args, _inplace_update=False, _batch_locked=False, **kwargs\n#         )\n# \n#     def set_specs_from_env(self, env: EnvBase):\n#         \"\"\"Sets the specs of the environment from the specs of the given environment.\"\"\"\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n,\n        batch_locked: bool = True,\n    ):\n        self.device = device\n        self.tensordict = tensordict\n        self.specs = specs\n        self.batch_size = batch_size\n        self.env_str = env_str\n        self.batch_locked = batch_locked\n\n    @property\n    def tensordict(self):\n        return self._tensordict.to(self.device)\n\n    @property\n    def specs(self):\n        return self._specs.to(self.device)\n\n    @tensordict.setter\n    def tensordict(self, value: TensorDictBase):\n        self._tensordict = value.to(\"cpu\")\n\n    @specs.setter\n    def specs(self, value: CompositeSpec):\n        self._specs = value.to(\"cpu\")\n\n    @staticmethod\n    def build_metadata_from_env(env) -> EnvMetaData:\n        tensordict = env.fake_tensordict().clone()\n        specs = {\n            \"input_spec\": env.input_spec,\n            \"observation_spec\": env.observation_spec,\n            \"reward_spec\": env.reward_spec,\n        }\n        specs = CompositeSpec(**specs, shape=env.batch_size).to(\"cpu\")\n\n        batch_size = env.batch_size\n        env_str = str(env)\n        device = env.device\n        specs = specs.to(\"cpu\")\n        batch_locked = env.batch_locked\n        return EnvMetaData(tensordict, specs, batch_size, env_str, device, batch_locked)\n\n    def expand(self, *size: int) -> EnvMetaData:\n        tensordict = self.tensordict.expand(*size).to_tensordict()\n        batch_size = torch.Size(list(size))\n        return EnvMetaData(\n            tensordict,\n            self.specs.expand(*size),\n            batch_size,\n            self.env_str,\n            self.device,\n            self.batch_locked,\n        )\n\n    def clone(self):\n        return EnvMetaData(\n            self.tensordict.clone(),\n            self.specs.clone(),\n            torch.Size([*self.batch_size]),\n            deepcopy(self.env_str),\n            self.device,\n            self.batch_locked,\n        )\n\n    def to(self, device: DEVICE_TYPING) -> EnvMetaData:\n        tensordict = self.tensordict.contiguous().to(device)\n        specs = self.specs.to(device)\n        return EnvMetaData(\n            tensordict, specs, self.batch_size, self.env_str, device, self.batch_locked\n        )\n\n\nclass Specs:\n    \"\"\"Container for action, observation and reward specs.\n\n    This class allows one to create an environment, retrieve all of the specs\n    in a single data container (and access them in one place) before erasing\n    the environment from the workspace.\n\n    Args:\n        env (EnvBase): environment from which the specs have to be read.\n\n    \"\"\"\n\n    _keys = {\n        \"action_spec\",\n        \"observation_spec\",\n        \"reward_spec\",\n        \"input_spec\",\n        \"from_pixels\",\n    }\n\n    def __init__(self, env: EnvBase):\n        self.env = env\n\n    def __getitem__(self, item: str) -> Any:\n        if item not in self._keys:\n            raise KeyError(f\"item must be one of {self._keys}\")\n        return getattr(self.env, item)\n\n    def keys(self) -> Sequence[str]:\n        return self._keys\n\n    def build_tensordict(\n        self, next_observation: bool = True, log_prob: bool = False\n    ) -> TensorDictBase:\n        \"\"\"Returns a TensorDict with empty tensors of the desired shape.\n\n        Args:\n            next_observation (bool, optional): if False, the observation returned\n                will be of the current step only (no :obj:`\"next\"` nested tensordict will be present).\n                Default is True.\n            log_prob (bool, optional): If True, a log_prob key-value pair will be added\n                to the tensordict.\n\n        Returns: A tensordict populated according to the env specs.\n\n        \"\"\"\n        # build a tensordict from specs\n        td = TensorDict({}, batch_size=torch.Size([]), _run_checks=False)\n        action_placeholder = torch.zeros(\n            self[\"action_spec\"].shape, dtype=self[\"action_spec\"].dtype\n        )\n        if not isinstance(self[\"observation_spec\"], CompositeSpec):\n            raise RuntimeError(\"observation_spec is expected to be of Composite type.\")\n        else:\n            for (key, item) in self[\"observation_spec\"].items():\n                observation_placeholder = torch.zeros(item.shape, dtype=item.dtype)\n                if next_observation:\n                    td.update({\"next\": {key: observation_placeholder}})\n                td.set(\n                    key,\n                    observation_placeholder.clone(),\n                )\n\n        reward_placeholder = torch.zeros(\n            self[\"reward_spec\"].shape, dtype=self[\"reward_spec\"].dtype\n        )\n        done_placeholder = torch.zeros_like(reward_placeholder, dtype=torch.bool)\n\n        td.set(\"action\", action_placeholder)\n        td.set(\"reward\", reward_placeholder)\n\n        if log_prob:\n            td.set(\n                \"log_prob\",\n                torch.zeros_like(reward_placeholder, dtype=torch.float32),\n            )  # we assume log_prob to be of type float32\n        td.set(\"done\", done_placeholder)\n        return td\n\n\nclass EnvBase(nn.Module, metaclass=abc.ABCMeta):\n    \"\"\"Abstract environment parent class.\n\n    Properties:\n        - observation_spec (CompositeSpec): sampling spec of the observations;\n        - action_spec (TensorSpec): sampling spec of the actions;\n        - input_spec (CompositeSpec): sampling spec of the actions and/or other inputs;\n        - reward_spec (TensorSpec): sampling spec of the rewards;\n        - batch_size (torch.Size): number of environments contained in the instance;\n        - device (torch.device): device where the env input and output are expected to live\n        - run_type_checks (bool): if True, the observation and reward dtypes\n            will be compared against their respective spec and an exception\n            will be raised if they don't match.\n\n    Methods:\n        step (TensorDictBase -> TensorDictBase): step in the environment\n        reset (TensorDictBase, optional -> TensorDictBase): reset the environment\n        set_seed (int -> int): sets the seed of the environment\n        rand_step (TensorDictBase, optional -> TensorDictBase): random step given the action spec\n        rollout (Callable, ... -> TensorDictBase): executes a rollout in the environment with the given policy (or random\n            steps if no policy is provided)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        device: DEVICE_TYPING = \"cpu\",\n        dtype: Optional[Union[torch.dtype, np.dtype]] = None,\n        batch_size: Optional[torch.Size] = None,\n        run_type_checks: bool = True,\n    ):\n        super().__init__()\n        if device is not None:\n            self.device = torch.device(device)\n        self.dtype = dtype_map.get(dtype, dtype)\n        if \"is_closed\" not in self.__dir__():\n            self.is_closed = True\n        if \"_input_spec\" not in self.__dir__():\n            self.__dict__[\"_input_spec\"] = None\n        if \"_reward_spec\" not in self.__dir__():\n            self.__dict__[\"_reward_spec\"] = None", "completion": "```\nclass EnvMetaData:\n    def __init__(\n        self,\n        tensordict: TensorDictBase,\n        specs: CompositeSpec,\n        batch_size: torch.Size,\n        env_str: str,\n        device: DEVICE_TYPING,\n        batch_locked: bool = True,\n    ):\n        self.device = device\n        self.tensordict = tensordict\n        self.specs = specs\n        self.batch_size = batch_size\n        self.env_str = env_str\n        self.batch_locked = batch_locked\n\n    @property\n    def tensordict(self):\n        return self._tensordict.to(self.device)\n\n    @property\n    def specs(self):\n        return self._specs.to(self.device)\n\n    @tensordict.setter\n    def tensordict(self, value: TensorDictBase):\n        self._tensordict = value.to(\"cpu\")\n\n    @specs.setter\n    def specs(self, value: CompositeSpec):\n        self._specs = value.to(\"cpu\")\n\n    def expand(self, *size: int) -> EnvMetaData:\n        tensordict = self.tensordict.expand(*size).to_tensordict()\n        batch_size = torch.Size(list(size))\n", "metadata": {"task_id": "pytorch_rl/53", "ground_truth": "        if \"_observation_spec\" not in self.__dir__():", "fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "context_start_lineno": 46, "line_no": 240, "query_window": {"context": "\n    \"\"\"\n\n    def __init__(\n        self,\n        device: DEVICE_TYPING = \"cpu\",\n        dtype: Optional[Union[torch.dtype, np.dtype]] = None,\n        batch_size: Optional[torch.Size] = None,\n        run_type_checks: bool = True,\n    ):\n        super().__init__()\n        if device is not None:\n            self.device = torch.device(device)\n        self.dtype = dtype_map.get(dtype, dtype)\n        if \"is_closed\" not in self.__dir__():\n            self.is_closed = True\n        if \"_input_spec\" not in self.__dir__():\n            self.__dict__[\"_input_spec\"] = None\n        if \"_reward_spec\" not in self.__dir__():\n            self.__dict__[\"_reward_spec\"] = None", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 240, "task_id": "pytorch_rl/53", "start_line_no": 220, "end_line_no": 240, "window_size": 20, "context_start_lineno": 46, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    \"\"\"\n\n    def __init__(\n        self,\n        world_model: SafeModule,\n        params: Optional[List[torch.Tensor]] = None,\n        buffers: Optional[List[torch.Tensor]] = None,\n        device: DEVICE_TYPING = \"cpu\",\n        dtype: Optional[Union[torch.dtype, np.dtype]] = None,\n        batch_size: Optional[torch.Size] = None,\n        run_type_checks: bool = False,\n    ):\n        super(ModelBasedEnvBase, self).__init__(\n            device=device,\n            dtype=dtype,\n            batch_size=batch_size,\n            run_type_checks=run_type_checks,\n        )\n        self.world_model = world_model.to(self.device)\n        self.world_model_params = params", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "model_based", "common.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.5052631578947369}, {"context": "        device (str, int or torch.device, optional): device of the tensors.\n        dtype (str or torch.dtype, optional): dtype of the tensors.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        minimum: Union[float, torch.Tensor, np.ndarray],\n        maximum: Union[float, torch.Tensor, np.ndarray],\n        shape: Optional[Union[torch.Size, int]] = None,\n        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[torch.dtype, str]] = None,\n    ):\n        dtype, device = _default_dtype_and_device(dtype, device)\n        if dtype is None:\n            dtype = torch.get_default_dtype()\n        if device is None:\n            device = torch._get_default_device()\n\n        if not isinstance(minimum, torch.Tensor):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 630, "start_line_no": 620, "end_line_no": 640, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4444444444444444}, {"context": "    space: DiscreteBox\n    device: torch.device = torch.device(\"cpu\")\n    dtype: torch.dtype = torch.float\n    domain: str = \"\"\n\n    def __init__(\n        self,\n        n: int,\n        shape: Optional[torch.Size] = None,\n        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[str, torch.dtype]] = torch.long,\n        use_register: bool = False,\n    ):\n\n        dtype, device = _default_dtype_and_device(dtype, device)\n        self.use_register = use_register\n        space = DiscreteBox(\n            n,\n        )\n        if shape is None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 470, "start_line_no": 460, "end_line_no": 480, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.43157894736842106}, {"context": "    space: DiscreteBox\n    device: torch.device = torch.device(\"cpu\")\n    dtype: torch.dtype = torch.float\n    domain: str = \"\"\n\n    def __init__(\n        self,\n        n: int,\n        shape: Optional[torch.Size] = None,\n        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[str, torch.dtype]] = torch.long,\n    ):\n        if shape is None:\n            shape = torch.Size([])\n        dtype, device = _default_dtype_and_device(dtype, device)\n        space = DiscreteBox(n)\n        super().__init__(shape, space, device, dtype, domain=\"discrete\")\n\n    def rand(self, shape=None) -> torch.Tensor:\n        if shape is None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 1270, "start_line_no": 1260, "end_line_no": 1280, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4077669902912621}, {"context": "        device: Optional[DEVICE_TYPING] = None,\n        dtype: Optional[Union[torch.dtype, str]] = None,\n    ):\n        dtype, device = _default_dtype_and_device(dtype, device)\n        if dtype is None:\n            dtype = torch.get_default_dtype()\n        if device is None:\n            device = torch._get_default_device()\n\n        if not isinstance(minimum, torch.Tensor):\n            minimum = torch.tensor(minimum, dtype=dtype, device=device)\n        if not isinstance(maximum, torch.Tensor):\n            maximum = torch.tensor(maximum, dtype=dtype, device=device)\n        if maximum.device != device:\n            maximum = maximum.to(device)\n        if minimum.device != device:\n            minimum = minimum.to(device)\n        if dtype is not None and minimum.dtype is not dtype:\n            minimum = minimum.to(dtype)\n        if dtype is not None and maximum.dtype is not dtype:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "data", "tensor_specs.py"], "line_no": 640, "start_line_no": 630, "end_line_no": 650, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.4}, {"context": "            self.to(self._device)\n        if self._dtype is not None:\n            self.to(self._dtype)\n\n    def to(self, dest: Union[DEVICE_TYPING, torch.dtype]):\n        if isinstance(dest, torch.dtype):\n            self._dtype = dest\n        else:\n            self._device = dest\n        return super().to(dest)\n\n    @property\n    def device(self):\n        return self._device\n\n    @property\n    def dtype(self):\n        return self._dtype", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "r3m.py"], "line_no": 370, "start_line_no": 360, "end_line_no": 378, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3764705882352941}, {"context": "            )\n\n        if self._device is not None:\n            self.to(self._device)\n        if self._dtype is not None:\n            self.to(self._dtype)\n\n    def to(self, dest: Union[DEVICE_TYPING, torch.dtype]):\n        if isinstance(dest, torch.dtype):\n            self._dtype = dest\n        else:\n            self._device = dest\n        return super().to(dest)\n\n    @property\n    def device(self):\n        return self._device\n\n    @property\n    def dtype(self):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "vip.py"], "line_no": 330, "start_line_no": 320, "end_line_no": 340, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.37209302325581395}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 fit_config=self.reg_fit_config_nodir_nodump,\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n# \n#             # no save dir but dump\n#             with self.assertRaises(ValueError):\n#                 status = prob_reg.train(\n#                     train_data_loader=self.reg_train_data_loader,\n#                     calib_data_loader=self.reg_val_data_loader,\n#                     val_data_loader=self.reg_val_data_loader,\n#                     fit_config=self.reg_fit_config_nodir_dump,\n#                     calib_config=self.reg_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#             prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_restore(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n# \n#             # load state\n#             prob_reg.load_state(checkpoint_path=tmp_dir)\n# \n#             # save state\n#             prob_reg.save_state(checkpoint_path=tmp_dir)\n# \n#     def test_dryrun_class_advi(self):\n#         with tempfile.TemporaryDirectory() as tmp_dir:\n#             prob_class = ProbClassifier(\n#                 model=MyModel(self.class_output_dim),\n#                 posterior_approximator=ADVIPosteriorApproximator(),\n#                 output_calibrator=ClassificationTemperatureScaler(),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_nodir_nodump,\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             sample = prob_reg.posterior.sample()\n# \n#             # no save dir but dump\n#             with self.assertRaises(ValueError):\n#                 status = prob_reg.train(\n#                     train_data_loader=self.reg_train_data_loader,\n#                     calib_data_loader=self.reg_val_data_loader,\n#                     val_data_loader=self.reg_val_data_loader,\n#                     fit_config=self.reg_fit_config_nodir_dump,\n#                     calib_config=self.reg_calib_config_nodir_nodump,\n#                 )\n# \n#             # save dir, no dump\n#             status = prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#             )\n# \n#             # restore from map\n#             prob_class_map = ProbClassifier(\n#                 model=MyModel(self.class_output_dim),\n#                 posterior_approximator=MAPPosteriorApproximator(),\n#                 output_calibrator=ClassificationTemperatureScaler(),\n#             )\n#             status = prob_class_map.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_restore(tmp_dir),\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n#             status = prob_class.train(\n#                 train_data_loader=self.class_train_data_loader,\n#                 calib_data_loader=self.class_val_data_loader,\n#                 val_data_loader=self.class_val_data_loader,\n#                 fit_config=self.class_fit_config_restore(tmp_dir),\n#                 calib_config=self.class_calib_config_nodir_nodump,\n#             )\n# \n#             # load state\n#             prob_class.load_state(checkpoint_path=tmp_dir)\n# \n#             # save state\n#             prob_class.save_state(checkpoint_path=tmp_dir)\n# \n#     def test_dryrun_reg_deep_ensemble(self):\n# --------------------------------------------------\n# the below code fragment can be found in:\n# tests/fortuna/prob_model/test_train.py\n# --------------------------------------------------\n#                 posterior_approximator=MAPPosteriorApproximator(),\n#                 output_calibrator=RegressionTemperatureScaler(),\n#             )\n#             status = prob_reg_map.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n#             prob_reg.train(\n#                 train_data_loader=self.reg_train_data_loader,\n#                 calib_data_loader=self.reg_val_data_loader,\n#                 val_data_loader=self.reg_val_data_loader,\n#                 fit_config=self.reg_fit_config_restore(tmp_dir),\n#                 calib_config=self.reg_calib_config_nodir_nodump,\n#             )\n# \n#             # load state\n#             prob_reg.load_state(checkpoint_path=tmp_dir)\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n tempfile.TemporaryDirectory() as tmp_dir:\n            prob_class = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=DeepEnsemblePosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_nodir_nodump,\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader,\n                    calib_data_loader=self.class_val_data_loader,\n                    val_data_loader=self.class_val_data_loader,\n                    fit_config=self.class_fit_config_nodir_dump,\n                    calib_config=self.class_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_dump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # restore\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_restore(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_class.load_state(checkpoint_path=tmp_dir)\n\n            # save state\n            prob_class.save_state(checkpoint_path=tmp_dir)\n\n    def test_dryrun_reg_laplace(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            prob_reg = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=LaplacePosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,\n                    val_data_loader=self.reg_val_data_loader,\n                    map_fit_config=self.reg_fit_config_nodir_nodump,\n                    fit_config=self.reg_fit_config_nodir_dump,\n                    calib_config=self.reg_calib_config_nodir_nodump,\n                )\n\n            # save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_dir_nodump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # save dir and dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n            prob_reg.posterior.load_state(tmp_dir)\n\n            # restore from laplace\n            prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # restore from map\n            prob_reg_map = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,", "completion": "val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_reg.load_state(checkpoint_path=tmp_dir)\n\n            # save state\n            prob_reg.save_state(checkpoint_path=tmp_dir)\n\n    def test_dryrun_class_advi(self):\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            prob_class = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=ADVIPosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_nodir_nodump,\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            sample = prob_class.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_class.train(\n                    train_data_loader=self.class_train_data_loader", "metadata": {"task_id": "awslabs_fortuna/1", "ground_truth": "                val_data_loader=self.reg_val_data_loader,", "fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "context_start_lineno": 515, "line_no": 660, "query_window": {"context": "            )\n\n            # restore from map\n            prob_reg_map = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                map_fit_config=self.reg_fit_config_nodir_nodump,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,", "metadata": {"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 660, "task_id": "awslabs_fortuna/1", "start_line_no": 640, "end_line_no": 660, "window_size": 20, "context_start_lineno": 515, "repo": "awslabs_fortuna"}}, "top_k_context": [{"context": "                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # restore from map\n            prob_reg_map = ProbRegressor(\n                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 340, "start_line_no": 330, "end_line_no": 350, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.9722222222222222}, {"context": "            )\n\n            # restore from map\n            prob_class_map = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            status = prob_class_map.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_dir_dump(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_restore(tmp_dir),", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 430, "start_line_no": 420, "end_line_no": 440, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.8026315789473685}, {"context": "            sample = prob_class.posterior.sample()\n            prob_class.posterior.load_state(tmp_dir)\n\n            # restore from advi\n            status = prob_class.train(\n                train_data_loader=self.class_train_data_loader,\n                calib_data_loader=self.class_val_data_loader,\n                val_data_loader=self.class_val_data_loader,\n                fit_config=self.class_fit_config_restore(tmp_dir),\n                calib_config=self.class_calib_config_nodir_nodump,\n            )\n\n            # restore from map\n            prob_class_map = ProbClassifier(\n                model=MyModel(self.class_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=ClassificationTemperatureScaler(),\n            )\n            status = prob_class_map.train(\n                train_data_loader=self.class_train_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 420, "start_line_no": 410, "end_line_no": 430, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7058823529411765}, {"context": "            prob_reg = ProbRegressor(\n                model=MLP(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 160, "start_line_no": 150, "end_line_no": 170, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.7}, {"context": "                posterior_approximator=MAPPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            status = prob_reg_map.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_dir_dump(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_restore(tmp_dir),\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n\n            # load state\n            prob_reg.load_state(checkpoint_path=tmp_dir)", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6875}, {"context": "                model=MyModel(self.reg_output_dim),\n                likelihood_log_variance_model=MyModel(self.reg_output_dim),\n                posterior_approximator=ADVIPosteriorApproximator(),\n                output_calibrator=RegressionTemperatureScaler(),\n            )\n            # no save dir, no dump\n            status = prob_reg.train(\n                train_data_loader=self.reg_train_data_loader,\n                calib_data_loader=self.reg_val_data_loader,\n                val_data_loader=self.reg_val_data_loader,\n                fit_config=self.reg_fit_config_nodir_nodump,\n                calib_config=self.reg_calib_config_nodir_nodump,\n            )\n            sample = prob_reg.posterior.sample()\n\n            # no save dir but dump\n            with self.assertRaises(ValueError):\n                status = prob_reg.train(\n                    train_data_loader=self.reg_train_data_loader,\n                    calib_data_loader=self.reg_val_data_loader,", "metadata": [{"fpath_tuple": ["awslabs_fortuna", "tests", "fortuna", "prob_model", "test_train.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "awslabs_fortuna", "slice_size": 2}], "sim_score": 0.6483516483516484}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/record/recorder.py\n# --------------------------------------------------\n#         out_file_base: str,\n#         skip_reset: bool = True,\n#         skip: int = 4,\n#         in_keys: Optional[Sequence[str]] = None,\n#     ) -> None:\n#         if in_keys is None:\n#             in_keys = []\n# \n#         super().__init__(in_keys=in_keys)\n#         self.iter = 0\n#         self.out_file_base = out_file_base\n#         self.td = []\n#         self.skip_reset = skip_reset\n#         self.skip = skip\n#         self.count = 0\n# \n#     def _call(self, td: TensorDictBase) -> TensorDictBase:\n#         self.count += 1\n#         if self.count % self.skip == 0:\n#             _td = td\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/vec_env.py\n# --------------------------------------------------\n#     def _reset(self, tensordict: TensorDictBase, **kwargs) -> TensorDictBase:\n# \n#         if tensordict is not None and \"_reset\" in tensordict.keys():\n#             self._assert_tensordict_shape(tensordict)\n#             _reset = tensordict.get(\"_reset\")\n#         else:\n#             _reset = torch.ones(self.batch_size, dtype=torch.bool)\n# \n#         keys = set()\n#         for i, _env in enumerate(self._envs):\n#             if not _reset[i].any():\n#                 continue\n#             _tensordict = tensordict[i] if tensordict is not None else None\n#             _td = _env._reset(tensordict=_tensordict, **kwargs)\n#             if \"_reset\" in _td.keys():\n#                 _td.del_(\"_reset\")\n#             keys = keys.union(_td.keys())\n#             self.shared_tensordicts[i].update_(_td)\n# \n#         return self.shared_tensordict_parent.select(\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/common.py\n# --------------------------------------------------\n# \n#         \"\"\"\n#         if tensordict is None:\n#             tensordict = TensorDict(\n#                 {}, device=self.device, batch_size=self.batch_size, _run_checks=False\n#             )\n#         action = self.action_spec.rand()\n#         tensordict.set(\"action\", action)\n#         return self.step(tensordict)\n# \n#     @property\n#     def specs(self) -> Specs:\n#         \"\"\"Returns a Specs container where all the environment specs are contained.\n# \n#         This feature allows one to create an environment, retrieve all of the specs in a single data container and then\n#         erase the environment from the workspace.\n# \n#         \"\"\"\n#         return Specs(self)\n# \n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/vip.py\n# --------------------------------------------------\n#         if \"goal_embedding\" not in tensordict.keys():\n#             tensordict = self._embed_goal(tensordict)\n#         return super().reset(tensordict)\n# \n#     def _embed_goal(self, tensordict):\n#         if \"goal_image\" not in tensordict.keys():\n#             raise KeyError(\n#                 f\"{self.__class__.__name__}.reset() requires a `'goal_image'` key to be \"\n#                 f\"present in the input tensordict.\"\n#             )\n#         tensordict_in = tensordict.select(\"goal_image\").rename_key(\n#             \"goal_image\", self.in_keys[0]\n#         )\n#         tensordict_in = super(VIPRewardTransform, self).forward(tensordict_in)\n#         tensordict = tensordict.update(\n#             tensordict_in.rename_key(self.out_keys[0], \"goal_embedding\")\n#         )\n#         return tensordict\n# \n#     def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/gym_like.py\n# --------------------------------------------------\n#         info = None\n#         if len(other) == 1:\n#             info = other\n# \n#         tensordict_out = TensorDict(\n#             source=self.read_obs(obs),\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n#         if self.info_dict_reader is not None and info is not None:\n#             self.info_dict_reader(info, tensordict_out)\n#         elif info is None and self.info_dict_reader is not None:\n#             # populate the reset with the items we have not seen from info\n#             for key, item in self.observation_spec.items():\n#                 if key not in tensordict_out.keys():\n#                     tensordict_out[key] = item.zero()\n#         tensordict_out.set(\"done\", torch.zeros(*self.batch_size, 1, dtype=torch.bool))\n#         return tensordict_out\n# \n#     def _output_transform(self, step_outputs_tuple: Tuple) -> Tuple:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/gym_like.py\n# --------------------------------------------------\n# \n#         return tensordict_out\n# \n#     def _reset(\n#         self, tensordict: Optional[TensorDictBase] = None, **kwargs\n#     ) -> TensorDictBase:\n#         reset_data = self._env.reset(**kwargs)\n#         if not isinstance(reset_data, tuple):\n#             reset_data = (reset_data,)\n#         obs, *other = self._output_transform(reset_data)\n#         info = None\n#         if len(other) == 1:\n#             info = other\n# \n#         tensordict_out = TensorDict(\n#             source=self.read_obs(obs),\n#             batch_size=self.batch_size,\n#             device=self.device,\n#         )\n#         if self.info_dict_reader is not None and info is not None:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# torchrl/envs/transforms/transforms.py\n# --------------------------------------------------\n# \n#     def _apply_transform(self, obs: torch.Tensor) -> torch.Tensor:\n#         return obs.to(torch.float)\n# \n#     def _inv_apply_transform(self, obs: torch.Tensor) -> torch.Tensor:\n#         return obs.to(torch.double)\n# \n#     def _transform_spec(self, spec: TensorSpec) -> None:\n#         if isinstance(spec, CompositeSpec):\n#             for key in spec:\n#                 self._transform_spec(spec[key])\n#         else:\n#             spec.dtype = torch.float\n#             space = spec.space\n#             if isinstance(space, ContinuousBox):\n#                 space.minimum = space.minimum.to(torch.float)\n#                 space.maximum = space.maximum.to(torch.float)\n# \n#     def transform_input_spec(self, input_spec: TensorSpec) -> TensorSpec:\n#         for key in self.in_keys_inv:\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n\n            f\"sampler={self._sampler}, \"\n            f\"writer={self._writer}\"\n            \")\"\n        )\n\n    @pin_memory_output\n    def __getitem__(self, index: Union[int, torch.Tensor]) -> Any:\n        index = _to_numpy(index)\n        with self._replay_lock:\n            data = self._storage[index]\n\n        if not isinstance(index, INT_CLASSES):\n            data = self._collate_fn(data)\n\n        return data\n\n    def state_dict(self) -> Dict[str, Any]:\n        return {\n            \"_storage\": self._storage.state_dict(),\n            \"_sampler\": self._sampler.state_dict(),\n            \"_writer\": self._writer.state_dict(),\n        }\n\n    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:\n        self._storage.load_state_dict(state_dict[\"_storage\"])\n        self._sampler.load_state_dict(state_dict[\"_sampler\"])\n        self._writer.load_state_dict(state_dict[\"_writer\"])\n\n    def add(self, data: Any) -> int:\n        \"\"\"Add a single element to the replay buffer.\n\n        Args:\n            data (Any): data to be added to the replay buffer\n\n        Returns:\n            index where the data lives in the replay buffer.\n        \"\"\"\n        with self._replay_lock:\n            index = self._writer.add(data)\n            self._sampler.add(index)\n        return index\n\n    def extend(self, data: Sequence) -> torch.Tensor:\n        \"\"\"Extends the replay buffer with one or more elements contained in an iterable.\n\n        Args:\n            data (iterable): collection of data to be added to the replay\n                buffer.\n\n        Returns:\n            Indices of the data aded to the replay buffer.\n        \"\"\"\n        with self._replay_lock:\n            index = self._writer.extend(data)\n            self._sampler.extend(index)\n        return index\n\n    def update_priority(\n        self,\n        index: Union[int, torch.Tensor],\n        priority: Union[int, torch.Tensor],\n    ) -> None:\n        with self._replay_lock:\n            self._sampler.update_priority(index, priority)\n\n    @pin_memory_output\n    def _sample(self, batch_size: int) -> Tuple[Any, dict]:\n        with self._replay_lock:\n            index, info = self._sampler.sample(self._storage, batch_size)\n            data = self._storage[index]\n        if not isinstance(index, INT_CLASSES):\n            data = self._collate_fn(data)\n        data = self._transform(data)\n        return data, info\n\n    def sample(self, batch_size: int, return_info: bool = False) -> Any:\n        \"\"\"Samples a batch of data from the replay buffer.\n\n        Uses Sampler to sample indices, and retrieves them from Storage.\n\n        Args:\n            batch_size (int): size of data to be collected.\n            return_info (bool): whether to return info. If True, the result\n                is a tuple (data, info). If False, the result is the data.\n\n        Returns:\n            A batch of data selected in the replay buffer.\n            A tuple containing this batch and info if return_info flag is set to True.\n        \"\"\"\n        if not self._prefetch:\n            ret = self._sample(batch_size)\n        else:\n            if len(self._prefetch_queue) == 0:\n                ret = self._sample(batch_size)\n            else:\n                with self._futures_lock:\n                    ret = self._prefetch_queue.popleft().result()\n\n            with self._futures_lock:\n                while len(self._prefetch_queue) < self._prefetch_cap:\n                    fut = self._prefetch_executor.submit(self._sample, batch_size)\n                    self._prefetch_queue.append(fut)\n\n        if return_info:\n            return ret\n        return ret[0]\n\n    def mark_update(self, index: Union[int, torch.Tensor]) -> None:\n        self._sampler.mark_update(index)\n\n    def append_transform(self, transform: \"Transform\") -> None:  # noqa-F821\n        \"\"\"Appends transform at the end.\n\n        Transforms are applied in order when `sample` is called.\n\n        Args:\n            transform (Transform): The transform to be appended\n        \"\"\"\n        transform.eval()\n        self._transform.append(transform)\n\n    def insert_transform(self, index: int, transform: \"Transform\") -> None:  # noqa-F821\n        \"\"\"Inserts transform.\n\n        Transforms are executed in order when `sample` is called.\n\n        Args:\n            index (int): Position to insert the transform.\n            transform (Transform): The transform to be appended\n        \"\"\"\n        transform.eval()\n        self._transform.insert(index, transform)\n\n\nclass PrioritizedReplayBuffer(ReplayBuffer):\n    \"\"\"Prioritized replay buffer.\n\n    Presented in\n        \"Schaul, T.; Quan, J.; Antonoglou, I.; and Silver, D. 2015.\n        Prioritized experience replay.\"\n        (https://arxiv.org/abs/1511.05952)\n\n    Args:\n        alpha (float): exponent \u03b1 determines how much prioritization is used,\n            with \u03b1 = 0 corresponding to the uniform case.\n        beta (float): importance sampling negative exponent.\n        eps (float): delta added to the priorities to ensure that the buffer\n            does not contain null priorities.\n        dtype (torch.dtype): type of the data. Can be torch.float or torch.double.\n        storage (Storage, optional): the storage to be used. If none is provided\n            a default ListStorage with max_size of 1_000 will be created.\n        collate_fn (callable, optional): merges a list of samples to form a\n            mini-batch of Tensor(s)/outputs.  Used when using batched\n            loading from a map-style dataset.\n        pin_memory (bool): whether pin_memory() should be called on the rb\n            samples.\n        prefetch (int, optional): number of next batches to be prefetched\n            using multithreading.\n        transform (Transform, optional): Transform to be executed when sample() is called.\n            To chain transforms use the :obj:`Compose` class.\n    \"\"\"\n\n    def __init__(\n        self,\n        alpha: float,\n        beta: float,\n        eps: float = 1e-8,\n        dtype: torch.dtype = torch.float,\n        storage: Optional[Storage] = None,\n        collate_fn: Optional[Callable] = None,\n        pin_memory: bool = False,\n        prefetch: Optional[int] = None,\n        transform: Optional[\"Transform\"] = None,  # noqa-F821\n    ) -> None:\n        if storage is None:\n            storage = ListStorage(max_size=1_000)\n        sampler = PrioritizedSampler(storage.max_size, alpha, beta, eps, dtype)\n        super(PrioritizedReplayBuffer, self).__init__(\n            storage=storage,\n            sampler=sampler,\n            collate_fn=collate_fn,\n            pin_memory=pin_memory,\n            prefetch=prefetch,\n            transform=transform,\n        )\n\n\nclass TensorDictReplayBuffer(ReplayBuffer):\n    \"\"\"TensorDict-specific wrapper around the ReplayBuffer class.\n\n    Args:\n        priority_key (str): the key at which priority is assumed to be stored\n            within TensorDicts added to this ReplayBuffer.\n    \"\"\"\n\n    def __init__(self, priority_key: str = \"td_error\", **kw) -> None:\n        super().__init__(**kw)\n        self.priority_key = priority_key\n\n    def _get_priority(self, tensordict: TensorDictBase) -> Optional[torch.Tensor]:\n        if self.priority_key not in tensordict.keys():\n            return self._sampler.default_priority\n        if tensordict.batch_dims:", "completion": "            return tensordict[self.priority_key].mean(dim=tensordict.batch_dims)\n        return tensordict[self.priority_key]\n\n    def add(self, tensordict: TensorDictBase) -> int:\n        priority = self._get_priority(tensordict)\n        index = super().add(tensordict)\n        self.update_priority(index, priority)\n        return index\n\n    def extend(self, tensordicts: Sequence[TensorDictBase]) -> torch.Tensor:\n        priorities = [self._get_priority(td) for td in tensordicts]\n        indices = super().extend(tensordicts)\n        self.update_priority(indices, priorities)\n        return indices\n\n    def update_priority(\n        self,\n        indices: Union[int, torch.Tensor],\n        priorities: Union[float, torch.Tensor],\n    ) -> None:\n        if isinstance(indices, int):\n            indices = torch.tensor([indices])\n            priorities = torch.tensor([priorities])\n        super().update_priority(indices, priorities)\n\n    def _sample(self, batch_size: int) -> Tuple[TensorDictBase, dict]:\n        data, info = super()._sample(batch_size)\n        if isinstance(data, TensorDict):\n            data.set(self.priority_key, info[\"priority", "metadata": {"task_id": "pytorch_rl/60", "ground_truth": "            tensordict = tensordict.clone(recurse=False)", "fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "replay_buffers.py"], "context_start_lineno": 145, "line_no": 349, "query_window": {"context": "            transform=transform,\n        )\n\n\nclass TensorDictReplayBuffer(ReplayBuffer):\n    \"\"\"TensorDict-specific wrapper around the ReplayBuffer class.\n\n    Args:\n        priority_key (str): the key at which priority is assumed to be stored\n            within TensorDicts added to this ReplayBuffer.\n    \"\"\"\n\n    def __init__(self, priority_key: str = \"td_error\", **kw) -> None:\n        super().__init__(**kw)\n        self.priority_key = priority_key\n\n    def _get_priority(self, tensordict: TensorDictBase) -> Optional[torch.Tensor]:\n        if self.priority_key not in tensordict.keys():\n            return self._sampler.default_priority\n        if tensordict.batch_dims:", "metadata": {"fpath_tuple": ["pytorch_rl", "torchrl", "data", "replay_buffers", "replay_buffers.py"], "line_no": 349, "task_id": "pytorch_rl/60", "start_line_no": 329, "end_line_no": 349, "window_size": 20, "context_start_lineno": 145, "repo": "pytorch_rl"}}, "top_k_context": [{"context": "    \"\"\"\n\n    invertible = True\n\n    def __init__(\n        self,\n        in_keys: Optional[Sequence[str]] = None,\n        in_keys_inv: Optional[Sequence[str]] = None,\n    ):\n        super().__init__(in_keys=in_keys, in_keys_inv=in_keys_inv)\n\n    def _apply_transform(self, obs: torch.Tensor) -> torch.Tensor:\n        return obs.to(torch.float)\n\n    def _inv_apply_transform(self, obs: torch.Tensor) -> torch.Tensor:\n        return obs.to(torch.double)\n\n    def _transform_spec(self, spec: TensorSpec) -> None:\n        if isinstance(spec, CompositeSpec):\n            for key in spec:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "transforms.py"], "line_no": 1720, "start_line_no": 1710, "end_line_no": 1730, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3565217391304348}, {"context": "        done = self._to_tensor(done, dtype=torch.bool)\n\n        tensordict_out = TensorDict(\n            obs_dict, batch_size=tensordict.batch_size, device=self.device\n        )\n\n        tensordict_out.set(\"reward\", reward)\n        tensordict_out.set(\"done\", done)\n        if self.info_dict_reader is not None and info is not None:\n            self.info_dict_reader(info, tensordict_out)\n\n        return tensordict_out\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:\n        reset_data = self._env.reset(**kwargs)\n        if not isinstance(reset_data, tuple):\n            reset_data = (reset_data,)\n        obs, *other = self._output_transform(reset_data)", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 230, "start_line_no": 220, "end_line_no": 240, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.34615384615384615}, {"context": "\n        return tensordict_out\n\n    def _reset(\n        self, tensordict: Optional[TensorDictBase] = None, **kwargs\n    ) -> TensorDictBase:\n        reset_data = self._env.reset(**kwargs)\n        if not isinstance(reset_data, tuple):\n            reset_data = (reset_data,)\n        obs, *other = self._output_transform(reset_data)\n        info = None\n        if len(other) == 1:\n            info = other\n\n        tensordict_out = TensorDict(\n            source=self.read_obs(obs),\n            batch_size=self.batch_size,\n            device=self.device,\n        )\n        if self.info_dict_reader is not None and info is not None:", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "gym_like.py"], "line_no": 240, "start_line_no": 230, "end_line_no": 250, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.336}, {"context": "        return self._dtype\n\n\nclass VIPRewardTransform(VIPTransform):\n    \"\"\"A VIP transform to compute rewards based on embedded similarity.\n\n    This class will update the reward computation\n    \"\"\"\n\n    def reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n        if \"goal_embedding\" not in tensordict.keys():\n            tensordict = self._embed_goal(tensordict)\n        return super().reset(tensordict)\n\n    def _embed_goal(self, tensordict):\n        if \"goal_image\" not in tensordict.keys():\n            raise KeyError(\n                f\"{self.__class__.__name__}.reset() requires a `'goal_image'` key to be \"\n                f\"present in the input tensordict.\"\n            )", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "transforms", "vip.py"], "line_no": 350, "start_line_no": 340, "end_line_no": 360, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "\n    def rand_step(self, tensordict: Optional[TensorDictBase] = None) -> TensorDictBase:\n        \"\"\"Performs a random step in the environment given the action_spec attribute.\n\n        Args:\n            tensordict (TensorDictBase, optional): tensordict where the resulting info should be written.\n\n        Returns:\n            a tensordict object with the new observation after a random step in the environment. The action will\n            be stored with the \"action\" key.\n\n        \"\"\"\n        if tensordict is None:\n            tensordict = TensorDict(\n                {}, device=self.device, batch_size=self.batch_size, _run_checks=False\n            )\n        action = self.action_spec.rand()\n        tensordict.set(\"action\", action)\n        return self.step(tensordict)\n", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "common.py"], "line_no": 580, "start_line_no": 570, "end_line_no": 590, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.33093525179856115}, {"context": "    @_check_start\n    def set_seed(\n        self, seed: Optional[int] = None, static_seed: bool = False\n    ) -> Optional[int]:\n        for env in self._envs:\n            new_seed = env.set_seed(seed, static_seed=static_seed)\n            seed = new_seed\n        return seed\n\n    @_check_start\n    def _reset(self, tensordict: TensorDictBase, **kwargs) -> TensorDictBase:\n\n        if tensordict is not None and \"_reset\" in tensordict.keys():\n            self._assert_tensordict_shape(tensordict)\n            _reset = tensordict.get(\"_reset\")\n        else:\n            _reset = torch.ones(self.batch_size, dtype=torch.bool)\n\n        keys = set()\n        for i, _env in enumerate(self._envs):", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "envs", "vec_env.py"], "line_no": 610, "start_line_no": 600, "end_line_no": 620, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.33088235294117646}, {"context": "        skip_reset (bool): if True, the first TensorDict of the list will be discarded (usually the tensordict\n            resulting from the call to :obj:`env.reset()`)\n            default: True\n        skip (int): frame interval for the saved tensordict.\n            default: 4\n\n    \"\"\"\n\n    def __init__(\n        self,\n        out_file_base: str,\n        skip_reset: bool = True,\n        skip: int = 4,\n        in_keys: Optional[Sequence[str]] = None,\n    ) -> None:\n        if in_keys is None:\n            in_keys = []\n\n        super().__init__(in_keys=in_keys)\n        self.iter = 0", "metadata": [{"fpath_tuple": ["pytorch_rl", "torchrl", "record", "recorder.py"], "line_no": 150, "start_line_no": 140, "end_line_no": 160, "window_size": 20, "repo": "pytorch_rl", "slice_size": 2}], "sim_score": 0.3282442748091603}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/coordinator/comm_coordinator.py\n# --------------------------------------------------\n#                     continue\n#                 result = get_data_task.result\n#                 task_id, buffer_id, batch_size = result['task_id'], result['buffer_id'], result['batch_size']\n#                 cur_learner_iter = result['cur_learner_iter']\n#                 sleep_count = 1\n#                 while True:\n#                     data = self._callback_fn['deal_with_learner_get_data'](\n#                         task_id, buffer_id, batch_size, cur_learner_iter\n#                     )\n#                     if self._end_flag or data is not None:\n#                         self._logger.info('sample result is ok')\n#                         break\n#                     else:\n#                         self._logger.info('sample result is None')\n#                         time.sleep(sleep_count)\n#                         sleep_count += 2\n#                 if self._end_flag:\n#                     break\n# \n#                 # learn task\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/adapter/learner_aggregator.py\n# --------------------------------------------------\n#         start = 0\n#         for item in self._data_demand.values():\n#             end = item['batch_size'] + start\n#             split_data.append(merged_data[start:end])\n#             start = end\n#         for (k, v), d in zip(self._learner_connection.items(), split_data):\n#             learn_task[k] = v.new_task({'name': task['name'], 'data': d})\n#             learn_task[k].start()\n#         for k, v in learn_task.items():\n#             v.join()\n#         # TODO deal with task fail\n#         info_list = [v.result for v in learn_task.values()]\n#         # Merge learn info through ``merge_info`` method.\n#         merged_info = self.merge_info(info_list)\n#         return merged_info\n# \n#     @staticmethod\n#     def merge_info(info: list) -> dict:\n#         homogeneous_keys = ['learner_step', 'buffer_id', 'task_id', 'learner_done']\n#         elem = info[0]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/utils/data/dataloader.py\n# --------------------------------------------------\n#                     data = self.collate_fn(data)\n#                     self.async_train_queue.put(data)\n#                     p.send('pass')\n#                 else:\n#                     p.send(data)\n#         p.close()\n# \n#     def _async_loop(self, p: tm.multiprocessing.connection, c: tm.multiprocessing.connection) -> None:\n#         \"\"\"\n#         Overview:\n#             Main worker process. Run through ``self.async_process``.\n#             Firstly, get data from ``self.get_data_thread``.\n#             If multiple workers, put data in ``self.job_queue`` for further multiprocessing operation;\n#             If only one worker, process data and put directly into ``self.async_train_queue``.\n#         Arguments:\n#             - p (:obj:`tm.multiprocessing.connection`): Parent connection.\n#             - c (:obj:`tm.multiprocessing.connection`): Child connection.\n#         \"\"\"\n#         p.close()  # Close unused p, only use c\n#         while not self.end_flag:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/adapter/learner_aggregator.py\n# --------------------------------------------------\n#         # TODO deal with task fail\n#         info_list = [v.result for v in learn_task.values()]\n#         # Merge learn info through ``merge_info`` method.\n#         merged_info = self.merge_info(info_list)\n#         return merged_info\n# \n#     @staticmethod\n#     def merge_info(info: list) -> dict:\n#         homogeneous_keys = ['learner_step', 'buffer_id', 'task_id', 'learner_done']\n#         elem = info[0]\n#         if elem is None:\n#             return info\n#         elif isinstance(elem, numbers.Integral) or isinstance(elem, str) or isinstance(elem, float):\n#             return info\n#         elif isinstance(elem, list) or isinstance(elem, tuple):\n#             return list(reduce(lambda x, y: x + y, info))\n#         elif isinstance(elem, dict):\n#             ret = {}\n#             for k in elem.keys():\n#                 if k in homogeneous_keys:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/model/wrapper/model_wrappers.py\n# --------------------------------------------------\n#         assert len(state) == len(state_id), '{}/{}'.format(len(state), len(state_id))\n#         for idx, s in zip(state_id, state):\n#             self._state[idx] = s\n# \n#     def before_forward(self, data: dict, state_id: Optional[list]) -> Tuple[dict, dict]:\n#         if state_id is None:\n#             state_id = [i for i in range(self._state_num)]\n# \n#         state_info = {idx: self._state[idx] for idx in state_id}\n#         data['prev_state'] = list(state_info.values())\n#         return data, state_info\n# \n#     def after_forward(self, h: Any, state_info: dict, valid_id: Optional[list] = None) -> None:\n#         assert len(h) == len(state_info), '{}/{}'.format(len(h), len(state_info))\n#         for i, idx in enumerate(state_info.keys()):\n#             if valid_id is None:\n#                 self._state[idx] = h[i]\n#             else:\n#                 if idx in valid_id:\n#                     self._state[idx] = h[i]\n# --------------------------------------------------\n# the below code fragment can be found in:\n# ding/worker/adapter/learner_aggregator.py\n# --------------------------------------------------\n#         # Merge data demand info by adding up all learners' demand batch size.\n#         merged_demand = copy.deepcopy(demand_list[0])\n#         merged_demand['batch_size'] = sum([d['batch_size'] for d in demand_list])\n#         return merged_demand\n# \n#     def deal_with_learn(self, task: dict) -> dict:\n#         learn_task = {}\n#         merged_data = task['data']\n#         # Split training data for each learner according to ``self._data_demand``.\n#         split_data = []\n#         start = 0\n#         for item in self._data_demand.values():\n#             end = item['batch_size'] + start\n#             split_data.append(merged_data[start:end])\n#             start = end\n#         for (k, v), d in zip(self._learner_connection.items(), split_data):\n#             learn_task[k] = v.new_task({'name': task['name'], 'data': d})\n#             learn_task[k].start()\n#         for k, v in learn_task.items():\n#             v.join()\n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\n_demand_queue = Queue(maxsize=1)\n        self._data_result_queue = Queue(maxsize=1)\n        self._learn_info_queue = Queue(maxsize=1)\n\n        # Task-level learner and policy will only be set once received the task.\n        self._learner = None\n        self._policy_id = None\n\n    def start(self) -> None:\n        \"\"\"\n        Overview:\n            Start comm learner itself and the learner slave.\n        \"\"\"\n        BaseCommLearner.start(self)\n        self._slave.start()\n\n    def close(self) -> None:\n        \"\"\"\n        Overview:\n            Join learner thread and close learner if still running.\n            Then close learner slave and comm learner itself.\n        \"\"\"\n        if self._end_flag:\n            return\n        if self._learner is not None:\n            self.deal_with_learner_close()\n        self._slave.close()\n        BaseCommLearner.close(self)\n\n    def __del__(self) -> None:\n        \"\"\"\n        Overview:\n            Call ``close`` for deletion.\n        \"\"\"\n        self.close()\n\n    def deal_with_resource(self) -> dict:\n        \"\"\"\n        Overview:\n            Callback function. Return how many resources are needed to start current learner.\n        Returns:\n            - resource (:obj:`dict`): Resource info dict, including [\"gpu\"].\n        \"\"\"\n        return {'gpu': self._world_size}\n\n    def deal_with_learner_start(self, task_info: dict) -> None:\n        \"\"\"\n        Overview:\n            Callback function. Create a learner and help register its hooks. Start a learner thread of the created one.\n        Arguments:\n            - task_info (:obj:`dict`): Task info dict.\n\n        .. note::\n            In ``_create_learner`` method in base class ``BaseCommLearner``, 3 methods\n            ('get_data', 'send_policy', 'send_learn_info'), dataloader and policy are set.\n            You can refer to it for details.\n        \"\"\"\n        self._policy_id = task_info['policy_id']\n        self._league_save_checkpoint_path = task_info.get('league_save_checkpoint_path', None)\n        self._learner = self._create_learner(task_info)\n        for h in self.hooks4call:\n            self._learner.register_hook(h)\n        self._learner_thread = Thread(target=self._learner.start, args=(), daemon=True, name='learner_start')\n        self._learner_thread.start()\n\n    def deal_with_get_data(self) -> Any:\n        \"\"\"\n        Overview:\n            Callback function. Get data demand info dict from ``_data_demand_queue``,\n            which will be sent to coordinator afterwards.\n        Returns:\n            - data_demand (:obj:`Any`): Data demand info dict.\n        \"\"\"\n        data_demand = self._data_demand_queue.get()\n        return data_demand\n\n    def deal_with_learner_learn(self, data: dict) -> dict:\n        \"\"\"\n        Overview:\n            Callback function. Put training data info dict (i.e. meta data), which is received from coordinator, into\n            ``_data_result_queue``, and wait for ``get_data`` to retrieve. Wait for learner training and\n            get learn info dict from ``_learn_info_queue``. If task is finished, join the learner thread and\n            close the learner.\n        Returns:\n            - learn_info (:obj:`Any`): Learn info dict.\n        \"\"\"\n        self._data_result_queue.put(data)\n        learn_info = self._learn_info_queue.get()\n        return learn_info\n\n    def deal_with_learner_close(self) -> None:\n        self._learner.close()\n        self._learner_thread.join()\n        del self._learner_thread\n        self._learner = None\n        self._policy_id = None\n\n    # override\n    def send_policy(self, state_dict: dict) -> None:\n        \"\"\"\n        Overview:\n            Save learner's policy in corresponding path, called by ``SendPolicyHook``.\n        Arguments:\n            - state_dict (:obj:`dict`): State dict of the policy.\n        \"\"\"\n        if not os.path.exists(self._path_policy):\n            os.mkdir(self._path_policy)\n        path = self._policy_id\n        if self._path_policy not in path:\n            path = os.path.join(self._path_policy, path)\n        setattr(self, \"_latest_policy_path\", path)\n        save_file(path, state_dict, use_lock=True)\n\n        if self._league_save_checkpoint_path is not None:\n            save_file(self._league_save_checkpoint_path, state_dict, use_lock=True)\n\n    @staticmethod\n    def load_data_fn(path, meta: Dict[str, Any], decompressor: Callable) -> Any:\n        \"\"\"\n        Overview:\n            The function that is used to load data file.\n        Arguments:\n            - meta (:obj:`Dict[str, Any]`): Meta data info dict.\n            - decompressor (:obj:`Callable`): Decompress function.\n        Returns:\n            - s (:obj:`Any`): Data which is read from file.\n        \"\"\"\n        # Due to read-write conflict, read_file raise an error, therefore we set a while loop.\n        while True:\n            try:\n                s = read_from_di_store(path) if read_from_di_store else read_file(path, use_lock=False)\n                s = decompressor(s)\n                break\n            except Exception:\n                time.sleep(0.01)\n        unroll_len = meta.get('unroll_len', 1)\n        if 'unroll_split_begin' in meta:\n            begin = meta['unroll_split_begin']\n            if unroll_len == 1:\n                s = s[begin]\n                s.update(meta)\n            else:\n                end = begin + unroll_len\n                s = s[begin:end]\n                # add metadata key-value to stepdata\n                for i in range(len(s)):\n                    s[i].update(meta)\n        else:\n            s.update(meta)\n        return s\n\n    # override\n    def get_data(self, batch_size: int) -> List[Callable]:\n        \"\"\"\n        Overview:\n            Get a list of data loading function, which can be implemented by dataloader to read data from files.\n        Arguments:\n            - batch_size (:obj:`int`): Batch size.\n        Returns:\n            - data (:obj:`List[Callable]`): A list of callable data loading function.\n        \"\"\"\n        while self._learner is None:\n            time.sleep(1)\n        # Tell coordinator that we need training data, by putting info dict in data_demand_queue.\n        assert self._data_demand_queue.qsize() == 0\n        self._data_demand_queue.put({'batch_size': batch_size, 'cur_learner_iter': self._learner.last_iter.val})\n        # Get a list of meta data (data info dict) from coordinator, by getting info dict from data_result_queue.\n        data = self._data_result_queue.get()\n        assert isinstance(data, list)\n        assert len(data) == batch_size, '{}/{}'.format(len(data), batch_size)\n        # Transform meta data to callable data loading function (partial ``load_data_fn``).\n        decompressor = get_data_decompressor(data[0].get('compressor', 'none'))\n        data = [\n            partial(\n                FlaskFileSystemLearner.load_data_fn,\n                path=m['object_ref'] if read_from_di_store else os.path.join(self._path_data, m['data_id']),\n                meta=m,\n                decompressor=decompressor,\n            ) for m in data\n        ]\n        return data\n\n    # override", "completion": "```\ndef get_data(self, batch_size: int) -> List[Callable]:\n    while self._learner is None:\n        time.sleep(1)\n    assert self._data_demand_queue.qsize() == 0\n    self._data_demand_queue.put({'batch_size': batch_size, 'cur_learner_iter': self._learner.last_iter.val})\n    data = self._data_result_queue.get()\n    assert isinstance(data, list)\n    assert len(data) == batch_size, '{}/{}'.format(len(data), batch_size)\n    decompressor = get_data_decompressor(data[0].get('compressor', 'none'))\n    data = [\n        partial(\n            FlaskFileSystemLearner.load_data_fn,\n            path=m['object_ref'] if read_from_di_store else os.path.join(self._path_data, m['data_id']),\n            meta=m,\n            decompressor=decompressor,\n        ) for m in data\n    ]\n    return data\n```", "metadata": {"task_id": "opendilab_ACE/38", "ground_truth": "    def send_learn_info(self, learn_info: dict) -> None:", "fpath_tuple": ["opendilab_ACE", "ding", "worker", "learner", "comm", "flask_fs_learner.py"], "context_start_lineno": 110, "line_no": 293, "query_window": {"context": "        # Tell coordinator that we need training data, by putting info dict in data_demand_queue.\n        assert self._data_demand_queue.qsize() == 0\n        self._data_demand_queue.put({'batch_size': batch_size, 'cur_learner_iter': self._learner.last_iter.val})\n        # Get a list of meta data (data info dict) from coordinator, by getting info dict from data_result_queue.\n        data = self._data_result_queue.get()\n        assert isinstance(data, list)\n        assert len(data) == batch_size, '{}/{}'.format(len(data), batch_size)\n        # Transform meta data to callable data loading function (partial ``load_data_fn``).\n        decompressor = get_data_decompressor(data[0].get('compressor', 'none'))\n        data = [\n            partial(\n                FlaskFileSystemLearner.load_data_fn,\n                path=m['object_ref'] if read_from_di_store else os.path.join(self._path_data, m['data_id']),\n                meta=m,\n                decompressor=decompressor,\n            ) for m in data\n        ]\n        return data\n\n    # override", "metadata": {"fpath_tuple": ["opendilab_ACE", "ding", "worker", "learner", "comm", "flask_fs_learner.py"], "line_no": 293, "task_id": "opendilab_ACE/38", "start_line_no": 273, "end_line_no": 293, "window_size": 20, "context_start_lineno": 110, "repo": "opendilab_ACE"}}, "top_k_context": [{"context": "    def deal_with_get_data(self, task: dict) -> dict:\n        data_task = {}\n        for k, v in self._learner_connection.items():\n            data_task[k] = v.new_task({'name': task['name']})\n            data_task[k].start()\n        for k, v in data_task.items():\n            v.join()\n        # TODO deal with task fail\n        self._data_demand = {k: v.result for k, v in data_task.items()}\n        demand_list = list(self._data_demand.values())\n        # Merge data demand info by adding up all learners' demand batch size.\n        merged_demand = copy.deepcopy(demand_list[0])\n        merged_demand['batch_size'] = sum([d['batch_size'] for d in demand_list])\n        return merged_demand\n\n    def deal_with_learn(self, task: dict) -> dict:\n        learn_task = {}\n        merged_data = task['data']\n        # Split training data for each learner according to ``self._data_demand``.\n        split_data = []", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "adapter", "learner_aggregator.py"], "line_no": 190, "start_line_no": 180, "end_line_no": 200, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2742857142857143}, {"context": "        state_id = kwargs.get('data_id', None)\n        self.reset_state(state, state_id)\n        if hasattr(self._model, 'reset'):\n            return self._model.reset(*args, **kwargs)\n\n    def reset_state(self, state: Optional[list] = None, state_id: Optional[list] = None) -> None:\n        if state_id is None:\n            state_id = [i for i in range(self._state_num)]\n        if state is None:\n            state = [self._init_fn() for i in range(len(state_id))]\n        assert len(state) == len(state_id), '{}/{}'.format(len(state), len(state_id))\n        for idx, s in zip(state_id, state):\n            self._state[idx] = s\n\n    def before_forward(self, data: dict, state_id: Optional[list]) -> Tuple[dict, dict]:\n        if state_id is None:\n            state_id = [i for i in range(self._state_num)]\n\n        state_info = {idx: self._state[idx] for idx in state_id}\n        data['prev_state'] = list(state_info.values())", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "model", "wrapper", "model_wrappers.py"], "line_no": 120, "start_line_no": 110, "end_line_no": 130, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.27380952380952384}, {"context": "        start = 0\n        for item in self._data_demand.values():\n            end = item['batch_size'] + start\n            split_data.append(merged_data[start:end])\n            start = end\n        for (k, v), d in zip(self._learner_connection.items(), split_data):\n            learn_task[k] = v.new_task({'name': task['name'], 'data': d})\n            learn_task[k].start()\n        for k, v in learn_task.items():\n            v.join()\n        # TODO deal with task fail\n        info_list = [v.result for v in learn_task.values()]\n        # Merge learn info through ``merge_info`` method.\n        merged_info = self.merge_info(info_list)\n        return merged_info\n\n    @staticmethod\n    def merge_info(info: list) -> dict:\n        homogeneous_keys = ['learner_step', 'buffer_id', 'task_id', 'learner_done']\n        elem = info[0]", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "adapter", "learner_aggregator.py"], "line_no": 210, "start_line_no": 200, "end_line_no": 220, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.2692307692307692}, {"context": "                break\n            if cmd == 'get_data':\n                # Main worker asks for data.\n                data = self.data_source(self.batch_size)\n                # ``data`` can be callable, e.g. a function to read data from file, therefore we can divide\n                # this job to pieces, assign to every slave worker and accomplish jobs asynchronously.\n                # But if we get a list of dicts, which means the data has already been processed and\n                # can be used directly, we can put it directly in async_train_queue and wait it\n                # to be accessed by a user, e.g. learner.\n                if isinstance(data[0], dict):\n                    data = self.collate_fn(data)\n                    self.async_train_queue.put(data)\n                    p.send('pass')\n                else:\n                    p.send(data)\n        p.close()\n\n    def _async_loop(self, p: tm.multiprocessing.connection, c: tm.multiprocessing.connection) -> None:\n        \"\"\"\n        Overview:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "utils", "data", "dataloader.py"], "line_no": 170, "start_line_no": 160, "end_line_no": 180, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.26903553299492383}, {"context": "        # Merge data demand info by adding up all learners' demand batch size.\n        merged_demand = copy.deepcopy(demand_list[0])\n        merged_demand['batch_size'] = sum([d['batch_size'] for d in demand_list])\n        return merged_demand\n\n    def deal_with_learn(self, task: dict) -> dict:\n        learn_task = {}\n        merged_data = task['data']\n        # Split training data for each learner according to ``self._data_demand``.\n        split_data = []\n        start = 0\n        for item in self._data_demand.values():\n            end = item['batch_size'] + start\n            split_data.append(merged_data[start:end])\n            start = end\n        for (k, v), d in zip(self._learner_connection.items(), split_data):\n            learn_task[k] = v.new_task({'name': task['name'], 'data': d})\n            learn_task[k].start()\n        for k, v in learn_task.items():\n            v.join()", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "adapter", "learner_aggregator.py"], "line_no": 200, "start_line_no": 190, "end_line_no": 210, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.26519337016574585}, {"context": "        close_flag = False\n        learner_id = learner_task['learner_id']\n        while not self._end_flag:\n            try:\n                # get data\n                get_data_task = self._connection_learner[learner_id].new_task({'name': 'learner_get_data_task'})\n                get_data_task.start().join()\n                if get_data_task.status != TaskStatus.COMPLETED:\n                    # TODO(deal with fail task)\n                    self._logger.error('learner get_data_task failed: {}'.format(get_data_task.result))\n                    continue\n                result = get_data_task.result\n                task_id, buffer_id, batch_size = result['task_id'], result['buffer_id'], result['batch_size']\n                cur_learner_iter = result['cur_learner_iter']\n                sleep_count = 1\n                while True:\n                    data = self._callback_fn['deal_with_learner_get_data'](\n                        task_id, buffer_id, batch_size, cur_learner_iter\n                    )\n                    if self._end_flag or data is not None:", "metadata": [{"fpath_tuple": ["opendilab_ACE", "ding", "worker", "coordinator", "comm_coordinator.py"], "line_no": 410, "start_line_no": 400, "end_line_no": 420, "window_size": 20, "repo": "opendilab_ACE", "slice_size": 2}], "sim_score": 0.25862068965517243}], "window_size": 20, "slice_size": 2}}
{"prompt": "# Here are some relevant code fragments from other files of the repo:\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/unclip/pipeline_unclip.py\n# --------------------------------------------------\n#             super_res_latents = self.super_res_scheduler.step(\n#                 noise_pred, t, super_res_latents, prev_timestep=prev_timestep, generator=generator\n#             ).prev_sample\n# \n#         image = super_res_latents\n#         # done super res\n# \n#         # post processing\n# \n#         image = image * 0.5 + 0.5\n#         image = image.clamp(0, 1)\n#         image = image.cpu().permute(0, 2, 3, 1).float().numpy()\n# \n#         if output_type == \"pil\":\n#             image = self.numpy_to_pil(image)\n# \n#         if not return_dict:\n#             return (image,)\n# \n#         return ImagePipelineOutput(images=image)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# examples/community/stable_unclip.py\n# --------------------------------------------------\n#                 prev_timestep = prior_timesteps_tensor[i + 1]\n# \n#             prior_latents = self.prior_scheduler.step(\n#                 predicted_image_embedding,\n#                 timestep=t,\n#                 sample=prior_latents,\n#                 generator=generator,\n#                 prev_timestep=prev_timestep,\n#             ).prev_sample\n# \n#         prior_latents = self.prior.post_process_latents(prior_latents)\n# \n#         image_embeddings = prior_latents\n# \n#         output = self.decoder_pipe(\n#             image=image_embeddings,\n#             height=height,\n#             width=width,\n#             num_inference_steps=decoder_num_inference_steps,\n#             guidance_scale=decoder_guidance_scale,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/score_sde_ve/pipeline_score_sde_ve.py\n# --------------------------------------------------\n#             # correction step\n#             for _ in range(self.scheduler.config.correct_steps):\n#                 model_output = self.unet(sample, sigma_t).sample\n#                 sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n# \n#             # prediction step\n#             model_output = model(sample, sigma_t).sample\n#             output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n# \n#             sample, sample_mean = output.prev_sample, output.prev_sample_mean\n# \n#         sample = sample_mean.clamp(0, 1)\n#         sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n#         if output_type == \"pil\":\n#             sample = self.numpy_to_pil(sample)\n# \n#         if not return_dict:\n#             return (sample,)\n# \n#         return ImagePipelineOutput(images=sample)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/unclip/pipeline_unclip.py\n# --------------------------------------------------\n# \n#             prior_latents = self.prior_scheduler.step(\n#                 predicted_image_embedding,\n#                 timestep=t,\n#                 sample=prior_latents,\n#                 generator=generator,\n#                 prev_timestep=prev_timestep,\n#             ).prev_sample\n# \n#         prior_latents = self.prior.post_process_latents(prior_latents)\n# \n#         image_embeddings = prior_latents\n# \n#         # done prior\n# \n#         # decoder\n# \n#         text_encoder_hidden_states, additive_clip_time_embeddings = self.text_proj(\n#             image_embeddings=image_embeddings,\n#             prompt_embeds=prompt_embeds,\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/stochastic_karras_ve/pipeline_stochastic_karras_ve.py\n# --------------------------------------------------\n#                 model_output = (sigma_prev / 2) * model((step_output.prev_sample + 1) / 2, sigma_prev / 2).sample\n#                 step_output = self.scheduler.step_correct(\n#                     model_output,\n#                     sigma_hat,\n#                     sigma_prev,\n#                     sample_hat,\n#                     step_output.prev_sample,\n#                     step_output[\"derivative\"],\n#                 )\n#             sample = step_output.prev_sample\n# \n#         sample = (sample / 2 + 0.5).clamp(0, 1)\n#         image = sample.cpu().permute(0, 2, 3, 1).numpy()\n#         if output_type == \"pil\":\n#             image = self.numpy_to_pil(sample)\n# \n#         if not return_dict:\n#             return (image,)\n# \n#         return ImagePipelineOutput(images=image)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/dit/pipeline_dit.py\n# --------------------------------------------------\n#         if guidance_scale > 1:\n#             latents, _ = latent_model_input.chunk(2, dim=0)\n#         else:\n#             latents = latent_model_input\n# \n#         latents = 1 / self.vae.config.scaling_factor * latents\n#         samples = self.vae.decode(latents).sample\n# \n#         samples = (samples / 2 + 0.5).clamp(0, 1)\n# \n#         # we always cast to float32 as this does not cause significant overhead and is compatible with bfloat16\n#         samples = samples.cpu().permute(0, 2, 3, 1).float().numpy()\n# \n#         if output_type == \"pil\":\n#             samples = self.numpy_to_pil(samples)\n# \n#         if not return_dict:\n#             return (samples,)\n# \n#         return ImagePipelineOutput(images=samples)\n# --------------------------------------------------\n# the below code fragment can be found in:\n# src/diffusers/pipelines/vq_diffusion/pipeline_vq_diffusion.py\n# --------------------------------------------------\n#             # call the callback, if provided\n#             if callback is not None and i % callback_steps == 0:\n#                 callback(i, t, sample)\n# \n#         embedding_channels = self.vqvae.config.vq_embed_dim\n#         embeddings_shape = (batch_size, self.transformer.height, self.transformer.width, embedding_channels)\n#         embeddings = self.vqvae.quantize.get_codebook_entry(sample, shape=embeddings_shape)\n#         image = self.vqvae.decode(embeddings, force_not_quantize=True).sample\n# \n#         image = (image / 2 + 0.5).clamp(0, 1)\n#         image = image.cpu().permute(0, 2, 3, 1).numpy()\n# \n#         if output_type == \"pil\":\n#             image = self.numpy_to_pil(image)\n# \n#         if not return_dict:\n#             return (image,)\n# \n#         return ImagePipelineOutput(images=image)\n# \n# --------------------------------------------------\n\"\"\"Based on the above, complete the following code:\"\"\"\n\ncheduler` or `DDPMScheduler`]): de-noising scheduler\n    \"\"\"\n\n    _optional_components = [\"vqvae\"]\n\n    def __init__(\n        self,\n        vqvae: AutoencoderKL,\n        unet: UNet2DConditionModel,\n        mel: Mel,\n        scheduler: Union[DDIMScheduler, DDPMScheduler],\n    ):\n        super().__init__()\n        self.register_modules(unet=unet, scheduler=scheduler, mel=mel, vqvae=vqvae)\n\n    def get_input_dims(self) -> Tuple:\n        \"\"\"Returns dimension of input image\n\n        Returns:\n            `Tuple`: (height, width)\n        \"\"\"\n        input_module = self.vqvae if self.vqvae is not None else self.unet\n        # For backwards compatibility\n        sample_size = (\n            (input_module.sample_size, input_module.sample_size)\n            if type(input_module.sample_size) == int\n            else input_module.sample_size\n        )\n        return sample_size\n\n    def get_default_steps(self) -> int:\n        \"\"\"Returns default number of steps recommended for inference\n\n        Returns:\n            `int`: number of steps\n        \"\"\"\n        return 50 if isinstance(self.scheduler, DDIMScheduler) else 1000\n\n    @torch.no_grad()\n    def __call__(\n        self,\n        batch_size: int = 1,\n        audio_file: str = None,\n        raw_audio: np.ndarray = None,\n        slice: int = 0,\n        start_step: int = 0,\n        steps: int = None,\n        generator: torch.Generator = None,\n        mask_start_secs: float = 0,\n        mask_end_secs: float = 0,\n        step_generator: torch.Generator = None,\n        eta: float = 0,\n        noise: torch.Tensor = None,\n        encoding: torch.Tensor = None,\n        return_dict=True,\n    ) -> Union[\n        Union[AudioPipelineOutput, ImagePipelineOutput],\n        Tuple[List[Image.Image], Tuple[int, List[np.ndarray]]],\n    ]:\n        \"\"\"Generate random mel spectrogram from audio input and convert to audio.\n\n        Args:\n            batch_size (`int`): number of samples to generate\n            audio_file (`str`): must be a file on disk due to Librosa limitation or\n            raw_audio (`np.ndarray`): audio as numpy array\n            slice (`int`): slice number of audio to convert\n            start_step (int): step to start from\n            steps (`int`): number of de-noising steps (defaults to 50 for DDIM, 1000 for DDPM)\n            generator (`torch.Generator`): random number generator or None\n            mask_start_secs (`float`): number of seconds of audio to mask (not generate) at start\n            mask_end_secs (`float`): number of seconds of audio to mask (not generate) at end\n            step_generator (`torch.Generator`): random number generator used to de-noise or None\n            eta (`float`): parameter between 0 and 1 used with DDIM scheduler\n            noise (`torch.Tensor`): noise tensor of shape (batch_size, 1, height, width) or None\n            encoding (`torch.Tensor`): for UNet2DConditionModel shape (batch_size, seq_length, cross_attention_dim)\n            return_dict (`bool`): if True return AudioPipelineOutput, ImagePipelineOutput else Tuple\n\n        Returns:\n            `List[PIL Image]`: mel spectrograms (`float`, `List[np.ndarray]`): sample rate and raw audios\n        \"\"\"\n\n        steps = steps or self.get_default_steps()\n        self.scheduler.set_timesteps(steps)\n        step_generator = step_generator or generator\n        # For backwards compatibility\n        if type(self.unet.sample_size) == int:\n            self.unet.sample_size = (self.unet.sample_size, self.unet.sample_size)\n        input_dims = self.get_input_dims()\n        self.mel.set_resolution(x_res=input_dims[1], y_res=input_dims[0])\n        if noise is None:\n            noise = randn_tensor(\n                (\n                    batch_size,\n                    self.unet.in_channels,\n                    self.unet.sample_size[0],\n                    self.unet.sample_size[1],\n                ),\n                generator=generator,\n                device=self.device,\n            )\n        images = noise\n        mask = None\n\n        if audio_file is not None or raw_audio is not None:\n            self.mel.load_audio(audio_file, raw_audio)\n            input_image = self.mel.audio_slice_to_image(slice)\n            input_image = np.frombuffer(input_image.tobytes(), dtype=\"uint8\").reshape(\n                (input_image.height, input_image.width)\n            )\n            input_image = (input_image / 255) * 2 - 1\n            input_images = torch.tensor(input_image[np.newaxis, :, :], dtype=torch.float).to(self.device)\n\n            if self.vqvae is not None:\n                input_images = self.vqvae.encode(torch.unsqueeze(input_images, 0)).latent_dist.sample(\n                    generator=generator\n                )[0]\n                input_images = self.vqvae.config.scaling_factor * input_images\n\n            if start_step > 0:\n                images[0, 0] = self.scheduler.add_noise(input_images, noise, self.scheduler.timesteps[start_step - 1])\n\n            pixels_per_second = (\n                self.unet.sample_size[1] * self.mel.get_sample_rate() / self.mel.x_res / self.mel.hop_length\n            )\n            mask_start = int(mask_start_secs * pixels_per_second)\n            mask_end = int(mask_end_secs * pixels_per_second)\n            mask = self.scheduler.add_noise(input_images, noise, torch.tensor(self.scheduler.timesteps[start_step:]))\n\n        for step, t in enumerate(self.progress_bar(self.scheduler.timesteps[start_step:])):\n            if isinstance(self.unet, UNet2DConditionModel):\n                model_output = self.unet(images, t, encoding)[\"sample\"]\n            else:\n                model_output = self.unet(images, t)[\"sample\"]\n\n            if isinstance(self.scheduler, DDIMScheduler):\n                images = self.scheduler.step(\n                    model_output=model_output,\n                    timestep=t,\n                    sample=images,\n                    eta=eta,\n                    generator=step_generator,\n                )[\"prev_sample\"]\n            else:\n                images = self.scheduler.step(\n                    model_output=model_output,\n                    timestep=t,\n                    sample=images,\n                    generator=step_generator,\n                )[\"prev_sample\"]\n\n            if mask is not None:\n                if mask_start > 0:\n                    images[:, :, :, :mask_start] = mask[:, step, :, :mask_start]\n                if mask_end > 0:\n                    images[:, :, :, -mask_end:] = mask[:, step, :, -mask_end:]\n\n        if self.vqvae is not None:\n            # 0.18215 was scaling factor used in training to ensure unit variance\n            images = 1 / self.vqvae.config.scaling_factor * images\n            images = self.vqvae.decode(images)[\"sample\"]\n\n        images = (images / 2 + 0.5).clamp(0, 1)", "completion": "images = images.cpu().permute(0, 2, 3, 1).numpy()\n\n        if return_dict:\n            return ImagePipelineOutput(images=images)\n        else:\n            return (images,)", "metadata": {"task_id": "huggingface_diffusers/173", "ground_truth": "        images = images.cpu().permute(0, 2, 3, 1).numpy()", "fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "audio_diffusion", "pipeline_audio_diffusion.py"], "context_start_lineno": 39, "line_no": 201, "query_window": {"context": "            else:\n                images = self.scheduler.step(\n                    model_output=model_output,\n                    timestep=t,\n                    sample=images,\n                    generator=step_generator,\n                )[\"prev_sample\"]\n\n            if mask is not None:\n                if mask_start > 0:\n                    images[:, :, :, :mask_start] = mask[:, step, :, :mask_start]\n                if mask_end > 0:\n                    images[:, :, :, -mask_end:] = mask[:, step, :, -mask_end:]\n\n        if self.vqvae is not None:\n            # 0.18215 was scaling factor used in training to ensure unit variance\n            images = 1 / self.vqvae.config.scaling_factor * images\n            images = self.vqvae.decode(images)[\"sample\"]\n\n        images = (images / 2 + 0.5).clamp(0, 1)", "metadata": {"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "audio_diffusion", "pipeline_audio_diffusion.py"], "line_no": 201, "task_id": "huggingface_diffusers/173", "start_line_no": 181, "end_line_no": 201, "window_size": 20, "context_start_lineno": 39, "repo": "huggingface_diffusers"}}, "top_k_context": [{"context": "                model_output -= torch.logsumexp(model_output, dim=1, keepdim=True)\n\n            model_output = self.truncate(model_output, truncation_rate)\n\n            # remove `log(0)`'s (`-inf`s)\n            model_output = model_output.clamp(-70)\n\n            # compute the previous noisy sample x_t -> x_t-1\n            sample = self.scheduler.step(model_output, timestep=t, sample=sample, generator=generator).prev_sample\n\n            # call the callback, if provided\n            if callback is not None and i % callback_steps == 0:\n                callback(i, t, sample)\n\n        embedding_channels = self.vqvae.config.vq_embed_dim\n        embeddings_shape = (batch_size, self.transformer.height, self.transformer.width, embedding_channels)\n        embeddings = self.vqvae.quantize.get_codebook_entry(sample, shape=embeddings_shape)\n        image = self.vqvae.decode(embeddings, force_not_quantize=True).sample\n\n        image = (image / 2 + 0.5).clamp(0, 1)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "vq_diffusion", "pipeline_vq_diffusion.py"], "line_no": 290, "start_line_no": 280, "end_line_no": 300, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3464052287581699}, {"context": "            # learned sigma\n            if self.transformer.config.out_channels // 2 == latent_channels:\n                model_output, _ = torch.split(noise_pred, latent_channels, dim=1)\n            else:\n                model_output = noise_pred\n\n            # compute previous image: x_t -> x_t-1\n            latent_model_input = self.scheduler.step(model_output, t, latent_model_input).prev_sample\n\n        if guidance_scale > 1:\n            latents, _ = latent_model_input.chunk(2, dim=0)\n        else:\n            latents = latent_model_input\n\n        latents = 1 / self.vae.config.scaling_factor * latents\n        samples = self.vae.decode(latents).sample\n\n        samples = (samples / 2 + 0.5).clamp(0, 1)\n\n        # we always cast to float32 as this does not cause significant overhead and is compatible with bfloat16", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "dit", "pipeline_dit.py"], "line_no": 180, "start_line_no": 170, "end_line_no": 190, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.34507042253521125}, {"context": "\n            # 4. Evaluate dx/dt at sigma_hat\n            # 5. Take Euler step from sigma to sigma_prev\n            step_output = self.scheduler.step(model_output, sigma_hat, sigma_prev, sample_hat)\n\n            if sigma_prev != 0:\n                # 6. Apply 2nd order correction\n                # The model inputs and output are adjusted by following eq. (213) in [1].\n                model_output = (sigma_prev / 2) * model((step_output.prev_sample + 1) / 2, sigma_prev / 2).sample\n                step_output = self.scheduler.step_correct(\n                    model_output,\n                    sigma_hat,\n                    sigma_prev,\n                    sample_hat,\n                    step_output.prev_sample,\n                    step_output[\"derivative\"],\n                )\n            sample = step_output.prev_sample\n\n        sample = (sample / 2 + 0.5).clamp(0, 1)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "stochastic_karras_ve", "pipeline_stochastic_karras_ve.py"], "line_no": 110, "start_line_no": 100, "end_line_no": 120, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.33858267716535434}, {"context": "            if do_classifier_free_guidance:\n                predicted_image_embedding_uncond, predicted_image_embedding_text = predicted_image_embedding.chunk(2)\n                predicted_image_embedding = predicted_image_embedding_uncond + prior_guidance_scale * (\n                    predicted_image_embedding_text - predicted_image_embedding_uncond\n                )\n\n            if i + 1 == prior_timesteps_tensor.shape[0]:\n                prev_timestep = None\n            else:\n                prev_timestep = prior_timesteps_tensor[i + 1]\n\n            prior_latents = self.prior_scheduler.step(\n                predicted_image_embedding,\n                timestep=t,\n                sample=prior_latents,\n                generator=generator,\n                prev_timestep=prev_timestep,\n            ).prev_sample\n\n        prior_latents = self.prior.post_process_latents(prior_latents)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "unclip", "pipeline_unclip.py"], "line_no": 380, "start_line_no": 370, "end_line_no": 390, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3360655737704918}, {"context": "\n            # correction step\n            for _ in range(self.scheduler.config.correct_steps):\n                model_output = self.unet(sample, sigma_t).sample\n                sample = self.scheduler.step_correct(model_output, sample, generator=generator).prev_sample\n\n            # prediction step\n            model_output = model(sample, sigma_t).sample\n            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)\n\n            sample, sample_mean = output.prev_sample, output.prev_sample_mean\n\n        sample = sample_mean.clamp(0, 1)\n        sample = sample.cpu().permute(0, 2, 3, 1).numpy()\n        if output_type == \"pil\":\n            sample = self.numpy_to_pil(sample)\n\n        if not return_dict:\n            return (sample,)\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "score_sde_ve", "pipeline_score_sde_ve.py"], "line_no": 90, "start_line_no": 80, "end_line_no": 100, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3360655737704918}, {"context": "\n            if do_classifier_free_guidance:\n                predicted_image_embedding_uncond, predicted_image_embedding_text = predicted_image_embedding.chunk(2)\n                predicted_image_embedding = predicted_image_embedding_uncond + prior_guidance_scale * (\n                    predicted_image_embedding_text - predicted_image_embedding_uncond\n                )\n\n            if i + 1 == prior_timesteps_tensor.shape[0]:\n                prev_timestep = None\n            else:\n                prev_timestep = prior_timesteps_tensor[i + 1]\n\n            prior_latents = self.prior_scheduler.step(\n                predicted_image_embedding,\n                timestep=t,\n                sample=prior_latents,\n                generator=generator,\n                prev_timestep=prev_timestep,\n            ).prev_sample\n", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "examples", "community", "stable_unclip.py"], "line_no": 260, "start_line_no": 250, "end_line_no": 270, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.3333333333333333}, {"context": "                prev_timestep = None\n            else:\n                prev_timestep = super_res_timesteps_tensor[i + 1]\n\n            # compute the previous noisy sample x_t -> x_t-1\n            super_res_latents = self.super_res_scheduler.step(\n                noise_pred, t, super_res_latents, prev_timestep=prev_timestep, generator=generator\n            ).prev_sample\n\n        image = super_res_latents\n        # done super res\n\n        # post processing\n\n        image = image * 0.5 + 0.5\n        image = image.clamp(0, 1)\n        image = image.cpu().permute(0, 2, 3, 1).float().numpy()\n\n        if output_type == \"pil\":\n            image = self.numpy_to_pil(image)", "metadata": [{"fpath_tuple": ["huggingface_diffusers", "src", "diffusers", "pipelines", "unclip", "pipeline_unclip.py"], "line_no": 520, "start_line_no": 510, "end_line_no": 530, "window_size": 20, "repo": "huggingface_diffusers", "slice_size": 2}], "sim_score": 0.32575757575757575}], "window_size": 20, "slice_size": 2}}
