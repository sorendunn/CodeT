{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Subsets for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Define the seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "# Define the fraction of lines you want in the random subset\n",
    "FRACTION = 0.1\n",
    "\n",
    "def create_random_subset_jsonl(input_filepath, output_filepath, seed):\n",
    "    random.seed(seed)  # Set the seed for reproducible results\n",
    "    lines = []\n",
    "\n",
    "    # Step 1: Read the original JSONL file and store the lines\n",
    "    with open(input_filepath, 'r') as infile:\n",
    "        for line in infile:\n",
    "            lines.append(line.strip())  # Strip to remove the newline at the end\n",
    "\n",
    "    # Step 2: Randomly select a subset of the lines\n",
    "    subset_size = int(FRACTION * len(lines))\n",
    "    random_subset = random.sample(lines, subset_size)\n",
    "\n",
    "    # Step 3: Write the random subset to the output JSONL file\n",
    "    with open(output_filepath, 'w') as outfile:\n",
    "        for line in random_subset:\n",
    "            outfile.write(line + '\\n')  # Add a newline at the end\n",
    "\n",
    "# Replace with your input and output file paths\n",
    "base_jsonl_name = \"rg-one-gram-ws-20-ss-2-fixed\"\n",
    "input_jsonl_fp = 'datasets/' + base_jsonl_name + '.jsonl'\n",
    "output_jsonl_fp = 'subsets/' + base_jsonl_name + \"_\" + str(FRACTION) + '.jsonl'\n",
    "\n",
    "# Create a random subset JSONL file\n",
    "create_random_subset_jsonl(input_jsonl_fp, output_jsonl_fp, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Here are some relevant code fragments from other files of the repo:\n",
      "# --------------------------------------------------\n",
      "# the below code fragment can be found in:\n",
      "# torchrl/envs/transforms/transforms.py\n",
      "# --------------------------------------------------\n",
      "# \n",
      "#     def empty_cache(self):\n",
      "#         self.__dict__[\"_parent\"] = None\n",
      "# \n",
      "# \n",
      "# class TransformedEnv(EnvBase):\n",
      "#     \"\"\"A transformed_in environment.\n",
      "# \n",
      "#     Args:\n",
      "#         env (EnvBase): original environment to be transformed_in.\n",
      "#         transform (Transform, optional): transform to apply to the tensordict resulting\n",
      "#             from :obj:`env.step(td)`. If none is provided, an empty Compose\n",
      "#             placeholder in an eval mode is used.\n",
      "#         cache_specs (bool, optional): if True, the specs will be cached once\n",
      "#             and for all after the first call (i.e. the specs will be\n",
      "#             transformed_in only once). If the transform changes during\n",
      "#             training, the original spec transform may not be valid anymore,\n",
      "#             in which case this value should be set  to `False`. Default is\n",
      "#             `True`.\n",
      "# \n",
      "# --------------------------------------------------\n",
      "# the below code fragment can be found in:\n",
      "# torchrl/envs/libs/dm_control.py\n",
      "# --------------------------------------------------\n",
      "#                 self._env.reward_spec(), device=self.device\n",
      "#             )\n",
      "#             if len(reward_spec.shape) == 0:\n",
      "#                 reward_spec.shape = torch.Size([1])\n",
      "#             self.__dict__[\"_reward_spec\"] = reward_spec\n",
      "#         return self._reward_spec\n",
      "# \n",
      "#     @reward_spec.setter\n",
      "#     def reward_spec(self, value: TensorSpec) -> None:\n",
      "#         if not hasattr(value, \"shape\"):\n",
      "#             raise TypeError(\n",
      "#                 f\"reward_spec of type {type(value)} do not have a shape \" f\"attribute.\"\n",
      "#             )\n",
      "#         if len(value.shape) == 0:\n",
      "#             raise RuntimeError(\n",
      "#                 \"the reward_spec shape cannot be empty (this error\"\n",
      "#                 \" usually comes from trying to set a reward_spec\"\n",
      "#                 \" with a null number of dimensions. Try using a multidimensional\"\n",
      "#                 \" spec instead, for instance with a singleton dimension at the tail).\"\n",
      "#             )\n",
      "# --------------------------------------------------\n",
      "# the below code fragment can be found in:\n",
      "# torchrl/envs/vec_env.py\n",
      "# --------------------------------------------------\n",
      "#         if self._observation_spec is None:\n",
      "#             self._set_properties()\n",
      "#         return self._observation_spec\n",
      "# \n",
      "#     @observation_spec.setter\n",
      "#     def observation_spec(self, value: TensorSpec) -> None:\n",
      "#         if not isinstance(value, CompositeSpec) and value is not None:\n",
      "#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n",
      "#         self.__dict__[\"_observation_spec\"] = value\n",
      "# \n",
      "#     @property\n",
      "#     def input_spec(self) -> TensorSpec:\n",
      "#         if self._input_spec is None:\n",
      "#             self._set_properties()\n",
      "#         return self._input_spec\n",
      "# \n",
      "#     @input_spec.setter\n",
      "#     def input_spec(self, value: TensorSpec) -> None:\n",
      "#         if not isinstance(value, CompositeSpec) and value is not None:\n",
      "#             raise TypeError(\"The type of an input_spec must be Composite.\")\n",
      "# --------------------------------------------------\n",
      "# the below code fragment can be found in:\n",
      "# torchrl/envs/libs/dm_control.py\n",
      "# --------------------------------------------------\n",
      "#         self.__dict__[\"_input_spec\"] = value\n",
      "# \n",
      "#     @property\n",
      "#     def observation_spec(self) -> TensorSpec:\n",
      "#         if self._observation_spec is None:\n",
      "#             self.__dict__[\"_observation_spec\"] = _dmcontrol_to_torchrl_spec_transform(\n",
      "#                 self._env.observation_spec(), device=self.device\n",
      "#             )\n",
      "#         return self._observation_spec\n",
      "# \n",
      "#     @observation_spec.setter\n",
      "#     def observation_spec(self, value: TensorSpec) -> None:\n",
      "#         if not isinstance(value, CompositeSpec):\n",
      "#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n",
      "#         self.__dict__[\"_observation_spec\"] = value\n",
      "# \n",
      "#     @property\n",
      "#     def reward_spec(self) -> TensorSpec:\n",
      "#         if self._reward_spec is None:\n",
      "#             reward_spec = _dmcontrol_to_torchrl_spec_transform(\n",
      "# --------------------------------------------------\n",
      "# the below code fragment can be found in:\n",
      "# torchrl/envs/vec_env.py\n",
      "# --------------------------------------------------\n",
      "#         self.__dict__[\"_input_spec\"] = value\n",
      "# \n",
      "#     @property\n",
      "#     def reward_spec(self) -> TensorSpec:\n",
      "#         if self._reward_spec is None:\n",
      "#             self._set_properties()\n",
      "#         return self._reward_spec\n",
      "# \n",
      "#     @reward_spec.setter\n",
      "#     def reward_spec(self, value: TensorSpec) -> None:\n",
      "#         if not hasattr(value, \"shape\") and value is not None:\n",
      "#             raise TypeError(\n",
      "#                 f\"reward_spec of type {type(value)} do not have a shape \" f\"attribute.\"\n",
      "#             )\n",
      "#         if value is not None and len(value.shape) == 0:\n",
      "#             raise RuntimeError(\n",
      "#                 \"the reward_spec shape cannot be empty (this error\"\n",
      "#                 \" usually comes from trying to set a reward_spec\"\n",
      "#                 \" with a null number of dimensions. Try using a multidimensional\"\n",
      "#                 \" spec instead, for instance with a singleton dimension at the tail).\"\n",
      "# --------------------------------------------------\n",
      "# the below code fragment can be found in:\n",
      "# torchrl/envs/vec_env.py\n",
      "# --------------------------------------------------\n",
      "#     @property\n",
      "#     def input_spec(self) -> TensorSpec:\n",
      "#         if self._input_spec is None:\n",
      "#             self._set_properties()\n",
      "#         return self._input_spec\n",
      "# \n",
      "#     @input_spec.setter\n",
      "#     def input_spec(self, value: TensorSpec) -> None:\n",
      "#         if not isinstance(value, CompositeSpec) and value is not None:\n",
      "#             raise TypeError(\"The type of an input_spec must be Composite.\")\n",
      "#         self.__dict__[\"_input_spec\"] = value\n",
      "# \n",
      "#     @property\n",
      "#     def reward_spec(self) -> TensorSpec:\n",
      "#         if self._reward_spec is None:\n",
      "#             self._set_properties()\n",
      "#         return self._reward_spec\n",
      "# \n",
      "#     @reward_spec.setter\n",
      "#     def reward_spec(self, value: TensorSpec) -> None:\n",
      "# --------------------------------------------------\n",
      "# the below code fragment can be found in:\n",
      "# torchrl/envs/libs/dm_control.py\n",
      "# --------------------------------------------------\n",
      "#     @observation_spec.setter\n",
      "#     def observation_spec(self, value: TensorSpec) -> None:\n",
      "#         if not isinstance(value, CompositeSpec):\n",
      "#             raise TypeError(\"The type of an observation_spec must be Composite.\")\n",
      "#         self.__dict__[\"_observation_spec\"] = value\n",
      "# \n",
      "#     @property\n",
      "#     def reward_spec(self) -> TensorSpec:\n",
      "#         if self._reward_spec is None:\n",
      "#             reward_spec = _dmcontrol_to_torchrl_spec_transform(\n",
      "#                 self._env.reward_spec(), device=self.device\n",
      "#             )\n",
      "#             if len(reward_spec.shape) == 0:\n",
      "#                 reward_spec.shape = torch.Size([1])\n",
      "#             self.__dict__[\"_reward_spec\"] = reward_spec\n",
      "#         return self._reward_spec\n",
      "# \n",
      "#     @reward_spec.setter\n",
      "#     def reward_spec(self, value: TensorSpec) -> None:\n",
      "#         if not hasattr(value, \"shape\"):\n",
      "# --------------------------------------------------\n",
      "\"\"\"Based on the above, complete the following code:\"\"\"\n",
      "\n",
      "ose but with other features that we don't want to loose.\n",
      "                transform = [transform]\n",
      "            else:\n",
      "                for t in transform:\n",
      "                    t.reset_parent()\n",
      "            env_transform = env.transform\n",
      "            if type(env_transform) is not Compose:\n",
      "                env_transform.reset_parent()\n",
      "                env_transform = [env_transform]\n",
      "            else:\n",
      "                for t in env_transform:\n",
      "                    t.reset_parent()\n",
      "            transform = Compose(*env_transform, *transform).to(device)\n",
      "        else:\n",
      "            self._set_env(env, device)\n",
      "            if transform is None:\n",
      "                transform = Compose()\n",
      "            else:\n",
      "                transform = transform.to(device)\n",
      "        self.transform = transform\n",
      "\n",
      "        self._last_obs = None\n",
      "        self.cache_specs = cache_specs\n",
      "        self.__dict__[\"_reward_spec\"] = None\n",
      "        self.__dict__[\"_input_spec\"] = None\n",
      "        self.__dict__[\"_observation_spec\"] = None\n",
      "        self.batch_size = self.base_env.batch_size\n",
      "\n",
      "    def _set_env(self, env: EnvBase, device) -> None:\n",
      "        if device != env.device:\n",
      "            env = env.to(device)\n",
      "        self.base_env = env\n",
      "        # updates need not be inplace, as transforms may modify values out-place\n",
      "        self.base_env._inplace_update = False\n",
      "\n",
      "    @property\n",
      "    def transform(self) -> Transform:\n",
      "        return self._transform\n",
      "\n",
      "    @transform.setter\n",
      "    def transform(self, transform: Transform):\n",
      "        if not isinstance(transform, Transform):\n",
      "            raise ValueError(\n",
      "                f\"\"\"Expected a transform of type torchrl.envs.transforms.Transform,\n",
      "but got an object of type {type(transform)}.\"\"\"\n",
      "            )\n",
      "        prev_transform = self.transform\n",
      "        if prev_transform is not None:\n",
      "            prev_transform.empty_cache()\n",
      "            prev_transform.__dict__[\"_container\"] = None\n",
      "        transform.set_container(self)\n",
      "        transform.eval()\n",
      "        self._transform = transform\n",
      "\n",
      "    @property\n",
      "    def device(self) -> bool:\n",
      "        return self.base_env.device\n",
      "\n",
      "    @device.setter\n",
      "    def device(self, value):\n",
      "        raise RuntimeError(\"device is a read-only property\")\n",
      "\n",
      "    @property\n",
      "    def batch_locked(self) -> bool:\n",
      "        return self.base_env.batch_locked\n",
      "\n",
      "    @batch_locked.setter\n",
      "    def batch_locked(self, value):\n",
      "        raise RuntimeError(\"batch_locked is a read-only property\")\n",
      "\n",
      "    @property\n",
      "    def run_type_checks(self) -> bool:\n",
      "        return self.base_env.run_type_checks\n",
      "\n",
      "    @run_type_checks.setter\n",
      "    def run_type_checks(self, value):\n",
      "        raise RuntimeError(\n",
      "            \"run_type_checks is a read-only property for TransformedEnvs\"\n",
      "        )\n",
      "\n",
      "    @property\n",
      "    def _inplace_update(self):\n",
      "        return self.base_env._inplace_update\n",
      "\n",
      "    @property\n",
      "    def observation_spec(self) -> TensorSpec:\n",
      "        \"\"\"Observation spec of the transformed environment.\"\"\"\n",
      "        if self._observation_spec is None or not self.cache_specs:\n",
      "            observation_spec = self.transform.transform_observation_spec(\n",
      "                self.base_env.observation_spec.clone()\n",
      "            )\n",
      "            if self.cache_specs:\n",
      "                self.__dict__[\"_observation_spec\"] = observation_spec\n",
      "        else:\n",
      "            observation_spec = self._observation_spec\n",
      "        return observation_spec\n",
      "\n",
      "    @property\n",
      "    def action_spec(self) -> TensorSpec:\n",
      "        \"\"\"Action spec of the transformed environment.\"\"\"\n",
      "        return self.input_spec[\"action\"]\n",
      "\n",
      "    @property\n",
      "    def input_spec(self) -> TensorSpec:\n",
      "        \"\"\"Action spec of the transformed environment.\"\"\"\n",
      "        if self._input_spec is None or not self.cache_specs:\n",
      "            input_spec = self.transform.transform_input_spec(\n",
      "                self.base_env.input_spec.clone()\n",
      "            )\n",
      "            if self.cache_specs:\n",
      "                self.__dict__[\"_input_spec\"] = input_spec\n",
      "        else:\n",
      "            input_spec = self._input_spec\n",
      "        return input_spec\n",
      "\n",
      "    @property\n",
      "    def reward_spec(self) -> TensorSpec:\n",
      "        \"\"\"Reward spec of the transformed environment.\"\"\"\n",
      "        if self._reward_spec is None or not self.cache_specs:\n",
      "            reward_spec = self.transform.transform_reward_spec(\n",
      "                self.base_env.reward_spec.clone()\n",
      "            )\n",
      "            if self.cache_specs:\n",
      "                self.__dict__[\"_reward_spec\"] = reward_spec\n",
      "        else:\n",
      "            reward_spec = self._reward_spec\n",
      "        return reward_spec\n",
      "\n",
      "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
      "        tensordict = tensordict.clone(False)\n",
      "        tensordict_in = self.transform.inv(tensordict)\n",
      "        tensordict_out = self.base_env._step(tensordict_in)\n",
      "        tensordict_out = (\n",
      "            tensordict_out.update(  # update the output with the original tensordict\n",
      "                tensordict.exclude(\n",
      "                    *tensordict_out.keys()\n",
      "                )  # exclude the newly written keys\n",
      "            )\n",
      "        )\n",
      "        next_tensordict = self.transform._step(tensordict_out)\n",
      "        # tensordict_out.update(next_tensordict, inplace=False)\n",
      "\n",
      "        return next_tensordict\n",
      "\n",
      "    def set_seed(\n",
      "        self, seed: Optional[int] = None, static_seed: bool = False\n",
      "    ) -> Optional[int]:\n",
      "        \"\"\"Set the seeds of the environment.\"\"\"\n",
      "        return self.base_env.set_seed(seed, static_seed=static_seed)\n",
      "\n",
      "    def _set_seed(self, seed: Optional[int]):\n",
      "        \"\"\"This method is not used in transformed envs.\"\"\"\n",
      "        pass\n",
      "\n",
      "    def _reset(self, tensordict: Optional[TensorDictBase] = None, **kwargs):\n",
      "        if tensordict is not None:\n",
      "            tensordict = tensordict.clone(recurse=False)\n",
      "        out_tensordict = self.base_env.reset(tensordict=tensordict, **kwargs)\n",
      "        out_tensordict = self.transform.reset(out_tensordict)\n",
      "        out_tensordict = self.transform(out_tensordict)\n",
      "        return out_tensordict\n",
      "\n",
      "    def state_dict(self) -> OrderedDict:\n",
      "        state_dict = self.transform.state_dict()\n",
      "        return state_dict\n",
      "\n",
      "    def load_state_dict(self, state_dict: OrderedDict, **kwargs) -> None:\n",
      "        self.transform.load_state_dict(state_dict, **kwargs)\n",
      "\n",
      "    def eval(self) -> TransformedEnv:\n",
      "        if \"transform\" in self.__dir__():\n",
      "            # when calling __init__, eval() is called but transforms are not set\n",
      "            # yet.\n",
      "            self.transform.eval()\n",
      "        return self\n",
      "\n",
      "    def train(self, mode: bool = True) -> TransformedEnv:\n",
      "        self.transform.train(mode)\n",
      "        return self\n",
      "\n",
      "    @property\n",
      "    def is_closed(self) -> bool:\n",
      "        return self.base_env.is_closed\n",
      "\n",
      "    @is_closed.setter\n",
      "    def is_closed(self, value: bool):\n",
      "        self.base_env.is_closed = value\n",
      "\n",
      "    def close(self):\n",
      "        self.base_env.close()\n",
      "        self.is_closed = True\n",
      "\n",
      "    def empty_cache(self):\n",
      "        self.__dict__[\"_observation_spec\"] = None\n",
      "        self.__dict__[\"_input_spec\"] = None\n",
      "        self.__dict__[\"_reward_spec\"] = None\n",
      "\n",
      "    def append_transform(self, transform: Transform) -> None:\n",
      "        self._erase_metadata()\n",
      "        if not isinstance(transform, Transform):\n",
      "            raise ValueError(\n",
      "                \"TransformedEnv.append_transform expected a transform but received an object of \"\n"
     ]
    }
   ],
   "source": [
    "## View Prompt Examples\n",
    "import json\n",
    "\n",
    "# Function to read a JSON Lines file and return the prompt of a desired line\n",
    "def get_prompt_at_line(jsonl_file_path, desired_line_no):\n",
    "    with open(jsonl_file_path, 'r') as file:\n",
    "        for line_no, line in enumerate(file, start=1):\n",
    "            if line_no == desired_line_no:\n",
    "                json_object = json.loads(line)\n",
    "                prompt = json_object.get('prompt', None)\n",
    "                return prompt\n",
    "    return None  # Return None if the desired line was not found\n",
    "\n",
    "# Specify the .jsonl file path and the desired line number\n",
    "jsonl_file_path = 'subsets/rg-one-gram-ws-20-ss-2-fixed_0.1_with_instructions.jsonl'\n",
    "desired_line_no = 3  # For example, we want the prompt at line 10\n",
    "\n",
    "# Get the prompt at the desired line\n",
    "prompt_at_desired_line = get_prompt_at_line(jsonl_file_path, desired_line_no)\n",
    "\n",
    "if prompt_at_desired_line:\n",
    "    print(prompt_at_desired_line)\n",
    "else:\n",
    "    print(f\"No prompt found at line {desired_line_no}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference with the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the completion string\n",
    "def preprocess_completion(completion):\n",
    "    # Extract content within ``\n",
    "    if '```python' in completion:\n",
    "        start = completion.find('```python') + 9  # Start index of content inside ``\n",
    "        end = completion.rfind('```')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "    elif '```' in completion:\n",
    "        start = completion.find('```') + 3  # Start index of content inside ``\n",
    "        end = completion.rfind('```')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "    elif '`' in completion:\n",
    "        start = completion.find('`') + 1  # Start index of content inside ``\n",
    "        end = completion.rfind('`')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "\n",
    "    # Remove lines starting with '#'\n",
    "    lines = [line.split('#', 1)[0].rstrip() for line in completion.split('\\n')]\n",
    "    # Save only the first non-empty line\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            return \" \".join(line.split()).replace(\"( \", \"(\").replace(\" )\", \")\")\n",
    "    return \"\"  # Return empty string if no non-empty lines are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess api completions\n",
    "def preprocess_api_completion(completion):\n",
    "    # Extract content within ``\n",
    "    if '```python' in completion:\n",
    "        start = completion.find('```python') + 9  # Start index of content inside ``\n",
    "        end = completion.rfind('```')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "    elif '```' in completion:\n",
    "        start = completion.find('```') + 3  # Start index of content inside ``\n",
    "        end = completion.rfind('```')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "    elif '`' in completion:\n",
    "        start = completion.find('`') + 1  # Start index of content inside ``\n",
    "        end = completion.rfind('`')  # End index of content inside ``\n",
    "        completion = completion[start:end]\n",
    "\n",
    "    # Remove lines starting with '#'\n",
    "    lines = [line.split('#', 1)[0].rstrip() for line in completion.split('\\n')]\n",
    "    # Save only the first non-empty line\n",
    "    final_string = \"\"\n",
    "    for line in lines:\n",
    "        final_string += line\n",
    "    return \" \".join(final_string.split()).replace(\"( \", \"(\").replace(\" )\", \")\")  # Return empty string if no non-empty lines are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learned_classifier_free_sampling_embeddings = LearnedClassifierFreeSamplingEmbeddings(learnable=True, hidden_size=self.text_embedder_hidden_size, length=tokenizer.model_max_length)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_api_completion(\"        learned_classifier_free_sampling_embeddings = LearnedClassifierFreeSamplingEmbeddings(\\n            learnable=True, hidden_size=self.text_embedder_hidden_size, length=tokenizer.model_max_length\\n        )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure to tell the model what it actually has to do as well (as given in paper)\n",
    "def rreplace(s, old, new, occurrence):\n",
    "    li = s.rsplit(old, occurrence)\n",
    "    return new.join(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"subsets/rg-one-gram-ws-20-ss-2-fixed_0.1.jsonl\", 'r') as original_file, open(\"subsets/rg-one-gram-ws-20-ss-2-fixed_0.1_with_instructions.jsonl\", 'w') as output_file:\n",
    "    for line in original_file:\n",
    "        entry = json.loads(line.strip())\n",
    "        completion = entry['prompt']\n",
    "        metadata = entry[\"metadata\"]\n",
    "        \n",
    "        output_entry = {\n",
    "            \"prompt\": rreplace(entry['prompt'],\"# --------------------------------------------------\",'# --------------------------------------------------\\n\"\"\"Based on the above, complete the following code:\"\"\"',1),\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "        output_file.write(json.dumps(output_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Input and output JSONL file paths\n",
    "base_jsonl_name = \"rg-one-gram-ws-20-ss-2-fixed_0.1_with_instructions_temp_0\"\n",
    "\n",
    "use_system_message = False\n",
    "\n",
    "if use_system_message:\n",
    "    ending = \".jsonl\"\n",
    "else:\n",
    "    ending = \"_no_system.jsonl\"\n",
    "\n",
    "# Original and preprocessed JSONL file paths\n",
    "original_responses_path = 'raw_generations/' + base_jsonl_name + '_raw_generations' + ending\n",
    "input_jsonl_file_path = 'subsets/' + base_jsonl_name + '.jsonl'\n",
    "output_jsonl_file_path = \"processed_generations/\" + base_jsonl_name + \"_generations\" + ending\n",
    "\n",
    "#Predefined system message\n",
    "system_message = '''Respond with only the next line completion'''\n",
    "\n",
    "# Function to process a single JSONL entry\n",
    "def process_entry(entry, model_name=\"gpt-3.5-turbo-0613\"):\n",
    "    prompt = entry['prompt']\n",
    "    if use_system_message:\n",
    "        messages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    else:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Generate the completion with the OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        max_tokens=250,  # Limit the number of generated tokens (adjust as needed)\n",
    "        temperature=0,  # Adjust for creativity of the response\n",
    "        seed = 1,\n",
    "        n=1,  # Number of completions to generate\n",
    "    )\n",
    "    \n",
    "    # Extract the text of the completion generated by the model\n",
    "    generated_completion = response.choices[0].message.content\n",
    "    return generated_completion\n",
    "\n",
    "# Read the input JSONL file and generate completions\n",
    "with open(input_jsonl_file_path, 'r') as input_file, open(original_responses_path, 'w') as original_file:\n",
    "    for line in input_file:\n",
    "        entry = json.loads(line.strip())\n",
    "        metadata = entry[\"metadata\"]\n",
    "        output_entry = process_entry(entry)\n",
    "        \n",
    "        # Save the original response to a new JSONL\n",
    "        original_file.write(json.dumps({\"prompt\": entry['prompt'], \"completion\": output_entry, \"metadata\" : metadata}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, read the original responses JSONL, preprocess, and write back out to the second JSONL\n",
    "with open(original_responses_path, 'r') as original_file, open(output_jsonl_file_path.replace(\".jsonl\",\"_processed.jsonl\"), 'w') as output_file:\n",
    "    for line in original_file:\n",
    "        entry = json.loads(line.strip())\n",
    "        completion = entry['completion']\n",
    "        metadata = entry[\"metadata\"]\n",
    "        metadata[\"ground_truth\"] = preprocess_completion(metadata[\"ground_truth\"])\n",
    "        preprocessed_completion = preprocess_completion(completion)\n",
    "        \n",
    "        output_entry = {\n",
    "            \"prompt\": entry['prompt'],\n",
    "            \"choices\": [{\"text\": preprocessed_completion}],\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "        output_file.write(json.dumps(output_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, read the original responses JSONL, preprocess, and write back out to the second JSONL\n",
    "with open(original_responses_path, 'r') as original_file, open(output_jsonl_file_path.replace(\".jsonl\",\"_not_processed.jsonl\"), 'w') as output_file:\n",
    "    for line in original_file:\n",
    "        entry = json.loads(line.strip())\n",
    "        completion = entry['completion']\n",
    "        metadata = entry[\"metadata\"]\n",
    "        preprocessed_completion = completion\n",
    "        \n",
    "        output_entry = {\n",
    "            \"prompt\": entry['prompt'],\n",
    "            \"choices\": [{\"text\": preprocessed_completion}],\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        \n",
    "        output_file.write(json.dumps(output_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "# Now, read the original responses JSONL, preprocess, and write back out to the second JSONL\n",
    "with open(\"processed_generations/rg-one-gram-ws-20-ss-2-fixed_0.1_with_instructions_generations.jsonl\", 'r') as original_file, open(\"processed_generations/rg-one-gram-ws-20-ss-2-fixed_0.1_with_instructions_generations.jsonl\".replace(\".jsonl\",\"_gt.jsonl\"), 'w') as output_file:\n",
    "    for line in original_file:\n",
    "        entry = json.loads(line.strip())\n",
    "        completion = entry['choices'][0][\"text\"]\n",
    "        ground_truth = entry[\"metadata\"][\"ground_truth\"]\n",
    "        \n",
    "        output_entry = {\n",
    "            \"completion\": completion,\n",
    "            \"ground_truth\": preprocess_completion(ground_truth)\n",
    "        }\n",
    "        \n",
    "        output_file.write(json.dumps(output_entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import annotations\n",
      "\n",
      "import logging\n",
      "from typing import Optional, Tuple\n",
      "\n",
      "import jax.numpy as jnp\n",
      "from flax.core import FrozenDict\n",
      "from jax._src.prng import PRNGKeyArray\n",
      "from jax.flatten_util import ravel_pytree\n",
      "\n",
      "from fortuna.data.loader import DataLoader, InputsLoader\n",
      "from fortuna.distribution.gaussian import DiagGaussian\n",
      "from fortuna.prob_model.fit_config import FitConfig\n",
      "from fortuna.prob_model.joint.base import Joint\n",
      "from fortuna.prob_model.joint.state import JointState\n",
      "from fortuna.prob_model.posterior.base import Posterior\n",
      "from fortuna.prob_model.posterior.normalizing_flow.advi import ADVI_NAME\n",
      "from fortuna.prob_model.posterior.normalizing_flow.advi.advi_approximator import \\\n",
      "    ADVIPosteriorApproximator\n",
      "from fortuna.prob_model.posterior.normalizing_flow.advi.advi_architecture import \\\n",
      "    ADVIArchitecture\n",
      "from fortuna.prob_model.posterior.normalizing_flow.advi.advi_state import \\\n",
      "    ADVIState\n",
      "from fortuna.prob_model.posterior.normalizing_flow.advi.advi_trainer import \\\n",
      "    ADVITrainer\n",
      "from fortuna.prob_model.posterior.posterior_state_repository import \\\n",
      "    PosteriorStateRepository\n",
      "from fortuna.training.trainer import JittedMixin, MultiDeviceMixin\n",
      "from fortuna.typing import Array, Status\n",
      "from fortuna.utils.device import select_trainer_given_devices\n",
      "\n",
      "\n",
      "class JittedADVITrainer(JittedMixin, ADVITrainer):\n",
      "    pass\n",
      "\n",
      "\n",
      "class MultiDeviceADVITrainer(MultiDeviceMixin, ADVITrainer):\n",
      "    pass\n",
      "\n",
      "\n",
      "class ADVIPosterior(Posterior):\n",
      "    def __init__(\n",
      "        self, joint: Joint, posterior_approximator: ADVIPosteriorApproximator,\n",
      "    ):\n",
      "        \"\"\"\n",
      "        Automatic Differentiation Variational Inference (ADVI) approximate posterior class.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        joint: Joint\n",
      "            A joint distribution object.\n",
      "        posterior_approximator: ADVI\n",
      "            An ADVI posterior approximator.\n",
      "        \"\"\"\n",
      "        super().__init__(joint=joint, posterior_approximator=posterior_approximator)\n",
      "\n",
      "    def __str__(self):\n",
      "        return ADVI_NAME\n",
      "\n",
      "    def fit(\n",
      "        self,\n",
      "        train_data_loader: DataLoader,\n",
      "        val_data_loader: Optional[DataLoader] = None,\n",
      "        fit_config: FitConfig = FitConfig(),\n",
      "        **kwargs,\n",
      "    ) -> Status:\n",
      "        if (\n",
      "            fit_config.checkpointer.dump_state is True\n",
      "            and not fit_config.checkpointer.save_checkpoint_dir\n",
      "        ):\n",
      "            raise ValueError(\n",
      "                \"`save_checkpoint_dir` must be passed when `dump_state` is set to True.\"\n",
      "            )\n",
      "\n",
      "        init_prob_model_state, n_train_data, n_val_data = self._init(\n",
      "            train_data_loader, val_data_loader\n",
      "        )\n",
      "\n",
      "        rav, self.unravel = ravel_pytree(init_prob_model_state.params)\n",
      "        size_rav = len(rav)\n",
      "        self.base = DiagGaussian(\n",
      "            mean=jnp.zeros(size_rav),\n",
      "            std=self.posterior_approximator.std_base * jnp.ones(size_rav),\n",
      "        )\n",
      "        self.architecture = ADVIArchitecture(\n",
      "            size_rav, std_init_params=self.posterior_approximator.std_init_params\n",
      "        )\n",
      "\n",
      "        trainer_cls = select_trainer_given_devices(\n",
      "            devices=fit_config.processor.devices,\n",
      "            BaseTrainer=ADVITrainer,\n",
      "            JittedTrainer=JittedADVITrainer,\n",
      "            MultiDeviceTrainer=MultiDeviceADVITrainer,\n",
      "            disable_jit=fit_config.processor.disable_jit,\n",
      "        )\n",
      "\n",
      "        trainer = trainer_cls(\n",
      "            predict_fn=self.joint.likelihood.prob_output_layer.predict,\n",
      "            save_checkpoint_dir=fit_config.checkpointer.save_checkpoint_dir,\n",
      "            save_every_n_steps=fit_config.checkpointer.save_every_n_steps,\n",
      "            keep_top_n_checkpoints=fit_config.checkpointer.keep_top_n_checkpoints,\n",
      "            disable_training_metrics_computation=fit_config.monitor.disable_training_metrics_computation,\n",
      "            eval_every_n_epochs=fit_config.monitor.eval_every_n_epochs,\n",
      "            early_stopping_monitor=fit_config.monitor.early_stopping_monitor,\n",
      "            early_stopping_min_delta=fit_config.monitor.early_stopping_min_delta,\n",
      "            early_stopping_patience=fit_config.monitor.early_stopping_patience,\n",
      "            base=self.base,\n",
      "            architecture=self.architecture,\n",
      "        )\n",
      "\n",
      "        state = None\n",
      "        if fit_config.checkpointer.restore_checkpoint_path:\n",
      "            state = self.restore_checkpoint(\n",
      "                restore_checkpoint_path=fit_config.checkpointer.restore_checkpoint_path,\n",
      "                optimizer=fit_config.optimizer.method,\n",
      "            )\n",
      "\n",
      "        if type(state)!= ADVIState:\n"
     ]
    }
   ],
   "source": [
    "print(\"from __future__ import annotations\\n\\nimport logging\\nfrom typing import Optional, Tuple\\n\\nimport jax.numpy as jnp\\nfrom flax.core import FrozenDict\\nfrom jax._src.prng import PRNGKeyArray\\nfrom jax.flatten_util import ravel_pytree\\n\\nfrom fortuna.data.loader import DataLoader, InputsLoader\\nfrom fortuna.distribution.gaussian import DiagGaussian\\nfrom fortuna.prob_model.fit_config import FitConfig\\nfrom fortuna.prob_model.joint.base import Joint\\nfrom fortuna.prob_model.joint.state import JointState\\nfrom fortuna.prob_model.posterior.base import Posterior\\nfrom fortuna.prob_model.posterior.normalizing_flow.advi import ADVI_NAME\\nfrom fortuna.prob_model.posterior.normalizing_flow.advi.advi_approximator import \\\\\\n    ADVIPosteriorApproximator\\nfrom fortuna.prob_model.posterior.normalizing_flow.advi.advi_architecture import \\\\\\n    ADVIArchitecture\\nfrom fortuna.prob_model.posterior.normalizing_flow.advi.advi_state import \\\\\\n    ADVIState\\nfrom fortuna.prob_model.posterior.normalizing_flow.advi.advi_trainer import \\\\\\n    ADVITrainer\\nfrom fortuna.prob_model.posterior.posterior_state_repository import \\\\\\n    PosteriorStateRepository\\nfrom fortuna.training.trainer import JittedMixin, MultiDeviceMixin\\nfrom fortuna.typing import Array, Status\\nfrom fortuna.utils.device import select_trainer_given_devices\\n\\n\\nclass JittedADVITrainer(JittedMixin, ADVITrainer):\\n    pass\\n\\n\\nclass MultiDeviceADVITrainer(MultiDeviceMixin, ADVITrainer):\\n    pass\\n\\n\\nclass ADVIPosterior(Posterior):\\n    def __init__(\\n        self, joint: Joint, posterior_approximator: ADVIPosteriorApproximator,\\n    ):\\n        \\\"\\\"\\\"\\n        Automatic Differentiation Variational Inference (ADVI) approximate posterior class.\\n\\n        Parameters\\n        ----------\\n        joint: Joint\\n            A joint distribution object.\\n        posterior_approximator: ADVI\\n            An ADVI posterior approximator.\\n        \\\"\\\"\\\"\\n        super().__init__(joint=joint, posterior_approximator=posterior_approximator)\\n\\n    def __str__(self):\\n        return ADVI_NAME\\n\\n    def fit(\\n        self,\\n        train_data_loader: DataLoader,\\n        val_data_loader: Optional[DataLoader] = None,\\n        fit_config: FitConfig = FitConfig(),\\n        **kwargs,\\n    ) -> Status:\\n        if (\\n            fit_config.checkpointer.dump_state is True\\n            and not fit_config.checkpointer.save_checkpoint_dir\\n        ):\\n            raise ValueError(\\n                \\\"`save_checkpoint_dir` must be passed when `dump_state` is set to True.\\\"\\n            )\\n\\n        init_prob_model_state, n_train_data, n_val_data = self._init(\\n            train_data_loader, val_data_loader\\n        )\\n\\n        rav, self.unravel = ravel_pytree(init_prob_model_state.params)\\n        size_rav = len(rav)\\n        self.base = DiagGaussian(\\n            mean=jnp.zeros(size_rav),\\n            std=self.posterior_approximator.std_base * jnp.ones(size_rav),\\n        )\\n        self.architecture = ADVIArchitecture(\\n            size_rav, std_init_params=self.posterior_approximator.std_init_params\\n        )\\n\\n        trainer_cls = select_trainer_given_devices(\\n            devices=fit_config.processor.devices,\\n            BaseTrainer=ADVITrainer,\\n            JittedTrainer=JittedADVITrainer,\\n            MultiDeviceTrainer=MultiDeviceADVITrainer,\\n            disable_jit=fit_config.processor.disable_jit,\\n        )\\n\\n        trainer = trainer_cls(\\n            predict_fn=self.joint.likelihood.prob_output_layer.predict,\\n            save_checkpoint_dir=fit_config.checkpointer.save_checkpoint_dir,\\n            save_every_n_steps=fit_config.checkpointer.save_every_n_steps,\\n            keep_top_n_checkpoints=fit_config.checkpointer.keep_top_n_checkpoints,\\n            disable_training_metrics_computation=fit_config.monitor.disable_training_metrics_computation,\\n            eval_every_n_epochs=fit_config.monitor.eval_every_n_epochs,\\n            early_stopping_monitor=fit_config.monitor.early_stopping_monitor,\\n            early_stopping_min_delta=fit_config.monitor.early_stopping_min_delta,\\n            early_stopping_patience=fit_config.monitor.early_stopping_patience,\\n            base=self.base,\\n            architecture=self.architecture,\\n        )\\n\\n        state = None\\n        if fit_config.checkpointer.restore_checkpoint_path:\\n            state = self.restore_checkpoint(\\n                restore_checkpoint_path=fit_config.checkpointer.restore_checkpoint_path,\\n                optimizer=fit_config.optimizer.method,\\n            )\\n\\n        if type(state)!= ADVIState:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if Generated Code is Syntactically Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pylint'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpylint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m epylint \u001b[38;5;28;01mas\u001b[39;00m lint\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIO\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_generated_code\u001b[39m(file_code, gen_code):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pylint'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from pylint import epylint as lint\n",
    "from io import StringIO\n",
    "\n",
    "def check_generated_code(file_code, gen_code):\n",
    "    combined_code = file_code + \"\\n\" + gen_code\n",
    "    \n",
    "    # Syntax & Indentation Check\n",
    "    try:\n",
    "        # Attempt to parse the combined code into an AST\n",
    "        ast.parse(combined_code)\n",
    "    except (SyntaxError, IndentationError) as e:\n",
    "        return f\"Syntax or indentation error: {e}\"\n",
    "\n",
    "    # Static Analysis\n",
    "    # Save the combined code to a temporary file or use StringIO\n",
    "    temp_file_path = 'temp_code.py'\n",
    "    with open(temp_file_path, 'w') as temp_file:\n",
    "        temp_file.write(combined_code)\n",
    "    \n",
    "    # Run pylint on the file\n",
    "    (pylint_stdout, pylint_stderr) = lint.py_run(temp_file_path, return_std=True)\n",
    "    stdout, stderr = pylint_stdout.getvalue(), pylint_stderr.getvalue()\n",
    "    \n",
    "    # Assuming you are interested in errors (convention/refactor/warning messages may be ignored)\n",
    "    if stdout.strip():\n",
    "        return f\"Pylint found issues with the code:\\n{stdout}\"\n",
    "    \n",
    "    return \"Generated code passed all checks.\"\n",
    "\n",
    "# Example usage\n",
    "file_code = \"\"\"\n",
    "def existing_function():\n",
    "    pass\n",
    "\"\"\"\n",
    "\n",
    "gen_code = \"\"\"\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "\"\"\"\n",
    "\n",
    "result = check_generated_code(file_code, gen_code)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use compute_score.py to evalaute "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
